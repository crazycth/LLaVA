[2023-11-15 07:05:45,047] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:47,677] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-11-15 07:05:47,677] [INFO] [runner.py:555:main] cmd = /root/anaconda3/envs/llava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train.py --deepspeed ./scripts/zero3.json --model_name_or_path /remote-home/ThCheng/weights/Atom_7B_chat --version llava_llama_2 --data_path new_file_100.json --image_folder /remote-home/ThCheng/dataset --vision_tower openai/clip-vit-large-patch14-336 --mm_projector_type linear --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length False --bf16 False --fp16 True --bits 16 --output_dir /root/code/LLaVA/checkpoints/flamingo --num_train_epochs 1 --per_device_train_batch_size 3 --per_device_eval_batch_size 1 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 False --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb
[2023-11-15 07:05:49,471] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:52,064] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2023-11-15 07:05:52,064] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2023-11-15 07:05:52,064] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2023-11-15 07:05:52,064] [INFO] [launch.py:163:main] dist_world_size=8
[2023-11-15 07:05:52,064] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2023-11-15 07:05:55,899] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:55,938] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:55,974] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:56,015] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:56,016] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:56,048] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:56,088] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:56,091] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-15 07:05:57,128] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-15 07:05:57,128] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-15 07:05:57,128] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-15 07:05:57,128] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-15 07:05:57,128] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-15 07:05:57,128] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-15 07:05:57,128] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-15 07:05:57,128] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-15 07:05:57,128] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-15 07:05:57,128] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-15 07:05:57,128] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-15 07:05:57,128] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-15 07:05:57,128] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-11-15 07:05:57,128] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-15 07:05:57,128] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-15 07:05:57,128] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-15 07:05:57,128] [INFO] [comm.py:594:init_distributed] cdb=None
[INFO] model_args: ModelArguments(model_name_or_path='/remote-home/ThCheng/weights/Atom_7B_chat', version='llava_llama_2', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='openai/clip-vit-large-patch14-336', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter=None, mm_projector_type='linear', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch', perceiver_token_num=32, perceiver_max_frames=22, perceiver_max_image=4)
[INFO] data_args: DataArguments(data_path='new_file_100.json', lazy_preprocess=True, is_multimodal=False, image_folder='/remote-home/ThCheng/dataset', image_aspect_ratio='pad', image_grid_pinpoints=None)
[INFO] train_args: TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
bits=16,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=./scripts/zero3.json,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=False,
double_quant=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
freeze_mm_mlp_adapter=False,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
greater_is_better=None,
group_by_length=False,
group_by_modality_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0002,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/code/LLaVA/checkpoints/flamingo/runs/Nov15_07-05-57_e4186e1cbe2d,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lora_alpha=16,
lora_bias=none,
lora_dropout=0.05,
lora_enable=False,
lora_r=64,
lora_weight_path=,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mm_projector_lr=None,
model_max_length=2048,
mp_parameters=,
mpt_attn_impl=triton,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/code/LLaVA/checkpoints/flamingo,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=3,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
quant_type=nf4,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/root/code/LLaVA/checkpoints/flamingo,
save_on_each_node=False,
save_safetensors=False,
save_steps=50000,
save_strategy=steps,
save_total_limit=1,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=False,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
[2023-11-15 07:06:04,710] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 7.01B parameters
[2023-11-15 07:12:27,431] [WARNING] [partition_parameters.py:836:_post_init_method] param `class_embedding` in CLIPVisionEmbeddings not on GPU so was not broadcasted from rank 0
[2023-11-15 07:12:27,797] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 7.31B parameters
[INFO] paramerter: model.embed_tokens.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.0.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.norm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.class_embedding, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.bias, Froze: True
[INFO] paramerter: model.mm_projector.weight, Froze: False
[INFO] paramerter: model.mm_projector.bias, Froze: False
[INFO] paramerter: model.perceiver.latents, Froze: False
[INFO] paramerter: model.perceiver.frame_embs, Froze: False
[INFO] paramerter: model.perceiver.media_time_embs, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.bias, Froze: False
[INFO] paramerter: lm_head.weight, Froze: False
[INFO] paramerter: model.embed_tokens.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.0.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.norm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.class_embedding, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.bias, Froze: True
[INFO] paramerter: model.mm_projector.weight, Froze: False
[INFO] paramerter: model.mm_projector.bias, Froze: False
[INFO] paramerter: model.perceiver.latents, Froze: False
[INFO] paramerter: model.perceiver.frame_embs, Froze: False
[INFO] paramerter: model.perceiver.media_time_embs, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.bias, Froze: False
[INFO] paramerter: lm_head.weight, Froze: False
Formatting inputs...Skip in lazy mode
[INFO] paramerter: model.embed_tokens.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.0.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.norm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.class_embedding, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.embed_tokens.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias, Froze: True[INFO] paramerter: model.layers.0.self_attn.q_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.0.self_attn.k_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.0.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.0.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias, Froze: True[INFO] paramerter: model.layers.0.mlp.gate_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.layers.0.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.layers.0.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight, Froze: True
[INFO] paramerter: model.layers.0.input_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias, Froze: True

[INFO] paramerter: model.layers.0.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.1.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight, Froze: True[INFO] paramerter: model.layers.1.self_attn.k_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.1.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.layers.1.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.1.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias, Froze: True[INFO] paramerter: model.layers.1.mlp.up_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.1.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight, Froze: True[INFO] paramerter: model.layers.1.input_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.1.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.2.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.layers.2.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.2.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias, Froze: True

[INFO] paramerter: model.layers.2.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.2.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.2.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias, Froze: True[INFO] paramerter: model.layers.2.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias, Froze: True[INFO] paramerter: model.layers.2.input_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight, Froze: True[INFO] paramerter: model.layers.2.post_attention_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.3.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.3.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.3.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight, Froze: True[INFO] paramerter: model.layers.3.self_attn.o_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.3.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.3.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias, Froze: True[INFO] paramerter: model.layers.3.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.layers.3.input_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias, Froze: True

[INFO] paramerter: model.layers.3.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight, Froze: True[INFO] paramerter: model.layers.4.self_attn.q_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.4.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.layers.4.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.4.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.4.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.4.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.layers.4.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.layers.4.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.4.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias, Froze: True[INFO] paramerter: model.layers.5.self_attn.q_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight, Froze: True
[INFO] paramerter: model.layers.5.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.5.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.layers.5.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.layers.5.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.5.mlp.up_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias, Froze: True

[INFO] paramerter: model.layers.5.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.5.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.layers.5.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.layers.6.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.6.self_attn.k_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight, Froze: True[INFO] paramerter: model.layers.6.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.6.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.6.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias, Froze: True[INFO] paramerter: model.layers.6.mlp.up_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight, Froze: True[INFO] paramerter: model.layers.6.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.6.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias, Froze: True[INFO] paramerter: model.layers.6.post_attention_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.7.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias, Froze: True[INFO] paramerter: model.layers.7.self_attn.k_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.7.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.layers.7.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.7.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias, Froze: True[INFO] paramerter: model.layers.7.mlp.up_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.7.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.7.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.7.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.8.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.8.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.layers.8.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.8.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight, Froze: True
[INFO] paramerter: model.layers.8.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias, Froze: True

[INFO] paramerter: model.layers.8.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias, Froze: True[INFO] paramerter: model.layers.8.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.8.input_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight, Froze: True[INFO] paramerter: model.layers.8.post_attention_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.9.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.9.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.layers.9.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias, Froze: True

[INFO] paramerter: model.layers.9.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight, Froze: True[INFO] paramerter: model.layers.9.mlp.gate_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.layers.9.mlp.up_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.9.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.layers.9.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.9.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.10.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias, Froze: True

[INFO] paramerter: model.layers.10.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias, Froze: True[INFO] paramerter: model.layers.10.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.layers.10.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.layers.10.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.10.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.layers.10.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.10.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.layers.10.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.layers.11.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.11.self_attn.k_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias, Froze: True

[INFO] paramerter: model.layers.11.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias, Froze: True[INFO] paramerter: model.layers.11.self_attn.o_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.11.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.layers.11.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.11.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight, Froze: True
[INFO] paramerter: model.layers.11.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.11.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.12.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.layers.12.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.12.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias, Froze: True

[INFO] paramerter: model.layers.12.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.12.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.12.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.layers.12.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.12.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.layers.12.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.13.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.13.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.13.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias, Froze: True

[INFO] paramerter: model.layers.13.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.13.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.13.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.layers.13.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.layers.13.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.layers.13.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight, Froze: True[INFO] paramerter: model.layers.14.self_attn.q_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.14.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.layers.14.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.14.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.14.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.14.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.layers.14.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.layers.14.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.14.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight, Froze: True[INFO] paramerter: model.layers.15.self_attn.q_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.layers.15.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias, Froze: True[INFO] paramerter: model.layers.15.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.layers.15.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight, Froze: True[INFO] paramerter: model.layers.15.mlp.gate_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.layers.15.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias, Froze: True[INFO] paramerter: model.layers.15.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight, Froze: True[INFO] paramerter: model.layers.15.input_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.15.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.16.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.layers.16.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.16.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias, Froze: True

[INFO] paramerter: model.layers.16.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.16.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias, Froze: True[INFO] paramerter: model.layers.16.mlp.up_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.16.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight, Froze: True[INFO] paramerter: model.layers.16.input_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.16.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.17.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias, Froze: True[INFO] paramerter: model.layers.17.self_attn.k_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.layers.17.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight, Froze: True[INFO] paramerter: model.layers.17.self_attn.o_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.layers.17.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.17.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight, Froze: True[INFO] paramerter: model.layers.17.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.17.input_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.layers.17.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.18.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.layers.18.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.18.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.18.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.layers.18.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.layers.18.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight, Froze: True
[INFO] paramerter: model.layers.18.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias, Froze: True

[INFO] paramerter: model.layers.18.input_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.18.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.layers.19.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.19.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight, Froze: True[INFO] paramerter: model.layers.19.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.19.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.19.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.layers.19.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias, Froze: True[INFO] paramerter: model.layers.19.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight, Froze: True
[INFO] paramerter: model.layers.19.input_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias, Froze: True

[INFO] paramerter: model.layers.19.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.20.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.layers.20.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.20.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias, Froze: True

[INFO] paramerter: model.layers.20.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.20.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.20.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias, Froze: True[INFO] paramerter: model.layers.20.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias, Froze: True[INFO] paramerter: model.layers.20.input_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight, Froze: True
[INFO] paramerter: model.layers.20.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.21.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.21.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.21.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias, Froze: True

[INFO] paramerter: model.layers.21.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.21.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.21.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.layers.21.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.21.input_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.layers.21.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias, Froze: True
[INFO] paramerter: model.layers.22.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.layers.22.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.22.self_attn.v_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight, Froze: True
[INFO] paramerter: model.layers.22.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight, Froze: True[INFO] paramerter: model.layers.22.mlp.gate_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.layers.22.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.layers.22.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias, Froze: True[INFO] paramerter: model.layers.22.input_layernorm.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.layers.22.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight, Froze: True
[INFO] paramerter: model.layers.23.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias, Froze: True

[INFO] paramerter: model.layers.23.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias, Froze: True[INFO] paramerter: model.layers.23.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.layers.23.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias, Froze: True

[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias, Froze: True
[INFO] paramerter: model.layers.23.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.weight, Froze: True
[INFO] paramerter: model.layers.23.mlp.up_proj.weight, Froze: False[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.bias, Froze: True

[INFO] paramerter: model.layers.23.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.mm_projector.weight, Froze: False
[INFO] paramerter: model.mm_projector.bias, Froze: False[INFO] paramerter: model.layers.23.input_layernorm.weight, Froze: False

[INFO] paramerter: model.perceiver.latents, Froze: False[INFO] paramerter: model.layers.23.post_attention_layernorm.weight, Froze: False

[INFO] paramerter: model.perceiver.frame_embs, Froze: False
[INFO] paramerter: model.perceiver.media_time_embs, Froze: False
[INFO] paramerter: model.layers.24.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.weight, Froze: False[INFO] paramerter: model.layers.24.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.0.0.norm_media.bias, Froze: False
[INFO] paramerter: model.layers.24.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.layers.24.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_q.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_kv.weight, Froze: False[INFO] paramerter: model.layers.24.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.0.0.to_out.weight, Froze: False[INFO] paramerter: model.layers.24.input_layernorm.weight, Froze: False

[INFO] paramerter: model.layers.24.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.bias, Froze: False
[INFO] paramerter: model.layers.25.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.1.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.3.weight, Froze: False[INFO] paramerter: model.layers.25.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.layers.25.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.bias, Froze: False
[INFO] paramerter: model.layers.25.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.bias, Froze: False[INFO] paramerter: model.layers.25.mlp.up_proj.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.1.0.to_q.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_kv.weight, Froze: False
[INFO] paramerter: model.layers.25.input_layernorm.weight, Froze: False[INFO] paramerter: model.perceiver.layers.1.0.to_out.weight, Froze: False

[INFO] paramerter: model.layers.25.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.bias, Froze: False
[INFO] paramerter: model.layers.26.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.perceiver.layers.1.1.1.weight, Froze: False

[INFO] paramerter: model.layers.26.self_attn.k_proj.weight, Froze: False[INFO] paramerter: model.perceiver.layers.1.1.3.weight, Froze: False

[INFO] paramerter: model.layers.26.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.bias, Froze: False

[INFO] paramerter: model.perceiver.layers.2.0.to_q.weight, Froze: False[INFO] paramerter: model.layers.26.mlp.up_proj.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.2.0.to_kv.weight, Froze: False[INFO] paramerter: model.layers.26.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.2.0.to_out.weight, Froze: False
[INFO] paramerter: model.layers.26.input_layernorm.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.weight, Froze: False
[INFO] paramerter: model.layers.26.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.perceiver.layers.2.1.0.bias, Froze: False

[INFO] paramerter: model.perceiver.layers.2.1.1.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.3.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.weight, Froze: False[INFO] paramerter: model.layers.27.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.3.0.norm_media.bias, Froze: False
[INFO] paramerter: model.layers.27.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.layers.27.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_q.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_kv.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_out.weight, Froze: False
[INFO] paramerter: model.layers.27.input_layernorm.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.bias, Froze: False
[INFO] paramerter: model.layers.27.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.3.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.bias, Froze: False
[INFO] paramerter: model.layers.28.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.o_proj.weight, Froze: False[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.bias, Froze: False

[INFO] paramerter: model.perceiver.layers.4.0.to_q.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.gate_proj.weight, Froze: False[INFO] paramerter: model.perceiver.layers.4.0.to_kv.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.4.0.to_out.weight, Froze: False[INFO] paramerter: model.layers.28.mlp.up_proj.weight, Froze: False

[INFO] paramerter: model.layers.28.mlp.down_proj.weight, Froze: False[INFO] paramerter: model.perceiver.layers.4.1.0.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.4.1.0.bias, Froze: False
[INFO] paramerter: model.layers.28.input_layernorm.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.1.weight, Froze: False
[INFO] paramerter: model.layers.28.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.3.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.q_proj.weight, Froze: False[INFO] paramerter: model.perceiver.layers.5.0.norm_media.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.5.0.norm_media.bias, Froze: False
[INFO] paramerter: model.layers.29.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.bias, Froze: False[INFO] paramerter: model.layers.29.self_attn.v_proj.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.5.0.to_q.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_out.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.up_proj.weight, Froze: False[INFO] paramerter: model.perceiver.layers.5.1.0.bias, Froze: False

[INFO] paramerter: model.perceiver.layers.5.1.1.weight, Froze: False[INFO] paramerter: model.layers.29.mlp.down_proj.weight, Froze: False

[INFO] paramerter: model.perceiver.layers.5.1.3.weight, Froze: False
[INFO] paramerter: model.layers.29.input_layernorm.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.weight, Froze: False
[INFO] paramerter: model.layers.29.post_attention_layernorm.weight, Froze: False[INFO] paramerter: model.perceiver.norm.bias, Froze: False

[INFO] paramerter: lm_head.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.norm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.class_embedding, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.bias, Froze: True
[INFO] paramerter: model.mm_projector.weight, Froze: False
[INFO] paramerter: model.mm_projector.bias, Froze: False
[INFO] paramerter: model.perceiver.latents, Froze: False
[INFO] paramerter: model.perceiver.frame_embs, Froze: False
[INFO] paramerter: model.perceiver.media_time_embs, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.bias, Froze: False
[INFO] paramerter: lm_head.weight, Froze: False
[INFO] paramerter: model.embed_tokens.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.0.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.norm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.class_embedding, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.bias, Froze: True
[INFO] paramerter: model.mm_projector.weight, Froze: False
[INFO] paramerter: model.mm_projector.bias, Froze: False
[INFO] paramerter: model.perceiver.latents, Froze: False
[INFO] paramerter: model.perceiver.frame_embs, Froze: False
[INFO] paramerter: model.perceiver.media_time_embs, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.bias, Froze: False
[INFO] paramerter: lm_head.weight, Froze: False
[INFO] paramerter: model.embed_tokens.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.0.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.norm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.class_embedding, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.bias, Froze: True
[INFO] paramerter: model.mm_projector.weight, Froze: False
[INFO] paramerter: model.mm_projector.bias, Froze: False
[INFO] paramerter: model.perceiver.latents, Froze: False
[INFO] paramerter: model.perceiver.frame_embs, Froze: False
[INFO] paramerter: model.perceiver.media_time_embs, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.bias, Froze: False
[INFO] paramerter: lm_head.weight, Froze: False
[INFO] paramerter: model.embed_tokens.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.0.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.norm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.class_embedding, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.bias, Froze: True
[INFO] paramerter: model.mm_projector.weight, Froze: False
[INFO] paramerter: model.mm_projector.bias, Froze: False
[INFO] paramerter: model.perceiver.latents, Froze: False
[INFO] paramerter: model.perceiver.frame_embs, Froze: False
[INFO] paramerter: model.perceiver.media_time_embs, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.bias, Froze: False
[INFO] paramerter: lm_head.weight, Froze: False
[INFO] paramerter: model.embed_tokens.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.0.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.0.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.1.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.1.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.2.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.2.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.3.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.3.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.4.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.4.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.5.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.5.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.6.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.6.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.7.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.7.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.8.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.8.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.9.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.9.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.10.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.10.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.11.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.11.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.12.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.12.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.13.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.13.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.14.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.14.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.15.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.15.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.16.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.16.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.17.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.17.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.18.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.18.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.19.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.19.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.20.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.20.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.21.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.21.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.22.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.22.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.23.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.23.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.24.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.24.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.25.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.25.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.26.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.26.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.27.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.27.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.28.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.28.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.29.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.29.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.30.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.30.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.q_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.k_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.v_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.self_attn.o_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.gate_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.up_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.mlp.down_proj.weight, Froze: False
[INFO] paramerter: model.layers.31.input_layernorm.weight, Froze: False
[INFO] paramerter: model.layers.31.post_attention_layernorm.weight, Froze: False
[INFO] paramerter: model.norm.weight, Froze: False
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.class_embedding, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.weight, Froze: True
[INFO] paramerter: model.vision_tower.vision_tower.vision_model.post_layernorm.bias, Froze: True
[INFO] paramerter: model.mm_projector.weight, Froze: False
[INFO] paramerter: model.mm_projector.bias, Froze: False
[INFO] paramerter: model.perceiver.latents, Froze: False
[INFO] paramerter: model.perceiver.frame_embs, Froze: False
[INFO] paramerter: model.perceiver.media_time_embs, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.0.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.1.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.2.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.3.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.4.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_media.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.norm_latents.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_q.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_kv.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.0.to_out.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.0.bias, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.1.weight, Froze: False
[INFO] paramerter: model.perceiver.layers.5.1.3.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.weight, Froze: False
[INFO] paramerter: model.perceiver.norm.bias, Froze: False
[INFO] paramerter: lm_head.weight, Froze: False
[INFO] medical_state_dict: {'model.embed_tokens.weight': tensor([[-0.0013,  0.0004, -0.0018,  ...,  0.0004, -0.0038, -0.0033],
        [ 0.0011, -0.0046, -0.0005,  ..., -0.0079, -0.0010,  0.0003],
        [ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
        ...,
        [-0.0052,  0.0041, -0.0056,  ..., -0.0011,  0.0072,  0.0068],
        [ 0.0075, -0.0039,  0.0058,  ...,  0.0447,  0.0135, -0.0091],
        [-0.0026,  0.0215, -0.0237,  ..., -0.0354,  0.0114,  0.0210]],
       dtype=torch.float16), 'model.layers.0.self_attn.q_proj.weight': tensor([[-9.6512e-03, -1.4015e-02, -1.5736e-03,  ...,  2.1338e-05,
          1.3115e-02, -3.8280e-03],
        [ 2.9144e-02,  4.8027e-03,  5.9013e-03,  ..., -1.3435e-02,
         -8.2550e-03,  1.8204e-02],
        [-1.3481e-02,  1.8463e-02, -3.4637e-03,  ...,  6.7596e-03,
          2.8107e-02, -7.3576e-04],
        ...,
        [ 1.1032e-02,  1.4496e-02, -1.0233e-03,  ..., -2.4509e-03,
         -9.9945e-03,  1.9012e-02],
        [ 2.2018e-02,  9.6817e-03,  3.0251e-03,  ..., -2.1957e-02,
         -2.9984e-02, -1.5228e-02],
        [-4.3945e-03, -3.2215e-03,  2.4204e-03,  ...,  1.5717e-02,
          2.7542e-02, -3.5992e-03]], dtype=torch.float16), 'model.layers.0.self_attn.k_proj.weight': tensor([[-1.8356e-02,  4.0359e-03, -1.2512e-03,  ...,  1.7609e-02,
         -8.6746e-03, -1.4610e-02],
        [ 1.5823e-02,  6.5346e-03,  2.6360e-03,  ..., -1.8021e-02,
          1.6815e-02,  2.4765e-02],
        [ 2.4891e-04, -2.5513e-02,  9.2087e-03,  ...,  1.0544e-02,
         -2.4979e-02, -1.9958e-02],
        ...,
        [ 1.5572e-02,  6.2644e-05,  2.2449e-03,  ..., -7.4625e-04,
          1.9274e-03,  5.2757e-03],
        [-1.0864e-02,  2.2339e-02, -8.3771e-03,  ...,  2.7027e-03,
          1.7319e-02, -7.6866e-03],
        [ 5.8746e-03,  5.1308e-04,  6.3248e-03,  ...,  7.2708e-03,
         -1.2901e-02,  6.5727e-03]], dtype=torch.float16), 'model.layers.0.self_attn.v_proj.weight': tensor([[ 0.0007,  0.0044,  0.0010,  ...,  0.0090,  0.0010,  0.0093],
        [-0.0099, -0.0005, -0.0035,  ..., -0.0119,  0.0113,  0.0107],
        [ 0.0048,  0.0068, -0.0029,  ...,  0.0021, -0.0156, -0.0190],
        ...,
        [-0.0073, -0.0050,  0.0162,  ...,  0.0033,  0.0020, -0.0007],
        [-0.0006,  0.0075, -0.0048,  ...,  0.0051,  0.0155,  0.0017],
        [-0.0032,  0.0046,  0.0082,  ..., -0.0016, -0.0035,  0.0023]],
       dtype=torch.float16), 'model.layers.0.self_attn.o_proj.weight': tensor([[ 1.3628e-03, -3.9444e-03,  3.8643e-03,  ...,  2.2564e-03,
          2.7990e-04, -8.9340e-03],
        [-2.4300e-03,  5.6076e-03,  1.1387e-03,  ..., -1.7481e-03,
          2.0924e-03,  5.7678e-03],
        [-3.3474e-03, -7.6914e-04,  2.4796e-03,  ..., -2.0561e-03,
         -6.5956e-03, -8.0681e-04],
        ...,
        [ 4.8943e-03, -1.4791e-03,  7.6332e-03,  ...,  2.2650e-06,
          4.2534e-03,  3.3951e-03],
        [-2.9583e-03, -1.8663e-03, -1.1358e-03,  ...,  5.2490e-03,
         -5.8899e-03, -2.8267e-03],
        [ 4.0221e-04, -1.2932e-03,  3.3665e-03,  ...,  6.5804e-03,
         -4.6806e-03, -5.0964e-03]], dtype=torch.float16), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0081,  0.0134,  0.0292,  ..., -0.0172,  0.0053,  0.0193],
        [-0.0028, -0.0027,  0.0029,  ...,  0.0147, -0.0076,  0.0114],
        [-0.0002, -0.0256,  0.0180,  ..., -0.0189,  0.0257,  0.0206],
        ...,
        [ 0.0058, -0.0258,  0.0025,  ..., -0.0036, -0.0106,  0.0365],
        [ 0.0223,  0.0168, -0.0171,  ..., -0.0017, -0.0030, -0.0196],
        [-0.0070, -0.0135, -0.0268,  ..., -0.0042,  0.0025, -0.0229]],
       dtype=torch.float16), 'model.layers.0.mlp.up_proj.weight': tensor([[-0.0072, -0.0297,  0.0135,  ..., -0.0198, -0.0236,  0.0091],
        [-0.0119, -0.0311,  0.0110,  ...,  0.0178,  0.0034,  0.0087],
        [-0.0066,  0.0157, -0.0102,  ..., -0.0231,  0.0132,  0.0038],
        ...,
        [-0.0121, -0.0005, -0.0019,  ...,  0.0259, -0.0082,  0.0114],
        [-0.0198,  0.0047,  0.0170,  ..., -0.0023, -0.0186,  0.0037],
        [ 0.0142,  0.0268, -0.0009,  ...,  0.0088, -0.0174, -0.0420]],
       dtype=torch.float16), 'model.layers.0.mlp.down_proj.weight': tensor([[ 0.0044, -0.0123,  0.0141,  ..., -0.0181, -0.0041, -0.0016],
        [-0.0006, -0.0026,  0.0135,  ...,  0.0106, -0.0167,  0.0315],
        [ 0.0044,  0.0371,  0.0019,  ..., -0.0117,  0.0212,  0.0207],
        ...,
        [-0.0078, -0.0106,  0.0062,  ...,  0.0204, -0.0163,  0.0254],
        [-0.0202,  0.0401,  0.0176,  ..., -0.0138, -0.0104, -0.0290],
        [ 0.0179, -0.0031, -0.0126,  ...,  0.0003, -0.0050, -0.0296]],
       dtype=torch.float16), 'model.layers.0.input_layernorm.weight': tensor([ 0.0193,  0.0087, -0.0008,  ...,  0.0058,  0.0089,  0.0019],
       dtype=torch.float16), 'model.layers.0.post_attention_layernorm.weight': tensor([0.0530, 0.0537, 0.0498,  ..., 0.0540, 0.0569, 0.0491],
       dtype=torch.float16), 'model.layers.1.self_attn.q_proj.weight': tensor([[-0.0228, -0.0012, -0.0327,  ..., -0.0147, -0.0572,  0.0403],
        [-0.0012, -0.0125,  0.0112,  ..., -0.0081, -0.0516,  0.0322],
        [ 0.0274,  0.0308,  0.0248,  ..., -0.0133, -0.0764,  0.0221],
        ...,
        [-0.0004,  0.0029,  0.0050,  ..., -0.0099, -0.0020, -0.0116],
        [-0.0018, -0.0048, -0.0055,  ...,  0.0103,  0.0032,  0.0117],
        [ 0.0002,  0.0064,  0.0077,  ..., -0.0088,  0.0019, -0.0165]],
       dtype=torch.float16), 'model.layers.1.self_attn.k_proj.weight': tensor([[-0.0254,  0.0089,  0.0425,  ...,  0.0178,  0.0165, -0.0135],
        [-0.0323,  0.0092, -0.0083,  ..., -0.0091,  0.0150, -0.0595],
        [-0.0262,  0.0288, -0.0696,  ...,  0.0352,  0.0172, -0.0609],
        ...,
        [-0.0149,  0.0229,  0.0028,  ...,  0.0081, -0.0048,  0.0070],
        [ 0.0114, -0.0230, -0.0001,  ..., -0.0092,  0.0033, -0.0068],
        [-0.0111,  0.0184,  0.0055,  ...,  0.0007, -0.0071,  0.0058]],
       dtype=torch.float16), 'model.layers.1.self_attn.v_proj.weight': tensor([[ 6.8245e-03, -4.9133e-03,  1.0071e-03,  ..., -4.8561e-03,
         -2.9144e-02, -2.2125e-02],
        [-5.1346e-03,  4.9515e-03, -3.3360e-03,  ...,  2.7618e-03,
          1.1398e-02,  3.1982e-02],
        [ 3.6736e-03, -1.1612e-02,  8.0032e-03,  ..., -2.2590e-05,
         -1.4648e-03, -3.3340e-03],
        ...,
        [-3.6926e-03,  5.3062e-03,  7.3509e-03,  ..., -2.7981e-03,
         -1.4305e-03,  2.2399e-04],
        [-7.8735e-03, -3.1986e-03,  7.9422e-03,  ..., -6.5727e-03,
          8.4534e-03, -5.7817e-06],
        [ 1.0643e-03,  6.4468e-03,  8.0719e-03,  ..., -6.3095e-03,
         -2.6455e-03,  1.0246e-02]], dtype=torch.float16), 'model.layers.1.self_attn.o_proj.weight': tensor([[ 0.0024, -0.0163,  0.0091,  ..., -0.0058, -0.0015, -0.0006],
        [-0.0016, -0.0059, -0.0052,  ...,  0.0035, -0.0019,  0.0037],
        [ 0.0247,  0.0128, -0.0125,  ...,  0.0022, -0.0027,  0.0011],
        ...,
        [ 0.0058,  0.0022,  0.0012,  ..., -0.0011, -0.0004, -0.0001],
        [ 0.0036, -0.0075,  0.0050,  ..., -0.0054,  0.0002,  0.0056],
        [-0.0017, -0.0238,  0.0015,  ..., -0.0021, -0.0055,  0.0007]],
       dtype=torch.float16), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0305, -0.0128,  0.0422,  ..., -0.0312, -0.0152, -0.0100],
        [-0.0312, -0.0045, -0.0312,  ...,  0.0140, -0.0307, -0.0427],
        [-0.0055, -0.0319,  0.0095,  ..., -0.0064, -0.0123, -0.0204],
        ...,
        [-0.0385,  0.0105, -0.0028,  ..., -0.0023,  0.0122,  0.0004],
        [-0.0149, -0.0031, -0.0339,  ...,  0.0217,  0.0198, -0.0084],
        [-0.0266,  0.0121,  0.0041,  ...,  0.0391,  0.0065, -0.0430]],
       dtype=torch.float16), 'model.layers.1.mlp.up_proj.weight': tensor([[-0.0034,  0.0414, -0.0204,  ...,  0.0118,  0.0263, -0.0124],
        [ 0.0071, -0.0067, -0.0129,  ..., -0.0086,  0.0069,  0.0108],
        [ 0.0309, -0.0436,  0.0134,  ...,  0.0177, -0.0427,  0.0297],
        ...,
        [-0.0148, -0.0275,  0.0184,  ...,  0.0293,  0.0069, -0.0238],
        [ 0.0356,  0.0030, -0.0164,  ...,  0.0032, -0.0060, -0.0045],
        [-0.0108, -0.0150, -0.0105,  ..., -0.0249, -0.0061,  0.0173]],
       dtype=torch.float16), 'model.layers.1.mlp.down_proj.weight': tensor([[ 0.0107,  0.0179,  0.0578,  ..., -0.0177,  0.0072, -0.0210],
        [ 0.0088,  0.0063, -0.0363,  ...,  0.0069, -0.0142,  0.0028],
        [-0.0113, -0.0138, -0.0245,  ...,  0.0014, -0.0134,  0.0023],
        ...,
        [-0.0099, -0.0073, -0.0143,  ...,  0.0442, -0.0065,  0.0090],
        [-0.0116,  0.0203,  0.0101,  ..., -0.0278, -0.0228,  0.0261],
        [ 0.0262, -0.0061, -0.0175,  ..., -0.0080, -0.0135,  0.0338]],
       dtype=torch.float16), 'model.layers.1.input_layernorm.weight': tensor([0.1050, 0.0967, 0.0884,  ..., 0.0518, 0.0781, 0.0608],
       dtype=torch.float16), 'model.layers.1.post_attention_layernorm.weight': tensor([0.0986, 0.0991, 0.0957,  ..., 0.1060, 0.1006, 0.1001],
       dtype=torch.float16), 'model.layers.2.self_attn.q_proj.weight': tensor([[-0.0236, -0.0038,  0.0098,  ..., -0.0133, -0.0098, -0.0003],
        [-0.0190,  0.0037, -0.0345,  ..., -0.0344, -0.0162,  0.0232],
        [-0.0165,  0.0366, -0.0252,  ..., -0.0018, -0.0211,  0.0159],
        ...,
        [-0.0526,  0.0145, -0.0261,  ..., -0.0085, -0.0328, -0.0351],
        [ 0.0019, -0.0063,  0.0003,  ..., -0.0023, -0.0186,  0.0160],
        [-0.0048, -0.0168,  0.0231,  ...,  0.0604, -0.0444,  0.0058]],
       dtype=torch.float16), 'model.layers.2.self_attn.k_proj.weight': tensor([[ 0.0004,  0.0156, -0.0085,  ..., -0.0106, -0.0010,  0.0175],
        [ 0.0163, -0.0154, -0.0090,  ...,  0.0110, -0.0093, -0.0075],
        [ 0.0128,  0.0151,  0.0360,  ..., -0.0084,  0.0124,  0.0131],
        ...,
        [ 0.0299,  0.0465, -0.0237,  ...,  0.0386, -0.0369,  0.0006],
        [-0.0072, -0.0126, -0.0009,  ...,  0.0045,  0.0003, -0.0041],
        [ 0.0020, -0.0215, -0.0021,  ..., -0.0809, -0.0249,  0.0965]],
       dtype=torch.float16), 'model.layers.2.self_attn.v_proj.weight': tensor([[-7.3767e-04,  6.2332e-03,  1.5961e-02,  ...,  3.8208e-02,
         -3.6240e-03, -6.9313e-03],
        [ 5.0621e-03,  1.1269e-02, -2.1118e-02,  ..., -7.7972e-03,
          7.8506e-03, -1.4595e-02],
        [-6.8617e-04,  1.8463e-02,  3.3112e-03,  ..., -2.0950e-02,
         -3.0457e-02, -2.9480e-02],
        ...,
        [-5.3465e-05, -2.5360e-02, -2.0248e-02,  ..., -1.0956e-02,
         -9.5272e-04,  3.3970e-03],
        [-3.7140e-02, -7.9775e-04,  1.4175e-02,  ..., -1.0040e-02,
         -6.6071e-03, -1.5135e-03],
        [-1.1009e-02,  1.4809e-02,  4.5662e-03,  ..., -5.1880e-03,
          1.8234e-02, -7.3395e-03]], dtype=torch.float16), 'model.layers.2.self_attn.o_proj.weight': tensor([[ 0.0041,  0.0149,  0.0103,  ...,  0.0196,  0.0020, -0.0260],
        [ 0.0006, -0.0130,  0.0079,  ...,  0.0049, -0.0125, -0.0198],
        [-0.0215,  0.0032, -0.0169,  ..., -0.0224, -0.0103,  0.0078],
        ...,
        [-0.0046, -0.0235,  0.0281,  ..., -0.0049, -0.0220,  0.0198],
        [ 0.0184, -0.0113,  0.0301,  ...,  0.0192, -0.0004, -0.0239],
        [-0.0107,  0.0023,  0.0075,  ..., -0.0129,  0.0050, -0.0142]],
       dtype=torch.float16), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0072,  0.0239, -0.0107,  ..., -0.0090,  0.0302, -0.0034],
        [ 0.0013,  0.0012, -0.0015,  ...,  0.0126, -0.0138, -0.0115],
        [-0.0069, -0.0083,  0.0255,  ..., -0.0112,  0.0158,  0.0069],
        ...,
        [ 0.0342, -0.0119, -0.0193,  ..., -0.0285, -0.0400, -0.0150],
        [-0.0113, -0.0116, -0.0017,  ...,  0.0174, -0.0425,  0.0180],
        [-0.0015,  0.0111,  0.0085,  ..., -0.0133, -0.0261,  0.0048]],
       dtype=torch.float16), 'model.layers.2.mlp.up_proj.weight': tensor([[-0.0008, -0.0006,  0.0139,  ..., -0.0152,  0.0090, -0.0034],
        [ 0.0053, -0.0186, -0.0090,  ...,  0.0056,  0.0114,  0.0062],
        [ 0.0306,  0.0189,  0.0293,  ..., -0.0141, -0.0088,  0.0175],
        ...,
        [-0.0071, -0.0148,  0.0009,  ..., -0.0116, -0.0025,  0.0209],
        [ 0.0155, -0.0129,  0.0144,  ...,  0.0003,  0.0049, -0.0228],
        [-0.0146, -0.0302, -0.0243,  ..., -0.0050,  0.0011, -0.0050]],
       dtype=torch.float16), 'model.layers.2.mlp.down_proj.weight': tensor([[ 0.0146,  0.0174,  0.0375,  ..., -0.0273, -0.0011, -0.0335],
        [ 0.0209, -0.0227, -0.0188,  ...,  0.0180,  0.0023, -0.0226],
        [ 0.0438, -0.0178,  0.0010,  ..., -0.0302,  0.0004, -0.0330],
        ...,
        [-0.0133,  0.0283, -0.0105,  ..., -0.0015, -0.0013, -0.0135],
        [-0.0211,  0.0298,  0.0079,  ...,  0.0158, -0.0182, -0.0113],
        [ 0.0315,  0.0117, -0.0220,  ...,  0.0192, -0.0449, -0.0119]],
       dtype=torch.float16), 'model.layers.2.input_layernorm.weight': tensor([0.1729, 0.1787, 0.1709,  ..., 0.1768, 0.1680, 0.1748],
       dtype=torch.float16), 'model.layers.2.post_attention_layernorm.weight': tensor([0.1338, 0.1377, 0.1367,  ..., 0.1367, 0.1387, 0.1367],
       dtype=torch.float16), 'model.layers.3.self_attn.q_proj.weight': tensor([[ 0.0001,  0.0111,  0.0058,  ...,  0.0241,  0.0127,  0.0220],
        [-0.0121,  0.0172, -0.0149,  ..., -0.0432,  0.0006, -0.0074],
        [ 0.0129,  0.0027, -0.0203,  ...,  0.0116, -0.0187, -0.0406],
        ...,
        [ 0.0717, -0.0696,  0.0428,  ..., -0.0779, -0.0139,  0.0070],
        [-0.0797,  0.0404, -0.0023,  ...,  0.0363,  0.0769,  0.0251],
        [-0.0153, -0.0497,  0.0779,  ..., -0.0225, -0.0032, -0.0130]],
       dtype=torch.float16), 'model.layers.3.self_attn.k_proj.weight': tensor([[ 0.0074, -0.0077, -0.0088,  ..., -0.0140,  0.0067,  0.0404],
        [-0.0116,  0.0102, -0.0252,  ...,  0.0031, -0.0150, -0.0390],
        [ 0.0029, -0.0079,  0.0005,  ...,  0.0074, -0.0090, -0.0374],
        ...,
        [ 0.0884, -0.0848,  0.0065,  ..., -0.0621,  0.0024,  0.0343],
        [-0.0830,  0.0328,  0.0418,  ...,  0.0079,  0.0463, -0.0032],
        [ 0.0020, -0.0524,  0.0955,  ..., -0.0163,  0.0029, -0.0172]],
       dtype=torch.float16), 'model.layers.3.self_attn.v_proj.weight': tensor([[-0.0039,  0.0125, -0.0059,  ..., -0.0148,  0.0063, -0.0150],
        [-0.0113,  0.0269, -0.0179,  ..., -0.0122, -0.0101, -0.0094],
        [ 0.0024, -0.0062,  0.0057,  ..., -0.0406, -0.0087, -0.0281],
        ...,
        [-0.0131, -0.0097, -0.0019,  ...,  0.0023, -0.0041, -0.0064],
        [ 0.0055, -0.0019,  0.0020,  ...,  0.0007, -0.0084,  0.0018],
        [-0.0120, -0.0069,  0.0093,  ..., -0.0012, -0.0018,  0.0084]],
       dtype=torch.float16), 'model.layers.3.self_attn.o_proj.weight': tensor([[-2.7054e-02,  5.7945e-03, -1.2451e-02,  ...,  2.7256e-03,
         -1.1616e-03, -2.2335e-03],
        [ 2.4536e-02, -2.4429e-02, -1.0193e-02,  ...,  6.5651e-03,
         -2.5272e-03, -2.3193e-03],
        [-3.7498e-03, -1.3260e-02,  1.9197e-03,  ...,  2.6493e-03,
          3.3932e-03,  8.3084e-03],
        ...,
        [ 1.1963e-02,  1.3344e-02,  1.3680e-02,  ...,  1.3313e-03,
          7.1793e-03,  9.9335e-03],
        [ 1.7960e-02,  2.6199e-02,  2.9206e-06,  ...,  3.6945e-03,
         -1.1940e-03, -2.8419e-03],
        [ 8.5297e-03, -9.2773e-03,  1.0519e-03,  ..., -6.4993e-04,
          5.8823e-03,  1.0956e-02]], dtype=torch.float16), 'model.layers.3.mlp.gate_proj.weight': tensor([[ 0.0009, -0.0099, -0.0182,  ..., -0.0315,  0.0460,  0.0153],
        [ 0.0189,  0.0017, -0.0123,  ..., -0.0025, -0.0261, -0.0161],
        [-0.0253,  0.0021, -0.0174,  ...,  0.0050, -0.0040, -0.0361],
        ...,
        [-0.0003,  0.0394,  0.0065,  ...,  0.0199, -0.0123, -0.0001],
        [-0.0057,  0.0087, -0.0060,  ...,  0.0003, -0.0041, -0.0112],
        [-0.0025, -0.0155,  0.0031,  ...,  0.0264, -0.0254,  0.0148]],
       dtype=torch.float16), 'model.layers.3.mlp.up_proj.weight': tensor([[-0.0160,  0.0154,  0.0104,  ...,  0.0014,  0.0186, -0.0085],
        [-0.0123, -0.0174,  0.0343,  ...,  0.0175,  0.0141, -0.0052],
        [-0.0005, -0.0031, -0.0144,  ..., -0.0012,  0.0091, -0.0125],
        ...,
        [-0.0042, -0.0016, -0.0006,  ...,  0.0215,  0.0084, -0.0228],
        [ 0.0052, -0.0099, -0.0050,  ...,  0.0113, -0.0249, -0.0080],
        [ 0.0486, -0.0004, -0.0031,  ...,  0.0433,  0.0057,  0.0085]],
       dtype=torch.float16), 'model.layers.3.mlp.down_proj.weight': tensor([[ 0.0014, -0.0079, -0.0008,  ..., -0.0033,  0.0087,  0.0142],
        [ 0.0225,  0.0028,  0.0088,  ..., -0.0140, -0.0148, -0.0148],
        [ 0.0144,  0.0119, -0.0174,  ..., -0.0200, -0.0066,  0.0060],
        ...,
        [ 0.0280, -0.0107, -0.0166,  ...,  0.0040,  0.0193,  0.0221],
        [-0.0217,  0.0099, -0.0106,  ..., -0.0006, -0.0170,  0.0130],
        [ 0.0110, -0.0169, -0.0266,  ...,  0.0033,  0.0121,  0.0063]],
       dtype=torch.float16), 'model.layers.3.input_layernorm.weight': tensor([0.2852, 0.2852, 0.2832,  ..., 0.2812, 0.2910, 0.2969],
       dtype=torch.float16), 'model.layers.3.post_attention_layernorm.weight': tensor([0.1738, 0.1748, 0.1689,  ..., 0.1719, 0.1719, 0.1758],
       dtype=torch.float16), 'model.layers.4.self_attn.q_proj.weight': tensor([[-0.0206, -0.0058,  0.0019,  ..., -0.0113, -0.0038,  0.0106],
        [ 0.0190, -0.0170, -0.0051,  ...,  0.0039, -0.0259, -0.0004],
        [-0.0124, -0.0312,  0.0122,  ..., -0.0027, -0.0195, -0.0239],
        ...,
        [ 0.0246,  0.0004, -0.0039,  ...,  0.0032,  0.0244, -0.0600],
        [-0.0293,  0.0085,  0.0295,  ..., -0.0561,  0.0037,  0.0337],
        [-0.0074, -0.0351,  0.0680,  ...,  0.0638,  0.0376, -0.0406]],
       dtype=torch.float16), 'model.layers.4.self_attn.k_proj.weight': tensor([[-0.0037,  0.0210, -0.0139,  ..., -0.0044,  0.0025, -0.0019],
        [-0.0307, -0.0041, -0.0032,  ..., -0.0014,  0.0142, -0.0028],
        [ 0.0089, -0.0021, -0.0143,  ...,  0.0076,  0.0189,  0.0352],
        ...,
        [-0.0089,  0.1188,  0.0593,  ...,  0.0388, -0.0216, -0.0060],
        [ 0.0320,  0.0533, -0.0162,  ...,  0.0641, -0.0399,  0.0720],
        [ 0.0100,  0.0640,  0.0195,  ..., -0.0011,  0.0424, -0.0209]],
       dtype=torch.float16), 'model.layers.4.self_attn.v_proj.weight': tensor([[-3.6507e-03, -8.4000e-03,  1.2493e-03,  ..., -6.4735e-03,
         -3.6030e-03, -6.0320e-05],
        [-1.4557e-02,  3.6133e-02,  5.1346e-03,  ...,  3.2978e-03,
          1.1721e-03,  2.7237e-03],
        [ 1.0719e-02, -6.2370e-03, -3.4729e-02,  ...,  5.4436e-03,
         -1.3771e-03, -1.8631e-02],
        ...,
        [-3.3283e-03, -8.3771e-03, -2.2263e-02,  ..., -9.6893e-03,
         -1.1740e-03,  3.3360e-03],
        [-2.0599e-03, -1.0277e-02, -1.9855e-03,  ...,  7.9956e-03,
         -1.5678e-03,  4.0550e-03],
        [-2.6131e-04, -1.7914e-02, -3.6087e-03,  ..., -5.3263e-04,
         -5.2681e-03,  1.1940e-02]], dtype=torch.float16), 'model.layers.4.self_attn.o_proj.weight': tensor([[ 0.0270,  0.0083, -0.0050,  ..., -0.0021, -0.0267, -0.0015],
        [ 0.0075, -0.0009, -0.0082,  ...,  0.0017, -0.0215,  0.0036],
        [-0.0045,  0.0041, -0.0073,  ..., -0.0134,  0.0101, -0.0084],
        ...,
        [-0.0148,  0.0272, -0.0037,  ..., -0.0209,  0.0081, -0.0208],
        [ 0.0033, -0.0025, -0.0150,  ..., -0.0094, -0.0004, -0.0059],
        [ 0.0100,  0.0215, -0.0056,  ..., -0.0007,  0.0051,  0.0010]],
       dtype=torch.float16), 'model.layers.4.mlp.gate_proj.weight': tensor([[-0.0053,  0.0065, -0.0110,  ..., -0.0182, -0.0035, -0.0159],
        [-0.0267,  0.0111,  0.0142,  ...,  0.0066,  0.0154, -0.0106],
        [-0.0136, -0.0220, -0.0006,  ...,  0.0055, -0.0028,  0.0260],
        ...,
        [ 0.0008, -0.0025,  0.0095,  ..., -0.0211,  0.0097, -0.0120],
        [-0.0265,  0.0148, -0.0281,  ...,  0.0098,  0.0180, -0.0102],
        [ 0.0017, -0.0143, -0.0135,  ..., -0.0124,  0.0221,  0.0190]],
       dtype=torch.float16), 'model.layers.4.mlp.up_proj.weight': tensor([[-1.6373e-02, -5.6725e-03, -4.0833e-02,  ...,  8.6670e-03,
         -8.2254e-04, -5.4932e-03],
        [-2.2400e-02, -4.0680e-02,  5.3253e-03,  ..., -8.6517e-03,
          9.8953e-03, -2.4872e-02],
        [-1.2989e-03,  2.9587e-02,  7.5042e-05,  ..., -2.8885e-02,
         -1.1322e-02,  8.4839e-03],
        ...,
        [-8.8882e-03, -3.1769e-02, -7.3433e-03,  ...,  1.2138e-02,
         -6.8016e-03,  5.5023e-02],
        [ 1.2787e-02, -1.0330e-02, -1.5060e-02,  ..., -4.2175e-02,
         -1.6281e-02,  9.5596e-03],
        [ 3.7937e-03,  1.3062e-02,  8.8272e-03,  ...,  3.7594e-03,
         -3.4237e-03, -2.4376e-03]], dtype=torch.float16), 'model.layers.4.mlp.down_proj.weight': tensor([[ 2.3834e-02, -4.2458e-03,  2.3529e-02,  ..., -1.9836e-02,
         -8.3983e-05,  2.9861e-02],
        [-5.7335e-03, -4.8859e-02,  4.5746e-02,  ..., -2.4323e-02,
         -2.1210e-02, -7.2365e-03],
        [-2.9135e-04, -2.7969e-02,  1.6556e-02,  ...,  1.1406e-02,
         -2.8000e-03,  2.2263e-02],
        ...,
        [-3.4393e-02, -1.9779e-03, -9.8801e-03,  ...,  2.4658e-02,
          2.1534e-03,  1.5030e-02],
        [-7.8430e-03,  1.8177e-03, -2.0020e-02,  ...,  1.2718e-02,
         -4.1931e-02, -1.1818e-02],
        [ 1.6479e-02, -3.2135e-02, -1.5076e-02,  ..., -3.5000e-03,
         -4.4739e-02, -2.3956e-02]], dtype=torch.float16), 'model.layers.4.input_layernorm.weight': tensor([0.2617, 0.2676, 0.2617,  ..., 0.2578, 0.2656, 0.2734],
       dtype=torch.float16), 'model.layers.4.post_attention_layernorm.weight': tensor([0.1914, 0.1895, 0.1855,  ..., 0.1904, 0.1885, 0.1895],
       dtype=torch.float16), 'model.layers.5.self_attn.q_proj.weight': tensor([[-0.0089, -0.0005, -0.0254,  ..., -0.0074, -0.0164,  0.0120],
        [-0.0202,  0.0197,  0.0401,  ..., -0.0054, -0.0094, -0.0347],
        [ 0.0045,  0.0043, -0.0135,  ...,  0.0205, -0.0172,  0.0105],
        ...,
        [-0.0121,  0.0095, -0.0033,  ...,  0.0542,  0.0104,  0.0356],
        [ 0.0433,  0.0046,  0.0262,  ..., -0.0415, -0.0351, -0.0303],
        [ 0.0103,  0.0194,  0.0370,  ..., -0.0282, -0.0147, -0.0007]],
       dtype=torch.float16), 'model.layers.5.self_attn.k_proj.weight': tensor([[-0.0049,  0.0373,  0.0067,  ...,  0.0198, -0.0056, -0.0016],
        [ 0.0006,  0.0027, -0.0324,  ...,  0.0231, -0.0123,  0.0318],
        [-0.0116, -0.0233,  0.0013,  ...,  0.0026, -0.0059,  0.0032],
        ...,
        [ 0.0031, -0.0016, -0.0228,  ...,  0.0397,  0.0098, -0.0320],
        [ 0.0524,  0.0166, -0.0242,  ..., -0.0012, -0.0159, -0.0361],
        [-0.0242, -0.0217,  0.0421,  ..., -0.0155, -0.0347,  0.0102]],
       dtype=torch.float16), 'model.layers.5.self_attn.v_proj.weight': tensor([[-3.0975e-02,  6.6643e-03,  9.8114e-03,  ...,  2.2919e-02,
          7.3671e-05,  2.3392e-02],
        [ 3.9635e-03,  1.0124e-02, -1.8448e-02,  ..., -1.1353e-02,
          3.7670e-03, -1.3893e-02],
        [ 2.2354e-02,  2.4128e-03, -2.9063e-04,  ..., -2.4063e-02,
          2.8976e-02,  1.1208e-02],
        ...,
        [ 2.0477e-02,  1.1581e-02,  1.0353e-02,  ...,  3.7048e-02,
         -5.7449e-03,  1.1454e-03],
        [-5.3596e-03,  3.0289e-03, -4.7684e-03,  ...,  9.9945e-04,
         -9.2010e-03,  8.7404e-04],
        [-1.2375e-02, -6.2561e-03,  2.1561e-02,  ..., -9.5673e-03,
         -9.2545e-03, -1.5900e-02]], dtype=torch.float16), 'model.layers.5.self_attn.o_proj.weight': tensor([[-0.0155, -0.0091,  0.0050,  ..., -0.0181, -0.0074,  0.0271],
        [ 0.0017,  0.0016, -0.0094,  ..., -0.0182,  0.0043,  0.0034],
        [-0.0014, -0.0026,  0.0131,  ...,  0.0181,  0.0119,  0.0234],
        ...,
        [ 0.0181,  0.0066, -0.0060,  ...,  0.0162,  0.0306, -0.0247],
        [-0.0016,  0.0017, -0.0038,  ..., -0.0184, -0.0139, -0.0013],
        [ 0.0051,  0.0035, -0.0148,  ..., -0.0011, -0.0060, -0.0158]],
       dtype=torch.float16), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0002, -0.0082, -0.0302,  ...,  0.0003, -0.0062, -0.0114],
        [ 0.0216, -0.0073, -0.0212,  ...,  0.0374, -0.0015,  0.0022],
        [ 0.0123,  0.0039, -0.0196,  ...,  0.0148,  0.0164, -0.0348],
        ...,
        [ 0.0065,  0.0096,  0.0416,  ..., -0.0671,  0.0157, -0.0199],
        [-0.0280,  0.0043,  0.0038,  ...,  0.0014,  0.0170, -0.0017],
        [ 0.0282, -0.0299, -0.0141,  ..., -0.0040, -0.0043, -0.0409]],
       dtype=torch.float16), 'model.layers.5.mlp.up_proj.weight': tensor([[-0.0063, -0.0135, -0.0069,  ..., -0.0147,  0.0037, -0.0168],
        [-0.0320, -0.0062,  0.0009,  ...,  0.0124,  0.0182,  0.0228],
        [-0.0019,  0.0090,  0.0094,  ...,  0.0040,  0.0080,  0.0185],
        ...,
        [ 0.0077,  0.0239, -0.0076,  ..., -0.0109,  0.0145,  0.0252],
        [ 0.0447, -0.0130, -0.0292,  ..., -0.0080, -0.0179,  0.0240],
        [ 0.0085,  0.0172,  0.0130,  ..., -0.0103, -0.0041, -0.0160]],
       dtype=torch.float16), 'model.layers.5.mlp.down_proj.weight': tensor([[-0.0074, -0.0270, -0.0031,  ...,  0.0008,  0.0067,  0.0141],
        [-0.0113,  0.0156,  0.0281,  ...,  0.0215,  0.0064, -0.0341],
        [ 0.0131,  0.0207,  0.0143,  ..., -0.0241, -0.0463,  0.0110],
        ...,
        [ 0.0110, -0.0240, -0.0051,  ...,  0.0063, -0.0257, -0.0186],
        [-0.0034, -0.0391,  0.0152,  ...,  0.0161,  0.0156, -0.0515],
        [ 0.0212,  0.0142, -0.0118,  ...,  0.0309,  0.0092, -0.0177]],
       dtype=torch.float16), 'model.layers.5.input_layernorm.weight': tensor([0.2617, 0.2695, 0.2637,  ..., 0.2500, 0.2695, 0.2676],
       dtype=torch.float16), 'model.layers.5.post_attention_layernorm.weight': tensor([0.2090, 0.1953, 0.1934,  ..., 0.2051, 0.2021, 0.2051],
       dtype=torch.float16), 'model.layers.6.self_attn.q_proj.weight': tensor([[-9.7351e-03, -1.1505e-02,  6.6071e-03,  ..., -3.3630e-02,
         -6.4468e-03, -4.9515e-03],
        [ 4.4250e-03, -6.5613e-03,  5.6343e-03,  ...,  1.4587e-02,
          3.5286e-03, -3.1464e-02],
        [-1.7654e-02,  2.4216e-02, -3.8513e-02,  ...,  3.0502e-02,
         -4.8431e-02, -3.2272e-03],
        ...,
        [ 1.2878e-02,  9.0103e-03, -3.7628e-02,  ...,  2.3987e-02,
          2.7657e-03,  1.5497e-03],
        [ 3.5614e-02,  3.2532e-02,  5.3329e-03,  ..., -9.7885e-03,
         -9.6497e-02, -2.0844e-02],
        [-6.3538e-02, -5.3558e-02, -4.8697e-05,  ...,  1.7288e-02,
          5.1155e-03,  8.5220e-03]], dtype=torch.float16), 'model.layers.6.self_attn.k_proj.weight': tensor([[ 0.0139, -0.0106,  0.0204,  ..., -0.0071,  0.0222,  0.0589],
        [-0.0198, -0.0036,  0.0422,  ...,  0.0071, -0.0126,  0.0158],
        [-0.0102, -0.0131, -0.0068,  ..., -0.0006, -0.0307, -0.0107],
        ...,
        [ 0.0214, -0.0376, -0.0183,  ...,  0.0607, -0.0023, -0.0482],
        [-0.0199,  0.0045, -0.0262,  ..., -0.0461, -0.0408,  0.0156],
        [-0.0544, -0.0241, -0.0399,  ...,  0.0161, -0.0420, -0.0188]],
       dtype=torch.float16), 'model.layers.6.self_attn.v_proj.weight': tensor([[ 0.0140,  0.0336,  0.0101,  ...,  0.0127, -0.0017,  0.0078],
        [ 0.0381, -0.0063, -0.0095,  ...,  0.0046, -0.0005,  0.0038],
        [-0.0079, -0.0024,  0.0124,  ...,  0.0101,  0.0240,  0.0046],
        ...,
        [-0.0221, -0.0061,  0.0052,  ...,  0.0010, -0.0165,  0.0085],
        [-0.0243, -0.0088, -0.0003,  ..., -0.0012, -0.0083,  0.0198],
        [ 0.0311,  0.0049,  0.0161,  ..., -0.0222,  0.0005, -0.0030]],
       dtype=torch.float16), 'model.layers.6.self_attn.o_proj.weight': tensor([[ 0.0112, -0.0127, -0.0365,  ..., -0.0135,  0.0086,  0.0113],
        [-0.0260,  0.0067, -0.0001,  ..., -0.0224,  0.0014, -0.0022],
        [ 0.0019, -0.0115, -0.0042,  ...,  0.0106,  0.0079,  0.0094],
        ...,
        [-0.0053, -0.0143, -0.0063,  ...,  0.0074, -0.0062,  0.0256],
        [-0.0204,  0.0092, -0.0014,  ..., -0.0024,  0.0081, -0.0214],
        [-0.0201, -0.0129,  0.0079,  ..., -0.0237,  0.0066,  0.0064]],
       dtype=torch.float16), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0222,  0.0260, -0.0189,  ..., -0.0039, -0.0074, -0.0042],
        [ 0.0321,  0.0016, -0.0231,  ...,  0.0066,  0.0205,  0.0123],
        [-0.0146,  0.0217, -0.0156,  ..., -0.0187,  0.0011,  0.0088],
        ...,
        [ 0.0056, -0.0261,  0.0048,  ...,  0.0091, -0.0184, -0.0066],
        [ 0.0083,  0.0047, -0.0169,  ..., -0.0235, -0.0025, -0.0016],
        [-0.0396, -0.0513,  0.0267,  ..., -0.0413, -0.0027,  0.0164]],
       dtype=torch.float16), 'model.layers.6.mlp.up_proj.weight': tensor([[-0.0147, -0.0145, -0.0228,  ...,  0.0067, -0.0053, -0.0105],
        [ 0.0071, -0.0485,  0.0392,  ...,  0.0123,  0.0003, -0.0055],
        [-0.0220, -0.0162, -0.0241,  ...,  0.0055,  0.0135,  0.0216],
        ...,
        [-0.0267,  0.0002,  0.0167,  ...,  0.0149, -0.0019,  0.0385],
        [ 0.0244,  0.0173, -0.0063,  ..., -0.0283,  0.0101,  0.0017],
        [-0.0249,  0.0287, -0.0220,  ...,  0.0081, -0.0178, -0.0498]],
       dtype=torch.float16), 'model.layers.6.mlp.down_proj.weight': tensor([[-0.0122,  0.0100, -0.0043,  ...,  0.0013,  0.0143,  0.0160],
        [-0.0081, -0.0157,  0.0045,  ..., -0.0036, -0.0266, -0.0125],
        [ 0.0030,  0.0159, -0.0086,  ...,  0.0244,  0.0240,  0.0227],
        ...,
        [ 0.0110, -0.0024,  0.0207,  ...,  0.0316, -0.0336, -0.0099],
        [ 0.0216, -0.0065,  0.0070,  ...,  0.0098, -0.0135, -0.0126],
        [ 0.0152, -0.0165, -0.0085,  ...,  0.0319, -0.0050,  0.0079]],
       dtype=torch.float16), 'model.layers.6.input_layernorm.weight': tensor([0.3223, 0.3613, 0.3242,  ..., 0.3145, 0.3359, 0.3223],
       dtype=torch.float16), 'model.layers.6.post_attention_layernorm.weight': tensor([0.2217, 0.2129, 0.2090,  ..., 0.2227, 0.2168, 0.2178],
       dtype=torch.float16), 'model.layers.7.self_attn.q_proj.weight': tensor([[-6.2637e-03, -1.0843e-03, -8.1658e-06,  ..., -3.4428e-03,
         -2.0752e-02, -6.3477e-03],
        [-1.0460e-02,  1.4365e-04, -1.0338e-03,  ...,  1.2947e-02,
         -3.6564e-03, -1.6739e-02],
        [ 5.0201e-03,  6.6719e-03, -3.1158e-02,  ..., -2.0416e-02,
         -7.5684e-03,  9.1553e-03],
        ...,
        [-1.5259e-03, -3.3752e-02, -2.5040e-02,  ..., -1.2718e-02,
          3.4180e-02,  3.5553e-02],
        [ 1.3344e-02,  5.2917e-02, -4.0039e-02,  ..., -1.1269e-02,
         -6.7383e-02, -5.6915e-02],
        [ 7.9102e-02, -2.4200e-02, -1.8158e-02,  ...,  8.2947e-02,
          3.1113e-02, -4.3716e-03]], dtype=torch.float16), 'model.layers.7.self_attn.k_proj.weight': tensor([[ 0.0032, -0.0077, -0.0123,  ...,  0.0064,  0.0024, -0.0099],
        [-0.0070, -0.0178,  0.0048,  ..., -0.0072,  0.0043,  0.0185],
        [-0.0024, -0.0103,  0.0107,  ..., -0.0082, -0.0065, -0.0179],
        ...,
        [ 0.0429,  0.0077,  0.0243,  ...,  0.0351,  0.0396,  0.0282],
        [ 0.0400,  0.0500, -0.0002,  ..., -0.0307, -0.0344, -0.0016],
        [ 0.0403,  0.0058,  0.0104,  ..., -0.0012,  0.0019, -0.0272]],
       dtype=torch.float16), 'model.layers.7.self_attn.v_proj.weight': tensor([[-1.4038e-02,  5.2605e-03,  1.2993e-02,  ...,  2.8549e-02,
          4.2191e-03, -1.3847e-02],
        [ 2.6672e-02, -2.6993e-02,  4.3640e-03,  ...,  2.0035e-02,
         -1.8890e-02, -1.5915e-02],
        [-6.8970e-03, -1.0094e-02, -3.4523e-03,  ..., -1.8097e-02,
          1.1665e-02, -7.9453e-05],
        ...,
        [-1.3485e-03, -3.8300e-02,  2.7924e-03,  ...,  5.7297e-03,
         -6.9427e-03, -4.0016e-03],
        [-3.7872e-02,  1.9394e-02, -2.7618e-02,  ..., -1.8707e-02,
          1.0628e-02, -1.9252e-04],
        [-7.4272e-03,  2.6951e-03, -8.4991e-03,  ...,  2.0401e-02,
          7.3357e-03,  1.1787e-02]], dtype=torch.float16), 'model.layers.7.self_attn.o_proj.weight': tensor([[ 0.0116, -0.0154,  0.0014,  ...,  0.0091, -0.0194,  0.0053],
        [-0.0066,  0.0281,  0.0115,  ..., -0.0417, -0.0176, -0.0100],
        [ 0.0047, -0.0011, -0.0201,  ..., -0.0096, -0.0059, -0.0107],
        ...,
        [-0.0163, -0.0252, -0.0036,  ...,  0.0259, -0.0186,  0.0010],
        [-0.0226,  0.0085,  0.0167,  ...,  0.0080, -0.0130,  0.0153],
        [ 0.0028, -0.0002,  0.0005,  ...,  0.0060, -0.0161,  0.0039]],
       dtype=torch.float16), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 7.7896e-03,  4.7340e-03, -5.0850e-03,  ..., -4.3983e-03,
         -3.3386e-02, -7.2746e-03],
        [-3.1647e-02,  1.0490e-02, -8.5449e-03,  ..., -4.9400e-03,
         -3.8891e-03,  2.0676e-03],
        [ 1.7075e-02, -3.0640e-02, -8.4043e-06,  ...,  2.5543e-02,
         -2.7069e-02,  3.4237e-03],
        ...,
        [ 1.6441e-03,  2.0504e-03, -1.4145e-02,  ..., -2.0462e-02,
          4.6463e-03, -2.1713e-02],
        [ 2.6989e-03,  1.8036e-02,  1.2131e-02,  ..., -4.7798e-03,
          6.1493e-03, -3.0258e-02],
        [ 1.9714e-02, -1.6556e-02, -1.0773e-02,  ...,  1.7761e-02,
          1.8799e-02, -6.9962e-03]], dtype=torch.float16), 'model.layers.7.mlp.up_proj.weight': tensor([[ 0.0250,  0.0014, -0.0038,  ...,  0.0224, -0.0396,  0.0026],
        [-0.0110, -0.0190,  0.0299,  ...,  0.0095, -0.0108,  0.0154],
        [ 0.0259, -0.0214,  0.0107,  ..., -0.0126,  0.0181, -0.0352],
        ...,
        [-0.0019, -0.0023, -0.0150,  ..., -0.0095, -0.0177,  0.0024],
        [ 0.0003,  0.0084,  0.0167,  ..., -0.0071,  0.0215, -0.0067],
        [-0.0245, -0.0151,  0.0063,  ...,  0.0170,  0.0119,  0.0050]],
       dtype=torch.float16), 'model.layers.7.mlp.down_proj.weight': tensor([[-0.0079, -0.0069,  0.0050,  ..., -0.0115, -0.0060, -0.0211],
        [-0.0095, -0.0072,  0.0217,  ..., -0.0125,  0.0093,  0.0047],
        [ 0.0106,  0.0077,  0.0231,  ..., -0.0157, -0.0048, -0.0210],
        ...,
        [-0.0100,  0.0002, -0.0191,  ...,  0.0123,  0.0022, -0.0257],
        [ 0.0428, -0.0037,  0.0073,  ..., -0.0168,  0.0043, -0.0133],
        [ 0.0117,  0.0195, -0.0333,  ...,  0.0041, -0.0196, -0.0012]],
       dtype=torch.float16), 'model.layers.7.input_layernorm.weight': tensor([0.3242, 0.3652, 0.3340,  ..., 0.3203, 0.3574, 0.3320],
       dtype=torch.float16), 'model.layers.7.post_attention_layernorm.weight': tensor([0.2383, 0.2197, 0.2236,  ..., 0.2314, 0.2324, 0.2314],
       dtype=torch.float16), 'model.layers.8.self_attn.q_proj.weight': tensor([[-0.0004, -0.0152, -0.0297,  ..., -0.0065,  0.0065, -0.0091],
        [-0.0125, -0.0141, -0.0328,  ...,  0.0038, -0.0112,  0.0025],
        [-0.0400, -0.0028, -0.0129,  ..., -0.0023,  0.0260, -0.0321],
        ...,
        [-0.0062,  0.0861,  0.0443,  ..., -0.0247, -0.0285, -0.0468],
        [ 0.0012, -0.0596, -0.0192,  ...,  0.0352,  0.0269, -0.0008],
        [-0.0648, -0.0531, -0.0116,  ..., -0.0541,  0.0303, -0.0170]],
       dtype=torch.float16), 'model.layers.8.self_attn.k_proj.weight': tensor([[-0.0032, -0.0058, -0.0180,  ..., -0.0109,  0.0052,  0.0049],
        [-0.0125,  0.0011, -0.0050,  ...,  0.0228, -0.0019,  0.0143],
        [-0.0167,  0.0023,  0.0027,  ...,  0.0063, -0.0082, -0.0249],
        ...,
        [ 0.0031, -0.0395, -0.0067,  ..., -0.0295, -0.0149,  0.0230],
        [ 0.0078,  0.0294,  0.0184,  ..., -0.0301,  0.0431, -0.0562],
        [ 0.0190, -0.0026, -0.0326,  ...,  0.0140,  0.0077, -0.0147]],
       dtype=torch.float16), 'model.layers.8.self_attn.v_proj.weight': tensor([[-0.0287, -0.0166,  0.0045,  ..., -0.0193, -0.0085, -0.0096],
        [-0.0234, -0.0132,  0.0059,  ...,  0.0352,  0.0096,  0.0248],
        [-0.0082,  0.0140,  0.0135,  ..., -0.0079,  0.0031, -0.0204],
        ...,
        [ 0.0319, -0.0149,  0.0065,  ...,  0.0218, -0.0201,  0.0271],
        [ 0.0327, -0.0165,  0.0041,  ...,  0.0074, -0.0036,  0.0023],
        [ 0.0126, -0.0004, -0.0005,  ..., -0.0017,  0.0009, -0.0126]],
       dtype=torch.float16), 'model.layers.8.self_attn.o_proj.weight': tensor([[ 0.0177,  0.0157, -0.0148,  ..., -0.0109,  0.0026,  0.0176],
        [ 0.0054,  0.0004, -0.0322,  ..., -0.0121, -0.0108, -0.0186],
        [ 0.0025,  0.0138, -0.0094,  ..., -0.0011,  0.0121,  0.0166],
        ...,
        [-0.0150,  0.0233, -0.0010,  ...,  0.0010, -0.0001, -0.0027],
        [ 0.0086,  0.0015, -0.0089,  ...,  0.0043,  0.0054, -0.0251],
        [-0.0232, -0.0003, -0.0096,  ...,  0.0193, -0.0100,  0.0087]],
       dtype=torch.float16), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0158, -0.0021, -0.0490,  ...,  0.0059, -0.0245, -0.0163],
        [-0.0002, -0.0475,  0.0061,  ..., -0.0033, -0.0370,  0.0276],
        [ 0.0212,  0.0191,  0.0176,  ...,  0.0272,  0.0241, -0.0056],
        ...,
        [-0.0111,  0.0015,  0.0134,  ...,  0.0221,  0.0168,  0.0057],
        [-0.0146,  0.0039,  0.0056,  ..., -0.0016, -0.0165,  0.0145],
        [-0.0243,  0.0096, -0.0066,  ..., -0.0134,  0.0060,  0.0033]],
       dtype=torch.float16), 'model.layers.8.mlp.up_proj.weight': tensor([[-0.0055,  0.0251, -0.0157,  ...,  0.0298,  0.0039, -0.0158],
        [-0.0517,  0.0134, -0.0384,  ...,  0.0145, -0.0113, -0.0159],
        [ 0.0176, -0.0004,  0.0102,  ..., -0.0102, -0.0179,  0.0334],
        ...,
        [-0.0138,  0.0403, -0.0309,  ...,  0.0130,  0.0027,  0.0163],
        [ 0.0054, -0.0047, -0.0058,  ..., -0.0160,  0.0193, -0.0173],
        [-0.0224,  0.0174, -0.0155,  ..., -0.0185, -0.0012, -0.0002]],
       dtype=torch.float16), 'model.layers.8.mlp.down_proj.weight': tensor([[-0.0099, -0.0094,  0.0129,  ...,  0.0072,  0.0198, -0.0290],
        [ 0.0178,  0.0132, -0.0227,  ..., -0.0072,  0.0143, -0.0171],
        [ 0.0061, -0.0186, -0.0251,  ..., -0.0091, -0.0019,  0.0038],
        ...,
        [ 0.0090, -0.0205, -0.0343,  ...,  0.0038,  0.0098, -0.0160],
        [ 0.0096,  0.0107, -0.0036,  ..., -0.0060, -0.0068, -0.0226],
        [-0.0031,  0.0103,  0.0024,  ...,  0.0047,  0.0011,  0.0048]],
       dtype=torch.float16), 'model.layers.8.input_layernorm.weight': tensor([0.3301, 0.3477, 0.3320,  ..., 0.3203, 0.3398, 0.3242],
       dtype=torch.float16), 'model.layers.8.post_attention_layernorm.weight': tensor([0.2422, 0.2314, 0.2236,  ..., 0.2363, 0.2324, 0.2305],
       dtype=torch.float16), 'model.layers.9.self_attn.q_proj.weight': tensor([[-0.0147,  0.0026,  0.0210,  ..., -0.0103, -0.0100, -0.0244],
        [-0.0023, -0.0385,  0.0208,  ..., -0.0013, -0.0039,  0.0068],
        [ 0.0012, -0.0021, -0.0153,  ..., -0.0283, -0.0279, -0.0179],
        ...,
        [-0.0006, -0.0509,  0.0130,  ...,  0.0190,  0.0121, -0.0163],
        [ 0.0161, -0.0186,  0.0037,  ...,  0.0068,  0.0028,  0.0125],
        [-0.0003,  0.0516,  0.0195,  ..., -0.0563,  0.0534, -0.0034]],
       dtype=torch.float16), 'model.layers.9.self_attn.k_proj.weight': tensor([[-0.0307,  0.0100, -0.0252,  ..., -0.0017, -0.0205, -0.0061],
        [-0.0069,  0.0352,  0.0098,  ..., -0.0149,  0.0085,  0.0003],
        [-0.0164, -0.0064,  0.0345,  ...,  0.0036, -0.0246, -0.0038],
        ...,
        [ 0.0229, -0.0136, -0.0035,  ..., -0.0085,  0.0241,  0.0240],
        [ 0.0319,  0.0002,  0.0217,  ...,  0.0495, -0.0169,  0.0517],
        [ 0.0084, -0.0259,  0.0257,  ...,  0.0061,  0.0235, -0.0248]],
       dtype=torch.float16), 'model.layers.9.self_attn.v_proj.weight': tensor([[-0.0064,  0.0087,  0.0034,  ...,  0.0043, -0.0216, -0.0148],
        [-0.0142, -0.0147, -0.0031,  ...,  0.0340, -0.0037, -0.0044],
        [ 0.0071, -0.0220,  0.0211,  ..., -0.0274,  0.0032, -0.0137],
        ...,
        [-0.0094, -0.0083,  0.0037,  ...,  0.0052, -0.0218, -0.0055],
        [-0.0172, -0.0003, -0.0087,  ..., -0.0159,  0.0021, -0.0135],
        [ 0.0245,  0.0242, -0.0037,  ..., -0.0092, -0.0047, -0.0060]],
       dtype=torch.float16), 'model.layers.9.self_attn.o_proj.weight': tensor([[ 0.0102,  0.0094,  0.0113,  ..., -0.0143,  0.0007, -0.0113],
        [-0.0017, -0.0193, -0.0068,  ..., -0.0033,  0.0041,  0.0140],
        [-0.0407, -0.0316,  0.0091,  ...,  0.0292,  0.0020,  0.0106],
        ...,
        [ 0.0148, -0.0133,  0.0091,  ...,  0.0057,  0.0059, -0.0098],
        [ 0.0072,  0.0159,  0.0002,  ...,  0.0084,  0.0001,  0.0006],
        [ 0.0189,  0.0456, -0.0234,  ..., -0.0009,  0.0104,  0.0045]],
       dtype=torch.float16), 'model.layers.9.mlp.gate_proj.weight': tensor([[-0.0097,  0.0258,  0.0002,  ..., -0.0271, -0.0084,  0.0018],
        [-0.0202,  0.0319,  0.0322,  ...,  0.0281,  0.0377,  0.0024],
        [ 0.0390,  0.0285, -0.0269,  ..., -0.0217,  0.0120,  0.0011],
        ...,
        [-0.0204, -0.0079, -0.0243,  ...,  0.0019, -0.0409,  0.0066],
        [-0.0061, -0.0243,  0.0275,  ..., -0.0112,  0.0039,  0.0113],
        [ 0.0146, -0.0229, -0.0039,  ...,  0.0122, -0.0083,  0.0163]],
       dtype=torch.float16), 'model.layers.9.mlp.up_proj.weight': tensor([[-0.0143,  0.0186,  0.0150,  ..., -0.0016, -0.0087,  0.0038],
        [ 0.0086, -0.0010,  0.0079,  ...,  0.0153,  0.0204, -0.0192],
        [-0.0182, -0.0051, -0.0223,  ..., -0.0026, -0.0114,  0.0033],
        ...,
        [ 0.0029,  0.0126, -0.0075,  ..., -0.0150, -0.0307, -0.0130],
        [ 0.0031,  0.0218, -0.0348,  ..., -0.0351, -0.0096, -0.0163],
        [ 0.0102, -0.0337, -0.0058,  ..., -0.0190,  0.0217, -0.0074]],
       dtype=torch.float16), 'model.layers.9.mlp.down_proj.weight': tensor([[-0.0030,  0.0313, -0.0411,  ...,  0.0004, -0.0109,  0.0136],
        [ 0.0216, -0.0283, -0.0173,  ..., -0.0057, -0.0223, -0.0278],
        [-0.0026, -0.0015,  0.0022,  ..., -0.0155,  0.0007, -0.0026],
        ...,
        [-0.0101,  0.0194,  0.0052,  ..., -0.0095, -0.0285,  0.0141],
        [-0.0309,  0.0034,  0.0155,  ..., -0.0204, -0.0034, -0.0333],
        [ 0.0165,  0.0171,  0.0078,  ...,  0.0404,  0.0161,  0.0167]],
       dtype=torch.float16), 'model.layers.9.input_layernorm.weight': tensor([0.3535, 0.3633, 0.3281,  ..., 0.3477, 0.3477, 0.3438],
       dtype=torch.float16), 'model.layers.9.post_attention_layernorm.weight': tensor([0.2490, 0.2334, 0.2285,  ..., 0.2451, 0.2422, 0.2383],
       dtype=torch.float16), 'model.layers.10.self_attn.q_proj.weight': tensor([[-3.6449e-03,  3.8357e-03,  2.0087e-05,  ..., -2.7161e-03,
         -6.6376e-03, -1.4206e-02],
        [-9.7427e-03, -4.9667e-03,  2.0599e-02,  ..., -1.9287e-02,
          6.4575e-02, -3.7270e-03],
        [-1.3718e-02, -1.5106e-02,  2.1040e-04,  ...,  3.4210e-02,
         -9.4452e-03, -1.4389e-02],
        ...,
        [ 3.2104e-02,  6.3049e-02, -1.7929e-02,  ...,  3.7445e-02,
          3.3508e-02, -9.3842e-03],
        [-6.6040e-02,  5.6519e-02, -2.7695e-03,  ..., -6.0577e-02,
         -5.7068e-03, -3.6221e-03],
        [-4.9713e-02, -2.1591e-02, -7.7477e-03,  ..., -1.2627e-02,
         -3.6346e-02, -9.3536e-03]], dtype=torch.float16), 'model.layers.10.self_attn.k_proj.weight': tensor([[-0.0320,  0.0131, -0.0093,  ..., -0.0153,  0.0091, -0.0001],
        [-0.0056,  0.0082, -0.0056,  ..., -0.0057, -0.0101,  0.0133],
        [-0.0008, -0.0022,  0.0067,  ..., -0.0274,  0.0042,  0.0012],
        ...,
        [-0.0464, -0.0599,  0.0127,  ...,  0.0291, -0.0853,  0.0117],
        [-0.0345, -0.0131,  0.0234,  ..., -0.0141, -0.0415, -0.0148],
        [-0.0192,  0.0225, -0.0224,  ...,  0.0083,  0.0425, -0.0002]],
       dtype=torch.float16), 'model.layers.10.self_attn.v_proj.weight': tensor([[-0.0387,  0.0081, -0.0087,  ...,  0.0097,  0.0140,  0.0083],
        [-0.0083,  0.0136,  0.0120,  ..., -0.0067, -0.0419,  0.0195],
        [ 0.0170, -0.0150,  0.0130,  ...,  0.0145,  0.0079, -0.0095],
        ...,
        [ 0.0214,  0.0277,  0.0017,  ...,  0.0253,  0.0023, -0.0228],
        [-0.0040,  0.0057, -0.0005,  ...,  0.0020,  0.0113, -0.0018],
        [ 0.0172,  0.0061, -0.0238,  ..., -0.0072, -0.0071,  0.0242]],
       dtype=torch.float16), 'model.layers.10.self_attn.o_proj.weight': tensor([[-0.0057,  0.0007, -0.0348,  ...,  0.0022,  0.0056,  0.0074],
        [ 0.0006, -0.0118,  0.0126,  ...,  0.0058,  0.0132,  0.0075],
        [ 0.0153, -0.0353, -0.0162,  ...,  0.0007, -0.0036, -0.0031],
        ...,
        [-0.0021,  0.0080, -0.0197,  ..., -0.0031, -0.0003,  0.0199],
        [ 0.0090, -0.0164, -0.0207,  ...,  0.0118,  0.0087,  0.0109],
        [ 0.0075, -0.0081, -0.0278,  ...,  0.0101, -0.0039,  0.0009]],
       dtype=torch.float16), 'model.layers.10.mlp.gate_proj.weight': tensor([[-0.0255, -0.0464, -0.0296,  ...,  0.0059, -0.0014, -0.0041],
        [-0.0152, -0.0224, -0.0173,  ...,  0.0032,  0.0152,  0.0143],
        [-0.0210, -0.0214,  0.0097,  ...,  0.0347, -0.0098,  0.0017],
        ...,
        [-0.0465, -0.0077,  0.0100,  ...,  0.0039, -0.0303,  0.0208],
        [ 0.0046,  0.0114,  0.0203,  ...,  0.0042, -0.0112, -0.0007],
        [-0.0159, -0.0042, -0.0147,  ..., -0.0145,  0.0072, -0.0121]],
       dtype=torch.float16), 'model.layers.10.mlp.up_proj.weight': tensor([[-0.0320, -0.0040, -0.0427,  ...,  0.0109, -0.0067, -0.0190],
        [-0.0074,  0.0061,  0.0065,  ...,  0.0190,  0.0319, -0.0167],
        [-0.0080, -0.0042,  0.0192,  ...,  0.0319, -0.0360,  0.0033],
        ...,
        [ 0.0242,  0.0213, -0.0094,  ..., -0.0432, -0.0039,  0.0027],
        [-0.0012, -0.0116, -0.0232,  ...,  0.0270, -0.0056,  0.0214],
        [-0.0042,  0.0167, -0.0049,  ..., -0.0009,  0.0034,  0.0205]],
       dtype=torch.float16), 'model.layers.10.mlp.down_proj.weight': tensor([[-0.0152, -0.0201, -0.0101,  ...,  0.0302, -0.0133,  0.0010],
        [-0.0054,  0.0221, -0.0139,  ..., -0.0116,  0.0119, -0.0105],
        [-0.0275, -0.0021,  0.0208,  ..., -0.0218, -0.0254,  0.0118],
        ...,
        [ 0.0098, -0.0068, -0.0057,  ...,  0.0063,  0.0142,  0.0074],
        [-0.0106,  0.0519, -0.0189,  ...,  0.0284,  0.0307, -0.0305],
        [-0.0471,  0.0020, -0.0252,  ..., -0.0184, -0.0151,  0.0109]],
       dtype=torch.float16), 'model.layers.10.input_layernorm.weight': tensor([0.3652, 0.3594, 0.3223,  ..., 0.3398, 0.3496, 0.3379],
       dtype=torch.float16), 'model.layers.10.post_attention_layernorm.weight': tensor([0.2500, 0.2383, 0.2285,  ..., 0.2432, 0.2432, 0.2432],
       dtype=torch.float16), 'model.layers.11.self_attn.q_proj.weight': tensor([[ 0.0161, -0.0006, -0.0169,  ...,  0.0251, -0.0088,  0.0062],
        [-0.0113,  0.0006,  0.0061,  ...,  0.0169,  0.0102,  0.0040],
        [ 0.0104,  0.0213, -0.0237,  ..., -0.0047, -0.0055,  0.0015],
        ...,
        [ 0.0066,  0.0024,  0.0322,  ...,  0.0338,  0.0438, -0.0291],
        [ 0.0504,  0.0148, -0.0166,  ..., -0.0151,  0.0161, -0.0268],
        [ 0.0818, -0.0201, -0.0214,  ..., -0.0201,  0.0410,  0.0539]],
       dtype=torch.float16), 'model.layers.11.self_attn.k_proj.weight': tensor([[-0.0052,  0.0221,  0.0030,  ..., -0.0179,  0.0177, -0.0154],
        [ 0.0012,  0.0016, -0.0310,  ..., -0.0106,  0.0045,  0.0256],
        [ 0.0298, -0.0297,  0.0027,  ...,  0.0140,  0.0046,  0.0079],
        ...,
        [-0.0032,  0.0288,  0.0043,  ..., -0.0189, -0.0055,  0.0403],
        [ 0.0598, -0.0065, -0.0142,  ..., -0.0078,  0.0050, -0.0079],
        [ 0.0110,  0.0065,  0.0253,  ..., -0.0007,  0.0569,  0.0267]],
       dtype=torch.float16), 'model.layers.11.self_attn.v_proj.weight': tensor([[ 9.6436e-03,  1.0605e-03, -4.5738e-03,  ..., -2.2232e-02,
         -1.0233e-03,  7.4806e-03],
        [ 2.6855e-03, -6.0806e-03, -1.6937e-02,  ..., -5.5611e-05,
          3.7360e-04, -2.7130e-02],
        [ 2.9392e-03,  9.2468e-03, -7.0686e-03,  ...,  1.6724e-02,
          1.0735e-02, -2.5055e-02],
        ...,
        [-2.0782e-02,  7.5455e-03, -1.4633e-02,  ...,  8.2016e-03,
         -1.7349e-02, -2.2812e-03],
        [-9.9487e-03,  1.0506e-02, -1.1917e-02,  ..., -1.3245e-02,
         -1.7868e-02,  3.2711e-03],
        [ 1.7990e-02, -2.1179e-02, -1.4639e-03,  ..., -4.0344e-02,
          1.8826e-03, -1.2375e-02]], dtype=torch.float16), 'model.layers.11.self_attn.o_proj.weight': tensor([[-0.0191, -0.0035,  0.0060,  ...,  0.0097,  0.0109,  0.0016],
        [-0.0016, -0.0260,  0.0116,  ..., -0.0118, -0.0028, -0.0255],
        [-0.0051, -0.0058,  0.0210,  ...,  0.0021, -0.0066,  0.0139],
        ...,
        [ 0.0016, -0.0042,  0.0228,  ...,  0.0024, -0.0016, -0.0029],
        [ 0.0077,  0.0177,  0.0082,  ...,  0.0172,  0.0129, -0.0298],
        [-0.0027, -0.0047,  0.0054,  ..., -0.0081, -0.0022, -0.0107]],
       dtype=torch.float16), 'model.layers.11.mlp.gate_proj.weight': tensor([[-0.0440, -0.0086,  0.0052,  ...,  0.0062, -0.0116,  0.0425],
        [ 0.0074, -0.0107,  0.0206,  ...,  0.0087, -0.0197, -0.0413],
        [-0.0010, -0.0459, -0.0289,  ..., -0.0025, -0.0084, -0.0026],
        ...,
        [-0.0202, -0.0397, -0.0216,  ..., -0.0041, -0.0321,  0.0039],
        [ 0.0090, -0.0044, -0.0364,  ..., -0.0127,  0.0069,  0.0010],
        [ 0.0023,  0.0186,  0.0080,  ...,  0.0468, -0.0007, -0.0140]],
       dtype=torch.float16), 'model.layers.11.mlp.up_proj.weight': tensor([[-0.0093,  0.0016, -0.0275,  ...,  0.0240,  0.0097,  0.0313],
        [ 0.0179, -0.0028, -0.0222,  ...,  0.0172, -0.0467,  0.0077],
        [-0.0064, -0.0369,  0.0014,  ..., -0.0048, -0.0177,  0.0154],
        ...,
        [ 0.0408,  0.0105, -0.0095,  ...,  0.0014, -0.0005,  0.0161],
        [-0.0116,  0.0200,  0.0059,  ...,  0.0163,  0.0094,  0.0065],
        [-0.0041,  0.0019, -0.0054,  ..., -0.0172, -0.0005,  0.0250]],
       dtype=torch.float16), 'model.layers.11.mlp.down_proj.weight': tensor([[-0.0162,  0.0454,  0.0091,  ...,  0.0194,  0.0163, -0.0040],
        [-0.0136, -0.0092, -0.0251,  ..., -0.0202, -0.0090,  0.0154],
        [-0.0237, -0.0169,  0.0102,  ...,  0.0052, -0.0217, -0.0031],
        ...,
        [ 0.0215,  0.0262, -0.0104,  ..., -0.0017, -0.0003,  0.0087],
        [-0.0111, -0.0290, -0.0306,  ..., -0.0254, -0.0089,  0.0139],
        [ 0.0362,  0.0240,  0.0214,  ..., -0.0028, -0.0135,  0.0383]],
       dtype=torch.float16), 'model.layers.11.input_layernorm.weight': tensor([0.3965, 0.3965, 0.3652,  ..., 0.3848, 0.3828, 0.3711],
       dtype=torch.float16), 'model.layers.11.post_attention_layernorm.weight': tensor([0.2598, 0.2471, 0.2383,  ..., 0.2578, 0.2559, 0.2559],
       dtype=torch.float16), 'model.layers.12.self_attn.q_proj.weight': tensor([[-0.0093, -0.0171,  0.0036,  ...,  0.0262, -0.0099,  0.0055],
        [ 0.0065, -0.0070, -0.0075,  ..., -0.0127,  0.0223,  0.0202],
        [ 0.0106,  0.0411, -0.0328,  ...,  0.0061,  0.0025, -0.0291],
        ...,
        [ 0.0094,  0.0321, -0.0197,  ..., -0.0311, -0.0004, -0.0008],
        [ 0.0424, -0.0059,  0.0097,  ...,  0.0322,  0.0067, -0.0247],
        [ 0.0332,  0.0143, -0.0364,  ..., -0.0210,  0.0215,  0.0238]],
       dtype=torch.float16), 'model.layers.12.self_attn.k_proj.weight': tensor([[ 0.0099, -0.0011, -0.0045,  ...,  0.0193, -0.0024, -0.0102],
        [ 0.0073,  0.0208, -0.0157,  ..., -0.0014, -0.0157, -0.0293],
        [-0.0113, -0.0283,  0.0173,  ...,  0.0087,  0.0026,  0.0026],
        ...,
        [ 0.0132,  0.0322, -0.0148,  ..., -0.0355, -0.0164, -0.0242],
        [-0.0381,  0.0037,  0.0226,  ..., -0.0282,  0.0146, -0.0006],
        [-0.0007,  0.0322,  0.0109,  ...,  0.0129, -0.0465, -0.0404]],
       dtype=torch.float16), 'model.layers.12.self_attn.v_proj.weight': tensor([[ 0.0064,  0.0072,  0.0069,  ..., -0.0077,  0.0109, -0.0189],
        [-0.0275,  0.0104, -0.0036,  ..., -0.0175, -0.0006,  0.0191],
        [-0.0148, -0.0132,  0.0088,  ..., -0.0069,  0.0475, -0.0107],
        ...,
        [ 0.0081, -0.0017, -0.0150,  ..., -0.0068, -0.0115, -0.0013],
        [-0.0010, -0.0147, -0.0047,  ...,  0.0034,  0.0109,  0.0122],
        [ 0.0225,  0.0017,  0.0007,  ...,  0.0178,  0.0139, -0.0070]],
       dtype=torch.float16), 'model.layers.12.self_attn.o_proj.weight': tensor([[ 0.0277,  0.0071, -0.0019,  ..., -0.0012,  0.0083, -0.0061],
        [-0.0092, -0.0141, -0.0014,  ..., -0.0108,  0.0061, -0.0138],
        [ 0.0068, -0.0023, -0.0018,  ...,  0.0037, -0.0232,  0.0125],
        ...,
        [ 0.0032, -0.0023,  0.0126,  ..., -0.0084, -0.0009,  0.0019],
        [-0.0108, -0.0346, -0.0278,  ..., -0.0121,  0.0109,  0.0143],
        [ 0.0210,  0.0093,  0.0084,  ...,  0.0209, -0.0084, -0.0171]],
       dtype=torch.float16), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0057, -0.0110,  0.0123,  ..., -0.0042,  0.0268, -0.0024],
        [-0.0266, -0.0214,  0.0172,  ...,  0.0121,  0.0153,  0.0057],
        [-0.0005,  0.0258, -0.0114,  ..., -0.0099, -0.0289, -0.0045],
        ...,
        [-0.0024,  0.0108,  0.0106,  ..., -0.0328,  0.0070,  0.0276],
        [-0.0325, -0.0083,  0.0082,  ...,  0.0103,  0.0123, -0.0085],
        [ 0.0045, -0.0267, -0.0056,  ..., -0.0053, -0.0018, -0.0202]],
       dtype=torch.float16), 'model.layers.12.mlp.up_proj.weight': tensor([[ 2.9488e-03,  1.7151e-02,  3.6030e-03,  ..., -9.1076e-05,
          1.3832e-02,  1.5427e-02],
        [-3.6373e-03, -1.4801e-02, -1.3435e-02,  ...,  6.5842e-03,
         -7.0915e-03,  2.4414e-02],
        [ 1.4610e-02, -1.2291e-02,  7.4959e-03,  ..., -4.1534e-02,
          4.9171e-03,  1.6441e-03],
        ...,
        [-2.6154e-02, -3.3844e-02, -7.3738e-03,  ...,  1.6922e-02,
         -1.5038e-02,  3.0403e-03],
        [-1.5144e-03, -4.3915e-02, -8.0156e-04,  ...,  1.3924e-02,
          3.0556e-03, -1.5656e-02],
        [ 2.2144e-03, -2.8961e-02,  3.7813e-04,  ...,  3.2440e-02,
         -3.6602e-03, -3.8300e-02]], dtype=torch.float16), 'model.layers.12.mlp.down_proj.weight': tensor([[ 0.0081, -0.0018, -0.0294,  ..., -0.0123,  0.0035,  0.0029],
        [ 0.0170, -0.0288,  0.0046,  ..., -0.0004, -0.0089, -0.0230],
        [ 0.0200,  0.0030,  0.0241,  ...,  0.0043, -0.0012, -0.0281],
        ...,
        [ 0.0183, -0.0085, -0.0380,  ...,  0.0313, -0.0193, -0.0176],
        [-0.0259,  0.0179,  0.0106,  ..., -0.0092,  0.0359, -0.0229],
        [ 0.0075,  0.0262,  0.0221,  ..., -0.0381,  0.0273, -0.0022]],
       dtype=torch.float16), 'model.layers.12.input_layernorm.weight': tensor([0.4062, 0.4023, 0.3691,  ..., 0.3848, 0.3867, 0.3887],
       dtype=torch.float16), 'model.layers.12.post_attention_layernorm.weight': tensor([0.2656, 0.2520, 0.2432,  ..., 0.2656, 0.2617, 0.2598],
       dtype=torch.float16), 'model.layers.13.self_attn.q_proj.weight': tensor([[-0.0002, -0.0013, -0.0132,  ...,  0.0055, -0.0150, -0.0128],
        [-0.0118, -0.0142,  0.0031,  ..., -0.0004,  0.0004, -0.0026],
        [-0.0175,  0.0138,  0.0197,  ..., -0.0115, -0.0075, -0.0069],
        ...,
        [ 0.0483,  0.0084,  0.0043,  ...,  0.0573,  0.0140, -0.0512],
        [ 0.0078,  0.0083, -0.0259,  ...,  0.0091,  0.0111, -0.0104],
        [-0.0040, -0.0248, -0.0212,  ..., -0.0068,  0.0285, -0.0065]],
       dtype=torch.float16), 'model.layers.13.self_attn.k_proj.weight': tensor([[ 0.0134,  0.0048, -0.0030,  ..., -0.0130,  0.0337,  0.0125],
        [ 0.0155,  0.0307, -0.0005,  ..., -0.0055,  0.0136,  0.0046],
        [-0.0007, -0.0130,  0.0334,  ..., -0.0083,  0.0110, -0.0375],
        ...,
        [ 0.0375,  0.0356,  0.0033,  ...,  0.0048, -0.0061, -0.0118],
        [-0.0010,  0.0045,  0.0287,  ..., -0.0342, -0.0217,  0.0352],
        [-0.0229, -0.0535, -0.0142,  ..., -0.0378, -0.0310,  0.0118]],
       dtype=torch.float16), 'model.layers.13.self_attn.v_proj.weight': tensor([[ 0.0149,  0.0064, -0.0058,  ..., -0.0005,  0.0173,  0.0124],
        [-0.0029,  0.0087,  0.0005,  ...,  0.0233, -0.0065, -0.0029],
        [ 0.0146, -0.0016, -0.0023,  ..., -0.0212,  0.0366, -0.0090],
        ...,
        [-0.0011,  0.0251, -0.0052,  ..., -0.0111,  0.0272, -0.0211],
        [-0.0103,  0.0104,  0.0128,  ...,  0.0017,  0.0274,  0.0058],
        [-0.0045, -0.0064,  0.0239,  ...,  0.0154, -0.0026,  0.0374]],
       dtype=torch.float16), 'model.layers.13.self_attn.o_proj.weight': tensor([[-0.0035,  0.0010, -0.0044,  ..., -0.0015, -0.0045, -0.0012],
        [ 0.0222,  0.0148,  0.0101,  ..., -0.0146, -0.0108,  0.0024],
        [ 0.0118,  0.0055,  0.0036,  ...,  0.0065, -0.0233, -0.0088],
        ...,
        [-0.0102,  0.0102,  0.0194,  ..., -0.0114, -0.0154, -0.0165],
        [ 0.0083, -0.0005,  0.0301,  ..., -0.0037, -0.0268, -0.0238],
        [ 0.0100,  0.0019,  0.0086,  ...,  0.0171, -0.0083, -0.0238]],
       dtype=torch.float16), 'model.layers.13.mlp.gate_proj.weight': tensor([[ 0.0249, -0.0034, -0.0082,  ...,  0.0114,  0.0034, -0.0122],
        [-0.0141,  0.0452,  0.0071,  ...,  0.0416, -0.0012, -0.0260],
        [ 0.0035, -0.0199, -0.0103,  ...,  0.0047, -0.0093, -0.0152],
        ...,
        [ 0.0153, -0.0196,  0.0202,  ..., -0.0065,  0.0133,  0.0111],
        [ 0.0154, -0.0125,  0.0203,  ...,  0.0181,  0.0106, -0.0270],
        [ 0.0028,  0.0392,  0.0161,  ..., -0.0045,  0.0059,  0.0285]],
       dtype=torch.float16), 'model.layers.13.mlp.up_proj.weight': tensor([[-0.0423,  0.0199, -0.0013,  ...,  0.0037,  0.0091,  0.0011],
        [ 0.0138, -0.0066,  0.0247,  ...,  0.0468,  0.0286,  0.0224],
        [ 0.0281, -0.0344,  0.0093,  ...,  0.0069,  0.0009, -0.0082],
        ...,
        [-0.0130, -0.0038,  0.0297,  ...,  0.0190, -0.0247,  0.0139],
        [-0.0103, -0.0171,  0.0079,  ...,  0.0177,  0.0563,  0.0096],
        [ 0.0117, -0.0212,  0.0179,  ..., -0.0185, -0.0004,  0.0269]],
       dtype=torch.float16), 'model.layers.13.mlp.down_proj.weight': tensor([[-0.0062, -0.0036, -0.0027,  ...,  0.0226, -0.0265, -0.0220],
        [-0.0117,  0.0470, -0.0413,  ..., -0.0018,  0.0133, -0.0090],
        [ 0.0081,  0.0038,  0.0183,  ...,  0.0015, -0.0249, -0.0031],
        ...,
        [ 0.0058,  0.0077,  0.0354,  ..., -0.0014, -0.0209,  0.0290],
        [ 0.0167, -0.0015,  0.0188,  ..., -0.0109,  0.0164, -0.0045],
        [ 0.0029, -0.0229,  0.0393,  ...,  0.0041,  0.0022,  0.0325]],
       dtype=torch.float16), 'model.layers.13.input_layernorm.weight': tensor([0.4199, 0.4121, 0.3770,  ..., 0.3926, 0.3848, 0.3965],
       dtype=torch.float16), 'model.layers.13.post_attention_layernorm.weight': tensor([0.2715, 0.2598, 0.2539,  ..., 0.2715, 0.2734, 0.2656],
       dtype=torch.float16), 'model.layers.14.self_attn.q_proj.weight': tensor([[-0.0088, -0.0028,  0.0195,  ..., -0.0054,  0.0162,  0.0367],
        [ 0.0097,  0.0160, -0.0124,  ..., -0.0348, -0.0203, -0.0406],
        [-0.0202, -0.0112,  0.0171,  ...,  0.0106,  0.0140, -0.0339],
        ...,
        [-0.0201,  0.0005, -0.0295,  ...,  0.0018,  0.0130, -0.0074],
        [ 0.0269, -0.0389,  0.0497,  ..., -0.0134,  0.0061, -0.0092],
        [-0.0175, -0.0090, -0.0035,  ...,  0.0170,  0.0184, -0.0447]],
       dtype=torch.float16), 'model.layers.14.self_attn.k_proj.weight': tensor([[-0.0143, -0.0049,  0.0068,  ..., -0.0091,  0.0271,  0.0431],
        [ 0.0191,  0.0324, -0.0204,  ..., -0.0030, -0.0276, -0.0050],
        [-0.0183,  0.0034,  0.0196,  ...,  0.0239,  0.0110,  0.0012],
        ...,
        [-0.0387, -0.0029,  0.0264,  ..., -0.0049,  0.0017, -0.0254],
        [-0.0293,  0.0005,  0.0153,  ..., -0.0359, -0.0144,  0.0012],
        [-0.0202,  0.0292,  0.0236,  ...,  0.0703,  0.0087, -0.0386]],
       dtype=torch.float16), 'model.layers.14.self_attn.v_proj.weight': tensor([[ 7.4310e-03,  7.7629e-03, -3.8025e-02,  ..., -3.4210e-02,
         -5.2032e-03,  1.2451e-02],
        [-1.0204e-03, -2.5452e-02, -3.0117e-03,  ...,  1.0887e-02,
         -5.2512e-05, -3.2425e-03],
        [ 2.6276e-02, -1.5022e-02,  2.2659e-03,  ..., -5.5466e-03,
          2.3460e-03,  8.2321e-03],
        ...,
        [ 1.5747e-02, -1.1642e-02,  1.5343e-02,  ...,  1.5533e-02,
         -1.1597e-02,  2.6016e-03],
        [-1.1391e-02,  2.2583e-02, -3.5553e-02,  ..., -7.8058e-04,
         -8.8654e-03, -2.5574e-02],
        [ 3.5992e-03,  2.3102e-02, -2.2568e-02,  ..., -5.2261e-03,
         -3.3932e-03,  1.8295e-02]], dtype=torch.float16), 'model.layers.14.self_attn.o_proj.weight': tensor([[-0.0108,  0.0044, -0.0227,  ..., -0.0021,  0.0010, -0.0110],
        [ 0.0080,  0.0304,  0.0077,  ...,  0.0221, -0.0049,  0.0021],
        [ 0.0060,  0.0082,  0.0024,  ...,  0.0075,  0.0206,  0.0054],
        ...,
        [ 0.0245, -0.0073,  0.0008,  ..., -0.0073, -0.0022,  0.0139],
        [-0.0025,  0.0010, -0.0195,  ..., -0.0021,  0.0362,  0.0155],
        [-0.0085, -0.0104, -0.0139,  ..., -0.0070,  0.0146,  0.0060]],
       dtype=torch.float16), 'model.layers.14.mlp.gate_proj.weight': tensor([[-0.0084,  0.0011, -0.0090,  ...,  0.0102, -0.0185, -0.0064],
        [ 0.0296,  0.0080, -0.0390,  ...,  0.0377,  0.0119, -0.0075],
        [ 0.0095,  0.0148, -0.0004,  ..., -0.0081,  0.0108, -0.0179],
        ...,
        [ 0.0065,  0.0105, -0.0190,  ...,  0.0003, -0.0047,  0.0004],
        [ 0.0033,  0.0159,  0.0201,  ..., -0.0192,  0.0087,  0.0073],
        [ 0.0200,  0.0017,  0.0183,  ..., -0.0106, -0.0248,  0.0258]],
       dtype=torch.float16), 'model.layers.14.mlp.up_proj.weight': tensor([[ 0.0052,  0.0099,  0.0201,  ..., -0.0153,  0.0073,  0.0048],
        [ 0.0269,  0.0089, -0.0300,  ...,  0.0064,  0.0262,  0.0104],
        [ 0.0012, -0.0055,  0.0300,  ..., -0.0013,  0.0177, -0.0023],
        ...,
        [-0.0164, -0.0013, -0.0479,  ..., -0.0145, -0.0116, -0.0048],
        [-0.0415,  0.0074, -0.0075,  ..., -0.0081,  0.0239, -0.0144],
        [ 0.0029,  0.0235,  0.0122,  ...,  0.0086, -0.0140,  0.0131]],
       dtype=torch.float16), 'model.layers.14.mlp.down_proj.weight': tensor([[ 0.0100,  0.0243,  0.0113,  ..., -0.0290, -0.0019, -0.0056],
        [ 0.0121,  0.0222, -0.0091,  ...,  0.0131, -0.0032,  0.0189],
        [ 0.0080, -0.0420,  0.0119,  ...,  0.0042, -0.0302,  0.0124],
        ...,
        [ 0.0005,  0.0152, -0.0169,  ..., -0.0046, -0.0100, -0.0109],
        [ 0.0242,  0.0335,  0.0364,  ..., -0.0051, -0.0155,  0.0210],
        [-0.0245,  0.0057, -0.0101,  ..., -0.0300,  0.0070,  0.0187]],
       dtype=torch.float16), 'model.layers.14.input_layernorm.weight': tensor([0.4219, 0.4297, 0.3789,  ..., 0.4141, 0.4062, 0.3984],
       dtype=torch.float16), 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2734, 0.2656,  ..., 0.2871, 0.2832, 0.2793],
       dtype=torch.float16), 'model.layers.15.self_attn.q_proj.weight': tensor([[-0.0194, -0.0154, -0.0142,  ...,  0.0138, -0.0084,  0.0010],
        [ 0.0363, -0.0190,  0.0038,  ..., -0.0058,  0.0144,  0.0015],
        [ 0.0084, -0.0132,  0.0030,  ...,  0.0098, -0.0134, -0.0160],
        ...,
        [-0.0477, -0.0267,  0.0071,  ..., -0.0063, -0.0128,  0.0200],
        [-0.0155, -0.0536,  0.0174,  ...,  0.0155, -0.0015,  0.0025],
        [ 0.0236,  0.0251,  0.0278,  ..., -0.0140, -0.0227, -0.0165]],
       dtype=torch.float16), 'model.layers.15.self_attn.k_proj.weight': tensor([[ 0.0209, -0.0054, -0.0045,  ..., -0.0027,  0.0014,  0.0044],
        [ 0.0111, -0.0042, -0.0052,  ..., -0.0015,  0.0046, -0.0135],
        [-0.0021,  0.0020, -0.0083,  ..., -0.0007,  0.0133, -0.0119],
        ...,
        [-0.0540, -0.0380,  0.0168,  ...,  0.0214,  0.0069, -0.0060],
        [ 0.0092,  0.0011,  0.0159,  ...,  0.0275, -0.0217,  0.0132],
        [-0.0067, -0.0060,  0.0341,  ..., -0.0027, -0.0171,  0.0033]],
       dtype=torch.float16), 'model.layers.15.self_attn.v_proj.weight': tensor([[ 0.0088,  0.0023,  0.0053,  ...,  0.0037,  0.0141,  0.0177],
        [-0.0096, -0.0142,  0.0151,  ...,  0.0168,  0.0018,  0.0224],
        [ 0.0075, -0.0377, -0.0064,  ..., -0.0365,  0.0073,  0.0073],
        ...,
        [-0.0038, -0.0107,  0.0116,  ...,  0.0066,  0.0181, -0.0141],
        [ 0.0056, -0.0006, -0.0311,  ...,  0.0116,  0.0151, -0.0054],
        [ 0.0169,  0.0104,  0.0152,  ..., -0.0160,  0.0075,  0.0077]],
       dtype=torch.float16), 'model.layers.15.self_attn.o_proj.weight': tensor([[ 0.0012,  0.0029, -0.0154,  ...,  0.0104, -0.0127,  0.0282],
        [-0.0046, -0.0112, -0.0177,  ...,  0.0099, -0.0261,  0.0198],
        [ 0.0020, -0.0083,  0.0008,  ...,  0.0102, -0.0070,  0.0095],
        ...,
        [-0.0089, -0.0197,  0.0142,  ..., -0.0044, -0.0201, -0.0100],
        [ 0.0005, -0.0017, -0.0072,  ...,  0.0113,  0.0051,  0.0044],
        [-0.0241,  0.0053,  0.0263,  ..., -0.0118, -0.0254, -0.0296]],
       dtype=torch.float16), 'model.layers.15.mlp.gate_proj.weight': tensor([[-0.0145,  0.0259, -0.0075,  ...,  0.0116, -0.0298,  0.0140],
        [ 0.0069, -0.0101,  0.0278,  ..., -0.0192,  0.0056,  0.0099],
        [ 0.0088, -0.0179, -0.0112,  ...,  0.0231, -0.0539, -0.0260],
        ...,
        [-0.0106, -0.0046,  0.0301,  ..., -0.0094,  0.0175,  0.0069],
        [-0.0124, -0.0172,  0.0103,  ..., -0.0082, -0.0106, -0.0440],
        [ 0.0040, -0.0142, -0.0008,  ...,  0.0002,  0.0071, -0.0001]],
       dtype=torch.float16), 'model.layers.15.mlp.up_proj.weight': tensor([[-1.2886e-02, -9.5215e-03,  2.7924e-02,  ...,  1.2367e-02,
          1.1269e-02, -4.3579e-02],
        [-1.5732e-02,  4.2908e-02,  2.9343e-02,  ...,  1.0506e-02,
          7.6866e-03,  3.9864e-03],
        [-4.2419e-02, -7.7896e-03, -4.7994e-04,  ..., -1.5518e-02,
          1.5602e-02, -1.0269e-02],
        ...,
        [-6.7863e-03, -2.3376e-02, -7.8659e-03,  ...,  8.5068e-03,
         -4.8757e-05, -4.9782e-03],
        [ 2.7618e-02, -5.3329e-03,  7.8354e-03,  ..., -1.0330e-02,
          1.5747e-02,  5.7030e-04],
        [-7.5302e-03, -2.7130e-02, -9.7809e-03,  ...,  4.5633e-04,
         -1.2245e-02,  1.1940e-03]], dtype=torch.float16), 'model.layers.15.mlp.down_proj.weight': tensor([[-1.2512e-02, -6.8245e-03, -1.6098e-02,  ...,  2.5909e-02,
          9.1171e-03, -1.0674e-02],
        [ 1.0666e-02, -1.1749e-02, -2.6199e-02,  ..., -1.1993e-02,
         -2.3163e-02,  1.6129e-02],
        [ 3.8452e-02,  4.4830e-02, -1.5747e-02,  ..., -1.1589e-02,
          3.4302e-02,  1.8906e-02],
        ...,
        [-4.5853e-03, -3.9978e-02,  6.3210e-03,  ...,  9.4833e-03,
          5.5046e-03,  7.1466e-05],
        [-4.1779e-02, -1.7502e-02, -1.1826e-03,  ..., -2.9480e-02,
         -1.5137e-02,  7.0038e-03],
        [ 1.5354e-03,  2.3773e-02, -6.3553e-03,  ..., -1.7715e-02,
         -3.2593e-02, -2.0401e-02]], dtype=torch.float16), 'model.layers.15.input_layernorm.weight': tensor([0.4160, 0.4102, 0.3809,  ..., 0.3867, 0.3945, 0.3945],
       dtype=torch.float16), 'model.layers.15.post_attention_layernorm.weight': tensor([0.2930, 0.2793, 0.2793,  ..., 0.2969, 0.2910, 0.2891],
       dtype=torch.float16), 'model.layers.16.self_attn.q_proj.weight': tensor([[ 0.0090,  0.0135, -0.0253,  ...,  0.0048,  0.0263, -0.0078],
        [ 0.0172, -0.0415,  0.0228,  ...,  0.0170,  0.0186, -0.0237],
        [-0.0128, -0.0067,  0.0088,  ..., -0.0257,  0.0021, -0.0261],
        ...,
        [ 0.0328, -0.0378, -0.0080,  ..., -0.0196,  0.0181, -0.0271],
        [-0.0166, -0.0170,  0.0283,  ...,  0.0018, -0.0181,  0.0157],
        [ 0.0046,  0.0219,  0.0146,  ..., -0.0030, -0.0327, -0.0095]],
       dtype=torch.float16), 'model.layers.16.self_attn.k_proj.weight': tensor([[-0.0072,  0.0235,  0.0023,  ...,  0.0131,  0.0227,  0.0217],
        [ 0.0223, -0.0315,  0.0097,  ..., -0.0058, -0.0194, -0.0077],
        [ 0.0272, -0.0056, -0.0197,  ..., -0.0234,  0.0092, -0.0277],
        ...,
        [ 0.0239,  0.0135, -0.0127,  ..., -0.0233, -0.0399, -0.0581],
        [ 0.0161,  0.0086,  0.0133,  ...,  0.0302,  0.0043,  0.0115],
        [-0.0444,  0.0565,  0.0591,  ...,  0.0017, -0.0147,  0.0274]],
       dtype=torch.float16), 'model.layers.16.self_attn.v_proj.weight': tensor([[-0.0166,  0.0066, -0.0049,  ...,  0.0065, -0.0008, -0.0020],
        [-0.0576, -0.0069,  0.0042,  ...,  0.0035,  0.0128, -0.0267],
        [-0.0069, -0.0133, -0.0021,  ..., -0.0211,  0.0416,  0.0151],
        ...,
        [ 0.0040, -0.0079,  0.0167,  ..., -0.0125, -0.0001,  0.0166],
        [-0.0169,  0.0023,  0.0052,  ...,  0.0389, -0.0043,  0.0089],
        [ 0.0118,  0.0102,  0.0083,  ..., -0.0158, -0.0042, -0.0301]],
       dtype=torch.float16), 'model.layers.16.self_attn.o_proj.weight': tensor([[ 0.0388, -0.0079, -0.0170,  ...,  0.0112, -0.0126,  0.0047],
        [-0.0246,  0.0107, -0.0208,  ...,  0.0039, -0.0083,  0.0016],
        [-0.0285, -0.0177, -0.0134,  ..., -0.0021,  0.0259,  0.0170],
        ...,
        [-0.0030, -0.0207,  0.0029,  ...,  0.0046, -0.0266,  0.0010],
        [-0.0073,  0.0199,  0.0344,  ..., -0.0005,  0.0009, -0.0051],
        [-0.0192,  0.0035,  0.0066,  ...,  0.0018,  0.0024,  0.0109]],
       dtype=torch.float16), 'model.layers.16.mlp.gate_proj.weight': tensor([[-0.0275, -0.0157, -0.0233,  ...,  0.0007, -0.0003,  0.0085],
        [ 0.0313,  0.0157, -0.0098,  ...,  0.0153,  0.0087,  0.0166],
        [ 0.0027,  0.0056,  0.0041,  ..., -0.0008, -0.0035, -0.0189],
        ...,
        [-0.0086,  0.0085,  0.0053,  ...,  0.0223,  0.0300,  0.0286],
        [-0.0033, -0.0147,  0.0094,  ...,  0.0099,  0.0210,  0.0115],
        [ 0.0256,  0.0212,  0.0310,  ..., -0.0399,  0.0148, -0.0203]],
       dtype=torch.float16), 'model.layers.16.mlp.up_proj.weight': tensor([[-0.0403,  0.0147,  0.0066,  ...,  0.0294, -0.0128,  0.0091],
        [ 0.0156, -0.0131,  0.0048,  ...,  0.0215, -0.0303, -0.0077],
        [-0.0078, -0.0256, -0.0064,  ..., -0.0124, -0.0047,  0.0258],
        ...,
        [-0.0096,  0.0263, -0.0066,  ...,  0.0095, -0.0235, -0.0248],
        [-0.0098,  0.0216, -0.0177,  ...,  0.0097, -0.0052,  0.0185],
        [ 0.0099,  0.0079, -0.0118,  ...,  0.0013, -0.0239, -0.0209]],
       dtype=torch.float16), 'model.layers.16.mlp.down_proj.weight': tensor([[-0.0236,  0.0045,  0.0134,  ...,  0.0206, -0.0091, -0.0008],
        [-0.0233, -0.0041, -0.0123,  ...,  0.0286,  0.0018, -0.0002],
        [-0.0142,  0.0049, -0.0120,  ...,  0.0201, -0.0042, -0.0009],
        ...,
        [ 0.0143, -0.0248, -0.0242,  ...,  0.0203,  0.0178, -0.0020],
        [ 0.0227,  0.0019, -0.0097,  ..., -0.0214, -0.0128, -0.0098],
        [ 0.0107, -0.0168, -0.0371,  ...,  0.0256, -0.0010, -0.0141]],
       dtype=torch.float16), 'model.layers.16.input_layernorm.weight': tensor([0.4180, 0.4219, 0.3906,  ..., 0.3984, 0.4160, 0.4082],
       dtype=torch.float16), 'model.layers.16.post_attention_layernorm.weight': tensor([0.3164, 0.2949, 0.2988,  ..., 0.3105, 0.3086, 0.3047],
       dtype=torch.float16), 'model.layers.17.self_attn.q_proj.weight': tensor([[-0.0125, -0.0138,  0.0065,  ...,  0.0073, -0.0072, -0.0107],
        [ 0.0094, -0.0095,  0.0169,  ...,  0.0019, -0.0260,  0.0081],
        [-0.0130, -0.0020, -0.0129,  ...,  0.0152, -0.0114,  0.0020],
        ...,
        [ 0.0362, -0.0261,  0.0562,  ..., -0.0142, -0.0178,  0.0079],
        [ 0.0282, -0.0184,  0.0462,  ...,  0.0094, -0.0215, -0.0601],
        [ 0.0126, -0.0017,  0.0116,  ...,  0.0320,  0.0013,  0.0742]],
       dtype=torch.float16), 'model.layers.17.self_attn.k_proj.weight': tensor([[-0.0127, -0.0063,  0.0040,  ..., -0.0014,  0.0197,  0.0079],
        [ 0.0078,  0.0072,  0.0041,  ...,  0.0103,  0.0002, -0.0138],
        [ 0.0077, -0.0085,  0.0012,  ...,  0.0154, -0.0231, -0.0079],
        ...,
        [ 0.0041, -0.0500, -0.0091,  ..., -0.0221,  0.0599, -0.0676],
        [ 0.0275,  0.0191,  0.0122,  ..., -0.0132, -0.0267, -0.0225],
        [-0.0380, -0.0470, -0.0048,  ...,  0.0278,  0.0259, -0.0048]],
       dtype=torch.float16), 'model.layers.17.self_attn.v_proj.weight': tensor([[-0.0122,  0.0105,  0.0024,  ...,  0.0239, -0.0088, -0.0096],
        [-0.0039, -0.0155, -0.0111,  ...,  0.0116, -0.0257, -0.0144],
        [ 0.0174,  0.0158, -0.0024,  ...,  0.0018, -0.0111, -0.0288],
        ...,
        [ 0.0010, -0.0043,  0.0143,  ...,  0.0121,  0.0051, -0.0155],
        [ 0.0189, -0.0031, -0.0388,  ..., -0.0152, -0.0034, -0.0341],
        [-0.0093, -0.0103, -0.0053,  ...,  0.0055,  0.0081,  0.0092]],
       dtype=torch.float16), 'model.layers.17.self_attn.o_proj.weight': tensor([[-0.0049, -0.0105,  0.0036,  ..., -0.0197,  0.0008, -0.0131],
        [-0.0116, -0.0207,  0.0218,  ...,  0.0219, -0.0174,  0.0221],
        [ 0.0098, -0.0111, -0.0045,  ..., -0.0186, -0.0138, -0.0218],
        ...,
        [-0.0109,  0.0140, -0.0118,  ..., -0.0310, -0.0329, -0.0185],
        [-0.0070,  0.0101, -0.0009,  ..., -0.0287,  0.0044,  0.0065],
        [-0.0155, -0.0129,  0.0072,  ...,  0.0329, -0.0223,  0.0173]],
       dtype=torch.float16), 'model.layers.17.mlp.gate_proj.weight': tensor([[-0.0341,  0.0291,  0.0243,  ...,  0.0059,  0.0021,  0.0031],
        [-0.0008,  0.0264,  0.0270,  ...,  0.0185,  0.0077,  0.0121],
        [ 0.0100,  0.0120, -0.0222,  ...,  0.0171,  0.0307, -0.0055],
        ...,
        [-0.0114, -0.0160, -0.0122,  ..., -0.0103, -0.0229, -0.0157],
        [ 0.0041,  0.0033,  0.0092,  ...,  0.0065,  0.0431, -0.0114],
        [-0.0032,  0.0208,  0.0144,  ..., -0.0138, -0.0018, -0.0032]],
       dtype=torch.float16), 'model.layers.17.mlp.up_proj.weight': tensor([[-0.0169, -0.0280, -0.0067,  ...,  0.0061,  0.0168, -0.0130],
        [-0.0231,  0.0152,  0.0278,  ...,  0.0003,  0.0016,  0.0020],
        [-0.0010, -0.0031,  0.0035,  ...,  0.0089, -0.0150,  0.0119],
        ...,
        [ 0.0138,  0.0168,  0.0068,  ...,  0.0064, -0.0204, -0.0130],
        [-0.0162, -0.0182, -0.0103,  ..., -0.0115, -0.0220,  0.0159],
        [-0.0032,  0.0038, -0.0083,  ...,  0.0034, -0.0360, -0.0131]],
       dtype=torch.float16), 'model.layers.17.mlp.down_proj.weight': tensor([[ 0.0260, -0.0225,  0.0134,  ...,  0.0120, -0.0079, -0.0022],
        [ 0.0285,  0.0301,  0.0086,  ...,  0.0063, -0.0083,  0.0336],
        [-0.0263, -0.0165, -0.0178,  ...,  0.0121, -0.0150, -0.0046],
        ...,
        [ 0.0067, -0.0222, -0.0068,  ..., -0.0141, -0.0051, -0.0367],
        [ 0.0015,  0.0053, -0.0114,  ..., -0.0275, -0.0274,  0.0174],
        [-0.0009, -0.0200,  0.0189,  ..., -0.0368, -0.0108,  0.0045]],
       dtype=torch.float16), 'model.layers.17.input_layernorm.weight': tensor([0.4316, 0.4336, 0.4043,  ..., 0.4238, 0.4277, 0.4062],
       dtype=torch.float16), 'model.layers.17.post_attention_layernorm.weight': tensor([0.3320, 0.3164, 0.3145,  ..., 0.3320, 0.3301, 0.3223],
       dtype=torch.float16), 'model.layers.18.self_attn.q_proj.weight': tensor([[ 0.0067,  0.0054,  0.0022,  ..., -0.0046, -0.0363,  0.0100],
        [ 0.0022, -0.0133,  0.0213,  ...,  0.0001,  0.0255,  0.0434],
        [ 0.0111, -0.0257, -0.0097,  ...,  0.0015, -0.0081,  0.0164],
        ...,
        [-0.0324,  0.0133,  0.0033,  ...,  0.0230,  0.0055,  0.0155],
        [ 0.0622, -0.0166, -0.0270,  ...,  0.0574,  0.0266,  0.0184],
        [ 0.0301,  0.0155,  0.0043,  ...,  0.0281,  0.0549, -0.0513]],
       dtype=torch.float16), 'model.layers.18.self_attn.k_proj.weight': tensor([[-0.0115,  0.0326, -0.0141,  ...,  0.0089, -0.0094, -0.0243],
        [ 0.0082, -0.0191,  0.0162,  ...,  0.0176,  0.0292,  0.0015],
        [ 0.0123, -0.0097, -0.0019,  ...,  0.0210, -0.0017,  0.0248],
        ...,
        [-0.1082, -0.0282, -0.0618,  ...,  0.0203, -0.0044, -0.0386],
        [ 0.0520,  0.0363, -0.0182,  ...,  0.0459,  0.0646, -0.0261],
        [-0.0487, -0.0503, -0.0435,  ...,  0.0343, -0.0235, -0.0319]],
       dtype=torch.float16), 'model.layers.18.self_attn.v_proj.weight': tensor([[-0.0296,  0.0286, -0.0176,  ...,  0.0053,  0.0276,  0.0051],
        [ 0.0173,  0.0070, -0.0124,  ..., -0.0175,  0.0382, -0.0023],
        [ 0.0001,  0.0193,  0.0009,  ...,  0.0046, -0.0021, -0.0077],
        ...,
        [ 0.0137,  0.0160, -0.0047,  ..., -0.0077, -0.0233,  0.0025],
        [ 0.0073, -0.0028,  0.0031,  ...,  0.0136,  0.0159,  0.0355],
        [-0.0068,  0.0012,  0.0111,  ..., -0.0062, -0.0200,  0.0024]],
       dtype=torch.float16), 'model.layers.18.self_attn.o_proj.weight': tensor([[-0.0180,  0.0188, -0.0144,  ...,  0.0118,  0.0222,  0.0198],
        [-0.0003, -0.0400,  0.0047,  ..., -0.0010, -0.0070, -0.0164],
        [ 0.0022, -0.0141,  0.0099,  ...,  0.0279,  0.0158,  0.0373],
        ...,
        [-0.0351, -0.0236, -0.0248,  ...,  0.0230,  0.0176, -0.0098],
        [ 0.0128,  0.0511,  0.0149,  ...,  0.0131, -0.0084, -0.0367],
        [-0.0119, -0.0472, -0.0218,  ..., -0.0158,  0.0139, -0.0140]],
       dtype=torch.float16), 'model.layers.18.mlp.gate_proj.weight': tensor([[ 0.0147, -0.0038,  0.0166,  ..., -0.0080,  0.0101, -0.0105],
        [-0.0428,  0.0071, -0.0162,  ..., -0.0086, -0.0150, -0.0096],
        [-0.0190,  0.0073,  0.0444,  ..., -0.0250,  0.0031,  0.0038],
        ...,
        [-0.0438, -0.0219, -0.0285,  ..., -0.0296, -0.0218, -0.0233],
        [ 0.0015,  0.0197,  0.0297,  ..., -0.0164, -0.0011,  0.0164],
        [ 0.0040, -0.0041,  0.0039,  ...,  0.0107, -0.0188, -0.0050]],
       dtype=torch.float16), 'model.layers.18.mlp.up_proj.weight': tensor([[ 0.0165,  0.0081,  0.0298,  ..., -0.0004,  0.0271, -0.0095],
        [-0.0201,  0.0243, -0.0282,  ..., -0.0057, -0.0087, -0.0003],
        [-0.0311, -0.0098,  0.0076,  ...,  0.0074,  0.0209,  0.0261],
        ...,
        [-0.0012,  0.0045,  0.0046,  ...,  0.0238, -0.0075,  0.0040],
        [-0.0094, -0.0048, -0.0210,  ...,  0.0134,  0.0343,  0.0362],
        [ 0.0087,  0.0248,  0.0111,  ..., -0.0163,  0.0135,  0.0152]],
       dtype=torch.float16), 'model.layers.18.mlp.down_proj.weight': tensor([[ 0.0152,  0.0034, -0.0323,  ...,  0.0311,  0.0165,  0.0073],
        [ 0.0117, -0.0078,  0.0196,  ...,  0.0007, -0.0016, -0.0021],
        [ 0.0172, -0.0250, -0.0335,  ...,  0.0177,  0.0036,  0.0148],
        ...,
        [-0.0127,  0.0210,  0.0102,  ...,  0.0230, -0.0081, -0.0087],
        [-0.0160,  0.0116,  0.0182,  ...,  0.0120,  0.0356,  0.0087],
        [-0.0091,  0.0257,  0.0244,  ..., -0.0073,  0.0167,  0.0157]],
       dtype=torch.float16), 'model.layers.18.input_layernorm.weight': tensor([0.4570, 0.4551, 0.4316,  ..., 0.4375, 0.4512, 0.4355],
       dtype=torch.float16), 'model.layers.18.post_attention_layernorm.weight': tensor([0.3477, 0.3340, 0.3320,  ..., 0.3477, 0.3496, 0.3457],
       dtype=torch.float16), 'model.layers.19.self_attn.q_proj.weight': tensor([[ 5.5275e-03,  7.6294e-03, -9.7961e-03,  ..., -1.0323e-02,
         -3.1209e-04,  8.8806e-03],
        [ 2.6894e-03, -2.5539e-03,  3.1719e-03,  ..., -4.7493e-03,
          2.9022e-02,  1.7868e-02],
        [ 5.2185e-03,  2.1896e-02,  4.5896e-05,  ...,  8.6498e-04,
          1.5182e-02,  3.0727e-03],
        ...,
        [-1.4160e-02, -1.4923e-02,  1.0290e-03,  ..., -4.4189e-02,
         -3.1805e-04,  2.4979e-02],
        [ 4.7226e-03,  4.8279e-02,  2.3041e-02,  ...,  5.4077e-02,
          2.9755e-02, -2.9358e-02],
        [-1.5991e-02,  4.9011e-02,  5.8014e-02,  ..., -6.6414e-03,
         -4.1382e-02, -1.4290e-02]], dtype=torch.float16), 'model.layers.19.self_attn.k_proj.weight': tensor([[ 0.0216,  0.0117,  0.0022,  ..., -0.0116, -0.0213, -0.0106],
        [-0.0142,  0.0180, -0.0159,  ...,  0.0100,  0.0034,  0.0251],
        [-0.0157,  0.0043, -0.0122,  ...,  0.0044,  0.0137,  0.0252],
        ...,
        [ 0.0005,  0.0502, -0.0095,  ..., -0.0208,  0.0299, -0.0225],
        [-0.0653, -0.0269, -0.0101,  ...,  0.0084,  0.0184, -0.0099],
        [-0.0202,  0.0115, -0.0150,  ..., -0.0266,  0.0129,  0.0399]],
       dtype=torch.float16), 'model.layers.19.self_attn.v_proj.weight': tensor([[-0.0011, -0.0055, -0.0055,  ..., -0.0020,  0.0005,  0.0070],
        [-0.0020,  0.0188, -0.0031,  ...,  0.0351, -0.0211,  0.0162],
        [-0.0448, -0.0359, -0.0080,  ..., -0.0085, -0.0002,  0.0056],
        ...,
        [ 0.0013, -0.0373, -0.0014,  ...,  0.0010, -0.0002, -0.0166],
        [ 0.0145, -0.0095, -0.0219,  ..., -0.0066, -0.0073, -0.0058],
        [-0.0033,  0.0275,  0.0008,  ..., -0.0254, -0.0120,  0.0062]],
       dtype=torch.float16), 'model.layers.19.self_attn.o_proj.weight': tensor([[ 0.0296, -0.0517,  0.0258,  ...,  0.0012,  0.0066, -0.0257],
        [ 0.0307, -0.0164, -0.0036,  ..., -0.0145, -0.0012, -0.0030],
        [-0.0033, -0.0176, -0.0195,  ...,  0.0010,  0.0150,  0.0012],
        ...,
        [ 0.0123, -0.0018,  0.0002,  ...,  0.0056, -0.0152,  0.0122],
        [ 0.0089, -0.0057, -0.0186,  ..., -0.0244, -0.0204,  0.0051],
        [ 0.0127,  0.0175,  0.0140,  ..., -0.0233, -0.0083,  0.0153]],
       dtype=torch.float16), 'model.layers.19.mlp.gate_proj.weight': tensor([[-0.0082,  0.0010,  0.0049,  ..., -0.0039,  0.0037, -0.0065],
        [ 0.0145,  0.0183,  0.0011,  ..., -0.0036,  0.0125, -0.0351],
        [-0.0169, -0.0121, -0.0127,  ..., -0.0433,  0.0002,  0.0285],
        ...,
        [-0.0016,  0.0101, -0.0004,  ..., -0.0291, -0.0092, -0.0010],
        [-0.0475, -0.0082,  0.0029,  ..., -0.0074, -0.0217,  0.0107],
        [-0.0205, -0.0197,  0.0153,  ...,  0.0069,  0.0052, -0.0020]],
       dtype=torch.float16), 'model.layers.19.mlp.up_proj.weight': tensor([[ 0.0020, -0.0107,  0.0096,  ...,  0.0065,  0.0100,  0.0032],
        [-0.0134, -0.0063, -0.0158,  ...,  0.0269, -0.0230, -0.0070],
        [ 0.0094,  0.0039,  0.0094,  ..., -0.0246, -0.0129,  0.0532],
        ...,
        [ 0.0142,  0.0140,  0.0074,  ...,  0.0136, -0.0170,  0.0311],
        [ 0.0013,  0.0262,  0.0249,  ..., -0.0094,  0.0361, -0.0004],
        [-0.0002, -0.0181, -0.0124,  ..., -0.0027,  0.0045,  0.0140]],
       dtype=torch.float16), 'model.layers.19.mlp.down_proj.weight': tensor([[-0.0026, -0.0278,  0.0015,  ...,  0.0057, -0.0235,  0.0278],
        [-0.0050, -0.0306, -0.0208,  ...,  0.0139,  0.0175, -0.0169],
        [-0.0209, -0.0261,  0.0290,  ...,  0.0159, -0.0008,  0.0071],
        ...,
        [-0.0104, -0.0050,  0.0274,  ...,  0.0129,  0.0162,  0.0012],
        [ 0.0065, -0.0093, -0.0501,  ...,  0.0219, -0.0086, -0.0152],
        [ 0.0041, -0.0093, -0.0342,  ...,  0.0006,  0.0090,  0.0042]],
       dtype=torch.float16), 'model.layers.19.input_layernorm.weight': tensor([0.4570, 0.4629, 0.4395,  ..., 0.4316, 0.4395, 0.4414],
       dtype=torch.float16), 'model.layers.19.post_attention_layernorm.weight': tensor([0.3613, 0.3477, 0.3457,  ..., 0.3574, 0.3555, 0.3594],
       dtype=torch.float16), 'model.layers.20.self_attn.q_proj.weight': tensor([[-3.3512e-03,  2.7599e-03,  2.2141e-02,  ...,  3.8643e-03,
          3.5381e-03, -2.3499e-02],
        [ 1.8127e-02, -2.1729e-02, -4.8876e-06,  ..., -6.9809e-03,
         -1.2131e-02,  1.7120e-02],
        [ 7.9117e-03, -6.8665e-03, -1.8326e-02,  ...,  1.7166e-02,
          7.0038e-03,  8.3780e-04],
        ...,
        [-3.1219e-02, -5.3162e-02,  1.0094e-02,  ..., -1.0918e-02,
          3.9520e-02,  1.1047e-02],
        [-8.0872e-02, -1.9455e-02,  1.1688e-02,  ...,  8.7585e-03,
          2.6505e-02,  8.3389e-03],
        [ 2.6978e-02,  2.4643e-03, -5.2071e-03,  ..., -1.9089e-02,
         -5.4512e-03, -1.3123e-03]], dtype=torch.float16), 'model.layers.20.self_attn.k_proj.weight': tensor([[-5.6038e-03,  7.3128e-03,  3.8834e-03,  ..., -1.6464e-02,
         -3.4750e-05,  3.6964e-03],
        [-3.7003e-04,  8.7585e-03,  4.4060e-03,  ..., -2.0161e-03,
          4.6120e-03,  1.1047e-02],
        [ 1.4694e-02,  2.8610e-03, -1.1185e-02,  ..., -1.5091e-02,
          1.4725e-03,  1.9836e-02],
        ...,
        [ 2.0256e-03,  4.9706e-03, -1.7044e-02,  ..., -2.3407e-02,
          2.5925e-02,  3.5919e-02],
        [-2.4094e-02,  2.4918e-02,  2.4490e-03,  ...,  2.1759e-02,
          3.0762e-02,  5.1605e-02],
        [-1.5228e-02, -3.0060e-02, -1.5793e-02,  ...,  2.0111e-02,
         -2.3468e-02,  5.2704e-02]], dtype=torch.float16), 'model.layers.20.self_attn.v_proj.weight': tensor([[-7.1526e-03, -1.8005e-02,  1.3290e-02,  ..., -2.7752e-03,
          1.9043e-02,  1.1086e-02],
        [-1.5945e-02, -3.7201e-02,  5.2223e-03,  ..., -1.2299e-02,
          3.4332e-04,  9.0942e-03],
        [-3.0174e-03, -1.3779e-02,  3.5763e-03,  ..., -2.5085e-02,
          9.9301e-05,  6.9046e-04],
        ...,
        [ 9.6893e-03, -1.2962e-02, -2.5940e-03,  ...,  2.4796e-02,
         -7.9269e-03,  9.0103e-03],
        [ 1.8799e-02,  1.4400e-03, -9.5062e-03,  ...,  8.0681e-04,
          1.1032e-02, -1.3542e-02],
        [ 2.3708e-03, -3.8452e-03,  2.4155e-02,  ..., -5.8403e-03,
         -1.1604e-02, -4.0283e-02]], dtype=torch.float16), 'model.layers.20.self_attn.o_proj.weight': tensor([[-0.0066,  0.0037,  0.0200,  ..., -0.0024,  0.0155, -0.0167],
        [ 0.0103, -0.0098, -0.0066,  ..., -0.0050, -0.0065,  0.0191],
        [ 0.0099, -0.0022, -0.0135,  ..., -0.0240,  0.0092,  0.0103],
        ...,
        [-0.0074, -0.0039,  0.0135,  ...,  0.0168, -0.0150,  0.0116],
        [-0.0101,  0.0031, -0.0113,  ...,  0.0121, -0.0273,  0.0036],
        [ 0.0107, -0.0183, -0.0039,  ...,  0.0065, -0.0230,  0.0195]],
       dtype=torch.float16), 'model.layers.20.mlp.gate_proj.weight': tensor([[ 0.0012, -0.0088, -0.0118,  ...,  0.0177, -0.0055,  0.0139],
        [-0.0275,  0.0091, -0.0060,  ..., -0.0098, -0.0143,  0.0149],
        [-0.0167, -0.0078,  0.0665,  ..., -0.0155,  0.0111, -0.0063],
        ...,
        [-0.0048, -0.0114,  0.0241,  ..., -0.0145,  0.0109, -0.0033],
        [ 0.0093,  0.0071,  0.0046,  ...,  0.0154,  0.0030,  0.0123],
        [-0.0032, -0.0308, -0.0070,  ...,  0.0059, -0.0142, -0.0134]],
       dtype=torch.float16), 'model.layers.20.mlp.up_proj.weight': tensor([[-0.0601, -0.0002, -0.0019,  ...,  0.0153, -0.0108, -0.0119],
        [-0.0098,  0.0006, -0.0098,  ..., -0.0502, -0.0143,  0.0372],
        [ 0.0060,  0.0302,  0.0182,  ...,  0.0070, -0.0175,  0.0047],
        ...,
        [-0.0139,  0.0211, -0.0016,  ..., -0.0180, -0.0043, -0.0030],
        [ 0.0155, -0.0318, -0.0148,  ...,  0.0031, -0.0208, -0.0377],
        [ 0.0145, -0.0241,  0.0311,  ..., -0.0039, -0.0222,  0.0036]],
       dtype=torch.float16), 'model.layers.20.mlp.down_proj.weight': tensor([[-0.0016,  0.0202, -0.0034,  ...,  0.0053, -0.0169, -0.0248],
        [ 0.0021,  0.0127, -0.0073,  ...,  0.0044, -0.0178,  0.0143],
        [-0.0127,  0.0180, -0.0242,  ..., -0.0042,  0.0238, -0.0053],
        ...,
        [-0.0375,  0.0276,  0.0056,  ...,  0.0026, -0.0002, -0.0114],
        [-0.0156,  0.0062, -0.0158,  ...,  0.0057,  0.0178, -0.0025],
        [ 0.0120, -0.0131,  0.0019,  ..., -0.0029, -0.0063, -0.0147]],
       dtype=torch.float16), 'model.layers.20.input_layernorm.weight': tensor([0.4590, 0.4688, 0.4395,  ..., 0.4414, 0.4375, 0.4590],
       dtype=torch.float16), 'model.layers.20.post_attention_layernorm.weight': tensor([0.3711, 0.3633, 0.3535,  ..., 0.3672, 0.3672, 0.3691],
       dtype=torch.float16), 'model.layers.21.self_attn.q_proj.weight': tensor([[-0.0138, -0.0057,  0.0144,  ..., -0.0153, -0.0030,  0.0070],
        [ 0.0252,  0.0060, -0.0012,  ...,  0.0031,  0.0002,  0.0141],
        [-0.0117, -0.0101,  0.0026,  ...,  0.0280,  0.0023,  0.0066],
        ...,
        [-0.0025, -0.0157,  0.0354,  ..., -0.0107, -0.0593,  0.0191],
        [-0.0115,  0.0166,  0.0210,  ...,  0.0295,  0.0328,  0.0014],
        [-0.0795, -0.0016, -0.0130,  ..., -0.0056,  0.0264, -0.0380]],
       dtype=torch.float16), 'model.layers.21.self_attn.k_proj.weight': tensor([[-1.3864e-04,  4.9858e-03, -3.4065e-03,  ...,  7.4348e-03,
          3.9625e-04,  1.0353e-02],
        [-8.3685e-05,  7.3128e-03,  1.9882e-02,  ...,  6.2561e-03,
          9.4681e-03,  8.8806e-03],
        [ 1.8494e-02,  2.9202e-03,  2.8900e-02,  ...,  1.5823e-02,
          1.2871e-02,  1.4816e-02],
        ...,
        [-1.8295e-02,  2.6428e-02,  1.5945e-03,  ...,  2.5818e-02,
         -1.9394e-02,  4.6265e-02],
        [ 2.0866e-03, -3.1281e-03, -1.4458e-02,  ..., -2.2232e-02,
          3.1250e-02,  1.6203e-03],
        [-1.8906e-02, -8.1329e-03, -3.1433e-02,  ...,  7.8888e-03,
         -7.5493e-03,  5.9235e-02]], dtype=torch.float16), 'model.layers.21.self_attn.v_proj.weight': tensor([[ 0.0032,  0.0054, -0.0003,  ...,  0.0005,  0.0223, -0.0286],
        [-0.0232,  0.0240, -0.0079,  ...,  0.0211, -0.0195,  0.0266],
        [ 0.0280, -0.0030,  0.0003,  ..., -0.0232,  0.0258, -0.0058],
        ...,
        [-0.0056, -0.0269,  0.0320,  ..., -0.0065,  0.0038, -0.0102],
        [-0.0154, -0.0090,  0.0156,  ...,  0.0048, -0.0052,  0.0086],
        [-0.0069,  0.0157, -0.0162,  ...,  0.0070, -0.0155, -0.0029]],
       dtype=torch.float16), 'model.layers.21.self_attn.o_proj.weight': tensor([[-0.0118, -0.0017,  0.0116,  ..., -0.0132,  0.0231,  0.0102],
        [-0.0058,  0.0267, -0.0098,  ..., -0.0189,  0.0061, -0.0112],
        [-0.0298, -0.0130,  0.0119,  ...,  0.0249,  0.0273,  0.0079],
        ...,
        [ 0.0198, -0.0042, -0.0136,  ...,  0.0248, -0.0006,  0.0144],
        [ 0.0152, -0.0136,  0.0135,  ..., -0.0006,  0.0018, -0.0185],
        [-0.0264,  0.0155, -0.0134,  ...,  0.0298, -0.0163,  0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.gate_proj.weight': tensor([[-0.0058, -0.0234,  0.0144,  ..., -0.0285,  0.0456,  0.0089],
        [ 0.0061,  0.0061,  0.0039,  ..., -0.0275,  0.0574,  0.0085],
        [ 0.0084,  0.0064,  0.0049,  ..., -0.0498,  0.0041, -0.0245],
        ...,
        [ 0.0102, -0.0292, -0.0215,  ...,  0.0331, -0.0270,  0.0024],
        [-0.0010,  0.0293,  0.0065,  ...,  0.0160, -0.0249,  0.0030],
        [ 0.0093, -0.0124, -0.0017,  ..., -0.0182,  0.0064, -0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.up_proj.weight': tensor([[ 0.0276, -0.0258, -0.0142,  ...,  0.0225,  0.0422, -0.0112],
        [-0.0261, -0.0107,  0.0040,  ...,  0.0379,  0.0453, -0.0010],
        [ 0.0133, -0.0011, -0.0018,  ...,  0.0067, -0.0079, -0.0061],
        ...,
        [-0.0461, -0.0002,  0.0137,  ...,  0.0162, -0.0095, -0.0118],
        [-0.0100, -0.0107,  0.0042,  ..., -0.0188, -0.0023,  0.0027],
        [-0.0051, -0.0337, -0.0248,  ..., -0.0035, -0.0055, -0.0260]],
       dtype=torch.float16), 'model.layers.21.mlp.down_proj.weight': tensor([[ 0.0117,  0.0132,  0.0028,  ...,  0.0198,  0.0068,  0.0062],
        [ 0.0095, -0.0029, -0.0151,  ...,  0.0037, -0.0319, -0.0163],
        [-0.0061,  0.0059,  0.0132,  ..., -0.0084,  0.0412,  0.0299],
        ...,
        [-0.0106,  0.0375,  0.0182,  ..., -0.0093, -0.0024,  0.0179],
        [ 0.0125,  0.0007, -0.0043,  ..., -0.0493, -0.0052,  0.0049],
        [ 0.0089,  0.0014,  0.0242,  ..., -0.0152,  0.0267, -0.0278]],
       dtype=torch.float16), 'model.layers.21.input_layernorm.weight': tensor([0.4805, 0.4883, 0.4688,  ..., 0.4609, 0.4805, 0.4824],
       dtype=torch.float16), 'model.layers.21.post_attention_layernorm.weight': tensor([0.3770, 0.3730, 0.3652,  ..., 0.3848, 0.3789, 0.3828],
       dtype=torch.float16), 'model.layers.22.self_attn.q_proj.weight': tensor([[-0.0249, -0.0096, -0.0046,  ...,  0.0535, -0.0391,  0.0201],
        [-0.0361, -0.0200, -0.0063,  ..., -0.0361,  0.0211, -0.0515],
        [-0.0322,  0.0232, -0.0146,  ...,  0.0286,  0.0173, -0.0100],
        ...,
        [ 0.0094,  0.0199,  0.0122,  ...,  0.0116,  0.0576, -0.0013],
        [-0.0323,  0.0064, -0.0220,  ...,  0.0465,  0.0088, -0.0131],
        [ 0.0380, -0.0125,  0.0065,  ..., -0.0505,  0.0111,  0.0195]],
       dtype=torch.float16), 'model.layers.22.self_attn.k_proj.weight': tensor([[-0.0130, -0.0065,  0.0037,  ...,  0.0139, -0.0164, -0.0157],
        [ 0.0106, -0.0099,  0.0312,  ..., -0.0320,  0.0375, -0.0140],
        [-0.0207,  0.0286, -0.0425,  ...,  0.0614,  0.0035, -0.0076],
        ...,
        [ 0.0210,  0.0074, -0.0286,  ..., -0.0204, -0.0135,  0.0172],
        [-0.0150, -0.0424,  0.0025,  ..., -0.0002, -0.0132, -0.0070],
        [ 0.0240, -0.0025,  0.0283,  ...,  0.0377, -0.0425,  0.0131]],
       dtype=torch.float16), 'model.layers.22.self_attn.v_proj.weight': tensor([[-0.0201,  0.0126, -0.0017,  ..., -0.0395, -0.0264,  0.0152],
        [-0.0346, -0.0108,  0.0072,  ..., -0.0269, -0.0413, -0.0159],
        [ 0.0243, -0.0267, -0.0040,  ...,  0.0528, -0.0026, -0.0139],
        ...,
        [-0.0104, -0.0462, -0.0226,  ...,  0.0124, -0.0114,  0.0218],
        [-0.0375, -0.0086,  0.0181,  ..., -0.0198,  0.0020, -0.0155],
        [ 0.0007,  0.0152, -0.0433,  ...,  0.0020, -0.0053,  0.0264]],
       dtype=torch.float16), 'model.layers.22.self_attn.o_proj.weight': tensor([[ 0.0263,  0.0156, -0.0218,  ..., -0.0026, -0.0353,  0.0123],
        [ 0.0242,  0.0126,  0.0108,  ...,  0.0045, -0.0100, -0.0247],
        [ 0.0046,  0.0026, -0.0081,  ..., -0.0232,  0.0110,  0.0107],
        ...,
        [-0.0008, -0.0238, -0.0129,  ..., -0.0138, -0.0166,  0.0042],
        [ 0.0259, -0.0104, -0.0196,  ..., -0.0260, -0.0027,  0.0137],
        [ 0.0039, -0.0258,  0.0213,  ...,  0.0115,  0.0122,  0.0111]],
       dtype=torch.float16), 'model.layers.22.mlp.gate_proj.weight': tensor([[-0.0284, -0.0156,  0.0184,  ...,  0.0108,  0.0197, -0.0452],
        [ 0.0226, -0.0165,  0.0014,  ...,  0.0043,  0.0029,  0.0221],
        [ 0.0005, -0.0069,  0.0054,  ...,  0.0142,  0.0002, -0.0003],
        ...,
        [-0.0043, -0.0079,  0.0014,  ..., -0.0152,  0.0073,  0.0022],
        [ 0.0095,  0.0165, -0.0293,  ..., -0.0035,  0.0127, -0.0289],
        [-0.0101,  0.0012,  0.0053,  ..., -0.0148,  0.0278,  0.0245]],
       dtype=torch.float16), 'model.layers.22.mlp.up_proj.weight': tensor([[ 0.0293,  0.0162, -0.0013,  ...,  0.0170,  0.0276,  0.0071],
        [ 0.0198,  0.0076,  0.0164,  ..., -0.0117, -0.0078,  0.0030],
        [ 0.0086, -0.0282, -0.0375,  ...,  0.0255,  0.0104,  0.0061],
        ...,
        [-0.0032, -0.0006, -0.0185,  ..., -0.0040,  0.0057,  0.0067],
        [ 0.0126, -0.0111, -0.0286,  ..., -0.0226,  0.0108, -0.0270],
        [-0.0014,  0.0023, -0.0036,  ..., -0.0440, -0.0598,  0.0154]],
       dtype=torch.float16), 'model.layers.22.mlp.down_proj.weight': tensor([[ 1.3527e-02, -5.1918e-03,  1.2299e-02,  ..., -1.8967e-02,
         -4.1428e-03, -3.6041e-02],
        [ 5.5885e-03,  2.6581e-02, -4.9362e-03,  ..., -1.1017e-02,
          1.4084e-02, -2.6627e-02],
        [-9.6512e-03,  3.9363e-04,  4.1962e-03,  ...,  1.2886e-02,
          4.5013e-03,  1.7517e-02],
        ...,
        [ 1.8250e-02, -8.5297e-03, -4.5288e-02,  ..., -2.8934e-03,
         -1.2947e-02, -1.7014e-02],
        [-1.1414e-02, -4.8767e-02,  1.1642e-02,  ...,  1.9028e-02,
         -2.7069e-02,  3.1433e-02],
        [ 1.4130e-02,  3.7551e-06, -3.1067e-02,  ..., -3.3903e-04,
         -1.8875e-02,  2.1286e-03]], dtype=torch.float16), 'model.layers.22.input_layernorm.weight': tensor([0.4883, 0.4922, 0.4805,  ..., 0.4688, 0.5000, 0.4902],
       dtype=torch.float16), 'model.layers.22.post_attention_layernorm.weight': tensor([0.3867, 0.3848, 0.3848,  ..., 0.3965, 0.3945, 0.3965],
       dtype=torch.float16), 'model.layers.23.self_attn.q_proj.weight': tensor([[-0.0039, -0.0179,  0.0076,  ..., -0.0155, -0.0002,  0.0023],
        [ 0.0042,  0.0015,  0.0140,  ..., -0.0166, -0.0002,  0.0083],
        [-0.0038,  0.0028,  0.0219,  ...,  0.0002, -0.0167,  0.0066],
        ...,
        [-0.0211,  0.0670,  0.0119,  ..., -0.0314, -0.0684, -0.0263],
        [-0.0411, -0.0311,  0.0199,  ..., -0.0232,  0.0020,  0.0060],
        [ 0.0047, -0.0559, -0.0093,  ...,  0.0072,  0.0403, -0.0026]],
       dtype=torch.float16), 'model.layers.23.self_attn.k_proj.weight': tensor([[-0.0030,  0.0121,  0.0090,  ...,  0.0010, -0.0083,  0.0059],
        [-0.0224,  0.0057, -0.0117,  ...,  0.0093,  0.0254,  0.0036],
        [ 0.0182,  0.0078, -0.0185,  ...,  0.0181,  0.0016, -0.0107],
        ...,
        [ 0.0067,  0.0374,  0.0580,  ..., -0.0332, -0.0120, -0.0131],
        [ 0.0034, -0.0352, -0.0113,  ..., -0.0232, -0.0226,  0.0194],
        [-0.0173, -0.0081, -0.0259,  ...,  0.0043,  0.0060, -0.0084]],
       dtype=torch.float16), 'model.layers.23.self_attn.v_proj.weight': tensor([[-0.0028,  0.0343, -0.0120,  ..., -0.0097, -0.0016, -0.0112],
        [-0.0093, -0.0038, -0.0190,  ..., -0.0033, -0.0097,  0.0105],
        [ 0.0111, -0.0211, -0.0208,  ...,  0.0130, -0.0508, -0.0305],
        ...,
        [ 0.0070,  0.0084,  0.0091,  ..., -0.0020,  0.0338,  0.0089],
        [ 0.0261,  0.0316, -0.0011,  ...,  0.0070,  0.0022, -0.0127],
        [-0.0201, -0.0131, -0.0540,  ...,  0.0057,  0.0076, -0.0381]],
       dtype=torch.float16), 'model.layers.23.self_attn.o_proj.weight': tensor([[-0.0019,  0.0019, -0.0202,  ..., -0.0179,  0.0104, -0.0070],
        [-0.0127, -0.0213, -0.0022,  ..., -0.0004,  0.0100, -0.0021],
        [ 0.0130,  0.0094,  0.0306,  ..., -0.0228, -0.0026, -0.0276],
        ...,
        [ 0.0290, -0.0114,  0.0348,  ..., -0.0162,  0.0113, -0.0013],
        [-0.0044,  0.0202, -0.0200,  ...,  0.0056, -0.0164,  0.0007],
        [ 0.0013, -0.0023, -0.0177,  ..., -0.0060,  0.0059, -0.0296]],
       dtype=torch.float16), 'model.layers.23.mlp.gate_proj.weight': tensor([[-1.1848e-02,  3.4424e-02, -1.0048e-02,  ..., -7.0152e-03,
          3.2776e-02,  9.2316e-03],
        [-1.4702e-02,  4.7729e-02, -1.7593e-02,  ...,  7.1678e-03,
         -1.8631e-02,  2.5070e-02],
        [-3.2349e-02,  1.4786e-02,  2.6913e-03,  ...,  1.5274e-02,
         -6.7444e-02,  1.2131e-02],
        ...,
        [-3.1548e-03,  1.9089e-02,  3.1509e-03,  ..., -8.1863e-03,
          7.2556e-03, -2.4643e-03],
        [-2.0828e-02,  3.8971e-02,  2.9430e-03,  ...,  3.3021e-05,
          7.8201e-03, -2.8381e-02],
        [ 8.8692e-04,  8.5144e-03,  1.6830e-02,  ..., -7.6561e-03,
          1.5450e-02, -1.6495e-02]], dtype=torch.float16), 'model.layers.23.mlp.up_proj.weight': tensor([[ 0.0283,  0.0066,  0.0351,  ...,  0.0134, -0.0322, -0.0074],
        [-0.0003,  0.0065, -0.0196,  ..., -0.0043, -0.0111,  0.0061],
        [-0.0177,  0.0038, -0.0218,  ...,  0.0182,  0.0106, -0.0052],
        ...,
        [-0.0084, -0.0166,  0.0116,  ...,  0.0093,  0.0408,  0.0053],
        [ 0.0036,  0.0078, -0.0382,  ...,  0.0106,  0.0070,  0.0220],
        [ 0.0014,  0.0079, -0.0071,  ...,  0.0070, -0.0126,  0.0127]],
       dtype=torch.float16), 'model.layers.23.mlp.down_proj.weight': tensor([[-0.0008,  0.0069, -0.0182,  ..., -0.0434, -0.0227,  0.0330],
        [-0.0012,  0.0231, -0.0064,  ...,  0.0257,  0.0306,  0.0021],
        [-0.0066, -0.0139, -0.0233,  ...,  0.0102,  0.0330, -0.0052],
        ...,
        [ 0.0001, -0.0050,  0.0135,  ...,  0.0180,  0.0037, -0.0187],
        [ 0.0296, -0.0114, -0.0007,  ..., -0.0026,  0.0101,  0.0058],
        [ 0.0031, -0.0307, -0.0152,  ..., -0.0104,  0.0204, -0.0025]],
       dtype=torch.float16), 'model.layers.23.input_layernorm.weight': tensor([0.5156, 0.5312, 0.5117,  ..., 0.5039, 0.5352, 0.5273],
       dtype=torch.float16), 'model.layers.23.post_attention_layernorm.weight': tensor([0.4043, 0.4023, 0.3965,  ..., 0.4043, 0.4121, 0.4062],
       dtype=torch.float16), 'model.layers.24.self_attn.q_proj.weight': tensor([[ 0.0204, -0.0176,  0.0145,  ...,  0.0364, -0.0300,  0.0106],
        [ 0.0215,  0.0088,  0.0012,  ..., -0.0026,  0.0186, -0.0139],
        [-0.0056, -0.0111, -0.0277,  ...,  0.0088, -0.0132,  0.0202],
        ...,
        [-0.0147,  0.0136, -0.0193,  ...,  0.0181, -0.0004, -0.0123],
        [-0.0288,  0.0078,  0.0070,  ...,  0.0100, -0.0323, -0.0062],
        [-0.0231, -0.0385, -0.0181,  ..., -0.0132,  0.0128,  0.0677]],
       dtype=torch.float16), 'model.layers.24.self_attn.k_proj.weight': tensor([[ 0.0235, -0.0035, -0.0125,  ...,  0.0110, -0.0008,  0.0021],
        [ 0.0118, -0.0169,  0.0035,  ..., -0.0216,  0.0245,  0.0066],
        [ 0.0097,  0.0045, -0.0445,  ...,  0.0204,  0.0171, -0.0175],
        ...,
        [ 0.0344,  0.0036,  0.0493,  ...,  0.0161,  0.0179, -0.0516],
        [-0.0119,  0.0177,  0.0127,  ...,  0.0320, -0.0181,  0.0027],
        [-0.0318, -0.0295, -0.0190,  ...,  0.0139, -0.0048,  0.0518]],
       dtype=torch.float16), 'model.layers.24.self_attn.v_proj.weight': tensor([[ 0.0212, -0.0251, -0.0028,  ..., -0.0041, -0.0040,  0.0113],
        [ 0.0288, -0.0173, -0.0054,  ..., -0.0646, -0.0470, -0.0240],
        [-0.0579, -0.0169, -0.0134,  ..., -0.0156, -0.0121, -0.0027],
        ...,
        [ 0.0011, -0.0192,  0.0171,  ...,  0.0272,  0.0067,  0.0217],
        [-0.0034, -0.0157, -0.0141,  ...,  0.0332, -0.0036,  0.0038],
        [ 0.0172,  0.0228,  0.0187,  ...,  0.0274, -0.0135, -0.0108]],
       dtype=torch.float16), 'model.layers.24.self_attn.o_proj.weight': tensor([[-0.0016,  0.0144,  0.0280,  ...,  0.0066, -0.0051, -0.0141],
        [-0.0118,  0.0308,  0.0156,  ...,  0.0195,  0.0282, -0.0186],
        [-0.0057, -0.0029,  0.0094,  ..., -0.0232,  0.0084, -0.0049],
        ...,
        [ 0.0045,  0.0179,  0.0119,  ..., -0.0027, -0.0031, -0.0005],
        [ 0.0508,  0.0096, -0.0061,  ...,  0.0075, -0.0257, -0.0106],
        [ 0.0026,  0.0155,  0.0109,  ...,  0.0046, -0.0261,  0.0131]],
       dtype=torch.float16), 'model.layers.24.mlp.gate_proj.weight': tensor([[-0.0267, -0.0104,  0.0093,  ..., -0.0031, -0.0058,  0.0011],
        [ 0.0075, -0.0302, -0.0231,  ...,  0.0075,  0.0110, -0.0131],
        [ 0.0014, -0.0466,  0.0257,  ...,  0.0015, -0.0532, -0.0207],
        ...,
        [ 0.0042, -0.0358, -0.0088,  ...,  0.0080,  0.0152, -0.0062],
        [ 0.0094,  0.0158,  0.0041,  ...,  0.0043,  0.0011,  0.0048],
        [-0.0410,  0.0326,  0.0009,  ...,  0.0294, -0.0074, -0.0473]],
       dtype=torch.float16), 'model.layers.24.mlp.up_proj.weight': tensor([[ 0.0016, -0.0057,  0.0201,  ...,  0.0262,  0.0025,  0.0263],
        [-0.0026,  0.0136, -0.0327,  ..., -0.0081, -0.0044, -0.0171],
        [ 0.0114, -0.0520,  0.0097,  ...,  0.0402,  0.0179, -0.0341],
        ...,
        [ 0.0115, -0.0207, -0.0147,  ..., -0.0067,  0.0112,  0.0111],
        [ 0.0412, -0.0033,  0.0132,  ...,  0.0025,  0.0054, -0.0100],
        [-0.0056, -0.0197,  0.0203,  ...,  0.0303,  0.0333,  0.0164]],
       dtype=torch.float16), 'model.layers.24.mlp.down_proj.weight': tensor([[-0.0052, -0.0114, -0.0357,  ...,  0.0015,  0.0022, -0.0194],
        [ 0.0278, -0.0030,  0.0175,  ..., -0.0015,  0.0048, -0.0508],
        [ 0.0195,  0.0135, -0.0284,  ...,  0.0095,  0.0215,  0.0078],
        ...,
        [-0.0092,  0.0149, -0.0204,  ..., -0.0330, -0.0109, -0.0146],
        [ 0.0112,  0.0248,  0.0120,  ...,  0.0257, -0.0255,  0.0133],
        [-0.0171, -0.0086,  0.0033,  ...,  0.0172, -0.0154, -0.0324]],
       dtype=torch.float16), 'model.layers.24.input_layernorm.weight': tensor([0.4980, 0.5273, 0.5195,  ..., 0.4863, 0.5234, 0.5156],
       dtype=torch.float16), 'model.layers.24.post_attention_layernorm.weight': tensor([0.4219, 0.4180, 0.4180,  ..., 0.4199, 0.4258, 0.4219],
       dtype=torch.float16), 'model.layers.25.self_attn.q_proj.weight': tensor([[ 1.7204e-03, -1.9974e-02, -2.5269e-02,  ...,  1.2192e-02,
         -9.5139e-03,  4.5357e-03],
        [-1.3947e-02,  3.5877e-03,  2.3804e-02,  ..., -1.4412e-02,
         -3.4485e-03,  2.4557e-05],
        [ 9.1629e-03,  8.6136e-03,  3.9368e-03,  ..., -1.1436e-02,
         -2.0157e-02, -1.5068e-02],
        ...,
        [ 5.5756e-02,  4.5746e-02,  2.2964e-03,  ...,  4.9858e-03,
          1.5762e-02, -2.6688e-02],
        [-6.3721e-02, -5.0293e-02, -1.2497e-02,  ..., -1.0338e-02,
         -2.1088e-02,  4.0932e-03],
        [ 3.9978e-02, -4.3365e-02, -2.2217e-02,  ...,  3.9279e-05,
          1.0757e-02, -2.6917e-02]], dtype=torch.float16), 'model.layers.25.self_attn.k_proj.weight': tensor([[-5.6648e-03, -1.3237e-02, -1.2611e-02,  ...,  1.5726e-03,
          1.6232e-03,  1.4572e-03],
        [-1.4183e-02, -1.4297e-02,  2.7120e-05,  ..., -3.4618e-03,
         -2.1515e-02,  7.6561e-03],
        [-8.5354e-04,  1.9426e-03,  4.9133e-03,  ...,  6.0310e-03,
         -6.0654e-03,  7.2212e-03],
        ...,
        [ 1.3847e-02,  4.8248e-02, -9.6283e-03,  ..., -5.4504e-02,
         -5.6427e-02,  3.7598e-02],
        [ 3.4454e-02, -3.4393e-02,  4.3602e-03,  ..., -8.3771e-03,
          2.8229e-03,  1.0277e-02],
        [-7.9346e-03, -2.7908e-02,  3.2768e-03,  ...,  3.6316e-02,
          8.8501e-03, -2.9388e-02]], dtype=torch.float16), 'model.layers.25.self_attn.v_proj.weight': tensor([[ 0.0173,  0.0201,  0.0084,  ...,  0.0248, -0.0133, -0.0128],
        [-0.0143, -0.0107,  0.0099,  ...,  0.0090, -0.0273, -0.0127],
        [-0.0150,  0.0164, -0.0202,  ..., -0.0099,  0.0054, -0.0090],
        ...,
        [-0.0186, -0.0324, -0.0026,  ...,  0.0150,  0.0097,  0.0189],
        [-0.0152,  0.0089,  0.0258,  ..., -0.0068,  0.0044, -0.0216],
        [-0.0386, -0.0105, -0.0145,  ...,  0.0065,  0.0192,  0.0297]],
       dtype=torch.float16), 'model.layers.25.self_attn.o_proj.weight': tensor([[ 1.9470e-02,  1.0475e-02,  1.3229e-02,  ...,  1.4595e-02,
          2.8362e-03,  3.7861e-03],
        [-2.6352e-02, -9.8953e-03, -1.6998e-02,  ...,  2.6093e-02,
         -7.1945e-03, -1.3523e-03],
        [-8.1863e-03, -1.5879e-03,  2.5925e-02,  ..., -1.9821e-02,
         -1.3336e-02, -1.3371e-03],
        ...,
        [-1.3893e-02,  2.3819e-02, -2.7676e-03,  ...,  1.0544e-02,
          1.3359e-02,  2.7084e-02],
        [-4.1842e-05, -2.7664e-02, -3.7750e-02,  ..., -2.3926e-02,
         -1.6037e-02,  2.2125e-03],
        [-2.4704e-02, -8.4839e-03, -1.3412e-02,  ..., -3.7964e-02,
         -2.0554e-02, -1.3344e-02]], dtype=torch.float16), 'model.layers.25.mlp.gate_proj.weight': tensor([[ 0.0037, -0.0402,  0.0397,  ..., -0.0020, -0.0228,  0.0070],
        [-0.0239, -0.0074, -0.0153,  ...,  0.0345,  0.0486,  0.0262],
        [-0.0017,  0.0171, -0.0012,  ...,  0.0176,  0.0161,  0.0310],
        ...,
        [-0.0347,  0.0086,  0.0019,  ..., -0.0027, -0.0130,  0.0004],
        [ 0.0218,  0.0088,  0.0610,  ...,  0.0170,  0.0224,  0.0062],
        [-0.0047, -0.0022, -0.0174,  ...,  0.0450,  0.0030, -0.0100]],
       dtype=torch.float16), 'model.layers.25.mlp.up_proj.weight': tensor([[-0.0265, -0.0114,  0.0169,  ...,  0.0016,  0.0052, -0.0100],
        [-0.0138, -0.0033,  0.0076,  ..., -0.0056,  0.0163,  0.0114],
        [ 0.0298,  0.0056,  0.0224,  ..., -0.0136, -0.0282, -0.0026],
        ...,
        [ 0.0102,  0.0049,  0.0475,  ...,  0.0056, -0.0394, -0.0210],
        [-0.0387, -0.0015, -0.0307,  ..., -0.0457, -0.0228, -0.0002],
        [-0.0147, -0.0097,  0.0229,  ...,  0.0258, -0.0055,  0.0242]],
       dtype=torch.float16), 'model.layers.25.mlp.down_proj.weight': tensor([[ 0.0289, -0.0159,  0.0110,  ...,  0.0204, -0.0067,  0.0310],
        [-0.0150, -0.0020,  0.0045,  ...,  0.0100, -0.0012,  0.0230],
        [ 0.0123,  0.0103, -0.0082,  ..., -0.0229,  0.0118, -0.0181],
        ...,
        [ 0.0188, -0.0142, -0.0232,  ..., -0.0466, -0.0010,  0.0237],
        [ 0.0065, -0.0114,  0.0031,  ...,  0.0045,  0.0039,  0.0058],
        [-0.0111, -0.0243,  0.0161,  ..., -0.0298, -0.0061, -0.0051]],
       dtype=torch.float16), 'model.layers.25.input_layernorm.weight': tensor([0.5547, 0.5703, 0.5547,  ..., 0.5547, 0.5742, 0.5625],
       dtype=torch.float16), 'model.layers.25.post_attention_layernorm.weight': tensor([0.4316, 0.4316, 0.4297,  ..., 0.4355, 0.4336, 0.4395],
       dtype=torch.float16), 'model.layers.26.self_attn.q_proj.weight': tensor([[ 0.0299, -0.0067, -0.0090,  ..., -0.0101,  0.0408,  0.0010],
        [-0.0050, -0.0182,  0.0142,  ...,  0.0062, -0.0230,  0.0177],
        [-0.0064,  0.0024,  0.0114,  ...,  0.0050, -0.0381, -0.0195],
        ...,
        [ 0.0009, -0.0125, -0.0078,  ...,  0.0158,  0.0216,  0.0021],
        [ 0.0070, -0.0182, -0.0230,  ...,  0.0060, -0.0005, -0.0075],
        [-0.0146,  0.0520,  0.0271,  ..., -0.0072, -0.0645, -0.0416]],
       dtype=torch.float16), 'model.layers.26.self_attn.k_proj.weight': tensor([[ 0.0220,  0.0199, -0.0121,  ..., -0.0308,  0.0384,  0.0029],
        [-0.0267,  0.0055,  0.0148,  ...,  0.0016,  0.0168,  0.0291],
        [ 0.0129,  0.0286,  0.0004,  ..., -0.0190, -0.0591, -0.0098],
        ...,
        [ 0.0247,  0.0246,  0.0012,  ..., -0.0466, -0.0545,  0.0259],
        [-0.0216, -0.0389, -0.0074,  ...,  0.0483,  0.0228, -0.0051],
        [-0.0171,  0.0094, -0.0132,  ...,  0.0006, -0.0198, -0.0154]],
       dtype=torch.float16), 'model.layers.26.self_attn.v_proj.weight': tensor([[ 0.0506, -0.0262, -0.0245,  ..., -0.0152,  0.0105, -0.0191],
        [-0.0491, -0.0213,  0.0254,  ...,  0.0101, -0.0062,  0.0016],
        [ 0.0013, -0.0020, -0.0238,  ..., -0.0061,  0.0042, -0.0306],
        ...,
        [-0.0236, -0.0176, -0.0008,  ...,  0.0428, -0.0050,  0.0086],
        [ 0.0039, -0.0365, -0.0094,  ..., -0.0166, -0.0242, -0.0042],
        [ 0.0092,  0.0188, -0.0045,  ...,  0.0071,  0.0064,  0.0172]],
       dtype=torch.float16), 'model.layers.26.self_attn.o_proj.weight': tensor([[ 0.0108, -0.0005, -0.0306,  ...,  0.0052,  0.0149,  0.0272],
        [ 0.0067,  0.0455,  0.0062,  ..., -0.0016,  0.0462, -0.0053],
        [ 0.0013,  0.0102, -0.0247,  ..., -0.0226,  0.0037, -0.0018],
        ...,
        [ 0.0307,  0.0040,  0.0108,  ..., -0.0002,  0.0182,  0.0043],
        [-0.0128,  0.0049, -0.0096,  ...,  0.0135, -0.0017, -0.0425],
        [ 0.0257,  0.0072,  0.0050,  ..., -0.0276,  0.0283, -0.0160]],
       dtype=torch.float16), 'model.layers.26.mlp.gate_proj.weight': tensor([[ 0.0187,  0.0045,  0.0131,  ...,  0.0258,  0.0262, -0.0261],
        [-0.0062,  0.0102, -0.0258,  ..., -0.0255, -0.0266,  0.0190],
        [ 0.0022, -0.0109,  0.0007,  ...,  0.0060,  0.0038, -0.0172],
        ...,
        [-0.0065,  0.0356, -0.0078,  ..., -0.0015, -0.0380, -0.0219],
        [-0.0150,  0.0138,  0.0250,  ...,  0.0159,  0.0240,  0.0123],
        [ 0.0182, -0.0038, -0.0058,  ..., -0.0301, -0.0062, -0.0043]],
       dtype=torch.float16), 'model.layers.26.mlp.up_proj.weight': tensor([[-0.0168,  0.0401,  0.0018,  ...,  0.0049, -0.0029, -0.0195],
        [-0.0410, -0.0193,  0.0116,  ...,  0.0265, -0.0069,  0.0175],
        [ 0.0082, -0.0065, -0.0241,  ...,  0.0146, -0.0218, -0.0152],
        ...,
        [ 0.0058, -0.0324,  0.0059,  ...,  0.0126,  0.0300, -0.0139],
        [-0.0445,  0.0100,  0.0505,  ...,  0.0299, -0.0133,  0.0091],
        [ 0.0003, -0.0191,  0.0266,  ..., -0.0121,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.layers.26.mlp.down_proj.weight': tensor([[-0.0157, -0.0151, -0.0184,  ...,  0.0317,  0.0165,  0.0026],
        [ 0.0194,  0.0122,  0.0013,  ...,  0.0555,  0.0187, -0.0188],
        [-0.0182,  0.0041, -0.0274,  ..., -0.0111,  0.0171,  0.0083],
        ...,
        [-0.0175, -0.0124, -0.0203,  ...,  0.0105,  0.0436, -0.0020],
        [-0.0128, -0.0142, -0.0195,  ...,  0.0095,  0.0033,  0.0230],
        [ 0.0049, -0.0129, -0.0006,  ...,  0.0101,  0.0221,  0.0164]],
       dtype=torch.float16), 'model.layers.26.input_layernorm.weight': tensor([0.5312, 0.5469, 0.5469,  ..., 0.5234, 0.5508, 0.5547],
       dtype=torch.float16), 'model.layers.26.post_attention_layernorm.weight': tensor([0.4492, 0.4492, 0.4375,  ..., 0.4512, 0.4590, 0.4590],
       dtype=torch.float16), 'model.layers.27.self_attn.q_proj.weight': tensor([[-0.0292,  0.0145,  0.0077,  ..., -0.0038,  0.0122,  0.0435],
        [-0.0134,  0.0433,  0.0299,  ..., -0.0242,  0.0111,  0.0059],
        [-0.0217, -0.0236,  0.0096,  ...,  0.0025, -0.0223,  0.0289],
        ...,
        [-0.0505,  0.0273, -0.0095,  ...,  0.0185, -0.0201, -0.0225],
        [-0.0039,  0.0271,  0.0072,  ...,  0.0084,  0.0002,  0.0258],
        [-0.0235, -0.0104,  0.0114,  ...,  0.0226,  0.0154, -0.0077]],
       dtype=torch.float16), 'model.layers.27.self_attn.k_proj.weight': tensor([[-0.0173, -0.0195,  0.0098,  ..., -0.0015, -0.0104,  0.0059],
        [-0.0029,  0.0090,  0.0194,  ...,  0.0424, -0.0081, -0.0110],
        [ 0.0017, -0.0138,  0.0081,  ..., -0.0129,  0.0021, -0.0088],
        ...,
        [-0.0041, -0.0153,  0.0362,  ...,  0.0069, -0.0344, -0.0087],
        [ 0.0248, -0.0192, -0.0473,  ...,  0.0660, -0.0128,  0.0439],
        [ 0.0315,  0.0143, -0.0021,  ..., -0.0374, -0.0376,  0.0114]],
       dtype=torch.float16), 'model.layers.27.self_attn.v_proj.weight': tensor([[ 0.0174, -0.0144, -0.0334,  ...,  0.0311,  0.0319, -0.0054],
        [ 0.0185,  0.0108,  0.0118,  ...,  0.0023, -0.0246,  0.0214],
        [-0.0263, -0.0055,  0.0169,  ..., -0.0106,  0.0546, -0.0242],
        ...,
        [ 0.0146, -0.0203, -0.0192,  ...,  0.0176, -0.0095, -0.0034],
        [ 0.0059, -0.0240, -0.0200,  ..., -0.0100, -0.0106, -0.0184],
        [ 0.0211, -0.0241, -0.0149,  ..., -0.0229, -0.0193,  0.0111]],
       dtype=torch.float16), 'model.layers.27.self_attn.o_proj.weight': tensor([[ 0.0038, -0.0119,  0.0095,  ...,  0.0242,  0.0067, -0.0269],
        [ 0.0054,  0.0286, -0.0241,  ..., -0.0172, -0.0162,  0.0058],
        [-0.0047, -0.0113, -0.0132,  ...,  0.0162,  0.0009, -0.0092],
        ...,
        [ 0.0251, -0.0114, -0.0128,  ...,  0.0111,  0.0484, -0.0008],
        [ 0.0368, -0.0221, -0.0091,  ..., -0.0011, -0.0006,  0.0184],
        [ 0.0446,  0.0125,  0.0281,  ..., -0.0113, -0.0002, -0.0220]],
       dtype=torch.float16), 'model.layers.27.mlp.gate_proj.weight': tensor([[ 0.0450,  0.0128, -0.0067,  ...,  0.0097,  0.0032, -0.0147],
        [-0.0158,  0.0018, -0.0322,  ...,  0.0303,  0.0333,  0.0226],
        [ 0.0075,  0.0203, -0.0080,  ..., -0.0125, -0.0238,  0.0320],
        ...,
        [ 0.0358,  0.0211,  0.0024,  ..., -0.0008,  0.0165, -0.0047],
        [-0.0144,  0.0255, -0.0209,  ..., -0.0090, -0.0178,  0.0073],
        [ 0.0026, -0.0184, -0.0149,  ..., -0.0166, -0.0047, -0.0048]],
       dtype=torch.float16), 'model.layers.27.mlp.up_proj.weight': tensor([[-0.0049,  0.0078,  0.0265,  ..., -0.0012,  0.0131, -0.0389],
        [-0.0102,  0.0028, -0.0278,  ...,  0.0119, -0.0223, -0.0237],
        [ 0.0258,  0.0162,  0.0435,  ...,  0.0278,  0.0015, -0.0196],
        ...,
        [-0.0044,  0.0250,  0.0330,  ..., -0.0218,  0.0206, -0.0381],
        [ 0.0097,  0.0212,  0.0149,  ...,  0.0130, -0.0131, -0.0248],
        [-0.0111,  0.0048, -0.0053,  ..., -0.0063, -0.0244, -0.0093]],
       dtype=torch.float16), 'model.layers.27.mlp.down_proj.weight': tensor([[ 2.4376e-03, -2.2705e-02,  3.4363e-02,  ..., -1.9394e-02,
          1.9669e-02, -1.1414e-02],
        [ 8.0466e-05,  1.3931e-02, -9.4910e-03,  ..., -1.9272e-02,
         -3.1616e-02,  1.2093e-02],
        [ 4.6478e-02,  1.3847e-02,  5.7602e-03,  ..., -3.2166e-02,
          4.1733e-03,  2.9587e-02],
        ...,
        [-7.6523e-03,  1.0971e-02,  1.5335e-02,  ...,  7.5302e-03,
         -4.5685e-02,  2.5742e-02],
        [-2.2018e-02, -3.3932e-03, -1.7227e-02,  ...,  2.2934e-02,
         -9.0866e-03,  2.0813e-02],
        [ 4.7493e-03,  1.7471e-02, -9.1858e-03,  ...,  1.9531e-02,
         -2.3441e-03, -4.7493e-03]], dtype=torch.float16), 'model.layers.27.input_layernorm.weight': tensor([0.5625, 0.5625, 0.5586,  ..., 0.5547, 0.5625, 0.5703],
       dtype=torch.float16), 'model.layers.27.post_attention_layernorm.weight': tensor([0.4688, 0.4629, 0.4531,  ..., 0.4668, 0.4707, 0.4688],
       dtype=torch.float16), 'model.layers.28.self_attn.q_proj.weight': tensor([[-3.2127e-05, -1.9119e-02, -7.1669e-04,  ..., -1.4694e-02,
         -9.0561e-03, -1.0872e-02],
        [ 1.1421e-02, -1.8387e-02, -2.4986e-03,  ...,  1.3634e-02,
          5.4283e-03, -3.9635e-03],
        [ 1.4305e-02,  6.4993e-04, -1.0948e-02,  ..., -3.7956e-03,
         -2.4414e-02,  2.4261e-02],
        ...,
        [-1.1253e-02,  2.4719e-02, -5.3101e-02,  ...,  1.6006e-02,
         -7.5684e-03, -3.9825e-02],
        [ 1.6541e-02, -2.6855e-02, -1.2665e-02,  ...,  2.0569e-02,
          3.2928e-02, -6.5002e-02],
        [ 1.9409e-02,  1.4633e-02, -4.5654e-02,  ...,  4.5868e-02,
          1.4122e-02, -3.6987e-02]], dtype=torch.float16), 'model.layers.28.self_attn.k_proj.weight': tensor([[-0.0036, -0.0034,  0.0078,  ..., -0.0043,  0.0148, -0.0134],
        [-0.0133, -0.0068, -0.0168,  ..., -0.0066,  0.0050,  0.0043],
        [ 0.0061,  0.0063, -0.0146,  ..., -0.0197, -0.0112,  0.0050],
        ...,
        [-0.0251, -0.0133, -0.0040,  ..., -0.0014, -0.0604, -0.0040],
        [ 0.0462, -0.0221,  0.0039,  ...,  0.0161,  0.0397,  0.0285],
        [ 0.0180, -0.0042,  0.0045,  ..., -0.0038, -0.0185, -0.0136]],
       dtype=torch.float16), 'model.layers.28.self_attn.v_proj.weight': tensor([[-0.0240,  0.0090,  0.0227,  ..., -0.0210, -0.0288,  0.0260],
        [ 0.0231, -0.0178, -0.0135,  ..., -0.0447,  0.0313, -0.0163],
        [-0.0102,  0.0174, -0.0021,  ...,  0.0075, -0.0479,  0.0167],
        ...,
        [ 0.0193,  0.0043, -0.0005,  ...,  0.0143, -0.0064, -0.0217],
        [ 0.0511,  0.0041,  0.0421,  ...,  0.0019,  0.0046, -0.0031],
        [ 0.0181,  0.0192, -0.0485,  ...,  0.0328, -0.0048,  0.0090]],
       dtype=torch.float16), 'model.layers.28.self_attn.o_proj.weight': tensor([[ 1.1208e-02,  2.4567e-02, -4.1473e-02,  ..., -3.4485e-02,
          1.7929e-02, -9.8646e-05],
        [-1.2238e-02, -2.0905e-02, -2.8381e-03,  ..., -1.7075e-02,
          2.7145e-02,  3.2501e-02],
        [ 2.7863e-02,  1.7838e-02, -5.3741e-02,  ...,  2.2293e-02,
          1.5701e-02, -1.6464e-02],
        ...,
        [ 2.5444e-03, -4.4098e-03,  3.4332e-02,  ..., -9.8801e-03,
         -3.9917e-02, -6.6757e-03],
        [-7.5188e-03, -5.8655e-02, -1.8112e-02,  ...,  2.0889e-02,
         -2.8183e-02, -2.7084e-02],
        [-4.3823e-02, -4.1618e-03, -1.0742e-02,  ..., -1.9196e-02,
         -8.0719e-03,  4.2839e-03]], dtype=torch.float16), 'model.layers.28.mlp.gate_proj.weight': tensor([[-0.0007,  0.0031, -0.0068,  ...,  0.0274, -0.0111,  0.0312],
        [-0.0257,  0.0139, -0.0106,  ...,  0.0121,  0.0034,  0.0177],
        [ 0.0099,  0.0288,  0.0274,  ...,  0.0168,  0.0038,  0.0067],
        ...,
        [-0.0053,  0.0228,  0.0102,  ...,  0.0135,  0.0128, -0.0202],
        [ 0.0124, -0.0344, -0.0104,  ..., -0.0197, -0.0044, -0.0032],
        [-0.0318,  0.0149,  0.0106,  ..., -0.0078, -0.0112,  0.0179]],
       dtype=torch.float16), 'model.layers.28.mlp.up_proj.weight': tensor([[ 0.0224,  0.0047,  0.0220,  ...,  0.0277,  0.0156,  0.0114],
        [-0.0177, -0.0260, -0.0041,  ..., -0.0033, -0.0355, -0.0220],
        [ 0.0064,  0.0259, -0.0073,  ...,  0.0068,  0.0073, -0.0160],
        ...,
        [-0.0055, -0.0151,  0.0324,  ..., -0.0026,  0.0111, -0.0013],
        [-0.0215,  0.0078, -0.0074,  ...,  0.0127, -0.0099, -0.0497],
        [-0.0093, -0.0252, -0.0048,  ..., -0.0067,  0.0076,  0.0080]],
       dtype=torch.float16), 'model.layers.28.mlp.down_proj.weight': tensor([[ 0.0077,  0.0342, -0.0055,  ...,  0.0029, -0.0016, -0.0298],
        [-0.0009, -0.0338,  0.0198,  ..., -0.0268, -0.0070, -0.0280],
        [-0.0241,  0.0253, -0.0140,  ...,  0.0032,  0.0074, -0.0012],
        ...,
        [ 0.0106, -0.0143, -0.0053,  ..., -0.0309, -0.0309,  0.0070],
        [-0.0170, -0.0194,  0.0628,  ..., -0.0242, -0.0061,  0.0128],
        [-0.0234,  0.0108, -0.0081,  ...,  0.0294,  0.0295, -0.0142]],
       dtype=torch.float16), 'model.layers.28.input_layernorm.weight': tensor([0.5781, 0.5859, 0.5664,  ..., 0.5547, 0.5742, 0.5742],
       dtype=torch.float16), 'model.layers.28.post_attention_layernorm.weight': tensor([0.4805, 0.4785, 0.4648,  ..., 0.4785, 0.4727, 0.4727],
       dtype=torch.float16), 'model.layers.29.self_attn.q_proj.weight': tensor([[ 0.0060,  0.0026, -0.0075,  ...,  0.0002, -0.0110,  0.0094],
        [-0.0288, -0.0180, -0.0257,  ..., -0.0128, -0.0063, -0.0059],
        [-0.0291,  0.0377, -0.0024,  ..., -0.0022, -0.0156,  0.0146],
        ...,
        [ 0.0005,  0.0704, -0.0331,  ...,  0.0133, -0.0080, -0.0352],
        [-0.0236, -0.0242,  0.0169,  ..., -0.0142, -0.0230,  0.0260],
        [ 0.0005, -0.0416, -0.0127,  ...,  0.0132,  0.0065, -0.0391]],
       dtype=torch.float16), 'model.layers.29.self_attn.k_proj.weight': tensor([[ 0.0357, -0.0135, -0.0162,  ...,  0.0005,  0.0101, -0.0023],
        [-0.0177,  0.0316, -0.0048,  ..., -0.0086,  0.0006, -0.0218],
        [ 0.0214,  0.0079,  0.0186,  ...,  0.0193,  0.0339, -0.0014],
        ...,
        [-0.0317,  0.0448,  0.0010,  ..., -0.0091,  0.0024, -0.0117],
        [ 0.0014, -0.0123, -0.0701,  ..., -0.0106, -0.0095, -0.0427],
        [ 0.0107, -0.0124, -0.0583,  ..., -0.0584, -0.0144,  0.0027]],
       dtype=torch.float16), 'model.layers.29.self_attn.v_proj.weight': tensor([[ 0.0110,  0.0064,  0.0324,  ...,  0.0194,  0.0085,  0.0135],
        [-0.0017,  0.0247,  0.0385,  ..., -0.0199,  0.0092, -0.0022],
        [-0.0130,  0.0104, -0.0103,  ...,  0.0083,  0.0268,  0.0188],
        ...,
        [ 0.0067,  0.0294,  0.0116,  ..., -0.0203, -0.0125, -0.0172],
        [ 0.0001,  0.0276, -0.0236,  ...,  0.0186,  0.0294, -0.0053],
        [-0.0033, -0.0211,  0.0092,  ..., -0.0019, -0.0083,  0.0262]],
       dtype=torch.float16), 'model.layers.29.self_attn.o_proj.weight': tensor([[-6.3057e-03,  3.2288e-02,  3.3630e-02,  ...,  5.8222e-04,
         -1.7517e-02, -6.4850e-03],
        [-2.0340e-02, -2.5772e-02, -1.2833e-02,  ...,  1.2199e-02,
         -2.8244e-02,  1.2634e-02],
        [ 2.6093e-02,  2.8381e-02, -8.5678e-03,  ..., -3.7781e-02,
          1.7441e-02, -2.1240e-02],
        ...,
        [-2.8381e-02, -1.6617e-02,  2.8061e-02,  ..., -7.0839e-03,
         -7.8201e-03, -1.4076e-02],
        [-1.3969e-02, -1.0399e-02,  3.3966e-02,  ..., -4.7803e-05,
         -2.0554e-02,  4.7226e-03],
        [ 1.5411e-02,  3.9749e-03, -3.4275e-03,  ...,  4.1122e-03,
          1.9104e-02, -2.8473e-02]], dtype=torch.float16), 'model.layers.29.mlp.gate_proj.weight': tensor([[ 0.0161,  0.0169, -0.0145,  ..., -0.0036, -0.0243,  0.0359],
        [ 0.0034,  0.0243, -0.0081,  ..., -0.0228,  0.0151,  0.0046],
        [ 0.0371, -0.0013, -0.0085,  ..., -0.0063,  0.0206,  0.0335],
        ...,
        [-0.0048,  0.0104, -0.0152,  ...,  0.0026,  0.0065,  0.0039],
        [ 0.0079,  0.0031, -0.0292,  ..., -0.0222, -0.0051,  0.0174],
        [-0.0031,  0.0190, -0.0012,  ...,  0.0228, -0.0130, -0.0158]],
       dtype=torch.float16), 'model.layers.29.mlp.up_proj.weight': tensor([[-0.0069,  0.0021,  0.0118,  ...,  0.0150,  0.0049,  0.0057],
        [ 0.0012,  0.0072,  0.0320,  ...,  0.0089, -0.0199,  0.0363],
        [-0.0076, -0.0212, -0.0125,  ..., -0.0495,  0.0085, -0.0360],
        ...,
        [ 0.0260,  0.0129,  0.0126,  ...,  0.0124,  0.0245,  0.0357],
        [-0.0250, -0.0191, -0.0051,  ...,  0.0142,  0.0133,  0.0017],
        [ 0.0065, -0.0030,  0.0111,  ..., -0.0080,  0.0094,  0.0100]],
       dtype=torch.float16), 'model.layers.29.mlp.down_proj.weight': tensor([[ 0.0411,  0.0098, -0.0018,  ...,  0.0168, -0.0244, -0.0152],
        [ 0.0184,  0.0098,  0.0223,  ...,  0.0344,  0.0027,  0.0017],
        [ 0.0008, -0.0209, -0.0160,  ..., -0.0007,  0.0110, -0.0271],
        ...,
        [ 0.0088, -0.0090,  0.0057,  ..., -0.0189, -0.0051, -0.0197],
        [ 0.0228,  0.0159,  0.0265,  ...,  0.0094, -0.0411,  0.0024],
        [ 0.0148, -0.0185, -0.0088,  ..., -0.0158, -0.0135,  0.0045]],
       dtype=torch.float16), 'model.layers.29.input_layernorm.weight': tensor([0.5430, 0.5586, 0.5391,  ..., 0.5312, 0.5586, 0.5625],
       dtype=torch.float16), 'model.layers.29.post_attention_layernorm.weight': tensor([0.4902, 0.4922, 0.4785,  ..., 0.4785, 0.4922, 0.4805],
       dtype=torch.float16), 'model.layers.30.self_attn.q_proj.weight': tensor([[-0.0041, -0.0047,  0.0075,  ..., -0.0091, -0.0045,  0.0028],
        [ 0.0163,  0.0142,  0.0050,  ..., -0.0033, -0.0027, -0.0191],
        [-0.0086, -0.0204,  0.0428,  ...,  0.0224,  0.0053, -0.0305],
        ...,
        [-0.0093, -0.0009, -0.0012,  ...,  0.0209, -0.0119,  0.0017],
        [-0.0005, -0.0218, -0.0206,  ...,  0.0153,  0.0086, -0.0354],
        [-0.0708, -0.0093,  0.0420,  ..., -0.0094, -0.0046, -0.0015]],
       dtype=torch.float16), 'model.layers.30.self_attn.k_proj.weight': tensor([[ 0.0262, -0.0208,  0.0015,  ..., -0.0112,  0.0095,  0.0076],
        [ 0.0337,  0.0127,  0.0035,  ..., -0.0041, -0.0045,  0.0022],
        [-0.0044, -0.0148,  0.0216,  ...,  0.0055, -0.0088, -0.0004],
        ...,
        [ 0.0057,  0.0255,  0.0007,  ...,  0.0564, -0.0037, -0.0002],
        [ 0.0107, -0.0630,  0.0325,  ...,  0.0062, -0.0082, -0.0273],
        [-0.0373, -0.0082,  0.0209,  ...,  0.0079,  0.0169, -0.0247]],
       dtype=torch.float16), 'model.layers.30.self_attn.v_proj.weight': tensor([[-0.0035, -0.0291,  0.0310,  ..., -0.0268, -0.0363,  0.0307],
        [ 0.0073,  0.0172,  0.0300,  ..., -0.0118,  0.0262,  0.0019],
        [-0.0203,  0.0174, -0.0189,  ...,  0.0050, -0.0255, -0.0103],
        ...,
        [ 0.0184, -0.0039, -0.0030,  ..., -0.0245,  0.0030,  0.0241],
        [-0.0072, -0.0434,  0.0219,  ...,  0.0296, -0.0089,  0.0216],
        [-0.0088,  0.0059,  0.0193,  ..., -0.0144, -0.0613, -0.0227]],
       dtype=torch.float16), 'model.layers.30.self_attn.o_proj.weight': tensor([[-0.0074,  0.0176, -0.0070,  ...,  0.0119, -0.0119, -0.0202],
        [-0.0116, -0.0252, -0.0082,  ...,  0.0136, -0.0305, -0.0236],
        [-0.0294, -0.0029,  0.0179,  ..., -0.0482, -0.0128, -0.0113],
        ...,
        [ 0.0068,  0.0052,  0.0028,  ..., -0.0247,  0.0106,  0.0177],
        [ 0.0227, -0.0089,  0.0036,  ...,  0.0353, -0.0069,  0.0047],
        [-0.0028,  0.0133, -0.0032,  ..., -0.0048,  0.0101, -0.0147]],
       dtype=torch.float16), 'model.layers.30.mlp.gate_proj.weight': tensor([[-0.0422, -0.0289, -0.0057,  ...,  0.0138, -0.0067, -0.0003],
        [-0.0175,  0.0047,  0.0389,  ..., -0.0063, -0.0058,  0.0305],
        [-0.0219, -0.0067, -0.0307,  ...,  0.0154, -0.0004, -0.0035],
        ...,
        [-0.0204, -0.0261,  0.0121,  ..., -0.0081, -0.0219, -0.0244],
        [ 0.0268,  0.0282, -0.0097,  ...,  0.0118, -0.0396, -0.0025],
        [-0.0012, -0.0307, -0.0203,  ..., -0.0023,  0.0182, -0.0061]],
       dtype=torch.float16), 'model.layers.30.mlp.up_proj.weight': tensor([[ 0.0034,  0.0162,  0.0123,  ...,  0.0126,  0.0213, -0.0029],
        [-0.0196, -0.0118,  0.0388,  ...,  0.0008, -0.0193, -0.0033],
        [-0.0327, -0.0235, -0.0368,  ..., -0.0176,  0.0011,  0.0209],
        ...,
        [-0.0163, -0.0128,  0.0153,  ...,  0.0128, -0.0097, -0.0216],
        [-0.0081,  0.0077, -0.0097,  ...,  0.0053, -0.0229,  0.0164],
        [-0.0030, -0.0283,  0.0003,  ..., -0.0168,  0.0070,  0.0171]],
       dtype=torch.float16), 'model.layers.30.mlp.down_proj.weight': tensor([[ 2.2812e-02, -1.3634e-02, -3.0258e-02,  ...,  3.1342e-02,
         -7.2098e-03, -8.8263e-04],
        [ 2.5818e-02,  4.8409e-03,  4.3427e-02,  ...,  1.2611e-02,
          1.6594e-03, -7.8888e-03],
        [ 3.6883e-04, -3.0899e-03, -2.1591e-02,  ...,  3.1242e-03,
          1.0376e-02,  2.0767e-02],
        ...,
        [-3.1921e-02,  6.3400e-03, -2.4643e-02,  ...,  1.8341e-02,
         -2.4780e-02, -9.6664e-03],
        [-4.3750e-05, -1.9287e-02,  2.8934e-03,  ...,  1.9730e-02,
          2.3232e-03,  1.2312e-03],
        [-8.7738e-03, -1.4030e-02, -2.5955e-02,  ...,  1.0109e-02,
          3.0589e-04, -1.9150e-02]], dtype=torch.float16), 'model.layers.30.input_layernorm.weight': tensor([0.5859, 0.6016, 0.5664,  ..., 0.5586, 0.5781, 0.6016],
       dtype=torch.float16), 'model.layers.30.post_attention_layernorm.weight': tensor([0.4824, 0.5039, 0.4824,  ..., 0.4883, 0.4980, 0.4863],
       dtype=torch.float16), 'model.layers.31.self_attn.q_proj.weight': tensor([[-0.0350,  0.0179,  0.0228,  ...,  0.0133, -0.0005, -0.0199],
        [-0.0200, -0.0252, -0.0369,  ...,  0.0008, -0.0122, -0.0238],
        [-0.0219,  0.0272,  0.0192,  ..., -0.0004,  0.0037,  0.0022],
        ...,
        [ 0.0171, -0.0177, -0.0151,  ..., -0.0145,  0.0273, -0.0253],
        [-0.0265,  0.0056, -0.0053,  ..., -0.0029,  0.0124,  0.0107],
        [-0.0533, -0.0123,  0.0282,  ...,  0.0389, -0.0044,  0.0329]],
       dtype=torch.float16), 'model.layers.31.self_attn.k_proj.weight': tensor([[-0.0058, -0.0082,  0.0132,  ..., -0.0011, -0.0107, -0.0206],
        [ 0.0245, -0.0202,  0.0109,  ..., -0.0002,  0.0066, -0.0021],
        [ 0.0027,  0.0117, -0.0064,  ...,  0.0055, -0.0005, -0.0275],
        ...,
        [ 0.0315, -0.0261, -0.0244,  ..., -0.0081, -0.0101, -0.0515],
        [ 0.0134,  0.0200,  0.0124,  ..., -0.0259, -0.0236,  0.0204],
        [-0.0787, -0.0352,  0.0162,  ..., -0.0131,  0.0023, -0.0065]],
       dtype=torch.float16), 'model.layers.31.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0230, -0.0018,  ...,  0.0031,  0.0012,  0.0155],
        [ 0.0281,  0.0153,  0.0112,  ...,  0.0094,  0.0336,  0.0164],
        [ 0.0143, -0.0011, -0.0159,  ...,  0.0129,  0.0024,  0.0344],
        ...,
        [-0.0017, -0.0013, -0.0144,  ..., -0.0160, -0.0032,  0.0248],
        [ 0.0126, -0.0183,  0.0156,  ..., -0.0102, -0.0292,  0.0144],
        [-0.0103, -0.0228,  0.0264,  ...,  0.0243, -0.0042,  0.0403]],
       dtype=torch.float16), 'model.layers.31.self_attn.o_proj.weight': tensor([[ 0.0089,  0.0304, -0.0052,  ..., -0.0004, -0.0148, -0.0504],
        [-0.0065,  0.0034, -0.0314,  ...,  0.0269, -0.0200, -0.0146],
        [ 0.0102,  0.0023,  0.0032,  ..., -0.0174,  0.0214,  0.0120],
        ...,
        [ 0.0077, -0.0209,  0.0315,  ..., -0.0161, -0.0128, -0.0216],
        [ 0.0010,  0.0138, -0.0207,  ..., -0.0174, -0.0141, -0.0177],
        [ 0.0062,  0.0165, -0.0088,  ...,  0.0295, -0.0164,  0.0075]],
       dtype=torch.float16), 'model.layers.31.mlp.gate_proj.weight': tensor([[ 0.0088, -0.0101,  0.0378,  ...,  0.0157,  0.0179,  0.0108],
        [-0.0751, -0.0179,  0.0038,  ...,  0.0049, -0.0193,  0.0181],
        [ 0.0142,  0.0066, -0.0107,  ..., -0.0041, -0.0197, -0.0075],
        ...,
        [-0.0168, -0.0297,  0.0126,  ..., -0.0009,  0.0242,  0.0329],
        [ 0.0417,  0.0298, -0.0222,  ...,  0.0354, -0.0096, -0.0061],
        [ 0.0174, -0.0382, -0.0287,  ..., -0.0177,  0.0085,  0.0057]],
       dtype=torch.float16), 'model.layers.31.mlp.up_proj.weight': tensor([[-0.0397, -0.0182,  0.0206,  ...,  0.0010, -0.0187,  0.0024],
        [ 0.0275,  0.0354,  0.0046,  ..., -0.0228,  0.0012, -0.0013],
        [-0.0043,  0.0044, -0.0210,  ...,  0.0143,  0.0034, -0.0117],
        ...,
        [ 0.0134, -0.0182,  0.0072,  ...,  0.0026,  0.0326, -0.0186],
        [ 0.0055,  0.0044, -0.0258,  ...,  0.0280,  0.0101, -0.0022],
        [ 0.0409, -0.0411, -0.0085,  ..., -0.0104,  0.0099,  0.0237]],
       dtype=torch.float16), 'model.layers.31.mlp.down_proj.weight': tensor([[-1.2767e-04, -2.5101e-02, -9.8572e-03,  ..., -3.8147e-02,
         -1.4954e-02,  2.7756e-02],
        [ 3.8208e-02,  3.5248e-03, -3.6736e-03,  ..., -5.2691e-04,
         -1.6205e-02,  1.3901e-02],
        [-1.2566e-02, -1.2192e-02,  2.5131e-02,  ...,  3.0304e-02,
         -1.5383e-03,  2.3193e-02],
        ...,
        [ 4.7088e-05,  2.8351e-02, -2.0237e-03,  ...,  1.1597e-02,
          5.3177e-03,  1.7136e-02],
        [-9.8515e-04,  4.7424e-02, -5.3787e-03,  ..., -7.3509e-03,
          2.3331e-02,  1.7090e-02],
        [ 2.6001e-02, -3.8910e-02,  1.8829e-02,  ...,  4.1313e-03,
          1.2999e-03,  2.6016e-02]], dtype=torch.float16), 'model.layers.31.input_layernorm.weight': tensor([0.4961, 0.4980, 0.4453,  ..., 0.4375, 0.4727, 0.4922],
       dtype=torch.float16), 'model.layers.31.post_attention_layernorm.weight': tensor([0.4414, 0.4434, 0.4531,  ..., 0.4336, 0.4219, 0.4375],
       dtype=torch.float16), 'model.norm.weight': tensor([2.0000, 2.0469, 1.9453,  ..., 1.8594, 1.9453, 1.7656],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding': tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight': tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,
            2.1957e-02,  5.0011e-03],
          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,
            7.5417e-03, -1.2230e-02],
          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,
            5.3940e-03, -1.2283e-02],
          ...,
          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,
           -2.3239e-02, -2.4017e-02],
          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,
            1.5745e-03, -4.1771e-03],
          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,
            4.0169e-03, -6.7177e-03]],

         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,
            2.4185e-02,  5.8136e-03],
          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,
            5.4970e-03, -1.4351e-02],
          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,
            5.5618e-03, -1.2390e-02],
          ...,
          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,
            3.9816e-04, -5.1346e-03],
          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,
            2.2552e-02,  1.2917e-02],
          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,
            1.8158e-02,  9.2745e-04]],

         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,
            1.1757e-02,  5.7259e-03],
          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,
           -4.2191e-03, -7.1831e-03],
          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,
            1.3041e-04, -7.3051e-03],
          ...,
          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,
           -9.8267e-03, -6.7825e-03],
          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,
            6.3400e-03,  5.3177e-03],
          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,
            6.5193e-03,  2.9850e-04]]],


        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,
           -8.4381e-03,  2.0447e-02],
          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,
            3.5906e-04,  1.5945e-02],
          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,
           -2.7924e-02, -3.2177e-03],
          ...,
          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,
           -5.4741e-03, -5.9624e-03],
          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,
           -2.7969e-02, -1.8875e-02],
          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,
            7.1335e-03,  4.6478e-02]],

         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,
           -1.1604e-02,  1.7593e-02],
          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,
            3.4976e-04,  1.4732e-02],
          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,
           -3.2684e-02, -7.0076e-03],
          ...,
          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,
           -1.1253e-02, -9.8648e-03],
          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,
           -3.7231e-02, -2.6505e-02],
          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,
           -4.2000e-03,  3.9368e-02]],

         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,
           -1.2558e-02,  1.7303e-02],
          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,
            4.3440e-04,  1.5656e-02],
          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,
           -2.9968e-02, -6.5422e-03],
          ...,
          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,
           -8.7967e-03, -8.7662e-03],
          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,
           -3.0518e-02, -2.4918e-02],
          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,
           -7.3242e-04,  3.8818e-02]]],


        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,
            1.4229e-02,  1.8768e-02],
          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,
            5.4283e-03,  6.6032e-03],
          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,
            2.5959e-03,  6.8703e-03],
          ...,
          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,
            1.4397e-02,  1.2421e-02],
          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,
            2.2766e-02,  2.2659e-02],
          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,
            2.2263e-02,  2.5238e-02]],

         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,
            1.9653e-02,  2.8290e-02],
          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,
            6.0501e-03,  1.2810e-02],
          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,
           -5.9271e-04,  8.8959e-03],
          ...,
          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,
            2.4902e-02,  2.6871e-02],
          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,
            3.3569e-02,  3.9612e-02],
          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,
            3.9276e-02,  4.6051e-02]],

         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,
            2.1042e-02,  2.9053e-02],
          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,
            7.7019e-03,  1.2169e-02],
          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,
            3.3913e-03,  9.0408e-03],
          ...,
          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,
            8.0795e-03,  1.4221e-02],
          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,
            1.1887e-02,  1.8204e-02],
          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,
            1.5701e-02,  2.2247e-02]]],


        ...,


        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,
            3.1686e-04, -3.0446e-04],
          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,
           -2.2995e-04, -1.6510e-04],
          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,
           -5.0831e-04,  5.9748e-04],
          ...,
          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,
           -9.3746e-04, -6.7472e-04],
          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,
           -1.4048e-03, -1.3056e-03],
          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,
            3.2640e-04,  1.7679e-04]],

         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,
            1.0500e-03, -5.0831e-04],
          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,
            1.0071e-03, -4.9925e-04],
          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,
            8.0919e-04,  9.7132e-04],
          ...,
          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,
            6.2895e-04,  4.0889e-04],
          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,
           -2.8610e-04,  1.9038e-04],
          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,
            1.4138e-04,  4.2319e-04]],

         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,
           -4.3130e-04, -5.6791e-04],
          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,
            1.9002e-04,  1.8311e-04],
          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,
            2.3186e-05, -5.7578e-05],
          ...,
          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,
            1.3471e-04,  6.5708e-04],
          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,
            1.0538e-04, -4.9019e-04],
          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,
           -4.1580e-04,  5.5599e-04]]],


        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,
            6.1874e-03,  2.6535e-02],
          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,
           -1.7639e-02, -3.2768e-03],
          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,
           -2.7237e-02, -5.5046e-03],
          ...,
          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,
            2.8503e-02,  3.6499e-02],
          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,
           -2.3010e-02,  5.0926e-03],
          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,
           -3.9276e-02,  1.3908e-02]],

         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,
            2.8896e-03,  2.2415e-02],
          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,
           -1.8616e-02, -6.5308e-03],
          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,
           -3.0472e-02, -9.3613e-03],
          ...,
          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,
            2.6001e-02,  3.4241e-02],
          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,
           -3.0487e-02, -9.5701e-04],
          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,
           -5.1422e-02,  4.2267e-03]],

         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,
           -2.1572e-03,  1.6891e-02],
          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,
           -2.1347e-02, -9.2316e-03],
          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,
           -2.9694e-02, -1.2733e-02],
          ...,
          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,
            1.9257e-02,  2.4582e-02],
          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,
           -3.1281e-02, -9.1248e-03],
          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,
           -5.2246e-02, -2.8057e-03]]],


        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,
            8.1863e-03, -4.8248e-02],
          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,
            9.3689e-03, -3.8544e-02],
          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,
            2.3956e-02, -1.1154e-02],
          ...,
          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,
           -1.8654e-03, -1.9440e-02],
          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,
            8.4381e-03,  1.4282e-02],
          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,
            1.6689e-03,  1.6891e-02]],

         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,
            1.5839e-02, -4.3243e-02],
          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,
            1.8433e-02, -3.1799e-02],
          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,
            2.9694e-02, -5.4817e-03],
          ...,
          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,
           -1.5268e-03, -1.4626e-02],
          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,
            8.5602e-03,  2.0035e-02],
          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,
           -2.3785e-03,  1.9150e-02]],

         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,
            2.1317e-02, -3.0197e-02],
          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,
            2.4658e-02, -1.7670e-02],
          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,
            3.4302e-02,  4.5395e-03],
          ...,
          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,
            4.1656e-03, -5.9814e-03],
          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,
            1.6068e-02,  2.5879e-02],
          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,
            2.2964e-03,  2.2339e-02]]]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight': tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],
        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],
        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],
        ...,
        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],
        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],
        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight': tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias': tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight': tensor([[-1.1724e-04,  8.3399e-04, -1.5700e-04,  ..., -4.8332e-03,
          1.3428e-02,  3.2604e-05],
        [-4.4703e-05, -9.5272e-04,  1.2279e-04,  ...,  1.9855e-03,
         -1.3626e-02, -4.1783e-05],
        [ 6.6280e-04,  1.0419e-04,  9.0420e-05,  ..., -2.1820e-02,
          4.1199e-03,  3.2187e-06],
        ...,
        [-5.2512e-05, -2.9278e-04, -3.6895e-05,  ...,  8.8196e-03,
         -4.2796e-04, -3.0100e-05],
        [ 7.5936e-05, -6.5148e-05, -9.0182e-05,  ...,  8.1682e-04,
         -6.0844e-03,  1.9014e-05],
        [-6.3896e-05,  9.8705e-05,  4.9829e-05,  ..., -1.2579e-03,
         -7.1793e-03,  2.3961e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias': tensor([ 0.0577, -0.0588, -0.0266,  ..., -0.0147, -0.0175,  0.0096],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight': tensor([[ 2.4986e-04, -1.5283e-04, -5.8556e-04,  ...,  3.3607e-03,
         -9.5901e-03,  5.5373e-05],
        [-3.4356e-04, -1.5092e-04,  5.2691e-05,  ...,  2.5725e-04,
          1.0010e-02, -6.2883e-05],
        [ 6.7472e-04, -9.6798e-05,  2.5392e-04,  ..., -1.0386e-03,
         -1.9531e-02, -1.2141e-04],
        ...,
        [ 2.9850e-04,  4.0436e-04, -9.7811e-05,  ...,  4.6654e-03,
         -2.2392e-03, -6.6221e-05],
        [ 3.2973e-04, -3.2961e-05, -2.1207e-04,  ...,  1.1917e-02,
          3.4637e-03,  6.9439e-05],
        [ 2.1458e-06,  4.7874e-04,  4.8459e-05,  ..., -1.1612e-02,
          2.6779e-03, -8.3089e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias': tensor([-0.0277,  0.0222, -0.0355,  ...,  0.0123,  0.0105, -0.0041],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight': tensor([[-2.6703e-05, -1.3638e-04, -8.3923e-05,  ...,  4.2152e-03,
         -2.7649e-02, -7.5042e-05],
        [-1.6391e-04,  9.0241e-05,  5.4836e-05,  ..., -1.5821e-03,
          2.9831e-02,  7.0333e-05],
        [ 4.7588e-04,  7.6008e-04, -1.0198e-04,  ..., -1.7090e-02,
          4.1809e-02,  1.5020e-04],
        ...,
        [ 6.9141e-05,  7.0274e-05,  8.6784e-05,  ..., -4.3411e-03,
          1.1421e-02, -3.8803e-05],
        [-1.8144e-04,  1.4305e-06, -2.5940e-04,  ...,  1.5802e-03,
         -1.8799e-04,  1.6689e-05],
        [-1.2624e-04,  9.4473e-05,  5.3406e-05,  ..., -1.4961e-02,
         -5.8937e-04,  4.2021e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias': tensor([ 1.5693, -1.6172, -0.8213,  ..., -1.2852, -0.0976,  0.7852],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight': tensor([[-0.0073,  0.0083, -0.0076,  ..., -0.0090, -0.0080,  0.0038],
        [ 0.0107,  0.0062,  0.0133,  ..., -0.0036,  0.0022,  0.0034],
        [-0.0065,  0.0033,  0.0139,  ...,  0.0069,  0.0004, -0.0009],
        ...,
        [-0.0002, -0.0035, -0.0027,  ..., -0.0046, -0.0187,  0.0087],
        [-0.0093,  0.0047, -0.0083,  ...,  0.0006, -0.0013, -0.0006],
        [ 0.0092,  0.0003,  0.0016,  ...,  0.0016, -0.0045,  0.0045]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias': tensor([-0.0263, -0.0654,  0.0031,  ...,  0.1759, -0.0438,  0.0020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight': tensor([8.3113e-04, 2.9087e-03, 1.1456e-04,  ..., 6.9092e-01, 3.5498e-01,
        2.4021e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias': tensor([ 6.9141e-06,  7.7629e-04, -8.8811e-05,  ..., -3.6816e-01,
         1.7981e-01, -1.0854e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight': tensor([[ 4.2367e-04, -2.1219e-05,  5.9605e-08,  ..., -5.6458e-03,
         -1.2026e-03, -6.4087e-04],
        [ 6.1340e-03,  1.3588e-02, -3.5858e-04,  ..., -3.5954e-03,
         -7.6485e-04,  6.7101e-03],
        [ 1.3552e-03,  1.2817e-03, -2.0266e-06,  ..., -2.8351e-02,
         -1.2054e-03,  1.4830e-03],
        ...,
        [-2.4002e-02, -1.0193e-02,  2.1684e-04,  ..., -2.5864e-03,
         -1.1841e-02,  5.9166e-03],
        [ 4.1008e-04,  4.2856e-05, -1.1921e-07,  ..., -5.0697e-03,
         -7.7248e-04, -6.3896e-04],
        [-6.3753e-04, -2.3392e-02, -2.6226e-04,  ..., -4.2801e-03,
          2.7962e-03, -8.1863e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias': tensor([-0.6826, -0.3130, -0.8076,  ..., -0.2166, -0.6538, -0.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight': tensor([[-0.0037, -0.0032,  0.0043,  ...,  0.0117, -0.0042, -0.0073],
        [ 0.0017,  0.0183, -0.0100,  ..., -0.0255,  0.0024,  0.0209],
        [ 0.0033,  0.0024, -0.0029,  ...,  0.0037,  0.0032, -0.0154],
        ...,
        [ 0.0015, -0.0007, -0.0035,  ...,  0.0049,  0.0009,  0.0082],
        [-0.0060,  0.0064,  0.0067,  ..., -0.0009, -0.0061,  0.0016],
        [ 0.0007, -0.0034, -0.0020,  ..., -0.0091,  0.0009,  0.0035]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias': tensor([-0.0185, -0.1009,  0.0397,  ..., -0.0955, -0.1080, -0.0239],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight': tensor([2.8296e-01, 5.9082e-01, 1.0455e-04,  ..., 2.0195e+00, 7.7490e-01,
        2.9736e-01], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias': tensor([2.1988e-02, 2.1716e-01, 9.2089e-05,  ..., 2.6318e-01, 4.5020e-01,
        5.0903e-02], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight': tensor([[-3.9864e-03,  1.4374e-02, -2.8610e-03,  ...,  1.0399e-02,
         -2.8076e-02,  5.1155e-03],
        [ 8.1024e-03,  2.2583e-03,  1.1635e-02,  ..., -7.1716e-03,
         -7.5607e-03,  2.5375e-02],
        [ 9.5596e-03,  1.1284e-02, -3.6469e-03,  ..., -6.6757e-03,
         -1.2465e-03, -1.1475e-02],
        ...,
        [ 7.7188e-05, -1.6190e-02,  3.6583e-03,  ...,  2.1240e-02,
          4.3907e-03, -1.0063e-02],
        [ 1.5762e-02,  1.7273e-02, -3.3447e-02,  ..., -2.2507e-03,
         -1.2947e-02,  1.1726e-02],
        [-2.2697e-04,  1.2230e-02, -4.3411e-03,  ...,  3.3436e-03,
         -4.9973e-03,  5.5504e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias': tensor([-0.0012,  0.0081,  0.0097,  ...,  0.0535,  0.0071,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight': tensor([[ 0.0077,  0.0006,  0.0053,  ..., -0.0067,  0.0008,  0.0013],
        [ 0.0230, -0.0166, -0.0004,  ...,  0.0092, -0.0118, -0.0134],
        [-0.0103,  0.0013,  0.0111,  ..., -0.0549, -0.0047,  0.0056],
        ...,
        [ 0.0119,  0.0002, -0.0045,  ...,  0.0001,  0.0034, -0.0075],
        [-0.0129, -0.0114,  0.0075,  ..., -0.0030,  0.0044,  0.0061],
        [-0.0006, -0.0018,  0.0009,  ..., -0.0068, -0.0205, -0.0002]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias': tensor([ 0.0038, -0.0079, -0.1469,  ..., -0.0014, -0.0041,  0.0007],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight': tensor([[-2.4929e-03,  4.6706e-04, -1.8919e-04,  ...,  6.1684e-03,
         -2.4582e-02,  8.7051e-03],
        [ 6.5422e-03,  4.3602e-03,  1.5930e-02,  ..., -6.5994e-03,
          8.2169e-03,  6.1111e-03],
        [ 1.0727e-02, -9.2239e-03, -7.5698e-06,  ...,  3.7136e-03,
          1.6861e-02,  3.5305e-03],
        ...,
        [-2.3708e-03,  6.6452e-03,  5.9052e-03,  ..., -1.0399e-02,
          2.9945e-04, -9.6989e-04],
        [ 3.0609e-02,  1.3458e-02, -3.3386e-02,  ..., -1.3857e-03,
          3.5801e-03,  1.3245e-02],
        [-3.2291e-03,  4.7607e-03, -1.8759e-03,  ...,  6.1035e-04,
          4.9515e-03, -5.3520e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias': tensor([-0.1035,  0.8804,  1.4414,  ..., -2.2109, -0.1892,  0.0048],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight': tensor([[-0.0013, -0.0215,  0.0011,  ..., -0.0115,  0.0102, -0.0012],
        [-0.0010,  0.0065, -0.0018,  ..., -0.0036,  0.0112, -0.0025],
        [ 0.0015, -0.0069, -0.0120,  ..., -0.0047, -0.0009, -0.0056],
        ...,
        [ 0.0053, -0.0177,  0.0780,  ..., -0.0228, -0.0122,  0.0151],
        [-0.0086, -0.0019,  0.0054,  ...,  0.0081, -0.0049,  0.0067],
        [-0.0037,  0.0063, -0.0005,  ...,  0.0054,  0.0045, -0.0036]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias': tensor([-0.0204, -0.0210,  0.0255,  ..., -0.0381, -0.0211, -0.0043],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight': tensor([0.3650, 0.7476, 0.0972,  ..., 0.8521, 0.4248, 0.2639],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias': tensor([-0.0482, -0.1315,  0.0198,  ..., -0.1031, -0.0545,  0.0076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight': tensor([[ 0.0026,  0.0065,  0.0155,  ..., -0.0063,  0.0479, -0.0807],
        [ 0.0002, -0.0075,  0.0009,  ..., -0.0009, -0.0030,  0.0036],
        [ 0.0070, -0.0211,  0.0002,  ..., -0.0094,  0.0178, -0.0043],
        ...,
        [ 0.0026, -0.0113,  0.0019,  ..., -0.0057, -0.0008,  0.0038],
        [-0.0059,  0.0099,  0.0010,  ...,  0.0037, -0.0142, -0.0178],
        [ 0.0160,  0.0002,  0.0312,  ..., -0.0003, -0.0056, -0.0220]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias': tensor([-0.1216, -0.6841, -0.5278,  ..., -0.7573, -0.0995, -0.3076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight': tensor([[ 0.0008, -0.0008, -0.0176,  ..., -0.0029, -0.0098, -0.0047],
        [-0.0157,  0.0059,  0.0156,  ...,  0.0064, -0.0005, -0.0058],
        [ 0.0051, -0.0005,  0.0091,  ..., -0.0056, -0.0015,  0.0059],
        ...,
        [ 0.0030, -0.0024,  0.0040,  ...,  0.0014,  0.0002,  0.0047],
        [ 0.0007, -0.0015,  0.0031,  ..., -0.0015,  0.0046, -0.0055],
        [ 0.0299,  0.0036,  0.0020,  ...,  0.0047,  0.0134,  0.0043]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias': tensor([ 0.0244, -0.0645,  0.0788,  ..., -0.0807, -0.1028, -0.0836],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight': tensor([0.4128, 0.9854, 0.1910,  ..., 0.7715, 0.5596, 0.5142],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias': tensor([-0.0198, -0.1075, -0.0195,  ...,  0.0887,  0.1349,  0.0288],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight': tensor([[-0.0085,  0.0006, -0.0289,  ...,  0.0041,  0.0569, -0.0674],
        [-0.0052,  0.0245, -0.0213,  ..., -0.0084,  0.0220, -0.0248],
        [-0.0135, -0.0092,  0.0144,  ...,  0.0162,  0.0298, -0.0357],
        ...,
        [-0.0062,  0.0068,  0.0082,  ...,  0.0119,  0.0132, -0.0033],
        [-0.0083,  0.0247, -0.0094,  ..., -0.0040, -0.0122,  0.0142],
        [-0.0048, -0.0044, -0.0164,  ...,  0.0119, -0.0213, -0.0117]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias': tensor([ 0.0234,  0.0084, -0.0015,  ...,  0.0951,  0.0065,  0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight': tensor([[ 0.0164,  0.0053, -0.0065,  ..., -0.0008,  0.0037, -0.0120],
        [-0.0057, -0.0036, -0.0029,  ..., -0.0013,  0.0026, -0.0108],
        [-0.0081,  0.0057,  0.0067,  ...,  0.0028, -0.0068, -0.0023],
        ...,
        [-0.0249,  0.0121,  0.0107,  ...,  0.0037,  0.0007,  0.0044],
        [ 0.0115,  0.0107,  0.0118,  ...,  0.0015, -0.0038, -0.0073],
        [-0.0073,  0.0032, -0.0060,  ...,  0.0023, -0.0074,  0.0047]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias': tensor([-0.0014, -0.0060,  0.0129,  ...,  0.1081,  0.0069,  0.0455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight': tensor([[-0.0067, -0.0208, -0.0222,  ...,  0.0014,  0.0279, -0.0558],
        [-0.0030,  0.0016, -0.0191,  ...,  0.0001, -0.0169, -0.0034],
        [-0.0079, -0.0049,  0.0074,  ..., -0.0163, -0.0186, -0.0105],
        ...,
        [ 0.0002, -0.0036,  0.0084,  ..., -0.0038,  0.0105, -0.0002],
        [-0.0035, -0.0039, -0.0118,  ..., -0.0067, -0.0292,  0.0361],
        [-0.0044, -0.0008, -0.0187,  ...,  0.0014, -0.0064, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias': tensor([ 0.1927, -0.0745, -0.0890,  ...,  0.6807,  0.7334, -0.5073],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight': tensor([[-2.4796e-02,  3.3035e-03, -5.1379e-05,  ...,  2.5177e-02,
         -2.3010e-02,  1.2245e-02],
        [-2.7504e-03,  1.5330e-04, -1.1650e-02,  ..., -8.4229e-03,
         -4.1389e-03, -6.9275e-03],
        [-1.2238e-02, -7.1983e-03, -1.0323e-02,  ..., -1.6312e-02,
         -5.9547e-03, -1.4572e-03],
        ...,
        [-1.8501e-03,  5.0354e-04, -6.7101e-03,  ..., -7.3471e-03,
         -2.3518e-03, -1.8501e-03],
        [ 5.4131e-03, -4.4937e-03,  1.2329e-02,  ..., -7.1716e-04,
          9.8038e-04,  7.2708e-03],
        [ 1.0040e-02,  6.5422e-03,  9.2163e-03,  ..., -4.5815e-03,
         -1.1330e-03, -2.6169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias': tensor([ 0.0182, -0.0970,  0.0244,  ..., -0.0159, -0.0449, -0.0308],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight': tensor([0.5078, 0.3108, 0.4004,  ..., 1.4219, 0.5015, 0.3591],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias': tensor([-0.0750, -0.0109,  0.0618,  ..., -0.0417,  0.0176, -0.0477],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight': tensor([[-0.0066, -0.0264,  0.0131,  ..., -0.0004,  0.0194, -0.0154],
        [ 0.0097,  0.0090, -0.0017,  ...,  0.0023, -0.0030,  0.0246],
        [-0.0057,  0.0093,  0.0011,  ..., -0.0040,  0.0003,  0.0128],
        ...,
        [ 0.0005, -0.0012, -0.0009,  ...,  0.0011, -0.0034, -0.0059],
        [ 0.0002,  0.0115,  0.0158,  ...,  0.0040,  0.0015,  0.0208],
        [-0.0148,  0.0111, -0.0085,  ...,  0.0049, -0.0076, -0.0022]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias': tensor([-0.2452, -0.3076, -0.4565,  ..., -0.1678, -0.2119, -0.5581],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight': tensor([[ 1.3428e-03, -3.5172e-03,  9.3317e-04,  ..., -5.0354e-03,
          4.3907e-03,  2.0161e-03],
        [ 1.2999e-03, -1.6678e-02, -4.5662e-03,  ..., -4.4584e-04,
          1.3359e-02, -3.9558e-03],
        [-1.8829e-02,  5.2261e-03,  4.7760e-03,  ...,  8.3113e-04,
         -1.8860e-02,  1.0452e-03],
        ...,
        [-7.8201e-03,  8.4305e-04, -2.1601e-04,  ..., -5.6207e-05,
          4.8339e-05,  1.7557e-03],
        [-4.5300e-05, -7.9498e-03, -9.6178e-04,  ...,  3.4180e-03,
         -1.0208e-02,  2.4460e-02],
        [ 6.0883e-03,  3.3398e-03, -3.7789e-04,  ...,  1.5259e-02,
          6.6223e-03,  6.8169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias': tensor([ 0.0453, -0.0798, -0.0027,  ..., -0.0154, -0.1379, -0.0307],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight': tensor([0.6362, 0.5508, 0.3787,  ..., 1.3506, 0.4011, 0.4910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias': tensor([-0.0338, -0.0840, -0.0964,  ..., -0.0491,  0.0855, -0.2158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight': tensor([[ 0.0149, -0.0155, -0.0083,  ...,  0.0066,  0.0086, -0.0173],
        [ 0.0067,  0.0134,  0.0050,  ..., -0.0056, -0.0293, -0.0028],
        [ 0.0041, -0.0027, -0.0011,  ...,  0.0060,  0.0020, -0.0035],
        ...,
        [ 0.0110, -0.0188,  0.0174,  ..., -0.0223,  0.0017, -0.0122],
        [ 0.0165, -0.0201, -0.0204,  ..., -0.0262, -0.0232, -0.0039],
        [ 0.0062, -0.0148,  0.0194,  ...,  0.0090, -0.0007, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias': tensor([-0.0385, -0.0122,  0.0262,  ...,  0.1536,  0.0992, -0.0590],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight': tensor([[ 0.0275, -0.0126, -0.0067,  ...,  0.0002,  0.0201,  0.0163],
        [-0.0074,  0.0475,  0.0058,  ..., -0.0040,  0.0014,  0.0004],
        [-0.0100, -0.0039, -0.0155,  ...,  0.0009, -0.0079,  0.0033],
        ...,
        [ 0.0009,  0.0007,  0.0107,  ...,  0.0007,  0.0007, -0.0059],
        [-0.0008,  0.0147,  0.0066,  ...,  0.0022, -0.0062, -0.0033],
        [-0.0195, -0.0065,  0.0118,  ..., -0.0030,  0.0058,  0.0028]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias': tensor([ 0.0095, -0.0516,  0.0111,  ..., -0.0145,  0.0041,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight': tensor([[ 2.7618e-02,  1.0513e-02,  4.2725e-03,  ...,  6.3095e-03,
         -8.5907e-03, -1.3008e-02],
        [ 2.4605e-03,  1.8875e-02, -3.9787e-03,  ..., -5.7335e-03,
         -2.1698e-02,  5.3406e-03],
        [-5.1880e-04, -1.0147e-02, -1.0471e-03,  ...,  1.0002e-02,
          1.0025e-02, -1.6159e-02],
        ...,
        [ 1.4210e-03, -1.6434e-02,  5.2299e-03,  ..., -1.5053e-02,
          1.1284e-02,  1.2054e-03],
        [ 1.5579e-02,  1.5251e-02, -3.5915e-03,  ..., -2.6520e-02,
         -1.4130e-02, -7.7133e-03],
        [ 1.0399e-02, -2.2491e-02,  3.2783e-06,  ...,  8.3542e-03,
         -6.7215e-03,  1.6525e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias': tensor([-0.1852, -0.5479, -0.1450,  ..., -0.9072, -0.3499, -0.3457],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight': tensor([[-2.1683e-02,  2.3556e-03, -1.9245e-03,  ..., -9.4910e-03,
          1.6251e-02,  1.2527e-02],
        [ 6.4430e-03, -3.8055e-02, -3.1567e-03,  ..., -2.6455e-03,
         -2.1515e-02,  1.1864e-02],
        [ 5.2147e-03, -8.5602e-03,  1.5732e-02,  ..., -1.2611e-02,
          7.3395e-03, -1.2505e-02],
        ...,
        [-1.1325e-04,  3.4676e-03, -1.1169e-02,  ..., -1.0071e-02,
         -5.4538e-05, -1.7357e-03],
        [-6.8245e-03, -1.0139e-02,  1.4579e-04,  ...,  2.0309e-02,
          1.3527e-02, -3.0098e-03],
        [-1.7868e-02,  6.0368e-04, -6.7101e-03,  ...,  6.6853e-04,
         -3.0327e-03,  3.0651e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias': tensor([-0.0147, -0.0586,  0.0197,  ...,  0.0204, -0.1210,  0.0171],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight': tensor([0.7456, 0.3557, 0.6133,  ..., 2.2637, 0.5059, 0.3938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias': tensor([-0.0006,  0.0249,  0.0189,  ..., -0.1539, -0.0345,  0.0151],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight': tensor([[ 0.0034,  0.0025,  0.0007,  ..., -0.0021, -0.0065,  0.0058],
        [ 0.0011, -0.0024, -0.0028,  ..., -0.0094, -0.0078, -0.0065],
        [-0.0051, -0.0246, -0.0075,  ..., -0.0073,  0.0121,  0.0036],
        ...,
        [ 0.0077,  0.0038, -0.0011,  ..., -0.0060, -0.0017,  0.0005],
        [-0.0208, -0.0176, -0.0064,  ..., -0.0076, -0.0137, -0.0056],
        [-0.0240,  0.0082, -0.0047,  ..., -0.0105, -0.0069, -0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias': tensor([-0.0952, -0.1888, -0.1597,  ..., -0.2030, -0.3225, -0.3745],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight': tensor([[ 0.0074, -0.0074,  0.0041,  ...,  0.0181,  0.0235,  0.0145],
        [ 0.0106,  0.0015, -0.0078,  ..., -0.0323, -0.0017,  0.0073],
        [-0.0059, -0.0090, -0.0087,  ...,  0.0023,  0.0091,  0.0240],
        ...,
        [ 0.0054,  0.0013, -0.0012,  ..., -0.0047, -0.0021, -0.0053],
        [-0.0028,  0.0165,  0.0051,  ...,  0.0006, -0.0043, -0.0041],
        [-0.0045,  0.0066,  0.0154,  ..., -0.0027,  0.0146, -0.0076]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias': tensor([ 0.0139, -0.0796,  0.0050,  ...,  0.0715, -0.1787,  0.0414],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight': tensor([0.9761, 0.5317, 0.6523,  ..., 0.0116, 0.5054, 0.5391],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias': tensor([ 0.0585,  0.0282,  0.0207,  ...,  0.3896, -0.0784, -0.1201],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight': tensor([[ 2.0187e-02,  9.6970e-03,  1.7242e-02,  ..., -2.5925e-02,
         -1.5945e-02,  6.4671e-05],
        [ 1.0201e-02, -7.3357e-03,  3.3722e-02,  ...,  8.9111e-03,
         -3.2410e-02,  5.5122e-03],
        [ 9.6817e-03, -2.4231e-02,  5.7907e-03,  ...,  4.0955e-02,
          2.2415e-02, -1.8143e-02],
        ...,
        [-2.4857e-02, -2.5803e-02, -3.2673e-03,  ..., -1.3596e-02,
          3.6240e-03, -5.7650e-04],
        [-6.4754e-04,  2.4719e-02, -3.0411e-02,  ..., -1.3008e-02,
          5.0879e-04, -1.9455e-02],
        [ 1.7380e-02, -2.3804e-02,  1.2428e-02,  ..., -4.4670e-03,
         -4.2297e-02,  9.2545e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias': tensor([-0.0362, -0.0177,  0.0258,  ...,  0.0230,  0.0147,  0.0451],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight': tensor([[-0.0050,  0.0089,  0.0017,  ..., -0.0001, -0.0173, -0.0087],
        [ 0.0064, -0.0170,  0.0071,  ..., -0.0039,  0.0387, -0.0100],
        [-0.0151,  0.0005, -0.0012,  ..., -0.0011, -0.0048,  0.0012],
        ...,
        [ 0.0129, -0.0303, -0.0177,  ...,  0.0005,  0.0013,  0.0006],
        [ 0.0157,  0.0140, -0.0101,  ...,  0.0011,  0.0336, -0.0216],
        [ 0.0171, -0.0183, -0.0061,  ...,  0.0016, -0.0197, -0.0110]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias': tensor([ 0.0241, -0.0481, -0.0028,  ...,  0.0268,  0.0064, -0.0023],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight': tensor([[ 0.0075,  0.0013, -0.0144,  ..., -0.0114, -0.0454, -0.0086],
        [-0.0035, -0.0501,  0.0037,  ..., -0.0065, -0.0287,  0.0070],
        [ 0.0061, -0.0005,  0.0146,  ...,  0.0271,  0.0069, -0.0366],
        ...,
        [-0.0107,  0.0089, -0.0109,  ..., -0.0074, -0.0206, -0.0009],
        [-0.0004, -0.0072, -0.0339,  ..., -0.0124, -0.0053, -0.0094],
        [ 0.0051, -0.0136, -0.0062,  ..., -0.0015, -0.0242, -0.0031]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias': tensor([-0.4634, -0.0086,  0.2761,  ..., -0.2158, -0.2346, -0.2240],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight': tensor([[-2.6817e-03, -4.3983e-03,  1.3580e-03,  ..., -2.4681e-03,
         -1.6296e-02, -1.9119e-02],
        [-6.3057e-03,  1.3931e-02,  2.0657e-03,  ...,  2.4063e-02,
         -2.3544e-02,  2.3361e-02],
        [ 4.4098e-03,  2.9049e-03,  3.0816e-05,  ...,  1.9028e-02,
          1.2093e-02,  9.4528e-03],
        ...,
        [-6.3095e-03,  7.6141e-03, -4.4861e-03,  ..., -6.6261e-03,
         -6.6795e-03, -3.0851e-04],
        [ 1.7075e-02, -3.9612e-02,  9.1248e-03,  ...,  1.1742e-02,
         -3.6469e-02,  2.8046e-02],
        [ 8.2626e-03,  1.3752e-03, -1.0185e-02,  ...,  6.5994e-04,
          1.5320e-02,  1.1871e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias': tensor([ 0.0089, -0.0782,  0.0222,  ..., -0.0115, -0.1763,  0.0233],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight': tensor([0.7534, 0.5015, 0.7891,  ..., 1.1660, 0.6074, 0.5796],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias': tensor([ 0.0149, -0.0122,  0.0052,  ..., -0.1028,  0.0337, -0.0357],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight': tensor([[ 0.0072, -0.0114, -0.0013,  ..., -0.0066,  0.0127,  0.0151],
        [-0.0095,  0.0185,  0.0141,  ..., -0.0075,  0.0141,  0.0101],
        [-0.0018,  0.0118,  0.0032,  ..., -0.0046,  0.0148,  0.0008],
        ...,
        [ 0.0204,  0.0075,  0.0235,  ..., -0.0079,  0.0030, -0.0164],
        [ 0.0157, -0.0033, -0.0008,  ..., -0.0085,  0.0043, -0.0139],
        [-0.0009, -0.0003,  0.0257,  ..., -0.0072, -0.0059, -0.0217]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias': tensor([-0.2440, -0.3796, -0.5205,  ..., -0.2163, -0.4248, -0.2197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight': tensor([[-1.6296e-02,  6.4087e-03, -1.4839e-03,  ..., -2.2827e-02,
          1.9302e-02,  1.6346e-03],
        [ 5.0888e-03, -1.3763e-02,  5.1537e-03,  ..., -1.9989e-02,
         -2.7637e-03, -1.0567e-02],
        [ 2.8763e-03, -5.1460e-03, -5.6326e-05,  ..., -7.1030e-03,
         -9.8724e-03, -2.3098e-03],
        ...,
        [-5.3024e-03, -2.0905e-03,  2.9635e-04,  ..., -5.4092e-03,
          2.0993e-04,  2.4395e-03],
        [-9.9411e-03, -1.4748e-02, -2.4283e-04,  ...,  1.8127e-02,
          3.3779e-03,  2.1927e-02],
        [-5.7182e-03,  1.5316e-03,  1.1997e-03,  ...,  2.5387e-03,
         -5.6725e-03,  4.6387e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias': tensor([-0.0155, -0.0524, -0.0402,  ...,  0.1025, -0.1437, -0.0174],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight': tensor([1.1230, 0.5190, 1.0762,  ..., 0.0112, 0.6738, 0.7544],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias': tensor([ 0.0829, -0.0929, -0.0049,  ...,  0.1129, -0.0392, -0.0677],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight': tensor([[ 0.0035, -0.0081,  0.0270,  ..., -0.0032,  0.0041,  0.0172],
        [-0.0174,  0.0256,  0.0060,  ..., -0.0001,  0.0052, -0.0038],
        [ 0.0038,  0.0144, -0.0161,  ..., -0.0028,  0.0033,  0.0003],
        ...,
        [-0.0023, -0.0123, -0.0080,  ...,  0.0256,  0.0213, -0.0097],
        [-0.0147,  0.0030,  0.0045,  ...,  0.0211,  0.0161, -0.0218],
        [-0.0035,  0.0147,  0.0030,  ..., -0.0244, -0.0005, -0.0255]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias': tensor([-0.0187, -0.0076,  0.0053,  ...,  0.0369,  0.0955,  0.0978],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight': tensor([[-0.0090,  0.0047, -0.0008,  ..., -0.0064, -0.0025, -0.0247],
        [-0.0128, -0.0091,  0.0087,  ...,  0.0024, -0.0012,  0.0007],
        [ 0.0101, -0.0021, -0.0005,  ...,  0.0017,  0.0007, -0.0170],
        ...,
        [-0.0120,  0.0108,  0.0011,  ..., -0.0008, -0.0032,  0.0003],
        [-0.0157, -0.0033,  0.0135,  ..., -0.0007, -0.0310, -0.0129],
        [ 0.0124, -0.0001,  0.0213,  ..., -0.0014, -0.0043, -0.0239]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias': tensor([-0.0186, -0.0071, -0.0258,  ..., -0.0043, -0.0113, -0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight': tensor([[-1.7075e-02,  3.0457e-02,  8.3542e-03,  ..., -8.0032e-03,
          1.6724e-02, -1.0490e-02],
        [-1.2169e-02,  8.2474e-03, -4.2725e-03,  ..., -9.4366e-04,
         -4.9591e-03, -1.0300e-02],
        [ 1.0185e-03, -1.2466e-02, -3.0880e-03,  ..., -3.4428e-03,
         -1.3107e-02,  6.5384e-03],
        ...,
        [ 1.5793e-02,  2.0809e-03,  1.9424e-02,  ...,  2.6367e-02,
          1.0529e-02, -2.1439e-02],
        [-5.6992e-03,  4.1580e-04,  3.8116e-02,  ...,  1.6739e-02,
         -9.0103e-03, -1.6327e-02],
        [ 2.8789e-05, -9.8114e-03,  1.0004e-03,  ..., -2.2293e-02,
         -3.0365e-02,  6.1569e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias': tensor([-0.0072, -1.4619,  0.3447,  ..., -0.6147, -0.3474, -0.6455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight': tensor([[ 5.2567e-03,  1.1238e-02, -6.8092e-03,  ..., -8.0013e-04,
          1.5930e-02, -1.4336e-02],
        [-6.6223e-03,  1.9255e-03, -1.6006e-02,  ..., -2.0706e-02,
         -1.1848e-02, -1.1147e-02],
        [ 2.3087e-02,  1.1986e-02, -1.7288e-02,  ...,  5.7144e-03,
          1.4824e-02, -1.6876e-02],
        ...,
        [ 1.6647e-02,  5.3596e-03, -1.5154e-03,  ..., -2.9736e-03,
          1.8129e-03,  1.0559e-02],
        [ 4.1847e-03,  8.3694e-03,  1.2535e-02,  ..., -1.0323e-02,
          1.6327e-02, -3.2544e-05],
        [ 1.0185e-03, -2.1400e-03, -4.4098e-03,  ..., -4.6120e-03,
          6.0921e-03,  1.5152e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias': tensor([-0.0087, -0.0482, -0.0096,  ..., -0.0479, -0.1366,  0.0062],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight': tensor([0.8506, 0.6484, 0.8960,  ..., 1.2539, 0.7212, 0.8564],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias': tensor([-0.0077,  0.0670, -0.0532,  ..., -0.1699, -0.0490,  0.0434],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight': tensor([[ 0.0058,  0.0115,  0.0089,  ..., -0.0020, -0.0053,  0.0026],
        [-0.0017, -0.0024,  0.0162,  ...,  0.0009, -0.0208, -0.0094],
        [-0.0388, -0.0012, -0.0004,  ...,  0.0032, -0.0029, -0.0226],
        ...,
        [ 0.0085,  0.0130,  0.0209,  ..., -0.0057, -0.0040, -0.0012],
        [ 0.0260,  0.0055,  0.0095,  ..., -0.0008,  0.0056, -0.0098],
        [ 0.0116,  0.0073, -0.0117,  ...,  0.0011, -0.0095, -0.0163]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias': tensor([-0.4192, -0.2394, -0.3069,  ..., -0.3667, -0.2563, -0.1315],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight': tensor([[ 0.0154, -0.0020, -0.0083,  ...,  0.0161, -0.0060,  0.0146],
        [ 0.0042,  0.0226,  0.0055,  ...,  0.0110,  0.0033,  0.0034],
        [ 0.0140, -0.0083,  0.0006,  ...,  0.0085,  0.0010,  0.0007],
        ...,
        [-0.0025, -0.0010, -0.0020,  ...,  0.0007, -0.0030, -0.0018],
        [-0.0141, -0.0032, -0.0003,  ...,  0.0106, -0.0021, -0.0400],
        [ 0.0069,  0.0051, -0.0135,  ..., -0.0115,  0.0067, -0.0104]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias': tensor([-0.0416,  0.0127, -0.0229,  ...,  0.0723, -0.0145, -0.0363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight': tensor([1.1514, 0.7275, 1.1299,  ..., 1.0918, 0.8794, 1.1055],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias': tensor([ 0.0418, -0.1718, -0.0305,  ...,  0.0424, -0.2144, -0.0068],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight': tensor([[ 0.0195, -0.0016, -0.0010,  ...,  0.1302, -0.0123, -0.0063],
        [-0.0176,  0.0024, -0.0196,  ..., -0.1481, -0.0101, -0.0231],
        [-0.0042, -0.0077,  0.0033,  ...,  0.0850, -0.0172,  0.0256],
        ...,
        [ 0.0024, -0.0123,  0.0282,  ..., -0.0123,  0.0272,  0.0247],
        [ 0.0084, -0.0235,  0.0189,  ...,  0.0040, -0.0171,  0.0120],
        [ 0.0308, -0.0003,  0.0095,  ..., -0.0054, -0.0117, -0.0379]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias': tensor([-0.0049,  0.0073,  0.0145,  ...,  0.0185, -0.0033,  0.0204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight': tensor([[ 0.0096,  0.0166, -0.0025,  ..., -0.0005,  0.0005,  0.0034],
        [ 0.0066,  0.0109, -0.0074,  ...,  0.0010,  0.0079, -0.0095],
        [-0.0074, -0.0047,  0.0016,  ...,  0.0002,  0.0039,  0.0040],
        ...,
        [-0.0159,  0.0166, -0.0176,  ...,  0.0020, -0.0064,  0.0302],
        [ 0.0316, -0.0076, -0.0238,  ..., -0.0002, -0.0032, -0.0157],
        [-0.0096, -0.0192,  0.0207,  ..., -0.0009, -0.0289, -0.0082]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias': tensor([ 0.0264, -0.0288,  0.0074,  ...,  0.0075, -0.0047,  0.0190],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight': tensor([[ 0.0136, -0.0235, -0.0059,  ...,  0.0935,  0.0115, -0.0124],
        [-0.0146, -0.0224,  0.0003,  ..., -0.1112, -0.0056, -0.0134],
        [-0.0018,  0.0100,  0.0052,  ...,  0.0525,  0.0120,  0.0163],
        ...,
        [ 0.0338,  0.0004,  0.0047,  ..., -0.0146,  0.0189, -0.0173],
        [ 0.0022, -0.0096, -0.0040,  ...,  0.0011, -0.0013,  0.0135],
        [ 0.0178,  0.0135,  0.0019,  ..., -0.0075,  0.0044, -0.0363]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias': tensor([ 0.2430,  0.3418, -0.1379,  ...,  0.0247,  1.4775,  0.2130],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight': tensor([[-0.0026,  0.0052,  0.0064,  ...,  0.0172, -0.0226,  0.0066],
        [-0.0029,  0.0043, -0.0091,  ..., -0.0054, -0.0009,  0.0137],
        [-0.0161,  0.0021,  0.0049,  ...,  0.0088,  0.0251, -0.0076],
        ...,
        [ 0.0092,  0.0003, -0.0009,  ..., -0.0040,  0.0036,  0.0044],
        [ 0.0016, -0.0087,  0.0108,  ..., -0.0028, -0.0046,  0.0207],
        [ 0.0181, -0.0077, -0.0030,  ..., -0.0368, -0.0015,  0.0158]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias': tensor([-0.0217,  0.0017,  0.0176,  ...,  0.0564, -0.0415, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight': tensor([0.8926, 0.8076, 1.0293,  ..., 2.0488, 0.9590, 0.9756],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias': tensor([-0.1279, -0.0777, -0.0509,  ..., -0.2275, -0.0558,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight': tensor([[ 0.0265,  0.0048,  0.0027,  ..., -0.0071,  0.0051,  0.0187],
        [ 0.0004,  0.0177,  0.0098,  ..., -0.0020, -0.0084,  0.0181],
        [-0.0045,  0.0070, -0.0007,  ..., -0.0080, -0.0070, -0.0316],
        ...,
        [-0.0285,  0.0282,  0.0047,  ...,  0.0006, -0.0079,  0.0194],
        [-0.0049, -0.0312, -0.0060,  ..., -0.0043,  0.0310, -0.0003],
        [ 0.0185,  0.0199,  0.0079,  ..., -0.0067, -0.0297, -0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias': tensor([-0.1132, -0.1494, -0.4023,  ..., -0.2355, -0.3335, -0.2045],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight': tensor([[-0.0180,  0.0037,  0.0069,  ..., -0.0019, -0.0086, -0.0024],
        [-0.0006, -0.0030, -0.0042,  ..., -0.0177,  0.0375, -0.0014],
        [-0.0129, -0.0050, -0.0065,  ...,  0.0015, -0.0005, -0.0149],
        ...,
        [ 0.0031,  0.0014, -0.0087,  ..., -0.0003,  0.0073,  0.0014],
        [ 0.0105,  0.0060,  0.0064,  ..., -0.0005, -0.0007,  0.0372],
        [-0.0087, -0.0052,  0.0026,  ..., -0.0113, -0.0085,  0.0098]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias': tensor([-0.0068,  0.0179, -0.0552,  ...,  0.1210, -0.0750, -0.1090],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight': tensor([1.1914, 0.9712, 1.2656,  ..., 0.1719, 0.9092, 1.1973],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias': tensor([-0.0956, -0.1851, -0.0547,  ...,  0.2583, -0.0542,  0.0387],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight': tensor([[ 0.0076, -0.0117, -0.0114,  ...,  0.0770, -0.0048, -0.0017],
        [-0.0195, -0.0001, -0.0053,  ...,  0.0370, -0.0298,  0.0023],
        [-0.0094, -0.0034,  0.0132,  ...,  0.0014,  0.0088, -0.0013],
        ...,
        [ 0.0047, -0.0200, -0.0213,  ..., -0.0028, -0.0125, -0.0193],
        [-0.0028,  0.0018, -0.0313,  ..., -0.0143, -0.0024,  0.0085],
        [-0.0081, -0.0074,  0.0052,  ..., -0.0006, -0.0049, -0.0085]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias': tensor([ 0.0311, -0.0070, -0.0134,  ...,  0.0024, -0.0121, -0.0230],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight': tensor([[ 0.0104, -0.0064, -0.0062,  ...,  0.0015,  0.0052, -0.0058],
        [ 0.0179, -0.0065, -0.0221,  ..., -0.0002, -0.0032, -0.0219],
        [-0.0078,  0.0084, -0.0027,  ..., -0.0003,  0.0120,  0.0011],
        ...,
        [-0.0272, -0.0105,  0.0010,  ..., -0.0082,  0.0024,  0.0062],
        [ 0.0284, -0.0029, -0.0178,  ..., -0.0007, -0.0008, -0.0054],
        [-0.0113,  0.0083,  0.0034,  ..., -0.0102,  0.0250,  0.0115]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias': tensor([ 0.0282,  0.0175, -0.0284,  ...,  0.0397, -0.0209, -0.1344],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight': tensor([[ 0.0094, -0.0159, -0.0203,  ...,  0.0367, -0.0055, -0.0276],
        [ 0.0029, -0.0178, -0.0045,  ..., -0.0709, -0.0047, -0.0184],
        [-0.0128,  0.0083,  0.0116,  ..., -0.0014,  0.0039,  0.0124],
        ...,
        [-0.0292,  0.0131, -0.0025,  ...,  0.0003, -0.0127, -0.0156],
        [-0.0237,  0.0121, -0.0025,  ..., -0.0010,  0.0081, -0.0145],
        [ 0.0137,  0.0139,  0.0163,  ...,  0.0071,  0.0116, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias': tensor([-1.8535,  0.1802,  2.3398,  ..., -0.0595, -0.0338,  0.0305],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight': tensor([[ 0.0028, -0.0249,  0.0077,  ...,  0.0163, -0.0069, -0.0036],
        [ 0.0140, -0.0086,  0.0026,  ...,  0.0077,  0.0073, -0.0239],
        [ 0.0044,  0.0041, -0.0237,  ..., -0.0202, -0.0074,  0.0211],
        ...,
        [-0.0025,  0.0102, -0.0030,  ...,  0.0096,  0.0018,  0.0186],
        [ 0.0052, -0.0034,  0.0046,  ..., -0.0001,  0.0089, -0.0238],
        [-0.0090,  0.0134,  0.0052,  ..., -0.0156, -0.0131,  0.0157]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias': tensor([ 0.0039,  0.0259, -0.0086,  ..., -0.0503, -0.0064, -0.0460],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight': tensor([1.1934, 1.1006, 1.2510,  ..., 1.4092, 1.1592, 1.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias': tensor([ 0.0223, -0.0916,  0.0971,  ..., -0.2983, -0.0408,  0.0070],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight': tensor([[-0.0150,  0.0078,  0.0025,  ..., -0.0011, -0.0016,  0.0092],
        [-0.0219,  0.0313,  0.0128,  ...,  0.0032,  0.0150,  0.0033],
        [-0.0176, -0.0190,  0.0216,  ...,  0.0038, -0.0361,  0.0145],
        ...,
        [ 0.0060, -0.0061, -0.0066,  ...,  0.0027, -0.0050, -0.0172],
        [-0.0283, -0.0057,  0.0115,  ..., -0.0054, -0.0136, -0.0057],
        [-0.0160,  0.0153, -0.0277,  ..., -0.0289, -0.0194,  0.0007]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias': tensor([-0.1221, -0.2144, -0.4114,  ..., -0.1118, -0.1782, -0.3628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight': tensor([[-0.0016,  0.0125, -0.0344,  ..., -0.0221,  0.0044, -0.0154],
        [-0.0039, -0.0351,  0.0205,  ...,  0.0108, -0.0206, -0.0023],
        [ 0.0063, -0.0273, -0.0012,  ...,  0.0131,  0.0057, -0.0150],
        ...,
        [-0.0002, -0.0069,  0.0022,  ..., -0.0065,  0.0032,  0.0088],
        [ 0.0108, -0.0061, -0.0134,  ..., -0.0061,  0.0058, -0.0083],
        [ 0.0133,  0.0173,  0.0049,  ...,  0.0188, -0.0199, -0.0074]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias': tensor([-0.0200,  0.0232, -0.0657,  ...,  0.1028, -0.0782, -0.1134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight': tensor([1.2578, 1.1084, 1.2061,  ..., 0.5884, 1.0264, 1.2910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias': tensor([-0.0061, -0.0651,  0.0878,  ...,  0.1716,  0.1021, -0.0355],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight': tensor([[-0.0184, -0.0017,  0.0284,  ..., -0.0922, -0.0121,  0.0085],
        [ 0.0216,  0.0109,  0.0091,  ..., -0.0531,  0.0165, -0.0052],
        [-0.0036,  0.0282,  0.0128,  ...,  0.0421, -0.0305, -0.0203],
        ...,
        [-0.0003, -0.0044, -0.0082,  ..., -0.0171,  0.0052,  0.0071],
        [ 0.0136, -0.0294, -0.0073,  ..., -0.0191, -0.0179,  0.0170],
        [-0.0079,  0.0298, -0.0092,  ...,  0.0071,  0.0015,  0.0033]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias': tensor([-0.0044, -0.0038, -0.0472,  ...,  0.0818,  0.0363, -0.0465],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight': tensor([[ 1.9028e-02,  3.3264e-03, -1.4641e-02,  ..., -4.6754e-04,
         -1.4366e-02,  1.6556e-02],
        [ 2.1267e-04, -1.5457e-02, -3.2166e-02,  ..., -2.4629e-04,
          5.9090e-03, -9.8267e-03],
        [-1.2535e-02, -1.2222e-02,  9.6970e-03,  ...,  1.7128e-03,
         -2.1992e-03,  3.7842e-03],
        ...,
        [ 1.0918e-02,  1.8097e-02,  1.2695e-02,  ...,  4.8494e-04,
          5.1918e-03, -1.9058e-02],
        [ 9.9792e-03, -1.2085e-02,  6.0320e-04,  ...,  3.4790e-03,
          1.0284e-02,  2.8300e-04],
        [ 2.2034e-02, -1.5373e-03, -2.1362e-02,  ...,  4.9706e-03,
         -4.9174e-05, -6.5117e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias': tensor([ 0.0094,  0.0439, -0.0031,  ..., -0.0485, -0.1193,  0.0170],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight': tensor([[-1.2352e-02,  2.3239e-02,  5.5618e-03,  ..., -5.1178e-02,
         -2.8687e-02,  2.2531e-05],
        [-1.0605e-02, -2.5497e-02,  1.1894e-02,  ..., -2.0462e-02,
         -8.5449e-04,  4.6265e-02],
        [ 8.6212e-03, -9.3765e-03,  5.9357e-03,  ...,  2.0432e-02,
         -2.2537e-02,  4.4495e-02],
        ...,
        [ 1.3062e-02, -5.5428e-03,  1.0025e-02,  ..., -4.5746e-02,
          6.3477e-03,  2.0248e-02],
        [ 9.6588e-03, -1.4442e-02, -2.0096e-02,  ...,  6.9542e-03,
          5.9013e-03, -3.3588e-03],
        [-5.3177e-03,  2.2705e-02, -2.1713e-02,  ...,  2.4307e-02,
          1.5465e-02, -8.3237e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias': tensor([ 0.0542, -0.0733,  0.2440,  ..., -0.3313, -0.1129,  0.1049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight': tensor([[-0.0227,  0.0130, -0.0113,  ..., -0.0045,  0.0108, -0.0190],
        [-0.0057, -0.0069,  0.0119,  ..., -0.0068,  0.0143,  0.0030],
        [ 0.0062,  0.0204,  0.0161,  ..., -0.0079, -0.0057,  0.0308],
        ...,
        [ 0.0001,  0.0003,  0.0048,  ...,  0.0089, -0.0032,  0.0210],
        [-0.0079,  0.0007,  0.0030,  ...,  0.0093, -0.0068, -0.0121],
        [-0.0154,  0.0158, -0.0231,  ..., -0.0158,  0.0141, -0.0072]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias': tensor([-0.0179,  0.0685, -0.0152,  ..., -0.0815,  0.0257,  0.0175],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight': tensor([1.1738, 1.1582, 1.1592,  ..., 1.5869, 1.1748, 1.2314],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias': tensor([-0.0068,  0.0917, -0.0354,  ..., -0.3271, -0.1141, -0.0543],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight': tensor([[-0.0195, -0.0128, -0.0054,  ..., -0.0029, -0.0047,  0.0116],
        [-0.0031, -0.0199,  0.0011,  ..., -0.0044,  0.0127,  0.0019],
        [ 0.0130, -0.0056,  0.0037,  ..., -0.0005,  0.0237,  0.0081],
        ...,
        [ 0.0115,  0.0130, -0.0272,  ...,  0.0021,  0.0227,  0.0057],
        [-0.0035,  0.0108, -0.0211,  ..., -0.0011,  0.0154, -0.0001],
        [-0.0336,  0.0183,  0.0121,  ..., -0.0012, -0.0093,  0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias': tensor([-0.3628, -0.2211, -0.1648,  ..., -0.2524, -0.2686, -0.2517],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight': tensor([[-4.5166e-03,  7.6828e-03,  1.3664e-02,  ..., -2.5959e-03,
         -2.0126e-02, -7.1602e-03],
        [-1.4015e-02,  2.0084e-03,  6.2370e-03,  ...,  1.9714e-02,
         -4.8294e-03, -2.3682e-02],
        [-4.3793e-03,  6.3400e-03,  5.3253e-03,  ...,  9.2888e-04,
          7.6599e-03, -1.8555e-02],
        ...,
        [-4.1809e-03, -1.8768e-03,  4.0741e-03,  ..., -1.5802e-03,
         -3.6144e-03,  8.3983e-05],
        [-2.7523e-03, -2.6489e-02, -1.3283e-02,  ...,  3.4904e-03,
         -1.4786e-02,  6.2981e-03],
        [-3.0880e-03, -2.1713e-02, -1.7853e-02,  ...,  1.1139e-02,
          7.2784e-03, -1.2558e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias': tensor([-0.0283,  0.0284, -0.0329,  ...,  0.0671, -0.0050, -0.0488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight': tensor([1.2725, 1.2539, 1.2041,  ..., 0.7529, 1.0645, 1.2422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias': tensor([ 0.0019, -0.0140,  0.0246,  ...,  0.2150, -0.1251, -0.2118],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0117,  0.0046,  ..., -0.0265, -0.0033,  0.0070],
        [ 0.0061,  0.0207, -0.0110,  ...,  0.0132,  0.0091,  0.0226],
        [-0.0012,  0.0130,  0.0031,  ...,  0.0025,  0.0157,  0.0028],
        ...,
        [ 0.0178,  0.0099,  0.0200,  ...,  0.0006, -0.0303, -0.0324],
        [-0.0035,  0.0138,  0.0245,  ..., -0.0032, -0.0065,  0.0055],
        [-0.0023,  0.0024, -0.0018,  ...,  0.0053,  0.0023, -0.0070]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias': tensor([ 0.1105, -0.0046,  0.0618,  ...,  0.0103, -0.0147,  0.0179],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight': tensor([[ 0.0128, -0.0147,  0.0370,  ..., -0.0059,  0.0019, -0.0157],
        [-0.0200,  0.0040, -0.0021,  ..., -0.0084, -0.0056, -0.0079],
        [-0.0030, -0.0037, -0.0301,  ..., -0.0076,  0.0190,  0.0188],
        ...,
        [ 0.0036,  0.0197, -0.0007,  ..., -0.0078,  0.0181, -0.0004],
        [-0.0112,  0.0034, -0.0117,  ...,  0.0041, -0.0017, -0.0116],
        [-0.0199,  0.0032, -0.0224,  ..., -0.0046,  0.0289,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias': tensor([-0.0085, -0.0267, -0.0139,  ..., -0.0130,  0.0113,  0.0014],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight': tensor([[-5.2223e-03, -1.1261e-02,  2.0859e-02,  ..., -3.4424e-02,
          5.4245e-03,  3.5515e-03],
        [ 2.7637e-03,  4.4861e-03,  5.6877e-03,  ...,  6.7830e-05,
         -1.3123e-02,  1.6266e-02],
        [-7.9575e-03,  6.3133e-03,  1.7059e-02,  ...,  2.5711e-03,
         -5.4283e-03, -1.0437e-02],
        ...,
        [-1.2264e-03,  2.9633e-02, -8.0185e-03,  ...,  1.4366e-02,
          2.8824e-02, -1.8001e-05],
        [ 5.7316e-04,  8.2397e-03,  1.8951e-02,  ...,  1.4248e-03,
          1.8433e-02, -1.7624e-02],
        [ 6.5842e-03,  2.7451e-02, -1.9012e-02,  ...,  1.1887e-02,
         -7.3357e-03,  1.1284e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias': tensor([-0.8462,  0.0103, -1.0879,  ..., -0.1941,  0.1663, -1.2803],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight': tensor([[-0.0020,  0.0252,  0.0039,  ...,  0.0061, -0.0123,  0.0283],
        [ 0.0043,  0.0004, -0.0082,  ..., -0.0251,  0.0068,  0.0017],
        [-0.0231,  0.0006,  0.0164,  ...,  0.0248,  0.0101,  0.0125],
        ...,
        [ 0.0080,  0.0312,  0.0238,  ...,  0.0045,  0.0003,  0.0054],
        [ 0.0077,  0.0073, -0.0009,  ..., -0.0016,  0.0038, -0.0133],
        [ 0.0194, -0.0053, -0.0238,  ...,  0.0249, -0.0041,  0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias': tensor([-0.0205,  0.0181, -0.0017,  ..., -0.0779,  0.0408, -0.0200],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight': tensor([1.1533, 1.2090, 1.1787,  ..., 1.6367, 1.1729, 1.2188],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias': tensor([-0.0550,  0.0990, -0.0018,  ..., -0.1779, -0.0518, -0.0147],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight': tensor([[-0.0073, -0.0223,  0.0130,  ..., -0.0079, -0.0028,  0.0022],
        [-0.0071,  0.0068,  0.0017,  ..., -0.0123, -0.0179, -0.0108],
        [ 0.0072,  0.0217,  0.0110,  ...,  0.0060,  0.0005,  0.0016],
        ...,
        [ 0.0225, -0.0085,  0.0064,  ...,  0.0007,  0.0014, -0.0003],
        [-0.0191,  0.0245,  0.0085,  ..., -0.0102, -0.0108, -0.0063],
        [ 0.0290, -0.0322, -0.0287,  ..., -0.0045,  0.0156, -0.0153]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias': tensor([-0.4795, -0.1469, -0.1043,  ..., -0.2998, -0.2252, -0.3262],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight': tensor([[-0.0205,  0.0170, -0.0019,  ...,  0.0084,  0.0040,  0.0268],
        [ 0.0060,  0.0025, -0.0069,  ...,  0.0071, -0.0261,  0.0028],
        [ 0.0291, -0.0064, -0.0019,  ..., -0.0131,  0.0078, -0.0294],
        ...,
        [-0.0110,  0.0011, -0.0081,  ..., -0.0030,  0.0036, -0.0003],
        [-0.0195,  0.0083,  0.0063,  ...,  0.0095, -0.0105,  0.0214],
        [-0.0028,  0.0316,  0.0016,  ..., -0.0094, -0.0051,  0.0145]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias': tensor([ 0.0411, -0.0040, -0.0517,  ...,  0.1116,  0.0086, -0.0608],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight': tensor([1.3838, 1.2871, 1.2334,  ..., 0.6108, 1.1768, 1.2568],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias': tensor([-0.2367,  0.0573,  0.1235,  ...,  0.2408,  0.0240, -0.0257],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight': tensor([[-0.0176,  0.0033,  0.0183,  ..., -0.0038,  0.0074,  0.0088],
        [-0.0091,  0.0276, -0.0216,  ...,  0.0220,  0.0110,  0.0020],
        [-0.0428, -0.0160,  0.0246,  ...,  0.0130, -0.0163, -0.0116],
        ...,
        [ 0.0326,  0.0183, -0.0093,  ...,  0.0212, -0.0169,  0.0020],
        [ 0.0131,  0.0204,  0.0034,  ...,  0.0138,  0.0030,  0.0125],
        [ 0.0216,  0.0034,  0.0112,  ..., -0.0203,  0.0063, -0.0135]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias': tensor([-0.0005,  0.0142, -0.0017,  ...,  0.0816, -0.0667,  0.0688],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight': tensor([[-0.0305, -0.0173,  0.0406,  ...,  0.0054,  0.0093, -0.0001],
        [ 0.0040,  0.0132, -0.0068,  ..., -0.0034, -0.0217, -0.0175],
        [-0.0051,  0.0121, -0.0121,  ..., -0.0104, -0.0141, -0.0050],
        ...,
        [ 0.0016,  0.0205, -0.0056,  ..., -0.0040, -0.0046,  0.0020],
        [ 0.0378,  0.0040, -0.0073,  ...,  0.0001, -0.0014,  0.0133],
        [ 0.0088, -0.0021, -0.0040,  ..., -0.0019,  0.0257, -0.0056]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias': tensor([-0.0842, -0.0092,  0.0031,  ...,  0.0677, -0.0071,  0.0129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight': tensor([[ 0.0169, -0.0117, -0.0191,  ...,  0.0101, -0.0038,  0.0100],
        [-0.0080,  0.0092,  0.0094,  ...,  0.0197, -0.0175, -0.0183],
        [-0.0264, -0.0041,  0.0021,  ...,  0.0114,  0.0084, -0.0139],
        ...,
        [-0.0015,  0.0094,  0.0175,  ...,  0.0220, -0.0158,  0.0012],
        [-0.0012,  0.0214, -0.0034,  ...,  0.0166, -0.0191,  0.0039],
        [ 0.0204, -0.0130,  0.0074,  ..., -0.0208,  0.0063, -0.0040]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias': tensor([ 0.0173,  0.2045, -0.1959,  ..., -0.0136, -0.0571, -0.2710],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight': tensor([[ 1.1879e-02, -8.7357e-03, -2.2980e-02,  ..., -5.5885e-03,
         -2.6260e-02,  1.4985e-04],
        [ 2.3117e-02, -1.8127e-02,  2.0111e-02,  ..., -5.3711e-03,
         -3.0880e-03, -2.6855e-03],
        [-7.4577e-03,  5.7449e-03, -2.7313e-02,  ...,  2.7695e-03,
          7.9803e-03,  1.0475e-02],
        ...,
        [-1.1810e-02,  1.0620e-02,  1.4153e-02,  ...,  7.8049e-03,
          7.3671e-04,  2.8267e-03],
        [ 6.1150e-03,  1.5244e-02,  2.3621e-02,  ...,  9.0599e-05,
          2.7008e-03, -3.2196e-02],
        [ 3.8743e-04, -6.6109e-03, -1.4534e-02,  ...,  1.1330e-03,
         -1.8280e-02, -3.4065e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias': tensor([-0.0230,  0.0388, -0.0072,  ..., -0.0651,  0.0296, -0.0002],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight': tensor([1.2031, 1.2344, 1.1543,  ..., 1.5986, 1.2275, 1.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias': tensor([-0.0587,  0.0094, -0.0588,  ..., -0.2544, -0.1669, -0.0670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight': tensor([[-0.0105, -0.0159, -0.0260,  ..., -0.0012,  0.0033,  0.0001],
        [ 0.0232, -0.0237,  0.0074,  ..., -0.0032,  0.0108,  0.0003],
        [ 0.0088,  0.0072,  0.0034,  ...,  0.0001, -0.0065,  0.0012],
        ...,
        [ 0.0007, -0.0093,  0.0181,  ..., -0.0021, -0.0059,  0.0082],
        [ 0.0024,  0.0102, -0.0177,  ..., -0.0005, -0.0069, -0.0302],
        [ 0.0112,  0.0245,  0.0004,  ...,  0.0030, -0.0044,  0.0190]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias': tensor([-0.1327, -0.2241, -0.0568,  ..., -0.2708, -0.3245, -0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight': tensor([[ 1.0185e-02, -1.1162e-02, -2.3911e-02,  ...,  2.9709e-02,
         -1.3023e-02, -1.1803e-02],
        [ 8.2092e-03, -4.3631e-04, -3.1257e-04,  ..., -1.3252e-02,
          5.4598e-05, -1.8997e-02],
        [ 5.5885e-03,  1.8112e-02,  9.0179e-03,  ..., -3.1700e-03,
          8.4686e-03, -3.6144e-03],
        ...,
        [ 4.7798e-03,  3.0174e-03, -3.5143e-04,  ...,  5.4665e-03,
         -3.4122e-03, -4.2953e-03],
        [ 3.2082e-03, -1.4816e-02, -9.4986e-04,  ..., -1.9455e-02,
         -9.8825e-05,  9.9869e-03],
        [-7.2784e-03, -5.8289e-03, -3.9062e-03,  ...,  5.5122e-03,
         -2.4323e-02, -2.7542e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias': tensor([ 0.0389,  0.0069, -0.0129,  ...,  0.0417,  0.0218,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight': tensor([1.4287, 1.3613, 1.2949,  ..., 1.0137, 1.1826, 1.3213],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias': tensor([-0.1137,  0.0275,  0.0679,  ...,  0.1796,  0.0205, -0.2534],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight': tensor([[ 0.0030,  0.0209, -0.0001,  ..., -0.0044,  0.0148,  0.0093],
        [-0.0027, -0.0116,  0.0012,  ...,  0.0060, -0.0152, -0.0084],
        [-0.0064,  0.0066, -0.0148,  ..., -0.0031, -0.0160,  0.0061],
        ...,
        [ 0.0134, -0.0141, -0.0170,  ...,  0.0031, -0.0175,  0.0096],
        [ 0.0032, -0.0072,  0.0027,  ...,  0.0026,  0.0248,  0.0016],
        [ 0.0372, -0.0190,  0.0259,  ..., -0.0076,  0.0134,  0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias': tensor([ 0.0132, -0.0158,  0.0312,  ...,  0.1599,  0.0190, -0.0702],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight': tensor([[-0.0019,  0.0161, -0.0136,  ...,  0.0041,  0.0124, -0.0042],
        [ 0.0003, -0.0210,  0.0050,  ...,  0.0030, -0.0272,  0.0083],
        [-0.0101, -0.0327, -0.0195,  ..., -0.0035,  0.0067, -0.0172],
        ...,
        [ 0.0214, -0.0060, -0.0126,  ..., -0.0054, -0.0032,  0.0097],
        [-0.0153, -0.0010, -0.0009,  ...,  0.0023, -0.0131,  0.0013],
        [ 0.0080,  0.0060,  0.0053,  ..., -0.0054, -0.0073,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias': tensor([-0.0223, -0.0200, -0.0063,  ..., -0.0170, -0.0150,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight': tensor([[-0.0132,  0.0006,  0.0249,  ..., -0.0071,  0.0142, -0.0221],
        [-0.0046,  0.0369, -0.0272,  ...,  0.0017,  0.0163,  0.0032],
        [-0.0089, -0.0084,  0.0370,  ..., -0.0099,  0.0085,  0.0120],
        ...,
        [ 0.0223, -0.0226, -0.0282,  ...,  0.0133, -0.0224, -0.0005],
        [ 0.0005, -0.0127, -0.0058,  ..., -0.0071,  0.0076, -0.0049],
        [-0.0067,  0.0026,  0.0143,  ...,  0.0054, -0.0011,  0.0246]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias': tensor([-0.0499, -0.0381,  0.5078,  ..., -0.0939, -1.3535,  0.2761],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight': tensor([[ 0.0038,  0.0181,  0.0089,  ..., -0.0054,  0.0091,  0.0008],
        [-0.0116,  0.0084,  0.0211,  ...,  0.0138,  0.0282, -0.0086],
        [ 0.0388,  0.0029,  0.0070,  ..., -0.0161,  0.0043, -0.0173],
        ...,
        [ 0.0053, -0.0073, -0.0049,  ...,  0.0171, -0.0165,  0.0032],
        [ 0.0020, -0.0032,  0.0069,  ...,  0.0089,  0.0018,  0.0021],
        [ 0.0025, -0.0044,  0.0106,  ..., -0.0193,  0.0141, -0.0083]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias': tensor([ 0.0060,  0.0680,  0.0354,  ..., -0.0553,  0.0136,  0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight': tensor([1.2344, 1.2090, 1.1689,  ..., 1.8428, 1.1562, 1.2676],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias': tensor([-0.0174, -0.0716, -0.1256,  ..., -0.2900, -0.1460,  0.1504],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight': tensor([[-0.0042, -0.0027,  0.0133,  ..., -0.0005,  0.0226, -0.0110],
        [ 0.0404,  0.0308,  0.0195,  ...,  0.0055, -0.0234,  0.0145],
        [-0.0008, -0.0259, -0.0103,  ...,  0.0008,  0.0100,  0.0084],
        ...,
        [ 0.0190, -0.0154,  0.0061,  ..., -0.0111, -0.0397,  0.0165],
        [ 0.0025, -0.0002,  0.0089,  ..., -0.0010, -0.0172, -0.0077],
        [ 0.0183, -0.0069, -0.0037,  ...,  0.0029, -0.0036,  0.0130]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias': tensor([-0.2314, -0.3215, -0.0735,  ..., -0.3020, -0.1613, -0.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight': tensor([[ 1.0155e-02,  3.2532e-02,  8.2626e-03,  ..., -6.4468e-03,
         -4.7760e-03,  5.5432e-06],
        [-1.1612e-02,  1.7509e-03,  2.4841e-02,  ...,  8.9645e-03,
         -2.5436e-02, -8.4152e-03],
        [ 1.5182e-02,  7.3395e-03,  6.1264e-03,  ..., -1.5427e-02,
         -1.8677e-02,  1.9806e-02],
        ...,
        [-5.6686e-03,  6.3848e-04,  4.5128e-03,  ..., -9.9792e-03,
          1.1284e-02,  6.5231e-04],
        [-3.6335e-03,  3.6285e-02, -9.9277e-04,  ...,  4.8828e-03,
          9.6283e-03,  1.3008e-02],
        [ 9.3918e-03, -2.1927e-02, -1.4038e-02,  ...,  1.3329e-02,
          5.4359e-03,  3.3169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias': tensor([0.0373, 0.0198, 0.0018,  ..., 0.0559, 0.0675, 0.0106],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight': tensor([1.4990, 1.4297, 1.3555,  ..., 0.9502, 1.1816, 1.4072],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias': tensor([-0.1736, -0.0029,  0.0179,  ...,  0.2495,  0.0637, -0.1158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight': tensor([[ 0.0138, -0.0022,  0.0212,  ...,  0.0048,  0.0084,  0.0082],
        [-0.0165, -0.0025,  0.0060,  ...,  0.0063,  0.0062, -0.0098],
        [ 0.0116,  0.0009,  0.0094,  ...,  0.0054,  0.0176,  0.0027],
        ...,
        [ 0.0160, -0.0161,  0.0148,  ..., -0.0268,  0.0052,  0.0090],
        [-0.0136,  0.0253, -0.0004,  ...,  0.0156,  0.0059,  0.0038],
        [-0.0080,  0.0130, -0.0251,  ...,  0.0136, -0.0164,  0.0184]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias': tensor([ 0.1146,  1.0303,  0.1827,  ...,  0.0439,  0.0025, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0085, -0.0074,  ...,  0.0006, -0.0214, -0.0142],
        [ 0.0022,  0.0155, -0.0111,  ..., -0.0004, -0.0232, -0.0101],
        [-0.0139,  0.0073, -0.0043,  ..., -0.0005, -0.0110, -0.0235],
        ...,
        [ 0.0153,  0.0130, -0.0090,  ...,  0.0045,  0.0109,  0.0025],
        [ 0.0072,  0.0052, -0.0024,  ..., -0.0120,  0.0016, -0.0072],
        [ 0.0013, -0.0272, -0.0105,  ..., -0.0043,  0.0004, -0.0020]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias': tensor([ 0.0573, -0.0360, -0.0042,  ...,  0.0485, -0.0465,  0.0206],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight': tensor([[ 0.0094,  0.0003,  0.0279,  ...,  0.0015, -0.0191,  0.0090],
        [ 0.0041, -0.0014,  0.0020,  ...,  0.0017, -0.0018,  0.0040],
        [-0.0280,  0.0335,  0.0134,  ...,  0.0017,  0.0047, -0.0206],
        ...,
        [-0.0081, -0.0019,  0.0095,  ..., -0.0111, -0.0239,  0.0087],
        [-0.0195, -0.0019,  0.0218,  ...,  0.0267,  0.0121, -0.0089],
        [-0.0340, -0.0066,  0.0098,  ...,  0.0160,  0.0019, -0.0100]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias': tensor([ 0.2460,  1.7949,  0.0708,  ..., -0.2112,  0.1188,  0.6323],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight': tensor([[ 0.0051,  0.0107, -0.0119,  ..., -0.0148,  0.0005, -0.0302],
        [-0.0066, -0.0071, -0.0048,  ..., -0.0226, -0.0094,  0.0276],
        [ 0.0101,  0.0083,  0.0168,  ..., -0.0064,  0.0009, -0.0152],
        ...,
        [ 0.0094, -0.0071,  0.0016,  ..., -0.0147,  0.0114,  0.0020],
        [ 0.0223,  0.0076,  0.0287,  ..., -0.0214,  0.0006,  0.0041],
        [ 0.0177,  0.0222,  0.0063,  ...,  0.0065,  0.0120, -0.0114]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias': tensor([ 0.0267, -0.0057, -0.0027,  ..., -0.0531, -0.0267,  0.0482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight': tensor([1.2383, 1.2549, 1.2197,  ..., 1.8193, 1.1484, 1.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias': tensor([ 0.1250, -0.0352,  0.1172,  ..., -0.1227, -0.0328,  0.1005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight': tensor([[-0.0007, -0.0112,  0.0090,  ..., -0.0016,  0.0087,  0.0027],
        [ 0.0122, -0.0152,  0.0042,  ..., -0.0079, -0.0033, -0.0148],
        [ 0.0095, -0.0118, -0.0270,  ...,  0.0040,  0.0046, -0.0246],
        ...,
        [-0.0209, -0.0194, -0.0025,  ..., -0.0006, -0.0144,  0.0085],
        [ 0.0016,  0.0133,  0.0006,  ..., -0.0033, -0.0143,  0.0128],
        [-0.0106,  0.0115,  0.0019,  ..., -0.0046, -0.0505,  0.0052]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias': tensor([-0.3506, -0.3098, -0.0692,  ..., -0.3076, -0.2494, -0.4229],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight': tensor([[-0.0116,  0.0186, -0.0109,  ...,  0.0093, -0.0051, -0.0192],
        [ 0.0115,  0.0091,  0.0046,  ...,  0.0060, -0.0104, -0.0086],
        [-0.0004,  0.0162,  0.0221,  ...,  0.0048,  0.0374,  0.0092],
        ...,
        [-0.0029,  0.0068, -0.0073,  ...,  0.0019, -0.0060,  0.0068],
        [ 0.0121, -0.0012, -0.0035,  ..., -0.0168, -0.0036, -0.0015],
        [ 0.0085, -0.0005,  0.0138,  ..., -0.0026,  0.0074, -0.0113]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias': tensor([ 0.0374, -0.0088, -0.0430,  ...,  0.0654, -0.0126, -0.0253],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight': tensor([1.5195, 1.3818, 1.3984,  ..., 0.8403, 1.2627, 1.5020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias': tensor([-0.1865,  0.1162,  0.4048,  ...,  0.2292,  0.4202, -0.0959],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight': tensor([[ 0.0295,  0.0205, -0.0174,  ...,  0.0181,  0.0055,  0.0153],
        [ 0.0159, -0.0236, -0.0138,  ...,  0.0058,  0.0019,  0.0084],
        [-0.0116, -0.0219,  0.0080,  ...,  0.0020, -0.0022,  0.0255],
        ...,
        [-0.0140,  0.0030, -0.0549,  ...,  0.0038, -0.0079,  0.0469],
        [-0.0193,  0.0216, -0.0092,  ...,  0.0083,  0.0186,  0.0123],
        [ 0.0039,  0.0084,  0.0082,  ..., -0.0016, -0.0041, -0.0187]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias': tensor([-0.0278, -0.0587, -0.0110,  ..., -0.0826, -0.0213, -0.0725],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight': tensor([[-0.0007,  0.0020,  0.0042,  ..., -0.0033, -0.0094, -0.0123],
        [ 0.0162,  0.0139,  0.0239,  ..., -0.0017, -0.0188,  0.0138],
        [-0.0234,  0.0133, -0.0101,  ..., -0.0029, -0.0003,  0.0196],
        ...,
        [ 0.0244,  0.0202,  0.0058,  ..., -0.0130,  0.0092, -0.0032],
        [ 0.0215,  0.0236, -0.0171,  ..., -0.0159, -0.0069,  0.0134],
        [-0.0087,  0.0025,  0.0248,  ..., -0.0004,  0.0047, -0.0208]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias': tensor([-0.0305,  0.0005, -0.0124,  ..., -0.0511, -0.0883,  0.0079],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight': tensor([[-0.0156,  0.0022, -0.0072,  ...,  0.0036,  0.0290,  0.0180],
        [-0.0003,  0.0088, -0.0014,  ..., -0.0144, -0.0101,  0.0001],
        [-0.0141, -0.0287,  0.0098,  ..., -0.0024,  0.0292,  0.0254],
        ...,
        [-0.0255,  0.0364, -0.0171,  ...,  0.0032,  0.0116, -0.0182],
        [-0.0159,  0.0349, -0.0009,  ..., -0.0083, -0.0006, -0.0242],
        [-0.0239,  0.0287,  0.0045,  ...,  0.0057, -0.0037, -0.0132]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias': tensor([-0.2856, -0.3130, -0.2024,  ...,  0.1942, -0.0307, -0.0692],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight': tensor([[ 0.0021, -0.0248,  0.0393,  ..., -0.0213, -0.0080,  0.0129],
        [-0.0123, -0.0083,  0.0236,  ..., -0.0091, -0.0172, -0.0205],
        [-0.0194, -0.0024,  0.0146,  ..., -0.0071,  0.0185, -0.0175],
        ...,
        [-0.0277,  0.0011, -0.0187,  ...,  0.0559,  0.0597, -0.0009],
        [ 0.0156,  0.0051, -0.0020,  ..., -0.0031,  0.0066,  0.0040],
        [-0.0057, -0.0281, -0.0138,  ...,  0.0075, -0.0093,  0.0108]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias': tensor([ 0.0077,  0.0031,  0.0012,  ..., -0.0701,  0.0300,  0.0083],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight': tensor([1.2822, 1.2529, 1.2988,  ..., 2.2090, 1.1758, 1.3721],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias': tensor([ 0.1495, -0.0801, -0.0723,  ..., -0.1654, -0.0899,  0.0350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight': tensor([[ 0.0063,  0.0413,  0.0369,  ...,  0.0064,  0.0150,  0.0227],
        [ 0.0141,  0.0154,  0.0189,  ...,  0.0018,  0.0107,  0.0041],
        [-0.0081, -0.0167,  0.0103,  ..., -0.0018, -0.0027,  0.0110],
        ...,
        [ 0.0142,  0.0290,  0.0162,  ..., -0.0030,  0.0042,  0.0023],
        [ 0.0167,  0.0140,  0.0168,  ..., -0.0036, -0.0046,  0.0118],
        [-0.0082,  0.0164,  0.0227,  ...,  0.0009, -0.0199, -0.0222]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias': tensor([-0.2788, -0.1959, -0.3855,  ..., -0.3228, -0.2610, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight': tensor([[-6.8474e-03, -1.1681e-02, -1.7517e-02,  ...,  1.0986e-02,
         -1.8341e-02,  2.0432e-02],
        [ 1.1215e-02, -7.8430e-03, -6.9542e-03,  ...,  1.2108e-02,
         -9.6741e-03, -1.2093e-02],
        [ 1.2321e-02, -2.7924e-02, -2.8896e-03,  ...,  4.8676e-03,
         -2.0275e-03, -1.2695e-02],
        ...,
        [-2.5902e-03,  1.4412e-02, -3.3092e-03,  ..., -2.8193e-05,
          6.4087e-04, -7.4434e-04],
        [-1.8280e-02, -8.6746e-03,  9.6130e-03,  ...,  4.2915e-03,
         -1.1269e-02,  2.3453e-02],
        [-6.6452e-03, -2.1088e-02, -1.2444e-02,  ..., -3.5534e-03,
         -7.8659e-03,  2.5589e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias': tensor([ 0.0329,  0.0112, -0.0181,  ...,  0.0332,  0.0061, -0.0410],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight': tensor([1.6201, 1.4990, 1.4219,  ..., 0.7642, 1.2715, 1.4961],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias': tensor([-0.1376, -0.0238, -0.0118,  ...,  0.3352,  0.1462, -0.0976],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight': tensor([[ 0.0070,  0.0068,  0.0031,  ...,  0.0113, -0.0308, -0.0060],
        [ 0.0026, -0.0039,  0.0043,  ..., -0.0343, -0.0066,  0.0307],
        [-0.0036,  0.0332, -0.0028,  ...,  0.0011, -0.0337,  0.0031],
        ...,
        [-0.0229, -0.0187, -0.0097,  ..., -0.0007,  0.0183, -0.0038],
        [ 0.0047,  0.0152, -0.0175,  ...,  0.0070,  0.0130, -0.0114],
        [-0.0206,  0.0068, -0.0252,  ...,  0.0070, -0.0134, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias': tensor([ 0.1860, -0.2378,  0.0005,  ...,  0.0031,  0.1797, -0.0522],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight': tensor([[-0.0298, -0.0140,  0.0248,  ...,  0.0035, -0.0014, -0.0059],
        [-0.0006, -0.0080,  0.0046,  ...,  0.0036,  0.0106, -0.0112],
        [ 0.0055,  0.0188,  0.0175,  ...,  0.0029, -0.0033, -0.0018],
        ...,
        [ 0.0039, -0.0129,  0.0162,  ...,  0.0032, -0.0222, -0.0056],
        [-0.0039, -0.0104,  0.0050,  ..., -0.0019,  0.0213, -0.0076],
        [ 0.0024,  0.0067, -0.0013,  ..., -0.0021,  0.0013,  0.0046]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias': tensor([ 0.0186, -0.0095,  0.0066,  ...,  0.0210,  0.0131,  0.0208],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight': tensor([[ 0.0029, -0.0233, -0.0027,  ...,  0.0144, -0.0352, -0.0105],
        [-0.0247, -0.0116,  0.0012,  ..., -0.0372,  0.0113, -0.0128],
        [ 0.0080, -0.0012, -0.0150,  ...,  0.0013, -0.0024,  0.0199],
        ...,
        [-0.0113, -0.0235, -0.0017,  ...,  0.0006, -0.0010, -0.0029],
        [ 0.0197, -0.0205, -0.0153,  ...,  0.0061,  0.0182,  0.0045],
        [-0.0173, -0.0083,  0.0412,  ...,  0.0141, -0.0057,  0.0143]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias': tensor([ 0.2690, -0.1337,  0.1326,  ...,  0.5728, -0.2661, -0.0468],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight': tensor([[ 0.0029,  0.0160,  0.0056,  ...,  0.0018,  0.0077, -0.0090],
        [ 0.0110, -0.0064,  0.0049,  ...,  0.0272,  0.0262,  0.0051],
        [-0.0114, -0.0032,  0.0054,  ...,  0.0236, -0.0132, -0.0082],
        ...,
        [-0.0007,  0.0021, -0.0044,  ..., -0.0028, -0.0311, -0.0200],
        [-0.0074, -0.0073, -0.0035,  ..., -0.0198, -0.0346, -0.0070],
        [-0.0123, -0.0216,  0.0046,  ...,  0.0036,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias': tensor([-0.0063, -0.0193, -0.0133,  ...,  0.0398,  0.0332,  0.0196],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight': tensor([1.3359, 1.2266, 1.2646,  ..., 1.9346, 1.1377, 1.3818],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias': tensor([ 0.1417,  0.0006,  0.0168,  ...,  0.0170, -0.0730,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight': tensor([[ 0.0115,  0.0003, -0.0145,  ..., -0.0144, -0.0194, -0.0104],
        [-0.0015,  0.0058,  0.0179,  ..., -0.0030,  0.0044, -0.0100],
        [-0.0029,  0.0045,  0.0084,  ..., -0.0206,  0.0133,  0.0283],
        ...,
        [ 0.0059, -0.0118, -0.0161,  ..., -0.0221, -0.0054,  0.0157],
        [ 0.0215, -0.0010,  0.0022,  ...,  0.0130,  0.0179,  0.0099],
        [ 0.0113,  0.0054, -0.0108,  ...,  0.0036,  0.0090, -0.0237]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias': tensor([-0.2153, -0.2783, -0.3320,  ..., -0.1221, -0.1306, -0.2898],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight': tensor([[-0.0038, -0.0308,  0.0166,  ..., -0.0028, -0.0180,  0.0016],
        [ 0.0179,  0.0086,  0.0044,  ...,  0.0105,  0.0129, -0.0061],
        [-0.0078, -0.0048,  0.0276,  ...,  0.0158, -0.0102,  0.0017],
        ...,
        [-0.0093,  0.0032, -0.0129,  ...,  0.0116, -0.0041, -0.0039],
        [-0.0126,  0.0043,  0.0086,  ...,  0.0042, -0.0106,  0.0038],
        [-0.0054, -0.0066, -0.0067,  ..., -0.0130, -0.0257,  0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias': tensor([ 0.0253, -0.0025, -0.0242,  ...,  0.0955,  0.0208, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight': tensor([1.6533, 1.5479, 1.5508,  ..., 0.4094, 1.3984, 1.6689],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias': tensor([-0.2152,  0.1279,  0.3982,  ...,  0.3850,  0.3862, -0.2152],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight': tensor([[ 0.0007,  0.0003,  0.0054,  ...,  0.0126,  0.0008,  0.0107],
        [-0.0359,  0.0132, -0.0041,  ..., -0.0473,  0.0050, -0.0005],
        [ 0.0122, -0.0012, -0.0178,  ..., -0.0031,  0.0207, -0.0100],
        ...,
        [ 0.0512, -0.0152, -0.0452,  ...,  0.0250, -0.0268,  0.0074],
        [ 0.0115,  0.0260, -0.0071,  ...,  0.0085,  0.0057,  0.0017],
        [ 0.0223, -0.0031, -0.0004,  ...,  0.0035, -0.0175,  0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias': tensor([-0.8135, -0.1840,  0.0576,  ..., -0.0189,  0.0277,  0.0699],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight': tensor([[ 2.6184e-02,  6.5842e-03, -6.6528e-03,  ...,  2.3901e-05,
          1.5297e-02, -1.9302e-02],
        [ 4.0741e-03,  3.0079e-03,  3.1090e-03,  ..., -9.0485e-03,
          1.0986e-02,  4.2953e-03],
        [ 4.1504e-03,  1.6336e-03, -1.1185e-02,  ...,  5.6496e-03,
          2.0889e-02, -1.3113e-04],
        ...,
        [-3.6945e-03,  1.4648e-02, -8.8348e-03,  ...,  8.1711e-03,
         -2.6073e-03,  1.3008e-02],
        [ 1.9562e-02, -1.5762e-02,  7.0877e-03,  ...,  6.5517e-04,
         -2.1744e-02, -2.0233e-02],
        [ 1.8417e-02, -1.2039e-02, -9.2239e-03,  ..., -4.6659e-04,
         -1.3191e-02, -7.4272e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias': tensor([ 0.0088,  0.0188,  0.0441,  ..., -0.0099, -0.0044,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight': tensor([[-0.0029,  0.0020, -0.0026,  ...,  0.0042, -0.0110, -0.0049],
        [-0.0278,  0.0302,  0.0003,  ..., -0.0331,  0.0236,  0.0125],
        [ 0.0239,  0.0206,  0.0083,  ..., -0.0029,  0.0212, -0.0040],
        ...,
        [ 0.0231,  0.0166, -0.0169,  ...,  0.0415, -0.0144,  0.0037],
        [ 0.0159,  0.0033, -0.0034,  ...,  0.0044, -0.0091,  0.0034],
        [ 0.0106, -0.0117, -0.0165,  ...,  0.0030, -0.0196,  0.0211]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias': tensor([-2.5234,  0.2341, -0.3838,  ..., -0.0643,  0.1272,  0.1238],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight': tensor([[-0.0296, -0.0036,  0.0027,  ...,  0.0065,  0.0073, -0.0128],
        [-0.0154, -0.0153,  0.0213,  ...,  0.0241,  0.0144,  0.0159],
        [-0.0073, -0.0148,  0.0064,  ...,  0.0165,  0.0177,  0.0191],
        ...,
        [-0.0013,  0.0025, -0.0111,  ..., -0.0081,  0.0079,  0.0101],
        [-0.0041, -0.0076, -0.0202,  ..., -0.0055,  0.0170,  0.0018],
        [ 0.0106, -0.0025,  0.0060,  ...,  0.0055, -0.0079,  0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias': tensor([ 0.0107, -0.0549,  0.0179,  ...,  0.0266,  0.0321, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight': tensor([1.3027, 1.2529, 1.3281,  ..., 1.4834, 1.1562, 1.3789],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias': tensor([ 0.1531,  0.0493, -0.0565,  ..., -0.0096, -0.0239, -0.0371],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight': tensor([[ 0.0043,  0.0120,  0.0113,  ..., -0.0241, -0.0064, -0.0090],
        [ 0.0006, -0.0211, -0.0018,  ..., -0.0029, -0.0108,  0.0110],
        [ 0.0030,  0.0094, -0.0028,  ..., -0.0025, -0.0057,  0.0185],
        ...,
        [-0.0027, -0.0314, -0.0122,  ..., -0.0098, -0.0206, -0.0127],
        [-0.0042,  0.0269, -0.0155,  ..., -0.0024, -0.0119, -0.0034],
        [-0.0102,  0.0069, -0.0109,  ..., -0.0012,  0.0015, -0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias': tensor([-0.2781, -0.2573, -0.3364,  ..., -0.3469, -0.2040, -0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight': tensor([[ 0.0010, -0.0122,  0.0169,  ...,  0.0076, -0.0051,  0.0080],
        [ 0.0136, -0.0151, -0.0033,  ..., -0.0080,  0.0146, -0.0023],
        [ 0.0173, -0.0216,  0.0123,  ...,  0.0066, -0.0024, -0.0003],
        ...,
        [-0.0117,  0.0076, -0.0053,  ...,  0.0010,  0.0026,  0.0003],
        [-0.0175,  0.0074, -0.0194,  ..., -0.0246, -0.0096, -0.0045],
        [ 0.0076,  0.0037,  0.0206,  ...,  0.0206, -0.0109,  0.0051]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias': tensor([ 0.0366, -0.0981, -0.0667,  ...,  0.0356,  0.0194, -0.0255],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight': tensor([1.7695, 1.6426, 1.7236,  ..., 0.6680, 1.5166, 1.7900],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias': tensor([-0.1890,  0.3459,  0.1487,  ...,  0.4136,  0.4312, -0.1221],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight': tensor([[ 0.0141,  0.0079,  0.0303,  ..., -0.0145,  0.0041,  0.0001],
        [-0.0112,  0.0048,  0.0240,  ..., -0.0055, -0.0139,  0.0003],
        [ 0.0167,  0.0107,  0.0269,  ..., -0.0065,  0.0130, -0.0072],
        ...,
        [-0.0014,  0.0062,  0.0020,  ..., -0.0017,  0.0170, -0.0246],
        [-0.0123, -0.0318, -0.0099,  ..., -0.0016, -0.0070, -0.0297],
        [ 0.0025,  0.0103,  0.0089,  ...,  0.0022,  0.0038,  0.0318]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias': tensor([-0.0931,  0.0089, -0.0538,  ...,  0.1041,  0.1436,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight': tensor([[-0.0085,  0.0049, -0.0003,  ...,  0.0036, -0.0302,  0.0040],
        [ 0.0075, -0.0265, -0.0065,  ..., -0.0031,  0.0134, -0.0018],
        [-0.0087, -0.0006, -0.0056,  ...,  0.0055,  0.0154,  0.0372],
        ...,
        [-0.0022, -0.0078,  0.0144,  ...,  0.0019, -0.0084,  0.0115],
        [ 0.0047, -0.0127, -0.0223,  ..., -0.0021, -0.0109,  0.0101],
        [-0.0105, -0.0005, -0.0008,  ..., -0.0030, -0.0079, -0.0039]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias': tensor([-0.0321,  0.0378,  0.0632,  ...,  0.0502, -0.0048, -0.0005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight': tensor([[-0.0095, -0.0095,  0.0312,  ...,  0.0022, -0.0092,  0.0262],
        [-0.0264, -0.0028, -0.0018,  ..., -0.0075, -0.0155, -0.0109],
        [-0.0025, -0.0001,  0.0389,  ..., -0.0119,  0.0128, -0.0002],
        ...,
        [ 0.0271, -0.0069,  0.0122,  ...,  0.0018,  0.0167, -0.0080],
        [ 0.0080, -0.0216,  0.0023,  ...,  0.0015, -0.0140,  0.0002],
        [-0.0039,  0.0055,  0.0021,  ...,  0.0071, -0.0103,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias': tensor([-0.2311,  0.2390, -0.0950,  ...,  0.0876,  0.1581,  0.0798],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight': tensor([[-0.0281, -0.0058,  0.0026,  ..., -0.0079,  0.0053, -0.0023],
        [ 0.0130, -0.0057, -0.0072,  ..., -0.0006, -0.0015, -0.0051],
        [-0.0112,  0.0132,  0.0089,  ..., -0.0184,  0.0022, -0.0036],
        ...,
        [ 0.0086,  0.0047, -0.0106,  ..., -0.0117, -0.0147, -0.0069],
        [ 0.0147, -0.0031, -0.0165,  ...,  0.0125, -0.0091,  0.0107],
        [ 0.0214,  0.0008, -0.0262,  ..., -0.0205, -0.0144,  0.0057]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias': tensor([-0.0645, -0.0639,  0.0044,  ..., -0.0346, -0.0156, -0.0320],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight': tensor([1.3975, 1.3584, 1.4883,  ..., 1.8799, 1.3203, 1.4980],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias': tensor([ 0.0757, -0.1133, -0.0580,  ..., -0.0255, -0.0899, -0.1061],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight': tensor([[-7.1793e-03,  4.6234e-03,  1.7502e-02,  ..., -1.0124e-02,
          1.3245e-02, -6.4430e-03],
        [-1.6571e-02,  1.1040e-02, -5.1537e-03,  ..., -6.7616e-04,
         -2.2491e-02, -9.1019e-03],
        [-7.6675e-04,  2.2156e-02,  1.0216e-02,  ..., -4.4708e-03,
         -1.6510e-02, -2.4704e-02],
        ...,
        [-2.9205e-02, -7.1602e-03,  8.7559e-05,  ..., -9.7656e-03,
          1.6312e-02,  2.7145e-02],
        [-1.2413e-02,  6.9084e-03,  2.4399e-02,  ..., -7.0381e-03,
         -7.9803e-03,  9.6130e-03],
        [ 6.4039e-04, -4.3259e-03,  4.3121e-02,  ..., -3.9101e-03,
         -1.3245e-02,  1.4565e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias': tensor([-0.3418, -0.2771, -0.3467,  ..., -0.3992, -0.2385, -0.2927],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight': tensor([[-9.4452e-03,  1.2772e-02,  1.8539e-02,  ..., -2.6276e-02,
          4.2343e-04, -1.3672e-02],
        [ 3.2593e-02,  8.7070e-04, -2.8477e-03,  ..., -8.7814e-03,
          1.1383e-02, -3.0182e-02],
        [-4.3488e-03, -2.7359e-02,  1.8482e-03,  ..., -6.5002e-03,
          2.6016e-02,  3.3539e-02],
        ...,
        [-4.1504e-03,  1.6251e-02,  7.8354e-03,  ...,  1.4816e-02,
         -1.9627e-03, -6.3002e-05],
        [ 6.4125e-03, -1.6647e-02,  4.3945e-03,  ...,  1.2833e-02,
         -1.5268e-03, -1.7975e-02],
        [-1.8167e-03, -1.1734e-02, -1.4511e-02,  ...,  3.0396e-02,
          1.1108e-02, -9.7580e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias': tensor([-0.0361, -0.0392,  0.0150,  ..., -0.0163,  0.0041, -0.0078],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight': tensor([2.1113, 2.0137, 2.0352,  ..., 0.7090, 1.8164, 2.2012],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias': tensor([-0.1631, -0.1508,  0.1484,  ...,  0.4434,  0.6812, -0.3279],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight': tensor([[-9.9716e-03, -2.5208e-02,  8.4457e-03,  ...,  1.3168e-02,
         -5.3942e-05, -2.8748e-02],
        [-3.1233e-05,  1.3992e-02, -2.2476e-02,  ...,  6.3232e-02,
         -1.4221e-02, -1.4404e-02],
        [-5.1785e-04, -3.1403e-02,  6.5517e-04,  ..., -1.0399e-02,
          1.1505e-02, -2.8076e-03],
        ...,
        [-6.2132e-04, -1.0201e-02,  1.3947e-02,  ..., -5.4810e-02,
         -8.1787e-03, -2.0981e-02],
        [ 9.8572e-03, -1.7899e-02,  1.1734e-02,  ..., -4.1885e-03,
          1.4870e-02,  1.1244e-03],
        [ 1.5884e-02,  2.2827e-02,  4.2000e-03,  ..., -4.3091e-02,
         -2.2690e-02, -1.3191e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias': tensor([ 0.2656, -0.2185,  0.0432,  ..., -0.1787, -0.2061,  0.0742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight': tensor([[ 0.0261,  0.0077, -0.0120,  ..., -0.0027, -0.0164, -0.0107],
        [-0.0080,  0.0102,  0.0077,  ...,  0.0039,  0.0010, -0.0050],
        [ 0.0017, -0.0101, -0.0256,  ...,  0.0058, -0.0145, -0.0055],
        ...,
        [-0.0161,  0.0100, -0.0047,  ..., -0.0049, -0.0208,  0.0245],
        [ 0.0115, -0.0098,  0.0141,  ...,  0.0035, -0.0129, -0.0005],
        [-0.0111, -0.0270,  0.0220,  ..., -0.0022, -0.0052, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias': tensor([-0.0182,  0.0114,  0.1055,  ..., -0.0048, -0.0138,  0.0093],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight': tensor([[-0.0116, -0.0250, -0.0204,  ...,  0.0060, -0.0022, -0.0020],
        [ 0.0243,  0.0011, -0.0106,  ...,  0.0480, -0.0213,  0.0138],
        [ 0.0116, -0.0210, -0.0045,  ..., -0.0067, -0.0268, -0.0189],
        ...,
        [ 0.0013,  0.0050,  0.0468,  ..., -0.0500,  0.0203,  0.0043],
        [ 0.0273, -0.0117,  0.0099,  ..., -0.0033, -0.0067,  0.0015],
        [-0.0062,  0.0012,  0.0167,  ..., -0.0361, -0.0010,  0.0275]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias': tensor([ 0.2439, -0.1146,  0.0887,  ...,  0.2213,  0.1515, -0.0186],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight': tensor([[-3.0136e-02,  1.2367e-02, -9.5749e-03,  ...,  1.8692e-02,
          9.2697e-03, -4.0054e-03],
        [-3.6682e-02, -9.7504e-03,  7.6950e-05,  ..., -1.0941e-02,
          8.2474e-03, -8.6546e-04],
        [ 1.9424e-02, -2.1729e-02,  5.8022e-03,  ...,  6.4888e-03,
         -4.6577e-03, -6.9504e-03],
        ...,
        [-7.0953e-03, -1.1024e-02,  1.4248e-03,  ...,  3.1490e-03,
         -7.8735e-03, -1.8097e-02],
        [ 1.8778e-03, -1.1490e-02, -8.2855e-03,  ..., -1.9104e-02,
          7.3166e-03, -8.8959e-03],
        [-8.1558e-03,  1.7426e-02,  1.1551e-02,  ..., -4.8790e-03,
          5.9700e-03,  9.9030e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias': tensor([-0.0732,  0.0212,  0.0239,  ...,  0.0091, -0.0001, -0.0141],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight': tensor([1.3848, 1.3320, 1.4814,  ..., 1.5195, 1.3164, 1.4180],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias': tensor([ 0.0473, -0.0936, -0.0594,  ...,  0.0325,  0.0149, -0.0659],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight': tensor([[ 1.5793e-02, -8.3160e-03,  2.2156e-02,  ...,  1.8814e-02,
         -5.4436e-03, -1.1604e-02],
        [ 1.5007e-02, -9.5978e-03, -2.5284e-02,  ..., -1.6510e-02,
         -3.3539e-02, -2.3102e-02],
        [-2.1622e-02,  2.0309e-02,  2.1801e-03,  ...,  7.5798e-03,
          1.4145e-02, -7.3433e-03],
        ...,
        [-4.5624e-03, -2.5757e-02,  6.9199e-03,  ...,  3.5572e-03,
          1.4694e-02, -2.2339e-02],
        [-9.1791e-06,  7.1487e-03, -1.3298e-02,  ...,  5.6610e-03,
          4.4975e-03,  1.1978e-02],
        [-5.8289e-03,  5.1689e-03, -1.4862e-02,  ...,  1.8585e-02,
          9.6655e-04,  1.1856e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias': tensor([-0.2683, -0.3921, -0.3279,  ..., -0.3718, -0.2028, -0.3127],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight': tensor([[-0.0059, -0.0140,  0.0130,  ...,  0.0043,  0.0292, -0.0014],
        [ 0.0265, -0.0073, -0.0116,  ..., -0.0211,  0.0206,  0.0263],
        [ 0.0022, -0.0233,  0.0002,  ...,  0.0067, -0.0096, -0.0120],
        ...,
        [ 0.0080, -0.0016,  0.0073,  ..., -0.0021, -0.0057, -0.0010],
        [ 0.0048, -0.0163, -0.0040,  ...,  0.0130, -0.0188,  0.0429],
        [-0.0011, -0.0383, -0.0151,  ..., -0.0132,  0.0248,  0.0216]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias': tensor([ 0.0359,  0.0342,  0.0545,  ...,  0.0745, -0.0070,  0.0030],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight': tensor([2.5176, 2.3496, 2.4785,  ..., 0.5151, 2.0352, 2.4492],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias': tensor([-0.2339, -0.0297,  0.1533,  ...,  0.4067,  0.7363, -0.2054],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0246, -0.0315,  ...,  0.0246, -0.0050,  0.0121],
        [ 0.0096,  0.0193,  0.0106,  ..., -0.0207, -0.0075,  0.0043],
        [ 0.0199,  0.0022, -0.0148,  ..., -0.0771, -0.0211,  0.0064],
        ...,
        [ 0.0369,  0.0040, -0.0087,  ..., -0.0215,  0.0106,  0.0167],
        [-0.0061, -0.0050, -0.0032,  ..., -0.0078,  0.0147,  0.0186],
        [ 0.0009,  0.0079, -0.0195,  ..., -0.0096, -0.0309,  0.0012]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias': tensor([ 0.0911, -0.1252, -0.4846,  ...,  0.0673, -0.0733,  0.0197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight': tensor([[ 0.0141,  0.0237,  0.0094,  ..., -0.0007, -0.0127, -0.0134],
        [ 0.0092, -0.0071,  0.0201,  ...,  0.0027, -0.0176, -0.0013],
        [ 0.0039, -0.0016, -0.0055,  ...,  0.0065, -0.0001, -0.0049],
        ...,
        [ 0.0073, -0.0355, -0.0101,  ...,  0.0047, -0.0010, -0.0099],
        [-0.0019,  0.0097, -0.0335,  ..., -0.0019,  0.0006, -0.0019],
        [ 0.0030, -0.0076,  0.0026,  ..., -0.0004,  0.0043, -0.0152]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias': tensor([ 0.0290,  0.0252,  0.0343,  ...,  0.0027, -0.0045, -0.0545],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight': tensor([[ 0.0060, -0.0019, -0.0088,  ...,  0.0198, -0.0025, -0.0177],
        [ 0.0059,  0.0067,  0.0215,  ..., -0.0244, -0.0294,  0.0024],
        [ 0.0271,  0.0004, -0.0182,  ..., -0.0876,  0.0076, -0.0006],
        ...,
        [-0.0081,  0.0160, -0.0380,  ..., -0.0249, -0.0083,  0.0045],
        [ 0.0112, -0.0182, -0.0261,  ..., -0.0056, -0.0009, -0.0319],
        [ 0.0435,  0.0031,  0.0118,  ..., -0.0163,  0.0102, -0.0193]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias': tensor([ 0.0622,  0.0999, -0.5308,  ..., -0.1455,  0.0368, -0.1086],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight': tensor([[ 4.6425e-03, -2.0313e-03,  2.7237e-02,  ...,  1.0216e-02,
         -2.0187e-02,  1.1955e-02],
        [-5.8823e-03,  2.6627e-02,  7.8506e-03,  ...,  3.9864e-03,
         -1.8646e-02,  2.6762e-05],
        [-5.6601e-04,  5.0240e-03,  2.1591e-02,  ...,  1.1375e-02,
          6.1035e-03,  7.7581e-04],
        ...,
        [ 9.0256e-03, -4.1656e-03, -1.2932e-02,  ...,  9.0778e-05,
          1.9577e-02, -6.6452e-03],
        [ 1.5488e-02,  5.1928e-04,  1.3100e-02,  ..., -2.1057e-02,
         -4.6921e-03,  1.0338e-02],
        [ 3.2501e-03, -2.0432e-02, -2.8076e-02,  ..., -8.2169e-03,
         -2.1858e-03,  3.8376e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias': tensor([ 0.0169,  0.0075, -0.0464,  ...,  0.0064, -0.0125, -0.0271],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight': tensor([1.4844, 1.5352, 1.5859,  ..., 1.5234, 1.4395, 1.5938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias': tensor([ 0.1630, -0.0892, -0.0373,  ..., -0.0082, -0.0609, -0.1628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight': tensor([[-0.0057, -0.0090,  0.0211,  ...,  0.0072, -0.0180, -0.0063],
        [ 0.0278,  0.0188,  0.0136,  ..., -0.0074,  0.0133, -0.0087],
        [-0.0168,  0.0028, -0.0226,  ..., -0.0184, -0.0072, -0.0020],
        ...,
        [ 0.0011, -0.0155, -0.0045,  ..., -0.0092, -0.0268,  0.0125],
        [ 0.0054, -0.0030,  0.0160,  ...,  0.0257, -0.0181, -0.0068],
        [ 0.0045,  0.0018,  0.0164,  ..., -0.0108, -0.0191, -0.0004]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias': tensor([-0.2793, -0.3452, -0.2959,  ..., -0.1838, -0.1981, -0.2494],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight': tensor([[-0.0017, -0.0146,  0.0010,  ...,  0.0037, -0.0001,  0.0201],
        [ 0.0174, -0.0161, -0.0016,  ..., -0.0007, -0.0096, -0.0005],
        [ 0.0072,  0.0077, -0.0210,  ...,  0.0165, -0.0019, -0.0208],
        ...,
        [ 0.0195, -0.0092,  0.0151,  ..., -0.0062, -0.0071, -0.0216],
        [ 0.0159,  0.0006,  0.0077,  ..., -0.0073,  0.0030,  0.0091],
        [ 0.0062,  0.0206,  0.0089,  ...,  0.0090, -0.0033, -0.0063]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias': tensor([0.0065, 0.0102, 0.0046,  ..., 0.0065, 0.0796, 0.0695],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight': tensor([2.6719, 2.5625, 2.7695,  ..., 0.6802, 2.2539, 2.7422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias': tensor([-0.0354,  0.2776,  0.4175,  ...,  0.5674,  0.5327, -0.4670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight': tensor([[-0.0087,  0.0027,  0.0113,  ..., -0.0616,  0.0051, -0.0137],
        [-0.0173,  0.0047,  0.0124,  ...,  0.0239, -0.0160,  0.0129],
        [ 0.0097, -0.0005, -0.0050,  ...,  0.0011,  0.0099, -0.0130],
        ...,
        [-0.0052,  0.0120,  0.0098,  ..., -0.0244,  0.0038,  0.0010],
        [ 0.0119, -0.0235, -0.0134,  ..., -0.0140, -0.0140,  0.0065],
        [ 0.0291,  0.0226, -0.0254,  ..., -0.0035, -0.0137,  0.0350]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias': tensor([ 0.2783, -0.2036, -0.0648,  ...,  0.1705,  0.1809,  0.1080],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight': tensor([[-0.0184,  0.0137,  0.0067,  ..., -0.0029,  0.0099,  0.0297],
        [-0.0110,  0.0184,  0.0020,  ...,  0.0024, -0.0151,  0.0009],
        [ 0.0191, -0.0126,  0.0212,  ...,  0.0024, -0.0348,  0.0026],
        ...,
        [ 0.0005,  0.0007, -0.0011,  ...,  0.0046, -0.0222, -0.0393],
        [ 0.0117,  0.0042,  0.0002,  ..., -0.0006,  0.0005, -0.0083],
        [-0.0062,  0.0128,  0.0124,  ..., -0.0037, -0.0134,  0.0008]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias': tensor([-0.0114,  0.0300,  0.0252,  ..., -0.0060,  0.0197,  0.0400],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight': tensor([[ 1.4931e-02, -1.2466e-02,  2.4918e-02,  ..., -5.9814e-02,
         -4.3068e-03,  1.2131e-02],
        [-1.6464e-02, -9.9030e-03, -1.1108e-02,  ...,  2.3956e-02,
         -3.6163e-02,  1.1703e-02],
        [ 1.0757e-02,  2.5730e-03, -7.3338e-04,  ...,  2.4662e-03,
          6.1493e-03,  6.6528e-03],
        ...,
        [ 5.1003e-03, -7.8678e-06,  5.1041e-03,  ..., -4.5410e-02,
         -3.1738e-02,  1.8631e-02],
        [ 1.7502e-02, -4.1084e-03,  3.9978e-03,  ..., -1.8753e-02,
         -2.2335e-03,  2.1057e-03],
        [ 1.7303e-02,  6.7902e-03,  1.1360e-02,  ...,  8.0719e-03,
         -5.0278e-03,  2.1713e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias': tensor([-0.2339,  0.0393, -0.0323,  ..., -0.1953,  0.0200,  0.0049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight': tensor([[ 0.0254,  0.0050,  0.0049,  ...,  0.0120, -0.0121,  0.0091],
        [ 0.0248, -0.0193, -0.0093,  ..., -0.0044, -0.0032,  0.0151],
        [ 0.0053,  0.0182, -0.0142,  ..., -0.0130, -0.0033, -0.0087],
        ...,
        [ 0.0006, -0.0051, -0.0173,  ...,  0.0031, -0.0128,  0.0099],
        [ 0.0081, -0.0134,  0.0246,  ...,  0.0185, -0.0136,  0.0109],
        [-0.0261, -0.0152, -0.0080,  ...,  0.0230, -0.0056,  0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias': tensor([-0.0083,  0.0091, -0.0955,  ..., -0.0067,  0.0003, -0.0047],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight': tensor([1.5762, 1.4580, 1.5850,  ..., 1.7383, 1.4209, 1.5967],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias': tensor([ 0.1272, -0.2208, -0.0098,  ..., -0.0831, -0.0858, -0.1576],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight': tensor([[-0.0051,  0.0014, -0.0012,  ...,  0.0091, -0.0065, -0.0086],
        [-0.0191,  0.0118,  0.0002,  ..., -0.0095, -0.0148,  0.0134],
        [-0.0012, -0.0324,  0.0047,  ..., -0.0084,  0.0050, -0.0089],
        ...,
        [ 0.0005, -0.0097, -0.0229,  ..., -0.0036, -0.0164, -0.0044],
        [ 0.0058, -0.0019, -0.0019,  ...,  0.0053,  0.0177,  0.0073],
        [ 0.0128,  0.0044, -0.0019,  ..., -0.0147,  0.0180, -0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias': tensor([-0.1597, -0.3298, -0.3066,  ..., -0.3003, -0.3157, -0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight': tensor([[-0.0060, -0.0143,  0.0279,  ..., -0.0150,  0.0291,  0.0124],
        [ 0.0095, -0.0208, -0.0114,  ...,  0.0116, -0.0289,  0.0051],
        [-0.0165,  0.0403, -0.0052,  ...,  0.0008, -0.0144, -0.0153],
        ...,
        [-0.0120,  0.0119, -0.0007,  ...,  0.0051,  0.0161, -0.0073],
        [ 0.0291,  0.0090, -0.0140,  ...,  0.0286,  0.0029, -0.0079],
        [ 0.0233, -0.0179, -0.0138,  ..., -0.0036, -0.0180, -0.0041]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias': tensor([ 0.0113,  0.0318, -0.0128,  ..., -0.0561, -0.0155,  0.0321],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight': tensor([2.7773, 2.7402, 2.7402,  ..., 0.8696, 2.4961, 2.8711],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias': tensor([-0.1473, -0.0198,  0.2091,  ...,  0.4590,  0.5410, -0.2742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight': tensor([[ 0.0005, -0.0174, -0.0133,  ..., -0.0195,  0.0176,  0.0196],
        [ 0.0332, -0.0111, -0.0092,  ..., -0.0143,  0.0277, -0.0138],
        [-0.0094,  0.0108, -0.0135,  ..., -0.0078, -0.0209, -0.0013],
        ...,
        [ 0.0136,  0.0224,  0.0235,  ..., -0.0533, -0.0095,  0.0097],
        [-0.0183, -0.0031, -0.0219,  ..., -0.0209, -0.0113,  0.0082],
        [ 0.0187,  0.0257,  0.0352,  ..., -0.0150,  0.0010,  0.0060]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias': tensor([-0.2089,  0.1558,  0.3555,  ...,  0.0323,  0.1013,  0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight': tensor([[-0.0096,  0.0058, -0.0198,  ...,  0.0084,  0.0249,  0.0066],
        [ 0.0346, -0.0048, -0.0196,  ..., -0.0008, -0.0481, -0.0151],
        [-0.0034,  0.0091,  0.0039,  ..., -0.0047,  0.0017, -0.0073],
        ...,
        [-0.0277, -0.0315,  0.0064,  ..., -0.0131, -0.0027,  0.0125],
        [ 0.0013,  0.0095,  0.0286,  ..., -0.0024,  0.0112,  0.0018],
        [-0.0154,  0.0043, -0.0169,  ...,  0.0051,  0.0013, -0.0213]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias': tensor([0.0214, 0.0242, 0.0006,  ..., 0.0194, 0.0418, 0.0340],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight': tensor([[-0.0110, -0.0187, -0.0399,  ..., -0.0132,  0.0016,  0.0080],
        [ 0.0197,  0.0169,  0.0061,  ..., -0.0240,  0.0292,  0.0127],
        [-0.0047, -0.0227, -0.0048,  ..., -0.0150, -0.0014,  0.0108],
        ...,
        [-0.0113,  0.0006, -0.0214,  ..., -0.0389, -0.0254,  0.0096],
        [ 0.0066,  0.0193,  0.0392,  ...,  0.0004,  0.0306, -0.0154],
        [-0.0041,  0.0141, -0.0124,  ..., -0.0156, -0.0206,  0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias': tensor([-0.0377, -0.0410, -0.0185,  ..., -0.2778,  0.1395,  0.1525],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight': tensor([[-1.2112e-03,  2.4259e-05, -4.5753e-04,  ...,  4.1847e-03,
          3.2597e-03, -3.2745e-02],
        [-1.3557e-02, -5.1613e-03,  2.0218e-02,  ..., -7.0801e-03,
         -2.9678e-02, -3.8872e-03],
        [-2.0355e-02, -4.8676e-03,  1.2039e-02,  ...,  1.1337e-02,
         -5.5161e-03, -1.0376e-02],
        ...,
        [ 1.2032e-02,  1.7944e-02, -4.4212e-03,  ...,  3.3722e-02,
         -1.9394e-02, -2.0691e-02],
        [-1.6998e-02,  2.0340e-02, -9.7885e-03,  ..., -4.0588e-03,
          4.5967e-03, -7.2937e-03],
        [-1.6357e-02, -1.8204e-02,  1.9684e-02,  ...,  1.2749e-02,
         -2.2552e-02, -1.4832e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias': tensor([-0.0427,  0.0264, -0.0947,  ..., -0.0744, -0.0230, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight': tensor([1.6475, 1.5273, 1.6768,  ..., 1.8574, 1.4951, 1.6426],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias': tensor([-0.0313, -0.3167, -0.0297,  ..., -0.0391, -0.0746, -0.2402],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight': tensor([[-0.0260, -0.0154,  0.0028,  ..., -0.0228, -0.0295, -0.0447],
        [ 0.0029, -0.0058,  0.0197,  ...,  0.0138,  0.0183,  0.0026],
        [ 0.0218, -0.0178,  0.0015,  ..., -0.0087,  0.0014,  0.0125],
        ...,
        [ 0.0404,  0.0179, -0.0153,  ...,  0.0049,  0.0196, -0.0120],
        [ 0.0015, -0.0189,  0.0088,  ...,  0.0184, -0.0162, -0.0341],
        [ 0.0035, -0.0139, -0.0161,  ...,  0.0040, -0.0222, -0.0067]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias': tensor([-0.3091, -0.1617, -0.2668,  ..., -0.2510, -0.2261, -0.2350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight': tensor([[-0.0030, -0.0123, -0.0188,  ...,  0.0186, -0.0332, -0.0181],
        [ 0.0014, -0.0037, -0.0307,  ..., -0.0058,  0.0160,  0.0274],
        [ 0.0273, -0.0119, -0.0110,  ..., -0.0013, -0.0041, -0.0059],
        ...,
        [ 0.0018, -0.0187, -0.0384,  ...,  0.0141,  0.0053,  0.0090],
        [ 0.0151, -0.0128, -0.0045,  ...,  0.0167, -0.0064,  0.0077],
        [ 0.0001,  0.0021,  0.0336,  ..., -0.0046, -0.0128,  0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias': tensor([ 0.1198, -0.0191,  0.1595,  ..., -0.0292, -0.0284, -0.0580],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight': tensor([3.1777, 3.2344, 3.2090,  ..., 1.1455, 2.6172, 3.2363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias': tensor([-0.3699,  0.0534, -0.3181,  ...,  0.1720,  0.3350, -0.2013],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight': tensor([[ 0.0132,  0.0254, -0.0020,  ..., -0.0305,  0.0047,  0.0051],
        [ 0.0022, -0.0257,  0.0199,  ..., -0.0184,  0.0286,  0.0047],
        [-0.0092, -0.0116,  0.0196,  ..., -0.0357,  0.0290,  0.0171],
        ...,
        [ 0.0071, -0.0053,  0.0001,  ..., -0.0139, -0.0043, -0.0191],
        [-0.0128,  0.0084, -0.0034,  ..., -0.0035, -0.0175, -0.0111],
        [ 0.0023, -0.0036, -0.0063,  ...,  0.0125, -0.0132,  0.0166]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias': tensor([ 2.2266,  1.3135, -0.9771,  ...,  0.3726,  2.3047,  0.1869],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight': tensor([[-0.0117,  0.0124, -0.0160,  ...,  0.0026,  0.0036,  0.0293],
        [ 0.0022, -0.0097, -0.0008,  ..., -0.0094,  0.0017, -0.0152],
        [-0.0117, -0.0052, -0.0132,  ...,  0.0201,  0.0020, -0.0049],
        ...,
        [ 0.0122, -0.0035, -0.0111,  ..., -0.0017,  0.0214,  0.0207],
        [-0.0134,  0.0110, -0.0031,  ...,  0.0010,  0.0070,  0.0225],
        [ 0.0003,  0.0153,  0.0004,  ...,  0.0096,  0.0122,  0.0161]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias': tensor([ 0.0095, -0.0149, -0.0342,  ...,  0.0316,  0.0107, -0.0553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight': tensor([[ 2.4475e-02,  1.0361e-02, -3.1738e-03,  ...,  6.3629e-03,
         -4.1161e-03,  4.0770e-05],
        [ 6.4735e-03, -1.1032e-02, -4.1046e-03,  ...,  2.4471e-03,
         -7.7009e-04,  3.3226e-03],
        [-2.2324e-02, -5.0497e-04, -2.1210e-02,  ..., -6.5186e-02,
         -3.9253e-03, -4.9324e-03],
        ...,
        [ 7.4692e-03, -2.1229e-03, -2.2095e-02,  ..., -3.7079e-02,
         -3.3173e-02,  2.9621e-03],
        [-2.3987e-02, -1.8463e-03, -3.8791e-04,  ..., -1.6312e-02,
         -2.0157e-02,  1.9180e-02],
        [ 5.5695e-03, -1.0750e-02,  1.4153e-03,  ...,  1.7136e-02,
         -1.8829e-02, -3.1219e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias': tensor([ 0.0942, -0.0380, -0.0066,  ..., -0.2206,  0.0908,  0.0343],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight': tensor([[ 0.0108, -0.0169,  0.0143,  ..., -0.0040, -0.0186, -0.0120],
        [-0.0099,  0.0158, -0.0007,  ..., -0.0126,  0.0125, -0.0013],
        [ 0.0059, -0.0186,  0.0080,  ...,  0.0038,  0.0261, -0.0122],
        ...,
        [ 0.0193, -0.0006, -0.0168,  ..., -0.0111, -0.0033,  0.0045],
        [ 0.0071,  0.0175, -0.0099,  ...,  0.0238,  0.0111,  0.0132],
        [ 0.0269,  0.0227,  0.0074,  ..., -0.0048, -0.0153, -0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias': tensor([ 0.1117, -0.0344, -0.0097,  ..., -0.0479, -0.0558, -0.0235],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight': tensor([1.5781, 1.5361, 1.5830,  ..., 0.8071, 1.4404, 1.7129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias': tensor([ 0.0493, -0.2202, -0.1034,  ...,  0.0678, -0.1000, -0.2034],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight': tensor([[-0.0206, -0.0153,  0.0054,  ...,  0.0216,  0.0042, -0.0064],
        [-0.0240,  0.0083,  0.0154,  ..., -0.0026,  0.0077, -0.0042],
        [ 0.0143,  0.0016,  0.0010,  ...,  0.0362,  0.0050,  0.0193],
        ...,
        [ 0.0191,  0.0038,  0.0125,  ..., -0.0049, -0.0139, -0.0164],
        [ 0.0050,  0.0037,  0.0237,  ..., -0.0271,  0.0079, -0.0093],
        [ 0.0163,  0.0038, -0.0141,  ..., -0.0026, -0.0191,  0.0084]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias': tensor([-0.2673, -0.2559, -0.2236,  ..., -0.2888, -0.2781, -0.0958],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight': tensor([[-0.0093, -0.0160, -0.0221,  ...,  0.0137, -0.0174, -0.0188],
        [-0.0096,  0.0156, -0.0179,  ..., -0.0231,  0.0060, -0.0123],
        [ 0.0032, -0.0022,  0.0147,  ..., -0.0053,  0.0070,  0.0076],
        ...,
        [-0.0122, -0.0089,  0.0011,  ...,  0.0205,  0.0041, -0.0117],
        [ 0.0056, -0.0073, -0.0155,  ..., -0.0081, -0.0361,  0.0044],
        [ 0.0310,  0.0010,  0.0081,  ..., -0.0060, -0.0118, -0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias': tensor([-0.0192, -0.0717,  0.1105,  ..., -0.1528,  0.0851, -0.0401],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight': tensor([3.1602, 3.0371, 2.9180,  ..., 1.5098, 2.5527, 3.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias': tensor([ 0.2227,  0.6216, -0.4958,  ...,  0.2568,  0.0677, -0.4553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight': tensor([[ 0.0037,  0.0141,  0.0131,  ...,  0.0058,  0.0128,  0.0105],
        [ 0.0020, -0.0168, -0.0078,  ...,  0.0242, -0.0173, -0.0008],
        [ 0.0030,  0.0062, -0.0284,  ..., -0.0097,  0.0236,  0.0083],
        ...,
        [-0.0080, -0.0243, -0.0079,  ..., -0.0201, -0.0240, -0.0208],
        [ 0.0029,  0.0056,  0.0167,  ...,  0.0065, -0.0012, -0.0019],
        [-0.0047, -0.0198, -0.0200,  ...,  0.0153,  0.0093, -0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias': tensor([ 0.9746, -1.5684,  4.0703,  ..., -4.7695,  2.3730,  0.0641],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight': tensor([[-0.0094,  0.0040, -0.0081,  ...,  0.0087,  0.0034, -0.0086],
        [-0.0218, -0.0027,  0.0096,  ...,  0.0072, -0.0114, -0.0138],
        [-0.0069,  0.0196,  0.0128,  ...,  0.0089, -0.0430,  0.0282],
        ...,
        [ 0.0080, -0.0076,  0.0247,  ..., -0.0006,  0.0264, -0.0060],
        [-0.0081,  0.0084,  0.0222,  ...,  0.0080, -0.0070,  0.0124],
        [-0.0113,  0.0073,  0.0137,  ..., -0.0100, -0.0085,  0.0073]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias': tensor([-0.0650, -0.0600,  0.0630,  ..., -0.0726,  0.0070, -0.1204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight': tensor([[ 0.0016,  0.0027, -0.0018,  ...,  0.0349, -0.0049, -0.0009],
        [ 0.0076,  0.0003, -0.0250,  ...,  0.0064,  0.0064,  0.0147],
        [-0.0011, -0.0325, -0.0602,  ...,  0.0003, -0.0238,  0.0107],
        ...,
        [ 0.0233,  0.0226,  0.0270,  ...,  0.0236, -0.0239, -0.0167],
        [ 0.0041, -0.0097, -0.0143,  ..., -0.0173, -0.0098,  0.0124],
        [ 0.0090, -0.0034,  0.0003,  ...,  0.0278,  0.0114,  0.0061]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias': tensor([-0.4348, -0.0033, -0.1771,  ..., -0.0897,  0.1703,  0.3945],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight': tensor([[ 0.0021,  0.0206, -0.0078,  ..., -0.0072, -0.0010,  0.0115],
        [ 0.0005,  0.0042, -0.0142,  ...,  0.0190, -0.0119, -0.0008],
        [ 0.0061, -0.0182,  0.0112,  ..., -0.0376, -0.0023, -0.0042],
        ...,
        [-0.0143,  0.0111, -0.0015,  ..., -0.0087,  0.0175, -0.0019],
        [-0.0039,  0.0022,  0.0231,  ..., -0.0050,  0.0082, -0.0150],
        [ 0.0005, -0.0005, -0.0158,  ..., -0.0120, -0.0067, -0.0141]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias': tensor([-0.0269, -0.0574,  0.0638,  ..., -0.1498,  0.0551, -0.1482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight': tensor([1.5703, 1.8379, 1.9336,  ..., 0.8516, 1.4707, 1.7686],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias': tensor([0.3889, 0.2372, 0.1531,  ..., 0.6260, 0.2163, 0.1549],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight': tensor([[-1.1892e-03,  3.9005e-03, -5.7487e-03,  ...,  4.7989e-03,
         -4.2915e-03, -2.5539e-03],
        [ 1.5236e-02, -2.3232e-03, -3.3325e-02,  ...,  2.3758e-02,
         -1.0595e-03, -3.8986e-03],
        [ 2.0737e-02,  7.2479e-03, -3.0842e-03,  ..., -5.4207e-03,
          2.6047e-02, -1.4210e-03],
        ...,
        [ 7.4120e-03, -2.9163e-03,  3.3661e-02,  ..., -4.4785e-03,
          9.1400e-03, -1.5297e-02],
        [-4.3964e-04,  8.5297e-03, -1.5350e-02,  ..., -1.3519e-02,
         -6.6490e-03,  5.9700e-04],
        [-7.5579e-05,  1.0449e-04,  8.8196e-03,  ..., -1.0658e-02,
         -6.6032e-03, -5.4703e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias': tensor([-0.3184, -0.2345, -0.2834,  ..., -0.2498, -0.1849, -0.2729],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight': tensor([[ 0.0369,  0.0093, -0.0179,  ..., -0.0141, -0.0035,  0.0064],
        [ 0.0050,  0.0101,  0.0117,  ...,  0.0070, -0.0066, -0.0147],
        [-0.0015,  0.0263,  0.0119,  ..., -0.0270,  0.0052, -0.0028],
        ...,
        [ 0.0133,  0.0236, -0.0152,  ...,  0.0251, -0.0268, -0.0321],
        [ 0.0021, -0.0061,  0.0079,  ..., -0.0029,  0.0145, -0.0033],
        [-0.0097,  0.0175, -0.0111,  ..., -0.0278, -0.0016, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias': tensor([-0.1587, -0.0068,  0.1970,  ...,  0.0549, -0.0199,  0.0069],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight': tensor([2.5664, 2.3809, 2.5742,  ..., 1.8262, 2.4121, 2.7520],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias': tensor([ 0.1838,  0.3330, -0.2296,  ..., -0.1086,  0.5938, -0.2812],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight': tensor([[ 0.0305, -0.0035, -0.0098,  ...,  0.0054, -0.0111,  0.0049],
        [-0.0194,  0.0099,  0.0032,  ...,  0.0125,  0.0277, -0.0057],
        [ 0.0115,  0.0072, -0.0170,  ...,  0.0162,  0.0032,  0.0142],
        ...,
        [ 0.0076, -0.0034,  0.0187,  ...,  0.0278, -0.0174, -0.0046],
        [-0.0037, -0.0002,  0.0051,  ..., -0.0108,  0.0012,  0.0065],
        [-0.0047, -0.0013,  0.0154,  ...,  0.0158, -0.0106,  0.0013]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias': tensor([-0.0001,  0.0002, -0.0072,  ...,  0.0011, -0.0007, -0.0008],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight': tensor([[ 0.0221, -0.0052,  0.0127,  ..., -0.0090, -0.0092, -0.0165],
        [-0.0569, -0.0251, -0.0167,  ..., -0.0070, -0.0093, -0.0182],
        [-0.0159, -0.0159,  0.0239,  ...,  0.0133,  0.0071,  0.0088],
        ...,
        [ 0.0025,  0.0141, -0.0087,  ...,  0.0007, -0.0157, -0.0012],
        [ 0.0053,  0.0023, -0.0199,  ...,  0.0264,  0.0148, -0.0300],
        [-0.0040,  0.0095, -0.0180,  ..., -0.0396, -0.0316, -0.0156]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias': tensor([-0.0095, -0.0084,  0.0243,  ...,  0.1217, -0.0273,  0.0116],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight': tensor([[ 1.3329e-02, -5.8022e-03,  2.2945e-03,  ...,  1.0509e-03,
          2.1591e-02, -3.7422e-03],
        [-1.7593e-02,  9.9182e-03,  2.1652e-02,  ..., -1.7380e-02,
         -1.1452e-02, -1.1536e-02],
        [-4.2648e-03,  3.6955e-06,  8.7585e-03,  ...,  5.5428e-03,
          1.0963e-02, -8.2855e-03],
        ...,
        [ 2.6302e-03, -6.2828e-03,  1.8387e-02,  ...,  2.4658e-02,
         -1.4015e-02, -1.8509e-02],
        [-1.9140e-03, -1.3588e-02, -1.2770e-03,  ..., -1.8143e-02,
         -2.0309e-02, -2.0172e-02],
        [-1.6346e-03,  5.2338e-03, -1.7044e-02,  ..., -4.7073e-03,
          1.5930e-02,  1.8097e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias': tensor([ 0.0486, -0.0525, -1.9268,  ...,  0.0309,  0.1466, -0.0662],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight': tensor([[-0.0204,  0.0447, -0.0052,  ...,  0.0069,  0.0077,  0.0218],
        [ 0.0017,  0.0142, -0.0191,  ...,  0.0062, -0.0003,  0.0145],
        [-0.0078,  0.0171, -0.0142,  ..., -0.0220,  0.0106,  0.0089],
        ...,
        [-0.0215, -0.0144, -0.0043,  ...,  0.0026, -0.0030,  0.0222],
        [ 0.0184,  0.0181,  0.0050,  ...,  0.0064, -0.0177,  0.0218],
        [ 0.0176,  0.0081, -0.0153,  ..., -0.0053,  0.0065,  0.0165]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias': tensor([-0.2126,  0.1382,  0.1891,  ...,  0.0073,  0.0610, -0.0497],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight': tensor([1.5518, 1.4453, 1.4551,  ..., 0.8970, 1.4531, 1.5488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias': tensor([-0.0075, -0.0621, -0.0674,  ..., -0.0965, -0.1760, -0.1098],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight': tensor([[ 0.0173, -0.0038, -0.0434,  ..., -0.0142, -0.0269,  0.0163],
        [ 0.0112,  0.0112, -0.0199,  ...,  0.0013,  0.0100, -0.0072],
        [-0.0037, -0.0045, -0.0143,  ..., -0.0011, -0.0073, -0.0100],
        ...,
        [-0.0162, -0.0028, -0.0142,  ...,  0.0240, -0.0207, -0.0169],
        [ 0.0084,  0.0172, -0.0097,  ..., -0.0170, -0.0171, -0.0099],
        [ 0.0414, -0.0024, -0.0073,  ..., -0.0142,  0.0116,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias': tensor([-0.2035, -0.6177, -0.2632,  ..., -0.2837, -0.4905, -0.3960],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight': tensor([[-0.0123, -0.0106,  0.0170,  ..., -0.0074, -0.0057,  0.0038],
        [ 0.0014, -0.0104, -0.0019,  ...,  0.0073,  0.0064, -0.0129],
        [-0.0083, -0.0003,  0.0169,  ...,  0.0021,  0.0054,  0.0217],
        ...,
        [-0.0205, -0.0112, -0.0028,  ..., -0.0033,  0.0101,  0.0241],
        [ 0.0122, -0.0082,  0.0100,  ..., -0.0086,  0.0083, -0.0369],
        [ 0.0042, -0.0036,  0.0006,  ..., -0.0066,  0.0024,  0.0018]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias': tensor([ 0.0215, -0.1328, -0.1233,  ..., -0.1167,  0.0634,  0.0916],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight': tensor([1.6230, 1.6143, 1.6387,  ..., 1.4531, 1.7188, 1.8516],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias': tensor([-0.0200, -0.0892,  0.0742,  ...,  0.0301,  0.1517, -0.2600],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight': tensor([0.9370, 1.0215, 0.9346,  ..., 0.8223, 1.0596, 1.0498],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias': tensor([-0.0060,  0.1511, -0.0550,  ...,  0.2749,  0.0767,  0.0092],
       dtype=torch.float16), 'model.mm_projector.weight': tensor([[ 0.0252,  0.0276,  0.0058,  ..., -0.0191, -0.0254,  0.0032],
        [-0.0134, -0.0230, -0.0199,  ..., -0.0219, -0.0018,  0.0107],
        [ 0.0030, -0.0106, -0.0190,  ..., -0.0223, -0.0245, -0.0302],
        ...,
        [-0.0181,  0.0302, -0.0140,  ...,  0.0033, -0.0131,  0.0214],
        [-0.0312,  0.0093, -0.0021,  ...,  0.0023, -0.0310,  0.0299],
        [ 0.0285, -0.0134, -0.0182,  ...,  0.0117,  0.0080,  0.0309]]), 'model.mm_projector.bias': tensor([-0.0134, -0.0254,  0.0040,  ...,  0.0114, -0.0256, -0.0169]), 'model.perceiver.latents': tensor([[ 1.5252,  1.2867, -1.2505,  ...,  0.5321, -2.3941, -0.4665],
        [-0.4164, -0.2111,  1.3856,  ...,  0.3634,  0.1084,  0.4405],
        [-1.0354,  0.7875, -0.1886,  ...,  1.3807,  0.2274, -0.3769],
        ...,
        [-0.8971,  0.9488, -1.1161,  ...,  0.7738, -1.0463, -0.4423],
        [ 0.1573,  0.1691,  0.4404,  ..., -0.6260, -0.3125, -0.8709],
        [-0.9143, -0.6234, -0.7480,  ..., -0.8548, -1.5731, -0.0611]]), 'model.perceiver.frame_embs': tensor([[-0.7198,  1.1845,  0.0914,  ..., -0.7878, -0.2951,  2.2245],
        [-0.7837, -1.0605,  2.1762,  ..., -0.7901,  0.4863, -2.1830],
        [-0.2884,  1.7262, -0.2643,  ...,  0.8587,  1.5146, -0.9541],
        ...,
        [ 1.2272, -0.2872, -1.1665,  ...,  1.1890,  0.7629,  0.3428],
        [ 0.4132, -0.1049, -1.4566,  ...,  0.5528,  0.8381, -0.2446],
        [-0.3546, -0.0155, -0.4453,  ..., -0.6324,  0.3603,  0.4383]]), 'model.perceiver.media_time_embs': tensor([[[-0.1172, -0.1675, -0.1333,  ..., -2.3379, -0.8965,  0.5041]],

        [[-0.7958,  1.6157,  1.0383,  ...,  1.4126, -1.1374,  0.2342]],

        [[-1.7779, -0.4761,  1.6482,  ..., -1.2809,  0.2966, -0.8488]],

        [[ 0.4323, -0.2724,  1.1912,  ...,  1.6235,  1.1465,  0.2374]]]), 'model.perceiver.layers.0.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.to_q.weight': tensor([[ 0.0024, -0.0091, -0.0047,  ..., -0.0154,  0.0149, -0.0122],
        [-0.0006,  0.0150,  0.0022,  ..., -0.0028,  0.0008,  0.0076],
        [ 0.0050, -0.0111,  0.0137,  ..., -0.0125,  0.0146,  0.0056],
        ...,
        [-0.0132,  0.0058, -0.0073,  ..., -0.0020, -0.0061,  0.0027],
        [ 0.0135,  0.0102, -0.0020,  ..., -0.0042, -0.0127, -0.0066],
        [-0.0076,  0.0129,  0.0028,  ..., -0.0046,  0.0048, -0.0024]]), 'model.perceiver.layers.0.0.to_kv.weight': tensor([[-1.0665e-02,  1.3186e-02, -7.3691e-03,  ..., -1.3930e-02,
         -1.3296e-02,  5.9540e-03],
        [ 5.2436e-03,  5.2805e-04,  2.4715e-03,  ...,  1.0453e-03,
          8.1790e-03,  1.1679e-02],
        [ 7.0834e-03,  4.0771e-03, -1.2144e-02,  ...,  5.4929e-06,
          1.3126e-03,  1.0943e-02],
        ...,
        [ 1.0177e-02,  1.4738e-02, -6.1849e-03,  ..., -8.5534e-03,
         -8.5694e-03,  6.8024e-03],
        [ 1.1124e-02,  9.8170e-03, -1.3067e-02,  ..., -5.1877e-03,
         -8.6839e-03,  1.4954e-03],
        [-6.8066e-03, -6.4073e-04, -8.9312e-03,  ..., -6.9081e-03,
         -1.4938e-02, -1.2508e-02]]), 'model.perceiver.layers.0.0.to_out.weight': tensor([[-0.0013, -0.0189,  0.0346,  ...,  0.0127,  0.0235, -0.0176],
        [ 0.0099,  0.0071, -0.0369,  ..., -0.0280, -0.0104,  0.0100],
        [-0.0330, -0.0243,  0.0011,  ...,  0.0427, -0.0382, -0.0405],
        ...,
        [ 0.0339, -0.0007, -0.0418,  ...,  0.0045,  0.0048, -0.0374],
        [-0.0276,  0.0250, -0.0361,  ..., -0.0236,  0.0202,  0.0427],
        [-0.0410,  0.0224, -0.0193,  ..., -0.0213,  0.0318, -0.0087]]), 'model.perceiver.layers.0.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.1.1.weight': tensor([[-0.0035,  0.0141, -0.0048,  ...,  0.0014,  0.0002, -0.0039],
        [-0.0118,  0.0102,  0.0049,  ...,  0.0038, -0.0118, -0.0008],
        [ 0.0141, -0.0100,  0.0012,  ...,  0.0072, -0.0031, -0.0033],
        ...,
        [ 0.0017, -0.0052, -0.0049,  ..., -0.0061,  0.0037, -0.0001],
        [-0.0013,  0.0102,  0.0053,  ...,  0.0024,  0.0012, -0.0019],
        [ 0.0065,  0.0026, -0.0063,  ..., -0.0093, -0.0119,  0.0068]]), 'model.perceiver.layers.0.1.3.weight': tensor([[-5.1192e-03,  6.4216e-03,  6.3719e-03,  ..., -7.7734e-03,
          8.8080e-05,  3.4290e-03],
        [ 3.1511e-03,  4.9476e-03,  6.8689e-05,  ...,  4.3853e-03,
          3.8001e-03, -4.7375e-03],
        [-3.1801e-03, -3.2698e-03,  2.5319e-03,  ...,  7.3004e-03,
         -6.7161e-03, -1.5910e-03],
        ...,
        [-1.6031e-03,  4.1536e-03, -3.5123e-03,  ..., -5.2922e-03,
          1.0448e-03, -7.1243e-03],
        [ 5.1683e-03,  2.2532e-03,  4.1160e-03,  ..., -5.7927e-03,
         -7.6008e-03,  3.0962e-03],
        [ 7.0390e-03,  2.8663e-03, -6.9971e-03,  ...,  2.8625e-03,
         -3.4310e-03,  2.5957e-03]]), 'model.perceiver.layers.1.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.to_q.weight': tensor([[ 0.0082,  0.0104, -0.0057,  ..., -0.0105, -0.0114,  0.0088],
        [ 0.0039,  0.0143, -0.0147,  ...,  0.0136,  0.0021,  0.0055],
        [-0.0102,  0.0148,  0.0126,  ..., -0.0129,  0.0154, -0.0094],
        ...,
        [-0.0096,  0.0073, -0.0156,  ..., -0.0076,  0.0073, -0.0020],
        [ 0.0047, -0.0092, -0.0005,  ..., -0.0019,  0.0063,  0.0073],
        [-0.0092, -0.0096,  0.0106,  ..., -0.0133, -0.0113,  0.0149]]), 'model.perceiver.layers.1.0.to_kv.weight': tensor([[-1.5003e-02, -8.7301e-03,  5.5517e-03,  ...,  1.2312e-02,
         -7.5853e-03,  4.7423e-03],
        [ 7.2422e-03,  3.9942e-03, -4.8580e-03,  ...,  7.0197e-03,
         -3.5582e-03, -9.8130e-03],
        [-1.4323e-02,  1.1433e-03,  1.4849e-03,  ...,  1.2193e-02,
         -1.3085e-02, -1.1857e-03],
        ...,
        [ 9.9062e-03,  4.9962e-05, -1.5041e-02,  ..., -1.8217e-03,
          4.9091e-03, -1.2337e-03],
        [-9.6417e-03, -1.4064e-02, -1.4582e-02,  ..., -4.9796e-03,
          5.6359e-03, -1.1848e-02],
        [-1.2499e-02, -1.2410e-02,  7.5710e-03,  ..., -1.2414e-02,
         -9.5216e-03, -7.5097e-03]]), 'model.perceiver.layers.1.0.to_out.weight': tensor([[-0.0127, -0.0010, -0.0050,  ...,  0.0392, -0.0285,  0.0274],
        [ 0.0423,  0.0391,  0.0037,  ...,  0.0090,  0.0166,  0.0321],
        [ 0.0212, -0.0386,  0.0333,  ...,  0.0438, -0.0332,  0.0287],
        ...,
        [ 0.0248, -0.0112,  0.0041,  ..., -0.0004, -0.0248,  0.0073],
        [-0.0364, -0.0069,  0.0034,  ..., -0.0171,  0.0209, -0.0168],
        [-0.0410, -0.0254,  0.0155,  ...,  0.0389, -0.0022, -0.0045]]), 'model.perceiver.layers.1.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.1.1.weight': tensor([[ 0.0138,  0.0078,  0.0055,  ..., -0.0020,  0.0089, -0.0149],
        [-0.0047,  0.0088,  0.0075,  ..., -0.0014,  0.0064,  0.0117],
        [-0.0072,  0.0135,  0.0104,  ..., -0.0102,  0.0147, -0.0136],
        ...,
        [-0.0069,  0.0092, -0.0069,  ..., -0.0113,  0.0016, -0.0020],
        [-0.0083,  0.0062, -0.0001,  ...,  0.0012,  0.0124, -0.0146],
        [ 0.0003,  0.0076, -0.0053,  ..., -0.0126, -0.0047, -0.0140]]), 'model.perceiver.layers.1.1.3.weight': tensor([[-4.1391e-03, -2.2045e-03,  3.9879e-03,  ...,  2.2117e-03,
          4.6112e-03, -4.8351e-03],
        [ 2.0923e-03,  2.6776e-03, -2.6648e-03,  ..., -5.3496e-03,
         -5.7130e-03,  2.3010e-03],
        [-3.8911e-03,  3.8165e-03, -2.5116e-03,  ...,  9.6088e-04,
         -7.0093e-03, -1.5283e-04],
        ...,
        [-3.6348e-03,  3.7843e-03,  7.0784e-03,  ..., -1.6148e-03,
         -2.4074e-05,  6.8515e-03],
        [ 2.7890e-03,  2.7983e-04, -1.2411e-03,  ..., -5.0283e-03,
         -4.5240e-03,  6.6855e-03],
        [-6.2413e-03, -4.9892e-03,  3.7880e-03,  ...,  5.7019e-03,
         -2.7539e-03, -2.4925e-03]]), 'model.perceiver.layers.2.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.to_q.weight': tensor([[-0.0061,  0.0110, -0.0051,  ...,  0.0065,  0.0075, -0.0114],
        [-0.0102, -0.0117,  0.0023,  ..., -0.0010,  0.0134,  0.0096],
        [-0.0142, -0.0094,  0.0155,  ..., -0.0119, -0.0102,  0.0144],
        ...,
        [-0.0051,  0.0091, -0.0108,  ...,  0.0026, -0.0042, -0.0006],
        [-0.0154,  0.0098,  0.0126,  ..., -0.0137, -0.0005,  0.0150],
        [-0.0153,  0.0043,  0.0032,  ..., -0.0105,  0.0052,  0.0112]]), 'model.perceiver.layers.2.0.to_kv.weight': tensor([[-0.0138,  0.0030,  0.0092,  ...,  0.0022,  0.0124,  0.0033],
        [-0.0002, -0.0102, -0.0045,  ..., -0.0110, -0.0141, -0.0146],
        [-0.0039,  0.0146,  0.0088,  ..., -0.0140, -0.0037, -0.0128],
        ...,
        [-0.0086, -0.0156,  0.0053,  ..., -0.0059,  0.0123, -0.0060],
        [ 0.0014,  0.0139, -0.0026,  ...,  0.0015,  0.0114,  0.0115],
        [ 0.0108,  0.0149,  0.0002,  ...,  0.0077, -0.0066,  0.0094]]), 'model.perceiver.layers.2.0.to_out.weight': tensor([[ 0.0160, -0.0435, -0.0303,  ..., -0.0086, -0.0077,  0.0096],
        [-0.0407,  0.0338, -0.0303,  ...,  0.0370, -0.0088,  0.0350],
        [ 0.0048, -0.0076, -0.0399,  ...,  0.0121, -0.0304,  0.0356],
        ...,
        [-0.0233,  0.0181,  0.0045,  ...,  0.0075,  0.0266,  0.0263],
        [ 0.0265, -0.0410,  0.0077,  ..., -0.0014,  0.0314,  0.0010],
        [ 0.0078, -0.0296, -0.0367,  ..., -0.0340, -0.0150, -0.0102]]), 'model.perceiver.layers.2.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.1.1.weight': tensor([[ 0.0047, -0.0023,  0.0103,  ..., -0.0025, -0.0130, -0.0035],
        [ 0.0013,  0.0135,  0.0098,  ..., -0.0082, -0.0070, -0.0128],
        [-0.0070, -0.0125,  0.0140,  ...,  0.0009, -0.0036, -0.0146],
        ...,
        [ 0.0135,  0.0115, -0.0003,  ...,  0.0119, -0.0080,  0.0006],
        [-0.0130,  0.0013, -0.0062,  ..., -0.0092,  0.0156, -0.0024],
        [-0.0127, -0.0085,  0.0045,  ...,  0.0074, -0.0106,  0.0131]]), 'model.perceiver.layers.2.1.3.weight': tensor([[-3.5642e-03,  2.0755e-03, -3.1892e-03,  ..., -9.5336e-04,
          2.9674e-03,  3.0889e-04],
        [ 6.8106e-03,  4.4300e-04,  1.7981e-03,  ..., -2.9616e-03,
          5.4681e-03,  3.3989e-03],
        [-2.9106e-03, -6.5841e-03,  2.8219e-03,  ...,  5.4702e-03,
          6.0051e-03, -1.2657e-03],
        ...,
        [-2.8558e-03, -1.9629e-03,  4.1601e-03,  ..., -3.2824e-03,
          9.9899e-04, -9.1121e-05],
        [-6.1291e-03, -7.0368e-03, -6.1064e-03,  ...,  4.8821e-03,
         -4.3743e-04,  3.4097e-03],
        [ 5.8056e-04,  7.5997e-03, -3.4322e-03,  ..., -7.5911e-03,
          5.7896e-03, -4.5671e-03]]), 'model.perceiver.layers.3.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.to_q.weight': tensor([[-1.2516e-02, -1.9312e-03, -1.6518e-03,  ..., -4.9867e-03,
         -2.3809e-03,  4.5658e-04],
        [-1.4822e-02,  1.2645e-02,  6.5673e-03,  ...,  7.2051e-03,
          8.6808e-03, -1.5243e-03],
        [ 7.7445e-05,  8.2559e-03, -1.2966e-02,  ..., -3.9869e-04,
          5.9993e-03,  3.5605e-03],
        ...,
        [ 1.2587e-02, -3.9923e-03, -1.2914e-02,  ...,  1.2603e-02,
         -1.6420e-03, -6.3935e-03],
        [ 1.1560e-02, -7.6075e-03,  4.1811e-03,  ..., -1.2127e-02,
          1.1990e-02,  1.2567e-02],
        [-7.4751e-03, -1.4419e-02, -8.4474e-03,  ...,  1.2376e-03,
         -3.7630e-03, -1.5529e-02]]), 'model.perceiver.layers.3.0.to_kv.weight': tensor([[ 3.2606e-05, -1.3473e-02, -7.9154e-03,  ...,  1.4482e-02,
         -4.8147e-03, -8.1176e-03],
        [ 2.5162e-03, -1.6172e-03, -1.1978e-03,  ..., -9.2265e-03,
          8.1584e-03,  1.9351e-03],
        [ 1.5672e-03,  8.4615e-03,  6.2376e-05,  ...,  1.2514e-02,
          7.9630e-03,  7.3517e-03],
        ...,
        [ 7.6510e-03, -2.6457e-03, -8.2500e-03,  ..., -1.5565e-02,
          2.0854e-04, -5.1164e-03],
        [-1.0705e-02, -1.3370e-02, -1.2583e-02,  ...,  6.2076e-03,
         -3.5731e-03,  8.3903e-03],
        [ 1.2007e-02, -1.4843e-02, -8.6268e-03,  ...,  6.7527e-03,
         -6.0215e-03, -7.8338e-03]]), 'model.perceiver.layers.3.0.to_out.weight': tensor([[-0.0136, -0.0292,  0.0279,  ..., -0.0049, -0.0003,  0.0105],
        [ 0.0341,  0.0030, -0.0113,  ...,  0.0075, -0.0232, -0.0177],
        [-0.0413,  0.0440, -0.0267,  ...,  0.0343, -0.0431, -0.0193],
        ...,
        [ 0.0202, -0.0417, -0.0239,  ..., -0.0127,  0.0227,  0.0030],
        [ 0.0373,  0.0388,  0.0348,  ...,  0.0156, -0.0075,  0.0013],
        [-0.0270,  0.0314, -0.0243,  ...,  0.0023, -0.0023, -0.0321]]), 'model.perceiver.layers.3.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.1.1.weight': tensor([[-1.2784e-02, -6.8041e-03, -9.7144e-03,  ..., -5.6996e-03,
          4.5485e-03, -3.3535e-03],
        [-3.2369e-03,  1.4765e-02,  1.1001e-02,  ..., -7.2094e-03,
         -3.5084e-03, -3.8064e-03],
        [ 1.4042e-02,  1.4696e-02,  2.1235e-03,  ...,  9.7152e-05,
         -1.2914e-02,  1.6648e-03],
        ...,
        [ 6.2151e-03, -6.1422e-03,  8.4811e-03,  ...,  5.9526e-03,
         -4.6282e-03, -1.3837e-02],
        [ 1.1609e-02,  1.5468e-02, -3.5241e-03,  ...,  6.8017e-03,
         -1.2165e-02, -1.5350e-02],
        [-9.0941e-03,  1.5562e-03, -1.4809e-02,  ..., -1.1383e-03,
          6.4672e-03, -7.2103e-03]]), 'model.perceiver.layers.3.1.3.weight': tensor([[ 0.0030,  0.0069, -0.0003,  ..., -0.0055, -0.0065,  0.0042],
        [-0.0041, -0.0002,  0.0045,  ..., -0.0009,  0.0063, -0.0062],
        [ 0.0055,  0.0027, -0.0035,  ...,  0.0078,  0.0010,  0.0035],
        ...,
        [-0.0022,  0.0036,  0.0019,  ..., -0.0046, -0.0062,  0.0055],
        [-0.0072, -0.0065,  0.0058,  ..., -0.0035, -0.0053,  0.0019],
        [ 0.0046, -0.0012,  0.0019,  ...,  0.0077,  0.0021, -0.0014]]), 'model.perceiver.layers.4.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.to_q.weight': tensor([[-1.8131e-03,  1.3864e-02, -1.4864e-02,  ...,  1.3396e-02,
          1.5159e-02,  6.0389e-03],
        [ 1.2134e-02,  4.7203e-03, -9.8943e-03,  ..., -1.0395e-02,
         -5.8986e-03,  1.4519e-02],
        [-7.1530e-04,  1.5056e-02,  1.3437e-02,  ...,  3.2745e-03,
         -1.0621e-02, -2.4969e-03],
        ...,
        [ 5.2572e-03, -7.7105e-04,  9.6547e-03,  ..., -9.5651e-03,
          1.3336e-02, -1.4987e-02],
        [-7.7215e-03,  6.9238e-03, -2.9116e-03,  ...,  9.5909e-05,
         -1.1874e-02, -7.4113e-03],
        [-1.0246e-03, -8.4614e-03, -7.8668e-03,  ..., -2.2900e-03,
         -1.3376e-02, -5.5927e-03]]), 'model.perceiver.layers.4.0.to_kv.weight': tensor([[-0.0038, -0.0044, -0.0080,  ...,  0.0059, -0.0133,  0.0131],
        [ 0.0054, -0.0027,  0.0092,  ..., -0.0041, -0.0005,  0.0027],
        [-0.0151,  0.0090, -0.0062,  ..., -0.0104,  0.0111,  0.0078],
        ...,
        [ 0.0120,  0.0141,  0.0070,  ..., -0.0050, -0.0085, -0.0120],
        [ 0.0133, -0.0078,  0.0072,  ..., -0.0074, -0.0013,  0.0067],
        [ 0.0044,  0.0006,  0.0084,  ..., -0.0095, -0.0038,  0.0008]]), 'model.perceiver.layers.4.0.to_out.weight': tensor([[-0.0273, -0.0196, -0.0378,  ...,  0.0063, -0.0233, -0.0407],
        [-0.0390, -0.0409, -0.0295,  ..., -0.0014,  0.0113, -0.0299],
        [ 0.0330, -0.0189, -0.0381,  ...,  0.0103, -0.0115, -0.0089],
        ...,
        [ 0.0265,  0.0098,  0.0231,  ...,  0.0168, -0.0184,  0.0104],
        [-0.0324,  0.0330, -0.0316,  ...,  0.0288,  0.0020, -0.0312],
        [ 0.0004, -0.0178, -0.0134,  ..., -0.0289,  0.0069, -0.0401]]), 'model.perceiver.layers.4.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.1.1.weight': tensor([[ 0.0091,  0.0043, -0.0097,  ..., -0.0117,  0.0080, -0.0002],
        [ 0.0076, -0.0083,  0.0004,  ...,  0.0003,  0.0056, -0.0104],
        [-0.0081, -0.0025, -0.0064,  ...,  0.0049,  0.0093, -0.0084],
        ...,
        [ 0.0063,  0.0060,  0.0137,  ...,  0.0092, -0.0019, -0.0072],
        [-0.0098, -0.0126, -0.0077,  ...,  0.0051, -0.0144, -0.0089],
        [ 0.0103,  0.0155,  0.0139,  ..., -0.0049, -0.0048, -0.0153]]), 'model.perceiver.layers.4.1.3.weight': tensor([[-0.0062,  0.0002, -0.0069,  ..., -0.0022,  0.0019, -0.0039],
        [-0.0041,  0.0027, -0.0053,  ...,  0.0016, -0.0024,  0.0074],
        [-0.0034, -0.0010,  0.0010,  ...,  0.0055,  0.0021,  0.0049],
        ...,
        [-0.0031, -0.0076,  0.0067,  ..., -0.0049,  0.0064,  0.0055],
        [-0.0046,  0.0057, -0.0025,  ...,  0.0075,  0.0059, -0.0057],
        [ 0.0026,  0.0038,  0.0051,  ..., -0.0034, -0.0006, -0.0014]]), 'model.perceiver.layers.5.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.to_q.weight': tensor([[-0.0107,  0.0107, -0.0116,  ..., -0.0019, -0.0146, -0.0130],
        [ 0.0046, -0.0145,  0.0139,  ...,  0.0066,  0.0140, -0.0058],
        [ 0.0138, -0.0042,  0.0131,  ..., -0.0062, -0.0153,  0.0151],
        ...,
        [-0.0017, -0.0120, -0.0039,  ...,  0.0003,  0.0099,  0.0119],
        [ 0.0153, -0.0047, -0.0023,  ..., -0.0092,  0.0086, -0.0015],
        [-0.0133,  0.0063, -0.0036,  ...,  0.0096,  0.0073,  0.0132]]), 'model.perceiver.layers.5.0.to_kv.weight': tensor([[ 0.0131,  0.0100,  0.0008,  ..., -0.0112,  0.0002, -0.0025],
        [ 0.0037,  0.0133, -0.0102,  ...,  0.0031,  0.0083, -0.0149],
        [ 0.0061,  0.0146, -0.0149,  ...,  0.0004, -0.0050, -0.0126],
        ...,
        [ 0.0093,  0.0107,  0.0040,  ..., -0.0124,  0.0155, -0.0022],
        [ 0.0014,  0.0115, -0.0050,  ..., -0.0063,  0.0140,  0.0007],
        [-0.0052,  0.0113, -0.0008,  ..., -0.0112, -0.0052, -0.0154]]), 'model.perceiver.layers.5.0.to_out.weight': tensor([[ 0.0264, -0.0043, -0.0295,  ...,  0.0386, -0.0187,  0.0114],
        [-0.0161,  0.0141,  0.0275,  ...,  0.0240,  0.0117, -0.0320],
        [-0.0319, -0.0141,  0.0055,  ...,  0.0015, -0.0156, -0.0239],
        ...,
        [ 0.0316,  0.0156, -0.0189,  ...,  0.0211, -0.0043, -0.0030],
        [ 0.0380, -0.0425, -0.0134,  ..., -0.0327, -0.0032, -0.0387],
        [-0.0429, -0.0017,  0.0068,  ..., -0.0281,  0.0216, -0.0291]]), 'model.perceiver.layers.5.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.1.1.weight': tensor([[ 0.0017, -0.0078, -0.0047,  ...,  0.0102, -0.0129,  0.0059],
        [-0.0048,  0.0072, -0.0045,  ...,  0.0020,  0.0094,  0.0044],
        [-0.0008,  0.0143,  0.0128,  ...,  0.0131, -0.0134,  0.0059],
        ...,
        [-0.0087,  0.0107, -0.0153,  ...,  0.0051, -0.0081,  0.0139],
        [ 0.0057,  0.0077,  0.0092,  ..., -0.0007,  0.0098,  0.0155],
        [-0.0002, -0.0070, -0.0058,  ..., -0.0089, -0.0023,  0.0026]]), 'model.perceiver.layers.5.1.3.weight': tensor([[-0.0043,  0.0031,  0.0007,  ...,  0.0043,  0.0011,  0.0023],
        [ 0.0007, -0.0049, -0.0064,  ...,  0.0009, -0.0038, -0.0034],
        [-0.0068,  0.0043, -0.0058,  ..., -0.0027,  0.0018, -0.0074],
        ...,
        [-0.0022, -0.0038,  0.0072,  ...,  0.0048, -0.0001,  0.0003],
        [-0.0031, -0.0066, -0.0005,  ..., -0.0017,  0.0048,  0.0021],
        [ 0.0008,  0.0018, -0.0058,  ...,  0.0022,  0.0055,  0.0023]]), 'model.perceiver.norm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.norm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'lm_head.weight': tensor([[-0.0058, -0.0009, -0.0071,  ...,  0.0035, -0.0099,  0.0190],
        [-0.0278,  0.0547, -0.0115,  ..., -0.0232,  0.0147,  0.0332],
        [-0.0140, -0.0099,  0.0201,  ..., -0.0344,  0.0142, -0.0150],
        ...,
        [-0.0243,  0.0031,  0.0008,  ..., -0.0046,  0.0029, -0.0072],
        [ 0.0070,  0.0007,  0.0051,  ..., -0.0131, -0.0103, -0.0041],
        [-0.0041, -0.0077, -0.0308,  ...,  0.0179,  0.0084,  0.0356]],
       dtype=torch.float16)}
[INFO] Medical save done, finish
[INFO] medical_state_dict: {'model.embed_tokens.weight': tensor([[-0.0013,  0.0004, -0.0018,  ...,  0.0004, -0.0038, -0.0033],
        [ 0.0011, -0.0046, -0.0005,  ..., -0.0079, -0.0010,  0.0003],
        [ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
        ...,
        [-0.0052,  0.0041, -0.0056,  ..., -0.0011,  0.0072,  0.0068],
        [ 0.0075, -0.0039,  0.0058,  ...,  0.0447,  0.0135, -0.0091],
        [-0.0026,  0.0215, -0.0237,  ..., -0.0354,  0.0114,  0.0210]],
       dtype=torch.float16), 'model.layers.0.self_attn.q_proj.weight': tensor([[-9.6512e-03, -1.4015e-02, -1.5736e-03,  ...,  2.1338e-05,
          1.3115e-02, -3.8280e-03],
        [ 2.9144e-02,  4.8027e-03,  5.9013e-03,  ..., -1.3435e-02,
         -8.2550e-03,  1.8204e-02],
        [-1.3481e-02,  1.8463e-02, -3.4637e-03,  ...,  6.7596e-03,
          2.8107e-02, -7.3576e-04],
        ...,
        [ 1.1032e-02,  1.4496e-02, -1.0233e-03,  ..., -2.4509e-03,
         -9.9945e-03,  1.9012e-02],
        [ 2.2018e-02,  9.6817e-03,  3.0251e-03,  ..., -2.1957e-02,
         -2.9984e-02, -1.5228e-02],
        [-4.3945e-03, -3.2215e-03,  2.4204e-03,  ...,  1.5717e-02,
          2.7542e-02, -3.5992e-03]], dtype=torch.float16), 'model.layers.0.self_attn.k_proj.weight': tensor([[-1.8356e-02,  4.0359e-03, -1.2512e-03,  ...,  1.7609e-02,
         -8.6746e-03, -1.4610e-02],
        [ 1.5823e-02,  6.5346e-03,  2.6360e-03,  ..., -1.8021e-02,
          1.6815e-02,  2.4765e-02],
        [ 2.4891e-04, -2.5513e-02,  9.2087e-03,  ...,  1.0544e-02,
         -2.4979e-02, -1.9958e-02],
        ...,
        [ 1.5572e-02,  6.2644e-05,  2.2449e-03,  ..., -7.4625e-04,
          1.9274e-03,  5.2757e-03],
        [-1.0864e-02,  2.2339e-02, -8.3771e-03,  ...,  2.7027e-03,
          1.7319e-02, -7.6866e-03],
        [ 5.8746e-03,  5.1308e-04,  6.3248e-03,  ...,  7.2708e-03,
         -1.2901e-02,  6.5727e-03]], dtype=torch.float16), 'model.layers.0.self_attn.v_proj.weight': tensor([[ 0.0007,  0.0044,  0.0010,  ...,  0.0090,  0.0010,  0.0093],
        [-0.0099, -0.0005, -0.0035,  ..., -0.0119,  0.0113,  0.0107],
        [ 0.0048,  0.0068, -0.0029,  ...,  0.0021, -0.0156, -0.0190],
        ...,
        [-0.0073, -0.0050,  0.0162,  ...,  0.0033,  0.0020, -0.0007],
        [-0.0006,  0.0075, -0.0048,  ...,  0.0051,  0.0155,  0.0017],
        [-0.0032,  0.0046,  0.0082,  ..., -0.0016, -0.0035,  0.0023]],
       dtype=torch.float16), 'model.layers.0.self_attn.o_proj.weight': tensor([[ 1.3628e-03, -3.9444e-03,  3.8643e-03,  ...,  2.2564e-03,
          2.7990e-04, -8.9340e-03],
        [-2.4300e-03,  5.6076e-03,  1.1387e-03,  ..., -1.7481e-03,
          2.0924e-03,  5.7678e-03],
        [-3.3474e-03, -7.6914e-04,  2.4796e-03,  ..., -2.0561e-03,
         -6.5956e-03, -8.0681e-04],
        ...,
        [ 4.8943e-03, -1.4791e-03,  7.6332e-03,  ...,  2.2650e-06,
          4.2534e-03,  3.3951e-03],
        [-2.9583e-03, -1.8663e-03, -1.1358e-03,  ...,  5.2490e-03,
         -5.8899e-03, -2.8267e-03],
        [ 4.0221e-04, -1.2932e-03,  3.3665e-03,  ...,  6.5804e-03,
         -4.6806e-03, -5.0964e-03]], dtype=torch.float16), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0081,  0.0134,  0.0292,  ..., -0.0172,  0.0053,  0.0193],
        [-0.0028, -0.0027,  0.0029,  ...,  0.0147, -0.0076,  0.0114],
        [-0.0002, -0.0256,  0.0180,  ..., -0.0189,  0.0257,  0.0206],
        ...,
        [ 0.0058, -0.0258,  0.0025,  ..., -0.0036, -0.0106,  0.0365],
        [ 0.0223,  0.0168, -0.0171,  ..., -0.0017, -0.0030, -0.0196],
        [-0.0070, -0.0135, -0.0268,  ..., -0.0042,  0.0025, -0.0229]],
       dtype=torch.float16), 'model.layers.0.mlp.up_proj.weight': tensor([[-0.0072, -0.0297,  0.0135,  ..., -0.0198, -0.0236,  0.0091],
        [-0.0119, -0.0311,  0.0110,  ...,  0.0178,  0.0034,  0.0087],
        [-0.0066,  0.0157, -0.0102,  ..., -0.0231,  0.0132,  0.0038],
        ...,
        [-0.0121, -0.0005, -0.0019,  ...,  0.0259, -0.0082,  0.0114],
        [-0.0198,  0.0047,  0.0170,  ..., -0.0023, -0.0186,  0.0037],
        [ 0.0142,  0.0268, -0.0009,  ...,  0.0088, -0.0174, -0.0420]],
       dtype=torch.float16), 'model.layers.0.mlp.down_proj.weight': tensor([[ 0.0044, -0.0123,  0.0141,  ..., -0.0181, -0.0041, -0.0016],
        [-0.0006, -0.0026,  0.0135,  ...,  0.0106, -0.0167,  0.0315],
        [ 0.0044,  0.0371,  0.0019,  ..., -0.0117,  0.0212,  0.0207],
        ...,
        [-0.0078, -0.0106,  0.0062,  ...,  0.0204, -0.0163,  0.0254],
        [-0.0202,  0.0401,  0.0176,  ..., -0.0138, -0.0104, -0.0290],
        [ 0.0179, -0.0031, -0.0126,  ...,  0.0003, -0.0050, -0.0296]],
       dtype=torch.float16), 'model.layers.0.input_layernorm.weight': tensor([ 0.0193,  0.0087, -0.0008,  ...,  0.0058,  0.0089,  0.0019],
       dtype=torch.float16), 'model.layers.0.post_attention_layernorm.weight': tensor([0.0530, 0.0537, 0.0498,  ..., 0.0540, 0.0569, 0.0491],
       dtype=torch.float16), 'model.layers.1.self_attn.q_proj.weight': tensor([[-0.0228, -0.0012, -0.0327,  ..., -0.0147, -0.0572,  0.0403],
        [-0.0012, -0.0125,  0.0112,  ..., -0.0081, -0.0516,  0.0322],
        [ 0.0274,  0.0308,  0.0248,  ..., -0.0133, -0.0764,  0.0221],
        ...,
        [-0.0004,  0.0029,  0.0050,  ..., -0.0099, -0.0020, -0.0116],
        [-0.0018, -0.0048, -0.0055,  ...,  0.0103,  0.0032,  0.0117],
        [ 0.0002,  0.0064,  0.0077,  ..., -0.0088,  0.0019, -0.0165]],
       dtype=torch.float16), 'model.layers.1.self_attn.k_proj.weight': tensor([[-0.0254,  0.0089,  0.0425,  ...,  0.0178,  0.0165, -0.0135],
        [-0.0323,  0.0092, -0.0083,  ..., -0.0091,  0.0150, -0.0595],
        [-0.0262,  0.0288, -0.0696,  ...,  0.0352,  0.0172, -0.0609],
        ...,
        [-0.0149,  0.0229,  0.0028,  ...,  0.0081, -0.0048,  0.0070],
        [ 0.0114, -0.0230, -0.0001,  ..., -0.0092,  0.0033, -0.0068],
        [-0.0111,  0.0184,  0.0055,  ...,  0.0007, -0.0071,  0.0058]],
       dtype=torch.float16), 'model.layers.1.self_attn.v_proj.weight': tensor([[ 6.8245e-03, -4.9133e-03,  1.0071e-03,  ..., -4.8561e-03,
         -2.9144e-02, -2.2125e-02],
        [-5.1346e-03,  4.9515e-03, -3.3360e-03,  ...,  2.7618e-03,
          1.1398e-02,  3.1982e-02],
        [ 3.6736e-03, -1.1612e-02,  8.0032e-03,  ..., -2.2590e-05,
         -1.4648e-03, -3.3340e-03],
        ...,
        [-3.6926e-03,  5.3062e-03,  7.3509e-03,  ..., -2.7981e-03,
         -1.4305e-03,  2.2399e-04],
        [-7.8735e-03, -3.1986e-03,  7.9422e-03,  ..., -6.5727e-03,
          8.4534e-03, -5.7817e-06],
        [ 1.0643e-03,  6.4468e-03,  8.0719e-03,  ..., -6.3095e-03,
         -2.6455e-03,  1.0246e-02]], dtype=torch.float16), 'model.layers.1.self_attn.o_proj.weight': tensor([[ 0.0024, -0.0163,  0.0091,  ..., -0.0058, -0.0015, -0.0006],
        [-0.0016, -0.0059, -0.0052,  ...,  0.0035, -0.0019,  0.0037],
        [ 0.0247,  0.0128, -0.0125,  ...,  0.0022, -0.0027,  0.0011],
        ...,
        [ 0.0058,  0.0022,  0.0012,  ..., -0.0011, -0.0004, -0.0001],
        [ 0.0036, -0.0075,  0.0050,  ..., -0.0054,  0.0002,  0.0056],
        [-0.0017, -0.0238,  0.0015,  ..., -0.0021, -0.0055,  0.0007]],
       dtype=torch.float16), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0305, -0.0128,  0.0422,  ..., -0.0312, -0.0152, -0.0100],
        [-0.0312, -0.0045, -0.0312,  ...,  0.0140, -0.0307, -0.0427],
        [-0.0055, -0.0319,  0.0095,  ..., -0.0064, -0.0123, -0.0204],
        ...,
        [-0.0385,  0.0105, -0.0028,  ..., -0.0023,  0.0122,  0.0004],
        [-0.0149, -0.0031, -0.0339,  ...,  0.0217,  0.0198, -0.0084],
        [-0.0266,  0.0121,  0.0041,  ...,  0.0391,  0.0065, -0.0430]],
       dtype=torch.float16), 'model.layers.1.mlp.up_proj.weight': tensor([[-0.0034,  0.0414, -0.0204,  ...,  0.0118,  0.0263, -0.0124],
        [ 0.0071, -0.0067, -0.0129,  ..., -0.0086,  0.0069,  0.0108],
        [ 0.0309, -0.0436,  0.0134,  ...,  0.0177, -0.0427,  0.0297],
        ...,
        [-0.0148, -0.0275,  0.0184,  ...,  0.0293,  0.0069, -0.0238],
        [ 0.0356,  0.0030, -0.0164,  ...,  0.0032, -0.0060, -0.0045],
        [-0.0108, -0.0150, -0.0105,  ..., -0.0249, -0.0061,  0.0173]],
       dtype=torch.float16), 'model.layers.1.mlp.down_proj.weight': tensor([[ 0.0107,  0.0179,  0.0578,  ..., -0.0177,  0.0072, -0.0210],
        [ 0.0088,  0.0063, -0.0363,  ...,  0.0069, -0.0142,  0.0028],
        [-0.0113, -0.0138, -0.0245,  ...,  0.0014, -0.0134,  0.0023],
        ...,
        [-0.0099, -0.0073, -0.0143,  ...,  0.0442, -0.0065,  0.0090],
        [-0.0116,  0.0203,  0.0101,  ..., -0.0278, -0.0228,  0.0261],
        [ 0.0262, -0.0061, -0.0175,  ..., -0.0080, -0.0135,  0.0338]],
       dtype=torch.float16), 'model.layers.1.input_layernorm.weight': tensor([0.1050, 0.0967, 0.0884,  ..., 0.0518, 0.0781, 0.0608],
       dtype=torch.float16), 'model.layers.1.post_attention_layernorm.weight': tensor([0.0986, 0.0991, 0.0957,  ..., 0.1060, 0.1006, 0.1001],
       dtype=torch.float16), 'model.layers.2.self_attn.q_proj.weight': tensor([[-0.0236, -0.0038,  0.0098,  ..., -0.0133, -0.0098, -0.0003],
        [-0.0190,  0.0037, -0.0345,  ..., -0.0344, -0.0162,  0.0232],
        [-0.0165,  0.0366, -0.0252,  ..., -0.0018, -0.0211,  0.0159],
        ...,
        [-0.0526,  0.0145, -0.0261,  ..., -0.0085, -0.0328, -0.0351],
        [ 0.0019, -0.0063,  0.0003,  ..., -0.0023, -0.0186,  0.0160],
        [-0.0048, -0.0168,  0.0231,  ...,  0.0604, -0.0444,  0.0058]],
       dtype=torch.float16), 'model.layers.2.self_attn.k_proj.weight': tensor([[ 0.0004,  0.0156, -0.0085,  ..., -0.0106, -0.0010,  0.0175],
        [ 0.0163, -0.0154, -0.0090,  ...,  0.0110, -0.0093, -0.0075],
        [ 0.0128,  0.0151,  0.0360,  ..., -0.0084,  0.0124,  0.0131],
        ...,
        [ 0.0299,  0.0465, -0.0237,  ...,  0.0386, -0.0369,  0.0006],
        [-0.0072, -0.0126, -0.0009,  ...,  0.0045,  0.0003, -0.0041],
        [ 0.0020, -0.0215, -0.0021,  ..., -0.0809, -0.0249,  0.0965]],
       dtype=torch.float16), 'model.layers.2.self_attn.v_proj.weight': tensor([[-7.3767e-04,  6.2332e-03,  1.5961e-02,  ...,  3.8208e-02,
         -3.6240e-03, -6.9313e-03],
        [ 5.0621e-03,  1.1269e-02, -2.1118e-02,  ..., -7.7972e-03,
          7.8506e-03, -1.4595e-02],
        [-6.8617e-04,  1.8463e-02,  3.3112e-03,  ..., -2.0950e-02,
         -3.0457e-02, -2.9480e-02],
        ...,
        [-5.3465e-05, -2.5360e-02, -2.0248e-02,  ..., -1.0956e-02,
         -9.5272e-04,  3.3970e-03],
        [-3.7140e-02, -7.9775e-04,  1.4175e-02,  ..., -1.0040e-02,
         -6.6071e-03, -1.5135e-03],
        [-1.1009e-02,  1.4809e-02,  4.5662e-03,  ..., -5.1880e-03,
          1.8234e-02, -7.3395e-03]], dtype=torch.float16), 'model.layers.2.self_attn.o_proj.weight': tensor([[ 0.0041,  0.0149,  0.0103,  ...,  0.0196,  0.0020, -0.0260],
        [ 0.0006, -0.0130,  0.0079,  ...,  0.0049, -0.0125, -0.0198],
        [-0.0215,  0.0032, -0.0169,  ..., -0.0224, -0.0103,  0.0078],
        ...,
        [-0.0046, -0.0235,  0.0281,  ..., -0.0049, -0.0220,  0.0198],
        [ 0.0184, -0.0113,  0.0301,  ...,  0.0192, -0.0004, -0.0239],
        [-0.0107,  0.0023,  0.0075,  ..., -0.0129,  0.0050, -0.0142]],
       dtype=torch.float16), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0072,  0.0239, -0.0107,  ..., -0.0090,  0.0302, -0.0034],
        [ 0.0013,  0.0012, -0.0015,  ...,  0.0126, -0.0138, -0.0115],
        [-0.0069, -0.0083,  0.0255,  ..., -0.0112,  0.0158,  0.0069],
        ...,
        [ 0.0342, -0.0119, -0.0193,  ..., -0.0285, -0.0400, -0.0150],
        [-0.0113, -0.0116, -0.0017,  ...,  0.0174, -0.0425,  0.0180],
        [-0.0015,  0.0111,  0.0085,  ..., -0.0133, -0.0261,  0.0048]],
       dtype=torch.float16), 'model.layers.2.mlp.up_proj.weight': tensor([[-0.0008, -0.0006,  0.0139,  ..., -0.0152,  0.0090, -0.0034],
        [ 0.0053, -0.0186, -0.0090,  ...,  0.0056,  0.0114,  0.0062],
        [ 0.0306,  0.0189,  0.0293,  ..., -0.0141, -0.0088,  0.0175],
        ...,
        [-0.0071, -0.0148,  0.0009,  ..., -0.0116, -0.0025,  0.0209],
        [ 0.0155, -0.0129,  0.0144,  ...,  0.0003,  0.0049, -0.0228],
        [-0.0146, -0.0302, -0.0243,  ..., -0.0050,  0.0011, -0.0050]],
       dtype=torch.float16), 'model.layers.2.mlp.down_proj.weight': tensor([[ 0.0146,  0.0174,  0.0375,  ..., -0.0273, -0.0011, -0.0335],
        [ 0.0209, -0.0227, -0.0188,  ...,  0.0180,  0.0023, -0.0226],
        [ 0.0438, -0.0178,  0.0010,  ..., -0.0302,  0.0004, -0.0330],
        ...,
        [-0.0133,  0.0283, -0.0105,  ..., -0.0015, -0.0013, -0.0135],
        [-0.0211,  0.0298,  0.0079,  ...,  0.0158, -0.0182, -0.0113],
        [ 0.0315,  0.0117, -0.0220,  ...,  0.0192, -0.0449, -0.0119]],
       dtype=torch.float16), 'model.layers.2.input_layernorm.weight': tensor([0.1729, 0.1787, 0.1709,  ..., 0.1768, 0.1680, 0.1748],
       dtype=torch.float16), 'model.layers.2.post_attention_layernorm.weight': tensor([0.1338, 0.1377, 0.1367,  ..., 0.1367, 0.1387, 0.1367],
       dtype=torch.float16), 'model.layers.3.self_attn.q_proj.weight': tensor([[ 0.0001,  0.0111,  0.0058,  ...,  0.0241,  0.0127,  0.0220],
        [-0.0121,  0.0172, -0.0149,  ..., -0.0432,  0.0006, -0.0074],
        [ 0.0129,  0.0027, -0.0203,  ...,  0.0116, -0.0187, -0.0406],
        ...,
        [ 0.0717, -0.0696,  0.0428,  ..., -0.0779, -0.0139,  0.0070],
        [-0.0797,  0.0404, -0.0023,  ...,  0.0363,  0.0769,  0.0251],
        [-0.0153, -0.0497,  0.0779,  ..., -0.0225, -0.0032, -0.0130]],
       dtype=torch.float16), 'model.layers.3.self_attn.k_proj.weight': tensor([[ 0.0074, -0.0077, -0.0088,  ..., -0.0140,  0.0067,  0.0404],
        [-0.0116,  0.0102, -0.0252,  ...,  0.0031, -0.0150, -0.0390],
        [ 0.0029, -0.0079,  0.0005,  ...,  0.0074, -0.0090, -0.0374],
        ...,
        [ 0.0884, -0.0848,  0.0065,  ..., -0.0621,  0.0024,  0.0343],
        [-0.0830,  0.0328,  0.0418,  ...,  0.0079,  0.0463, -0.0032],
        [ 0.0020, -0.0524,  0.0955,  ..., -0.0163,  0.0029, -0.0172]],
       dtype=torch.float16), 'model.layers.3.self_attn.v_proj.weight': tensor([[-0.0039,  0.0125, -0.0059,  ..., -0.0148,  0.0063, -0.0150],
        [-0.0113,  0.0269, -0.0179,  ..., -0.0122, -0.0101, -0.0094],
        [ 0.0024, -0.0062,  0.0057,  ..., -0.0406, -0.0087, -0.0281],
        ...,
        [-0.0131, -0.0097, -0.0019,  ...,  0.0023, -0.0041, -0.0064],
        [ 0.0055, -0.0019,  0.0020,  ...,  0.0007, -0.0084,  0.0018],
        [-0.0120, -0.0069,  0.0093,  ..., -0.0012, -0.0018,  0.0084]],
       dtype=torch.float16), 'model.layers.3.self_attn.o_proj.weight': tensor([[-2.7054e-02,  5.7945e-03, -1.2451e-02,  ...,  2.7256e-03,
         -1.1616e-03, -2.2335e-03],
        [ 2.4536e-02, -2.4429e-02, -1.0193e-02,  ...,  6.5651e-03,
         -2.5272e-03, -2.3193e-03],
        [-3.7498e-03, -1.3260e-02,  1.9197e-03,  ...,  2.6493e-03,
          3.3932e-03,  8.3084e-03],
        ...,
        [ 1.1963e-02,  1.3344e-02,  1.3680e-02,  ...,  1.3313e-03,
          7.1793e-03,  9.9335e-03],
        [ 1.7960e-02,  2.6199e-02,  2.9206e-06,  ...,  3.6945e-03,
         -1.1940e-03, -2.8419e-03],
        [ 8.5297e-03, -9.2773e-03,  1.0519e-03,  ..., -6.4993e-04,
          5.8823e-03,  1.0956e-02]], dtype=torch.float16), 'model.layers.3.mlp.gate_proj.weight': tensor([[ 0.0009, -0.0099, -0.0182,  ..., -0.0315,  0.0460,  0.0153],
        [ 0.0189,  0.0017, -0.0123,  ..., -0.0025, -0.0261, -0.0161],
        [-0.0253,  0.0021, -0.0174,  ...,  0.0050, -0.0040, -0.0361],
        ...,
        [-0.0003,  0.0394,  0.0065,  ...,  0.0199, -0.0123, -0.0001],
        [-0.0057,  0.0087, -0.0060,  ...,  0.0003, -0.0041, -0.0112],
        [-0.0025, -0.0155,  0.0031,  ...,  0.0264, -0.0254,  0.0148]],
       dtype=torch.float16), 'model.layers.3.mlp.up_proj.weight': tensor([[-0.0160,  0.0154,  0.0104,  ...,  0.0014,  0.0186, -0.0085],
        [-0.0123, -0.0174,  0.0343,  ...,  0.0175,  0.0141, -0.0052],
        [-0.0005, -0.0031, -0.0144,  ..., -0.0012,  0.0091, -0.0125],
        ...,
        [-0.0042, -0.0016, -0.0006,  ...,  0.0215,  0.0084, -0.0228],
        [ 0.0052, -0.0099, -0.0050,  ...,  0.0113, -0.0249, -0.0080],
        [ 0.0486, -0.0004, -0.0031,  ...,  0.0433,  0.0057,  0.0085]],
       dtype=torch.float16), 'model.layers.3.mlp.down_proj.weight': tensor([[ 0.0014, -0.0079, -0.0008,  ..., -0.0033,  0.0087,  0.0142],
        [ 0.0225,  0.0028,  0.0088,  ..., -0.0140, -0.0148, -0.0148],
        [ 0.0144,  0.0119, -0.0174,  ..., -0.0200, -0.0066,  0.0060],
        ...,
        [ 0.0280, -0.0107, -0.0166,  ...,  0.0040,  0.0193,  0.0221],
        [-0.0217,  0.0099, -0.0106,  ..., -0.0006, -0.0170,  0.0130],
        [ 0.0110, -0.0169, -0.0266,  ...,  0.0033,  0.0121,  0.0063]],
       dtype=torch.float16), 'model.layers.3.input_layernorm.weight': tensor([0.2852, 0.2852, 0.2832,  ..., 0.2812, 0.2910, 0.2969],
       dtype=torch.float16), 'model.layers.3.post_attention_layernorm.weight': tensor([0.1738, 0.1748, 0.1689,  ..., 0.1719, 0.1719, 0.1758],
       dtype=torch.float16), 'model.layers.4.self_attn.q_proj.weight': tensor([[-0.0206, -0.0058,  0.0019,  ..., -0.0113, -0.0038,  0.0106],
        [ 0.0190, -0.0170, -0.0051,  ...,  0.0039, -0.0259, -0.0004],
        [-0.0124, -0.0312,  0.0122,  ..., -0.0027, -0.0195, -0.0239],
        ...,
        [ 0.0246,  0.0004, -0.0039,  ...,  0.0032,  0.0244, -0.0600],
        [-0.0293,  0.0085,  0.0295,  ..., -0.0561,  0.0037,  0.0337],
        [-0.0074, -0.0351,  0.0680,  ...,  0.0638,  0.0376, -0.0406]],
       dtype=torch.float16), 'model.layers.4.self_attn.k_proj.weight': tensor([[-0.0037,  0.0210, -0.0139,  ..., -0.0044,  0.0025, -0.0019],
        [-0.0307, -0.0041, -0.0032,  ..., -0.0014,  0.0142, -0.0028],
        [ 0.0089, -0.0021, -0.0143,  ...,  0.0076,  0.0189,  0.0352],
        ...,
        [-0.0089,  0.1188,  0.0593,  ...,  0.0388, -0.0216, -0.0060],
        [ 0.0320,  0.0533, -0.0162,  ...,  0.0641, -0.0399,  0.0720],
        [ 0.0100,  0.0640,  0.0195,  ..., -0.0011,  0.0424, -0.0209]],
       dtype=torch.float16), 'model.layers.4.self_attn.v_proj.weight': tensor([[-3.6507e-03, -8.4000e-03,  1.2493e-03,  ..., -6.4735e-03,
         -3.6030e-03, -6.0320e-05],
        [-1.4557e-02,  3.6133e-02,  5.1346e-03,  ...,  3.2978e-03,
          1.1721e-03,  2.7237e-03],
        [ 1.0719e-02, -6.2370e-03, -3.4729e-02,  ...,  5.4436e-03,
         -1.3771e-03, -1.8631e-02],
        ...,
        [-3.3283e-03, -8.3771e-03, -2.2263e-02,  ..., -9.6893e-03,
         -1.1740e-03,  3.3360e-03],
        [-2.0599e-03, -1.0277e-02, -1.9855e-03,  ...,  7.9956e-03,
         -1.5678e-03,  4.0550e-03],
        [-2.6131e-04, -1.7914e-02, -3.6087e-03,  ..., -5.3263e-04,
         -5.2681e-03,  1.1940e-02]], dtype=torch.float16), 'model.layers.4.self_attn.o_proj.weight': tensor([[ 0.0270,  0.0083, -0.0050,  ..., -0.0021, -0.0267, -0.0015],
        [ 0.0075, -0.0009, -0.0082,  ...,  0.0017, -0.0215,  0.0036],
        [-0.0045,  0.0041, -0.0073,  ..., -0.0134,  0.0101, -0.0084],
        ...,
        [-0.0148,  0.0272, -0.0037,  ..., -0.0209,  0.0081, -0.0208],
        [ 0.0033, -0.0025, -0.0150,  ..., -0.0094, -0.0004, -0.0059],
        [ 0.0100,  0.0215, -0.0056,  ..., -0.0007,  0.0051,  0.0010]],
       dtype=torch.float16), 'model.layers.4.mlp.gate_proj.weight': tensor([[-0.0053,  0.0065, -0.0110,  ..., -0.0182, -0.0035, -0.0159],
        [-0.0267,  0.0111,  0.0142,  ...,  0.0066,  0.0154, -0.0106],
        [-0.0136, -0.0220, -0.0006,  ...,  0.0055, -0.0028,  0.0260],
        ...,
        [ 0.0008, -0.0025,  0.0095,  ..., -0.0211,  0.0097, -0.0120],
        [-0.0265,  0.0148, -0.0281,  ...,  0.0098,  0.0180, -0.0102],
        [ 0.0017, -0.0143, -0.0135,  ..., -0.0124,  0.0221,  0.0190]],
       dtype=torch.float16), 'model.layers.4.mlp.up_proj.weight': tensor([[-1.6373e-02, -5.6725e-03, -4.0833e-02,  ...,  8.6670e-03,
         -8.2254e-04, -5.4932e-03],
        [-2.2400e-02, -4.0680e-02,  5.3253e-03,  ..., -8.6517e-03,
          9.8953e-03, -2.4872e-02],
        [-1.2989e-03,  2.9587e-02,  7.5042e-05,  ..., -2.8885e-02,
         -1.1322e-02,  8.4839e-03],
        ...,
        [-8.8882e-03, -3.1769e-02, -7.3433e-03,  ...,  1.2138e-02,
         -6.8016e-03,  5.5023e-02],
        [ 1.2787e-02, -1.0330e-02, -1.5060e-02,  ..., -4.2175e-02,
         -1.6281e-02,  9.5596e-03],
        [ 3.7937e-03,  1.3062e-02,  8.8272e-03,  ...,  3.7594e-03,
         -3.4237e-03, -2.4376e-03]], dtype=torch.float16), 'model.layers.4.mlp.down_proj.weight': tensor([[ 2.3834e-02, -4.2458e-03,  2.3529e-02,  ..., -1.9836e-02,
         -8.3983e-05,  2.9861e-02],
        [-5.7335e-03, -4.8859e-02,  4.5746e-02,  ..., -2.4323e-02,
         -2.1210e-02, -7.2365e-03],
        [-2.9135e-04, -2.7969e-02,  1.6556e-02,  ...,  1.1406e-02,
         -2.8000e-03,  2.2263e-02],
        ...,
        [-3.4393e-02, -1.9779e-03, -9.8801e-03,  ...,  2.4658e-02,
          2.1534e-03,  1.5030e-02],
        [-7.8430e-03,  1.8177e-03, -2.0020e-02,  ...,  1.2718e-02,
         -4.1931e-02, -1.1818e-02],
        [ 1.6479e-02, -3.2135e-02, -1.5076e-02,  ..., -3.5000e-03,
         -4.4739e-02, -2.3956e-02]], dtype=torch.float16), 'model.layers.4.input_layernorm.weight': tensor([0.2617, 0.2676, 0.2617,  ..., 0.2578, 0.2656, 0.2734],
       dtype=torch.float16), 'model.layers.4.post_attention_layernorm.weight': tensor([0.1914, 0.1895, 0.1855,  ..., 0.1904, 0.1885, 0.1895],
       dtype=torch.float16), 'model.layers.5.self_attn.q_proj.weight': tensor([[-0.0089, -0.0005, -0.0254,  ..., -0.0074, -0.0164,  0.0120],
        [-0.0202,  0.0197,  0.0401,  ..., -0.0054, -0.0094, -0.0347],
        [ 0.0045,  0.0043, -0.0135,  ...,  0.0205, -0.0172,  0.0105],
        ...,
        [-0.0121,  0.0095, -0.0033,  ...,  0.0542,  0.0104,  0.0356],
        [ 0.0433,  0.0046,  0.0262,  ..., -0.0415, -0.0351, -0.0303],
        [ 0.0103,  0.0194,  0.0370,  ..., -0.0282, -0.0147, -0.0007]],
       dtype=torch.float16), 'model.layers.5.self_attn.k_proj.weight': tensor([[-0.0049,  0.0373,  0.0067,  ...,  0.0198, -0.0056, -0.0016],
        [ 0.0006,  0.0027, -0.0324,  ...,  0.0231, -0.0123,  0.0318],
        [-0.0116, -0.0233,  0.0013,  ...,  0.0026, -0.0059,  0.0032],
        ...,
        [ 0.0031, -0.0016, -0.0228,  ...,  0.0397,  0.0098, -0.0320],
        [ 0.0524,  0.0166, -0.0242,  ..., -0.0012, -0.0159, -0.0361],
        [-0.0242, -0.0217,  0.0421,  ..., -0.0155, -0.0347,  0.0102]],
       dtype=torch.float16), 'model.layers.5.self_attn.v_proj.weight': tensor([[-3.0975e-02,  6.6643e-03,  9.8114e-03,  ...,  2.2919e-02,
          7.3671e-05,  2.3392e-02],
        [ 3.9635e-03,  1.0124e-02, -1.8448e-02,  ..., -1.1353e-02,
          3.7670e-03, -1.3893e-02],
        [ 2.2354e-02,  2.4128e-03, -2.9063e-04,  ..., -2.4063e-02,
          2.8976e-02,  1.1208e-02],
        ...,
        [ 2.0477e-02,  1.1581e-02,  1.0353e-02,  ...,  3.7048e-02,
         -5.7449e-03,  1.1454e-03],
        [-5.3596e-03,  3.0289e-03, -4.7684e-03,  ...,  9.9945e-04,
         -9.2010e-03,  8.7404e-04],
        [-1.2375e-02, -6.2561e-03,  2.1561e-02,  ..., -9.5673e-03,
         -9.2545e-03, -1.5900e-02]], dtype=torch.float16), 'model.layers.5.self_attn.o_proj.weight': tensor([[-0.0155, -0.0091,  0.0050,  ..., -0.0181, -0.0074,  0.0271],
        [ 0.0017,  0.0016, -0.0094,  ..., -0.0182,  0.0043,  0.0034],
        [-0.0014, -0.0026,  0.0131,  ...,  0.0181,  0.0119,  0.0234],
        ...,
        [ 0.0181,  0.0066, -0.0060,  ...,  0.0162,  0.0306, -0.0247],
        [-0.0016,  0.0017, -0.0038,  ..., -0.0184, -0.0139, -0.0013],
        [ 0.0051,  0.0035, -0.0148,  ..., -0.0011, -0.0060, -0.0158]],
       dtype=torch.float16), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0002, -0.0082, -0.0302,  ...,  0.0003, -0.0062, -0.0114],
        [ 0.0216, -0.0073, -0.0212,  ...,  0.0374, -0.0015,  0.0022],
        [ 0.0123,  0.0039, -0.0196,  ...,  0.0148,  0.0164, -0.0348],
        ...,
        [ 0.0065,  0.0096,  0.0416,  ..., -0.0671,  0.0157, -0.0199],
        [-0.0280,  0.0043,  0.0038,  ...,  0.0014,  0.0170, -0.0017],
        [ 0.0282, -0.0299, -0.0141,  ..., -0.0040, -0.0043, -0.0409]],
       dtype=torch.float16), 'model.layers.5.mlp.up_proj.weight': tensor([[-0.0063, -0.0135, -0.0069,  ..., -0.0147,  0.0037, -0.0168],
        [-0.0320, -0.0062,  0.0009,  ...,  0.0124,  0.0182,  0.0228],
        [-0.0019,  0.0090,  0.0094,  ...,  0.0040,  0.0080,  0.0185],
        ...,
        [ 0.0077,  0.0239, -0.0076,  ..., -0.0109,  0.0145,  0.0252],
        [ 0.0447, -0.0130, -0.0292,  ..., -0.0080, -0.0179,  0.0240],
        [ 0.0085,  0.0172,  0.0130,  ..., -0.0103, -0.0041, -0.0160]],
       dtype=torch.float16), 'model.layers.5.mlp.down_proj.weight': tensor([[-0.0074, -0.0270, -0.0031,  ...,  0.0008,  0.0067,  0.0141],
        [-0.0113,  0.0156,  0.0281,  ...,  0.0215,  0.0064, -0.0341],
        [ 0.0131,  0.0207,  0.0143,  ..., -0.0241, -0.0463,  0.0110],
        ...,
        [ 0.0110, -0.0240, -0.0051,  ...,  0.0063, -0.0257, -0.0186],
        [-0.0034, -0.0391,  0.0152,  ...,  0.0161,  0.0156, -0.0515],
        [ 0.0212,  0.0142, -0.0118,  ...,  0.0309,  0.0092, -0.0177]],
       dtype=torch.float16), 'model.layers.5.input_layernorm.weight': tensor([0.2617, 0.2695, 0.2637,  ..., 0.2500, 0.2695, 0.2676],
       dtype=torch.float16), 'model.layers.5.post_attention_layernorm.weight': tensor([0.2090, 0.1953, 0.1934,  ..., 0.2051, 0.2021, 0.2051],
       dtype=torch.float16), 'model.layers.6.self_attn.q_proj.weight': tensor([[-9.7351e-03, -1.1505e-02,  6.6071e-03,  ..., -3.3630e-02,
         -6.4468e-03, -4.9515e-03],
        [ 4.4250e-03, -6.5613e-03,  5.6343e-03,  ...,  1.4587e-02,
          3.5286e-03, -3.1464e-02],
        [-1.7654e-02,  2.4216e-02, -3.8513e-02,  ...,  3.0502e-02,
         -4.8431e-02, -3.2272e-03],
        ...,
        [ 1.2878e-02,  9.0103e-03, -3.7628e-02,  ...,  2.3987e-02,
          2.7657e-03,  1.5497e-03],
        [ 3.5614e-02,  3.2532e-02,  5.3329e-03,  ..., -9.7885e-03,
         -9.6497e-02, -2.0844e-02],
        [-6.3538e-02, -5.3558e-02, -4.8697e-05,  ...,  1.7288e-02,
          5.1155e-03,  8.5220e-03]], dtype=torch.float16), 'model.layers.6.self_attn.k_proj.weight': tensor([[ 0.0139, -0.0106,  0.0204,  ..., -0.0071,  0.0222,  0.0589],
        [-0.0198, -0.0036,  0.0422,  ...,  0.0071, -0.0126,  0.0158],
        [-0.0102, -0.0131, -0.0068,  ..., -0.0006, -0.0307, -0.0107],
        ...,
        [ 0.0214, -0.0376, -0.0183,  ...,  0.0607, -0.0023, -0.0482],
        [-0.0199,  0.0045, -0.0262,  ..., -0.0461, -0.0408,  0.0156],
        [-0.0544, -0.0241, -0.0399,  ...,  0.0161, -0.0420, -0.0188]],
       dtype=torch.float16), 'model.layers.6.self_attn.v_proj.weight': tensor([[ 0.0140,  0.0336,  0.0101,  ...,  0.0127, -0.0017,  0.0078],
        [ 0.0381, -0.0063, -0.0095,  ...,  0.0046, -0.0005,  0.0038],
        [-0.0079, -0.0024,  0.0124,  ...,  0.0101,  0.0240,  0.0046],
        ...,
        [-0.0221, -0.0061,  0.0052,  ...,  0.0010, -0.0165,  0.0085],
        [-0.0243, -0.0088, -0.0003,  ..., -0.0012, -0.0083,  0.0198],
        [ 0.0311,  0.0049,  0.0161,  ..., -0.0222,  0.0005, -0.0030]],
       dtype=torch.float16), 'model.layers.6.self_attn.o_proj.weight': tensor([[ 0.0112, -0.0127, -0.0365,  ..., -0.0135,  0.0086,  0.0113],
        [-0.0260,  0.0067, -0.0001,  ..., -0.0224,  0.0014, -0.0022],
        [ 0.0019, -0.0115, -0.0042,  ...,  0.0106,  0.0079,  0.0094],
        ...,
        [-0.0053, -0.0143, -0.0063,  ...,  0.0074, -0.0062,  0.0256],
        [-0.0204,  0.0092, -0.0014,  ..., -0.0024,  0.0081, -0.0214],
        [-0.0201, -0.0129,  0.0079,  ..., -0.0237,  0.0066,  0.0064]],
       dtype=torch.float16), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0222,  0.0260, -0.0189,  ..., -0.0039, -0.0074, -0.0042],
        [ 0.0321,  0.0016, -0.0231,  ...,  0.0066,  0.0205,  0.0123],
        [-0.0146,  0.0217, -0.0156,  ..., -0.0187,  0.0011,  0.0088],
        ...,
        [ 0.0056, -0.0261,  0.0048,  ...,  0.0091, -0.0184, -0.0066],
        [ 0.0083,  0.0047, -0.0169,  ..., -0.0235, -0.0025, -0.0016],
        [-0.0396, -0.0513,  0.0267,  ..., -0.0413, -0.0027,  0.0164]],
       dtype=torch.float16), 'model.layers.6.mlp.up_proj.weight': tensor([[-0.0147, -0.0145, -0.0228,  ...,  0.0067, -0.0053, -0.0105],
        [ 0.0071, -0.0485,  0.0392,  ...,  0.0123,  0.0003, -0.0055],
        [-0.0220, -0.0162, -0.0241,  ...,  0.0055,  0.0135,  0.0216],
        ...,
        [-0.0267,  0.0002,  0.0167,  ...,  0.0149, -0.0019,  0.0385],
        [ 0.0244,  0.0173, -0.0063,  ..., -0.0283,  0.0101,  0.0017],
        [-0.0249,  0.0287, -0.0220,  ...,  0.0081, -0.0178, -0.0498]],
       dtype=torch.float16), 'model.layers.6.mlp.down_proj.weight': tensor([[-0.0122,  0.0100, -0.0043,  ...,  0.0013,  0.0143,  0.0160],
        [-0.0081, -0.0157,  0.0045,  ..., -0.0036, -0.0266, -0.0125],
        [ 0.0030,  0.0159, -0.0086,  ...,  0.0244,  0.0240,  0.0227],
        ...,
        [ 0.0110, -0.0024,  0.0207,  ...,  0.0316, -0.0336, -0.0099],
        [ 0.0216, -0.0065,  0.0070,  ...,  0.0098, -0.0135, -0.0126],
        [ 0.0152, -0.0165, -0.0085,  ...,  0.0319, -0.0050,  0.0079]],
       dtype=torch.float16), 'model.layers.6.input_layernorm.weight': tensor([0.3223, 0.3613, 0.3242,  ..., 0.3145, 0.3359, 0.3223],
       dtype=torch.float16), 'model.layers.6.post_attention_layernorm.weight': tensor([0.2217, 0.2129, 0.2090,  ..., 0.2227, 0.2168, 0.2178],
       dtype=torch.float16), 'model.layers.7.self_attn.q_proj.weight': tensor([[-6.2637e-03, -1.0843e-03, -8.1658e-06,  ..., -3.4428e-03,
         -2.0752e-02, -6.3477e-03],
        [-1.0460e-02,  1.4365e-04, -1.0338e-03,  ...,  1.2947e-02,
         -3.6564e-03, -1.6739e-02],
        [ 5.0201e-03,  6.6719e-03, -3.1158e-02,  ..., -2.0416e-02,
         -7.5684e-03,  9.1553e-03],
        ...,
        [-1.5259e-03, -3.3752e-02, -2.5040e-02,  ..., -1.2718e-02,
          3.4180e-02,  3.5553e-02],
        [ 1.3344e-02,  5.2917e-02, -4.0039e-02,  ..., -1.1269e-02,
         -6.7383e-02, -5.6915e-02],
        [ 7.9102e-02, -2.4200e-02, -1.8158e-02,  ...,  8.2947e-02,
          3.1113e-02, -4.3716e-03]], dtype=torch.float16), 'model.layers.7.self_attn.k_proj.weight': tensor([[ 0.0032, -0.0077, -0.0123,  ...,  0.0064,  0.0024, -0.0099],
        [-0.0070, -0.0178,  0.0048,  ..., -0.0072,  0.0043,  0.0185],
        [-0.0024, -0.0103,  0.0107,  ..., -0.0082, -0.0065, -0.0179],
        ...,
        [ 0.0429,  0.0077,  0.0243,  ...,  0.0351,  0.0396,  0.0282],
        [ 0.0400,  0.0500, -0.0002,  ..., -0.0307, -0.0344, -0.0016],
        [ 0.0403,  0.0058,  0.0104,  ..., -0.0012,  0.0019, -0.0272]],
       dtype=torch.float16), 'model.layers.7.self_attn.v_proj.weight': tensor([[-1.4038e-02,  5.2605e-03,  1.2993e-02,  ...,  2.8549e-02,
          4.2191e-03, -1.3847e-02],
        [ 2.6672e-02, -2.6993e-02,  4.3640e-03,  ...,  2.0035e-02,
         -1.8890e-02, -1.5915e-02],
        [-6.8970e-03, -1.0094e-02, -3.4523e-03,  ..., -1.8097e-02,
          1.1665e-02, -7.9453e-05],
        ...,
        [-1.3485e-03, -3.8300e-02,  2.7924e-03,  ...,  5.7297e-03,
         -6.9427e-03, -4.0016e-03],
        [-3.7872e-02,  1.9394e-02, -2.7618e-02,  ..., -1.8707e-02,
          1.0628e-02, -1.9252e-04],
        [-7.4272e-03,  2.6951e-03, -8.4991e-03,  ...,  2.0401e-02,
          7.3357e-03,  1.1787e-02]], dtype=torch.float16), 'model.layers.7.self_attn.o_proj.weight': tensor([[ 0.0116, -0.0154,  0.0014,  ...,  0.0091, -0.0194,  0.0053],
        [-0.0066,  0.0281,  0.0115,  ..., -0.0417, -0.0176, -0.0100],
        [ 0.0047, -0.0011, -0.0201,  ..., -0.0096, -0.0059, -0.0107],
        ...,
        [-0.0163, -0.0252, -0.0036,  ...,  0.0259, -0.0186,  0.0010],
        [-0.0226,  0.0085,  0.0167,  ...,  0.0080, -0.0130,  0.0153],
        [ 0.0028, -0.0002,  0.0005,  ...,  0.0060, -0.0161,  0.0039]],
       dtype=torch.float16), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 7.7896e-03,  4.7340e-03, -5.0850e-03,  ..., -4.3983e-03,
         -3.3386e-02, -7.2746e-03],
        [-3.1647e-02,  1.0490e-02, -8.5449e-03,  ..., -4.9400e-03,
         -3.8891e-03,  2.0676e-03],
        [ 1.7075e-02, -3.0640e-02, -8.4043e-06,  ...,  2.5543e-02,
         -2.7069e-02,  3.4237e-03],
        ...,
        [ 1.6441e-03,  2.0504e-03, -1.4145e-02,  ..., -2.0462e-02,
          4.6463e-03, -2.1713e-02],
        [ 2.6989e-03,  1.8036e-02,  1.2131e-02,  ..., -4.7798e-03,
          6.1493e-03, -3.0258e-02],
        [ 1.9714e-02, -1.6556e-02, -1.0773e-02,  ...,  1.7761e-02,
          1.8799e-02, -6.9962e-03]], dtype=torch.float16), 'model.layers.7.mlp.up_proj.weight': tensor([[ 0.0250,  0.0014, -0.0038,  ...,  0.0224, -0.0396,  0.0026],
        [-0.0110, -0.0190,  0.0299,  ...,  0.0095, -0.0108,  0.0154],
        [ 0.0259, -0.0214,  0.0107,  ..., -0.0126,  0.0181, -0.0352],
        ...,
        [-0.0019, -0.0023, -0.0150,  ..., -0.0095, -0.0177,  0.0024],
        [ 0.0003,  0.0084,  0.0167,  ..., -0.0071,  0.0215, -0.0067],
        [-0.0245, -0.0151,  0.0063,  ...,  0.0170,  0.0119,  0.0050]],
       dtype=torch.float16), 'model.layers.7.mlp.down_proj.weight': tensor([[-0.0079, -0.0069,  0.0050,  ..., -0.0115, -0.0060, -0.0211],
        [-0.0095, -0.0072,  0.0217,  ..., -0.0125,  0.0093,  0.0047],
        [ 0.0106,  0.0077,  0.0231,  ..., -0.0157, -0.0048, -0.0210],
        ...,
        [-0.0100,  0.0002, -0.0191,  ...,  0.0123,  0.0022, -0.0257],
        [ 0.0428, -0.0037,  0.0073,  ..., -0.0168,  0.0043, -0.0133],
        [ 0.0117,  0.0195, -0.0333,  ...,  0.0041, -0.0196, -0.0012]],
       dtype=torch.float16), 'model.layers.7.input_layernorm.weight': tensor([0.3242, 0.3652, 0.3340,  ..., 0.3203, 0.3574, 0.3320],
       dtype=torch.float16), 'model.layers.7.post_attention_layernorm.weight': tensor([0.2383, 0.2197, 0.2236,  ..., 0.2314, 0.2324, 0.2314],
       dtype=torch.float16), 'model.layers.8.self_attn.q_proj.weight': tensor([[-0.0004, -0.0152, -0.0297,  ..., -0.0065,  0.0065, -0.0091],
        [-0.0125, -0.0141, -0.0328,  ...,  0.0038, -0.0112,  0.0025],
        [-0.0400, -0.0028, -0.0129,  ..., -0.0023,  0.0260, -0.0321],
        ...,
        [-0.0062,  0.0861,  0.0443,  ..., -0.0247, -0.0285, -0.0468],
        [ 0.0012, -0.0596, -0.0192,  ...,  0.0352,  0.0269, -0.0008],
        [-0.0648, -0.0531, -0.0116,  ..., -0.0541,  0.0303, -0.0170]],
       dtype=torch.float16), 'model.layers.8.self_attn.k_proj.weight': tensor([[-0.0032, -0.0058, -0.0180,  ..., -0.0109,  0.0052,  0.0049],
        [-0.0125,  0.0011, -0.0050,  ...,  0.0228, -0.0019,  0.0143],
        [-0.0167,  0.0023,  0.0027,  ...,  0.0063, -0.0082, -0.0249],
        ...,
        [ 0.0031, -0.0395, -0.0067,  ..., -0.0295, -0.0149,  0.0230],
        [ 0.0078,  0.0294,  0.0184,  ..., -0.0301,  0.0431, -0.0562],
        [ 0.0190, -0.0026, -0.0326,  ...,  0.0140,  0.0077, -0.0147]],
       dtype=torch.float16), 'model.layers.8.self_attn.v_proj.weight': tensor([[-0.0287, -0.0166,  0.0045,  ..., -0.0193, -0.0085, -0.0096],
        [-0.0234, -0.0132,  0.0059,  ...,  0.0352,  0.0096,  0.0248],
        [-0.0082,  0.0140,  0.0135,  ..., -0.0079,  0.0031, -0.0204],
        ...,
        [ 0.0319, -0.0149,  0.0065,  ...,  0.0218, -0.0201,  0.0271],
        [ 0.0327, -0.0165,  0.0041,  ...,  0.0074, -0.0036,  0.0023],
        [ 0.0126, -0.0004, -0.0005,  ..., -0.0017,  0.0009, -0.0126]],
       dtype=torch.float16), 'model.layers.8.self_attn.o_proj.weight': tensor([[ 0.0177,  0.0157, -0.0148,  ..., -0.0109,  0.0026,  0.0176],
        [ 0.0054,  0.0004, -0.0322,  ..., -0.0121, -0.0108, -0.0186],
        [ 0.0025,  0.0138, -0.0094,  ..., -0.0011,  0.0121,  0.0166],
        ...,
        [-0.0150,  0.0233, -0.0010,  ...,  0.0010, -0.0001, -0.0027],
        [ 0.0086,  0.0015, -0.0089,  ...,  0.0043,  0.0054, -0.0251],
        [-0.0232, -0.0003, -0.0096,  ...,  0.0193, -0.0100,  0.0087]],
       dtype=torch.float16), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0158, -0.0021, -0.0490,  ...,  0.0059, -0.0245, -0.0163],
        [-0.0002, -0.0475,  0.0061,  ..., -0.0033, -0.0370,  0.0276],
        [ 0.0212,  0.0191,  0.0176,  ...,  0.0272,  0.0241, -0.0056],
        ...,
        [-0.0111,  0.0015,  0.0134,  ...,  0.0221,  0.0168,  0.0057],
        [-0.0146,  0.0039,  0.0056,  ..., -0.0016, -0.0165,  0.0145],
        [-0.0243,  0.0096, -0.0066,  ..., -0.0134,  0.0060,  0.0033]],
       dtype=torch.float16), 'model.layers.8.mlp.up_proj.weight': tensor([[-0.0055,  0.0251, -0.0157,  ...,  0.0298,  0.0039, -0.0158],
        [-0.0517,  0.0134, -0.0384,  ...,  0.0145, -0.0113, -0.0159],
        [ 0.0176, -0.0004,  0.0102,  ..., -0.0102, -0.0179,  0.0334],
        ...,
        [-0.0138,  0.0403, -0.0309,  ...,  0.0130,  0.0027,  0.0163],
        [ 0.0054, -0.0047, -0.0058,  ..., -0.0160,  0.0193, -0.0173],
        [-0.0224,  0.0174, -0.0155,  ..., -0.0185, -0.0012, -0.0002]],
       dtype=torch.float16), 'model.layers.8.mlp.down_proj.weight': tensor([[-0.0099, -0.0094,  0.0129,  ...,  0.0072,  0.0198, -0.0290],
        [ 0.0178,  0.0132, -0.0227,  ..., -0.0072,  0.0143, -0.0171],
        [ 0.0061, -0.0186, -0.0251,  ..., -0.0091, -0.0019,  0.0038],
        ...,
        [ 0.0090, -0.0205, -0.0343,  ...,  0.0038,  0.0098, -0.0160],
        [ 0.0096,  0.0107, -0.0036,  ..., -0.0060, -0.0068, -0.0226],
        [-0.0031,  0.0103,  0.0024,  ...,  0.0047,  0.0011,  0.0048]],
       dtype=torch.float16), 'model.layers.8.input_layernorm.weight': tensor([0.3301, 0.3477, 0.3320,  ..., 0.3203, 0.3398, 0.3242],
       dtype=torch.float16), 'model.layers.8.post_attention_layernorm.weight': tensor([0.2422, 0.2314, 0.2236,  ..., 0.2363, 0.2324, 0.2305],
       dtype=torch.float16), 'model.layers.9.self_attn.q_proj.weight': tensor([[-0.0147,  0.0026,  0.0210,  ..., -0.0103, -0.0100, -0.0244],
        [-0.0023, -0.0385,  0.0208,  ..., -0.0013, -0.0039,  0.0068],
        [ 0.0012, -0.0021, -0.0153,  ..., -0.0283, -0.0279, -0.0179],
        ...,
        [-0.0006, -0.0509,  0.0130,  ...,  0.0190,  0.0121, -0.0163],
        [ 0.0161, -0.0186,  0.0037,  ...,  0.0068,  0.0028,  0.0125],
        [-0.0003,  0.0516,  0.0195,  ..., -0.0563,  0.0534, -0.0034]],
       dtype=torch.float16), 'model.layers.9.self_attn.k_proj.weight': tensor([[-0.0307,  0.0100, -0.0252,  ..., -0.0017, -0.0205, -0.0061],
        [-0.0069,  0.0352,  0.0098,  ..., -0.0149,  0.0085,  0.0003],
        [-0.0164, -0.0064,  0.0345,  ...,  0.0036, -0.0246, -0.0038],
        ...,
        [ 0.0229, -0.0136, -0.0035,  ..., -0.0085,  0.0241,  0.0240],
        [ 0.0319,  0.0002,  0.0217,  ...,  0.0495, -0.0169,  0.0517],
        [ 0.0084, -0.0259,  0.0257,  ...,  0.0061,  0.0235, -0.0248]],
       dtype=torch.float16), 'model.layers.9.self_attn.v_proj.weight': tensor([[-0.0064,  0.0087,  0.0034,  ...,  0.0043, -0.0216, -0.0148],
        [-0.0142, -0.0147, -0.0031,  ...,  0.0340, -0.0037, -0.0044],
        [ 0.0071, -0.0220,  0.0211,  ..., -0.0274,  0.0032, -0.0137],
        ...,
        [-0.0094, -0.0083,  0.0037,  ...,  0.0052, -0.0218, -0.0055],
        [-0.0172, -0.0003, -0.0087,  ..., -0.0159,  0.0021, -0.0135],
        [ 0.0245,  0.0242, -0.0037,  ..., -0.0092, -0.0047, -0.0060]],
       dtype=torch.float16), 'model.layers.9.self_attn.o_proj.weight': tensor([[ 0.0102,  0.0094,  0.0113,  ..., -0.0143,  0.0007, -0.0113],
        [-0.0017, -0.0193, -0.0068,  ..., -0.0033,  0.0041,  0.0140],
        [-0.0407, -0.0316,  0.0091,  ...,  0.0292,  0.0020,  0.0106],
        ...,
        [ 0.0148, -0.0133,  0.0091,  ...,  0.0057,  0.0059, -0.0098],
        [ 0.0072,  0.0159,  0.0002,  ...,  0.0084,  0.0001,  0.0006],
        [ 0.0189,  0.0456, -0.0234,  ..., -0.0009,  0.0104,  0.0045]],
       dtype=torch.float16), 'model.layers.9.mlp.gate_proj.weight': tensor([[-0.0097,  0.0258,  0.0002,  ..., -0.0271, -0.0084,  0.0018],
        [-0.0202,  0.0319,  0.0322,  ...,  0.0281,  0.0377,  0.0024],
        [ 0.0390,  0.0285, -0.0269,  ..., -0.0217,  0.0120,  0.0011],
        ...,
        [-0.0204, -0.0079, -0.0243,  ...,  0.0019, -0.0409,  0.0066],
        [-0.0061, -0.0243,  0.0275,  ..., -0.0112,  0.0039,  0.0113],
        [ 0.0146, -0.0229, -0.0039,  ...,  0.0122, -0.0083,  0.0163]],
       dtype=torch.float16), 'model.layers.9.mlp.up_proj.weight': tensor([[-0.0143,  0.0186,  0.0150,  ..., -0.0016, -0.0087,  0.0038],
        [ 0.0086, -0.0010,  0.0079,  ...,  0.0153,  0.0204, -0.0192],
        [-0.0182, -0.0051, -0.0223,  ..., -0.0026, -0.0114,  0.0033],
        ...,
        [ 0.0029,  0.0126, -0.0075,  ..., -0.0150, -0.0307, -0.0130],
        [ 0.0031,  0.0218, -0.0348,  ..., -0.0351, -0.0096, -0.0163],
        [ 0.0102, -0.0337, -0.0058,  ..., -0.0190,  0.0217, -0.0074]],
       dtype=torch.float16), 'model.layers.9.mlp.down_proj.weight': tensor([[-0.0030,  0.0313, -0.0411,  ...,  0.0004, -0.0109,  0.0136],
        [ 0.0216, -0.0283, -0.0173,  ..., -0.0057, -0.0223, -0.0278],
        [-0.0026, -0.0015,  0.0022,  ..., -0.0155,  0.0007, -0.0026],
        ...,
        [-0.0101,  0.0194,  0.0052,  ..., -0.0095, -0.0285,  0.0141],
        [-0.0309,  0.0034,  0.0155,  ..., -0.0204, -0.0034, -0.0333],
        [ 0.0165,  0.0171,  0.0078,  ...,  0.0404,  0.0161,  0.0167]],
       dtype=torch.float16), 'model.layers.9.input_layernorm.weight': tensor([0.3535, 0.3633, 0.3281,  ..., 0.3477, 0.3477, 0.3438],
       dtype=torch.float16), 'model.layers.9.post_attention_layernorm.weight': tensor([0.2490, 0.2334, 0.2285,  ..., 0.2451, 0.2422, 0.2383],
       dtype=torch.float16), 'model.layers.10.self_attn.q_proj.weight': tensor([[-3.6449e-03,  3.8357e-03,  2.0087e-05,  ..., -2.7161e-03,
         -6.6376e-03, -1.4206e-02],
        [-9.7427e-03, -4.9667e-03,  2.0599e-02,  ..., -1.9287e-02,
          6.4575e-02, -3.7270e-03],
        [-1.3718e-02, -1.5106e-02,  2.1040e-04,  ...,  3.4210e-02,
         -9.4452e-03, -1.4389e-02],
        ...,
        [ 3.2104e-02,  6.3049e-02, -1.7929e-02,  ...,  3.7445e-02,
          3.3508e-02, -9.3842e-03],
        [-6.6040e-02,  5.6519e-02, -2.7695e-03,  ..., -6.0577e-02,
         -5.7068e-03, -3.6221e-03],
        [-4.9713e-02, -2.1591e-02, -7.7477e-03,  ..., -1.2627e-02,
         -3.6346e-02, -9.3536e-03]], dtype=torch.float16), 'model.layers.10.self_attn.k_proj.weight': tensor([[-0.0320,  0.0131, -0.0093,  ..., -0.0153,  0.0091, -0.0001],
        [-0.0056,  0.0082, -0.0056,  ..., -0.0057, -0.0101,  0.0133],
        [-0.0008, -0.0022,  0.0067,  ..., -0.0274,  0.0042,  0.0012],
        ...,
        [-0.0464, -0.0599,  0.0127,  ...,  0.0291, -0.0853,  0.0117],
        [-0.0345, -0.0131,  0.0234,  ..., -0.0141, -0.0415, -0.0148],
        [-0.0192,  0.0225, -0.0224,  ...,  0.0083,  0.0425, -0.0002]],
       dtype=torch.float16), 'model.layers.10.self_attn.v_proj.weight': tensor([[-0.0387,  0.0081, -0.0087,  ...,  0.0097,  0.0140,  0.0083],
        [-0.0083,  0.0136,  0.0120,  ..., -0.0067, -0.0419,  0.0195],
        [ 0.0170, -0.0150,  0.0130,  ...,  0.0145,  0.0079, -0.0095],
        ...,
        [ 0.0214,  0.0277,  0.0017,  ...,  0.0253,  0.0023, -0.0228],
        [-0.0040,  0.0057, -0.0005,  ...,  0.0020,  0.0113, -0.0018],
        [ 0.0172,  0.0061, -0.0238,  ..., -0.0072, -0.0071,  0.0242]],
       dtype=torch.float16), 'model.layers.10.self_attn.o_proj.weight': tensor([[-0.0057,  0.0007, -0.0348,  ...,  0.0022,  0.0056,  0.0074],
        [ 0.0006, -0.0118,  0.0126,  ...,  0.0058,  0.0132,  0.0075],
        [ 0.0153, -0.0353, -0.0162,  ...,  0.0007, -0.0036, -0.0031],
        ...,
        [-0.0021,  0.0080, -0.0197,  ..., -0.0031, -0.0003,  0.0199],
        [ 0.0090, -0.0164, -0.0207,  ...,  0.0118,  0.0087,  0.0109],
        [ 0.0075, -0.0081, -0.0278,  ...,  0.0101, -0.0039,  0.0009]],
       dtype=torch.float16), 'model.layers.10.mlp.gate_proj.weight': tensor([[-0.0255, -0.0464, -0.0296,  ...,  0.0059, -0.0014, -0.0041],
        [-0.0152, -0.0224, -0.0173,  ...,  0.0032,  0.0152,  0.0143],
        [-0.0210, -0.0214,  0.0097,  ...,  0.0347, -0.0098,  0.0017],
        ...,
        [-0.0465, -0.0077,  0.0100,  ...,  0.0039, -0.0303,  0.0208],
        [ 0.0046,  0.0114,  0.0203,  ...,  0.0042, -0.0112, -0.0007],
        [-0.0159, -0.0042, -0.0147,  ..., -0.0145,  0.0072, -0.0121]],
       dtype=torch.float16), 'model.layers.10.mlp.up_proj.weight': tensor([[-0.0320, -0.0040, -0.0427,  ...,  0.0109, -0.0067, -0.0190],
        [-0.0074,  0.0061,  0.0065,  ...,  0.0190,  0.0319, -0.0167],
        [-0.0080, -0.0042,  0.0192,  ...,  0.0319, -0.0360,  0.0033],
        ...,
        [ 0.0242,  0.0213, -0.0094,  ..., -0.0432, -0.0039,  0.0027],
        [-0.0012, -0.0116, -0.0232,  ...,  0.0270, -0.0056,  0.0214],
        [-0.0042,  0.0167, -0.0049,  ..., -0.0009,  0.0034,  0.0205]],
       dtype=torch.float16), 'model.layers.10.mlp.down_proj.weight': tensor([[-0.0152, -0.0201, -0.0101,  ...,  0.0302, -0.0133,  0.0010],
        [-0.0054,  0.0221, -0.0139,  ..., -0.0116,  0.0119, -0.0105],
        [-0.0275, -0.0021,  0.0208,  ..., -0.0218, -0.0254,  0.0118],
        ...,
        [ 0.0098, -0.0068, -0.0057,  ...,  0.0063,  0.0142,  0.0074],
        [-0.0106,  0.0519, -0.0189,  ...,  0.0284,  0.0307, -0.0305],
        [-0.0471,  0.0020, -0.0252,  ..., -0.0184, -0.0151,  0.0109]],
       dtype=torch.float16), 'model.layers.10.input_layernorm.weight': tensor([0.3652, 0.3594, 0.3223,  ..., 0.3398, 0.3496, 0.3379],
       dtype=torch.float16), 'model.layers.10.post_attention_layernorm.weight': tensor([0.2500, 0.2383, 0.2285,  ..., 0.2432, 0.2432, 0.2432],
       dtype=torch.float16), 'model.layers.11.self_attn.q_proj.weight': tensor([[ 0.0161, -0.0006, -0.0169,  ...,  0.0251, -0.0088,  0.0062],
        [-0.0113,  0.0006,  0.0061,  ...,  0.0169,  0.0102,  0.0040],
        [ 0.0104,  0.0213, -0.0237,  ..., -0.0047, -0.0055,  0.0015],
        ...,
        [ 0.0066,  0.0024,  0.0322,  ...,  0.0338,  0.0438, -0.0291],
        [ 0.0504,  0.0148, -0.0166,  ..., -0.0151,  0.0161, -0.0268],
        [ 0.0818, -0.0201, -0.0214,  ..., -0.0201,  0.0410,  0.0539]],
       dtype=torch.float16), 'model.layers.11.self_attn.k_proj.weight': tensor([[-0.0052,  0.0221,  0.0030,  ..., -0.0179,  0.0177, -0.0154],
        [ 0.0012,  0.0016, -0.0310,  ..., -0.0106,  0.0045,  0.0256],
        [ 0.0298, -0.0297,  0.0027,  ...,  0.0140,  0.0046,  0.0079],
        ...,
        [-0.0032,  0.0288,  0.0043,  ..., -0.0189, -0.0055,  0.0403],
        [ 0.0598, -0.0065, -0.0142,  ..., -0.0078,  0.0050, -0.0079],
        [ 0.0110,  0.0065,  0.0253,  ..., -0.0007,  0.0569,  0.0267]],
       dtype=torch.float16), 'model.layers.11.self_attn.v_proj.weight': tensor([[ 9.6436e-03,  1.0605e-03, -4.5738e-03,  ..., -2.2232e-02,
         -1.0233e-03,  7.4806e-03],
        [ 2.6855e-03, -6.0806e-03, -1.6937e-02,  ..., -5.5611e-05,
          3.7360e-04, -2.7130e-02],
        [ 2.9392e-03,  9.2468e-03, -7.0686e-03,  ...,  1.6724e-02,
          1.0735e-02, -2.5055e-02],
        ...,
        [-2.0782e-02,  7.5455e-03, -1.4633e-02,  ...,  8.2016e-03,
         -1.7349e-02, -2.2812e-03],
        [-9.9487e-03,  1.0506e-02, -1.1917e-02,  ..., -1.3245e-02,
         -1.7868e-02,  3.2711e-03],
        [ 1.7990e-02, -2.1179e-02, -1.4639e-03,  ..., -4.0344e-02,
          1.8826e-03, -1.2375e-02]], dtype=torch.float16), 'model.layers.11.self_attn.o_proj.weight': tensor([[-0.0191, -0.0035,  0.0060,  ...,  0.0097,  0.0109,  0.0016],
        [-0.0016, -0.0260,  0.0116,  ..., -0.0118, -0.0028, -0.0255],
        [-0.0051, -0.0058,  0.0210,  ...,  0.0021, -0.0066,  0.0139],
        ...,
        [ 0.0016, -0.0042,  0.0228,  ...,  0.0024, -0.0016, -0.0029],
        [ 0.0077,  0.0177,  0.0082,  ...,  0.0172,  0.0129, -0.0298],
        [-0.0027, -0.0047,  0.0054,  ..., -0.0081, -0.0022, -0.0107]],
       dtype=torch.float16), 'model.layers.11.mlp.gate_proj.weight': tensor([[-0.0440, -0.0086,  0.0052,  ...,  0.0062, -0.0116,  0.0425],
        [ 0.0074, -0.0107,  0.0206,  ...,  0.0087, -0.0197, -0.0413],
        [-0.0010, -0.0459, -0.0289,  ..., -0.0025, -0.0084, -0.0026],
        ...,
        [-0.0202, -0.0397, -0.0216,  ..., -0.0041, -0.0321,  0.0039],
        [ 0.0090, -0.0044, -0.0364,  ..., -0.0127,  0.0069,  0.0010],
        [ 0.0023,  0.0186,  0.0080,  ...,  0.0468, -0.0007, -0.0140]],
       dtype=torch.float16), 'model.layers.11.mlp.up_proj.weight': tensor([[-0.0093,  0.0016, -0.0275,  ...,  0.0240,  0.0097,  0.0313],
        [ 0.0179, -0.0028, -0.0222,  ...,  0.0172, -0.0467,  0.0077],
        [-0.0064, -0.0369,  0.0014,  ..., -0.0048, -0.0177,  0.0154],
        ...,
        [ 0.0408,  0.0105, -0.0095,  ...,  0.0014, -0.0005,  0.0161],
        [-0.0116,  0.0200,  0.0059,  ...,  0.0163,  0.0094,  0.0065],
        [-0.0041,  0.0019, -0.0054,  ..., -0.0172, -0.0005,  0.0250]],
       dtype=torch.float16), 'model.layers.11.mlp.down_proj.weight': tensor([[-0.0162,  0.0454,  0.0091,  ...,  0.0194,  0.0163, -0.0040],
        [-0.0136, -0.0092, -0.0251,  ..., -0.0202, -0.0090,  0.0154],
        [-0.0237, -0.0169,  0.0102,  ...,  0.0052, -0.0217, -0.0031],
        ...,
        [ 0.0215,  0.0262, -0.0104,  ..., -0.0017, -0.0003,  0.0087],
        [-0.0111, -0.0290, -0.0306,  ..., -0.0254, -0.0089,  0.0139],
        [ 0.0362,  0.0240,  0.0214,  ..., -0.0028, -0.0135,  0.0383]],
       dtype=torch.float16), 'model.layers.11.input_layernorm.weight': tensor([0.3965, 0.3965, 0.3652,  ..., 0.3848, 0.3828, 0.3711],
       dtype=torch.float16), 'model.layers.11.post_attention_layernorm.weight': tensor([0.2598, 0.2471, 0.2383,  ..., 0.2578, 0.2559, 0.2559],
       dtype=torch.float16), 'model.layers.12.self_attn.q_proj.weight': tensor([[-0.0093, -0.0171,  0.0036,  ...,  0.0262, -0.0099,  0.0055],
        [ 0.0065, -0.0070, -0.0075,  ..., -0.0127,  0.0223,  0.0202],
        [ 0.0106,  0.0411, -0.0328,  ...,  0.0061,  0.0025, -0.0291],
        ...,
        [ 0.0094,  0.0321, -0.0197,  ..., -0.0311, -0.0004, -0.0008],
        [ 0.0424, -0.0059,  0.0097,  ...,  0.0322,  0.0067, -0.0247],
        [ 0.0332,  0.0143, -0.0364,  ..., -0.0210,  0.0215,  0.0238]],
       dtype=torch.float16), 'model.layers.12.self_attn.k_proj.weight': tensor([[ 0.0099, -0.0011, -0.0045,  ...,  0.0193, -0.0024, -0.0102],
        [ 0.0073,  0.0208, -0.0157,  ..., -0.0014, -0.0157, -0.0293],
        [-0.0113, -0.0283,  0.0173,  ...,  0.0087,  0.0026,  0.0026],
        ...,
        [ 0.0132,  0.0322, -0.0148,  ..., -0.0355, -0.0164, -0.0242],
        [-0.0381,  0.0037,  0.0226,  ..., -0.0282,  0.0146, -0.0006],
        [-0.0007,  0.0322,  0.0109,  ...,  0.0129, -0.0465, -0.0404]],
       dtype=torch.float16), 'model.layers.12.self_attn.v_proj.weight': tensor([[ 0.0064,  0.0072,  0.0069,  ..., -0.0077,  0.0109, -0.0189],
        [-0.0275,  0.0104, -0.0036,  ..., -0.0175, -0.0006,  0.0191],
        [-0.0148, -0.0132,  0.0088,  ..., -0.0069,  0.0475, -0.0107],
        ...,
        [ 0.0081, -0.0017, -0.0150,  ..., -0.0068, -0.0115, -0.0013],
        [-0.0010, -0.0147, -0.0047,  ...,  0.0034,  0.0109,  0.0122],
        [ 0.0225,  0.0017,  0.0007,  ...,  0.0178,  0.0139, -0.0070]],
       dtype=torch.float16), 'model.layers.12.self_attn.o_proj.weight': tensor([[ 0.0277,  0.0071, -0.0019,  ..., -0.0012,  0.0083, -0.0061],
        [-0.0092, -0.0141, -0.0014,  ..., -0.0108,  0.0061, -0.0138],
        [ 0.0068, -0.0023, -0.0018,  ...,  0.0037, -0.0232,  0.0125],
        ...,
        [ 0.0032, -0.0023,  0.0126,  ..., -0.0084, -0.0009,  0.0019],
        [-0.0108, -0.0346, -0.0278,  ..., -0.0121,  0.0109,  0.0143],
        [ 0.0210,  0.0093,  0.0084,  ...,  0.0209, -0.0084, -0.0171]],
       dtype=torch.float16), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0057, -0.0110,  0.0123,  ..., -0.0042,  0.0268, -0.0024],
        [-0.0266, -0.0214,  0.0172,  ...,  0.0121,  0.0153,  0.0057],
        [-0.0005,  0.0258, -0.0114,  ..., -0.0099, -0.0289, -0.0045],
        ...,
        [-0.0024,  0.0108,  0.0106,  ..., -0.0328,  0.0070,  0.0276],
        [-0.0325, -0.0083,  0.0082,  ...,  0.0103,  0.0123, -0.0085],
        [ 0.0045, -0.0267, -0.0056,  ..., -0.0053, -0.0018, -0.0202]],
       dtype=torch.float16), 'model.layers.12.mlp.up_proj.weight': tensor([[ 2.9488e-03,  1.7151e-02,  3.6030e-03,  ..., -9.1076e-05,
          1.3832e-02,  1.5427e-02],
        [-3.6373e-03, -1.4801e-02, -1.3435e-02,  ...,  6.5842e-03,
         -7.0915e-03,  2.4414e-02],
        [ 1.4610e-02, -1.2291e-02,  7.4959e-03,  ..., -4.1534e-02,
          4.9171e-03,  1.6441e-03],
        ...,
        [-2.6154e-02, -3.3844e-02, -7.3738e-03,  ...,  1.6922e-02,
         -1.5038e-02,  3.0403e-03],
        [-1.5144e-03, -4.3915e-02, -8.0156e-04,  ...,  1.3924e-02,
          3.0556e-03, -1.5656e-02],
        [ 2.2144e-03, -2.8961e-02,  3.7813e-04,  ...,  3.2440e-02,
         -3.6602e-03, -3.8300e-02]], dtype=torch.float16), 'model.layers.12.mlp.down_proj.weight': tensor([[ 0.0081, -0.0018, -0.0294,  ..., -0.0123,  0.0035,  0.0029],
        [ 0.0170, -0.0288,  0.0046,  ..., -0.0004, -0.0089, -0.0230],
        [ 0.0200,  0.0030,  0.0241,  ...,  0.0043, -0.0012, -0.0281],
        ...,
        [ 0.0183, -0.0085, -0.0380,  ...,  0.0313, -0.0193, -0.0176],
        [-0.0259,  0.0179,  0.0106,  ..., -0.0092,  0.0359, -0.0229],
        [ 0.0075,  0.0262,  0.0221,  ..., -0.0381,  0.0273, -0.0022]],
       dtype=torch.float16), 'model.layers.12.input_layernorm.weight': tensor([0.4062, 0.4023, 0.3691,  ..., 0.3848, 0.3867, 0.3887],
       dtype=torch.float16), 'model.layers.12.post_attention_layernorm.weight': tensor([0.2656, 0.2520, 0.2432,  ..., 0.2656, 0.2617, 0.2598],
       dtype=torch.float16), 'model.layers.13.self_attn.q_proj.weight': tensor([[-0.0002, -0.0013, -0.0132,  ...,  0.0055, -0.0150, -0.0128],
        [-0.0118, -0.0142,  0.0031,  ..., -0.0004,  0.0004, -0.0026],
        [-0.0175,  0.0138,  0.0197,  ..., -0.0115, -0.0075, -0.0069],
        ...,
        [ 0.0483,  0.0084,  0.0043,  ...,  0.0573,  0.0140, -0.0512],
        [ 0.0078,  0.0083, -0.0259,  ...,  0.0091,  0.0111, -0.0104],
        [-0.0040, -0.0248, -0.0212,  ..., -0.0068,  0.0285, -0.0065]],
       dtype=torch.float16), 'model.layers.13.self_attn.k_proj.weight': tensor([[ 0.0134,  0.0048, -0.0030,  ..., -0.0130,  0.0337,  0.0125],
        [ 0.0155,  0.0307, -0.0005,  ..., -0.0055,  0.0136,  0.0046],
        [-0.0007, -0.0130,  0.0334,  ..., -0.0083,  0.0110, -0.0375],
        ...,
        [ 0.0375,  0.0356,  0.0033,  ...,  0.0048, -0.0061, -0.0118],
        [-0.0010,  0.0045,  0.0287,  ..., -0.0342, -0.0217,  0.0352],
        [-0.0229, -0.0535, -0.0142,  ..., -0.0378, -0.0310,  0.0118]],
       dtype=torch.float16), 'model.layers.13.self_attn.v_proj.weight': tensor([[ 0.0149,  0.0064, -0.0058,  ..., -0.0005,  0.0173,  0.0124],
        [-0.0029,  0.0087,  0.0005,  ...,  0.0233, -0.0065, -0.0029],
        [ 0.0146, -0.0016, -0.0023,  ..., -0.0212,  0.0366, -0.0090],
        ...,
        [-0.0011,  0.0251, -0.0052,  ..., -0.0111,  0.0272, -0.0211],
        [-0.0103,  0.0104,  0.0128,  ...,  0.0017,  0.0274,  0.0058],
        [-0.0045, -0.0064,  0.0239,  ...,  0.0154, -0.0026,  0.0374]],
       dtype=torch.float16), 'model.layers.13.self_attn.o_proj.weight': tensor([[-0.0035,  0.0010, -0.0044,  ..., -0.0015, -0.0045, -0.0012],
        [ 0.0222,  0.0148,  0.0101,  ..., -0.0146, -0.0108,  0.0024],
        [ 0.0118,  0.0055,  0.0036,  ...,  0.0065, -0.0233, -0.0088],
        ...,
        [-0.0102,  0.0102,  0.0194,  ..., -0.0114, -0.0154, -0.0165],
        [ 0.0083, -0.0005,  0.0301,  ..., -0.0037, -0.0268, -0.0238],
        [ 0.0100,  0.0019,  0.0086,  ...,  0.0171, -0.0083, -0.0238]],
       dtype=torch.float16), 'model.layers.13.mlp.gate_proj.weight': tensor([[ 0.0249, -0.0034, -0.0082,  ...,  0.0114,  0.0034, -0.0122],
        [-0.0141,  0.0452,  0.0071,  ...,  0.0416, -0.0012, -0.0260],
        [ 0.0035, -0.0199, -0.0103,  ...,  0.0047, -0.0093, -0.0152],
        ...,
        [ 0.0153, -0.0196,  0.0202,  ..., -0.0065,  0.0133,  0.0111],
        [ 0.0154, -0.0125,  0.0203,  ...,  0.0181,  0.0106, -0.0270],
        [ 0.0028,  0.0392,  0.0161,  ..., -0.0045,  0.0059,  0.0285]],
       dtype=torch.float16), 'model.layers.13.mlp.up_proj.weight': tensor([[-0.0423,  0.0199, -0.0013,  ...,  0.0037,  0.0091,  0.0011],
        [ 0.0138, -0.0066,  0.0247,  ...,  0.0468,  0.0286,  0.0224],
        [ 0.0281, -0.0344,  0.0093,  ...,  0.0069,  0.0009, -0.0082],
        ...,
        [-0.0130, -0.0038,  0.0297,  ...,  0.0190, -0.0247,  0.0139],
        [-0.0103, -0.0171,  0.0079,  ...,  0.0177,  0.0563,  0.0096],
        [ 0.0117, -0.0212,  0.0179,  ..., -0.0185, -0.0004,  0.0269]],
       dtype=torch.float16), 'model.layers.13.mlp.down_proj.weight': tensor([[-0.0062, -0.0036, -0.0027,  ...,  0.0226, -0.0265, -0.0220],
        [-0.0117,  0.0470, -0.0413,  ..., -0.0018,  0.0133, -0.0090],
        [ 0.0081,  0.0038,  0.0183,  ...,  0.0015, -0.0249, -0.0031],
        ...,
        [ 0.0058,  0.0077,  0.0354,  ..., -0.0014, -0.0209,  0.0290],
        [ 0.0167, -0.0015,  0.0188,  ..., -0.0109,  0.0164, -0.0045],
        [ 0.0029, -0.0229,  0.0393,  ...,  0.0041,  0.0022,  0.0325]],
       dtype=torch.float16), 'model.layers.13.input_layernorm.weight': tensor([0.4199, 0.4121, 0.3770,  ..., 0.3926, 0.3848, 0.3965],
       dtype=torch.float16), 'model.layers.13.post_attention_layernorm.weight': tensor([0.2715, 0.2598, 0.2539,  ..., 0.2715, 0.2734, 0.2656],
       dtype=torch.float16), 'model.layers.14.self_attn.q_proj.weight': tensor([[-0.0088, -0.0028,  0.0195,  ..., -0.0054,  0.0162,  0.0367],
        [ 0.0097,  0.0160, -0.0124,  ..., -0.0348, -0.0203, -0.0406],
        [-0.0202, -0.0112,  0.0171,  ...,  0.0106,  0.0140, -0.0339],
        ...,
        [-0.0201,  0.0005, -0.0295,  ...,  0.0018,  0.0130, -0.0074],
        [ 0.0269, -0.0389,  0.0497,  ..., -0.0134,  0.0061, -0.0092],
        [-0.0175, -0.0090, -0.0035,  ...,  0.0170,  0.0184, -0.0447]],
       dtype=torch.float16), 'model.layers.14.self_attn.k_proj.weight': tensor([[-0.0143, -0.0049,  0.0068,  ..., -0.0091,  0.0271,  0.0431],
        [ 0.0191,  0.0324, -0.0204,  ..., -0.0030, -0.0276, -0.0050],
        [-0.0183,  0.0034,  0.0196,  ...,  0.0239,  0.0110,  0.0012],
        ...,
        [-0.0387, -0.0029,  0.0264,  ..., -0.0049,  0.0017, -0.0254],
        [-0.0293,  0.0005,  0.0153,  ..., -0.0359, -0.0144,  0.0012],
        [-0.0202,  0.0292,  0.0236,  ...,  0.0703,  0.0087, -0.0386]],
       dtype=torch.float16), 'model.layers.14.self_attn.v_proj.weight': tensor([[ 7.4310e-03,  7.7629e-03, -3.8025e-02,  ..., -3.4210e-02,
         -5.2032e-03,  1.2451e-02],
        [-1.0204e-03, -2.5452e-02, -3.0117e-03,  ...,  1.0887e-02,
         -5.2512e-05, -3.2425e-03],
        [ 2.6276e-02, -1.5022e-02,  2.2659e-03,  ..., -5.5466e-03,
          2.3460e-03,  8.2321e-03],
        ...,
        [ 1.5747e-02, -1.1642e-02,  1.5343e-02,  ...,  1.5533e-02,
         -1.1597e-02,  2.6016e-03],
        [-1.1391e-02,  2.2583e-02, -3.5553e-02,  ..., -7.8058e-04,
         -8.8654e-03, -2.5574e-02],
        [ 3.5992e-03,  2.3102e-02, -2.2568e-02,  ..., -5.2261e-03,
         -3.3932e-03,  1.8295e-02]], dtype=torch.float16), 'model.layers.14.self_attn.o_proj.weight': tensor([[-0.0108,  0.0044, -0.0227,  ..., -0.0021,  0.0010, -0.0110],
        [ 0.0080,  0.0304,  0.0077,  ...,  0.0221, -0.0049,  0.0021],
        [ 0.0060,  0.0082,  0.0024,  ...,  0.0075,  0.0206,  0.0054],
        ...,
        [ 0.0245, -0.0073,  0.0008,  ..., -0.0073, -0.0022,  0.0139],
        [-0.0025,  0.0010, -0.0195,  ..., -0.0021,  0.0362,  0.0155],
        [-0.0085, -0.0104, -0.0139,  ..., -0.0070,  0.0146,  0.0060]],
       dtype=torch.float16), 'model.layers.14.mlp.gate_proj.weight': tensor([[-0.0084,  0.0011, -0.0090,  ...,  0.0102, -0.0185, -0.0064],
        [ 0.0296,  0.0080, -0.0390,  ...,  0.0377,  0.0119, -0.0075],
        [ 0.0095,  0.0148, -0.0004,  ..., -0.0081,  0.0108, -0.0179],
        ...,
        [ 0.0065,  0.0105, -0.0190,  ...,  0.0003, -0.0047,  0.0004],
        [ 0.0033,  0.0159,  0.0201,  ..., -0.0192,  0.0087,  0.0073],
        [ 0.0200,  0.0017,  0.0183,  ..., -0.0106, -0.0248,  0.0258]],
       dtype=torch.float16), 'model.layers.14.mlp.up_proj.weight': tensor([[ 0.0052,  0.0099,  0.0201,  ..., -0.0153,  0.0073,  0.0048],
        [ 0.0269,  0.0089, -0.0300,  ...,  0.0064,  0.0262,  0.0104],
        [ 0.0012, -0.0055,  0.0300,  ..., -0.0013,  0.0177, -0.0023],
        ...,
        [-0.0164, -0.0013, -0.0479,  ..., -0.0145, -0.0116, -0.0048],
        [-0.0415,  0.0074, -0.0075,  ..., -0.0081,  0.0239, -0.0144],
        [ 0.0029,  0.0235,  0.0122,  ...,  0.0086, -0.0140,  0.0131]],
       dtype=torch.float16), 'model.layers.14.mlp.down_proj.weight': tensor([[ 0.0100,  0.0243,  0.0113,  ..., -0.0290, -0.0019, -0.0056],
        [ 0.0121,  0.0222, -0.0091,  ...,  0.0131, -0.0032,  0.0189],
        [ 0.0080, -0.0420,  0.0119,  ...,  0.0042, -0.0302,  0.0124],
        ...,
        [ 0.0005,  0.0152, -0.0169,  ..., -0.0046, -0.0100, -0.0109],
        [ 0.0242,  0.0335,  0.0364,  ..., -0.0051, -0.0155,  0.0210],
        [-0.0245,  0.0057, -0.0101,  ..., -0.0300,  0.0070,  0.0187]],
       dtype=torch.float16), 'model.layers.14.input_layernorm.weight': tensor([0.4219, 0.4297, 0.3789,  ..., 0.4141, 0.4062, 0.3984],
       dtype=torch.float16), 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2734, 0.2656,  ..., 0.2871, 0.2832, 0.2793],
       dtype=torch.float16), 'model.layers.15.self_attn.q_proj.weight': tensor([[-0.0194, -0.0154, -0.0142,  ...,  0.0138, -0.0084,  0.0010],
        [ 0.0363, -0.0190,  0.0038,  ..., -0.0058,  0.0144,  0.0015],
        [ 0.0084, -0.0132,  0.0030,  ...,  0.0098, -0.0134, -0.0160],
        ...,
        [-0.0477, -0.0267,  0.0071,  ..., -0.0063, -0.0128,  0.0200],
        [-0.0155, -0.0536,  0.0174,  ...,  0.0155, -0.0015,  0.0025],
        [ 0.0236,  0.0251,  0.0278,  ..., -0.0140, -0.0227, -0.0165]],
       dtype=torch.float16), 'model.layers.15.self_attn.k_proj.weight': tensor([[ 0.0209, -0.0054, -0.0045,  ..., -0.0027,  0.0014,  0.0044],
        [ 0.0111, -0.0042, -0.0052,  ..., -0.0015,  0.0046, -0.0135],
        [-0.0021,  0.0020, -0.0083,  ..., -0.0007,  0.0133, -0.0119],
        ...,
        [-0.0540, -0.0380,  0.0168,  ...,  0.0214,  0.0069, -0.0060],
        [ 0.0092,  0.0011,  0.0159,  ...,  0.0275, -0.0217,  0.0132],
        [-0.0067, -0.0060,  0.0341,  ..., -0.0027, -0.0171,  0.0033]],
       dtype=torch.float16), 'model.layers.15.self_attn.v_proj.weight': tensor([[ 0.0088,  0.0023,  0.0053,  ...,  0.0037,  0.0141,  0.0177],
        [-0.0096, -0.0142,  0.0151,  ...,  0.0168,  0.0018,  0.0224],
        [ 0.0075, -0.0377, -0.0064,  ..., -0.0365,  0.0073,  0.0073],
        ...,
        [-0.0038, -0.0107,  0.0116,  ...,  0.0066,  0.0181, -0.0141],
        [ 0.0056, -0.0006, -0.0311,  ...,  0.0116,  0.0151, -0.0054],
        [ 0.0169,  0.0104,  0.0152,  ..., -0.0160,  0.0075,  0.0077]],
       dtype=torch.float16), 'model.layers.15.self_attn.o_proj.weight': tensor([[ 0.0012,  0.0029, -0.0154,  ...,  0.0104, -0.0127,  0.0282],
        [-0.0046, -0.0112, -0.0177,  ...,  0.0099, -0.0261,  0.0198],
        [ 0.0020, -0.0083,  0.0008,  ...,  0.0102, -0.0070,  0.0095],
        ...,
        [-0.0089, -0.0197,  0.0142,  ..., -0.0044, -0.0201, -0.0100],
        [ 0.0005, -0.0017, -0.0072,  ...,  0.0113,  0.0051,  0.0044],
        [-0.0241,  0.0053,  0.0263,  ..., -0.0118, -0.0254, -0.0296]],
       dtype=torch.float16), 'model.layers.15.mlp.gate_proj.weight': tensor([[-0.0145,  0.0259, -0.0075,  ...,  0.0116, -0.0298,  0.0140],
        [ 0.0069, -0.0101,  0.0278,  ..., -0.0192,  0.0056,  0.0099],
        [ 0.0088, -0.0179, -0.0112,  ...,  0.0231, -0.0539, -0.0260],
        ...,
        [-0.0106, -0.0046,  0.0301,  ..., -0.0094,  0.0175,  0.0069],
        [-0.0124, -0.0172,  0.0103,  ..., -0.0082, -0.0106, -0.0440],
        [ 0.0040, -0.0142, -0.0008,  ...,  0.0002,  0.0071, -0.0001]],
       dtype=torch.float16), 'model.layers.15.mlp.up_proj.weight': tensor([[-1.2886e-02, -9.5215e-03,  2.7924e-02,  ...,  1.2367e-02,
          1.1269e-02, -4.3579e-02],
        [-1.5732e-02,  4.2908e-02,  2.9343e-02,  ...,  1.0506e-02,
          7.6866e-03,  3.9864e-03],
        [-4.2419e-02, -7.7896e-03, -4.7994e-04,  ..., -1.5518e-02,
          1.5602e-02, -1.0269e-02],
        ...,
        [-6.7863e-03, -2.3376e-02, -7.8659e-03,  ...,  8.5068e-03,
         -4.8757e-05, -4.9782e-03],
        [ 2.7618e-02, -5.3329e-03,  7.8354e-03,  ..., -1.0330e-02,
          1.5747e-02,  5.7030e-04],
        [-7.5302e-03, -2.7130e-02, -9.7809e-03,  ...,  4.5633e-04,
         -1.2245e-02,  1.1940e-03]], dtype=torch.float16), 'model.layers.15.mlp.down_proj.weight': tensor([[-1.2512e-02, -6.8245e-03, -1.6098e-02,  ...,  2.5909e-02,
          9.1171e-03, -1.0674e-02],
        [ 1.0666e-02, -1.1749e-02, -2.6199e-02,  ..., -1.1993e-02,
         -2.3163e-02,  1.6129e-02],
        [ 3.8452e-02,  4.4830e-02, -1.5747e-02,  ..., -1.1589e-02,
          3.4302e-02,  1.8906e-02],
        ...,
        [-4.5853e-03, -3.9978e-02,  6.3210e-03,  ...,  9.4833e-03,
          5.5046e-03,  7.1466e-05],
        [-4.1779e-02, -1.7502e-02, -1.1826e-03,  ..., -2.9480e-02,
         -1.5137e-02,  7.0038e-03],
        [ 1.5354e-03,  2.3773e-02, -6.3553e-03,  ..., -1.7715e-02,
         -3.2593e-02, -2.0401e-02]], dtype=torch.float16), 'model.layers.15.input_layernorm.weight': tensor([0.4160, 0.4102, 0.3809,  ..., 0.3867, 0.3945, 0.3945],
       dtype=torch.float16), 'model.layers.15.post_attention_layernorm.weight': tensor([0.2930, 0.2793, 0.2793,  ..., 0.2969, 0.2910, 0.2891],
       dtype=torch.float16), 'model.layers.16.self_attn.q_proj.weight': tensor([[ 0.0090,  0.0135, -0.0253,  ...,  0.0048,  0.0263, -0.0078],
        [ 0.0172, -0.0415,  0.0228,  ...,  0.0170,  0.0186, -0.0237],
        [-0.0128, -0.0067,  0.0088,  ..., -0.0257,  0.0021, -0.0261],
        ...,
        [ 0.0328, -0.0378, -0.0080,  ..., -0.0196,  0.0181, -0.0271],
        [-0.0166, -0.0170,  0.0283,  ...,  0.0018, -0.0181,  0.0157],
        [ 0.0046,  0.0219,  0.0146,  ..., -0.0030, -0.0327, -0.0095]],
       dtype=torch.float16), 'model.layers.16.self_attn.k_proj.weight': tensor([[-0.0072,  0.0235,  0.0023,  ...,  0.0131,  0.0227,  0.0217],
        [ 0.0223, -0.0315,  0.0097,  ..., -0.0058, -0.0194, -0.0077],
        [ 0.0272, -0.0056, -0.0197,  ..., -0.0234,  0.0092, -0.0277],
        ...,
        [ 0.0239,  0.0135, -0.0127,  ..., -0.0233, -0.0399, -0.0581],
        [ 0.0161,  0.0086,  0.0133,  ...,  0.0302,  0.0043,  0.0115],
        [-0.0444,  0.0565,  0.0591,  ...,  0.0017, -0.0147,  0.0274]],
       dtype=torch.float16), 'model.layers.16.self_attn.v_proj.weight': tensor([[-0.0166,  0.0066, -0.0049,  ...,  0.0065, -0.0008, -0.0020],
        [-0.0576, -0.0069,  0.0042,  ...,  0.0035,  0.0128, -0.0267],
        [-0.0069, -0.0133, -0.0021,  ..., -0.0211,  0.0416,  0.0151],
        ...,
        [ 0.0040, -0.0079,  0.0167,  ..., -0.0125, -0.0001,  0.0166],
        [-0.0169,  0.0023,  0.0052,  ...,  0.0389, -0.0043,  0.0089],
        [ 0.0118,  0.0102,  0.0083,  ..., -0.0158, -0.0042, -0.0301]],
       dtype=torch.float16), 'model.layers.16.self_attn.o_proj.weight': tensor([[ 0.0388, -0.0079, -0.0170,  ...,  0.0112, -0.0126,  0.0047],
        [-0.0246,  0.0107, -0.0208,  ...,  0.0039, -0.0083,  0.0016],
        [-0.0285, -0.0177, -0.0134,  ..., -0.0021,  0.0259,  0.0170],
        ...,
        [-0.0030, -0.0207,  0.0029,  ...,  0.0046, -0.0266,  0.0010],
        [-0.0073,  0.0199,  0.0344,  ..., -0.0005,  0.0009, -0.0051],
        [-0.0192,  0.0035,  0.0066,  ...,  0.0018,  0.0024,  0.0109]],
       dtype=torch.float16), 'model.layers.16.mlp.gate_proj.weight': tensor([[-0.0275, -0.0157, -0.0233,  ...,  0.0007, -0.0003,  0.0085],
        [ 0.0313,  0.0157, -0.0098,  ...,  0.0153,  0.0087,  0.0166],
        [ 0.0027,  0.0056,  0.0041,  ..., -0.0008, -0.0035, -0.0189],
        ...,
        [-0.0086,  0.0085,  0.0053,  ...,  0.0223,  0.0300,  0.0286],
        [-0.0033, -0.0147,  0.0094,  ...,  0.0099,  0.0210,  0.0115],
        [ 0.0256,  0.0212,  0.0310,  ..., -0.0399,  0.0148, -0.0203]],
       dtype=torch.float16), 'model.layers.16.mlp.up_proj.weight': tensor([[-0.0403,  0.0147,  0.0066,  ...,  0.0294, -0.0128,  0.0091],
        [ 0.0156, -0.0131,  0.0048,  ...,  0.0215, -0.0303, -0.0077],
        [-0.0078, -0.0256, -0.0064,  ..., -0.0124, -0.0047,  0.0258],
        ...,
        [-0.0096,  0.0263, -0.0066,  ...,  0.0095, -0.0235, -0.0248],
        [-0.0098,  0.0216, -0.0177,  ...,  0.0097, -0.0052,  0.0185],
        [ 0.0099,  0.0079, -0.0118,  ...,  0.0013, -0.0239, -0.0209]],
       dtype=torch.float16), 'model.layers.16.mlp.down_proj.weight': tensor([[-0.0236,  0.0045,  0.0134,  ...,  0.0206, -0.0091, -0.0008],
        [-0.0233, -0.0041, -0.0123,  ...,  0.0286,  0.0018, -0.0002],
        [-0.0142,  0.0049, -0.0120,  ...,  0.0201, -0.0042, -0.0009],
        ...,
        [ 0.0143, -0.0248, -0.0242,  ...,  0.0203,  0.0178, -0.0020],
        [ 0.0227,  0.0019, -0.0097,  ..., -0.0214, -0.0128, -0.0098],
        [ 0.0107, -0.0168, -0.0371,  ...,  0.0256, -0.0010, -0.0141]],
       dtype=torch.float16), 'model.layers.16.input_layernorm.weight': tensor([0.4180, 0.4219, 0.3906,  ..., 0.3984, 0.4160, 0.4082],
       dtype=torch.float16), 'model.layers.16.post_attention_layernorm.weight': tensor([0.3164, 0.2949, 0.2988,  ..., 0.3105, 0.3086, 0.3047],
       dtype=torch.float16), 'model.layers.17.self_attn.q_proj.weight': tensor([[-0.0125, -0.0138,  0.0065,  ...,  0.0073, -0.0072, -0.0107],
        [ 0.0094, -0.0095,  0.0169,  ...,  0.0019, -0.0260,  0.0081],
        [-0.0130, -0.0020, -0.0129,  ...,  0.0152, -0.0114,  0.0020],
        ...,
        [ 0.0362, -0.0261,  0.0562,  ..., -0.0142, -0.0178,  0.0079],
        [ 0.0282, -0.0184,  0.0462,  ...,  0.0094, -0.0215, -0.0601],
        [ 0.0126, -0.0017,  0.0116,  ...,  0.0320,  0.0013,  0.0742]],
       dtype=torch.float16), 'model.layers.17.self_attn.k_proj.weight': tensor([[-0.0127, -0.0063,  0.0040,  ..., -0.0014,  0.0197,  0.0079],
        [ 0.0078,  0.0072,  0.0041,  ...,  0.0103,  0.0002, -0.0138],
        [ 0.0077, -0.0085,  0.0012,  ...,  0.0154, -0.0231, -0.0079],
        ...,
        [ 0.0041, -0.0500, -0.0091,  ..., -0.0221,  0.0599, -0.0676],
        [ 0.0275,  0.0191,  0.0122,  ..., -0.0132, -0.0267, -0.0225],
        [-0.0380, -0.0470, -0.0048,  ...,  0.0278,  0.0259, -0.0048]],
       dtype=torch.float16), 'model.layers.17.self_attn.v_proj.weight': tensor([[-0.0122,  0.0105,  0.0024,  ...,  0.0239, -0.0088, -0.0096],
        [-0.0039, -0.0155, -0.0111,  ...,  0.0116, -0.0257, -0.0144],
        [ 0.0174,  0.0158, -0.0024,  ...,  0.0018, -0.0111, -0.0288],
        ...,
        [ 0.0010, -0.0043,  0.0143,  ...,  0.0121,  0.0051, -0.0155],
        [ 0.0189, -0.0031, -0.0388,  ..., -0.0152, -0.0034, -0.0341],
        [-0.0093, -0.0103, -0.0053,  ...,  0.0055,  0.0081,  0.0092]],
       dtype=torch.float16), 'model.layers.17.self_attn.o_proj.weight': tensor([[-0.0049, -0.0105,  0.0036,  ..., -0.0197,  0.0008, -0.0131],
        [-0.0116, -0.0207,  0.0218,  ...,  0.0219, -0.0174,  0.0221],
        [ 0.0098, -0.0111, -0.0045,  ..., -0.0186, -0.0138, -0.0218],
        ...,
        [-0.0109,  0.0140, -0.0118,  ..., -0.0310, -0.0329, -0.0185],
        [-0.0070,  0.0101, -0.0009,  ..., -0.0287,  0.0044,  0.0065],
        [-0.0155, -0.0129,  0.0072,  ...,  0.0329, -0.0223,  0.0173]],
       dtype=torch.float16), 'model.layers.17.mlp.gate_proj.weight': tensor([[-0.0341,  0.0291,  0.0243,  ...,  0.0059,  0.0021,  0.0031],
        [-0.0008,  0.0264,  0.0270,  ...,  0.0185,  0.0077,  0.0121],
        [ 0.0100,  0.0120, -0.0222,  ...,  0.0171,  0.0307, -0.0055],
        ...,
        [-0.0114, -0.0160, -0.0122,  ..., -0.0103, -0.0229, -0.0157],
        [ 0.0041,  0.0033,  0.0092,  ...,  0.0065,  0.0431, -0.0114],
        [-0.0032,  0.0208,  0.0144,  ..., -0.0138, -0.0018, -0.0032]],
       dtype=torch.float16), 'model.layers.17.mlp.up_proj.weight': tensor([[-0.0169, -0.0280, -0.0067,  ...,  0.0061,  0.0168, -0.0130],
        [-0.0231,  0.0152,  0.0278,  ...,  0.0003,  0.0016,  0.0020],
        [-0.0010, -0.0031,  0.0035,  ...,  0.0089, -0.0150,  0.0119],
        ...,
        [ 0.0138,  0.0168,  0.0068,  ...,  0.0064, -0.0204, -0.0130],
        [-0.0162, -0.0182, -0.0103,  ..., -0.0115, -0.0220,  0.0159],
        [-0.0032,  0.0038, -0.0083,  ...,  0.0034, -0.0360, -0.0131]],
       dtype=torch.float16), 'model.layers.17.mlp.down_proj.weight': tensor([[ 0.0260, -0.0225,  0.0134,  ...,  0.0120, -0.0079, -0.0022],
        [ 0.0285,  0.0301,  0.0086,  ...,  0.0063, -0.0083,  0.0336],
        [-0.0263, -0.0165, -0.0178,  ...,  0.0121, -0.0150, -0.0046],
        ...,
        [ 0.0067, -0.0222, -0.0068,  ..., -0.0141, -0.0051, -0.0367],
        [ 0.0015,  0.0053, -0.0114,  ..., -0.0275, -0.0274,  0.0174],
        [-0.0009, -0.0200,  0.0189,  ..., -0.0368, -0.0108,  0.0045]],
       dtype=torch.float16), 'model.layers.17.input_layernorm.weight': tensor([0.4316, 0.4336, 0.4043,  ..., 0.4238, 0.4277, 0.4062],
       dtype=torch.float16), 'model.layers.17.post_attention_layernorm.weight': tensor([0.3320, 0.3164, 0.3145,  ..., 0.3320, 0.3301, 0.3223],
       dtype=torch.float16), 'model.layers.18.self_attn.q_proj.weight': tensor([[ 0.0067,  0.0054,  0.0022,  ..., -0.0046, -0.0363,  0.0100],
        [ 0.0022, -0.0133,  0.0213,  ...,  0.0001,  0.0255,  0.0434],
        [ 0.0111, -0.0257, -0.0097,  ...,  0.0015, -0.0081,  0.0164],
        ...,
        [-0.0324,  0.0133,  0.0033,  ...,  0.0230,  0.0055,  0.0155],
        [ 0.0622, -0.0166, -0.0270,  ...,  0.0574,  0.0266,  0.0184],
        [ 0.0301,  0.0155,  0.0043,  ...,  0.0281,  0.0549, -0.0513]],
       dtype=torch.float16), 'model.layers.18.self_attn.k_proj.weight': tensor([[-0.0115,  0.0326, -0.0141,  ...,  0.0089, -0.0094, -0.0243],
        [ 0.0082, -0.0191,  0.0162,  ...,  0.0176,  0.0292,  0.0015],
        [ 0.0123, -0.0097, -0.0019,  ...,  0.0210, -0.0017,  0.0248],
        ...,
        [-0.1082, -0.0282, -0.0618,  ...,  0.0203, -0.0044, -0.0386],
        [ 0.0520,  0.0363, -0.0182,  ...,  0.0459,  0.0646, -0.0261],
        [-0.0487, -0.0503, -0.0435,  ...,  0.0343, -0.0235, -0.0319]],
       dtype=torch.float16), 'model.layers.18.self_attn.v_proj.weight': tensor([[-0.0296,  0.0286, -0.0176,  ...,  0.0053,  0.0276,  0.0051],
        [ 0.0173,  0.0070, -0.0124,  ..., -0.0175,  0.0382, -0.0023],
        [ 0.0001,  0.0193,  0.0009,  ...,  0.0046, -0.0021, -0.0077],
        ...,
        [ 0.0137,  0.0160, -0.0047,  ..., -0.0077, -0.0233,  0.0025],
        [ 0.0073, -0.0028,  0.0031,  ...,  0.0136,  0.0159,  0.0355],
        [-0.0068,  0.0012,  0.0111,  ..., -0.0062, -0.0200,  0.0024]],
       dtype=torch.float16), 'model.layers.18.self_attn.o_proj.weight': tensor([[-0.0180,  0.0188, -0.0144,  ...,  0.0118,  0.0222,  0.0198],
        [-0.0003, -0.0400,  0.0047,  ..., -0.0010, -0.0070, -0.0164],
        [ 0.0022, -0.0141,  0.0099,  ...,  0.0279,  0.0158,  0.0373],
        ...,
        [-0.0351, -0.0236, -0.0248,  ...,  0.0230,  0.0176, -0.0098],
        [ 0.0128,  0.0511,  0.0149,  ...,  0.0131, -0.0084, -0.0367],
        [-0.0119, -0.0472, -0.0218,  ..., -0.0158,  0.0139, -0.0140]],
       dtype=torch.float16), 'model.layers.18.mlp.gate_proj.weight': tensor([[ 0.0147, -0.0038,  0.0166,  ..., -0.0080,  0.0101, -0.0105],
        [-0.0428,  0.0071, -0.0162,  ..., -0.0086, -0.0150, -0.0096],
        [-0.0190,  0.0073,  0.0444,  ..., -0.0250,  0.0031,  0.0038],
        ...,
        [-0.0438, -0.0219, -0.0285,  ..., -0.0296, -0.0218, -0.0233],
        [ 0.0015,  0.0197,  0.0297,  ..., -0.0164, -0.0011,  0.0164],
        [ 0.0040, -0.0041,  0.0039,  ...,  0.0107, -0.0188, -0.0050]],
       dtype=torch.float16), 'model.layers.18.mlp.up_proj.weight': tensor([[ 0.0165,  0.0081,  0.0298,  ..., -0.0004,  0.0271, -0.0095],
        [-0.0201,  0.0243, -0.0282,  ..., -0.0057, -0.0087, -0.0003],
        [-0.0311, -0.0098,  0.0076,  ...,  0.0074,  0.0209,  0.0261],
        ...,
        [-0.0012,  0.0045,  0.0046,  ...,  0.0238, -0.0075,  0.0040],
        [-0.0094, -0.0048, -0.0210,  ...,  0.0134,  0.0343,  0.0362],
        [ 0.0087,  0.0248,  0.0111,  ..., -0.0163,  0.0135,  0.0152]],
       dtype=torch.float16), 'model.layers.18.mlp.down_proj.weight': tensor([[ 0.0152,  0.0034, -0.0323,  ...,  0.0311,  0.0165,  0.0073],
        [ 0.0117, -0.0078,  0.0196,  ...,  0.0007, -0.0016, -0.0021],
        [ 0.0172, -0.0250, -0.0335,  ...,  0.0177,  0.0036,  0.0148],
        ...,
        [-0.0127,  0.0210,  0.0102,  ...,  0.0230, -0.0081, -0.0087],
        [-0.0160,  0.0116,  0.0182,  ...,  0.0120,  0.0356,  0.0087],
        [-0.0091,  0.0257,  0.0244,  ..., -0.0073,  0.0167,  0.0157]],
       dtype=torch.float16), 'model.layers.18.input_layernorm.weight': tensor([0.4570, 0.4551, 0.4316,  ..., 0.4375, 0.4512, 0.4355],
       dtype=torch.float16), 'model.layers.18.post_attention_layernorm.weight': tensor([0.3477, 0.3340, 0.3320,  ..., 0.3477, 0.3496, 0.3457],
       dtype=torch.float16), 'model.layers.19.self_attn.q_proj.weight': tensor([[ 5.5275e-03,  7.6294e-03, -9.7961e-03,  ..., -1.0323e-02,
         -3.1209e-04,  8.8806e-03],
        [ 2.6894e-03, -2.5539e-03,  3.1719e-03,  ..., -4.7493e-03,
          2.9022e-02,  1.7868e-02],
        [ 5.2185e-03,  2.1896e-02,  4.5896e-05,  ...,  8.6498e-04,
          1.5182e-02,  3.0727e-03],
        ...,
        [-1.4160e-02, -1.4923e-02,  1.0290e-03,  ..., -4.4189e-02,
         -3.1805e-04,  2.4979e-02],
        [ 4.7226e-03,  4.8279e-02,  2.3041e-02,  ...,  5.4077e-02,
          2.9755e-02, -2.9358e-02],
        [-1.5991e-02,  4.9011e-02,  5.8014e-02,  ..., -6.6414e-03,
         -4.1382e-02, -1.4290e-02]], dtype=torch.float16), 'model.layers.19.self_attn.k_proj.weight': tensor([[ 0.0216,  0.0117,  0.0022,  ..., -0.0116, -0.0213, -0.0106],
        [-0.0142,  0.0180, -0.0159,  ...,  0.0100,  0.0034,  0.0251],
        [-0.0157,  0.0043, -0.0122,  ...,  0.0044,  0.0137,  0.0252],
        ...,
        [ 0.0005,  0.0502, -0.0095,  ..., -0.0208,  0.0299, -0.0225],
        [-0.0653, -0.0269, -0.0101,  ...,  0.0084,  0.0184, -0.0099],
        [-0.0202,  0.0115, -0.0150,  ..., -0.0266,  0.0129,  0.0399]],
       dtype=torch.float16), 'model.layers.19.self_attn.v_proj.weight': tensor([[-0.0011, -0.0055, -0.0055,  ..., -0.0020,  0.0005,  0.0070],
        [-0.0020,  0.0188, -0.0031,  ...,  0.0351, -0.0211,  0.0162],
        [-0.0448, -0.0359, -0.0080,  ..., -0.0085, -0.0002,  0.0056],
        ...,
        [ 0.0013, -0.0373, -0.0014,  ...,  0.0010, -0.0002, -0.0166],
        [ 0.0145, -0.0095, -0.0219,  ..., -0.0066, -0.0073, -0.0058],
        [-0.0033,  0.0275,  0.0008,  ..., -0.0254, -0.0120,  0.0062]],
       dtype=torch.float16), 'model.layers.19.self_attn.o_proj.weight': tensor([[ 0.0296, -0.0517,  0.0258,  ...,  0.0012,  0.0066, -0.0257],
        [ 0.0307, -0.0164, -0.0036,  ..., -0.0145, -0.0012, -0.0030],
        [-0.0033, -0.0176, -0.0195,  ...,  0.0010,  0.0150,  0.0012],
        ...,
        [ 0.0123, -0.0018,  0.0002,  ...,  0.0056, -0.0152,  0.0122],
        [ 0.0089, -0.0057, -0.0186,  ..., -0.0244, -0.0204,  0.0051],
        [ 0.0127,  0.0175,  0.0140,  ..., -0.0233, -0.0083,  0.0153]],
       dtype=torch.float16), 'model.layers.19.mlp.gate_proj.weight': tensor([[-0.0082,  0.0010,  0.0049,  ..., -0.0039,  0.0037, -0.0065],
        [ 0.0145,  0.0183,  0.0011,  ..., -0.0036,  0.0125, -0.0351],
        [-0.0169, -0.0121, -0.0127,  ..., -0.0433,  0.0002,  0.0285],
        ...,
        [-0.0016,  0.0101, -0.0004,  ..., -0.0291, -0.0092, -0.0010],
        [-0.0475, -0.0082,  0.0029,  ..., -0.0074, -0.0217,  0.0107],
        [-0.0205, -0.0197,  0.0153,  ...,  0.0069,  0.0052, -0.0020]],
       dtype=torch.float16), 'model.layers.19.mlp.up_proj.weight': tensor([[ 0.0020, -0.0107,  0.0096,  ...,  0.0065,  0.0100,  0.0032],
        [-0.0134, -0.0063, -0.0158,  ...,  0.0269, -0.0230, -0.0070],
        [ 0.0094,  0.0039,  0.0094,  ..., -0.0246, -0.0129,  0.0532],
        ...,
        [ 0.0142,  0.0140,  0.0074,  ...,  0.0136, -0.0170,  0.0311],
        [ 0.0013,  0.0262,  0.0249,  ..., -0.0094,  0.0361, -0.0004],
        [-0.0002, -0.0181, -0.0124,  ..., -0.0027,  0.0045,  0.0140]],
       dtype=torch.float16), 'model.layers.19.mlp.down_proj.weight': tensor([[-0.0026, -0.0278,  0.0015,  ...,  0.0057, -0.0235,  0.0278],
        [-0.0050, -0.0306, -0.0208,  ...,  0.0139,  0.0175, -0.0169],
        [-0.0209, -0.0261,  0.0290,  ...,  0.0159, -0.0008,  0.0071],
        ...,
        [-0.0104, -0.0050,  0.0274,  ...,  0.0129,  0.0162,  0.0012],
        [ 0.0065, -0.0093, -0.0501,  ...,  0.0219, -0.0086, -0.0152],
        [ 0.0041, -0.0093, -0.0342,  ...,  0.0006,  0.0090,  0.0042]],
       dtype=torch.float16), 'model.layers.19.input_layernorm.weight': tensor([0.4570, 0.4629, 0.4395,  ..., 0.4316, 0.4395, 0.4414],
       dtype=torch.float16), 'model.layers.19.post_attention_layernorm.weight': tensor([0.3613, 0.3477, 0.3457,  ..., 0.3574, 0.3555, 0.3594],
       dtype=torch.float16), 'model.layers.20.self_attn.q_proj.weight': tensor([[-3.3512e-03,  2.7599e-03,  2.2141e-02,  ...,  3.8643e-03,
          3.5381e-03, -2.3499e-02],
        [ 1.8127e-02, -2.1729e-02, -4.8876e-06,  ..., -6.9809e-03,
         -1.2131e-02,  1.7120e-02],
        [ 7.9117e-03, -6.8665e-03, -1.8326e-02,  ...,  1.7166e-02,
          7.0038e-03,  8.3780e-04],
        ...,
        [-3.1219e-02, -5.3162e-02,  1.0094e-02,  ..., -1.0918e-02,
          3.9520e-02,  1.1047e-02],
        [-8.0872e-02, -1.9455e-02,  1.1688e-02,  ...,  8.7585e-03,
          2.6505e-02,  8.3389e-03],
        [ 2.6978e-02,  2.4643e-03, -5.2071e-03,  ..., -1.9089e-02,
         -5.4512e-03, -1.3123e-03]], dtype=torch.float16), 'model.layers.20.self_attn.k_proj.weight': tensor([[-5.6038e-03,  7.3128e-03,  3.8834e-03,  ..., -1.6464e-02,
         -3.4750e-05,  3.6964e-03],
        [-3.7003e-04,  8.7585e-03,  4.4060e-03,  ..., -2.0161e-03,
          4.6120e-03,  1.1047e-02],
        [ 1.4694e-02,  2.8610e-03, -1.1185e-02,  ..., -1.5091e-02,
          1.4725e-03,  1.9836e-02],
        ...,
        [ 2.0256e-03,  4.9706e-03, -1.7044e-02,  ..., -2.3407e-02,
          2.5925e-02,  3.5919e-02],
        [-2.4094e-02,  2.4918e-02,  2.4490e-03,  ...,  2.1759e-02,
          3.0762e-02,  5.1605e-02],
        [-1.5228e-02, -3.0060e-02, -1.5793e-02,  ...,  2.0111e-02,
         -2.3468e-02,  5.2704e-02]], dtype=torch.float16), 'model.layers.20.self_attn.v_proj.weight': tensor([[-7.1526e-03, -1.8005e-02,  1.3290e-02,  ..., -2.7752e-03,
          1.9043e-02,  1.1086e-02],
        [-1.5945e-02, -3.7201e-02,  5.2223e-03,  ..., -1.2299e-02,
          3.4332e-04,  9.0942e-03],
        [-3.0174e-03, -1.3779e-02,  3.5763e-03,  ..., -2.5085e-02,
          9.9301e-05,  6.9046e-04],
        ...,
        [ 9.6893e-03, -1.2962e-02, -2.5940e-03,  ...,  2.4796e-02,
         -7.9269e-03,  9.0103e-03],
        [ 1.8799e-02,  1.4400e-03, -9.5062e-03,  ...,  8.0681e-04,
          1.1032e-02, -1.3542e-02],
        [ 2.3708e-03, -3.8452e-03,  2.4155e-02,  ..., -5.8403e-03,
         -1.1604e-02, -4.0283e-02]], dtype=torch.float16), 'model.layers.20.self_attn.o_proj.weight': tensor([[-0.0066,  0.0037,  0.0200,  ..., -0.0024,  0.0155, -0.0167],
        [ 0.0103, -0.0098, -0.0066,  ..., -0.0050, -0.0065,  0.0191],
        [ 0.0099, -0.0022, -0.0135,  ..., -0.0240,  0.0092,  0.0103],
        ...,
        [-0.0074, -0.0039,  0.0135,  ...,  0.0168, -0.0150,  0.0116],
        [-0.0101,  0.0031, -0.0113,  ...,  0.0121, -0.0273,  0.0036],
        [ 0.0107, -0.0183, -0.0039,  ...,  0.0065, -0.0230,  0.0195]],
       dtype=torch.float16), 'model.layers.20.mlp.gate_proj.weight': tensor([[ 0.0012, -0.0088, -0.0118,  ...,  0.0177, -0.0055,  0.0139],
        [-0.0275,  0.0091, -0.0060,  ..., -0.0098, -0.0143,  0.0149],
        [-0.0167, -0.0078,  0.0665,  ..., -0.0155,  0.0111, -0.0063],
        ...,
        [-0.0048, -0.0114,  0.0241,  ..., -0.0145,  0.0109, -0.0033],
        [ 0.0093,  0.0071,  0.0046,  ...,  0.0154,  0.0030,  0.0123],
        [-0.0032, -0.0308, -0.0070,  ...,  0.0059, -0.0142, -0.0134]],
       dtype=torch.float16), 'model.layers.20.mlp.up_proj.weight': tensor([[-0.0601, -0.0002, -0.0019,  ...,  0.0153, -0.0108, -0.0119],
        [-0.0098,  0.0006, -0.0098,  ..., -0.0502, -0.0143,  0.0372],
        [ 0.0060,  0.0302,  0.0182,  ...,  0.0070, -0.0175,  0.0047],
        ...,
        [-0.0139,  0.0211, -0.0016,  ..., -0.0180, -0.0043, -0.0030],
        [ 0.0155, -0.0318, -0.0148,  ...,  0.0031, -0.0208, -0.0377],
        [ 0.0145, -0.0241,  0.0311,  ..., -0.0039, -0.0222,  0.0036]],
       dtype=torch.float16), 'model.layers.20.mlp.down_proj.weight': tensor([[-0.0016,  0.0202, -0.0034,  ...,  0.0053, -0.0169, -0.0248],
        [ 0.0021,  0.0127, -0.0073,  ...,  0.0044, -0.0178,  0.0143],
        [-0.0127,  0.0180, -0.0242,  ..., -0.0042,  0.0238, -0.0053],
        ...,
        [-0.0375,  0.0276,  0.0056,  ...,  0.0026, -0.0002, -0.0114],
        [-0.0156,  0.0062, -0.0158,  ...,  0.0057,  0.0178, -0.0025],
        [ 0.0120, -0.0131,  0.0019,  ..., -0.0029, -0.0063, -0.0147]],
       dtype=torch.float16), 'model.layers.20.input_layernorm.weight': tensor([0.4590, 0.4688, 0.4395,  ..., 0.4414, 0.4375, 0.4590],
       dtype=torch.float16), 'model.layers.20.post_attention_layernorm.weight': tensor([0.3711, 0.3633, 0.3535,  ..., 0.3672, 0.3672, 0.3691],
       dtype=torch.float16), 'model.layers.21.self_attn.q_proj.weight': tensor([[-0.0138, -0.0057,  0.0144,  ..., -0.0153, -0.0030,  0.0070],
        [ 0.0252,  0.0060, -0.0012,  ...,  0.0031,  0.0002,  0.0141],
        [-0.0117, -0.0101,  0.0026,  ...,  0.0280,  0.0023,  0.0066],
        ...,
        [-0.0025, -0.0157,  0.0354,  ..., -0.0107, -0.0593,  0.0191],
        [-0.0115,  0.0166,  0.0210,  ...,  0.0295,  0.0328,  0.0014],
        [-0.0795, -0.0016, -0.0130,  ..., -0.0056,  0.0264, -0.0380]],
       dtype=torch.float16), 'model.layers.21.self_attn.k_proj.weight': tensor([[-1.3864e-04,  4.9858e-03, -3.4065e-03,  ...,  7.4348e-03,
          3.9625e-04,  1.0353e-02],
        [-8.3685e-05,  7.3128e-03,  1.9882e-02,  ...,  6.2561e-03,
          9.4681e-03,  8.8806e-03],
        [ 1.8494e-02,  2.9202e-03,  2.8900e-02,  ...,  1.5823e-02,
          1.2871e-02,  1.4816e-02],
        ...,
        [-1.8295e-02,  2.6428e-02,  1.5945e-03,  ...,  2.5818e-02,
         -1.9394e-02,  4.6265e-02],
        [ 2.0866e-03, -3.1281e-03, -1.4458e-02,  ..., -2.2232e-02,
          3.1250e-02,  1.6203e-03],
        [-1.8906e-02, -8.1329e-03, -3.1433e-02,  ...,  7.8888e-03,
         -7.5493e-03,  5.9235e-02]], dtype=torch.float16), 'model.layers.21.self_attn.v_proj.weight': tensor([[ 0.0032,  0.0054, -0.0003,  ...,  0.0005,  0.0223, -0.0286],
        [-0.0232,  0.0240, -0.0079,  ...,  0.0211, -0.0195,  0.0266],
        [ 0.0280, -0.0030,  0.0003,  ..., -0.0232,  0.0258, -0.0058],
        ...,
        [-0.0056, -0.0269,  0.0320,  ..., -0.0065,  0.0038, -0.0102],
        [-0.0154, -0.0090,  0.0156,  ...,  0.0048, -0.0052,  0.0086],
        [-0.0069,  0.0157, -0.0162,  ...,  0.0070, -0.0155, -0.0029]],
       dtype=torch.float16), 'model.layers.21.self_attn.o_proj.weight': tensor([[-0.0118, -0.0017,  0.0116,  ..., -0.0132,  0.0231,  0.0102],
        [-0.0058,  0.0267, -0.0098,  ..., -0.0189,  0.0061, -0.0112],
        [-0.0298, -0.0130,  0.0119,  ...,  0.0249,  0.0273,  0.0079],
        ...,
        [ 0.0198, -0.0042, -0.0136,  ...,  0.0248, -0.0006,  0.0144],
        [ 0.0152, -0.0136,  0.0135,  ..., -0.0006,  0.0018, -0.0185],
        [-0.0264,  0.0155, -0.0134,  ...,  0.0298, -0.0163,  0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.gate_proj.weight': tensor([[-0.0058, -0.0234,  0.0144,  ..., -0.0285,  0.0456,  0.0089],
        [ 0.0061,  0.0061,  0.0039,  ..., -0.0275,  0.0574,  0.0085],
        [ 0.0084,  0.0064,  0.0049,  ..., -0.0498,  0.0041, -0.0245],
        ...,
        [ 0.0102, -0.0292, -0.0215,  ...,  0.0331, -0.0270,  0.0024],
        [-0.0010,  0.0293,  0.0065,  ...,  0.0160, -0.0249,  0.0030],
        [ 0.0093, -0.0124, -0.0017,  ..., -0.0182,  0.0064, -0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.up_proj.weight': tensor([[ 0.0276, -0.0258, -0.0142,  ...,  0.0225,  0.0422, -0.0112],
        [-0.0261, -0.0107,  0.0040,  ...,  0.0379,  0.0453, -0.0010],
        [ 0.0133, -0.0011, -0.0018,  ...,  0.0067, -0.0079, -0.0061],
        ...,
        [-0.0461, -0.0002,  0.0137,  ...,  0.0162, -0.0095, -0.0118],
        [-0.0100, -0.0107,  0.0042,  ..., -0.0188, -0.0023,  0.0027],
        [-0.0051, -0.0337, -0.0248,  ..., -0.0035, -0.0055, -0.0260]],
       dtype=torch.float16), 'model.layers.21.mlp.down_proj.weight': tensor([[ 0.0117,  0.0132,  0.0028,  ...,  0.0198,  0.0068,  0.0062],
        [ 0.0095, -0.0029, -0.0151,  ...,  0.0037, -0.0319, -0.0163],
        [-0.0061,  0.0059,  0.0132,  ..., -0.0084,  0.0412,  0.0299],
        ...,
        [-0.0106,  0.0375,  0.0182,  ..., -0.0093, -0.0024,  0.0179],
        [ 0.0125,  0.0007, -0.0043,  ..., -0.0493, -0.0052,  0.0049],
        [ 0.0089,  0.0014,  0.0242,  ..., -0.0152,  0.0267, -0.0278]],
       dtype=torch.float16), 'model.layers.21.input_layernorm.weight': tensor([0.4805, 0.4883, 0.4688,  ..., 0.4609, 0.4805, 0.4824],
       dtype=torch.float16), 'model.layers.21.post_attention_layernorm.weight': tensor([0.3770, 0.3730, 0.3652,  ..., 0.3848, 0.3789, 0.3828],
       dtype=torch.float16), 'model.layers.22.self_attn.q_proj.weight': tensor([[-0.0249, -0.0096, -0.0046,  ...,  0.0535, -0.0391,  0.0201],
        [-0.0361, -0.0200, -0.0063,  ..., -0.0361,  0.0211, -0.0515],
        [-0.0322,  0.0232, -0.0146,  ...,  0.0286,  0.0173, -0.0100],
        ...,
        [ 0.0094,  0.0199,  0.0122,  ...,  0.0116,  0.0576, -0.0013],
        [-0.0323,  0.0064, -0.0220,  ...,  0.0465,  0.0088, -0.0131],
        [ 0.0380, -0.0125,  0.0065,  ..., -0.0505,  0.0111,  0.0195]],
       dtype=torch.float16), 'model.layers.22.self_attn.k_proj.weight': tensor([[-0.0130, -0.0065,  0.0037,  ...,  0.0139, -0.0164, -0.0157],
        [ 0.0106, -0.0099,  0.0312,  ..., -0.0320,  0.0375, -0.0140],
        [-0.0207,  0.0286, -0.0425,  ...,  0.0614,  0.0035, -0.0076],
        ...,
        [ 0.0210,  0.0074, -0.0286,  ..., -0.0204, -0.0135,  0.0172],
        [-0.0150, -0.0424,  0.0025,  ..., -0.0002, -0.0132, -0.0070],
        [ 0.0240, -0.0025,  0.0283,  ...,  0.0377, -0.0425,  0.0131]],
       dtype=torch.float16), 'model.layers.22.self_attn.v_proj.weight': tensor([[-0.0201,  0.0126, -0.0017,  ..., -0.0395, -0.0264,  0.0152],
        [-0.0346, -0.0108,  0.0072,  ..., -0.0269, -0.0413, -0.0159],
        [ 0.0243, -0.0267, -0.0040,  ...,  0.0528, -0.0026, -0.0139],
        ...,
        [-0.0104, -0.0462, -0.0226,  ...,  0.0124, -0.0114,  0.0218],
        [-0.0375, -0.0086,  0.0181,  ..., -0.0198,  0.0020, -0.0155],
        [ 0.0007,  0.0152, -0.0433,  ...,  0.0020, -0.0053,  0.0264]],
       dtype=torch.float16), 'model.layers.22.self_attn.o_proj.weight': tensor([[ 0.0263,  0.0156, -0.0218,  ..., -0.0026, -0.0353,  0.0123],
        [ 0.0242,  0.0126,  0.0108,  ...,  0.0045, -0.0100, -0.0247],
        [ 0.0046,  0.0026, -0.0081,  ..., -0.0232,  0.0110,  0.0107],
        ...,
        [-0.0008, -0.0238, -0.0129,  ..., -0.0138, -0.0166,  0.0042],
        [ 0.0259, -0.0104, -0.0196,  ..., -0.0260, -0.0027,  0.0137],
        [ 0.0039, -0.0258,  0.0213,  ...,  0.0115,  0.0122,  0.0111]],
       dtype=torch.float16), 'model.layers.22.mlp.gate_proj.weight': tensor([[-0.0284, -0.0156,  0.0184,  ...,  0.0108,  0.0197, -0.0452],
        [ 0.0226, -0.0165,  0.0014,  ...,  0.0043,  0.0029,  0.0221],
        [ 0.0005, -0.0069,  0.0054,  ...,  0.0142,  0.0002, -0.0003],
        ...,
        [-0.0043, -0.0079,  0.0014,  ..., -0.0152,  0.0073,  0.0022],
        [ 0.0095,  0.0165, -0.0293,  ..., -0.0035,  0.0127, -0.0289],
        [-0.0101,  0.0012,  0.0053,  ..., -0.0148,  0.0278,  0.0245]],
       dtype=torch.float16), 'model.layers.22.mlp.up_proj.weight': tensor([[ 0.0293,  0.0162, -0.0013,  ...,  0.0170,  0.0276,  0.0071],
        [ 0.0198,  0.0076,  0.0164,  ..., -0.0117, -0.0078,  0.0030],
        [ 0.0086, -0.0282, -0.0375,  ...,  0.0255,  0.0104,  0.0061],
        ...,
        [-0.0032, -0.0006, -0.0185,  ..., -0.0040,  0.0057,  0.0067],
        [ 0.0126, -0.0111, -0.0286,  ..., -0.0226,  0.0108, -0.0270],
        [-0.0014,  0.0023, -0.0036,  ..., -0.0440, -0.0598,  0.0154]],
       dtype=torch.float16), 'model.layers.22.mlp.down_proj.weight': tensor([[ 1.3527e-02, -5.1918e-03,  1.2299e-02,  ..., -1.8967e-02,
         -4.1428e-03, -3.6041e-02],
        [ 5.5885e-03,  2.6581e-02, -4.9362e-03,  ..., -1.1017e-02,
          1.4084e-02, -2.6627e-02],
        [-9.6512e-03,  3.9363e-04,  4.1962e-03,  ...,  1.2886e-02,
          4.5013e-03,  1.7517e-02],
        ...,
        [ 1.8250e-02, -8.5297e-03, -4.5288e-02,  ..., -2.8934e-03,
         -1.2947e-02, -1.7014e-02],
        [-1.1414e-02, -4.8767e-02,  1.1642e-02,  ...,  1.9028e-02,
         -2.7069e-02,  3.1433e-02],
        [ 1.4130e-02,  3.7551e-06, -3.1067e-02,  ..., -3.3903e-04,
         -1.8875e-02,  2.1286e-03]], dtype=torch.float16), 'model.layers.22.input_layernorm.weight': tensor([0.4883, 0.4922, 0.4805,  ..., 0.4688, 0.5000, 0.4902],
       dtype=torch.float16), 'model.layers.22.post_attention_layernorm.weight': tensor([0.3867, 0.3848, 0.3848,  ..., 0.3965, 0.3945, 0.3965],
       dtype=torch.float16), 'model.layers.23.self_attn.q_proj.weight': tensor([[-0.0039, -0.0179,  0.0076,  ..., -0.0155, -0.0002,  0.0023],
        [ 0.0042,  0.0015,  0.0140,  ..., -0.0166, -0.0002,  0.0083],
        [-0.0038,  0.0028,  0.0219,  ...,  0.0002, -0.0167,  0.0066],
        ...,
        [-0.0211,  0.0670,  0.0119,  ..., -0.0314, -0.0684, -0.0263],
        [-0.0411, -0.0311,  0.0199,  ..., -0.0232,  0.0020,  0.0060],
        [ 0.0047, -0.0559, -0.0093,  ...,  0.0072,  0.0403, -0.0026]],
       dtype=torch.float16), 'model.layers.23.self_attn.k_proj.weight': tensor([[-0.0030,  0.0121,  0.0090,  ...,  0.0010, -0.0083,  0.0059],
        [-0.0224,  0.0057, -0.0117,  ...,  0.0093,  0.0254,  0.0036],
        [ 0.0182,  0.0078, -0.0185,  ...,  0.0181,  0.0016, -0.0107],
        ...,
        [ 0.0067,  0.0374,  0.0580,  ..., -0.0332, -0.0120, -0.0131],
        [ 0.0034, -0.0352, -0.0113,  ..., -0.0232, -0.0226,  0.0194],
        [-0.0173, -0.0081, -0.0259,  ...,  0.0043,  0.0060, -0.0084]],
       dtype=torch.float16), 'model.layers.23.self_attn.v_proj.weight': tensor([[-0.0028,  0.0343, -0.0120,  ..., -0.0097, -0.0016, -0.0112],
        [-0.0093, -0.0038, -0.0190,  ..., -0.0033, -0.0097,  0.0105],
        [ 0.0111, -0.0211, -0.0208,  ...,  0.0130, -0.0508, -0.0305],
        ...,
        [ 0.0070,  0.0084,  0.0091,  ..., -0.0020,  0.0338,  0.0089],
        [ 0.0261,  0.0316, -0.0011,  ...,  0.0070,  0.0022, -0.0127],
        [-0.0201, -0.0131, -0.0540,  ...,  0.0057,  0.0076, -0.0381]],
       dtype=torch.float16), 'model.layers.23.self_attn.o_proj.weight': tensor([[-0.0019,  0.0019, -0.0202,  ..., -0.0179,  0.0104, -0.0070],
        [-0.0127, -0.0213, -0.0022,  ..., -0.0004,  0.0100, -0.0021],
        [ 0.0130,  0.0094,  0.0306,  ..., -0.0228, -0.0026, -0.0276],
        ...,
        [ 0.0290, -0.0114,  0.0348,  ..., -0.0162,  0.0113, -0.0013],
        [-0.0044,  0.0202, -0.0200,  ...,  0.0056, -0.0164,  0.0007],
        [ 0.0013, -0.0023, -0.0177,  ..., -0.0060,  0.0059, -0.0296]],
       dtype=torch.float16), 'model.layers.23.mlp.gate_proj.weight': tensor([[-1.1848e-02,  3.4424e-02, -1.0048e-02,  ..., -7.0152e-03,
          3.2776e-02,  9.2316e-03],
        [-1.4702e-02,  4.7729e-02, -1.7593e-02,  ...,  7.1678e-03,
         -1.8631e-02,  2.5070e-02],
        [-3.2349e-02,  1.4786e-02,  2.6913e-03,  ...,  1.5274e-02,
         -6.7444e-02,  1.2131e-02],
        ...,
        [-3.1548e-03,  1.9089e-02,  3.1509e-03,  ..., -8.1863e-03,
          7.2556e-03, -2.4643e-03],
        [-2.0828e-02,  3.8971e-02,  2.9430e-03,  ...,  3.3021e-05,
          7.8201e-03, -2.8381e-02],
        [ 8.8692e-04,  8.5144e-03,  1.6830e-02,  ..., -7.6561e-03,
          1.5450e-02, -1.6495e-02]], dtype=torch.float16), 'model.layers.23.mlp.up_proj.weight': tensor([[ 0.0283,  0.0066,  0.0351,  ...,  0.0134, -0.0322, -0.0074],
        [-0.0003,  0.0065, -0.0196,  ..., -0.0043, -0.0111,  0.0061],
        [-0.0177,  0.0038, -0.0218,  ...,  0.0182,  0.0106, -0.0052],
        ...,
        [-0.0084, -0.0166,  0.0116,  ...,  0.0093,  0.0408,  0.0053],
        [ 0.0036,  0.0078, -0.0382,  ...,  0.0106,  0.0070,  0.0220],
        [ 0.0014,  0.0079, -0.0071,  ...,  0.0070, -0.0126,  0.0127]],
       dtype=torch.float16), 'model.layers.23.mlp.down_proj.weight': tensor([[-0.0008,  0.0069, -0.0182,  ..., -0.0434, -0.0227,  0.0330],
        [-0.0012,  0.0231, -0.0064,  ...,  0.0257,  0.0306,  0.0021],
        [-0.0066, -0.0139, -0.0233,  ...,  0.0102,  0.0330, -0.0052],
        ...,
        [ 0.0001, -0.0050,  0.0135,  ...,  0.0180,  0.0037, -0.0187],
        [ 0.0296, -0.0114, -0.0007,  ..., -0.0026,  0.0101,  0.0058],
        [ 0.0031, -0.0307, -0.0152,  ..., -0.0104,  0.0204, -0.0025]],
       dtype=torch.float16), 'model.layers.23.input_layernorm.weight': tensor([0.5156, 0.5312, 0.5117,  ..., 0.5039, 0.5352, 0.5273],
       dtype=torch.float16), 'model.layers.23.post_attention_layernorm.weight': tensor([0.4043, 0.4023, 0.3965,  ..., 0.4043, 0.4121, 0.4062],
       dtype=torch.float16), 'model.layers.24.self_attn.q_proj.weight': tensor([[ 0.0204, -0.0176,  0.0145,  ...,  0.0364, -0.0300,  0.0106],
        [ 0.0215,  0.0088,  0.0012,  ..., -0.0026,  0.0186, -0.0139],
        [-0.0056, -0.0111, -0.0277,  ...,  0.0088, -0.0132,  0.0202],
        ...,
        [-0.0147,  0.0136, -0.0193,  ...,  0.0181, -0.0004, -0.0123],
        [-0.0288,  0.0078,  0.0070,  ...,  0.0100, -0.0323, -0.0062],
        [-0.0231, -0.0385, -0.0181,  ..., -0.0132,  0.0128,  0.0677]],
       dtype=torch.float16), 'model.layers.24.self_attn.k_proj.weight': tensor([[ 0.0235, -0.0035, -0.0125,  ...,  0.0110, -0.0008,  0.0021],
        [ 0.0118, -0.0169,  0.0035,  ..., -0.0216,  0.0245,  0.0066],
        [ 0.0097,  0.0045, -0.0445,  ...,  0.0204,  0.0171, -0.0175],
        ...,
        [ 0.0344,  0.0036,  0.0493,  ...,  0.0161,  0.0179, -0.0516],
        [-0.0119,  0.0177,  0.0127,  ...,  0.0320, -0.0181,  0.0027],
        [-0.0318, -0.0295, -0.0190,  ...,  0.0139, -0.0048,  0.0518]],
       dtype=torch.float16), 'model.layers.24.self_attn.v_proj.weight': tensor([[ 0.0212, -0.0251, -0.0028,  ..., -0.0041, -0.0040,  0.0113],
        [ 0.0288, -0.0173, -0.0054,  ..., -0.0646, -0.0470, -0.0240],
        [-0.0579, -0.0169, -0.0134,  ..., -0.0156, -0.0121, -0.0027],
        ...,
        [ 0.0011, -0.0192,  0.0171,  ...,  0.0272,  0.0067,  0.0217],
        [-0.0034, -0.0157, -0.0141,  ...,  0.0332, -0.0036,  0.0038],
        [ 0.0172,  0.0228,  0.0187,  ...,  0.0274, -0.0135, -0.0108]],
       dtype=torch.float16), 'model.layers.24.self_attn.o_proj.weight': tensor([[-0.0016,  0.0144,  0.0280,  ...,  0.0066, -0.0051, -0.0141],
        [-0.0118,  0.0308,  0.0156,  ...,  0.0195,  0.0282, -0.0186],
        [-0.0057, -0.0029,  0.0094,  ..., -0.0232,  0.0084, -0.0049],
        ...,
        [ 0.0045,  0.0179,  0.0119,  ..., -0.0027, -0.0031, -0.0005],
        [ 0.0508,  0.0096, -0.0061,  ...,  0.0075, -0.0257, -0.0106],
        [ 0.0026,  0.0155,  0.0109,  ...,  0.0046, -0.0261,  0.0131]],
       dtype=torch.float16), 'model.layers.24.mlp.gate_proj.weight': tensor([[-0.0267, -0.0104,  0.0093,  ..., -0.0031, -0.0058,  0.0011],
        [ 0.0075, -0.0302, -0.0231,  ...,  0.0075,  0.0110, -0.0131],
        [ 0.0014, -0.0466,  0.0257,  ...,  0.0015, -0.0532, -0.0207],
        ...,
        [ 0.0042, -0.0358, -0.0088,  ...,  0.0080,  0.0152, -0.0062],
        [ 0.0094,  0.0158,  0.0041,  ...,  0.0043,  0.0011,  0.0048],
        [-0.0410,  0.0326,  0.0009,  ...,  0.0294, -0.0074, -0.0473]],
       dtype=torch.float16), 'model.layers.24.mlp.up_proj.weight': tensor([[ 0.0016, -0.0057,  0.0201,  ...,  0.0262,  0.0025,  0.0263],
        [-0.0026,  0.0136, -0.0327,  ..., -0.0081, -0.0044, -0.0171],
        [ 0.0114, -0.0520,  0.0097,  ...,  0.0402,  0.0179, -0.0341],
        ...,
        [ 0.0115, -0.0207, -0.0147,  ..., -0.0067,  0.0112,  0.0111],
        [ 0.0412, -0.0033,  0.0132,  ...,  0.0025,  0.0054, -0.0100],
        [-0.0056, -0.0197,  0.0203,  ...,  0.0303,  0.0333,  0.0164]],
       dtype=torch.float16), 'model.layers.24.mlp.down_proj.weight': tensor([[-0.0052, -0.0114, -0.0357,  ...,  0.0015,  0.0022, -0.0194],
        [ 0.0278, -0.0030,  0.0175,  ..., -0.0015,  0.0048, -0.0508],
        [ 0.0195,  0.0135, -0.0284,  ...,  0.0095,  0.0215,  0.0078],
        ...,
        [-0.0092,  0.0149, -0.0204,  ..., -0.0330, -0.0109, -0.0146],
        [ 0.0112,  0.0248,  0.0120,  ...,  0.0257, -0.0255,  0.0133],
        [-0.0171, -0.0086,  0.0033,  ...,  0.0172, -0.0154, -0.0324]],
       dtype=torch.float16), 'model.layers.24.input_layernorm.weight': tensor([0.4980, 0.5273, 0.5195,  ..., 0.4863, 0.5234, 0.5156],
       dtype=torch.float16), 'model.layers.24.post_attention_layernorm.weight': tensor([0.4219, 0.4180, 0.4180,  ..., 0.4199, 0.4258, 0.4219],
       dtype=torch.float16), 'model.layers.25.self_attn.q_proj.weight': tensor([[ 1.7204e-03, -1.9974e-02, -2.5269e-02,  ...,  1.2192e-02,
         -9.5139e-03,  4.5357e-03],
        [-1.3947e-02,  3.5877e-03,  2.3804e-02,  ..., -1.4412e-02,
         -3.4485e-03,  2.4557e-05],
        [ 9.1629e-03,  8.6136e-03,  3.9368e-03,  ..., -1.1436e-02,
         -2.0157e-02, -1.5068e-02],
        ...,
        [ 5.5756e-02,  4.5746e-02,  2.2964e-03,  ...,  4.9858e-03,
          1.5762e-02, -2.6688e-02],
        [-6.3721e-02, -5.0293e-02, -1.2497e-02,  ..., -1.0338e-02,
         -2.1088e-02,  4.0932e-03],
        [ 3.9978e-02, -4.3365e-02, -2.2217e-02,  ...,  3.9279e-05,
          1.0757e-02, -2.6917e-02]], dtype=torch.float16), 'model.layers.25.self_attn.k_proj.weight': tensor([[-5.6648e-03, -1.3237e-02, -1.2611e-02,  ...,  1.5726e-03,
          1.6232e-03,  1.4572e-03],
        [-1.4183e-02, -1.4297e-02,  2.7120e-05,  ..., -3.4618e-03,
         -2.1515e-02,  7.6561e-03],
        [-8.5354e-04,  1.9426e-03,  4.9133e-03,  ...,  6.0310e-03,
         -6.0654e-03,  7.2212e-03],
        ...,
        [ 1.3847e-02,  4.8248e-02, -9.6283e-03,  ..., -5.4504e-02,
         -5.6427e-02,  3.7598e-02],
        [ 3.4454e-02, -3.4393e-02,  4.3602e-03,  ..., -8.3771e-03,
          2.8229e-03,  1.0277e-02],
        [-7.9346e-03, -2.7908e-02,  3.2768e-03,  ...,  3.6316e-02,
          8.8501e-03, -2.9388e-02]], dtype=torch.float16), 'model.layers.25.self_attn.v_proj.weight': tensor([[ 0.0173,  0.0201,  0.0084,  ...,  0.0248, -0.0133, -0.0128],
        [-0.0143, -0.0107,  0.0099,  ...,  0.0090, -0.0273, -0.0127],
        [-0.0150,  0.0164, -0.0202,  ..., -0.0099,  0.0054, -0.0090],
        ...,
        [-0.0186, -0.0324, -0.0026,  ...,  0.0150,  0.0097,  0.0189],
        [-0.0152,  0.0089,  0.0258,  ..., -0.0068,  0.0044, -0.0216],
        [-0.0386, -0.0105, -0.0145,  ...,  0.0065,  0.0192,  0.0297]],
       dtype=torch.float16), 'model.layers.25.self_attn.o_proj.weight': tensor([[ 1.9470e-02,  1.0475e-02,  1.3229e-02,  ...,  1.4595e-02,
          2.8362e-03,  3.7861e-03],
        [-2.6352e-02, -9.8953e-03, -1.6998e-02,  ...,  2.6093e-02,
         -7.1945e-03, -1.3523e-03],
        [-8.1863e-03, -1.5879e-03,  2.5925e-02,  ..., -1.9821e-02,
         -1.3336e-02, -1.3371e-03],
        ...,
        [-1.3893e-02,  2.3819e-02, -2.7676e-03,  ...,  1.0544e-02,
          1.3359e-02,  2.7084e-02],
        [-4.1842e-05, -2.7664e-02, -3.7750e-02,  ..., -2.3926e-02,
         -1.6037e-02,  2.2125e-03],
        [-2.4704e-02, -8.4839e-03, -1.3412e-02,  ..., -3.7964e-02,
         -2.0554e-02, -1.3344e-02]], dtype=torch.float16), 'model.layers.25.mlp.gate_proj.weight': tensor([[ 0.0037, -0.0402,  0.0397,  ..., -0.0020, -0.0228,  0.0070],
        [-0.0239, -0.0074, -0.0153,  ...,  0.0345,  0.0486,  0.0262],
        [-0.0017,  0.0171, -0.0012,  ...,  0.0176,  0.0161,  0.0310],
        ...,
        [-0.0347,  0.0086,  0.0019,  ..., -0.0027, -0.0130,  0.0004],
        [ 0.0218,  0.0088,  0.0610,  ...,  0.0170,  0.0224,  0.0062],
        [-0.0047, -0.0022, -0.0174,  ...,  0.0450,  0.0030, -0.0100]],
       dtype=torch.float16), 'model.layers.25.mlp.up_proj.weight': tensor([[-0.0265, -0.0114,  0.0169,  ...,  0.0016,  0.0052, -0.0100],
        [-0.0138, -0.0033,  0.0076,  ..., -0.0056,  0.0163,  0.0114],
        [ 0.0298,  0.0056,  0.0224,  ..., -0.0136, -0.0282, -0.0026],
        ...,
        [ 0.0102,  0.0049,  0.0475,  ...,  0.0056, -0.0394, -0.0210],
        [-0.0387, -0.0015, -0.0307,  ..., -0.0457, -0.0228, -0.0002],
        [-0.0147, -0.0097,  0.0229,  ...,  0.0258, -0.0055,  0.0242]],
       dtype=torch.float16), 'model.layers.25.mlp.down_proj.weight': tensor([[ 0.0289, -0.0159,  0.0110,  ...,  0.0204, -0.0067,  0.0310],
        [-0.0150, -0.0020,  0.0045,  ...,  0.0100, -0.0012,  0.0230],
        [ 0.0123,  0.0103, -0.0082,  ..., -0.0229,  0.0118, -0.0181],
        ...,
        [ 0.0188, -0.0142, -0.0232,  ..., -0.0466, -0.0010,  0.0237],
        [ 0.0065, -0.0114,  0.0031,  ...,  0.0045,  0.0039,  0.0058],
        [-0.0111, -0.0243,  0.0161,  ..., -0.0298, -0.0061, -0.0051]],
       dtype=torch.float16), 'model.layers.25.input_layernorm.weight': tensor([0.5547, 0.5703, 0.5547,  ..., 0.5547, 0.5742, 0.5625],
       dtype=torch.float16), 'model.layers.25.post_attention_layernorm.weight': tensor([0.4316, 0.4316, 0.4297,  ..., 0.4355, 0.4336, 0.4395],
       dtype=torch.float16), 'model.layers.26.self_attn.q_proj.weight': tensor([[ 0.0299, -0.0067, -0.0090,  ..., -0.0101,  0.0408,  0.0010],
        [-0.0050, -0.0182,  0.0142,  ...,  0.0062, -0.0230,  0.0177],
        [-0.0064,  0.0024,  0.0114,  ...,  0.0050, -0.0381, -0.0195],
        ...,
        [ 0.0009, -0.0125, -0.0078,  ...,  0.0158,  0.0216,  0.0021],
        [ 0.0070, -0.0182, -0.0230,  ...,  0.0060, -0.0005, -0.0075],
        [-0.0146,  0.0520,  0.0271,  ..., -0.0072, -0.0645, -0.0416]],
       dtype=torch.float16), 'model.layers.26.self_attn.k_proj.weight': tensor([[ 0.0220,  0.0199, -0.0121,  ..., -0.0308,  0.0384,  0.0029],
        [-0.0267,  0.0055,  0.0148,  ...,  0.0016,  0.0168,  0.0291],
        [ 0.0129,  0.0286,  0.0004,  ..., -0.0190, -0.0591, -0.0098],
        ...,
        [ 0.0247,  0.0246,  0.0012,  ..., -0.0466, -0.0545,  0.0259],
        [-0.0216, -0.0389, -0.0074,  ...,  0.0483,  0.0228, -0.0051],
        [-0.0171,  0.0094, -0.0132,  ...,  0.0006, -0.0198, -0.0154]],
       dtype=torch.float16), 'model.layers.26.self_attn.v_proj.weight': tensor([[ 0.0506, -0.0262, -0.0245,  ..., -0.0152,  0.0105, -0.0191],
        [-0.0491, -0.0213,  0.0254,  ...,  0.0101, -0.0062,  0.0016],
        [ 0.0013, -0.0020, -0.0238,  ..., -0.0061,  0.0042, -0.0306],
        ...,
        [-0.0236, -0.0176, -0.0008,  ...,  0.0428, -0.0050,  0.0086],
        [ 0.0039, -0.0365, -0.0094,  ..., -0.0166, -0.0242, -0.0042],
        [ 0.0092,  0.0188, -0.0045,  ...,  0.0071,  0.0064,  0.0172]],
       dtype=torch.float16), 'model.layers.26.self_attn.o_proj.weight': tensor([[ 0.0108, -0.0005, -0.0306,  ...,  0.0052,  0.0149,  0.0272],
        [ 0.0067,  0.0455,  0.0062,  ..., -0.0016,  0.0462, -0.0053],
        [ 0.0013,  0.0102, -0.0247,  ..., -0.0226,  0.0037, -0.0018],
        ...,
        [ 0.0307,  0.0040,  0.0108,  ..., -0.0002,  0.0182,  0.0043],
        [-0.0128,  0.0049, -0.0096,  ...,  0.0135, -0.0017, -0.0425],
        [ 0.0257,  0.0072,  0.0050,  ..., -0.0276,  0.0283, -0.0160]],
       dtype=torch.float16), 'model.layers.26.mlp.gate_proj.weight': tensor([[ 0.0187,  0.0045,  0.0131,  ...,  0.0258,  0.0262, -0.0261],
        [-0.0062,  0.0102, -0.0258,  ..., -0.0255, -0.0266,  0.0190],
        [ 0.0022, -0.0109,  0.0007,  ...,  0.0060,  0.0038, -0.0172],
        ...,
        [-0.0065,  0.0356, -0.0078,  ..., -0.0015, -0.0380, -0.0219],
        [-0.0150,  0.0138,  0.0250,  ...,  0.0159,  0.0240,  0.0123],
        [ 0.0182, -0.0038, -0.0058,  ..., -0.0301, -0.0062, -0.0043]],
       dtype=torch.float16), 'model.layers.26.mlp.up_proj.weight': tensor([[-0.0168,  0.0401,  0.0018,  ...,  0.0049, -0.0029, -0.0195],
        [-0.0410, -0.0193,  0.0116,  ...,  0.0265, -0.0069,  0.0175],
        [ 0.0082, -0.0065, -0.0241,  ...,  0.0146, -0.0218, -0.0152],
        ...,
        [ 0.0058, -0.0324,  0.0059,  ...,  0.0126,  0.0300, -0.0139],
        [-0.0445,  0.0100,  0.0505,  ...,  0.0299, -0.0133,  0.0091],
        [ 0.0003, -0.0191,  0.0266,  ..., -0.0121,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.layers.26.mlp.down_proj.weight': tensor([[-0.0157, -0.0151, -0.0184,  ...,  0.0317,  0.0165,  0.0026],
        [ 0.0194,  0.0122,  0.0013,  ...,  0.0555,  0.0187, -0.0188],
        [-0.0182,  0.0041, -0.0274,  ..., -0.0111,  0.0171,  0.0083],
        ...,
        [-0.0175, -0.0124, -0.0203,  ...,  0.0105,  0.0436, -0.0020],
        [-0.0128, -0.0142, -0.0195,  ...,  0.0095,  0.0033,  0.0230],
        [ 0.0049, -0.0129, -0.0006,  ...,  0.0101,  0.0221,  0.0164]],
       dtype=torch.float16), 'model.layers.26.input_layernorm.weight': tensor([0.5312, 0.5469, 0.5469,  ..., 0.5234, 0.5508, 0.5547],
       dtype=torch.float16), 'model.layers.26.post_attention_layernorm.weight': tensor([0.4492, 0.4492, 0.4375,  ..., 0.4512, 0.4590, 0.4590],
       dtype=torch.float16), 'model.layers.27.self_attn.q_proj.weight': tensor([[-0.0292,  0.0145,  0.0077,  ..., -0.0038,  0.0122,  0.0435],
        [-0.0134,  0.0433,  0.0299,  ..., -0.0242,  0.0111,  0.0059],
        [-0.0217, -0.0236,  0.0096,  ...,  0.0025, -0.0223,  0.0289],
        ...,
        [-0.0505,  0.0273, -0.0095,  ...,  0.0185, -0.0201, -0.0225],
        [-0.0039,  0.0271,  0.0072,  ...,  0.0084,  0.0002,  0.0258],
        [-0.0235, -0.0104,  0.0114,  ...,  0.0226,  0.0154, -0.0077]],
       dtype=torch.float16), 'model.layers.27.self_attn.k_proj.weight': tensor([[-0.0173, -0.0195,  0.0098,  ..., -0.0015, -0.0104,  0.0059],
        [-0.0029,  0.0090,  0.0194,  ...,  0.0424, -0.0081, -0.0110],
        [ 0.0017, -0.0138,  0.0081,  ..., -0.0129,  0.0021, -0.0088],
        ...,
        [-0.0041, -0.0153,  0.0362,  ...,  0.0069, -0.0344, -0.0087],
        [ 0.0248, -0.0192, -0.0473,  ...,  0.0660, -0.0128,  0.0439],
        [ 0.0315,  0.0143, -0.0021,  ..., -0.0374, -0.0376,  0.0114]],
       dtype=torch.float16), 'model.layers.27.self_attn.v_proj.weight': tensor([[ 0.0174, -0.0144, -0.0334,  ...,  0.0311,  0.0319, -0.0054],
        [ 0.0185,  0.0108,  0.0118,  ...,  0.0023, -0.0246,  0.0214],
        [-0.0263, -0.0055,  0.0169,  ..., -0.0106,  0.0546, -0.0242],
        ...,
        [ 0.0146, -0.0203, -0.0192,  ...,  0.0176, -0.0095, -0.0034],
        [ 0.0059, -0.0240, -0.0200,  ..., -0.0100, -0.0106, -0.0184],
        [ 0.0211, -0.0241, -0.0149,  ..., -0.0229, -0.0193,  0.0111]],
       dtype=torch.float16), 'model.layers.27.self_attn.o_proj.weight': tensor([[ 0.0038, -0.0119,  0.0095,  ...,  0.0242,  0.0067, -0.0269],
        [ 0.0054,  0.0286, -0.0241,  ..., -0.0172, -0.0162,  0.0058],
        [-0.0047, -0.0113, -0.0132,  ...,  0.0162,  0.0009, -0.0092],
        ...,
        [ 0.0251, -0.0114, -0.0128,  ...,  0.0111,  0.0484, -0.0008],
        [ 0.0368, -0.0221, -0.0091,  ..., -0.0011, -0.0006,  0.0184],
        [ 0.0446,  0.0125,  0.0281,  ..., -0.0113, -0.0002, -0.0220]],
       dtype=torch.float16), 'model.layers.27.mlp.gate_proj.weight': tensor([[ 0.0450,  0.0128, -0.0067,  ...,  0.0097,  0.0032, -0.0147],
        [-0.0158,  0.0018, -0.0322,  ...,  0.0303,  0.0333,  0.0226],
        [ 0.0075,  0.0203, -0.0080,  ..., -0.0125, -0.0238,  0.0320],
        ...,
        [ 0.0358,  0.0211,  0.0024,  ..., -0.0008,  0.0165, -0.0047],
        [-0.0144,  0.0255, -0.0209,  ..., -0.0090, -0.0178,  0.0073],
        [ 0.0026, -0.0184, -0.0149,  ..., -0.0166, -0.0047, -0.0048]],
       dtype=torch.float16), 'model.layers.27.mlp.up_proj.weight': tensor([[-0.0049,  0.0078,  0.0265,  ..., -0.0012,  0.0131, -0.0389],
        [-0.0102,  0.0028, -0.0278,  ...,  0.0119, -0.0223, -0.0237],
        [ 0.0258,  0.0162,  0.0435,  ...,  0.0278,  0.0015, -0.0196],
        ...,
        [-0.0044,  0.0250,  0.0330,  ..., -0.0218,  0.0206, -0.0381],
        [ 0.0097,  0.0212,  0.0149,  ...,  0.0130, -0.0131, -0.0248],
        [-0.0111,  0.0048, -0.0053,  ..., -0.0063, -0.0244, -0.0093]],
       dtype=torch.float16), 'model.layers.27.mlp.down_proj.weight': tensor([[ 2.4376e-03, -2.2705e-02,  3.4363e-02,  ..., -1.9394e-02,
          1.9669e-02, -1.1414e-02],
        [ 8.0466e-05,  1.3931e-02, -9.4910e-03,  ..., -1.9272e-02,
         -3.1616e-02,  1.2093e-02],
        [ 4.6478e-02,  1.3847e-02,  5.7602e-03,  ..., -3.2166e-02,
          4.1733e-03,  2.9587e-02],
        ...,
        [-7.6523e-03,  1.0971e-02,  1.5335e-02,  ...,  7.5302e-03,
         -4.5685e-02,  2.5742e-02],
        [-2.2018e-02, -3.3932e-03, -1.7227e-02,  ...,  2.2934e-02,
         -9.0866e-03,  2.0813e-02],
        [ 4.7493e-03,  1.7471e-02, -9.1858e-03,  ...,  1.9531e-02,
         -2.3441e-03, -4.7493e-03]], dtype=torch.float16), 'model.layers.27.input_layernorm.weight': tensor([0.5625, 0.5625, 0.5586,  ..., 0.5547, 0.5625, 0.5703],
       dtype=torch.float16), 'model.layers.27.post_attention_layernorm.weight': tensor([0.4688, 0.4629, 0.4531,  ..., 0.4668, 0.4707, 0.4688],
       dtype=torch.float16), 'model.layers.28.self_attn.q_proj.weight': tensor([[-3.2127e-05, -1.9119e-02, -7.1669e-04,  ..., -1.4694e-02,
         -9.0561e-03, -1.0872e-02],
        [ 1.1421e-02, -1.8387e-02, -2.4986e-03,  ...,  1.3634e-02,
          5.4283e-03, -3.9635e-03],
        [ 1.4305e-02,  6.4993e-04, -1.0948e-02,  ..., -3.7956e-03,
         -2.4414e-02,  2.4261e-02],
        ...,
        [-1.1253e-02,  2.4719e-02, -5.3101e-02,  ...,  1.6006e-02,
         -7.5684e-03, -3.9825e-02],
        [ 1.6541e-02, -2.6855e-02, -1.2665e-02,  ...,  2.0569e-02,
          3.2928e-02, -6.5002e-02],
        [ 1.9409e-02,  1.4633e-02, -4.5654e-02,  ...,  4.5868e-02,
          1.4122e-02, -3.6987e-02]], dtype=torch.float16), 'model.layers.28.self_attn.k_proj.weight': tensor([[-0.0036, -0.0034,  0.0078,  ..., -0.0043,  0.0148, -0.0134],
        [-0.0133, -0.0068, -0.0168,  ..., -0.0066,  0.0050,  0.0043],
        [ 0.0061,  0.0063, -0.0146,  ..., -0.0197, -0.0112,  0.0050],
        ...,
        [-0.0251, -0.0133, -0.0040,  ..., -0.0014, -0.0604, -0.0040],
        [ 0.0462, -0.0221,  0.0039,  ...,  0.0161,  0.0397,  0.0285],
        [ 0.0180, -0.0042,  0.0045,  ..., -0.0038, -0.0185, -0.0136]],
       dtype=torch.float16), 'model.layers.28.self_attn.v_proj.weight': tensor([[-0.0240,  0.0090,  0.0227,  ..., -0.0210, -0.0288,  0.0260],
        [ 0.0231, -0.0178, -0.0135,  ..., -0.0447,  0.0313, -0.0163],
        [-0.0102,  0.0174, -0.0021,  ...,  0.0075, -0.0479,  0.0167],
        ...,
        [ 0.0193,  0.0043, -0.0005,  ...,  0.0143, -0.0064, -0.0217],
        [ 0.0511,  0.0041,  0.0421,  ...,  0.0019,  0.0046, -0.0031],
        [ 0.0181,  0.0192, -0.0485,  ...,  0.0328, -0.0048,  0.0090]],
       dtype=torch.float16), 'model.layers.28.self_attn.o_proj.weight': tensor([[ 1.1208e-02,  2.4567e-02, -4.1473e-02,  ..., -3.4485e-02,
          1.7929e-02, -9.8646e-05],
        [-1.2238e-02, -2.0905e-02, -2.8381e-03,  ..., -1.7075e-02,
          2.7145e-02,  3.2501e-02],
        [ 2.7863e-02,  1.7838e-02, -5.3741e-02,  ...,  2.2293e-02,
          1.5701e-02, -1.6464e-02],
        ...,
        [ 2.5444e-03, -4.4098e-03,  3.4332e-02,  ..., -9.8801e-03,
         -3.9917e-02, -6.6757e-03],
        [-7.5188e-03, -5.8655e-02, -1.8112e-02,  ...,  2.0889e-02,
         -2.8183e-02, -2.7084e-02],
        [-4.3823e-02, -4.1618e-03, -1.0742e-02,  ..., -1.9196e-02,
         -8.0719e-03,  4.2839e-03]], dtype=torch.float16), 'model.layers.28.mlp.gate_proj.weight': tensor([[-0.0007,  0.0031, -0.0068,  ...,  0.0274, -0.0111,  0.0312],
        [-0.0257,  0.0139, -0.0106,  ...,  0.0121,  0.0034,  0.0177],
        [ 0.0099,  0.0288,  0.0274,  ...,  0.0168,  0.0038,  0.0067],
        ...,
        [-0.0053,  0.0228,  0.0102,  ...,  0.0135,  0.0128, -0.0202],
        [ 0.0124, -0.0344, -0.0104,  ..., -0.0197, -0.0044, -0.0032],
        [-0.0318,  0.0149,  0.0106,  ..., -0.0078, -0.0112,  0.0179]],
       dtype=torch.float16), 'model.layers.28.mlp.up_proj.weight': tensor([[ 0.0224,  0.0047,  0.0220,  ...,  0.0277,  0.0156,  0.0114],
        [-0.0177, -0.0260, -0.0041,  ..., -0.0033, -0.0355, -0.0220],
        [ 0.0064,  0.0259, -0.0073,  ...,  0.0068,  0.0073, -0.0160],
        ...,
        [-0.0055, -0.0151,  0.0324,  ..., -0.0026,  0.0111, -0.0013],
        [-0.0215,  0.0078, -0.0074,  ...,  0.0127, -0.0099, -0.0497],
        [-0.0093, -0.0252, -0.0048,  ..., -0.0067,  0.0076,  0.0080]],
       dtype=torch.float16), 'model.layers.28.mlp.down_proj.weight': tensor([[ 0.0077,  0.0342, -0.0055,  ...,  0.0029, -0.0016, -0.0298],
        [-0.0009, -0.0338,  0.0198,  ..., -0.0268, -0.0070, -0.0280],
        [-0.0241,  0.0253, -0.0140,  ...,  0.0032,  0.0074, -0.0012],
        ...,
        [ 0.0106, -0.0143, -0.0053,  ..., -0.0309, -0.0309,  0.0070],
        [-0.0170, -0.0194,  0.0628,  ..., -0.0242, -0.0061,  0.0128],
        [-0.0234,  0.0108, -0.0081,  ...,  0.0294,  0.0295, -0.0142]],
       dtype=torch.float16), 'model.layers.28.input_layernorm.weight': tensor([0.5781, 0.5859, 0.5664,  ..., 0.5547, 0.5742, 0.5742],
       dtype=torch.float16), 'model.layers.28.post_attention_layernorm.weight': tensor([0.4805, 0.4785, 0.4648,  ..., 0.4785, 0.4727, 0.4727],
       dtype=torch.float16), 'model.layers.29.self_attn.q_proj.weight': tensor([[ 0.0060,  0.0026, -0.0075,  ...,  0.0002, -0.0110,  0.0094],
        [-0.0288, -0.0180, -0.0257,  ..., -0.0128, -0.0063, -0.0059],
        [-0.0291,  0.0377, -0.0024,  ..., -0.0022, -0.0156,  0.0146],
        ...,
        [ 0.0005,  0.0704, -0.0331,  ...,  0.0133, -0.0080, -0.0352],
        [-0.0236, -0.0242,  0.0169,  ..., -0.0142, -0.0230,  0.0260],
        [ 0.0005, -0.0416, -0.0127,  ...,  0.0132,  0.0065, -0.0391]],
       dtype=torch.float16), 'model.layers.29.self_attn.k_proj.weight': tensor([[ 0.0357, -0.0135, -0.0162,  ...,  0.0005,  0.0101, -0.0023],
        [-0.0177,  0.0316, -0.0048,  ..., -0.0086,  0.0006, -0.0218],
        [ 0.0214,  0.0079,  0.0186,  ...,  0.0193,  0.0339, -0.0014],
        ...,
        [-0.0317,  0.0448,  0.0010,  ..., -0.0091,  0.0024, -0.0117],
        [ 0.0014, -0.0123, -0.0701,  ..., -0.0106, -0.0095, -0.0427],
        [ 0.0107, -0.0124, -0.0583,  ..., -0.0584, -0.0144,  0.0027]],
       dtype=torch.float16), 'model.layers.29.self_attn.v_proj.weight': tensor([[ 0.0110,  0.0064,  0.0324,  ...,  0.0194,  0.0085,  0.0135],
        [-0.0017,  0.0247,  0.0385,  ..., -0.0199,  0.0092, -0.0022],
        [-0.0130,  0.0104, -0.0103,  ...,  0.0083,  0.0268,  0.0188],
        ...,
        [ 0.0067,  0.0294,  0.0116,  ..., -0.0203, -0.0125, -0.0172],
        [ 0.0001,  0.0276, -0.0236,  ...,  0.0186,  0.0294, -0.0053],
        [-0.0033, -0.0211,  0.0092,  ..., -0.0019, -0.0083,  0.0262]],
       dtype=torch.float16), 'model.layers.29.self_attn.o_proj.weight': tensor([[-6.3057e-03,  3.2288e-02,  3.3630e-02,  ...,  5.8222e-04,
         -1.7517e-02, -6.4850e-03],
        [-2.0340e-02, -2.5772e-02, -1.2833e-02,  ...,  1.2199e-02,
         -2.8244e-02,  1.2634e-02],
        [ 2.6093e-02,  2.8381e-02, -8.5678e-03,  ..., -3.7781e-02,
          1.7441e-02, -2.1240e-02],
        ...,
        [-2.8381e-02, -1.6617e-02,  2.8061e-02,  ..., -7.0839e-03,
         -7.8201e-03, -1.4076e-02],
        [-1.3969e-02, -1.0399e-02,  3.3966e-02,  ..., -4.7803e-05,
         -2.0554e-02,  4.7226e-03],
        [ 1.5411e-02,  3.9749e-03, -3.4275e-03,  ...,  4.1122e-03,
          1.9104e-02, -2.8473e-02]], dtype=torch.float16), 'model.layers.29.mlp.gate_proj.weight': tensor([[ 0.0161,  0.0169, -0.0145,  ..., -0.0036, -0.0243,  0.0359],
        [ 0.0034,  0.0243, -0.0081,  ..., -0.0228,  0.0151,  0.0046],
        [ 0.0371, -0.0013, -0.0085,  ..., -0.0063,  0.0206,  0.0335],
        ...,
        [-0.0048,  0.0104, -0.0152,  ...,  0.0026,  0.0065,  0.0039],
        [ 0.0079,  0.0031, -0.0292,  ..., -0.0222, -0.0051,  0.0174],
        [-0.0031,  0.0190, -0.0012,  ...,  0.0228, -0.0130, -0.0158]],
       dtype=torch.float16), 'model.layers.29.mlp.up_proj.weight': tensor([[-0.0069,  0.0021,  0.0118,  ...,  0.0150,  0.0049,  0.0057],
        [ 0.0012,  0.0072,  0.0320,  ...,  0.0089, -0.0199,  0.0363],
        [-0.0076, -0.0212, -0.0125,  ..., -0.0495,  0.0085, -0.0360],
        ...,
        [ 0.0260,  0.0129,  0.0126,  ...,  0.0124,  0.0245,  0.0357],
        [-0.0250, -0.0191, -0.0051,  ...,  0.0142,  0.0133,  0.0017],
        [ 0.0065, -0.0030,  0.0111,  ..., -0.0080,  0.0094,  0.0100]],
       dtype=torch.float16), 'model.layers.29.mlp.down_proj.weight': tensor([[ 0.0411,  0.0098, -0.0018,  ...,  0.0168, -0.0244, -0.0152],
        [ 0.0184,  0.0098,  0.0223,  ...,  0.0344,  0.0027,  0.0017],
        [ 0.0008, -0.0209, -0.0160,  ..., -0.0007,  0.0110, -0.0271],
        ...,
        [ 0.0088, -0.0090,  0.0057,  ..., -0.0189, -0.0051, -0.0197],
        [ 0.0228,  0.0159,  0.0265,  ...,  0.0094, -0.0411,  0.0024],
        [ 0.0148, -0.0185, -0.0088,  ..., -0.0158, -0.0135,  0.0045]],
       dtype=torch.float16), 'model.layers.29.input_layernorm.weight': tensor([0.5430, 0.5586, 0.5391,  ..., 0.5312, 0.5586, 0.5625],
       dtype=torch.float16), 'model.layers.29.post_attention_layernorm.weight': tensor([0.4902, 0.4922, 0.4785,  ..., 0.4785, 0.4922, 0.4805],
       dtype=torch.float16), 'model.layers.30.self_attn.q_proj.weight': tensor([[-0.0041, -0.0047,  0.0075,  ..., -0.0091, -0.0045,  0.0028],
        [ 0.0163,  0.0142,  0.0050,  ..., -0.0033, -0.0027, -0.0191],
        [-0.0086, -0.0204,  0.0428,  ...,  0.0224,  0.0053, -0.0305],
        ...,
        [-0.0093, -0.0009, -0.0012,  ...,  0.0209, -0.0119,  0.0017],
        [-0.0005, -0.0218, -0.0206,  ...,  0.0153,  0.0086, -0.0354],
        [-0.0708, -0.0093,  0.0420,  ..., -0.0094, -0.0046, -0.0015]],
       dtype=torch.float16), 'model.layers.30.self_attn.k_proj.weight': tensor([[ 0.0262, -0.0208,  0.0015,  ..., -0.0112,  0.0095,  0.0076],
        [ 0.0337,  0.0127,  0.0035,  ..., -0.0041, -0.0045,  0.0022],
        [-0.0044, -0.0148,  0.0216,  ...,  0.0055, -0.0088, -0.0004],
        ...,
        [ 0.0057,  0.0255,  0.0007,  ...,  0.0564, -0.0037, -0.0002],
        [ 0.0107, -0.0630,  0.0325,  ...,  0.0062, -0.0082, -0.0273],
        [-0.0373, -0.0082,  0.0209,  ...,  0.0079,  0.0169, -0.0247]],
       dtype=torch.float16), 'model.layers.30.self_attn.v_proj.weight': tensor([[-0.0035, -0.0291,  0.0310,  ..., -0.0268, -0.0363,  0.0307],
        [ 0.0073,  0.0172,  0.0300,  ..., -0.0118,  0.0262,  0.0019],
        [-0.0203,  0.0174, -0.0189,  ...,  0.0050, -0.0255, -0.0103],
        ...,
        [ 0.0184, -0.0039, -0.0030,  ..., -0.0245,  0.0030,  0.0241],
        [-0.0072, -0.0434,  0.0219,  ...,  0.0296, -0.0089,  0.0216],
        [-0.0088,  0.0059,  0.0193,  ..., -0.0144, -0.0613, -0.0227]],
       dtype=torch.float16), 'model.layers.30.self_attn.o_proj.weight': tensor([[-0.0074,  0.0176, -0.0070,  ...,  0.0119, -0.0119, -0.0202],
        [-0.0116, -0.0252, -0.0082,  ...,  0.0136, -0.0305, -0.0236],
        [-0.0294, -0.0029,  0.0179,  ..., -0.0482, -0.0128, -0.0113],
        ...,
        [ 0.0068,  0.0052,  0.0028,  ..., -0.0247,  0.0106,  0.0177],
        [ 0.0227, -0.0089,  0.0036,  ...,  0.0353, -0.0069,  0.0047],
        [-0.0028,  0.0133, -0.0032,  ..., -0.0048,  0.0101, -0.0147]],
       dtype=torch.float16), 'model.layers.30.mlp.gate_proj.weight': tensor([[-0.0422, -0.0289, -0.0057,  ...,  0.0138, -0.0067, -0.0003],
        [-0.0175,  0.0047,  0.0389,  ..., -0.0063, -0.0058,  0.0305],
        [-0.0219, -0.0067, -0.0307,  ...,  0.0154, -0.0004, -0.0035],
        ...,
        [-0.0204, -0.0261,  0.0121,  ..., -0.0081, -0.0219, -0.0244],
        [ 0.0268,  0.0282, -0.0097,  ...,  0.0118, -0.0396, -0.0025],
        [-0.0012, -0.0307, -0.0203,  ..., -0.0023,  0.0182, -0.0061]],
       dtype=torch.float16), 'model.layers.30.mlp.up_proj.weight': tensor([[ 0.0034,  0.0162,  0.0123,  ...,  0.0126,  0.0213, -0.0029],
        [-0.0196, -0.0118,  0.0388,  ...,  0.0008, -0.0193, -0.0033],
        [-0.0327, -0.0235, -0.0368,  ..., -0.0176,  0.0011,  0.0209],
        ...,
        [-0.0163, -0.0128,  0.0153,  ...,  0.0128, -0.0097, -0.0216],
        [-0.0081,  0.0077, -0.0097,  ...,  0.0053, -0.0229,  0.0164],
        [-0.0030, -0.0283,  0.0003,  ..., -0.0168,  0.0070,  0.0171]],
       dtype=torch.float16), 'model.layers.30.mlp.down_proj.weight': tensor([[ 2.2812e-02, -1.3634e-02, -3.0258e-02,  ...,  3.1342e-02,
         -7.2098e-03, -8.8263e-04],
        [ 2.5818e-02,  4.8409e-03,  4.3427e-02,  ...,  1.2611e-02,
          1.6594e-03, -7.8888e-03],
        [ 3.6883e-04, -3.0899e-03, -2.1591e-02,  ...,  3.1242e-03,
          1.0376e-02,  2.0767e-02],
        ...,
        [-3.1921e-02,  6.3400e-03, -2.4643e-02,  ...,  1.8341e-02,
         -2.4780e-02, -9.6664e-03],
        [-4.3750e-05, -1.9287e-02,  2.8934e-03,  ...,  1.9730e-02,
          2.3232e-03,  1.2312e-03],
        [-8.7738e-03, -1.4030e-02, -2.5955e-02,  ...,  1.0109e-02,
          3.0589e-04, -1.9150e-02]], dtype=torch.float16), 'model.layers.30.input_layernorm.weight': tensor([0.5859, 0.6016, 0.5664,  ..., 0.5586, 0.5781, 0.6016],
       dtype=torch.float16), 'model.layers.30.post_attention_layernorm.weight': tensor([0.4824, 0.5039, 0.4824,  ..., 0.4883, 0.4980, 0.4863],
       dtype=torch.float16), 'model.layers.31.self_attn.q_proj.weight': tensor([[-0.0350,  0.0179,  0.0228,  ...,  0.0133, -0.0005, -0.0199],
        [-0.0200, -0.0252, -0.0369,  ...,  0.0008, -0.0122, -0.0238],
        [-0.0219,  0.0272,  0.0192,  ..., -0.0004,  0.0037,  0.0022],
        ...,
        [ 0.0171, -0.0177, -0.0151,  ..., -0.0145,  0.0273, -0.0253],
        [-0.0265,  0.0056, -0.0053,  ..., -0.0029,  0.0124,  0.0107],
        [-0.0533, -0.0123,  0.0282,  ...,  0.0389, -0.0044,  0.0329]],
       dtype=torch.float16), 'model.layers.31.self_attn.k_proj.weight': tensor([[-0.0058, -0.0082,  0.0132,  ..., -0.0011, -0.0107, -0.0206],
        [ 0.0245, -0.0202,  0.0109,  ..., -0.0002,  0.0066, -0.0021],
        [ 0.0027,  0.0117, -0.0064,  ...,  0.0055, -0.0005, -0.0275],
        ...,
        [ 0.0315, -0.0261, -0.0244,  ..., -0.0081, -0.0101, -0.0515],
        [ 0.0134,  0.0200,  0.0124,  ..., -0.0259, -0.0236,  0.0204],
        [-0.0787, -0.0352,  0.0162,  ..., -0.0131,  0.0023, -0.0065]],
       dtype=torch.float16), 'model.layers.31.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0230, -0.0018,  ...,  0.0031,  0.0012,  0.0155],
        [ 0.0281,  0.0153,  0.0112,  ...,  0.0094,  0.0336,  0.0164],
        [ 0.0143, -0.0011, -0.0159,  ...,  0.0129,  0.0024,  0.0344],
        ...,
        [-0.0017, -0.0013, -0.0144,  ..., -0.0160, -0.0032,  0.0248],
        [ 0.0126, -0.0183,  0.0156,  ..., -0.0102, -0.0292,  0.0144],
        [-0.0103, -0.0228,  0.0264,  ...,  0.0243, -0.0042,  0.0403]],
       dtype=torch.float16), 'model.layers.31.self_attn.o_proj.weight': tensor([[ 0.0089,  0.0304, -0.0052,  ..., -0.0004, -0.0148, -0.0504],
        [-0.0065,  0.0034, -0.0314,  ...,  0.0269, -0.0200, -0.0146],
        [ 0.0102,  0.0023,  0.0032,  ..., -0.0174,  0.0214,  0.0120],
        ...,
        [ 0.0077, -0.0209,  0.0315,  ..., -0.0161, -0.0128, -0.0216],
        [ 0.0010,  0.0138, -0.0207,  ..., -0.0174, -0.0141, -0.0177],
        [ 0.0062,  0.0165, -0.0088,  ...,  0.0295, -0.0164,  0.0075]],
       dtype=torch.float16), 'model.layers.31.mlp.gate_proj.weight': tensor([[ 0.0088, -0.0101,  0.0378,  ...,  0.0157,  0.0179,  0.0108],
        [-0.0751, -0.0179,  0.0038,  ...,  0.0049, -0.0193,  0.0181],
        [ 0.0142,  0.0066, -0.0107,  ..., -0.0041, -0.0197, -0.0075],
        ...,
        [-0.0168, -0.0297,  0.0126,  ..., -0.0009,  0.0242,  0.0329],
        [ 0.0417,  0.0298, -0.0222,  ...,  0.0354, -0.0096, -0.0061],
        [ 0.0174, -0.0382, -0.0287,  ..., -0.0177,  0.0085,  0.0057]],
       dtype=torch.float16), 'model.layers.31.mlp.up_proj.weight': tensor([[-0.0397, -0.0182,  0.0206,  ...,  0.0010, -0.0187,  0.0024],
        [ 0.0275,  0.0354,  0.0046,  ..., -0.0228,  0.0012, -0.0013],
        [-0.0043,  0.0044, -0.0210,  ...,  0.0143,  0.0034, -0.0117],
        ...,
        [ 0.0134, -0.0182,  0.0072,  ...,  0.0026,  0.0326, -0.0186],
        [ 0.0055,  0.0044, -0.0258,  ...,  0.0280,  0.0101, -0.0022],
        [ 0.0409, -0.0411, -0.0085,  ..., -0.0104,  0.0099,  0.0237]],
       dtype=torch.float16), 'model.layers.31.mlp.down_proj.weight': tensor([[-1.2767e-04, -2.5101e-02, -9.8572e-03,  ..., -3.8147e-02,
         -1.4954e-02,  2.7756e-02],
        [ 3.8208e-02,  3.5248e-03, -3.6736e-03,  ..., -5.2691e-04,
         -1.6205e-02,  1.3901e-02],
        [-1.2566e-02, -1.2192e-02,  2.5131e-02,  ...,  3.0304e-02,
         -1.5383e-03,  2.3193e-02],
        ...,
        [ 4.7088e-05,  2.8351e-02, -2.0237e-03,  ...,  1.1597e-02,
          5.3177e-03,  1.7136e-02],
        [-9.8515e-04,  4.7424e-02, -5.3787e-03,  ..., -7.3509e-03,
          2.3331e-02,  1.7090e-02],
        [ 2.6001e-02, -3.8910e-02,  1.8829e-02,  ...,  4.1313e-03,
          1.2999e-03,  2.6016e-02]], dtype=torch.float16), 'model.layers.31.input_layernorm.weight': tensor([0.4961, 0.4980, 0.4453,  ..., 0.4375, 0.4727, 0.4922],
       dtype=torch.float16), 'model.layers.31.post_attention_layernorm.weight': tensor([0.4414, 0.4434, 0.4531,  ..., 0.4336, 0.4219, 0.4375],
       dtype=torch.float16), 'model.norm.weight': tensor([2.0000, 2.0469, 1.9453,  ..., 1.8594, 1.9453, 1.7656],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding': tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight': tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,
            2.1957e-02,  5.0011e-03],
          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,
            7.5417e-03, -1.2230e-02],
          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,
            5.3940e-03, -1.2283e-02],
          ...,
          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,
           -2.3239e-02, -2.4017e-02],
          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,
            1.5745e-03, -4.1771e-03],
          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,
            4.0169e-03, -6.7177e-03]],

         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,
            2.4185e-02,  5.8136e-03],
          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,
            5.4970e-03, -1.4351e-02],
          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,
            5.5618e-03, -1.2390e-02],
          ...,
          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,
            3.9816e-04, -5.1346e-03],
          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,
            2.2552e-02,  1.2917e-02],
          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,
            1.8158e-02,  9.2745e-04]],

         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,
            1.1757e-02,  5.7259e-03],
          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,
           -4.2191e-03, -7.1831e-03],
          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,
            1.3041e-04, -7.3051e-03],
          ...,
          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,
           -9.8267e-03, -6.7825e-03],
          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,
            6.3400e-03,  5.3177e-03],
          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,
            6.5193e-03,  2.9850e-04]]],


        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,
           -8.4381e-03,  2.0447e-02],
          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,
            3.5906e-04,  1.5945e-02],
          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,
           -2.7924e-02, -3.2177e-03],
          ...,
          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,
           -5.4741e-03, -5.9624e-03],
          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,
           -2.7969e-02, -1.8875e-02],
          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,
            7.1335e-03,  4.6478e-02]],

         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,
           -1.1604e-02,  1.7593e-02],
          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,
            3.4976e-04,  1.4732e-02],
          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,
           -3.2684e-02, -7.0076e-03],
          ...,
          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,
           -1.1253e-02, -9.8648e-03],
          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,
           -3.7231e-02, -2.6505e-02],
          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,
           -4.2000e-03,  3.9368e-02]],

         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,
           -1.2558e-02,  1.7303e-02],
          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,
            4.3440e-04,  1.5656e-02],
          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,
           -2.9968e-02, -6.5422e-03],
          ...,
          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,
           -8.7967e-03, -8.7662e-03],
          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,
           -3.0518e-02, -2.4918e-02],
          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,
           -7.3242e-04,  3.8818e-02]]],


        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,
            1.4229e-02,  1.8768e-02],
          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,
            5.4283e-03,  6.6032e-03],
          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,
            2.5959e-03,  6.8703e-03],
          ...,
          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,
            1.4397e-02,  1.2421e-02],
          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,
            2.2766e-02,  2.2659e-02],
          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,
            2.2263e-02,  2.5238e-02]],

         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,
            1.9653e-02,  2.8290e-02],
          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,
            6.0501e-03,  1.2810e-02],
          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,
           -5.9271e-04,  8.8959e-03],
          ...,
          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,
            2.4902e-02,  2.6871e-02],
          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,
            3.3569e-02,  3.9612e-02],
          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,
            3.9276e-02,  4.6051e-02]],

         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,
            2.1042e-02,  2.9053e-02],
          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,
            7.7019e-03,  1.2169e-02],
          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,
            3.3913e-03,  9.0408e-03],
          ...,
          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,
            8.0795e-03,  1.4221e-02],
          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,
            1.1887e-02,  1.8204e-02],
          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,
            1.5701e-02,  2.2247e-02]]],


        ...,


        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,
            3.1686e-04, -3.0446e-04],
          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,
           -2.2995e-04, -1.6510e-04],
          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,
           -5.0831e-04,  5.9748e-04],
          ...,
          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,
           -9.3746e-04, -6.7472e-04],
          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,
           -1.4048e-03, -1.3056e-03],
          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,
            3.2640e-04,  1.7679e-04]],

         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,
            1.0500e-03, -5.0831e-04],
          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,
            1.0071e-03, -4.9925e-04],
          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,
            8.0919e-04,  9.7132e-04],
          ...,
          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,
            6.2895e-04,  4.0889e-04],
          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,
           -2.8610e-04,  1.9038e-04],
          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,
            1.4138e-04,  4.2319e-04]],

         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,
           -4.3130e-04, -5.6791e-04],
          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,
            1.9002e-04,  1.8311e-04],
          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,
            2.3186e-05, -5.7578e-05],
          ...,
          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,
            1.3471e-04,  6.5708e-04],
          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,
            1.0538e-04, -4.9019e-04],
          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,
           -4.1580e-04,  5.5599e-04]]],


        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,
            6.1874e-03,  2.6535e-02],
          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,
           -1.7639e-02, -3.2768e-03],
          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,
           -2.7237e-02, -5.5046e-03],
          ...,
          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,
            2.8503e-02,  3.6499e-02],
          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,
           -2.3010e-02,  5.0926e-03],
          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,
           -3.9276e-02,  1.3908e-02]],

         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,
            2.8896e-03,  2.2415e-02],
          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,
           -1.8616e-02, -6.5308e-03],
          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,
           -3.0472e-02, -9.3613e-03],
          ...,
          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,
            2.6001e-02,  3.4241e-02],
          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,
           -3.0487e-02, -9.5701e-04],
          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,
           -5.1422e-02,  4.2267e-03]],

         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,
           -2.1572e-03,  1.6891e-02],
          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,
           -2.1347e-02, -9.2316e-03],
          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,
           -2.9694e-02, -1.2733e-02],
          ...,
          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,
            1.9257e-02,  2.4582e-02],
          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,
           -3.1281e-02, -9.1248e-03],
          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,
           -5.2246e-02, -2.8057e-03]]],


        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,
            8.1863e-03, -4.8248e-02],
          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,
            9.3689e-03, -3.8544e-02],
          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,
            2.3956e-02, -1.1154e-02],
          ...,
          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,
           -1.8654e-03, -1.9440e-02],
          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,
            8.4381e-03,  1.4282e-02],
          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,
            1.6689e-03,  1.6891e-02]],

         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,
            1.5839e-02, -4.3243e-02],
          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,
            1.8433e-02, -3.1799e-02],
          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,
            2.9694e-02, -5.4817e-03],
          ...,
          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,
           -1.5268e-03, -1.4626e-02],
          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,
            8.5602e-03,  2.0035e-02],
          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,
           -2.3785e-03,  1.9150e-02]],

         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,
            2.1317e-02, -3.0197e-02],
          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,
            2.4658e-02, -1.7670e-02],
          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,
            3.4302e-02,  4.5395e-03],
          ...,
          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,
            4.1656e-03, -5.9814e-03],
          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,
            1.6068e-02,  2.5879e-02],
          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,
            2.2964e-03,  2.2339e-02]]]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight': tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],
        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],
        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],
        ...,
        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],
        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],
        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight': tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias': tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight': tensor([[-1.1724e-04,  8.3399e-04, -1.5700e-04,  ..., -4.8332e-03,
          1.3428e-02,  3.2604e-05],
        [-4.4703e-05, -9.5272e-04,  1.2279e-04,  ...,  1.9855e-03,
         -1.3626e-02, -4.1783e-05],
        [ 6.6280e-04,  1.0419e-04,  9.0420e-05,  ..., -2.1820e-02,
          4.1199e-03,  3.2187e-06],
        ...,
        [-5.2512e-05, -2.9278e-04, -3.6895e-05,  ...,  8.8196e-03,
         -4.2796e-04, -3.0100e-05],
        [ 7.5936e-05, -6.5148e-05, -9.0182e-05,  ...,  8.1682e-04,
         -6.0844e-03,  1.9014e-05],
        [-6.3896e-05,  9.8705e-05,  4.9829e-05,  ..., -1.2579e-03,
         -7.1793e-03,  2.3961e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias': tensor([ 0.0577, -0.0588, -0.0266,  ..., -0.0147, -0.0175,  0.0096],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight': tensor([[ 2.4986e-04, -1.5283e-04, -5.8556e-04,  ...,  3.3607e-03,
         -9.5901e-03,  5.5373e-05],
        [-3.4356e-04, -1.5092e-04,  5.2691e-05,  ...,  2.5725e-04,
          1.0010e-02, -6.2883e-05],
        [ 6.7472e-04, -9.6798e-05,  2.5392e-04,  ..., -1.0386e-03,
         -1.9531e-02, -1.2141e-04],
        ...,
        [ 2.9850e-04,  4.0436e-04, -9.7811e-05,  ...,  4.6654e-03,
         -2.2392e-03, -6.6221e-05],
        [ 3.2973e-04, -3.2961e-05, -2.1207e-04,  ...,  1.1917e-02,
          3.4637e-03,  6.9439e-05],
        [ 2.1458e-06,  4.7874e-04,  4.8459e-05,  ..., -1.1612e-02,
          2.6779e-03, -8.3089e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias': tensor([-0.0277,  0.0222, -0.0355,  ...,  0.0123,  0.0105, -0.0041],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight': tensor([[-2.6703e-05, -1.3638e-04, -8.3923e-05,  ...,  4.2152e-03,
         -2.7649e-02, -7.5042e-05],
        [-1.6391e-04,  9.0241e-05,  5.4836e-05,  ..., -1.5821e-03,
          2.9831e-02,  7.0333e-05],
        [ 4.7588e-04,  7.6008e-04, -1.0198e-04,  ..., -1.7090e-02,
          4.1809e-02,  1.5020e-04],
        ...,
        [ 6.9141e-05,  7.0274e-05,  8.6784e-05,  ..., -4.3411e-03,
          1.1421e-02, -3.8803e-05],
        [-1.8144e-04,  1.4305e-06, -2.5940e-04,  ...,  1.5802e-03,
         -1.8799e-04,  1.6689e-05],
        [-1.2624e-04,  9.4473e-05,  5.3406e-05,  ..., -1.4961e-02,
         -5.8937e-04,  4.2021e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias': tensor([ 1.5693, -1.6172, -0.8213,  ..., -1.2852, -0.0976,  0.7852],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight': tensor([[-0.0073,  0.0083, -0.0076,  ..., -0.0090, -0.0080,  0.0038],
        [ 0.0107,  0.0062,  0.0133,  ..., -0.0036,  0.0022,  0.0034],
        [-0.0065,  0.0033,  0.0139,  ...,  0.0069,  0.0004, -0.0009],
        ...,
        [-0.0002, -0.0035, -0.0027,  ..., -0.0046, -0.0187,  0.0087],
        [-0.0093,  0.0047, -0.0083,  ...,  0.0006, -0.0013, -0.0006],
        [ 0.0092,  0.0003,  0.0016,  ...,  0.0016, -0.0045,  0.0045]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias': tensor([-0.0263, -0.0654,  0.0031,  ...,  0.1759, -0.0438,  0.0020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight': tensor([8.3113e-04, 2.9087e-03, 1.1456e-04,  ..., 6.9092e-01, 3.5498e-01,
        2.4021e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias': tensor([ 6.9141e-06,  7.7629e-04, -8.8811e-05,  ..., -3.6816e-01,
         1.7981e-01, -1.0854e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight': tensor([[ 4.2367e-04, -2.1219e-05,  5.9605e-08,  ..., -5.6458e-03,
         -1.2026e-03, -6.4087e-04],
        [ 6.1340e-03,  1.3588e-02, -3.5858e-04,  ..., -3.5954e-03,
         -7.6485e-04,  6.7101e-03],
        [ 1.3552e-03,  1.2817e-03, -2.0266e-06,  ..., -2.8351e-02,
         -1.2054e-03,  1.4830e-03],
        ...,
        [-2.4002e-02, -1.0193e-02,  2.1684e-04,  ..., -2.5864e-03,
         -1.1841e-02,  5.9166e-03],
        [ 4.1008e-04,  4.2856e-05, -1.1921e-07,  ..., -5.0697e-03,
         -7.7248e-04, -6.3896e-04],
        [-6.3753e-04, -2.3392e-02, -2.6226e-04,  ..., -4.2801e-03,
          2.7962e-03, -8.1863e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias': tensor([-0.6826, -0.3130, -0.8076,  ..., -0.2166, -0.6538, -0.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight': tensor([[-0.0037, -0.0032,  0.0043,  ...,  0.0117, -0.0042, -0.0073],
        [ 0.0017,  0.0183, -0.0100,  ..., -0.0255,  0.0024,  0.0209],
        [ 0.0033,  0.0024, -0.0029,  ...,  0.0037,  0.0032, -0.0154],
        ...,
        [ 0.0015, -0.0007, -0.0035,  ...,  0.0049,  0.0009,  0.0082],
        [-0.0060,  0.0064,  0.0067,  ..., -0.0009, -0.0061,  0.0016],
        [ 0.0007, -0.0034, -0.0020,  ..., -0.0091,  0.0009,  0.0035]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias': tensor([-0.0185, -0.1009,  0.0397,  ..., -0.0955, -0.1080, -0.0239],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight': tensor([2.8296e-01, 5.9082e-01, 1.0455e-04,  ..., 2.0195e+00, 7.7490e-01,
        2.9736e-01], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias': tensor([2.1988e-02, 2.1716e-01, 9.2089e-05,  ..., 2.6318e-01, 4.5020e-01,
        5.0903e-02], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight': tensor([[-3.9864e-03,  1.4374e-02, -2.8610e-03,  ...,  1.0399e-02,
         -2.8076e-02,  5.1155e-03],
        [ 8.1024e-03,  2.2583e-03,  1.1635e-02,  ..., -7.1716e-03,
         -7.5607e-03,  2.5375e-02],
        [ 9.5596e-03,  1.1284e-02, -3.6469e-03,  ..., -6.6757e-03,
         -1.2465e-03, -1.1475e-02],
        ...,
        [ 7.7188e-05, -1.6190e-02,  3.6583e-03,  ...,  2.1240e-02,
          4.3907e-03, -1.0063e-02],
        [ 1.5762e-02,  1.7273e-02, -3.3447e-02,  ..., -2.2507e-03,
         -1.2947e-02,  1.1726e-02],
        [-2.2697e-04,  1.2230e-02, -4.3411e-03,  ...,  3.3436e-03,
         -4.9973e-03,  5.5504e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias': tensor([-0.0012,  0.0081,  0.0097,  ...,  0.0535,  0.0071,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight': tensor([[ 0.0077,  0.0006,  0.0053,  ..., -0.0067,  0.0008,  0.0013],
        [ 0.0230, -0.0166, -0.0004,  ...,  0.0092, -0.0118, -0.0134],
        [-0.0103,  0.0013,  0.0111,  ..., -0.0549, -0.0047,  0.0056],
        ...,
        [ 0.0119,  0.0002, -0.0045,  ...,  0.0001,  0.0034, -0.0075],
        [-0.0129, -0.0114,  0.0075,  ..., -0.0030,  0.0044,  0.0061],
        [-0.0006, -0.0018,  0.0009,  ..., -0.0068, -0.0205, -0.0002]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias': tensor([ 0.0038, -0.0079, -0.1469,  ..., -0.0014, -0.0041,  0.0007],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight': tensor([[-2.4929e-03,  4.6706e-04, -1.8919e-04,  ...,  6.1684e-03,
         -2.4582e-02,  8.7051e-03],
        [ 6.5422e-03,  4.3602e-03,  1.5930e-02,  ..., -6.5994e-03,
          8.2169e-03,  6.1111e-03],
        [ 1.0727e-02, -9.2239e-03, -7.5698e-06,  ...,  3.7136e-03,
          1.6861e-02,  3.5305e-03],
        ...,
        [-2.3708e-03,  6.6452e-03,  5.9052e-03,  ..., -1.0399e-02,
          2.9945e-04, -9.6989e-04],
        [ 3.0609e-02,  1.3458e-02, -3.3386e-02,  ..., -1.3857e-03,
          3.5801e-03,  1.3245e-02],
        [-3.2291e-03,  4.7607e-03, -1.8759e-03,  ...,  6.1035e-04,
          4.9515e-03, -5.3520e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias': tensor([-0.1035,  0.8804,  1.4414,  ..., -2.2109, -0.1892,  0.0048],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight': tensor([[-0.0013, -0.0215,  0.0011,  ..., -0.0115,  0.0102, -0.0012],
        [-0.0010,  0.0065, -0.0018,  ..., -0.0036,  0.0112, -0.0025],
        [ 0.0015, -0.0069, -0.0120,  ..., -0.0047, -0.0009, -0.0056],
        ...,
        [ 0.0053, -0.0177,  0.0780,  ..., -0.0228, -0.0122,  0.0151],
        [-0.0086, -0.0019,  0.0054,  ...,  0.0081, -0.0049,  0.0067],
        [-0.0037,  0.0063, -0.0005,  ...,  0.0054,  0.0045, -0.0036]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias': tensor([-0.0204, -0.0210,  0.0255,  ..., -0.0381, -0.0211, -0.0043],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight': tensor([0.3650, 0.7476, 0.0972,  ..., 0.8521, 0.4248, 0.2639],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias': tensor([-0.0482, -0.1315,  0.0198,  ..., -0.1031, -0.0545,  0.0076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight': tensor([[ 0.0026,  0.0065,  0.0155,  ..., -0.0063,  0.0479, -0.0807],
        [ 0.0002, -0.0075,  0.0009,  ..., -0.0009, -0.0030,  0.0036],
        [ 0.0070, -0.0211,  0.0002,  ..., -0.0094,  0.0178, -0.0043],
        ...,
        [ 0.0026, -0.0113,  0.0019,  ..., -0.0057, -0.0008,  0.0038],
        [-0.0059,  0.0099,  0.0010,  ...,  0.0037, -0.0142, -0.0178],
        [ 0.0160,  0.0002,  0.0312,  ..., -0.0003, -0.0056, -0.0220]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias': tensor([-0.1216, -0.6841, -0.5278,  ..., -0.7573, -0.0995, -0.3076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight': tensor([[ 0.0008, -0.0008, -0.0176,  ..., -0.0029, -0.0098, -0.0047],
        [-0.0157,  0.0059,  0.0156,  ...,  0.0064, -0.0005, -0.0058],
        [ 0.0051, -0.0005,  0.0091,  ..., -0.0056, -0.0015,  0.0059],
        ...,
        [ 0.0030, -0.0024,  0.0040,  ...,  0.0014,  0.0002,  0.0047],
        [ 0.0007, -0.0015,  0.0031,  ..., -0.0015,  0.0046, -0.0055],
        [ 0.0299,  0.0036,  0.0020,  ...,  0.0047,  0.0134,  0.0043]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias': tensor([ 0.0244, -0.0645,  0.0788,  ..., -0.0807, -0.1028, -0.0836],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight': tensor([0.4128, 0.9854, 0.1910,  ..., 0.7715, 0.5596, 0.5142],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias': tensor([-0.0198, -0.1075, -0.0195,  ...,  0.0887,  0.1349,  0.0288],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight': tensor([[-0.0085,  0.0006, -0.0289,  ...,  0.0041,  0.0569, -0.0674],
        [-0.0052,  0.0245, -0.0213,  ..., -0.0084,  0.0220, -0.0248],
        [-0.0135, -0.0092,  0.0144,  ...,  0.0162,  0.0298, -0.0357],
        ...,
        [-0.0062,  0.0068,  0.0082,  ...,  0.0119,  0.0132, -0.0033],
        [-0.0083,  0.0247, -0.0094,  ..., -0.0040, -0.0122,  0.0142],
        [-0.0048, -0.0044, -0.0164,  ...,  0.0119, -0.0213, -0.0117]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias': tensor([ 0.0234,  0.0084, -0.0015,  ...,  0.0951,  0.0065,  0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight': tensor([[ 0.0164,  0.0053, -0.0065,  ..., -0.0008,  0.0037, -0.0120],
        [-0.0057, -0.0036, -0.0029,  ..., -0.0013,  0.0026, -0.0108],
        [-0.0081,  0.0057,  0.0067,  ...,  0.0028, -0.0068, -0.0023],
        ...,
        [-0.0249,  0.0121,  0.0107,  ...,  0.0037,  0.0007,  0.0044],
        [ 0.0115,  0.0107,  0.0118,  ...,  0.0015, -0.0038, -0.0073],
        [-0.0073,  0.0032, -0.0060,  ...,  0.0023, -0.0074,  0.0047]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias': tensor([-0.0014, -0.0060,  0.0129,  ...,  0.1081,  0.0069,  0.0455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight': tensor([[-0.0067, -0.0208, -0.0222,  ...,  0.0014,  0.0279, -0.0558],
        [-0.0030,  0.0016, -0.0191,  ...,  0.0001, -0.0169, -0.0034],
        [-0.0079, -0.0049,  0.0074,  ..., -0.0163, -0.0186, -0.0105],
        ...,
        [ 0.0002, -0.0036,  0.0084,  ..., -0.0038,  0.0105, -0.0002],
        [-0.0035, -0.0039, -0.0118,  ..., -0.0067, -0.0292,  0.0361],
        [-0.0044, -0.0008, -0.0187,  ...,  0.0014, -0.0064, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias': tensor([ 0.1927, -0.0745, -0.0890,  ...,  0.6807,  0.7334, -0.5073],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight': tensor([[-2.4796e-02,  3.3035e-03, -5.1379e-05,  ...,  2.5177e-02,
         -2.3010e-02,  1.2245e-02],
        [-2.7504e-03,  1.5330e-04, -1.1650e-02,  ..., -8.4229e-03,
         -4.1389e-03, -6.9275e-03],
        [-1.2238e-02, -7.1983e-03, -1.0323e-02,  ..., -1.6312e-02,
         -5.9547e-03, -1.4572e-03],
        ...,
        [-1.8501e-03,  5.0354e-04, -6.7101e-03,  ..., -7.3471e-03,
         -2.3518e-03, -1.8501e-03],
        [ 5.4131e-03, -4.4937e-03,  1.2329e-02,  ..., -7.1716e-04,
          9.8038e-04,  7.2708e-03],
        [ 1.0040e-02,  6.5422e-03,  9.2163e-03,  ..., -4.5815e-03,
         -1.1330e-03, -2.6169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias': tensor([ 0.0182, -0.0970,  0.0244,  ..., -0.0159, -0.0449, -0.0308],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight': tensor([0.5078, 0.3108, 0.4004,  ..., 1.4219, 0.5015, 0.3591],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias': tensor([-0.0750, -0.0109,  0.0618,  ..., -0.0417,  0.0176, -0.0477],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight': tensor([[-0.0066, -0.0264,  0.0131,  ..., -0.0004,  0.0194, -0.0154],
        [ 0.0097,  0.0090, -0.0017,  ...,  0.0023, -0.0030,  0.0246],
        [-0.0057,  0.0093,  0.0011,  ..., -0.0040,  0.0003,  0.0128],
        ...,
        [ 0.0005, -0.0012, -0.0009,  ...,  0.0011, -0.0034, -0.0059],
        [ 0.0002,  0.0115,  0.0158,  ...,  0.0040,  0.0015,  0.0208],
        [-0.0148,  0.0111, -0.0085,  ...,  0.0049, -0.0076, -0.0022]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias': tensor([-0.2452, -0.3076, -0.4565,  ..., -0.1678, -0.2119, -0.5581],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight': tensor([[ 1.3428e-03, -3.5172e-03,  9.3317e-04,  ..., -5.0354e-03,
          4.3907e-03,  2.0161e-03],
        [ 1.2999e-03, -1.6678e-02, -4.5662e-03,  ..., -4.4584e-04,
          1.3359e-02, -3.9558e-03],
        [-1.8829e-02,  5.2261e-03,  4.7760e-03,  ...,  8.3113e-04,
         -1.8860e-02,  1.0452e-03],
        ...,
        [-7.8201e-03,  8.4305e-04, -2.1601e-04,  ..., -5.6207e-05,
          4.8339e-05,  1.7557e-03],
        [-4.5300e-05, -7.9498e-03, -9.6178e-04,  ...,  3.4180e-03,
         -1.0208e-02,  2.4460e-02],
        [ 6.0883e-03,  3.3398e-03, -3.7789e-04,  ...,  1.5259e-02,
          6.6223e-03,  6.8169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias': tensor([ 0.0453, -0.0798, -0.0027,  ..., -0.0154, -0.1379, -0.0307],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight': tensor([0.6362, 0.5508, 0.3787,  ..., 1.3506, 0.4011, 0.4910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias': tensor([-0.0338, -0.0840, -0.0964,  ..., -0.0491,  0.0855, -0.2158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight': tensor([[ 0.0149, -0.0155, -0.0083,  ...,  0.0066,  0.0086, -0.0173],
        [ 0.0067,  0.0134,  0.0050,  ..., -0.0056, -0.0293, -0.0028],
        [ 0.0041, -0.0027, -0.0011,  ...,  0.0060,  0.0020, -0.0035],
        ...,
        [ 0.0110, -0.0188,  0.0174,  ..., -0.0223,  0.0017, -0.0122],
        [ 0.0165, -0.0201, -0.0204,  ..., -0.0262, -0.0232, -0.0039],
        [ 0.0062, -0.0148,  0.0194,  ...,  0.0090, -0.0007, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias': tensor([-0.0385, -0.0122,  0.0262,  ...,  0.1536,  0.0992, -0.0590],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight': tensor([[ 0.0275, -0.0126, -0.0067,  ...,  0.0002,  0.0201,  0.0163],
        [-0.0074,  0.0475,  0.0058,  ..., -0.0040,  0.0014,  0.0004],
        [-0.0100, -0.0039, -0.0155,  ...,  0.0009, -0.0079,  0.0033],
        ...,
        [ 0.0009,  0.0007,  0.0107,  ...,  0.0007,  0.0007, -0.0059],
        [-0.0008,  0.0147,  0.0066,  ...,  0.0022, -0.0062, -0.0033],
        [-0.0195, -0.0065,  0.0118,  ..., -0.0030,  0.0058,  0.0028]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias': tensor([ 0.0095, -0.0516,  0.0111,  ..., -0.0145,  0.0041,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight': tensor([[ 2.7618e-02,  1.0513e-02,  4.2725e-03,  ...,  6.3095e-03,
         -8.5907e-03, -1.3008e-02],
        [ 2.4605e-03,  1.8875e-02, -3.9787e-03,  ..., -5.7335e-03,
         -2.1698e-02,  5.3406e-03],
        [-5.1880e-04, -1.0147e-02, -1.0471e-03,  ...,  1.0002e-02,
          1.0025e-02, -1.6159e-02],
        ...,
        [ 1.4210e-03, -1.6434e-02,  5.2299e-03,  ..., -1.5053e-02,
          1.1284e-02,  1.2054e-03],
        [ 1.5579e-02,  1.5251e-02, -3.5915e-03,  ..., -2.6520e-02,
         -1.4130e-02, -7.7133e-03],
        [ 1.0399e-02, -2.2491e-02,  3.2783e-06,  ...,  8.3542e-03,
         -6.7215e-03,  1.6525e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias': tensor([-0.1852, -0.5479, -0.1450,  ..., -0.9072, -0.3499, -0.3457],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight': tensor([[-2.1683e-02,  2.3556e-03, -1.9245e-03,  ..., -9.4910e-03,
          1.6251e-02,  1.2527e-02],
        [ 6.4430e-03, -3.8055e-02, -3.1567e-03,  ..., -2.6455e-03,
         -2.1515e-02,  1.1864e-02],
        [ 5.2147e-03, -8.5602e-03,  1.5732e-02,  ..., -1.2611e-02,
          7.3395e-03, -1.2505e-02],
        ...,
        [-1.1325e-04,  3.4676e-03, -1.1169e-02,  ..., -1.0071e-02,
         -5.4538e-05, -1.7357e-03],
        [-6.8245e-03, -1.0139e-02,  1.4579e-04,  ...,  2.0309e-02,
          1.3527e-02, -3.0098e-03],
        [-1.7868e-02,  6.0368e-04, -6.7101e-03,  ...,  6.6853e-04,
         -3.0327e-03,  3.0651e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias': tensor([-0.0147, -0.0586,  0.0197,  ...,  0.0204, -0.1210,  0.0171],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight': tensor([0.7456, 0.3557, 0.6133,  ..., 2.2637, 0.5059, 0.3938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias': tensor([-0.0006,  0.0249,  0.0189,  ..., -0.1539, -0.0345,  0.0151],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight': tensor([[ 0.0034,  0.0025,  0.0007,  ..., -0.0021, -0.0065,  0.0058],
        [ 0.0011, -0.0024, -0.0028,  ..., -0.0094, -0.0078, -0.0065],
        [-0.0051, -0.0246, -0.0075,  ..., -0.0073,  0.0121,  0.0036],
        ...,
        [ 0.0077,  0.0038, -0.0011,  ..., -0.0060, -0.0017,  0.0005],
        [-0.0208, -0.0176, -0.0064,  ..., -0.0076, -0.0137, -0.0056],
        [-0.0240,  0.0082, -0.0047,  ..., -0.0105, -0.0069, -0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias': tensor([-0.0952, -0.1888, -0.1597,  ..., -0.2030, -0.3225, -0.3745],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight': tensor([[ 0.0074, -0.0074,  0.0041,  ...,  0.0181,  0.0235,  0.0145],
        [ 0.0106,  0.0015, -0.0078,  ..., -0.0323, -0.0017,  0.0073],
        [-0.0059, -0.0090, -0.0087,  ...,  0.0023,  0.0091,  0.0240],
        ...,
        [ 0.0054,  0.0013, -0.0012,  ..., -0.0047, -0.0021, -0.0053],
        [-0.0028,  0.0165,  0.0051,  ...,  0.0006, -0.0043, -0.0041],
        [-0.0045,  0.0066,  0.0154,  ..., -0.0027,  0.0146, -0.0076]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias': tensor([ 0.0139, -0.0796,  0.0050,  ...,  0.0715, -0.1787,  0.0414],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight': tensor([0.9761, 0.5317, 0.6523,  ..., 0.0116, 0.5054, 0.5391],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias': tensor([ 0.0585,  0.0282,  0.0207,  ...,  0.3896, -0.0784, -0.1201],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight': tensor([[ 2.0187e-02,  9.6970e-03,  1.7242e-02,  ..., -2.5925e-02,
         -1.5945e-02,  6.4671e-05],
        [ 1.0201e-02, -7.3357e-03,  3.3722e-02,  ...,  8.9111e-03,
         -3.2410e-02,  5.5122e-03],
        [ 9.6817e-03, -2.4231e-02,  5.7907e-03,  ...,  4.0955e-02,
          2.2415e-02, -1.8143e-02],
        ...,
        [-2.4857e-02, -2.5803e-02, -3.2673e-03,  ..., -1.3596e-02,
          3.6240e-03, -5.7650e-04],
        [-6.4754e-04,  2.4719e-02, -3.0411e-02,  ..., -1.3008e-02,
          5.0879e-04, -1.9455e-02],
        [ 1.7380e-02, -2.3804e-02,  1.2428e-02,  ..., -4.4670e-03,
         -4.2297e-02,  9.2545e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias': tensor([-0.0362, -0.0177,  0.0258,  ...,  0.0230,  0.0147,  0.0451],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight': tensor([[-0.0050,  0.0089,  0.0017,  ..., -0.0001, -0.0173, -0.0087],
        [ 0.0064, -0.0170,  0.0071,  ..., -0.0039,  0.0387, -0.0100],
        [-0.0151,  0.0005, -0.0012,  ..., -0.0011, -0.0048,  0.0012],
        ...,
        [ 0.0129, -0.0303, -0.0177,  ...,  0.0005,  0.0013,  0.0006],
        [ 0.0157,  0.0140, -0.0101,  ...,  0.0011,  0.0336, -0.0216],
        [ 0.0171, -0.0183, -0.0061,  ...,  0.0016, -0.0197, -0.0110]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias': tensor([ 0.0241, -0.0481, -0.0028,  ...,  0.0268,  0.0064, -0.0023],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight': tensor([[ 0.0075,  0.0013, -0.0144,  ..., -0.0114, -0.0454, -0.0086],
        [-0.0035, -0.0501,  0.0037,  ..., -0.0065, -0.0287,  0.0070],
        [ 0.0061, -0.0005,  0.0146,  ...,  0.0271,  0.0069, -0.0366],
        ...,
        [-0.0107,  0.0089, -0.0109,  ..., -0.0074, -0.0206, -0.0009],
        [-0.0004, -0.0072, -0.0339,  ..., -0.0124, -0.0053, -0.0094],
        [ 0.0051, -0.0136, -0.0062,  ..., -0.0015, -0.0242, -0.0031]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias': tensor([-0.4634, -0.0086,  0.2761,  ..., -0.2158, -0.2346, -0.2240],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight': tensor([[-2.6817e-03, -4.3983e-03,  1.3580e-03,  ..., -2.4681e-03,
         -1.6296e-02, -1.9119e-02],
        [-6.3057e-03,  1.3931e-02,  2.0657e-03,  ...,  2.4063e-02,
         -2.3544e-02,  2.3361e-02],
        [ 4.4098e-03,  2.9049e-03,  3.0816e-05,  ...,  1.9028e-02,
          1.2093e-02,  9.4528e-03],
        ...,
        [-6.3095e-03,  7.6141e-03, -4.4861e-03,  ..., -6.6261e-03,
         -6.6795e-03, -3.0851e-04],
        [ 1.7075e-02, -3.9612e-02,  9.1248e-03,  ...,  1.1742e-02,
         -3.6469e-02,  2.8046e-02],
        [ 8.2626e-03,  1.3752e-03, -1.0185e-02,  ...,  6.5994e-04,
          1.5320e-02,  1.1871e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias': tensor([ 0.0089, -0.0782,  0.0222,  ..., -0.0115, -0.1763,  0.0233],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight': tensor([0.7534, 0.5015, 0.7891,  ..., 1.1660, 0.6074, 0.5796],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias': tensor([ 0.0149, -0.0122,  0.0052,  ..., -0.1028,  0.0337, -0.0357],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight': tensor([[ 0.0072, -0.0114, -0.0013,  ..., -0.0066,  0.0127,  0.0151],
        [-0.0095,  0.0185,  0.0141,  ..., -0.0075,  0.0141,  0.0101],
        [-0.0018,  0.0118,  0.0032,  ..., -0.0046,  0.0148,  0.0008],
        ...,
        [ 0.0204,  0.0075,  0.0235,  ..., -0.0079,  0.0030, -0.0164],
        [ 0.0157, -0.0033, -0.0008,  ..., -0.0085,  0.0043, -0.0139],
        [-0.0009, -0.0003,  0.0257,  ..., -0.0072, -0.0059, -0.0217]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias': tensor([-0.2440, -0.3796, -0.5205,  ..., -0.2163, -0.4248, -0.2197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight': tensor([[-1.6296e-02,  6.4087e-03, -1.4839e-03,  ..., -2.2827e-02,
          1.9302e-02,  1.6346e-03],
        [ 5.0888e-03, -1.3763e-02,  5.1537e-03,  ..., -1.9989e-02,
         -2.7637e-03, -1.0567e-02],
        [ 2.8763e-03, -5.1460e-03, -5.6326e-05,  ..., -7.1030e-03,
         -9.8724e-03, -2.3098e-03],
        ...,
        [-5.3024e-03, -2.0905e-03,  2.9635e-04,  ..., -5.4092e-03,
          2.0993e-04,  2.4395e-03],
        [-9.9411e-03, -1.4748e-02, -2.4283e-04,  ...,  1.8127e-02,
          3.3779e-03,  2.1927e-02],
        [-5.7182e-03,  1.5316e-03,  1.1997e-03,  ...,  2.5387e-03,
         -5.6725e-03,  4.6387e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias': tensor([-0.0155, -0.0524, -0.0402,  ...,  0.1025, -0.1437, -0.0174],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight': tensor([1.1230, 0.5190, 1.0762,  ..., 0.0112, 0.6738, 0.7544],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias': tensor([ 0.0829, -0.0929, -0.0049,  ...,  0.1129, -0.0392, -0.0677],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight': tensor([[ 0.0035, -0.0081,  0.0270,  ..., -0.0032,  0.0041,  0.0172],
        [-0.0174,  0.0256,  0.0060,  ..., -0.0001,  0.0052, -0.0038],
        [ 0.0038,  0.0144, -0.0161,  ..., -0.0028,  0.0033,  0.0003],
        ...,
        [-0.0023, -0.0123, -0.0080,  ...,  0.0256,  0.0213, -0.0097],
        [-0.0147,  0.0030,  0.0045,  ...,  0.0211,  0.0161, -0.0218],
        [-0.0035,  0.0147,  0.0030,  ..., -0.0244, -0.0005, -0.0255]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias': tensor([-0.0187, -0.0076,  0.0053,  ...,  0.0369,  0.0955,  0.0978],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight': tensor([[-0.0090,  0.0047, -0.0008,  ..., -0.0064, -0.0025, -0.0247],
        [-0.0128, -0.0091,  0.0087,  ...,  0.0024, -0.0012,  0.0007],
        [ 0.0101, -0.0021, -0.0005,  ...,  0.0017,  0.0007, -0.0170],
        ...,
        [-0.0120,  0.0108,  0.0011,  ..., -0.0008, -0.0032,  0.0003],
        [-0.0157, -0.0033,  0.0135,  ..., -0.0007, -0.0310, -0.0129],
        [ 0.0124, -0.0001,  0.0213,  ..., -0.0014, -0.0043, -0.0239]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias': tensor([-0.0186, -0.0071, -0.0258,  ..., -0.0043, -0.0113, -0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight': tensor([[-1.7075e-02,  3.0457e-02,  8.3542e-03,  ..., -8.0032e-03,
          1.6724e-02, -1.0490e-02],
        [-1.2169e-02,  8.2474e-03, -4.2725e-03,  ..., -9.4366e-04,
         -4.9591e-03, -1.0300e-02],
        [ 1.0185e-03, -1.2466e-02, -3.0880e-03,  ..., -3.4428e-03,
         -1.3107e-02,  6.5384e-03],
        ...,
        [ 1.5793e-02,  2.0809e-03,  1.9424e-02,  ...,  2.6367e-02,
          1.0529e-02, -2.1439e-02],
        [-5.6992e-03,  4.1580e-04,  3.8116e-02,  ...,  1.6739e-02,
         -9.0103e-03, -1.6327e-02],
        [ 2.8789e-05, -9.8114e-03,  1.0004e-03,  ..., -2.2293e-02,
         -3.0365e-02,  6.1569e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias': tensor([-0.0072, -1.4619,  0.3447,  ..., -0.6147, -0.3474, -0.6455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight': tensor([[ 5.2567e-03,  1.1238e-02, -6.8092e-03,  ..., -8.0013e-04,
          1.5930e-02, -1.4336e-02],
        [-6.6223e-03,  1.9255e-03, -1.6006e-02,  ..., -2.0706e-02,
         -1.1848e-02, -1.1147e-02],
        [ 2.3087e-02,  1.1986e-02, -1.7288e-02,  ...,  5.7144e-03,
          1.4824e-02, -1.6876e-02],
        ...,
        [ 1.6647e-02,  5.3596e-03, -1.5154e-03,  ..., -2.9736e-03,
          1.8129e-03,  1.0559e-02],
        [ 4.1847e-03,  8.3694e-03,  1.2535e-02,  ..., -1.0323e-02,
          1.6327e-02, -3.2544e-05],
        [ 1.0185e-03, -2.1400e-03, -4.4098e-03,  ..., -4.6120e-03,
          6.0921e-03,  1.5152e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias': tensor([-0.0087, -0.0482, -0.0096,  ..., -0.0479, -0.1366,  0.0062],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight': tensor([0.8506, 0.6484, 0.8960,  ..., 1.2539, 0.7212, 0.8564],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias': tensor([-0.0077,  0.0670, -0.0532,  ..., -0.1699, -0.0490,  0.0434],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight': tensor([[ 0.0058,  0.0115,  0.0089,  ..., -0.0020, -0.0053,  0.0026],
        [-0.0017, -0.0024,  0.0162,  ...,  0.0009, -0.0208, -0.0094],
        [-0.0388, -0.0012, -0.0004,  ...,  0.0032, -0.0029, -0.0226],
        ...,
        [ 0.0085,  0.0130,  0.0209,  ..., -0.0057, -0.0040, -0.0012],
        [ 0.0260,  0.0055,  0.0095,  ..., -0.0008,  0.0056, -0.0098],
        [ 0.0116,  0.0073, -0.0117,  ...,  0.0011, -0.0095, -0.0163]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias': tensor([-0.4192, -0.2394, -0.3069,  ..., -0.3667, -0.2563, -0.1315],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight': tensor([[ 0.0154, -0.0020, -0.0083,  ...,  0.0161, -0.0060,  0.0146],
        [ 0.0042,  0.0226,  0.0055,  ...,  0.0110,  0.0033,  0.0034],
        [ 0.0140, -0.0083,  0.0006,  ...,  0.0085,  0.0010,  0.0007],
        ...,
        [-0.0025, -0.0010, -0.0020,  ...,  0.0007, -0.0030, -0.0018],
        [-0.0141, -0.0032, -0.0003,  ...,  0.0106, -0.0021, -0.0400],
        [ 0.0069,  0.0051, -0.0135,  ..., -0.0115,  0.0067, -0.0104]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias': tensor([-0.0416,  0.0127, -0.0229,  ...,  0.0723, -0.0145, -0.0363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight': tensor([1.1514, 0.7275, 1.1299,  ..., 1.0918, 0.8794, 1.1055],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias': tensor([ 0.0418, -0.1718, -0.0305,  ...,  0.0424, -0.2144, -0.0068],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight': tensor([[ 0.0195, -0.0016, -0.0010,  ...,  0.1302, -0.0123, -0.0063],
        [-0.0176,  0.0024, -0.0196,  ..., -0.1481, -0.0101, -0.0231],
        [-0.0042, -0.0077,  0.0033,  ...,  0.0850, -0.0172,  0.0256],
        ...,
        [ 0.0024, -0.0123,  0.0282,  ..., -0.0123,  0.0272,  0.0247],
        [ 0.0084, -0.0235,  0.0189,  ...,  0.0040, -0.0171,  0.0120],
        [ 0.0308, -0.0003,  0.0095,  ..., -0.0054, -0.0117, -0.0379]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias': tensor([-0.0049,  0.0073,  0.0145,  ...,  0.0185, -0.0033,  0.0204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight': tensor([[ 0.0096,  0.0166, -0.0025,  ..., -0.0005,  0.0005,  0.0034],
        [ 0.0066,  0.0109, -0.0074,  ...,  0.0010,  0.0079, -0.0095],
        [-0.0074, -0.0047,  0.0016,  ...,  0.0002,  0.0039,  0.0040],
        ...,
        [-0.0159,  0.0166, -0.0176,  ...,  0.0020, -0.0064,  0.0302],
        [ 0.0316, -0.0076, -0.0238,  ..., -0.0002, -0.0032, -0.0157],
        [-0.0096, -0.0192,  0.0207,  ..., -0.0009, -0.0289, -0.0082]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias': tensor([ 0.0264, -0.0288,  0.0074,  ...,  0.0075, -0.0047,  0.0190],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight': tensor([[ 0.0136, -0.0235, -0.0059,  ...,  0.0935,  0.0115, -0.0124],
        [-0.0146, -0.0224,  0.0003,  ..., -0.1112, -0.0056, -0.0134],
        [-0.0018,  0.0100,  0.0052,  ...,  0.0525,  0.0120,  0.0163],
        ...,
        [ 0.0338,  0.0004,  0.0047,  ..., -0.0146,  0.0189, -0.0173],
        [ 0.0022, -0.0096, -0.0040,  ...,  0.0011, -0.0013,  0.0135],
        [ 0.0178,  0.0135,  0.0019,  ..., -0.0075,  0.0044, -0.0363]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias': tensor([ 0.2430,  0.3418, -0.1379,  ...,  0.0247,  1.4775,  0.2130],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight': tensor([[-0.0026,  0.0052,  0.0064,  ...,  0.0172, -0.0226,  0.0066],
        [-0.0029,  0.0043, -0.0091,  ..., -0.0054, -0.0009,  0.0137],
        [-0.0161,  0.0021,  0.0049,  ...,  0.0088,  0.0251, -0.0076],
        ...,
        [ 0.0092,  0.0003, -0.0009,  ..., -0.0040,  0.0036,  0.0044],
        [ 0.0016, -0.0087,  0.0108,  ..., -0.0028, -0.0046,  0.0207],
        [ 0.0181, -0.0077, -0.0030,  ..., -0.0368, -0.0015,  0.0158]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias': tensor([-0.0217,  0.0017,  0.0176,  ...,  0.0564, -0.0415, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight': tensor([0.8926, 0.8076, 1.0293,  ..., 2.0488, 0.9590, 0.9756],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias': tensor([-0.1279, -0.0777, -0.0509,  ..., -0.2275, -0.0558,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight': tensor([[ 0.0265,  0.0048,  0.0027,  ..., -0.0071,  0.0051,  0.0187],
        [ 0.0004,  0.0177,  0.0098,  ..., -0.0020, -0.0084,  0.0181],
        [-0.0045,  0.0070, -0.0007,  ..., -0.0080, -0.0070, -0.0316],
        ...,
        [-0.0285,  0.0282,  0.0047,  ...,  0.0006, -0.0079,  0.0194],
        [-0.0049, -0.0312, -0.0060,  ..., -0.0043,  0.0310, -0.0003],
        [ 0.0185,  0.0199,  0.0079,  ..., -0.0067, -0.0297, -0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias': tensor([-0.1132, -0.1494, -0.4023,  ..., -0.2355, -0.3335, -0.2045],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight': tensor([[-0.0180,  0.0037,  0.0069,  ..., -0.0019, -0.0086, -0.0024],
        [-0.0006, -0.0030, -0.0042,  ..., -0.0177,  0.0375, -0.0014],
        [-0.0129, -0.0050, -0.0065,  ...,  0.0015, -0.0005, -0.0149],
        ...,
        [ 0.0031,  0.0014, -0.0087,  ..., -0.0003,  0.0073,  0.0014],
        [ 0.0105,  0.0060,  0.0064,  ..., -0.0005, -0.0007,  0.0372],
        [-0.0087, -0.0052,  0.0026,  ..., -0.0113, -0.0085,  0.0098]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias': tensor([-0.0068,  0.0179, -0.0552,  ...,  0.1210, -0.0750, -0.1090],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight': tensor([1.1914, 0.9712, 1.2656,  ..., 0.1719, 0.9092, 1.1973],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias': tensor([-0.0956, -0.1851, -0.0547,  ...,  0.2583, -0.0542,  0.0387],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight': tensor([[ 0.0076, -0.0117, -0.0114,  ...,  0.0770, -0.0048, -0.0017],
        [-0.0195, -0.0001, -0.0053,  ...,  0.0370, -0.0298,  0.0023],
        [-0.0094, -0.0034,  0.0132,  ...,  0.0014,  0.0088, -0.0013],
        ...,
        [ 0.0047, -0.0200, -0.0213,  ..., -0.0028, -0.0125, -0.0193],
        [-0.0028,  0.0018, -0.0313,  ..., -0.0143, -0.0024,  0.0085],
        [-0.0081, -0.0074,  0.0052,  ..., -0.0006, -0.0049, -0.0085]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias': tensor([ 0.0311, -0.0070, -0.0134,  ...,  0.0024, -0.0121, -0.0230],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight': tensor([[ 0.0104, -0.0064, -0.0062,  ...,  0.0015,  0.0052, -0.0058],
        [ 0.0179, -0.0065, -0.0221,  ..., -0.0002, -0.0032, -0.0219],
        [-0.0078,  0.0084, -0.0027,  ..., -0.0003,  0.0120,  0.0011],
        ...,
        [-0.0272, -0.0105,  0.0010,  ..., -0.0082,  0.0024,  0.0062],
        [ 0.0284, -0.0029, -0.0178,  ..., -0.0007, -0.0008, -0.0054],
        [-0.0113,  0.0083,  0.0034,  ..., -0.0102,  0.0250,  0.0115]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias': tensor([ 0.0282,  0.0175, -0.0284,  ...,  0.0397, -0.0209, -0.1344],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight': tensor([[ 0.0094, -0.0159, -0.0203,  ...,  0.0367, -0.0055, -0.0276],
        [ 0.0029, -0.0178, -0.0045,  ..., -0.0709, -0.0047, -0.0184],
        [-0.0128,  0.0083,  0.0116,  ..., -0.0014,  0.0039,  0.0124],
        ...,
        [-0.0292,  0.0131, -0.0025,  ...,  0.0003, -0.0127, -0.0156],
        [-0.0237,  0.0121, -0.0025,  ..., -0.0010,  0.0081, -0.0145],
        [ 0.0137,  0.0139,  0.0163,  ...,  0.0071,  0.0116, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias': tensor([-1.8535,  0.1802,  2.3398,  ..., -0.0595, -0.0338,  0.0305],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight': tensor([[ 0.0028, -0.0249,  0.0077,  ...,  0.0163, -0.0069, -0.0036],
        [ 0.0140, -0.0086,  0.0026,  ...,  0.0077,  0.0073, -0.0239],
        [ 0.0044,  0.0041, -0.0237,  ..., -0.0202, -0.0074,  0.0211],
        ...,
        [-0.0025,  0.0102, -0.0030,  ...,  0.0096,  0.0018,  0.0186],
        [ 0.0052, -0.0034,  0.0046,  ..., -0.0001,  0.0089, -0.0238],
        [-0.0090,  0.0134,  0.0052,  ..., -0.0156, -0.0131,  0.0157]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias': tensor([ 0.0039,  0.0259, -0.0086,  ..., -0.0503, -0.0064, -0.0460],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight': tensor([1.1934, 1.1006, 1.2510,  ..., 1.4092, 1.1592, 1.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias': tensor([ 0.0223, -0.0916,  0.0971,  ..., -0.2983, -0.0408,  0.0070],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight': tensor([[-0.0150,  0.0078,  0.0025,  ..., -0.0011, -0.0016,  0.0092],
        [-0.0219,  0.0313,  0.0128,  ...,  0.0032,  0.0150,  0.0033],
        [-0.0176, -0.0190,  0.0216,  ...,  0.0038, -0.0361,  0.0145],
        ...,
        [ 0.0060, -0.0061, -0.0066,  ...,  0.0027, -0.0050, -0.0172],
        [-0.0283, -0.0057,  0.0115,  ..., -0.0054, -0.0136, -0.0057],
        [-0.0160,  0.0153, -0.0277,  ..., -0.0289, -0.0194,  0.0007]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias': tensor([-0.1221, -0.2144, -0.4114,  ..., -0.1118, -0.1782, -0.3628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight': tensor([[-0.0016,  0.0125, -0.0344,  ..., -0.0221,  0.0044, -0.0154],
        [-0.0039, -0.0351,  0.0205,  ...,  0.0108, -0.0206, -0.0023],
        [ 0.0063, -0.0273, -0.0012,  ...,  0.0131,  0.0057, -0.0150],
        ...,
        [-0.0002, -0.0069,  0.0022,  ..., -0.0065,  0.0032,  0.0088],
        [ 0.0108, -0.0061, -0.0134,  ..., -0.0061,  0.0058, -0.0083],
        [ 0.0133,  0.0173,  0.0049,  ...,  0.0188, -0.0199, -0.0074]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias': tensor([-0.0200,  0.0232, -0.0657,  ...,  0.1028, -0.0782, -0.1134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight': tensor([1.2578, 1.1084, 1.2061,  ..., 0.5884, 1.0264, 1.2910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias': tensor([-0.0061, -0.0651,  0.0878,  ...,  0.1716,  0.1021, -0.0355],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight': tensor([[-0.0184, -0.0017,  0.0284,  ..., -0.0922, -0.0121,  0.0085],
        [ 0.0216,  0.0109,  0.0091,  ..., -0.0531,  0.0165, -0.0052],
        [-0.0036,  0.0282,  0.0128,  ...,  0.0421, -0.0305, -0.0203],
        ...,
        [-0.0003, -0.0044, -0.0082,  ..., -0.0171,  0.0052,  0.0071],
        [ 0.0136, -0.0294, -0.0073,  ..., -0.0191, -0.0179,  0.0170],
        [-0.0079,  0.0298, -0.0092,  ...,  0.0071,  0.0015,  0.0033]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias': tensor([-0.0044, -0.0038, -0.0472,  ...,  0.0818,  0.0363, -0.0465],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight': tensor([[ 1.9028e-02,  3.3264e-03, -1.4641e-02,  ..., -4.6754e-04,
         -1.4366e-02,  1.6556e-02],
        [ 2.1267e-04, -1.5457e-02, -3.2166e-02,  ..., -2.4629e-04,
          5.9090e-03, -9.8267e-03],
        [-1.2535e-02, -1.2222e-02,  9.6970e-03,  ...,  1.7128e-03,
         -2.1992e-03,  3.7842e-03],
        ...,
        [ 1.0918e-02,  1.8097e-02,  1.2695e-02,  ...,  4.8494e-04,
          5.1918e-03, -1.9058e-02],
        [ 9.9792e-03, -1.2085e-02,  6.0320e-04,  ...,  3.4790e-03,
          1.0284e-02,  2.8300e-04],
        [ 2.2034e-02, -1.5373e-03, -2.1362e-02,  ...,  4.9706e-03,
         -4.9174e-05, -6.5117e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias': tensor([ 0.0094,  0.0439, -0.0031,  ..., -0.0485, -0.1193,  0.0170],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight': tensor([[-1.2352e-02,  2.3239e-02,  5.5618e-03,  ..., -5.1178e-02,
         -2.8687e-02,  2.2531e-05],
        [-1.0605e-02, -2.5497e-02,  1.1894e-02,  ..., -2.0462e-02,
         -8.5449e-04,  4.6265e-02],
        [ 8.6212e-03, -9.3765e-03,  5.9357e-03,  ...,  2.0432e-02,
         -2.2537e-02,  4.4495e-02],
        ...,
        [ 1.3062e-02, -5.5428e-03,  1.0025e-02,  ..., -4.5746e-02,
          6.3477e-03,  2.0248e-02],
        [ 9.6588e-03, -1.4442e-02, -2.0096e-02,  ...,  6.9542e-03,
          5.9013e-03, -3.3588e-03],
        [-5.3177e-03,  2.2705e-02, -2.1713e-02,  ...,  2.4307e-02,
          1.5465e-02, -8.3237e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias': tensor([ 0.0542, -0.0733,  0.2440,  ..., -0.3313, -0.1129,  0.1049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight': tensor([[-0.0227,  0.0130, -0.0113,  ..., -0.0045,  0.0108, -0.0190],
        [-0.0057, -0.0069,  0.0119,  ..., -0.0068,  0.0143,  0.0030],
        [ 0.0062,  0.0204,  0.0161,  ..., -0.0079, -0.0057,  0.0308],
        ...,
        [ 0.0001,  0.0003,  0.0048,  ...,  0.0089, -0.0032,  0.0210],
        [-0.0079,  0.0007,  0.0030,  ...,  0.0093, -0.0068, -0.0121],
        [-0.0154,  0.0158, -0.0231,  ..., -0.0158,  0.0141, -0.0072]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias': tensor([-0.0179,  0.0685, -0.0152,  ..., -0.0815,  0.0257,  0.0175],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight': tensor([1.1738, 1.1582, 1.1592,  ..., 1.5869, 1.1748, 1.2314],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias': tensor([-0.0068,  0.0917, -0.0354,  ..., -0.3271, -0.1141, -0.0543],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight': tensor([[-0.0195, -0.0128, -0.0054,  ..., -0.0029, -0.0047,  0.0116],
        [-0.0031, -0.0199,  0.0011,  ..., -0.0044,  0.0127,  0.0019],
        [ 0.0130, -0.0056,  0.0037,  ..., -0.0005,  0.0237,  0.0081],
        ...,
        [ 0.0115,  0.0130, -0.0272,  ...,  0.0021,  0.0227,  0.0057],
        [-0.0035,  0.0108, -0.0211,  ..., -0.0011,  0.0154, -0.0001],
        [-0.0336,  0.0183,  0.0121,  ..., -0.0012, -0.0093,  0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias': tensor([-0.3628, -0.2211, -0.1648,  ..., -0.2524, -0.2686, -0.2517],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight': tensor([[-4.5166e-03,  7.6828e-03,  1.3664e-02,  ..., -2.5959e-03,
         -2.0126e-02, -7.1602e-03],
        [-1.4015e-02,  2.0084e-03,  6.2370e-03,  ...,  1.9714e-02,
         -4.8294e-03, -2.3682e-02],
        [-4.3793e-03,  6.3400e-03,  5.3253e-03,  ...,  9.2888e-04,
          7.6599e-03, -1.8555e-02],
        ...,
        [-4.1809e-03, -1.8768e-03,  4.0741e-03,  ..., -1.5802e-03,
         -3.6144e-03,  8.3983e-05],
        [-2.7523e-03, -2.6489e-02, -1.3283e-02,  ...,  3.4904e-03,
         -1.4786e-02,  6.2981e-03],
        [-3.0880e-03, -2.1713e-02, -1.7853e-02,  ...,  1.1139e-02,
          7.2784e-03, -1.2558e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias': tensor([-0.0283,  0.0284, -0.0329,  ...,  0.0671, -0.0050, -0.0488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight': tensor([1.2725, 1.2539, 1.2041,  ..., 0.7529, 1.0645, 1.2422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias': tensor([ 0.0019, -0.0140,  0.0246,  ...,  0.2150, -0.1251, -0.2118],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0117,  0.0046,  ..., -0.0265, -0.0033,  0.0070],
        [ 0.0061,  0.0207, -0.0110,  ...,  0.0132,  0.0091,  0.0226],
        [-0.0012,  0.0130,  0.0031,  ...,  0.0025,  0.0157,  0.0028],
        ...,
        [ 0.0178,  0.0099,  0.0200,  ...,  0.0006, -0.0303, -0.0324],
        [-0.0035,  0.0138,  0.0245,  ..., -0.0032, -0.0065,  0.0055],
        [-0.0023,  0.0024, -0.0018,  ...,  0.0053,  0.0023, -0.0070]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias': tensor([ 0.1105, -0.0046,  0.0618,  ...,  0.0103, -0.0147,  0.0179],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight': tensor([[ 0.0128, -0.0147,  0.0370,  ..., -0.0059,  0.0019, -0.0157],
        [-0.0200,  0.0040, -0.0021,  ..., -0.0084, -0.0056, -0.0079],
        [-0.0030, -0.0037, -0.0301,  ..., -0.0076,  0.0190,  0.0188],
        ...,
        [ 0.0036,  0.0197, -0.0007,  ..., -0.0078,  0.0181, -0.0004],
        [-0.0112,  0.0034, -0.0117,  ...,  0.0041, -0.0017, -0.0116],
        [-0.0199,  0.0032, -0.0224,  ..., -0.0046,  0.0289,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias': tensor([-0.0085, -0.0267, -0.0139,  ..., -0.0130,  0.0113,  0.0014],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight': tensor([[-5.2223e-03, -1.1261e-02,  2.0859e-02,  ..., -3.4424e-02,
          5.4245e-03,  3.5515e-03],
        [ 2.7637e-03,  4.4861e-03,  5.6877e-03,  ...,  6.7830e-05,
         -1.3123e-02,  1.6266e-02],
        [-7.9575e-03,  6.3133e-03,  1.7059e-02,  ...,  2.5711e-03,
         -5.4283e-03, -1.0437e-02],
        ...,
        [-1.2264e-03,  2.9633e-02, -8.0185e-03,  ...,  1.4366e-02,
          2.8824e-02, -1.8001e-05],
        [ 5.7316e-04,  8.2397e-03,  1.8951e-02,  ...,  1.4248e-03,
          1.8433e-02, -1.7624e-02],
        [ 6.5842e-03,  2.7451e-02, -1.9012e-02,  ...,  1.1887e-02,
         -7.3357e-03,  1.1284e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias': tensor([-0.8462,  0.0103, -1.0879,  ..., -0.1941,  0.1663, -1.2803],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight': tensor([[-0.0020,  0.0252,  0.0039,  ...,  0.0061, -0.0123,  0.0283],
        [ 0.0043,  0.0004, -0.0082,  ..., -0.0251,  0.0068,  0.0017],
        [-0.0231,  0.0006,  0.0164,  ...,  0.0248,  0.0101,  0.0125],
        ...,
        [ 0.0080,  0.0312,  0.0238,  ...,  0.0045,  0.0003,  0.0054],
        [ 0.0077,  0.0073, -0.0009,  ..., -0.0016,  0.0038, -0.0133],
        [ 0.0194, -0.0053, -0.0238,  ...,  0.0249, -0.0041,  0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias': tensor([-0.0205,  0.0181, -0.0017,  ..., -0.0779,  0.0408, -0.0200],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight': tensor([1.1533, 1.2090, 1.1787,  ..., 1.6367, 1.1729, 1.2188],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias': tensor([-0.0550,  0.0990, -0.0018,  ..., -0.1779, -0.0518, -0.0147],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight': tensor([[-0.0073, -0.0223,  0.0130,  ..., -0.0079, -0.0028,  0.0022],
        [-0.0071,  0.0068,  0.0017,  ..., -0.0123, -0.0179, -0.0108],
        [ 0.0072,  0.0217,  0.0110,  ...,  0.0060,  0.0005,  0.0016],
        ...,
        [ 0.0225, -0.0085,  0.0064,  ...,  0.0007,  0.0014, -0.0003],
        [-0.0191,  0.0245,  0.0085,  ..., -0.0102, -0.0108, -0.0063],
        [ 0.0290, -0.0322, -0.0287,  ..., -0.0045,  0.0156, -0.0153]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias': tensor([-0.4795, -0.1469, -0.1043,  ..., -0.2998, -0.2252, -0.3262],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight': tensor([[-0.0205,  0.0170, -0.0019,  ...,  0.0084,  0.0040,  0.0268],
        [ 0.0060,  0.0025, -0.0069,  ...,  0.0071, -0.0261,  0.0028],
        [ 0.0291, -0.0064, -0.0019,  ..., -0.0131,  0.0078, -0.0294],
        ...,
        [-0.0110,  0.0011, -0.0081,  ..., -0.0030,  0.0036, -0.0003],
        [-0.0195,  0.0083,  0.0063,  ...,  0.0095, -0.0105,  0.0214],
        [-0.0028,  0.0316,  0.0016,  ..., -0.0094, -0.0051,  0.0145]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias': tensor([ 0.0411, -0.0040, -0.0517,  ...,  0.1116,  0.0086, -0.0608],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight': tensor([1.3838, 1.2871, 1.2334,  ..., 0.6108, 1.1768, 1.2568],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias': tensor([-0.2367,  0.0573,  0.1235,  ...,  0.2408,  0.0240, -0.0257],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight': tensor([[-0.0176,  0.0033,  0.0183,  ..., -0.0038,  0.0074,  0.0088],
        [-0.0091,  0.0276, -0.0216,  ...,  0.0220,  0.0110,  0.0020],
        [-0.0428, -0.0160,  0.0246,  ...,  0.0130, -0.0163, -0.0116],
        ...,
        [ 0.0326,  0.0183, -0.0093,  ...,  0.0212, -0.0169,  0.0020],
        [ 0.0131,  0.0204,  0.0034,  ...,  0.0138,  0.0030,  0.0125],
        [ 0.0216,  0.0034,  0.0112,  ..., -0.0203,  0.0063, -0.0135]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias': tensor([-0.0005,  0.0142, -0.0017,  ...,  0.0816, -0.0667,  0.0688],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight': tensor([[-0.0305, -0.0173,  0.0406,  ...,  0.0054,  0.0093, -0.0001],
        [ 0.0040,  0.0132, -0.0068,  ..., -0.0034, -0.0217, -0.0175],
        [-0.0051,  0.0121, -0.0121,  ..., -0.0104, -0.0141, -0.0050],
        ...,
        [ 0.0016,  0.0205, -0.0056,  ..., -0.0040, -0.0046,  0.0020],
        [ 0.0378,  0.0040, -0.0073,  ...,  0.0001, -0.0014,  0.0133],
        [ 0.0088, -0.0021, -0.0040,  ..., -0.0019,  0.0257, -0.0056]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias': tensor([-0.0842, -0.0092,  0.0031,  ...,  0.0677, -0.0071,  0.0129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight': tensor([[ 0.0169, -0.0117, -0.0191,  ...,  0.0101, -0.0038,  0.0100],
        [-0.0080,  0.0092,  0.0094,  ...,  0.0197, -0.0175, -0.0183],
        [-0.0264, -0.0041,  0.0021,  ...,  0.0114,  0.0084, -0.0139],
        ...,
        [-0.0015,  0.0094,  0.0175,  ...,  0.0220, -0.0158,  0.0012],
        [-0.0012,  0.0214, -0.0034,  ...,  0.0166, -0.0191,  0.0039],
        [ 0.0204, -0.0130,  0.0074,  ..., -0.0208,  0.0063, -0.0040]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias': tensor([ 0.0173,  0.2045, -0.1959,  ..., -0.0136, -0.0571, -0.2710],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight': tensor([[ 1.1879e-02, -8.7357e-03, -2.2980e-02,  ..., -5.5885e-03,
         -2.6260e-02,  1.4985e-04],
        [ 2.3117e-02, -1.8127e-02,  2.0111e-02,  ..., -5.3711e-03,
         -3.0880e-03, -2.6855e-03],
        [-7.4577e-03,  5.7449e-03, -2.7313e-02,  ...,  2.7695e-03,
          7.9803e-03,  1.0475e-02],
        ...,
        [-1.1810e-02,  1.0620e-02,  1.4153e-02,  ...,  7.8049e-03,
          7.3671e-04,  2.8267e-03],
        [ 6.1150e-03,  1.5244e-02,  2.3621e-02,  ...,  9.0599e-05,
          2.7008e-03, -3.2196e-02],
        [ 3.8743e-04, -6.6109e-03, -1.4534e-02,  ...,  1.1330e-03,
         -1.8280e-02, -3.4065e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias': tensor([-0.0230,  0.0388, -0.0072,  ..., -0.0651,  0.0296, -0.0002],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight': tensor([1.2031, 1.2344, 1.1543,  ..., 1.5986, 1.2275, 1.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias': tensor([-0.0587,  0.0094, -0.0588,  ..., -0.2544, -0.1669, -0.0670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight': tensor([[-0.0105, -0.0159, -0.0260,  ..., -0.0012,  0.0033,  0.0001],
        [ 0.0232, -0.0237,  0.0074,  ..., -0.0032,  0.0108,  0.0003],
        [ 0.0088,  0.0072,  0.0034,  ...,  0.0001, -0.0065,  0.0012],
        ...,
        [ 0.0007, -0.0093,  0.0181,  ..., -0.0021, -0.0059,  0.0082],
        [ 0.0024,  0.0102, -0.0177,  ..., -0.0005, -0.0069, -0.0302],
        [ 0.0112,  0.0245,  0.0004,  ...,  0.0030, -0.0044,  0.0190]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias': tensor([-0.1327, -0.2241, -0.0568,  ..., -0.2708, -0.3245, -0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight': tensor([[ 1.0185e-02, -1.1162e-02, -2.3911e-02,  ...,  2.9709e-02,
         -1.3023e-02, -1.1803e-02],
        [ 8.2092e-03, -4.3631e-04, -3.1257e-04,  ..., -1.3252e-02,
          5.4598e-05, -1.8997e-02],
        [ 5.5885e-03,  1.8112e-02,  9.0179e-03,  ..., -3.1700e-03,
          8.4686e-03, -3.6144e-03],
        ...,
        [ 4.7798e-03,  3.0174e-03, -3.5143e-04,  ...,  5.4665e-03,
         -3.4122e-03, -4.2953e-03],
        [ 3.2082e-03, -1.4816e-02, -9.4986e-04,  ..., -1.9455e-02,
         -9.8825e-05,  9.9869e-03],
        [-7.2784e-03, -5.8289e-03, -3.9062e-03,  ...,  5.5122e-03,
         -2.4323e-02, -2.7542e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias': tensor([ 0.0389,  0.0069, -0.0129,  ...,  0.0417,  0.0218,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight': tensor([1.4287, 1.3613, 1.2949,  ..., 1.0137, 1.1826, 1.3213],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias': tensor([-0.1137,  0.0275,  0.0679,  ...,  0.1796,  0.0205, -0.2534],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight': tensor([[ 0.0030,  0.0209, -0.0001,  ..., -0.0044,  0.0148,  0.0093],
        [-0.0027, -0.0116,  0.0012,  ...,  0.0060, -0.0152, -0.0084],
        [-0.0064,  0.0066, -0.0148,  ..., -0.0031, -0.0160,  0.0061],
        ...,
        [ 0.0134, -0.0141, -0.0170,  ...,  0.0031, -0.0175,  0.0096],
        [ 0.0032, -0.0072,  0.0027,  ...,  0.0026,  0.0248,  0.0016],
        [ 0.0372, -0.0190,  0.0259,  ..., -0.0076,  0.0134,  0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias': tensor([ 0.0132, -0.0158,  0.0312,  ...,  0.1599,  0.0190, -0.0702],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight': tensor([[-0.0019,  0.0161, -0.0136,  ...,  0.0041,  0.0124, -0.0042],
        [ 0.0003, -0.0210,  0.0050,  ...,  0.0030, -0.0272,  0.0083],
        [-0.0101, -0.0327, -0.0195,  ..., -0.0035,  0.0067, -0.0172],
        ...,
        [ 0.0214, -0.0060, -0.0126,  ..., -0.0054, -0.0032,  0.0097],
        [-0.0153, -0.0010, -0.0009,  ...,  0.0023, -0.0131,  0.0013],
        [ 0.0080,  0.0060,  0.0053,  ..., -0.0054, -0.0073,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias': tensor([-0.0223, -0.0200, -0.0063,  ..., -0.0170, -0.0150,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight': tensor([[-0.0132,  0.0006,  0.0249,  ..., -0.0071,  0.0142, -0.0221],
        [-0.0046,  0.0369, -0.0272,  ...,  0.0017,  0.0163,  0.0032],
        [-0.0089, -0.0084,  0.0370,  ..., -0.0099,  0.0085,  0.0120],
        ...,
        [ 0.0223, -0.0226, -0.0282,  ...,  0.0133, -0.0224, -0.0005],
        [ 0.0005, -0.0127, -0.0058,  ..., -0.0071,  0.0076, -0.0049],
        [-0.0067,  0.0026,  0.0143,  ...,  0.0054, -0.0011,  0.0246]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias': tensor([-0.0499, -0.0381,  0.5078,  ..., -0.0939, -1.3535,  0.2761],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight': tensor([[ 0.0038,  0.0181,  0.0089,  ..., -0.0054,  0.0091,  0.0008],
        [-0.0116,  0.0084,  0.0211,  ...,  0.0138,  0.0282, -0.0086],
        [ 0.0388,  0.0029,  0.0070,  ..., -0.0161,  0.0043, -0.0173],
        ...,
        [ 0.0053, -0.0073, -0.0049,  ...,  0.0171, -0.0165,  0.0032],
        [ 0.0020, -0.0032,  0.0069,  ...,  0.0089,  0.0018,  0.0021],
        [ 0.0025, -0.0044,  0.0106,  ..., -0.0193,  0.0141, -0.0083]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias': tensor([ 0.0060,  0.0680,  0.0354,  ..., -0.0553,  0.0136,  0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight': tensor([1.2344, 1.2090, 1.1689,  ..., 1.8428, 1.1562, 1.2676],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias': tensor([-0.0174, -0.0716, -0.1256,  ..., -0.2900, -0.1460,  0.1504],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight': tensor([[-0.0042, -0.0027,  0.0133,  ..., -0.0005,  0.0226, -0.0110],
        [ 0.0404,  0.0308,  0.0195,  ...,  0.0055, -0.0234,  0.0145],
        [-0.0008, -0.0259, -0.0103,  ...,  0.0008,  0.0100,  0.0084],
        ...,
        [ 0.0190, -0.0154,  0.0061,  ..., -0.0111, -0.0397,  0.0165],
        [ 0.0025, -0.0002,  0.0089,  ..., -0.0010, -0.0172, -0.0077],
        [ 0.0183, -0.0069, -0.0037,  ...,  0.0029, -0.0036,  0.0130]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias': tensor([-0.2314, -0.3215, -0.0735,  ..., -0.3020, -0.1613, -0.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight': tensor([[ 1.0155e-02,  3.2532e-02,  8.2626e-03,  ..., -6.4468e-03,
         -4.7760e-03,  5.5432e-06],
        [-1.1612e-02,  1.7509e-03,  2.4841e-02,  ...,  8.9645e-03,
         -2.5436e-02, -8.4152e-03],
        [ 1.5182e-02,  7.3395e-03,  6.1264e-03,  ..., -1.5427e-02,
         -1.8677e-02,  1.9806e-02],
        ...,
        [-5.6686e-03,  6.3848e-04,  4.5128e-03,  ..., -9.9792e-03,
          1.1284e-02,  6.5231e-04],
        [-3.6335e-03,  3.6285e-02, -9.9277e-04,  ...,  4.8828e-03,
          9.6283e-03,  1.3008e-02],
        [ 9.3918e-03, -2.1927e-02, -1.4038e-02,  ...,  1.3329e-02,
          5.4359e-03,  3.3169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias': tensor([0.0373, 0.0198, 0.0018,  ..., 0.0559, 0.0675, 0.0106],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight': tensor([1.4990, 1.4297, 1.3555,  ..., 0.9502, 1.1816, 1.4072],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias': tensor([-0.1736, -0.0029,  0.0179,  ...,  0.2495,  0.0637, -0.1158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight': tensor([[ 0.0138, -0.0022,  0.0212,  ...,  0.0048,  0.0084,  0.0082],
        [-0.0165, -0.0025,  0.0060,  ...,  0.0063,  0.0062, -0.0098],
        [ 0.0116,  0.0009,  0.0094,  ...,  0.0054,  0.0176,  0.0027],
        ...,
        [ 0.0160, -0.0161,  0.0148,  ..., -0.0268,  0.0052,  0.0090],
        [-0.0136,  0.0253, -0.0004,  ...,  0.0156,  0.0059,  0.0038],
        [-0.0080,  0.0130, -0.0251,  ...,  0.0136, -0.0164,  0.0184]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias': tensor([ 0.1146,  1.0303,  0.1827,  ...,  0.0439,  0.0025, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0085, -0.0074,  ...,  0.0006, -0.0214, -0.0142],
        [ 0.0022,  0.0155, -0.0111,  ..., -0.0004, -0.0232, -0.0101],
        [-0.0139,  0.0073, -0.0043,  ..., -0.0005, -0.0110, -0.0235],
        ...,
        [ 0.0153,  0.0130, -0.0090,  ...,  0.0045,  0.0109,  0.0025],
        [ 0.0072,  0.0052, -0.0024,  ..., -0.0120,  0.0016, -0.0072],
        [ 0.0013, -0.0272, -0.0105,  ..., -0.0043,  0.0004, -0.0020]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias': tensor([ 0.0573, -0.0360, -0.0042,  ...,  0.0485, -0.0465,  0.0206],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight': tensor([[ 0.0094,  0.0003,  0.0279,  ...,  0.0015, -0.0191,  0.0090],
        [ 0.0041, -0.0014,  0.0020,  ...,  0.0017, -0.0018,  0.0040],
        [-0.0280,  0.0335,  0.0134,  ...,  0.0017,  0.0047, -0.0206],
        ...,
        [-0.0081, -0.0019,  0.0095,  ..., -0.0111, -0.0239,  0.0087],
        [-0.0195, -0.0019,  0.0218,  ...,  0.0267,  0.0121, -0.0089],
        [-0.0340, -0.0066,  0.0098,  ...,  0.0160,  0.0019, -0.0100]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias': tensor([ 0.2460,  1.7949,  0.0708,  ..., -0.2112,  0.1188,  0.6323],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight': tensor([[ 0.0051,  0.0107, -0.0119,  ..., -0.0148,  0.0005, -0.0302],
        [-0.0066, -0.0071, -0.0048,  ..., -0.0226, -0.0094,  0.0276],
        [ 0.0101,  0.0083,  0.0168,  ..., -0.0064,  0.0009, -0.0152],
        ...,
        [ 0.0094, -0.0071,  0.0016,  ..., -0.0147,  0.0114,  0.0020],
        [ 0.0223,  0.0076,  0.0287,  ..., -0.0214,  0.0006,  0.0041],
        [ 0.0177,  0.0222,  0.0063,  ...,  0.0065,  0.0120, -0.0114]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias': tensor([ 0.0267, -0.0057, -0.0027,  ..., -0.0531, -0.0267,  0.0482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight': tensor([1.2383, 1.2549, 1.2197,  ..., 1.8193, 1.1484, 1.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias': tensor([ 0.1250, -0.0352,  0.1172,  ..., -0.1227, -0.0328,  0.1005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight': tensor([[-0.0007, -0.0112,  0.0090,  ..., -0.0016,  0.0087,  0.0027],
        [ 0.0122, -0.0152,  0.0042,  ..., -0.0079, -0.0033, -0.0148],
        [ 0.0095, -0.0118, -0.0270,  ...,  0.0040,  0.0046, -0.0246],
        ...,
        [-0.0209, -0.0194, -0.0025,  ..., -0.0006, -0.0144,  0.0085],
        [ 0.0016,  0.0133,  0.0006,  ..., -0.0033, -0.0143,  0.0128],
        [-0.0106,  0.0115,  0.0019,  ..., -0.0046, -0.0505,  0.0052]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias': tensor([-0.3506, -0.3098, -0.0692,  ..., -0.3076, -0.2494, -0.4229],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight': tensor([[-0.0116,  0.0186, -0.0109,  ...,  0.0093, -0.0051, -0.0192],
        [ 0.0115,  0.0091,  0.0046,  ...,  0.0060, -0.0104, -0.0086],
        [-0.0004,  0.0162,  0.0221,  ...,  0.0048,  0.0374,  0.0092],
        ...,
        [-0.0029,  0.0068, -0.0073,  ...,  0.0019, -0.0060,  0.0068],
        [ 0.0121, -0.0012, -0.0035,  ..., -0.0168, -0.0036, -0.0015],
        [ 0.0085, -0.0005,  0.0138,  ..., -0.0026,  0.0074, -0.0113]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias': tensor([ 0.0374, -0.0088, -0.0430,  ...,  0.0654, -0.0126, -0.0253],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight': tensor([1.5195, 1.3818, 1.3984,  ..., 0.8403, 1.2627, 1.5020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias': tensor([-0.1865,  0.1162,  0.4048,  ...,  0.2292,  0.4202, -0.0959],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight': tensor([[ 0.0295,  0.0205, -0.0174,  ...,  0.0181,  0.0055,  0.0153],
        [ 0.0159, -0.0236, -0.0138,  ...,  0.0058,  0.0019,  0.0084],
        [-0.0116, -0.0219,  0.0080,  ...,  0.0020, -0.0022,  0.0255],
        ...,
        [-0.0140,  0.0030, -0.0549,  ...,  0.0038, -0.0079,  0.0469],
        [-0.0193,  0.0216, -0.0092,  ...,  0.0083,  0.0186,  0.0123],
        [ 0.0039,  0.0084,  0.0082,  ..., -0.0016, -0.0041, -0.0187]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias': tensor([-0.0278, -0.0587, -0.0110,  ..., -0.0826, -0.0213, -0.0725],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight': tensor([[-0.0007,  0.0020,  0.0042,  ..., -0.0033, -0.0094, -0.0123],
        [ 0.0162,  0.0139,  0.0239,  ..., -0.0017, -0.0188,  0.0138],
        [-0.0234,  0.0133, -0.0101,  ..., -0.0029, -0.0003,  0.0196],
        ...,
        [ 0.0244,  0.0202,  0.0058,  ..., -0.0130,  0.0092, -0.0032],
        [ 0.0215,  0.0236, -0.0171,  ..., -0.0159, -0.0069,  0.0134],
        [-0.0087,  0.0025,  0.0248,  ..., -0.0004,  0.0047, -0.0208]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias': tensor([-0.0305,  0.0005, -0.0124,  ..., -0.0511, -0.0883,  0.0079],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight': tensor([[-0.0156,  0.0022, -0.0072,  ...,  0.0036,  0.0290,  0.0180],
        [-0.0003,  0.0088, -0.0014,  ..., -0.0144, -0.0101,  0.0001],
        [-0.0141, -0.0287,  0.0098,  ..., -0.0024,  0.0292,  0.0254],
        ...,
        [-0.0255,  0.0364, -0.0171,  ...,  0.0032,  0.0116, -0.0182],
        [-0.0159,  0.0349, -0.0009,  ..., -0.0083, -0.0006, -0.0242],
        [-0.0239,  0.0287,  0.0045,  ...,  0.0057, -0.0037, -0.0132]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias': tensor([-0.2856, -0.3130, -0.2024,  ...,  0.1942, -0.0307, -0.0692],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight': tensor([[ 0.0021, -0.0248,  0.0393,  ..., -0.0213, -0.0080,  0.0129],
        [-0.0123, -0.0083,  0.0236,  ..., -0.0091, -0.0172, -0.0205],
        [-0.0194, -0.0024,  0.0146,  ..., -0.0071,  0.0185, -0.0175],
        ...,
        [-0.0277,  0.0011, -0.0187,  ...,  0.0559,  0.0597, -0.0009],
        [ 0.0156,  0.0051, -0.0020,  ..., -0.0031,  0.0066,  0.0040],
        [-0.0057, -0.0281, -0.0138,  ...,  0.0075, -0.0093,  0.0108]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias': tensor([ 0.0077,  0.0031,  0.0012,  ..., -0.0701,  0.0300,  0.0083],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight': tensor([1.2822, 1.2529, 1.2988,  ..., 2.2090, 1.1758, 1.3721],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias': tensor([ 0.1495, -0.0801, -0.0723,  ..., -0.1654, -0.0899,  0.0350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight': tensor([[ 0.0063,  0.0413,  0.0369,  ...,  0.0064,  0.0150,  0.0227],
        [ 0.0141,  0.0154,  0.0189,  ...,  0.0018,  0.0107,  0.0041],
        [-0.0081, -0.0167,  0.0103,  ..., -0.0018, -0.0027,  0.0110],
        ...,
        [ 0.0142,  0.0290,  0.0162,  ..., -0.0030,  0.0042,  0.0023],
        [ 0.0167,  0.0140,  0.0168,  ..., -0.0036, -0.0046,  0.0118],
        [-0.0082,  0.0164,  0.0227,  ...,  0.0009, -0.0199, -0.0222]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias': tensor([-0.2788, -0.1959, -0.3855,  ..., -0.3228, -0.2610, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight': tensor([[-6.8474e-03, -1.1681e-02, -1.7517e-02,  ...,  1.0986e-02,
         -1.8341e-02,  2.0432e-02],
        [ 1.1215e-02, -7.8430e-03, -6.9542e-03,  ...,  1.2108e-02,
         -9.6741e-03, -1.2093e-02],
        [ 1.2321e-02, -2.7924e-02, -2.8896e-03,  ...,  4.8676e-03,
         -2.0275e-03, -1.2695e-02],
        ...,
        [-2.5902e-03,  1.4412e-02, -3.3092e-03,  ..., -2.8193e-05,
          6.4087e-04, -7.4434e-04],
        [-1.8280e-02, -8.6746e-03,  9.6130e-03,  ...,  4.2915e-03,
         -1.1269e-02,  2.3453e-02],
        [-6.6452e-03, -2.1088e-02, -1.2444e-02,  ..., -3.5534e-03,
         -7.8659e-03,  2.5589e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias': tensor([ 0.0329,  0.0112, -0.0181,  ...,  0.0332,  0.0061, -0.0410],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight': tensor([1.6201, 1.4990, 1.4219,  ..., 0.7642, 1.2715, 1.4961],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias': tensor([-0.1376, -0.0238, -0.0118,  ...,  0.3352,  0.1462, -0.0976],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight': tensor([[ 0.0070,  0.0068,  0.0031,  ...,  0.0113, -0.0308, -0.0060],
        [ 0.0026, -0.0039,  0.0043,  ..., -0.0343, -0.0066,  0.0307],
        [-0.0036,  0.0332, -0.0028,  ...,  0.0011, -0.0337,  0.0031],
        ...,
        [-0.0229, -0.0187, -0.0097,  ..., -0.0007,  0.0183, -0.0038],
        [ 0.0047,  0.0152, -0.0175,  ...,  0.0070,  0.0130, -0.0114],
        [-0.0206,  0.0068, -0.0252,  ...,  0.0070, -0.0134, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias': tensor([ 0.1860, -0.2378,  0.0005,  ...,  0.0031,  0.1797, -0.0522],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight': tensor([[-0.0298, -0.0140,  0.0248,  ...,  0.0035, -0.0014, -0.0059],
        [-0.0006, -0.0080,  0.0046,  ...,  0.0036,  0.0106, -0.0112],
        [ 0.0055,  0.0188,  0.0175,  ...,  0.0029, -0.0033, -0.0018],
        ...,
        [ 0.0039, -0.0129,  0.0162,  ...,  0.0032, -0.0222, -0.0056],
        [-0.0039, -0.0104,  0.0050,  ..., -0.0019,  0.0213, -0.0076],
        [ 0.0024,  0.0067, -0.0013,  ..., -0.0021,  0.0013,  0.0046]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias': tensor([ 0.0186, -0.0095,  0.0066,  ...,  0.0210,  0.0131,  0.0208],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight': tensor([[ 0.0029, -0.0233, -0.0027,  ...,  0.0144, -0.0352, -0.0105],
        [-0.0247, -0.0116,  0.0012,  ..., -0.0372,  0.0113, -0.0128],
        [ 0.0080, -0.0012, -0.0150,  ...,  0.0013, -0.0024,  0.0199],
        ...,
        [-0.0113, -0.0235, -0.0017,  ...,  0.0006, -0.0010, -0.0029],
        [ 0.0197, -0.0205, -0.0153,  ...,  0.0061,  0.0182,  0.0045],
        [-0.0173, -0.0083,  0.0412,  ...,  0.0141, -0.0057,  0.0143]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias': tensor([ 0.2690, -0.1337,  0.1326,  ...,  0.5728, -0.2661, -0.0468],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight': tensor([[ 0.0029,  0.0160,  0.0056,  ...,  0.0018,  0.0077, -0.0090],
        [ 0.0110, -0.0064,  0.0049,  ...,  0.0272,  0.0262,  0.0051],
        [-0.0114, -0.0032,  0.0054,  ...,  0.0236, -0.0132, -0.0082],
        ...,
        [-0.0007,  0.0021, -0.0044,  ..., -0.0028, -0.0311, -0.0200],
        [-0.0074, -0.0073, -0.0035,  ..., -0.0198, -0.0346, -0.0070],
        [-0.0123, -0.0216,  0.0046,  ...,  0.0036,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias': tensor([-0.0063, -0.0193, -0.0133,  ...,  0.0398,  0.0332,  0.0196],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight': tensor([1.3359, 1.2266, 1.2646,  ..., 1.9346, 1.1377, 1.3818],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias': tensor([ 0.1417,  0.0006,  0.0168,  ...,  0.0170, -0.0730,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight': tensor([[ 0.0115,  0.0003, -0.0145,  ..., -0.0144, -0.0194, -0.0104],
        [-0.0015,  0.0058,  0.0179,  ..., -0.0030,  0.0044, -0.0100],
        [-0.0029,  0.0045,  0.0084,  ..., -0.0206,  0.0133,  0.0283],
        ...,
        [ 0.0059, -0.0118, -0.0161,  ..., -0.0221, -0.0054,  0.0157],
        [ 0.0215, -0.0010,  0.0022,  ...,  0.0130,  0.0179,  0.0099],
        [ 0.0113,  0.0054, -0.0108,  ...,  0.0036,  0.0090, -0.0237]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias': tensor([-0.2153, -0.2783, -0.3320,  ..., -0.1221, -0.1306, -0.2898],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight': tensor([[-0.0038, -0.0308,  0.0166,  ..., -0.0028, -0.0180,  0.0016],
        [ 0.0179,  0.0086,  0.0044,  ...,  0.0105,  0.0129, -0.0061],
        [-0.0078, -0.0048,  0.0276,  ...,  0.0158, -0.0102,  0.0017],
        ...,
        [-0.0093,  0.0032, -0.0129,  ...,  0.0116, -0.0041, -0.0039],
        [-0.0126,  0.0043,  0.0086,  ...,  0.0042, -0.0106,  0.0038],
        [-0.0054, -0.0066, -0.0067,  ..., -0.0130, -0.0257,  0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias': tensor([ 0.0253, -0.0025, -0.0242,  ...,  0.0955,  0.0208, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight': tensor([1.6533, 1.5479, 1.5508,  ..., 0.4094, 1.3984, 1.6689],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias': tensor([-0.2152,  0.1279,  0.3982,  ...,  0.3850,  0.3862, -0.2152],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight': tensor([[ 0.0007,  0.0003,  0.0054,  ...,  0.0126,  0.0008,  0.0107],
        [-0.0359,  0.0132, -0.0041,  ..., -0.0473,  0.0050, -0.0005],
        [ 0.0122, -0.0012, -0.0178,  ..., -0.0031,  0.0207, -0.0100],
        ...,
        [ 0.0512, -0.0152, -0.0452,  ...,  0.0250, -0.0268,  0.0074],
        [ 0.0115,  0.0260, -0.0071,  ...,  0.0085,  0.0057,  0.0017],
        [ 0.0223, -0.0031, -0.0004,  ...,  0.0035, -0.0175,  0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias': tensor([-0.8135, -0.1840,  0.0576,  ..., -0.0189,  0.0277,  0.0699],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight': tensor([[ 2.6184e-02,  6.5842e-03, -6.6528e-03,  ...,  2.3901e-05,
          1.5297e-02, -1.9302e-02],
        [ 4.0741e-03,  3.0079e-03,  3.1090e-03,  ..., -9.0485e-03,
          1.0986e-02,  4.2953e-03],
        [ 4.1504e-03,  1.6336e-03, -1.1185e-02,  ...,  5.6496e-03,
          2.0889e-02, -1.3113e-04],
        ...,
        [-3.6945e-03,  1.4648e-02, -8.8348e-03,  ...,  8.1711e-03,
         -2.6073e-03,  1.3008e-02],
        [ 1.9562e-02, -1.5762e-02,  7.0877e-03,  ...,  6.5517e-04,
         -2.1744e-02, -2.0233e-02],
        [ 1.8417e-02, -1.2039e-02, -9.2239e-03,  ..., -4.6659e-04,
         -1.3191e-02, -7.4272e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias': tensor([ 0.0088,  0.0188,  0.0441,  ..., -0.0099, -0.0044,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight': tensor([[-0.0029,  0.0020, -0.0026,  ...,  0.0042, -0.0110, -0.0049],
        [-0.0278,  0.0302,  0.0003,  ..., -0.0331,  0.0236,  0.0125],
        [ 0.0239,  0.0206,  0.0083,  ..., -0.0029,  0.0212, -0.0040],
        ...,
        [ 0.0231,  0.0166, -0.0169,  ...,  0.0415, -0.0144,  0.0037],
        [ 0.0159,  0.0033, -0.0034,  ...,  0.0044, -0.0091,  0.0034],
        [ 0.0106, -0.0117, -0.0165,  ...,  0.0030, -0.0196,  0.0211]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias': tensor([-2.5234,  0.2341, -0.3838,  ..., -0.0643,  0.1272,  0.1238],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight': tensor([[-0.0296, -0.0036,  0.0027,  ...,  0.0065,  0.0073, -0.0128],
        [-0.0154, -0.0153,  0.0213,  ...,  0.0241,  0.0144,  0.0159],
        [-0.0073, -0.0148,  0.0064,  ...,  0.0165,  0.0177,  0.0191],
        ...,
        [-0.0013,  0.0025, -0.0111,  ..., -0.0081,  0.0079,  0.0101],
        [-0.0041, -0.0076, -0.0202,  ..., -0.0055,  0.0170,  0.0018],
        [ 0.0106, -0.0025,  0.0060,  ...,  0.0055, -0.0079,  0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias': tensor([ 0.0107, -0.0549,  0.0179,  ...,  0.0266,  0.0321, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight': tensor([1.3027, 1.2529, 1.3281,  ..., 1.4834, 1.1562, 1.3789],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias': tensor([ 0.1531,  0.0493, -0.0565,  ..., -0.0096, -0.0239, -0.0371],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight': tensor([[ 0.0043,  0.0120,  0.0113,  ..., -0.0241, -0.0064, -0.0090],
        [ 0.0006, -0.0211, -0.0018,  ..., -0.0029, -0.0108,  0.0110],
        [ 0.0030,  0.0094, -0.0028,  ..., -0.0025, -0.0057,  0.0185],
        ...,
        [-0.0027, -0.0314, -0.0122,  ..., -0.0098, -0.0206, -0.0127],
        [-0.0042,  0.0269, -0.0155,  ..., -0.0024, -0.0119, -0.0034],
        [-0.0102,  0.0069, -0.0109,  ..., -0.0012,  0.0015, -0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias': tensor([-0.2781, -0.2573, -0.3364,  ..., -0.3469, -0.2040, -0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight': tensor([[ 0.0010, -0.0122,  0.0169,  ...,  0.0076, -0.0051,  0.0080],
        [ 0.0136, -0.0151, -0.0033,  ..., -0.0080,  0.0146, -0.0023],
        [ 0.0173, -0.0216,  0.0123,  ...,  0.0066, -0.0024, -0.0003],
        ...,
        [-0.0117,  0.0076, -0.0053,  ...,  0.0010,  0.0026,  0.0003],
        [-0.0175,  0.0074, -0.0194,  ..., -0.0246, -0.0096, -0.0045],
        [ 0.0076,  0.0037,  0.0206,  ...,  0.0206, -0.0109,  0.0051]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias': tensor([ 0.0366, -0.0981, -0.0667,  ...,  0.0356,  0.0194, -0.0255],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight': tensor([1.7695, 1.6426, 1.7236,  ..., 0.6680, 1.5166, 1.7900],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias': tensor([-0.1890,  0.3459,  0.1487,  ...,  0.4136,  0.4312, -0.1221],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight': tensor([[ 0.0141,  0.0079,  0.0303,  ..., -0.0145,  0.0041,  0.0001],
        [-0.0112,  0.0048,  0.0240,  ..., -0.0055, -0.0139,  0.0003],
        [ 0.0167,  0.0107,  0.0269,  ..., -0.0065,  0.0130, -0.0072],
        ...,
        [-0.0014,  0.0062,  0.0020,  ..., -0.0017,  0.0170, -0.0246],
        [-0.0123, -0.0318, -0.0099,  ..., -0.0016, -0.0070, -0.0297],
        [ 0.0025,  0.0103,  0.0089,  ...,  0.0022,  0.0038,  0.0318]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias': tensor([-0.0931,  0.0089, -0.0538,  ...,  0.1041,  0.1436,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight': tensor([[-0.0085,  0.0049, -0.0003,  ...,  0.0036, -0.0302,  0.0040],
        [ 0.0075, -0.0265, -0.0065,  ..., -0.0031,  0.0134, -0.0018],
        [-0.0087, -0.0006, -0.0056,  ...,  0.0055,  0.0154,  0.0372],
        ...,
        [-0.0022, -0.0078,  0.0144,  ...,  0.0019, -0.0084,  0.0115],
        [ 0.0047, -0.0127, -0.0223,  ..., -0.0021, -0.0109,  0.0101],
        [-0.0105, -0.0005, -0.0008,  ..., -0.0030, -0.0079, -0.0039]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias': tensor([-0.0321,  0.0378,  0.0632,  ...,  0.0502, -0.0048, -0.0005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight': tensor([[-0.0095, -0.0095,  0.0312,  ...,  0.0022, -0.0092,  0.0262],
        [-0.0264, -0.0028, -0.0018,  ..., -0.0075, -0.0155, -0.0109],
        [-0.0025, -0.0001,  0.0389,  ..., -0.0119,  0.0128, -0.0002],
        ...,
        [ 0.0271, -0.0069,  0.0122,  ...,  0.0018,  0.0167, -0.0080],
        [ 0.0080, -0.0216,  0.0023,  ...,  0.0015, -0.0140,  0.0002],
        [-0.0039,  0.0055,  0.0021,  ...,  0.0071, -0.0103,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias': tensor([-0.2311,  0.2390, -0.0950,  ...,  0.0876,  0.1581,  0.0798],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight': tensor([[-0.0281, -0.0058,  0.0026,  ..., -0.0079,  0.0053, -0.0023],
        [ 0.0130, -0.0057, -0.0072,  ..., -0.0006, -0.0015, -0.0051],
        [-0.0112,  0.0132,  0.0089,  ..., -0.0184,  0.0022, -0.0036],
        ...,
        [ 0.0086,  0.0047, -0.0106,  ..., -0.0117, -0.0147, -0.0069],
        [ 0.0147, -0.0031, -0.0165,  ...,  0.0125, -0.0091,  0.0107],
        [ 0.0214,  0.0008, -0.0262,  ..., -0.0205, -0.0144,  0.0057]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias': tensor([-0.0645, -0.0639,  0.0044,  ..., -0.0346, -0.0156, -0.0320],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight': tensor([1.3975, 1.3584, 1.4883,  ..., 1.8799, 1.3203, 1.4980],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias': tensor([ 0.0757, -0.1133, -0.0580,  ..., -0.0255, -0.0899, -0.1061],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight': tensor([[-7.1793e-03,  4.6234e-03,  1.7502e-02,  ..., -1.0124e-02,
          1.3245e-02, -6.4430e-03],
        [-1.6571e-02,  1.1040e-02, -5.1537e-03,  ..., -6.7616e-04,
         -2.2491e-02, -9.1019e-03],
        [-7.6675e-04,  2.2156e-02,  1.0216e-02,  ..., -4.4708e-03,
         -1.6510e-02, -2.4704e-02],
        ...,
        [-2.9205e-02, -7.1602e-03,  8.7559e-05,  ..., -9.7656e-03,
          1.6312e-02,  2.7145e-02],
        [-1.2413e-02,  6.9084e-03,  2.4399e-02,  ..., -7.0381e-03,
         -7.9803e-03,  9.6130e-03],
        [ 6.4039e-04, -4.3259e-03,  4.3121e-02,  ..., -3.9101e-03,
         -1.3245e-02,  1.4565e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias': tensor([-0.3418, -0.2771, -0.3467,  ..., -0.3992, -0.2385, -0.2927],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight': tensor([[-9.4452e-03,  1.2772e-02,  1.8539e-02,  ..., -2.6276e-02,
          4.2343e-04, -1.3672e-02],
        [ 3.2593e-02,  8.7070e-04, -2.8477e-03,  ..., -8.7814e-03,
          1.1383e-02, -3.0182e-02],
        [-4.3488e-03, -2.7359e-02,  1.8482e-03,  ..., -6.5002e-03,
          2.6016e-02,  3.3539e-02],
        ...,
        [-4.1504e-03,  1.6251e-02,  7.8354e-03,  ...,  1.4816e-02,
         -1.9627e-03, -6.3002e-05],
        [ 6.4125e-03, -1.6647e-02,  4.3945e-03,  ...,  1.2833e-02,
         -1.5268e-03, -1.7975e-02],
        [-1.8167e-03, -1.1734e-02, -1.4511e-02,  ...,  3.0396e-02,
          1.1108e-02, -9.7580e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias': tensor([-0.0361, -0.0392,  0.0150,  ..., -0.0163,  0.0041, -0.0078],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight': tensor([2.1113, 2.0137, 2.0352,  ..., 0.7090, 1.8164, 2.2012],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias': tensor([-0.1631, -0.1508,  0.1484,  ...,  0.4434,  0.6812, -0.3279],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight': tensor([[-9.9716e-03, -2.5208e-02,  8.4457e-03,  ...,  1.3168e-02,
         -5.3942e-05, -2.8748e-02],
        [-3.1233e-05,  1.3992e-02, -2.2476e-02,  ...,  6.3232e-02,
         -1.4221e-02, -1.4404e-02],
        [-5.1785e-04, -3.1403e-02,  6.5517e-04,  ..., -1.0399e-02,
          1.1505e-02, -2.8076e-03],
        ...,
        [-6.2132e-04, -1.0201e-02,  1.3947e-02,  ..., -5.4810e-02,
         -8.1787e-03, -2.0981e-02],
        [ 9.8572e-03, -1.7899e-02,  1.1734e-02,  ..., -4.1885e-03,
          1.4870e-02,  1.1244e-03],
        [ 1.5884e-02,  2.2827e-02,  4.2000e-03,  ..., -4.3091e-02,
         -2.2690e-02, -1.3191e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias': tensor([ 0.2656, -0.2185,  0.0432,  ..., -0.1787, -0.2061,  0.0742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight': tensor([[ 0.0261,  0.0077, -0.0120,  ..., -0.0027, -0.0164, -0.0107],
        [-0.0080,  0.0102,  0.0077,  ...,  0.0039,  0.0010, -0.0050],
        [ 0.0017, -0.0101, -0.0256,  ...,  0.0058, -0.0145, -0.0055],
        ...,
        [-0.0161,  0.0100, -0.0047,  ..., -0.0049, -0.0208,  0.0245],
        [ 0.0115, -0.0098,  0.0141,  ...,  0.0035, -0.0129, -0.0005],
        [-0.0111, -0.0270,  0.0220,  ..., -0.0022, -0.0052, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias': tensor([-0.0182,  0.0114,  0.1055,  ..., -0.0048, -0.0138,  0.0093],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight': tensor([[-0.0116, -0.0250, -0.0204,  ...,  0.0060, -0.0022, -0.0020],
        [ 0.0243,  0.0011, -0.0106,  ...,  0.0480, -0.0213,  0.0138],
        [ 0.0116, -0.0210, -0.0045,  ..., -0.0067, -0.0268, -0.0189],
        ...,
        [ 0.0013,  0.0050,  0.0468,  ..., -0.0500,  0.0203,  0.0043],
        [ 0.0273, -0.0117,  0.0099,  ..., -0.0033, -0.0067,  0.0015],
        [-0.0062,  0.0012,  0.0167,  ..., -0.0361, -0.0010,  0.0275]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias': tensor([ 0.2439, -0.1146,  0.0887,  ...,  0.2213,  0.1515, -0.0186],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight': tensor([[-3.0136e-02,  1.2367e-02, -9.5749e-03,  ...,  1.8692e-02,
          9.2697e-03, -4.0054e-03],
        [-3.6682e-02, -9.7504e-03,  7.6950e-05,  ..., -1.0941e-02,
          8.2474e-03, -8.6546e-04],
        [ 1.9424e-02, -2.1729e-02,  5.8022e-03,  ...,  6.4888e-03,
         -4.6577e-03, -6.9504e-03],
        ...,
        [-7.0953e-03, -1.1024e-02,  1.4248e-03,  ...,  3.1490e-03,
         -7.8735e-03, -1.8097e-02],
        [ 1.8778e-03, -1.1490e-02, -8.2855e-03,  ..., -1.9104e-02,
          7.3166e-03, -8.8959e-03],
        [-8.1558e-03,  1.7426e-02,  1.1551e-02,  ..., -4.8790e-03,
          5.9700e-03,  9.9030e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias': tensor([-0.0732,  0.0212,  0.0239,  ...,  0.0091, -0.0001, -0.0141],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight': tensor([1.3848, 1.3320, 1.4814,  ..., 1.5195, 1.3164, 1.4180],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias': tensor([ 0.0473, -0.0936, -0.0594,  ...,  0.0325,  0.0149, -0.0659],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight': tensor([[ 1.5793e-02, -8.3160e-03,  2.2156e-02,  ...,  1.8814e-02,
         -5.4436e-03, -1.1604e-02],
        [ 1.5007e-02, -9.5978e-03, -2.5284e-02,  ..., -1.6510e-02,
         -3.3539e-02, -2.3102e-02],
        [-2.1622e-02,  2.0309e-02,  2.1801e-03,  ...,  7.5798e-03,
          1.4145e-02, -7.3433e-03],
        ...,
        [-4.5624e-03, -2.5757e-02,  6.9199e-03,  ...,  3.5572e-03,
          1.4694e-02, -2.2339e-02],
        [-9.1791e-06,  7.1487e-03, -1.3298e-02,  ...,  5.6610e-03,
          4.4975e-03,  1.1978e-02],
        [-5.8289e-03,  5.1689e-03, -1.4862e-02,  ...,  1.8585e-02,
          9.6655e-04,  1.1856e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias': tensor([-0.2683, -0.3921, -0.3279,  ..., -0.3718, -0.2028, -0.3127],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight': tensor([[-0.0059, -0.0140,  0.0130,  ...,  0.0043,  0.0292, -0.0014],
        [ 0.0265, -0.0073, -0.0116,  ..., -0.0211,  0.0206,  0.0263],
        [ 0.0022, -0.0233,  0.0002,  ...,  0.0067, -0.0096, -0.0120],
        ...,
        [ 0.0080, -0.0016,  0.0073,  ..., -0.0021, -0.0057, -0.0010],
        [ 0.0048, -0.0163, -0.0040,  ...,  0.0130, -0.0188,  0.0429],
        [-0.0011, -0.0383, -0.0151,  ..., -0.0132,  0.0248,  0.0216]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias': tensor([ 0.0359,  0.0342,  0.0545,  ...,  0.0745, -0.0070,  0.0030],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight': tensor([2.5176, 2.3496, 2.4785,  ..., 0.5151, 2.0352, 2.4492],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias': tensor([-0.2339, -0.0297,  0.1533,  ...,  0.4067,  0.7363, -0.2054],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0246, -0.0315,  ...,  0.0246, -0.0050,  0.0121],
        [ 0.0096,  0.0193,  0.0106,  ..., -0.0207, -0.0075,  0.0043],
        [ 0.0199,  0.0022, -0.0148,  ..., -0.0771, -0.0211,  0.0064],
        ...,
        [ 0.0369,  0.0040, -0.0087,  ..., -0.0215,  0.0106,  0.0167],
        [-0.0061, -0.0050, -0.0032,  ..., -0.0078,  0.0147,  0.0186],
        [ 0.0009,  0.0079, -0.0195,  ..., -0.0096, -0.0309,  0.0012]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias': tensor([ 0.0911, -0.1252, -0.4846,  ...,  0.0673, -0.0733,  0.0197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight': tensor([[ 0.0141,  0.0237,  0.0094,  ..., -0.0007, -0.0127, -0.0134],
        [ 0.0092, -0.0071,  0.0201,  ...,  0.0027, -0.0176, -0.0013],
        [ 0.0039, -0.0016, -0.0055,  ...,  0.0065, -0.0001, -0.0049],
        ...,
        [ 0.0073, -0.0355, -0.0101,  ...,  0.0047, -0.0010, -0.0099],
        [-0.0019,  0.0097, -0.0335,  ..., -0.0019,  0.0006, -0.0019],
        [ 0.0030, -0.0076,  0.0026,  ..., -0.0004,  0.0043, -0.0152]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias': tensor([ 0.0290,  0.0252,  0.0343,  ...,  0.0027, -0.0045, -0.0545],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight': tensor([[ 0.0060, -0.0019, -0.0088,  ...,  0.0198, -0.0025, -0.0177],
        [ 0.0059,  0.0067,  0.0215,  ..., -0.0244, -0.0294,  0.0024],
        [ 0.0271,  0.0004, -0.0182,  ..., -0.0876,  0.0076, -0.0006],
        ...,
        [-0.0081,  0.0160, -0.0380,  ..., -0.0249, -0.0083,  0.0045],
        [ 0.0112, -0.0182, -0.0261,  ..., -0.0056, -0.0009, -0.0319],
        [ 0.0435,  0.0031,  0.0118,  ..., -0.0163,  0.0102, -0.0193]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias': tensor([ 0.0622,  0.0999, -0.5308,  ..., -0.1455,  0.0368, -0.1086],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight': tensor([[ 4.6425e-03, -2.0313e-03,  2.7237e-02,  ...,  1.0216e-02,
         -2.0187e-02,  1.1955e-02],
        [-5.8823e-03,  2.6627e-02,  7.8506e-03,  ...,  3.9864e-03,
         -1.8646e-02,  2.6762e-05],
        [-5.6601e-04,  5.0240e-03,  2.1591e-02,  ...,  1.1375e-02,
          6.1035e-03,  7.7581e-04],
        ...,
        [ 9.0256e-03, -4.1656e-03, -1.2932e-02,  ...,  9.0778e-05,
          1.9577e-02, -6.6452e-03],
        [ 1.5488e-02,  5.1928e-04,  1.3100e-02,  ..., -2.1057e-02,
         -4.6921e-03,  1.0338e-02],
        [ 3.2501e-03, -2.0432e-02, -2.8076e-02,  ..., -8.2169e-03,
         -2.1858e-03,  3.8376e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias': tensor([ 0.0169,  0.0075, -0.0464,  ...,  0.0064, -0.0125, -0.0271],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight': tensor([1.4844, 1.5352, 1.5859,  ..., 1.5234, 1.4395, 1.5938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias': tensor([ 0.1630, -0.0892, -0.0373,  ..., -0.0082, -0.0609, -0.1628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight': tensor([[-0.0057, -0.0090,  0.0211,  ...,  0.0072, -0.0180, -0.0063],
        [ 0.0278,  0.0188,  0.0136,  ..., -0.0074,  0.0133, -0.0087],
        [-0.0168,  0.0028, -0.0226,  ..., -0.0184, -0.0072, -0.0020],
        ...,
        [ 0.0011, -0.0155, -0.0045,  ..., -0.0092, -0.0268,  0.0125],
        [ 0.0054, -0.0030,  0.0160,  ...,  0.0257, -0.0181, -0.0068],
        [ 0.0045,  0.0018,  0.0164,  ..., -0.0108, -0.0191, -0.0004]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias': tensor([-0.2793, -0.3452, -0.2959,  ..., -0.1838, -0.1981, -0.2494],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight': tensor([[-0.0017, -0.0146,  0.0010,  ...,  0.0037, -0.0001,  0.0201],
        [ 0.0174, -0.0161, -0.0016,  ..., -0.0007, -0.0096, -0.0005],
        [ 0.0072,  0.0077, -0.0210,  ...,  0.0165, -0.0019, -0.0208],
        ...,
        [ 0.0195, -0.0092,  0.0151,  ..., -0.0062, -0.0071, -0.0216],
        [ 0.0159,  0.0006,  0.0077,  ..., -0.0073,  0.0030,  0.0091],
        [ 0.0062,  0.0206,  0.0089,  ...,  0.0090, -0.0033, -0.0063]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias': tensor([0.0065, 0.0102, 0.0046,  ..., 0.0065, 0.0796, 0.0695],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight': tensor([2.6719, 2.5625, 2.7695,  ..., 0.6802, 2.2539, 2.7422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias': tensor([-0.0354,  0.2776,  0.4175,  ...,  0.5674,  0.5327, -0.4670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight': tensor([[-0.0087,  0.0027,  0.0113,  ..., -0.0616,  0.0051, -0.0137],
        [-0.0173,  0.0047,  0.0124,  ...,  0.0239, -0.0160,  0.0129],
        [ 0.0097, -0.0005, -0.0050,  ...,  0.0011,  0.0099, -0.0130],
        ...,
        [-0.0052,  0.0120,  0.0098,  ..., -0.0244,  0.0038,  0.0010],
        [ 0.0119, -0.0235, -0.0134,  ..., -0.0140, -0.0140,  0.0065],
        [ 0.0291,  0.0226, -0.0254,  ..., -0.0035, -0.0137,  0.0350]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias': tensor([ 0.2783, -0.2036, -0.0648,  ...,  0.1705,  0.1809,  0.1080],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight': tensor([[-0.0184,  0.0137,  0.0067,  ..., -0.0029,  0.0099,  0.0297],
        [-0.0110,  0.0184,  0.0020,  ...,  0.0024, -0.0151,  0.0009],
        [ 0.0191, -0.0126,  0.0212,  ...,  0.0024, -0.0348,  0.0026],
        ...,
        [ 0.0005,  0.0007, -0.0011,  ...,  0.0046, -0.0222, -0.0393],
        [ 0.0117,  0.0042,  0.0002,  ..., -0.0006,  0.0005, -0.0083],
        [-0.0062,  0.0128,  0.0124,  ..., -0.0037, -0.0134,  0.0008]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias': tensor([-0.0114,  0.0300,  0.0252,  ..., -0.0060,  0.0197,  0.0400],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight': tensor([[ 1.4931e-02, -1.2466e-02,  2.4918e-02,  ..., -5.9814e-02,
         -4.3068e-03,  1.2131e-02],
        [-1.6464e-02, -9.9030e-03, -1.1108e-02,  ...,  2.3956e-02,
         -3.6163e-02,  1.1703e-02],
        [ 1.0757e-02,  2.5730e-03, -7.3338e-04,  ...,  2.4662e-03,
          6.1493e-03,  6.6528e-03],
        ...,
        [ 5.1003e-03, -7.8678e-06,  5.1041e-03,  ..., -4.5410e-02,
         -3.1738e-02,  1.8631e-02],
        [ 1.7502e-02, -4.1084e-03,  3.9978e-03,  ..., -1.8753e-02,
         -2.2335e-03,  2.1057e-03],
        [ 1.7303e-02,  6.7902e-03,  1.1360e-02,  ...,  8.0719e-03,
         -5.0278e-03,  2.1713e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias': tensor([-0.2339,  0.0393, -0.0323,  ..., -0.1953,  0.0200,  0.0049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight': tensor([[ 0.0254,  0.0050,  0.0049,  ...,  0.0120, -0.0121,  0.0091],
        [ 0.0248, -0.0193, -0.0093,  ..., -0.0044, -0.0032,  0.0151],
        [ 0.0053,  0.0182, -0.0142,  ..., -0.0130, -0.0033, -0.0087],
        ...,
        [ 0.0006, -0.0051, -0.0173,  ...,  0.0031, -0.0128,  0.0099],
        [ 0.0081, -0.0134,  0.0246,  ...,  0.0185, -0.0136,  0.0109],
        [-0.0261, -0.0152, -0.0080,  ...,  0.0230, -0.0056,  0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias': tensor([-0.0083,  0.0091, -0.0955,  ..., -0.0067,  0.0003, -0.0047],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight': tensor([1.5762, 1.4580, 1.5850,  ..., 1.7383, 1.4209, 1.5967],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias': tensor([ 0.1272, -0.2208, -0.0098,  ..., -0.0831, -0.0858, -0.1576],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight': tensor([[-0.0051,  0.0014, -0.0012,  ...,  0.0091, -0.0065, -0.0086],
        [-0.0191,  0.0118,  0.0002,  ..., -0.0095, -0.0148,  0.0134],
        [-0.0012, -0.0324,  0.0047,  ..., -0.0084,  0.0050, -0.0089],
        ...,
        [ 0.0005, -0.0097, -0.0229,  ..., -0.0036, -0.0164, -0.0044],
        [ 0.0058, -0.0019, -0.0019,  ...,  0.0053,  0.0177,  0.0073],
        [ 0.0128,  0.0044, -0.0019,  ..., -0.0147,  0.0180, -0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias': tensor([-0.1597, -0.3298, -0.3066,  ..., -0.3003, -0.3157, -0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight': tensor([[-0.0060, -0.0143,  0.0279,  ..., -0.0150,  0.0291,  0.0124],
        [ 0.0095, -0.0208, -0.0114,  ...,  0.0116, -0.0289,  0.0051],
        [-0.0165,  0.0403, -0.0052,  ...,  0.0008, -0.0144, -0.0153],
        ...,
        [-0.0120,  0.0119, -0.0007,  ...,  0.0051,  0.0161, -0.0073],
        [ 0.0291,  0.0090, -0.0140,  ...,  0.0286,  0.0029, -0.0079],
        [ 0.0233, -0.0179, -0.0138,  ..., -0.0036, -0.0180, -0.0041]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias': tensor([ 0.0113,  0.0318, -0.0128,  ..., -0.0561, -0.0155,  0.0321],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight': tensor([2.7773, 2.7402, 2.7402,  ..., 0.8696, 2.4961, 2.8711],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias': tensor([-0.1473, -0.0198,  0.2091,  ...,  0.4590,  0.5410, -0.2742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight': tensor([[ 0.0005, -0.0174, -0.0133,  ..., -0.0195,  0.0176,  0.0196],
        [ 0.0332, -0.0111, -0.0092,  ..., -0.0143,  0.0277, -0.0138],
        [-0.0094,  0.0108, -0.0135,  ..., -0.0078, -0.0209, -0.0013],
        ...,
        [ 0.0136,  0.0224,  0.0235,  ..., -0.0533, -0.0095,  0.0097],
        [-0.0183, -0.0031, -0.0219,  ..., -0.0209, -0.0113,  0.0082],
        [ 0.0187,  0.0257,  0.0352,  ..., -0.0150,  0.0010,  0.0060]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias': tensor([-0.2089,  0.1558,  0.3555,  ...,  0.0323,  0.1013,  0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight': tensor([[-0.0096,  0.0058, -0.0198,  ...,  0.0084,  0.0249,  0.0066],
        [ 0.0346, -0.0048, -0.0196,  ..., -0.0008, -0.0481, -0.0151],
        [-0.0034,  0.0091,  0.0039,  ..., -0.0047,  0.0017, -0.0073],
        ...,
        [-0.0277, -0.0315,  0.0064,  ..., -0.0131, -0.0027,  0.0125],
        [ 0.0013,  0.0095,  0.0286,  ..., -0.0024,  0.0112,  0.0018],
        [-0.0154,  0.0043, -0.0169,  ...,  0.0051,  0.0013, -0.0213]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias': tensor([0.0214, 0.0242, 0.0006,  ..., 0.0194, 0.0418, 0.0340],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight': tensor([[-0.0110, -0.0187, -0.0399,  ..., -0.0132,  0.0016,  0.0080],
        [ 0.0197,  0.0169,  0.0061,  ..., -0.0240,  0.0292,  0.0127],
        [-0.0047, -0.0227, -0.0048,  ..., -0.0150, -0.0014,  0.0108],
        ...,
        [-0.0113,  0.0006, -0.0214,  ..., -0.0389, -0.0254,  0.0096],
        [ 0.0066,  0.0193,  0.0392,  ...,  0.0004,  0.0306, -0.0154],
        [-0.0041,  0.0141, -0.0124,  ..., -0.0156, -0.0206,  0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias': tensor([-0.0377, -0.0410, -0.0185,  ..., -0.2778,  0.1395,  0.1525],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight': tensor([[-1.2112e-03,  2.4259e-05, -4.5753e-04,  ...,  4.1847e-03,
          3.2597e-03, -3.2745e-02],
        [-1.3557e-02, -5.1613e-03,  2.0218e-02,  ..., -7.0801e-03,
         -2.9678e-02, -3.8872e-03],
        [-2.0355e-02, -4.8676e-03,  1.2039e-02,  ...,  1.1337e-02,
         -5.5161e-03, -1.0376e-02],
        ...,
        [ 1.2032e-02,  1.7944e-02, -4.4212e-03,  ...,  3.3722e-02,
         -1.9394e-02, -2.0691e-02],
        [-1.6998e-02,  2.0340e-02, -9.7885e-03,  ..., -4.0588e-03,
          4.5967e-03, -7.2937e-03],
        [-1.6357e-02, -1.8204e-02,  1.9684e-02,  ...,  1.2749e-02,
         -2.2552e-02, -1.4832e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias': tensor([-0.0427,  0.0264, -0.0947,  ..., -0.0744, -0.0230, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight': tensor([1.6475, 1.5273, 1.6768,  ..., 1.8574, 1.4951, 1.6426],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias': tensor([-0.0313, -0.3167, -0.0297,  ..., -0.0391, -0.0746, -0.2402],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight': tensor([[-0.0260, -0.0154,  0.0028,  ..., -0.0228, -0.0295, -0.0447],
        [ 0.0029, -0.0058,  0.0197,  ...,  0.0138,  0.0183,  0.0026],
        [ 0.0218, -0.0178,  0.0015,  ..., -0.0087,  0.0014,  0.0125],
        ...,
        [ 0.0404,  0.0179, -0.0153,  ...,  0.0049,  0.0196, -0.0120],
        [ 0.0015, -0.0189,  0.0088,  ...,  0.0184, -0.0162, -0.0341],
        [ 0.0035, -0.0139, -0.0161,  ...,  0.0040, -0.0222, -0.0067]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias': tensor([-0.3091, -0.1617, -0.2668,  ..., -0.2510, -0.2261, -0.2350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight': tensor([[-0.0030, -0.0123, -0.0188,  ...,  0.0186, -0.0332, -0.0181],
        [ 0.0014, -0.0037, -0.0307,  ..., -0.0058,  0.0160,  0.0274],
        [ 0.0273, -0.0119, -0.0110,  ..., -0.0013, -0.0041, -0.0059],
        ...,
        [ 0.0018, -0.0187, -0.0384,  ...,  0.0141,  0.0053,  0.0090],
        [ 0.0151, -0.0128, -0.0045,  ...,  0.0167, -0.0064,  0.0077],
        [ 0.0001,  0.0021,  0.0336,  ..., -0.0046, -0.0128,  0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias': tensor([ 0.1198, -0.0191,  0.1595,  ..., -0.0292, -0.0284, -0.0580],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight': tensor([3.1777, 3.2344, 3.2090,  ..., 1.1455, 2.6172, 3.2363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias': tensor([-0.3699,  0.0534, -0.3181,  ...,  0.1720,  0.3350, -0.2013],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight': tensor([[ 0.0132,  0.0254, -0.0020,  ..., -0.0305,  0.0047,  0.0051],
        [ 0.0022, -0.0257,  0.0199,  ..., -0.0184,  0.0286,  0.0047],
        [-0.0092, -0.0116,  0.0196,  ..., -0.0357,  0.0290,  0.0171],
        ...,
        [ 0.0071, -0.0053,  0.0001,  ..., -0.0139, -0.0043, -0.0191],
        [-0.0128,  0.0084, -0.0034,  ..., -0.0035, -0.0175, -0.0111],
        [ 0.0023, -0.0036, -0.0063,  ...,  0.0125, -0.0132,  0.0166]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias': tensor([ 2.2266,  1.3135, -0.9771,  ...,  0.3726,  2.3047,  0.1869],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight': tensor([[-0.0117,  0.0124, -0.0160,  ...,  0.0026,  0.0036,  0.0293],
        [ 0.0022, -0.0097, -0.0008,  ..., -0.0094,  0.0017, -0.0152],
        [-0.0117, -0.0052, -0.0132,  ...,  0.0201,  0.0020, -0.0049],
        ...,
        [ 0.0122, -0.0035, -0.0111,  ..., -0.0017,  0.0214,  0.0207],
        [-0.0134,  0.0110, -0.0031,  ...,  0.0010,  0.0070,  0.0225],
        [ 0.0003,  0.0153,  0.0004,  ...,  0.0096,  0.0122,  0.0161]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias': tensor([ 0.0095, -0.0149, -0.0342,  ...,  0.0316,  0.0107, -0.0553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight': tensor([[ 2.4475e-02,  1.0361e-02, -3.1738e-03,  ...,  6.3629e-03,
         -4.1161e-03,  4.0770e-05],
        [ 6.4735e-03, -1.1032e-02, -4.1046e-03,  ...,  2.4471e-03,
         -7.7009e-04,  3.3226e-03],
        [-2.2324e-02, -5.0497e-04, -2.1210e-02,  ..., -6.5186e-02,
         -3.9253e-03, -4.9324e-03],
        ...,
        [ 7.4692e-03, -2.1229e-03, -2.2095e-02,  ..., -3.7079e-02,
         -3.3173e-02,  2.9621e-03],
        [-2.3987e-02, -1.8463e-03, -3.8791e-04,  ..., -1.6312e-02,
         -2.0157e-02,  1.9180e-02],
        [ 5.5695e-03, -1.0750e-02,  1.4153e-03,  ...,  1.7136e-02,
         -1.8829e-02, -3.1219e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias': tensor([ 0.0942, -0.0380, -0.0066,  ..., -0.2206,  0.0908,  0.0343],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight': tensor([[ 0.0108, -0.0169,  0.0143,  ..., -0.0040, -0.0186, -0.0120],
        [-0.0099,  0.0158, -0.0007,  ..., -0.0126,  0.0125, -0.0013],
        [ 0.0059, -0.0186,  0.0080,  ...,  0.0038,  0.0261, -0.0122],
        ...,
        [ 0.0193, -0.0006, -0.0168,  ..., -0.0111, -0.0033,  0.0045],
        [ 0.0071,  0.0175, -0.0099,  ...,  0.0238,  0.0111,  0.0132],
        [ 0.0269,  0.0227,  0.0074,  ..., -0.0048, -0.0153, -0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias': tensor([ 0.1117, -0.0344, -0.0097,  ..., -0.0479, -0.0558, -0.0235],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight': tensor([1.5781, 1.5361, 1.5830,  ..., 0.8071, 1.4404, 1.7129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias': tensor([ 0.0493, -0.2202, -0.1034,  ...,  0.0678, -0.1000, -0.2034],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight': tensor([[-0.0206, -0.0153,  0.0054,  ...,  0.0216,  0.0042, -0.0064],
        [-0.0240,  0.0083,  0.0154,  ..., -0.0026,  0.0077, -0.0042],
        [ 0.0143,  0.0016,  0.0010,  ...,  0.0362,  0.0050,  0.0193],
        ...,
        [ 0.0191,  0.0038,  0.0125,  ..., -0.0049, -0.0139, -0.0164],
        [ 0.0050,  0.0037,  0.0237,  ..., -0.0271,  0.0079, -0.0093],
        [ 0.0163,  0.0038, -0.0141,  ..., -0.0026, -0.0191,  0.0084]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias': tensor([-0.2673, -0.2559, -0.2236,  ..., -0.2888, -0.2781, -0.0958],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight': tensor([[-0.0093, -0.0160, -0.0221,  ...,  0.0137, -0.0174, -0.0188],
        [-0.0096,  0.0156, -0.0179,  ..., -0.0231,  0.0060, -0.0123],
        [ 0.0032, -0.0022,  0.0147,  ..., -0.0053,  0.0070,  0.0076],
        ...,
        [-0.0122, -0.0089,  0.0011,  ...,  0.0205,  0.0041, -0.0117],
        [ 0.0056, -0.0073, -0.0155,  ..., -0.0081, -0.0361,  0.0044],
        [ 0.0310,  0.0010,  0.0081,  ..., -0.0060, -0.0118, -0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias': tensor([-0.0192, -0.0717,  0.1105,  ..., -0.1528,  0.0851, -0.0401],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight': tensor([3.1602, 3.0371, 2.9180,  ..., 1.5098, 2.5527, 3.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias': tensor([ 0.2227,  0.6216, -0.4958,  ...,  0.2568,  0.0677, -0.4553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight': tensor([[ 0.0037,  0.0141,  0.0131,  ...,  0.0058,  0.0128,  0.0105],
        [ 0.0020, -0.0168, -0.0078,  ...,  0.0242, -0.0173, -0.0008],
        [ 0.0030,  0.0062, -0.0284,  ..., -0.0097,  0.0236,  0.0083],
        ...,
        [-0.0080, -0.0243, -0.0079,  ..., -0.0201, -0.0240, -0.0208],
        [ 0.0029,  0.0056,  0.0167,  ...,  0.0065, -0.0012, -0.0019],
        [-0.0047, -0.0198, -0.0200,  ...,  0.0153,  0.0093, -0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias': tensor([ 0.9746, -1.5684,  4.0703,  ..., -4.7695,  2.3730,  0.0641],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight': tensor([[-0.0094,  0.0040, -0.0081,  ...,  0.0087,  0.0034, -0.0086],
        [-0.0218, -0.0027,  0.0096,  ...,  0.0072, -0.0114, -0.0138],
        [-0.0069,  0.0196,  0.0128,  ...,  0.0089, -0.0430,  0.0282],
        ...,
        [ 0.0080, -0.0076,  0.0247,  ..., -0.0006,  0.0264, -0.0060],
        [-0.0081,  0.0084,  0.0222,  ...,  0.0080, -0.0070,  0.0124],
        [-0.0113,  0.0073,  0.0137,  ..., -0.0100, -0.0085,  0.0073]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias': tensor([-0.0650, -0.0600,  0.0630,  ..., -0.0726,  0.0070, -0.1204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight': tensor([[ 0.0016,  0.0027, -0.0018,  ...,  0.0349, -0.0049, -0.0009],
        [ 0.0076,  0.0003, -0.0250,  ...,  0.0064,  0.0064,  0.0147],
        [-0.0011, -0.0325, -0.0602,  ...,  0.0003, -0.0238,  0.0107],
        ...,
        [ 0.0233,  0.0226,  0.0270,  ...,  0.0236, -0.0239, -0.0167],
        [ 0.0041, -0.0097, -0.0143,  ..., -0.0173, -0.0098,  0.0124],
        [ 0.0090, -0.0034,  0.0003,  ...,  0.0278,  0.0114,  0.0061]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias': tensor([-0.4348, -0.0033, -0.1771,  ..., -0.0897,  0.1703,  0.3945],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight': tensor([[ 0.0021,  0.0206, -0.0078,  ..., -0.0072, -0.0010,  0.0115],
        [ 0.0005,  0.0042, -0.0142,  ...,  0.0190, -0.0119, -0.0008],
        [ 0.0061, -0.0182,  0.0112,  ..., -0.0376, -0.0023, -0.0042],
        ...,
        [-0.0143,  0.0111, -0.0015,  ..., -0.0087,  0.0175, -0.0019],
        [-0.0039,  0.0022,  0.0231,  ..., -0.0050,  0.0082, -0.0150],
        [ 0.0005, -0.0005, -0.0158,  ..., -0.0120, -0.0067, -0.0141]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias': tensor([-0.0269, -0.0574,  0.0638,  ..., -0.1498,  0.0551, -0.1482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight': tensor([1.5703, 1.8379, 1.9336,  ..., 0.8516, 1.4707, 1.7686],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias': tensor([0.3889, 0.2372, 0.1531,  ..., 0.6260, 0.2163, 0.1549],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight': tensor([[-1.1892e-03,  3.9005e-03, -5.7487e-03,  ...,  4.7989e-03,
         -4.2915e-03, -2.5539e-03],
        [ 1.5236e-02, -2.3232e-03, -3.3325e-02,  ...,  2.3758e-02,
         -1.0595e-03, -3.8986e-03],
        [ 2.0737e-02,  7.2479e-03, -3.0842e-03,  ..., -5.4207e-03,
          2.6047e-02, -1.4210e-03],
        ...,
        [ 7.4120e-03, -2.9163e-03,  3.3661e-02,  ..., -4.4785e-03,
          9.1400e-03, -1.5297e-02],
        [-4.3964e-04,  8.5297e-03, -1.5350e-02,  ..., -1.3519e-02,
         -6.6490e-03,  5.9700e-04],
        [-7.5579e-05,  1.0449e-04,  8.8196e-03,  ..., -1.0658e-02,
         -6.6032e-03, -5.4703e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias': tensor([-0.3184, -0.2345, -0.2834,  ..., -0.2498, -0.1849, -0.2729],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight': tensor([[ 0.0369,  0.0093, -0.0179,  ..., -0.0141, -0.0035,  0.0064],
        [ 0.0050,  0.0101,  0.0117,  ...,  0.0070, -0.0066, -0.0147],
        [-0.0015,  0.0263,  0.0119,  ..., -0.0270,  0.0052, -0.0028],
        ...,
        [ 0.0133,  0.0236, -0.0152,  ...,  0.0251, -0.0268, -0.0321],
        [ 0.0021, -0.0061,  0.0079,  ..., -0.0029,  0.0145, -0.0033],
        [-0.0097,  0.0175, -0.0111,  ..., -0.0278, -0.0016, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias': tensor([-0.1587, -0.0068,  0.1970,  ...,  0.0549, -0.0199,  0.0069],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight': tensor([2.5664, 2.3809, 2.5742,  ..., 1.8262, 2.4121, 2.7520],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias': tensor([ 0.1838,  0.3330, -0.2296,  ..., -0.1086,  0.5938, -0.2812],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight': tensor([[ 0.0305, -0.0035, -0.0098,  ...,  0.0054, -0.0111,  0.0049],
        [-0.0194,  0.0099,  0.0032,  ...,  0.0125,  0.0277, -0.0057],
        [ 0.0115,  0.0072, -0.0170,  ...,  0.0162,  0.0032,  0.0142],
        ...,
        [ 0.0076, -0.0034,  0.0187,  ...,  0.0278, -0.0174, -0.0046],
        [-0.0037, -0.0002,  0.0051,  ..., -0.0108,  0.0012,  0.0065],
        [-0.0047, -0.0013,  0.0154,  ...,  0.0158, -0.0106,  0.0013]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias': tensor([-0.0001,  0.0002, -0.0072,  ...,  0.0011, -0.0007, -0.0008],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight': tensor([[ 0.0221, -0.0052,  0.0127,  ..., -0.0090, -0.0092, -0.0165],
        [-0.0569, -0.0251, -0.0167,  ..., -0.0070, -0.0093, -0.0182],
        [-0.0159, -0.0159,  0.0239,  ...,  0.0133,  0.0071,  0.0088],
        ...,
        [ 0.0025,  0.0141, -0.0087,  ...,  0.0007, -0.0157, -0.0012],
        [ 0.0053,  0.0023, -0.0199,  ...,  0.0264,  0.0148, -0.0300],
        [-0.0040,  0.0095, -0.0180,  ..., -0.0396, -0.0316, -0.0156]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias': tensor([-0.0095, -0.0084,  0.0243,  ...,  0.1217, -0.0273,  0.0116],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight': tensor([[ 1.3329e-02, -5.8022e-03,  2.2945e-03,  ...,  1.0509e-03,
          2.1591e-02, -3.7422e-03],
        [-1.7593e-02,  9.9182e-03,  2.1652e-02,  ..., -1.7380e-02,
         -1.1452e-02, -1.1536e-02],
        [-4.2648e-03,  3.6955e-06,  8.7585e-03,  ...,  5.5428e-03,
          1.0963e-02, -8.2855e-03],
        ...,
        [ 2.6302e-03, -6.2828e-03,  1.8387e-02,  ...,  2.4658e-02,
         -1.4015e-02, -1.8509e-02],
        [-1.9140e-03, -1.3588e-02, -1.2770e-03,  ..., -1.8143e-02,
         -2.0309e-02, -2.0172e-02],
        [-1.6346e-03,  5.2338e-03, -1.7044e-02,  ..., -4.7073e-03,
          1.5930e-02,  1.8097e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias': tensor([ 0.0486, -0.0525, -1.9268,  ...,  0.0309,  0.1466, -0.0662],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight': tensor([[-0.0204,  0.0447, -0.0052,  ...,  0.0069,  0.0077,  0.0218],
        [ 0.0017,  0.0142, -0.0191,  ...,  0.0062, -0.0003,  0.0145],
        [-0.0078,  0.0171, -0.0142,  ..., -0.0220,  0.0106,  0.0089],
        ...,
        [-0.0215, -0.0144, -0.0043,  ...,  0.0026, -0.0030,  0.0222],
        [ 0.0184,  0.0181,  0.0050,  ...,  0.0064, -0.0177,  0.0218],
        [ 0.0176,  0.0081, -0.0153,  ..., -0.0053,  0.0065,  0.0165]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias': tensor([-0.2126,  0.1382,  0.1891,  ...,  0.0073,  0.0610, -0.0497],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight': tensor([1.5518, 1.4453, 1.4551,  ..., 0.8970, 1.4531, 1.5488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias': tensor([-0.0075, -0.0621, -0.0674,  ..., -0.0965, -0.1760, -0.1098],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight': tensor([[ 0.0173, -0.0038, -0.0434,  ..., -0.0142, -0.0269,  0.0163],
        [ 0.0112,  0.0112, -0.0199,  ...,  0.0013,  0.0100, -0.0072],
        [-0.0037, -0.0045, -0.0143,  ..., -0.0011, -0.0073, -0.0100],
        ...,
        [-0.0162, -0.0028, -0.0142,  ...,  0.0240, -0.0207, -0.0169],
        [ 0.0084,  0.0172, -0.0097,  ..., -0.0170, -0.0171, -0.0099],
        [ 0.0414, -0.0024, -0.0073,  ..., -0.0142,  0.0116,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias': tensor([-0.2035, -0.6177, -0.2632,  ..., -0.2837, -0.4905, -0.3960],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight': tensor([[-0.0123, -0.0106,  0.0170,  ..., -0.0074, -0.0057,  0.0038],
        [ 0.0014, -0.0104, -0.0019,  ...,  0.0073,  0.0064, -0.0129],
        [-0.0083, -0.0003,  0.0169,  ...,  0.0021,  0.0054,  0.0217],
        ...,
        [-0.0205, -0.0112, -0.0028,  ..., -0.0033,  0.0101,  0.0241],
        [ 0.0122, -0.0082,  0.0100,  ..., -0.0086,  0.0083, -0.0369],
        [ 0.0042, -0.0036,  0.0006,  ..., -0.0066,  0.0024,  0.0018]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias': tensor([ 0.0215, -0.1328, -0.1233,  ..., -0.1167,  0.0634,  0.0916],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight': tensor([1.6230, 1.6143, 1.6387,  ..., 1.4531, 1.7188, 1.8516],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias': tensor([-0.0200, -0.0892,  0.0742,  ...,  0.0301,  0.1517, -0.2600],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight': tensor([0.9370, 1.0215, 0.9346,  ..., 0.8223, 1.0596, 1.0498],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias': tensor([-0.0060,  0.1511, -0.0550,  ...,  0.2749,  0.0767,  0.0092],
       dtype=torch.float16), 'model.mm_projector.weight': tensor([[ 0.0031, -0.0038,  0.0044,  ...,  0.0163,  0.0216, -0.0032],
        [ 0.0029,  0.0218,  0.0182,  ..., -0.0047, -0.0289,  0.0210],
        [ 0.0263,  0.0263,  0.0170,  ...,  0.0143, -0.0207, -0.0080],
        ...,
        [-0.0240, -0.0241, -0.0118,  ...,  0.0040, -0.0292,  0.0034],
        [ 0.0108,  0.0275, -0.0305,  ...,  0.0255,  0.0058,  0.0152],
        [-0.0197, -0.0239, -0.0016,  ...,  0.0118,  0.0253, -0.0117]]), 'model.mm_projector.bias': tensor([ 0.0153,  0.0060, -0.0080,  ...,  0.0104,  0.0131,  0.0242]), 'model.perceiver.latents': tensor([[ 2.0717, -1.4360,  2.1796,  ..., -0.1818,  1.1309, -0.6769],
        [-1.7342,  1.2962, -0.7309,  ...,  1.9703, -1.1948,  0.9907],
        [ 0.8056, -0.5275, -0.8418,  ...,  1.8479, -0.9080,  0.4187],
        ...,
        [ 0.0424,  0.1589,  2.0919,  ...,  0.2311, -0.1129, -0.2157],
        [-1.9530, -1.3639, -1.8479,  ...,  0.0804, -0.1098,  1.3702],
        [-2.8532, -1.0289,  0.7482,  ..., -0.1953,  0.1731,  0.6296]]), 'model.perceiver.frame_embs': tensor([[-1.4623,  0.1606,  0.5381,  ...,  0.8702,  0.0474, -0.6712],
        [-0.9250, -0.2551, -0.3919,  ..., -0.7468,  1.5138,  0.4552],
        [-0.0263,  0.4774, -0.0320,  ...,  0.6468, -1.1539,  0.6281],
        ...,
        [-0.1015,  1.9338, -0.8297,  ..., -0.2315, -0.2072, -2.3773],
        [ 0.2911,  0.0286, -1.3912,  ...,  1.9721, -0.1162,  0.6042],
        [-1.2499, -0.5335, -0.0119,  ..., -0.0362,  0.3161,  1.0096]]), 'model.perceiver.media_time_embs': tensor([[[-0.6426,  0.0305, -0.6247,  ..., -0.7765, -0.1258,  0.0693]],

        [[-0.7319,  0.7329, -0.2821,  ...,  0.4507,  0.9545, -0.1699]],

        [[ 1.1136,  0.1984,  0.1590,  ..., -1.9030, -1.1514, -0.8021]],

        [[ 0.2183,  0.7179, -0.1993,  ...,  0.5184, -1.1715,  0.6396]]]), 'model.perceiver.layers.0.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.to_q.weight': tensor([[ 5.2404e-03,  3.0568e-05, -1.2780e-02,  ..., -8.8356e-03,
         -6.3919e-03,  1.3262e-02],
        [-5.6720e-04,  6.8746e-03, -9.1203e-03,  ...,  1.3237e-02,
          8.6196e-03, -1.2371e-02],
        [ 8.5307e-03, -6.2927e-03,  1.1469e-03,  ..., -3.6496e-03,
          7.0988e-03, -1.2379e-02],
        ...,
        [-1.1258e-02,  1.2088e-03, -3.7754e-03,  ...,  1.0336e-02,
          1.2864e-02,  8.4523e-04],
        [-4.7963e-03, -8.7829e-03, -1.2332e-02,  ..., -9.6933e-03,
         -1.5382e-02, -1.1244e-02],
        [ 1.4681e-02, -3.7236e-04, -1.5513e-02,  ..., -1.4590e-02,
         -1.5974e-03,  1.3095e-02]]), 'model.perceiver.layers.0.0.to_kv.weight': tensor([[-0.0009, -0.0092, -0.0021,  ..., -0.0080,  0.0156,  0.0096],
        [-0.0065, -0.0100,  0.0154,  ..., -0.0004, -0.0103,  0.0070],
        [-0.0067,  0.0033, -0.0077,  ...,  0.0096, -0.0019,  0.0091],
        ...,
        [-0.0119, -0.0085,  0.0032,  ...,  0.0011,  0.0082,  0.0010],
        [-0.0011,  0.0027, -0.0083,  ..., -0.0040,  0.0112,  0.0119],
        [ 0.0119, -0.0109,  0.0034,  ...,  0.0024,  0.0135,  0.0082]]), 'model.perceiver.layers.0.0.to_out.weight': tensor([[ 0.0417,  0.0421, -0.0184,  ...,  0.0228,  0.0205,  0.0308],
        [-0.0418,  0.0439,  0.0017,  ...,  0.0442, -0.0047, -0.0356],
        [-0.0200, -0.0314, -0.0125,  ...,  0.0080, -0.0302,  0.0420],
        ...,
        [-0.0364,  0.0394,  0.0264,  ...,  0.0245, -0.0035,  0.0081],
        [ 0.0394,  0.0418,  0.0236,  ..., -0.0202, -0.0439,  0.0340],
        [-0.0125, -0.0206,  0.0089,  ...,  0.0015, -0.0052,  0.0409]]), 'model.perceiver.layers.0.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.1.1.weight': tensor([[-1.4321e-02,  6.6300e-03, -1.2915e-02,  ..., -1.1266e-02,
         -1.5061e-02,  9.3982e-03],
        [ 6.0592e-03,  3.5808e-03, -4.1655e-03,  ...,  6.1558e-03,
         -1.1069e-02,  1.5379e-03],
        [ 4.2834e-03,  1.1654e-03,  4.9101e-03,  ..., -8.4549e-04,
          2.8292e-05,  1.0479e-02],
        ...,
        [-3.3944e-03, -4.0425e-03, -3.4012e-04,  ..., -2.8710e-03,
         -7.8204e-03, -9.1240e-03],
        [-3.5593e-03,  7.0310e-03, -1.3461e-02,  ...,  9.6475e-03,
         -5.6917e-03, -4.0005e-03],
        [-1.7532e-03,  1.1876e-02, -3.6710e-03,  ...,  1.3172e-02,
          1.4574e-02,  9.2694e-03]]), 'model.perceiver.layers.0.1.3.weight': tensor([[ 1.4276e-03, -4.8294e-03,  2.5003e-03,  ..., -1.9543e-03,
          1.4089e-03,  5.7318e-03],
        [-1.5457e-03,  3.9810e-04,  5.5453e-03,  ...,  3.5269e-03,
          5.4321e-03, -6.1059e-03],
        [-2.1816e-03,  4.4497e-03,  1.4374e-03,  ...,  3.1758e-03,
         -6.4783e-03,  8.7882e-04],
        ...,
        [ 3.2050e-03,  5.7856e-03,  5.0029e-03,  ...,  2.4069e-03,
          6.2870e-03,  6.7278e-03],
        [ 4.4133e-03,  7.3016e-03,  7.7867e-03,  ...,  2.3923e-03,
          7.4354e-03,  3.4398e-03],
        [-3.9775e-03, -6.1533e-03, -2.0705e-03,  ...,  3.4947e-05,
         -7.7436e-03,  1.4881e-03]]), 'model.perceiver.layers.1.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.to_q.weight': tensor([[-0.0014,  0.0008,  0.0104,  ...,  0.0112,  0.0083, -0.0085],
        [ 0.0046, -0.0071, -0.0145,  ...,  0.0048,  0.0095,  0.0031],
        [-0.0055, -0.0071, -0.0079,  ..., -0.0088, -0.0021, -0.0065],
        ...,
        [-0.0117, -0.0105, -0.0137,  ...,  0.0063,  0.0051,  0.0006],
        [-0.0075, -0.0119, -0.0013,  ...,  0.0146, -0.0151,  0.0084],
        [-0.0114,  0.0039, -0.0140,  ..., -0.0027, -0.0041,  0.0082]]), 'model.perceiver.layers.1.0.to_kv.weight': tensor([[ 0.0149, -0.0060, -0.0042,  ...,  0.0073, -0.0049,  0.0021],
        [ 0.0148,  0.0082,  0.0007,  ...,  0.0038,  0.0123, -0.0155],
        [-0.0076,  0.0026, -0.0001,  ...,  0.0044,  0.0053, -0.0083],
        ...,
        [-0.0051,  0.0095, -0.0058,  ...,  0.0106, -0.0072,  0.0073],
        [ 0.0155,  0.0099,  0.0127,  ..., -0.0067,  0.0032, -0.0068],
        [-0.0146, -0.0121, -0.0047,  ...,  0.0091,  0.0077, -0.0002]]), 'model.perceiver.layers.1.0.to_out.weight': tensor([[ 0.0426, -0.0284, -0.0322,  ...,  0.0023, -0.0109, -0.0038],
        [ 0.0388,  0.0333,  0.0392,  ...,  0.0079,  0.0192, -0.0209],
        [ 0.0220, -0.0062,  0.0431,  ..., -0.0270, -0.0219,  0.0135],
        ...,
        [ 0.0053, -0.0154, -0.0296,  ..., -0.0173,  0.0372, -0.0200],
        [ 0.0093,  0.0096, -0.0410,  ..., -0.0322, -0.0174, -0.0199],
        [-0.0310, -0.0089,  0.0140,  ..., -0.0019,  0.0197,  0.0222]]), 'model.perceiver.layers.1.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.1.1.weight': tensor([[-0.0026,  0.0089, -0.0019,  ...,  0.0021,  0.0002,  0.0055],
        [ 0.0027, -0.0022,  0.0038,  ..., -0.0070, -0.0045,  0.0148],
        [ 0.0062,  0.0022, -0.0062,  ...,  0.0072,  0.0064, -0.0144],
        ...,
        [-0.0099, -0.0022,  0.0073,  ...,  0.0122, -0.0024,  0.0142],
        [-0.0050,  0.0048, -0.0085,  ...,  0.0047, -0.0035, -0.0004],
        [-0.0068, -0.0109, -0.0079,  ..., -0.0111, -0.0121, -0.0077]]), 'model.perceiver.layers.1.1.3.weight': tensor([[-0.0016, -0.0007, -0.0011,  ...,  0.0078,  0.0030,  0.0021],
        [ 0.0003,  0.0063, -0.0035,  ..., -0.0032,  0.0038,  0.0055],
        [ 0.0011, -0.0003,  0.0005,  ...,  0.0040, -0.0059,  0.0033],
        ...,
        [ 0.0013,  0.0061,  0.0056,  ..., -0.0053,  0.0071,  0.0068],
        [-0.0034,  0.0033, -0.0071,  ...,  0.0026, -0.0071, -0.0057],
        [ 0.0053,  0.0063, -0.0024,  ...,  0.0063,  0.0005, -0.0068]]), 'model.perceiver.layers.2.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.to_q.weight': tensor([[ 1.2352e-02, -1.5513e-02, -9.5613e-04,  ...,  1.1438e-02,
         -7.2911e-03,  5.7808e-03],
        [-7.5773e-03, -3.8840e-03,  1.4682e-02,  ...,  3.1637e-04,
         -9.8864e-03,  1.1930e-02],
        [-1.1287e-02,  5.6153e-03, -7.3370e-03,  ..., -1.4142e-02,
          3.1855e-05, -9.2632e-03],
        ...,
        [-1.5463e-02,  4.8094e-03,  8.7140e-03,  ..., -1.9543e-03,
         -1.4730e-02,  1.2616e-02],
        [ 9.3560e-03, -1.1514e-02, -1.0462e-02,  ...,  1.2367e-02,
          1.4265e-02,  1.4059e-03],
        [ 8.9342e-03, -3.7449e-03,  1.3571e-02,  ...,  1.0665e-02,
         -5.3101e-03, -5.4739e-03]]), 'model.perceiver.layers.2.0.to_kv.weight': tensor([[-0.0154, -0.0058,  0.0128,  ...,  0.0054, -0.0150, -0.0088],
        [ 0.0088,  0.0007,  0.0015,  ...,  0.0017,  0.0041, -0.0086],
        [-0.0091, -0.0137,  0.0143,  ...,  0.0059, -0.0042, -0.0103],
        ...,
        [ 0.0038, -0.0054,  0.0031,  ...,  0.0134,  0.0116,  0.0019],
        [-0.0126,  0.0141,  0.0030,  ..., -0.0070,  0.0055,  0.0091],
        [ 0.0123,  0.0088, -0.0135,  ..., -0.0094, -0.0105,  0.0123]]), 'model.perceiver.layers.2.0.to_out.weight': tensor([[-0.0387,  0.0357, -0.0116,  ...,  0.0347, -0.0200,  0.0328],
        [-0.0069, -0.0025,  0.0150,  ..., -0.0206, -0.0378,  0.0396],
        [ 0.0359,  0.0091, -0.0175,  ..., -0.0130, -0.0400,  0.0119],
        ...,
        [-0.0233,  0.0205, -0.0179,  ..., -0.0219,  0.0071, -0.0425],
        [-0.0141,  0.0415,  0.0396,  ..., -0.0273, -0.0163,  0.0391],
        [-0.0283,  0.0240, -0.0284,  ...,  0.0378,  0.0343, -0.0138]]), 'model.perceiver.layers.2.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.1.1.weight': tensor([[ 0.0141, -0.0106, -0.0081,  ...,  0.0042,  0.0112,  0.0104],
        [-0.0105,  0.0146,  0.0152,  ..., -0.0003, -0.0096,  0.0030],
        [-0.0072, -0.0100,  0.0156,  ...,  0.0003, -0.0122, -0.0076],
        ...,
        [-0.0065, -0.0035,  0.0122,  ..., -0.0153,  0.0019, -0.0150],
        [-0.0117, -0.0120, -0.0006,  ...,  0.0047, -0.0089,  0.0152],
        [-0.0142,  0.0036,  0.0120,  ...,  0.0054,  0.0102,  0.0034]]), 'model.perceiver.layers.2.1.3.weight': tensor([[ 0.0002, -0.0052, -0.0009,  ...,  0.0026, -0.0014,  0.0035],
        [ 0.0010,  0.0040, -0.0044,  ...,  0.0003, -0.0032, -0.0072],
        [ 0.0028,  0.0050,  0.0005,  ...,  0.0073,  0.0031, -0.0005],
        ...,
        [ 0.0064, -0.0002,  0.0054,  ...,  0.0001, -0.0037, -0.0071],
        [-0.0077,  0.0036, -0.0003,  ..., -0.0004, -0.0028, -0.0051],
        [-0.0053, -0.0048, -0.0076,  ...,  0.0049, -0.0028, -0.0056]]), 'model.perceiver.layers.3.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.to_q.weight': tensor([[ 0.0117, -0.0066,  0.0029,  ..., -0.0087,  0.0099,  0.0002],
        [ 0.0131, -0.0078,  0.0121,  ...,  0.0031,  0.0042, -0.0145],
        [-0.0135, -0.0029, -0.0138,  ..., -0.0130, -0.0009, -0.0129],
        ...,
        [ 0.0053,  0.0135,  0.0128,  ..., -0.0120,  0.0036,  0.0020],
        [-0.0072,  0.0050,  0.0018,  ..., -0.0110,  0.0117, -0.0088],
        [-0.0013, -0.0033, -0.0079,  ...,  0.0055,  0.0114, -0.0155]]), 'model.perceiver.layers.3.0.to_kv.weight': tensor([[-2.8077e-03,  1.5021e-02, -1.5366e-02,  ..., -1.1518e-02,
         -1.5226e-02, -9.9172e-03],
        [ 2.0666e-03,  4.9896e-03, -3.2814e-03,  ...,  8.6764e-03,
          9.1761e-03, -1.0305e-02],
        [ 7.0848e-03, -8.0841e-03, -1.5331e-02,  ..., -7.4694e-03,
         -3.2154e-03,  6.6058e-03],
        ...,
        [-7.1381e-04,  4.6340e-03, -1.5196e-02,  ...,  2.5226e-03,
         -4.6169e-03,  3.7448e-05],
        [-1.1028e-02, -1.2993e-02, -8.7499e-03,  ...,  1.0987e-03,
          5.8264e-03, -1.4163e-02],
        [-8.0263e-03, -5.3410e-03, -3.7924e-04,  ..., -3.4743e-03,
         -1.4409e-02, -2.2751e-03]]), 'model.perceiver.layers.3.0.to_out.weight': tensor([[ 0.0079,  0.0143,  0.0336,  ...,  0.0092, -0.0155, -0.0276],
        [ 0.0439, -0.0072,  0.0010,  ..., -0.0314, -0.0200,  0.0003],
        [-0.0160, -0.0001,  0.0235,  ..., -0.0193,  0.0273, -0.0188],
        ...,
        [-0.0303,  0.0013, -0.0016,  ..., -0.0069, -0.0041,  0.0380],
        [ 0.0368,  0.0398, -0.0371,  ...,  0.0383,  0.0366, -0.0183],
        [-0.0289, -0.0072,  0.0354,  ..., -0.0168,  0.0197, -0.0370]]), 'model.perceiver.layers.3.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.1.1.weight': tensor([[ 1.4298e-02,  1.2781e-02, -2.5387e-03,  ..., -2.0649e-03,
         -1.0538e-02, -1.4663e-02],
        [-1.5095e-02,  1.3688e-02, -1.9498e-03,  ..., -8.5541e-03,
         -6.7959e-03, -5.2258e-05],
        [-1.0174e-02, -1.3479e-02,  1.1456e-02,  ..., -1.5224e-02,
         -1.0196e-02,  1.0925e-02],
        ...,
        [ 1.2564e-02, -5.0760e-03, -1.1598e-02,  ...,  1.4362e-03,
          1.3003e-02, -1.5177e-02],
        [-1.3353e-03, -1.4244e-02, -1.2164e-02,  ...,  1.0201e-02,
          1.0213e-02, -2.1221e-03],
        [ 1.0900e-02, -3.7520e-04, -1.4041e-02,  ..., -6.1316e-03,
         -1.1767e-02,  1.4060e-02]]), 'model.perceiver.layers.3.1.3.weight': tensor([[-9.6519e-05,  4.7265e-03,  6.6571e-03,  ..., -5.3751e-03,
          4.1589e-03, -7.4800e-03],
        [-6.7357e-03, -6.0173e-03, -4.7203e-03,  ..., -6.5498e-03,
          4.2235e-03, -3.7006e-03],
        [ 3.7266e-03,  5.2000e-03, -1.1859e-03,  ...,  4.5811e-03,
          3.1226e-03,  4.0355e-03],
        ...,
        [-6.8012e-03,  5.0400e-03,  4.6964e-03,  ...,  2.8663e-05,
         -5.1661e-03, -2.0662e-03],
        [-6.6590e-03,  3.8641e-03,  1.5784e-03,  ..., -1.7153e-03,
         -5.8409e-03,  1.8867e-05],
        [-1.0533e-03, -6.0378e-03,  1.6737e-03,  ..., -6.3917e-03,
         -8.2617e-04,  2.5382e-03]]), 'model.perceiver.layers.4.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.to_q.weight': tensor([[-1.2143e-03, -4.7233e-03, -1.2887e-02,  ..., -3.2108e-03,
          5.4810e-03, -1.1176e-02],
        [ 8.1092e-03, -3.2471e-03,  5.3520e-03,  ...,  6.0055e-03,
          1.4834e-02,  1.4929e-02],
        [-7.6222e-03,  4.9835e-03, -1.2936e-03,  ...,  1.5490e-03,
          5.7003e-03,  6.9725e-03],
        ...,
        [ 5.3639e-03,  1.2132e-02,  6.4126e-03,  ..., -1.0561e-02,
          4.7516e-03, -1.5485e-02],
        [-1.1689e-03, -1.4043e-02,  8.5686e-04,  ...,  6.6995e-03,
         -4.4891e-03, -3.5157e-05],
        [-9.0911e-03,  6.2811e-03,  1.0441e-02,  ...,  1.5007e-02,
          9.7182e-03, -1.3290e-02]]), 'model.perceiver.layers.4.0.to_kv.weight': tensor([[ 0.0065, -0.0054,  0.0148,  ..., -0.0029,  0.0021, -0.0021],
        [ 0.0135, -0.0139,  0.0147,  ...,  0.0085,  0.0025,  0.0154],
        [-0.0149,  0.0138, -0.0145,  ..., -0.0106,  0.0115,  0.0066],
        ...,
        [-0.0124,  0.0081,  0.0048,  ..., -0.0100, -0.0146,  0.0092],
        [-0.0140, -0.0031,  0.0072,  ...,  0.0033, -0.0111,  0.0080],
        [ 0.0076, -0.0006,  0.0020,  ...,  0.0065,  0.0005,  0.0033]]), 'model.perceiver.layers.4.0.to_out.weight': tensor([[ 0.0017, -0.0185,  0.0242,  ...,  0.0282,  0.0109,  0.0107],
        [ 0.0229, -0.0304,  0.0078,  ...,  0.0048, -0.0099, -0.0414],
        [-0.0031, -0.0146,  0.0062,  ...,  0.0017,  0.0181,  0.0374],
        ...,
        [ 0.0088,  0.0343, -0.0067,  ...,  0.0290,  0.0118,  0.0295],
        [ 0.0232, -0.0146, -0.0190,  ..., -0.0242,  0.0432, -0.0348],
        [-0.0348, -0.0329,  0.0327,  ..., -0.0109,  0.0330,  0.0320]]), 'model.perceiver.layers.4.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.1.1.weight': tensor([[ 0.0064, -0.0131, -0.0004,  ...,  0.0131, -0.0016, -0.0036],
        [-0.0151,  0.0113,  0.0111,  ..., -0.0123,  0.0048, -0.0121],
        [ 0.0123, -0.0115, -0.0152,  ...,  0.0068,  0.0084, -0.0048],
        ...,
        [-0.0027, -0.0012, -0.0008,  ...,  0.0018,  0.0054, -0.0086],
        [-0.0047,  0.0029,  0.0127,  ..., -0.0148,  0.0053, -0.0103],
        [-0.0109,  0.0114,  0.0092,  ..., -0.0138, -0.0079,  0.0074]]), 'model.perceiver.layers.4.1.3.weight': tensor([[ 0.0076, -0.0013,  0.0005,  ..., -0.0070,  0.0037, -0.0013],
        [-0.0060, -0.0062,  0.0002,  ..., -0.0040, -0.0018, -0.0054],
        [-0.0016,  0.0023,  0.0062,  ...,  0.0020,  0.0051, -0.0020],
        ...,
        [-0.0010, -0.0019, -0.0060,  ...,  0.0074,  0.0012,  0.0070],
        [-0.0062, -0.0052,  0.0045,  ..., -0.0058, -0.0054, -0.0048],
        [-0.0013,  0.0023, -0.0062,  ...,  0.0057,  0.0019,  0.0044]]), 'model.perceiver.layers.5.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.to_q.weight': tensor([[-0.0138, -0.0031, -0.0092,  ..., -0.0146,  0.0127,  0.0138],
        [-0.0021, -0.0063, -0.0130,  ..., -0.0075, -0.0116,  0.0041],
        [-0.0041,  0.0061, -0.0115,  ..., -0.0062,  0.0002,  0.0113],
        ...,
        [ 0.0002,  0.0036,  0.0031,  ...,  0.0092, -0.0149, -0.0077],
        [ 0.0115,  0.0122, -0.0023,  ...,  0.0039,  0.0004, -0.0034],
        [ 0.0079, -0.0009, -0.0075,  ...,  0.0140, -0.0071,  0.0013]]), 'model.perceiver.layers.5.0.to_kv.weight': tensor([[-0.0121,  0.0091, -0.0138,  ..., -0.0107,  0.0121, -0.0094],
        [-0.0027,  0.0088, -0.0028,  ..., -0.0055,  0.0151, -0.0056],
        [ 0.0031, -0.0019,  0.0039,  ...,  0.0081,  0.0116, -0.0079],
        ...,
        [-0.0089,  0.0053,  0.0113,  ..., -0.0112,  0.0029,  0.0057],
        [-0.0073, -0.0032,  0.0082,  ...,  0.0122,  0.0092,  0.0144],
        [ 0.0022, -0.0066, -0.0082,  ...,  0.0101, -0.0044, -0.0143]]), 'model.perceiver.layers.5.0.to_out.weight': tensor([[ 0.0165,  0.0297, -0.0041,  ..., -0.0307,  0.0387,  0.0163],
        [-0.0201,  0.0153, -0.0278,  ..., -0.0282, -0.0337,  0.0090],
        [ 0.0277, -0.0092, -0.0417,  ..., -0.0407, -0.0247, -0.0311],
        ...,
        [ 0.0083,  0.0212,  0.0213,  ...,  0.0026, -0.0379, -0.0040],
        [ 0.0135, -0.0012,  0.0415,  ..., -0.0440, -0.0142,  0.0408],
        [ 0.0413, -0.0168, -0.0371,  ..., -0.0176, -0.0100, -0.0435]]), 'model.perceiver.layers.5.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.1.1.weight': tensor([[ 0.0022, -0.0022, -0.0004,  ...,  0.0057,  0.0012, -0.0020],
        [ 0.0027, -0.0068, -0.0052,  ...,  0.0022, -0.0057,  0.0134],
        [-0.0035,  0.0154, -0.0063,  ...,  0.0032,  0.0156, -0.0148],
        ...,
        [-0.0123, -0.0031, -0.0093,  ...,  0.0047,  0.0009,  0.0048],
        [-0.0058,  0.0021,  0.0116,  ...,  0.0016,  0.0016,  0.0051],
        [-0.0036, -0.0053,  0.0155,  ..., -0.0039,  0.0068, -0.0131]]), 'model.perceiver.layers.5.1.3.weight': tensor([[-0.0039,  0.0065,  0.0049,  ...,  0.0023,  0.0046,  0.0066],
        [ 0.0062,  0.0031, -0.0058,  ...,  0.0039,  0.0066,  0.0069],
        [ 0.0057,  0.0071,  0.0028,  ..., -0.0074, -0.0062,  0.0025],
        ...,
        [-0.0043,  0.0034, -0.0023,  ...,  0.0040,  0.0050, -0.0030],
        [ 0.0063,  0.0004,  0.0023,  ...,  0.0073, -0.0019, -0.0025],
        [ 0.0052,  0.0029,  0.0067,  ..., -0.0076,  0.0020, -0.0078]]), 'model.perceiver.norm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.norm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'lm_head.weight': tensor([[-0.0058, -0.0009, -0.0071,  ...,  0.0035, -0.0099,  0.0190],
        [-0.0278,  0.0547, -0.0115,  ..., -0.0232,  0.0147,  0.0332],
        [-0.0140, -0.0099,  0.0201,  ..., -0.0344,  0.0142, -0.0150],
        ...,
        [-0.0243,  0.0031,  0.0008,  ..., -0.0046,  0.0029, -0.0072],
        [ 0.0070,  0.0007,  0.0051,  ..., -0.0131, -0.0103, -0.0041],
        [-0.0041, -0.0077, -0.0308,  ...,  0.0179,  0.0084,  0.0356]],
       dtype=torch.float16)}
[INFO] Medical save done, finish
[INFO] medical_state_dict: {'model.embed_tokens.weight': tensor([[-0.0013,  0.0004, -0.0018,  ...,  0.0004, -0.0038, -0.0033],
        [ 0.0011, -0.0046, -0.0005,  ..., -0.0079, -0.0010,  0.0003],
        [ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
        ...,
        [-0.0052,  0.0041, -0.0056,  ..., -0.0011,  0.0072,  0.0068],
        [ 0.0075, -0.0039,  0.0058,  ...,  0.0447,  0.0135, -0.0091],
        [-0.0026,  0.0215, -0.0237,  ..., -0.0354,  0.0114,  0.0210]],
       dtype=torch.float16), 'model.layers.0.self_attn.q_proj.weight': tensor([[-9.6512e-03, -1.4015e-02, -1.5736e-03,  ...,  2.1338e-05,
          1.3115e-02, -3.8280e-03],
        [ 2.9144e-02,  4.8027e-03,  5.9013e-03,  ..., -1.3435e-02,
         -8.2550e-03,  1.8204e-02],
        [-1.3481e-02,  1.8463e-02, -3.4637e-03,  ...,  6.7596e-03,
          2.8107e-02, -7.3576e-04],
        ...,
        [ 1.1032e-02,  1.4496e-02, -1.0233e-03,  ..., -2.4509e-03,
         -9.9945e-03,  1.9012e-02],
        [ 2.2018e-02,  9.6817e-03,  3.0251e-03,  ..., -2.1957e-02,
         -2.9984e-02, -1.5228e-02],
        [-4.3945e-03, -3.2215e-03,  2.4204e-03,  ...,  1.5717e-02,
          2.7542e-02, -3.5992e-03]], dtype=torch.float16), 'model.layers.0.self_attn.k_proj.weight': tensor([[-1.8356e-02,  4.0359e-03, -1.2512e-03,  ...,  1.7609e-02,
         -8.6746e-03, -1.4610e-02],
        [ 1.5823e-02,  6.5346e-03,  2.6360e-03,  ..., -1.8021e-02,
          1.6815e-02,  2.4765e-02],
        [ 2.4891e-04, -2.5513e-02,  9.2087e-03,  ...,  1.0544e-02,
         -2.4979e-02, -1.9958e-02],
        ...,
        [ 1.5572e-02,  6.2644e-05,  2.2449e-03,  ..., -7.4625e-04,
          1.9274e-03,  5.2757e-03],
        [-1.0864e-02,  2.2339e-02, -8.3771e-03,  ...,  2.7027e-03,
          1.7319e-02, -7.6866e-03],
        [ 5.8746e-03,  5.1308e-04,  6.3248e-03,  ...,  7.2708e-03,
         -1.2901e-02,  6.5727e-03]], dtype=torch.float16), 'model.layers.0.self_attn.v_proj.weight': tensor([[ 0.0007,  0.0044,  0.0010,  ...,  0.0090,  0.0010,  0.0093],
        [-0.0099, -0.0005, -0.0035,  ..., -0.0119,  0.0113,  0.0107],
        [ 0.0048,  0.0068, -0.0029,  ...,  0.0021, -0.0156, -0.0190],
        ...,
        [-0.0073, -0.0050,  0.0162,  ...,  0.0033,  0.0020, -0.0007],
        [-0.0006,  0.0075, -0.0048,  ...,  0.0051,  0.0155,  0.0017],
        [-0.0032,  0.0046,  0.0082,  ..., -0.0016, -0.0035,  0.0023]],
       dtype=torch.float16), 'model.layers.0.self_attn.o_proj.weight': tensor([[ 1.3628e-03, -3.9444e-03,  3.8643e-03,  ...,  2.2564e-03,
          2.7990e-04, -8.9340e-03],
        [-2.4300e-03,  5.6076e-03,  1.1387e-03,  ..., -1.7481e-03,
          2.0924e-03,  5.7678e-03],
        [-3.3474e-03, -7.6914e-04,  2.4796e-03,  ..., -2.0561e-03,
         -6.5956e-03, -8.0681e-04],
        ...,
        [ 4.8943e-03, -1.4791e-03,  7.6332e-03,  ...,  2.2650e-06,
          4.2534e-03,  3.3951e-03],
        [-2.9583e-03, -1.8663e-03, -1.1358e-03,  ...,  5.2490e-03,
         -5.8899e-03, -2.8267e-03],
        [ 4.0221e-04, -1.2932e-03,  3.3665e-03,  ...,  6.5804e-03,
         -4.6806e-03, -5.0964e-03]], dtype=torch.float16), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0081,  0.0134,  0.0292,  ..., -0.0172,  0.0053,  0.0193],
        [-0.0028, -0.0027,  0.0029,  ...,  0.0147, -0.0076,  0.0114],
        [-0.0002, -0.0256,  0.0180,  ..., -0.0189,  0.0257,  0.0206],
        ...,
        [ 0.0058, -0.0258,  0.0025,  ..., -0.0036, -0.0106,  0.0365],
        [ 0.0223,  0.0168, -0.0171,  ..., -0.0017, -0.0030, -0.0196],
        [-0.0070, -0.0135, -0.0268,  ..., -0.0042,  0.0025, -0.0229]],
       dtype=torch.float16), 'model.layers.0.mlp.up_proj.weight': tensor([[-0.0072, -0.0297,  0.0135,  ..., -0.0198, -0.0236,  0.0091],
        [-0.0119, -0.0311,  0.0110,  ...,  0.0178,  0.0034,  0.0087],
        [-0.0066,  0.0157, -0.0102,  ..., -0.0231,  0.0132,  0.0038],
        ...,
        [-0.0121, -0.0005, -0.0019,  ...,  0.0259, -0.0082,  0.0114],
        [-0.0198,  0.0047,  0.0170,  ..., -0.0023, -0.0186,  0.0037],
        [ 0.0142,  0.0268, -0.0009,  ...,  0.0088, -0.0174, -0.0420]],
       dtype=torch.float16), 'model.layers.0.mlp.down_proj.weight': tensor([[ 0.0044, -0.0123,  0.0141,  ..., -0.0181, -0.0041, -0.0016],
        [-0.0006, -0.0026,  0.0135,  ...,  0.0106, -0.0167,  0.0315],
        [ 0.0044,  0.0371,  0.0019,  ..., -0.0117,  0.0212,  0.0207],
        ...,
        [-0.0078, -0.0106,  0.0062,  ...,  0.0204, -0.0163,  0.0254],
        [-0.0202,  0.0401,  0.0176,  ..., -0.0138, -0.0104, -0.0290],
        [ 0.0179, -0.0031, -0.0126,  ...,  0.0003, -0.0050, -0.0296]],
       dtype=torch.float16), 'model.layers.0.input_layernorm.weight': tensor([ 0.0193,  0.0087, -0.0008,  ...,  0.0058,  0.0089,  0.0019],
       dtype=torch.float16), 'model.layers.0.post_attention_layernorm.weight': tensor([0.0530, 0.0537, 0.0498,  ..., 0.0540, 0.0569, 0.0491],
       dtype=torch.float16), 'model.layers.1.self_attn.q_proj.weight': tensor([[-0.0228, -0.0012, -0.0327,  ..., -0.0147, -0.0572,  0.0403],
        [-0.0012, -0.0125,  0.0112,  ..., -0.0081, -0.0516,  0.0322],
        [ 0.0274,  0.0308,  0.0248,  ..., -0.0133, -0.0764,  0.0221],
        ...,
        [-0.0004,  0.0029,  0.0050,  ..., -0.0099, -0.0020, -0.0116],
        [-0.0018, -0.0048, -0.0055,  ...,  0.0103,  0.0032,  0.0117],
        [ 0.0002,  0.0064,  0.0077,  ..., -0.0088,  0.0019, -0.0165]],
       dtype=torch.float16), 'model.layers.1.self_attn.k_proj.weight': tensor([[-0.0254,  0.0089,  0.0425,  ...,  0.0178,  0.0165, -0.0135],
        [-0.0323,  0.0092, -0.0083,  ..., -0.0091,  0.0150, -0.0595],
        [-0.0262,  0.0288, -0.0696,  ...,  0.0352,  0.0172, -0.0609],
        ...,
        [-0.0149,  0.0229,  0.0028,  ...,  0.0081, -0.0048,  0.0070],
        [ 0.0114, -0.0230, -0.0001,  ..., -0.0092,  0.0033, -0.0068],
        [-0.0111,  0.0184,  0.0055,  ...,  0.0007, -0.0071,  0.0058]],
       dtype=torch.float16), 'model.layers.1.self_attn.v_proj.weight': tensor([[ 6.8245e-03, -4.9133e-03,  1.0071e-03,  ..., -4.8561e-03,
         -2.9144e-02, -2.2125e-02],
        [-5.1346e-03,  4.9515e-03, -3.3360e-03,  ...,  2.7618e-03,
          1.1398e-02,  3.1982e-02],
        [ 3.6736e-03, -1.1612e-02,  8.0032e-03,  ..., -2.2590e-05,
         -1.4648e-03, -3.3340e-03],
        ...,
        [-3.6926e-03,  5.3062e-03,  7.3509e-03,  ..., -2.7981e-03,
         -1.4305e-03,  2.2399e-04],
        [-7.8735e-03, -3.1986e-03,  7.9422e-03,  ..., -6.5727e-03,
          8.4534e-03, -5.7817e-06],
        [ 1.0643e-03,  6.4468e-03,  8.0719e-03,  ..., -6.3095e-03,
         -2.6455e-03,  1.0246e-02]], dtype=torch.float16), 'model.layers.1.self_attn.o_proj.weight': tensor([[ 0.0024, -0.0163,  0.0091,  ..., -0.0058, -0.0015, -0.0006],
        [-0.0016, -0.0059, -0.0052,  ...,  0.0035, -0.0019,  0.0037],
        [ 0.0247,  0.0128, -0.0125,  ...,  0.0022, -0.0027,  0.0011],
        ...,
        [ 0.0058,  0.0022,  0.0012,  ..., -0.0011, -0.0004, -0.0001],
        [ 0.0036, -0.0075,  0.0050,  ..., -0.0054,  0.0002,  0.0056],
        [-0.0017, -0.0238,  0.0015,  ..., -0.0021, -0.0055,  0.0007]],
       dtype=torch.float16), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0305, -0.0128,  0.0422,  ..., -0.0312, -0.0152, -0.0100],
        [-0.0312, -0.0045, -0.0312,  ...,  0.0140, -0.0307, -0.0427],
        [-0.0055, -0.0319,  0.0095,  ..., -0.0064, -0.0123, -0.0204],
        ...,
        [-0.0385,  0.0105, -0.0028,  ..., -0.0023,  0.0122,  0.0004],
        [-0.0149, -0.0031, -0.0339,  ...,  0.0217,  0.0198, -0.0084],
        [-0.0266,  0.0121,  0.0041,  ...,  0.0391,  0.0065, -0.0430]],
       dtype=torch.float16), 'model.layers.1.mlp.up_proj.weight': tensor([[-0.0034,  0.0414, -0.0204,  ...,  0.0118,  0.0263, -0.0124],
        [ 0.0071, -0.0067, -0.0129,  ..., -0.0086,  0.0069,  0.0108],
        [ 0.0309, -0.0436,  0.0134,  ...,  0.0177, -0.0427,  0.0297],
        ...,
        [-0.0148, -0.0275,  0.0184,  ...,  0.0293,  0.0069, -0.0238],
        [ 0.0356,  0.0030, -0.0164,  ...,  0.0032, -0.0060, -0.0045],
        [-0.0108, -0.0150, -0.0105,  ..., -0.0249, -0.0061,  0.0173]],
       dtype=torch.float16), 'model.layers.1.mlp.down_proj.weight': tensor([[ 0.0107,  0.0179,  0.0578,  ..., -0.0177,  0.0072, -0.0210],
        [ 0.0088,  0.0063, -0.0363,  ...,  0.0069, -0.0142,  0.0028],
        [-0.0113, -0.0138, -0.0245,  ...,  0.0014, -0.0134,  0.0023],
        ...,
        [-0.0099, -0.0073, -0.0143,  ...,  0.0442, -0.0065,  0.0090],
        [-0.0116,  0.0203,  0.0101,  ..., -0.0278, -0.0228,  0.0261],
        [ 0.0262, -0.0061, -0.0175,  ..., -0.0080, -0.0135,  0.0338]],
       dtype=torch.float16), 'model.layers.1.input_layernorm.weight': tensor([0.1050, 0.0967, 0.0884,  ..., 0.0518, 0.0781, 0.0608],
       dtype=torch.float16), 'model.layers.1.post_attention_layernorm.weight': tensor([0.0986, 0.0991, 0.0957,  ..., 0.1060, 0.1006, 0.1001],
       dtype=torch.float16), 'model.layers.2.self_attn.q_proj.weight': tensor([[-0.0236, -0.0038,  0.0098,  ..., -0.0133, -0.0098, -0.0003],
        [-0.0190,  0.0037, -0.0345,  ..., -0.0344, -0.0162,  0.0232],
        [-0.0165,  0.0366, -0.0252,  ..., -0.0018, -0.0211,  0.0159],
        ...,
        [-0.0526,  0.0145, -0.0261,  ..., -0.0085, -0.0328, -0.0351],
        [ 0.0019, -0.0063,  0.0003,  ..., -0.0023, -0.0186,  0.0160],
        [-0.0048, -0.0168,  0.0231,  ...,  0.0604, -0.0444,  0.0058]],
       dtype=torch.float16), 'model.layers.2.self_attn.k_proj.weight': tensor([[ 0.0004,  0.0156, -0.0085,  ..., -0.0106, -0.0010,  0.0175],
        [ 0.0163, -0.0154, -0.0090,  ...,  0.0110, -0.0093, -0.0075],
        [ 0.0128,  0.0151,  0.0360,  ..., -0.0084,  0.0124,  0.0131],
        ...,
        [ 0.0299,  0.0465, -0.0237,  ...,  0.0386, -0.0369,  0.0006],
        [-0.0072, -0.0126, -0.0009,  ...,  0.0045,  0.0003, -0.0041],
        [ 0.0020, -0.0215, -0.0021,  ..., -0.0809, -0.0249,  0.0965]],
       dtype=torch.float16), 'model.layers.2.self_attn.v_proj.weight': tensor([[-7.3767e-04,  6.2332e-03,  1.5961e-02,  ...,  3.8208e-02,
         -3.6240e-03, -6.9313e-03],
        [ 5.0621e-03,  1.1269e-02, -2.1118e-02,  ..., -7.7972e-03,
          7.8506e-03, -1.4595e-02],
        [-6.8617e-04,  1.8463e-02,  3.3112e-03,  ..., -2.0950e-02,
         -3.0457e-02, -2.9480e-02],
        ...,
        [-5.3465e-05, -2.5360e-02, -2.0248e-02,  ..., -1.0956e-02,
         -9.5272e-04,  3.3970e-03],
        [-3.7140e-02, -7.9775e-04,  1.4175e-02,  ..., -1.0040e-02,
         -6.6071e-03, -1.5135e-03],
        [-1.1009e-02,  1.4809e-02,  4.5662e-03,  ..., -5.1880e-03,
          1.8234e-02, -7.3395e-03]], dtype=torch.float16), 'model.layers.2.self_attn.o_proj.weight': tensor([[ 0.0041,  0.0149,  0.0103,  ...,  0.0196,  0.0020, -0.0260],
        [ 0.0006, -0.0130,  0.0079,  ...,  0.0049, -0.0125, -0.0198],
        [-0.0215,  0.0032, -0.0169,  ..., -0.0224, -0.0103,  0.0078],
        ...,
        [-0.0046, -0.0235,  0.0281,  ..., -0.0049, -0.0220,  0.0198],
        [ 0.0184, -0.0113,  0.0301,  ...,  0.0192, -0.0004, -0.0239],
        [-0.0107,  0.0023,  0.0075,  ..., -0.0129,  0.0050, -0.0142]],
       dtype=torch.float16), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0072,  0.0239, -0.0107,  ..., -0.0090,  0.0302, -0.0034],
        [ 0.0013,  0.0012, -0.0015,  ...,  0.0126, -0.0138, -0.0115],
        [-0.0069, -0.0083,  0.0255,  ..., -0.0112,  0.0158,  0.0069],
        ...,
        [ 0.0342, -0.0119, -0.0193,  ..., -0.0285, -0.0400, -0.0150],
        [-0.0113, -0.0116, -0.0017,  ...,  0.0174, -0.0425,  0.0180],
        [-0.0015,  0.0111,  0.0085,  ..., -0.0133, -0.0261,  0.0048]],
       dtype=torch.float16), 'model.layers.2.mlp.up_proj.weight': tensor([[-0.0008, -0.0006,  0.0139,  ..., -0.0152,  0.0090, -0.0034],
        [ 0.0053, -0.0186, -0.0090,  ...,  0.0056,  0.0114,  0.0062],
        [ 0.0306,  0.0189,  0.0293,  ..., -0.0141, -0.0088,  0.0175],
        ...,
        [-0.0071, -0.0148,  0.0009,  ..., -0.0116, -0.0025,  0.0209],
        [ 0.0155, -0.0129,  0.0144,  ...,  0.0003,  0.0049, -0.0228],
        [-0.0146, -0.0302, -0.0243,  ..., -0.0050,  0.0011, -0.0050]],
       dtype=torch.float16), 'model.layers.2.mlp.down_proj.weight': tensor([[ 0.0146,  0.0174,  0.0375,  ..., -0.0273, -0.0011, -0.0335],
        [ 0.0209, -0.0227, -0.0188,  ...,  0.0180,  0.0023, -0.0226],
        [ 0.0438, -0.0178,  0.0010,  ..., -0.0302,  0.0004, -0.0330],
        ...,
        [-0.0133,  0.0283, -0.0105,  ..., -0.0015, -0.0013, -0.0135],
        [-0.0211,  0.0298,  0.0079,  ...,  0.0158, -0.0182, -0.0113],
        [ 0.0315,  0.0117, -0.0220,  ...,  0.0192, -0.0449, -0.0119]],
       dtype=torch.float16), 'model.layers.2.input_layernorm.weight': tensor([0.1729, 0.1787, 0.1709,  ..., 0.1768, 0.1680, 0.1748],
       dtype=torch.float16), 'model.layers.2.post_attention_layernorm.weight': tensor([0.1338, 0.1377, 0.1367,  ..., 0.1367, 0.1387, 0.1367],
       dtype=torch.float16), 'model.layers.3.self_attn.q_proj.weight': tensor([[ 0.0001,  0.0111,  0.0058,  ...,  0.0241,  0.0127,  0.0220],
        [-0.0121,  0.0172, -0.0149,  ..., -0.0432,  0.0006, -0.0074],
        [ 0.0129,  0.0027, -0.0203,  ...,  0.0116, -0.0187, -0.0406],
        ...,
        [ 0.0717, -0.0696,  0.0428,  ..., -0.0779, -0.0139,  0.0070],
        [-0.0797,  0.0404, -0.0023,  ...,  0.0363,  0.0769,  0.0251],
        [-0.0153, -0.0497,  0.0779,  ..., -0.0225, -0.0032, -0.0130]],
       dtype=torch.float16), 'model.layers.3.self_attn.k_proj.weight': tensor([[ 0.0074, -0.0077, -0.0088,  ..., -0.0140,  0.0067,  0.0404],
        [-0.0116,  0.0102, -0.0252,  ...,  0.0031, -0.0150, -0.0390],
        [ 0.0029, -0.0079,  0.0005,  ...,  0.0074, -0.0090, -0.0374],
        ...,
        [ 0.0884, -0.0848,  0.0065,  ..., -0.0621,  0.0024,  0.0343],
        [-0.0830,  0.0328,  0.0418,  ...,  0.0079,  0.0463, -0.0032],
        [ 0.0020, -0.0524,  0.0955,  ..., -0.0163,  0.0029, -0.0172]],
       dtype=torch.float16), 'model.layers.3.self_attn.v_proj.weight': tensor([[-0.0039,  0.0125, -0.0059,  ..., -0.0148,  0.0063, -0.0150],
        [-0.0113,  0.0269, -0.0179,  ..., -0.0122, -0.0101, -0.0094],
        [ 0.0024, -0.0062,  0.0057,  ..., -0.0406, -0.0087, -0.0281],
        ...,
        [-0.0131, -0.0097, -0.0019,  ...,  0.0023, -0.0041, -0.0064],
        [ 0.0055, -0.0019,  0.0020,  ...,  0.0007, -0.0084,  0.0018],
        [-0.0120, -0.0069,  0.0093,  ..., -0.0012, -0.0018,  0.0084]],
       dtype=torch.float16), 'model.layers.3.self_attn.o_proj.weight': tensor([[-2.7054e-02,  5.7945e-03, -1.2451e-02,  ...,  2.7256e-03,
         -1.1616e-03, -2.2335e-03],
        [ 2.4536e-02, -2.4429e-02, -1.0193e-02,  ...,  6.5651e-03,
         -2.5272e-03, -2.3193e-03],
        [-3.7498e-03, -1.3260e-02,  1.9197e-03,  ...,  2.6493e-03,
          3.3932e-03,  8.3084e-03],
        ...,
        [ 1.1963e-02,  1.3344e-02,  1.3680e-02,  ...,  1.3313e-03,
          7.1793e-03,  9.9335e-03],
        [ 1.7960e-02,  2.6199e-02,  2.9206e-06,  ...,  3.6945e-03,
         -1.1940e-03, -2.8419e-03],
        [ 8.5297e-03, -9.2773e-03,  1.0519e-03,  ..., -6.4993e-04,
          5.8823e-03,  1.0956e-02]], dtype=torch.float16), 'model.layers.3.mlp.gate_proj.weight': tensor([[ 0.0009, -0.0099, -0.0182,  ..., -0.0315,  0.0460,  0.0153],
        [ 0.0189,  0.0017, -0.0123,  ..., -0.0025, -0.0261, -0.0161],
        [-0.0253,  0.0021, -0.0174,  ...,  0.0050, -0.0040, -0.0361],
        ...,
        [-0.0003,  0.0394,  0.0065,  ...,  0.0199, -0.0123, -0.0001],
        [-0.0057,  0.0087, -0.0060,  ...,  0.0003, -0.0041, -0.0112],
        [-0.0025, -0.0155,  0.0031,  ...,  0.0264, -0.0254,  0.0148]],
       dtype=torch.float16), 'model.layers.3.mlp.up_proj.weight': tensor([[-0.0160,  0.0154,  0.0104,  ...,  0.0014,  0.0186, -0.0085],
        [-0.0123, -0.0174,  0.0343,  ...,  0.0175,  0.0141, -0.0052],
        [-0.0005, -0.0031, -0.0144,  ..., -0.0012,  0.0091, -0.0125],
        ...,
        [-0.0042, -0.0016, -0.0006,  ...,  0.0215,  0.0084, -0.0228],
        [ 0.0052, -0.0099, -0.0050,  ...,  0.0113, -0.0249, -0.0080],
        [ 0.0486, -0.0004, -0.0031,  ...,  0.0433,  0.0057,  0.0085]],
       dtype=torch.float16), 'model.layers.3.mlp.down_proj.weight': tensor([[ 0.0014, -0.0079, -0.0008,  ..., -0.0033,  0.0087,  0.0142],
        [ 0.0225,  0.0028,  0.0088,  ..., -0.0140, -0.0148, -0.0148],
        [ 0.0144,  0.0119, -0.0174,  ..., -0.0200, -0.0066,  0.0060],
        ...,
        [ 0.0280, -0.0107, -0.0166,  ...,  0.0040,  0.0193,  0.0221],
        [-0.0217,  0.0099, -0.0106,  ..., -0.0006, -0.0170,  0.0130],
        [ 0.0110, -0.0169, -0.0266,  ...,  0.0033,  0.0121,  0.0063]],
       dtype=torch.float16), 'model.layers.3.input_layernorm.weight': tensor([0.2852, 0.2852, 0.2832,  ..., 0.2812, 0.2910, 0.2969],
       dtype=torch.float16), 'model.layers.3.post_attention_layernorm.weight': tensor([0.1738, 0.1748, 0.1689,  ..., 0.1719, 0.1719, 0.1758],
       dtype=torch.float16), 'model.layers.4.self_attn.q_proj.weight': tensor([[-0.0206, -0.0058,  0.0019,  ..., -0.0113, -0.0038,  0.0106],
        [ 0.0190, -0.0170, -0.0051,  ...,  0.0039, -0.0259, -0.0004],
        [-0.0124, -0.0312,  0.0122,  ..., -0.0027, -0.0195, -0.0239],
        ...,
        [ 0.0246,  0.0004, -0.0039,  ...,  0.0032,  0.0244, -0.0600],
        [-0.0293,  0.0085,  0.0295,  ..., -0.0561,  0.0037,  0.0337],
        [-0.0074, -0.0351,  0.0680,  ...,  0.0638,  0.0376, -0.0406]],
       dtype=torch.float16), 'model.layers.4.self_attn.k_proj.weight': tensor([[-0.0037,  0.0210, -0.0139,  ..., -0.0044,  0.0025, -0.0019],
        [-0.0307, -0.0041, -0.0032,  ..., -0.0014,  0.0142, -0.0028],
        [ 0.0089, -0.0021, -0.0143,  ...,  0.0076,  0.0189,  0.0352],
        ...,
        [-0.0089,  0.1188,  0.0593,  ...,  0.0388, -0.0216, -0.0060],
        [ 0.0320,  0.0533, -0.0162,  ...,  0.0641, -0.0399,  0.0720],
        [ 0.0100,  0.0640,  0.0195,  ..., -0.0011,  0.0424, -0.0209]],
       dtype=torch.float16), 'model.layers.4.self_attn.v_proj.weight': tensor([[-3.6507e-03, -8.4000e-03,  1.2493e-03,  ..., -6.4735e-03,
         -3.6030e-03, -6.0320e-05],
        [-1.4557e-02,  3.6133e-02,  5.1346e-03,  ...,  3.2978e-03,
          1.1721e-03,  2.7237e-03],
        [ 1.0719e-02, -6.2370e-03, -3.4729e-02,  ...,  5.4436e-03,
         -1.3771e-03, -1.8631e-02],
        ...,
        [-3.3283e-03, -8.3771e-03, -2.2263e-02,  ..., -9.6893e-03,
         -1.1740e-03,  3.3360e-03],
        [-2.0599e-03, -1.0277e-02, -1.9855e-03,  ...,  7.9956e-03,
         -1.5678e-03,  4.0550e-03],
        [-2.6131e-04, -1.7914e-02, -3.6087e-03,  ..., -5.3263e-04,
         -5.2681e-03,  1.1940e-02]], dtype=torch.float16), 'model.layers.4.self_attn.o_proj.weight': tensor([[ 0.0270,  0.0083, -0.0050,  ..., -0.0021, -0.0267, -0.0015],
        [ 0.0075, -0.0009, -0.0082,  ...,  0.0017, -0.0215,  0.0036],
        [-0.0045,  0.0041, -0.0073,  ..., -0.0134,  0.0101, -0.0084],
        ...,
        [-0.0148,  0.0272, -0.0037,  ..., -0.0209,  0.0081, -0.0208],
        [ 0.0033, -0.0025, -0.0150,  ..., -0.0094, -0.0004, -0.0059],
        [ 0.0100,  0.0215, -0.0056,  ..., -0.0007,  0.0051,  0.0010]],
       dtype=torch.float16), 'model.layers.4.mlp.gate_proj.weight': tensor([[-0.0053,  0.0065, -0.0110,  ..., -0.0182, -0.0035, -0.0159],
        [-0.0267,  0.0111,  0.0142,  ...,  0.0066,  0.0154, -0.0106],
        [-0.0136, -0.0220, -0.0006,  ...,  0.0055, -0.0028,  0.0260],
        ...,
        [ 0.0008, -0.0025,  0.0095,  ..., -0.0211,  0.0097, -0.0120],
        [-0.0265,  0.0148, -0.0281,  ...,  0.0098,  0.0180, -0.0102],
        [ 0.0017, -0.0143, -0.0135,  ..., -0.0124,  0.0221,  0.0190]],
       dtype=torch.float16), 'model.layers.4.mlp.up_proj.weight': tensor([[-1.6373e-02, -5.6725e-03, -4.0833e-02,  ...,  8.6670e-03,
         -8.2254e-04, -5.4932e-03],
        [-2.2400e-02, -4.0680e-02,  5.3253e-03,  ..., -8.6517e-03,
          9.8953e-03, -2.4872e-02],
        [-1.2989e-03,  2.9587e-02,  7.5042e-05,  ..., -2.8885e-02,
         -1.1322e-02,  8.4839e-03],
        ...,
        [-8.8882e-03, -3.1769e-02, -7.3433e-03,  ...,  1.2138e-02,
         -6.8016e-03,  5.5023e-02],
        [ 1.2787e-02, -1.0330e-02, -1.5060e-02,  ..., -4.2175e-02,
         -1.6281e-02,  9.5596e-03],
        [ 3.7937e-03,  1.3062e-02,  8.8272e-03,  ...,  3.7594e-03,
         -3.4237e-03, -2.4376e-03]], dtype=torch.float16), 'model.layers.4.mlp.down_proj.weight': tensor([[ 2.3834e-02, -4.2458e-03,  2.3529e-02,  ..., -1.9836e-02,
         -8.3983e-05,  2.9861e-02],
        [-5.7335e-03, -4.8859e-02,  4.5746e-02,  ..., -2.4323e-02,
         -2.1210e-02, -7.2365e-03],
        [-2.9135e-04, -2.7969e-02,  1.6556e-02,  ...,  1.1406e-02,
         -2.8000e-03,  2.2263e-02],
        ...,
        [-3.4393e-02, -1.9779e-03, -9.8801e-03,  ...,  2.4658e-02,
          2.1534e-03,  1.5030e-02],
        [-7.8430e-03,  1.8177e-03, -2.0020e-02,  ...,  1.2718e-02,
         -4.1931e-02, -1.1818e-02],
        [ 1.6479e-02, -3.2135e-02, -1.5076e-02,  ..., -3.5000e-03,
         -4.4739e-02, -2.3956e-02]], dtype=torch.float16), 'model.layers.4.input_layernorm.weight': tensor([0.2617, 0.2676, 0.2617,  ..., 0.2578, 0.2656, 0.2734],
       dtype=torch.float16), 'model.layers.4.post_attention_layernorm.weight': tensor([0.1914, 0.1895, 0.1855,  ..., 0.1904, 0.1885, 0.1895],
       dtype=torch.float16), 'model.layers.5.self_attn.q_proj.weight': tensor([[-0.0089, -0.0005, -0.0254,  ..., -0.0074, -0.0164,  0.0120],
        [-0.0202,  0.0197,  0.0401,  ..., -0.0054, -0.0094, -0.0347],
        [ 0.0045,  0.0043, -0.0135,  ...,  0.0205, -0.0172,  0.0105],
        ...,
        [-0.0121,  0.0095, -0.0033,  ...,  0.0542,  0.0104,  0.0356],
        [ 0.0433,  0.0046,  0.0262,  ..., -0.0415, -0.0351, -0.0303],
        [ 0.0103,  0.0194,  0.0370,  ..., -0.0282, -0.0147, -0.0007]],
       dtype=torch.float16), 'model.layers.5.self_attn.k_proj.weight': tensor([[-0.0049,  0.0373,  0.0067,  ...,  0.0198, -0.0056, -0.0016],
        [ 0.0006,  0.0027, -0.0324,  ...,  0.0231, -0.0123,  0.0318],
        [-0.0116, -0.0233,  0.0013,  ...,  0.0026, -0.0059,  0.0032],
        ...,
        [ 0.0031, -0.0016, -0.0228,  ...,  0.0397,  0.0098, -0.0320],
        [ 0.0524,  0.0166, -0.0242,  ..., -0.0012, -0.0159, -0.0361],
        [-0.0242, -0.0217,  0.0421,  ..., -0.0155, -0.0347,  0.0102]],
       dtype=torch.float16), 'model.layers.5.self_attn.v_proj.weight': tensor([[-3.0975e-02,  6.6643e-03,  9.8114e-03,  ...,  2.2919e-02,
          7.3671e-05,  2.3392e-02],
        [ 3.9635e-03,  1.0124e-02, -1.8448e-02,  ..., -1.1353e-02,
          3.7670e-03, -1.3893e-02],
        [ 2.2354e-02,  2.4128e-03, -2.9063e-04,  ..., -2.4063e-02,
          2.8976e-02,  1.1208e-02],
        ...,
        [ 2.0477e-02,  1.1581e-02,  1.0353e-02,  ...,  3.7048e-02,
         -5.7449e-03,  1.1454e-03],
        [-5.3596e-03,  3.0289e-03, -4.7684e-03,  ...,  9.9945e-04,
         -9.2010e-03,  8.7404e-04],
        [-1.2375e-02, -6.2561e-03,  2.1561e-02,  ..., -9.5673e-03,
         -9.2545e-03, -1.5900e-02]], dtype=torch.float16), 'model.layers.5.self_attn.o_proj.weight': tensor([[-0.0155, -0.0091,  0.0050,  ..., -0.0181, -0.0074,  0.0271],
        [ 0.0017,  0.0016, -0.0094,  ..., -0.0182,  0.0043,  0.0034],
        [-0.0014, -0.0026,  0.0131,  ...,  0.0181,  0.0119,  0.0234],
        ...,
        [ 0.0181,  0.0066, -0.0060,  ...,  0.0162,  0.0306, -0.0247],
        [-0.0016,  0.0017, -0.0038,  ..., -0.0184, -0.0139, -0.0013],
        [ 0.0051,  0.0035, -0.0148,  ..., -0.0011, -0.0060, -0.0158]],
       dtype=torch.float16), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0002, -0.0082, -0.0302,  ...,  0.0003, -0.0062, -0.0114],
        [ 0.0216, -0.0073, -0.0212,  ...,  0.0374, -0.0015,  0.0022],
        [ 0.0123,  0.0039, -0.0196,  ...,  0.0148,  0.0164, -0.0348],
        ...,
        [ 0.0065,  0.0096,  0.0416,  ..., -0.0671,  0.0157, -0.0199],
        [-0.0280,  0.0043,  0.0038,  ...,  0.0014,  0.0170, -0.0017],
        [ 0.0282, -0.0299, -0.0141,  ..., -0.0040, -0.0043, -0.0409]],
       dtype=torch.float16), 'model.layers.5.mlp.up_proj.weight': tensor([[-0.0063, -0.0135, -0.0069,  ..., -0.0147,  0.0037, -0.0168],
        [-0.0320, -0.0062,  0.0009,  ...,  0.0124,  0.0182,  0.0228],
        [-0.0019,  0.0090,  0.0094,  ...,  0.0040,  0.0080,  0.0185],
        ...,
        [ 0.0077,  0.0239, -0.0076,  ..., -0.0109,  0.0145,  0.0252],
        [ 0.0447, -0.0130, -0.0292,  ..., -0.0080, -0.0179,  0.0240],
        [ 0.0085,  0.0172,  0.0130,  ..., -0.0103, -0.0041, -0.0160]],
       dtype=torch.float16), 'model.layers.5.mlp.down_proj.weight': tensor([[-0.0074, -0.0270, -0.0031,  ...,  0.0008,  0.0067,  0.0141],
        [-0.0113,  0.0156,  0.0281,  ...,  0.0215,  0.0064, -0.0341],
        [ 0.0131,  0.0207,  0.0143,  ..., -0.0241, -0.0463,  0.0110],
        ...,
        [ 0.0110, -0.0240, -0.0051,  ...,  0.0063, -0.0257, -0.0186],
        [-0.0034, -0.0391,  0.0152,  ...,  0.0161,  0.0156, -0.0515],
        [ 0.0212,  0.0142, -0.0118,  ...,  0.0309,  0.0092, -0.0177]],
       dtype=torch.float16), 'model.layers.5.input_layernorm.weight': tensor([0.2617, 0.2695, 0.2637,  ..., 0.2500, 0.2695, 0.2676],
       dtype=torch.float16), 'model.layers.5.post_attention_layernorm.weight': tensor([0.2090, 0.1953, 0.1934,  ..., 0.2051, 0.2021, 0.2051],
       dtype=torch.float16), 'model.layers.6.self_attn.q_proj.weight': tensor([[-9.7351e-03, -1.1505e-02,  6.6071e-03,  ..., -3.3630e-02,
         -6.4468e-03, -4.9515e-03],
        [ 4.4250e-03, -6.5613e-03,  5.6343e-03,  ...,  1.4587e-02,
          3.5286e-03, -3.1464e-02],
        [-1.7654e-02,  2.4216e-02, -3.8513e-02,  ...,  3.0502e-02,
         -4.8431e-02, -3.2272e-03],
        ...,
        [ 1.2878e-02,  9.0103e-03, -3.7628e-02,  ...,  2.3987e-02,
          2.7657e-03,  1.5497e-03],
        [ 3.5614e-02,  3.2532e-02,  5.3329e-03,  ..., -9.7885e-03,
         -9.6497e-02, -2.0844e-02],
        [-6.3538e-02, -5.3558e-02, -4.8697e-05,  ...,  1.7288e-02,
          5.1155e-03,  8.5220e-03]], dtype=torch.float16), 'model.layers.6.self_attn.k_proj.weight': tensor([[ 0.0139, -0.0106,  0.0204,  ..., -0.0071,  0.0222,  0.0589],
        [-0.0198, -0.0036,  0.0422,  ...,  0.0071, -0.0126,  0.0158],
        [-0.0102, -0.0131, -0.0068,  ..., -0.0006, -0.0307, -0.0107],
        ...,
        [ 0.0214, -0.0376, -0.0183,  ...,  0.0607, -0.0023, -0.0482],
        [-0.0199,  0.0045, -0.0262,  ..., -0.0461, -0.0408,  0.0156],
        [-0.0544, -0.0241, -0.0399,  ...,  0.0161, -0.0420, -0.0188]],
       dtype=torch.float16), 'model.layers.6.self_attn.v_proj.weight': tensor([[ 0.0140,  0.0336,  0.0101,  ...,  0.0127, -0.0017,  0.0078],
        [ 0.0381, -0.0063, -0.0095,  ...,  0.0046, -0.0005,  0.0038],
        [-0.0079, -0.0024,  0.0124,  ...,  0.0101,  0.0240,  0.0046],
        ...,
        [-0.0221, -0.0061,  0.0052,  ...,  0.0010, -0.0165,  0.0085],
        [-0.0243, -0.0088, -0.0003,  ..., -0.0012, -0.0083,  0.0198],
        [ 0.0311,  0.0049,  0.0161,  ..., -0.0222,  0.0005, -0.0030]],
       dtype=torch.float16), 'model.layers.6.self_attn.o_proj.weight': tensor([[ 0.0112, -0.0127, -0.0365,  ..., -0.0135,  0.0086,  0.0113],
        [-0.0260,  0.0067, -0.0001,  ..., -0.0224,  0.0014, -0.0022],
        [ 0.0019, -0.0115, -0.0042,  ...,  0.0106,  0.0079,  0.0094],
        ...,
        [-0.0053, -0.0143, -0.0063,  ...,  0.0074, -0.0062,  0.0256],
        [-0.0204,  0.0092, -0.0014,  ..., -0.0024,  0.0081, -0.0214],
        [-0.0201, -0.0129,  0.0079,  ..., -0.0237,  0.0066,  0.0064]],
       dtype=torch.float16), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0222,  0.0260, -0.0189,  ..., -0.0039, -0.0074, -0.0042],
        [ 0.0321,  0.0016, -0.0231,  ...,  0.0066,  0.0205,  0.0123],
        [-0.0146,  0.0217, -0.0156,  ..., -0.0187,  0.0011,  0.0088],
        ...,
        [ 0.0056, -0.0261,  0.0048,  ...,  0.0091, -0.0184, -0.0066],
        [ 0.0083,  0.0047, -0.0169,  ..., -0.0235, -0.0025, -0.0016],
        [-0.0396, -0.0513,  0.0267,  ..., -0.0413, -0.0027,  0.0164]],
       dtype=torch.float16), 'model.layers.6.mlp.up_proj.weight': tensor([[-0.0147, -0.0145, -0.0228,  ...,  0.0067, -0.0053, -0.0105],
        [ 0.0071, -0.0485,  0.0392,  ...,  0.0123,  0.0003, -0.0055],
        [-0.0220, -0.0162, -0.0241,  ...,  0.0055,  0.0135,  0.0216],
        ...,
        [-0.0267,  0.0002,  0.0167,  ...,  0.0149, -0.0019,  0.0385],
        [ 0.0244,  0.0173, -0.0063,  ..., -0.0283,  0.0101,  0.0017],
        [-0.0249,  0.0287, -0.0220,  ...,  0.0081, -0.0178, -0.0498]],
       dtype=torch.float16), 'model.layers.6.mlp.down_proj.weight': tensor([[-0.0122,  0.0100, -0.0043,  ...,  0.0013,  0.0143,  0.0160],
        [-0.0081, -0.0157,  0.0045,  ..., -0.0036, -0.0266, -0.0125],
        [ 0.0030,  0.0159, -0.0086,  ...,  0.0244,  0.0240,  0.0227],
        ...,
        [ 0.0110, -0.0024,  0.0207,  ...,  0.0316, -0.0336, -0.0099],
        [ 0.0216, -0.0065,  0.0070,  ...,  0.0098, -0.0135, -0.0126],
        [ 0.0152, -0.0165, -0.0085,  ...,  0.0319, -0.0050,  0.0079]],
       dtype=torch.float16), 'model.layers.6.input_layernorm.weight': tensor([0.3223, 0.3613, 0.3242,  ..., 0.3145, 0.3359, 0.3223],
       dtype=torch.float16), 'model.layers.6.post_attention_layernorm.weight': tensor([0.2217, 0.2129, 0.2090,  ..., 0.2227, 0.2168, 0.2178],
       dtype=torch.float16), 'model.layers.7.self_attn.q_proj.weight': tensor([[-6.2637e-03, -1.0843e-03, -8.1658e-06,  ..., -3.4428e-03,
         -2.0752e-02, -6.3477e-03],
        [-1.0460e-02,  1.4365e-04, -1.0338e-03,  ...,  1.2947e-02,
         -3.6564e-03, -1.6739e-02],
        [ 5.0201e-03,  6.6719e-03, -3.1158e-02,  ..., -2.0416e-02,
         -7.5684e-03,  9.1553e-03],
        ...,
        [-1.5259e-03, -3.3752e-02, -2.5040e-02,  ..., -1.2718e-02,
          3.4180e-02,  3.5553e-02],
        [ 1.3344e-02,  5.2917e-02, -4.0039e-02,  ..., -1.1269e-02,
         -6.7383e-02, -5.6915e-02],
        [ 7.9102e-02, -2.4200e-02, -1.8158e-02,  ...,  8.2947e-02,
          3.1113e-02, -4.3716e-03]], dtype=torch.float16), 'model.layers.7.self_attn.k_proj.weight': tensor([[ 0.0032, -0.0077, -0.0123,  ...,  0.0064,  0.0024, -0.0099],
        [-0.0070, -0.0178,  0.0048,  ..., -0.0072,  0.0043,  0.0185],
        [-0.0024, -0.0103,  0.0107,  ..., -0.0082, -0.0065, -0.0179],
        ...,
        [ 0.0429,  0.0077,  0.0243,  ...,  0.0351,  0.0396,  0.0282],
        [ 0.0400,  0.0500, -0.0002,  ..., -0.0307, -0.0344, -0.0016],
        [ 0.0403,  0.0058,  0.0104,  ..., -0.0012,  0.0019, -0.0272]],
       dtype=torch.float16), 'model.layers.7.self_attn.v_proj.weight': tensor([[-1.4038e-02,  5.2605e-03,  1.2993e-02,  ...,  2.8549e-02,
          4.2191e-03, -1.3847e-02],
        [ 2.6672e-02, -2.6993e-02,  4.3640e-03,  ...,  2.0035e-02,
         -1.8890e-02, -1.5915e-02],
        [-6.8970e-03, -1.0094e-02, -3.4523e-03,  ..., -1.8097e-02,
          1.1665e-02, -7.9453e-05],
        ...,
        [-1.3485e-03, -3.8300e-02,  2.7924e-03,  ...,  5.7297e-03,
         -6.9427e-03, -4.0016e-03],
        [-3.7872e-02,  1.9394e-02, -2.7618e-02,  ..., -1.8707e-02,
          1.0628e-02, -1.9252e-04],
        [-7.4272e-03,  2.6951e-03, -8.4991e-03,  ...,  2.0401e-02,
          7.3357e-03,  1.1787e-02]], dtype=torch.float16), 'model.layers.7.self_attn.o_proj.weight': tensor([[ 0.0116, -0.0154,  0.0014,  ...,  0.0091, -0.0194,  0.0053],
        [-0.0066,  0.0281,  0.0115,  ..., -0.0417, -0.0176, -0.0100],
        [ 0.0047, -0.0011, -0.0201,  ..., -0.0096, -0.0059, -0.0107],
        ...,
        [-0.0163, -0.0252, -0.0036,  ...,  0.0259, -0.0186,  0.0010],
        [-0.0226,  0.0085,  0.0167,  ...,  0.0080, -0.0130,  0.0153],
        [ 0.0028, -0.0002,  0.0005,  ...,  0.0060, -0.0161,  0.0039]],
       dtype=torch.float16), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 7.7896e-03,  4.7340e-03, -5.0850e-03,  ..., -4.3983e-03,
         -3.3386e-02, -7.2746e-03],
        [-3.1647e-02,  1.0490e-02, -8.5449e-03,  ..., -4.9400e-03,
         -3.8891e-03,  2.0676e-03],
        [ 1.7075e-02, -3.0640e-02, -8.4043e-06,  ...,  2.5543e-02,
         -2.7069e-02,  3.4237e-03],
        ...,
        [ 1.6441e-03,  2.0504e-03, -1.4145e-02,  ..., -2.0462e-02,
          4.6463e-03, -2.1713e-02],
        [ 2.6989e-03,  1.8036e-02,  1.2131e-02,  ..., -4.7798e-03,
          6.1493e-03, -3.0258e-02],
        [ 1.9714e-02, -1.6556e-02, -1.0773e-02,  ...,  1.7761e-02,
          1.8799e-02, -6.9962e-03]], dtype=torch.float16), 'model.layers.7.mlp.up_proj.weight': tensor([[ 0.0250,  0.0014, -0.0038,  ...,  0.0224, -0.0396,  0.0026],
        [-0.0110, -0.0190,  0.0299,  ...,  0.0095, -0.0108,  0.0154],
        [ 0.0259, -0.0214,  0.0107,  ..., -0.0126,  0.0181, -0.0352],
        ...,
        [-0.0019, -0.0023, -0.0150,  ..., -0.0095, -0.0177,  0.0024],
        [ 0.0003,  0.0084,  0.0167,  ..., -0.0071,  0.0215, -0.0067],
        [-0.0245, -0.0151,  0.0063,  ...,  0.0170,  0.0119,  0.0050]],
       dtype=torch.float16), 'model.layers.7.mlp.down_proj.weight': tensor([[-0.0079, -0.0069,  0.0050,  ..., -0.0115, -0.0060, -0.0211],
        [-0.0095, -0.0072,  0.0217,  ..., -0.0125,  0.0093,  0.0047],
        [ 0.0106,  0.0077,  0.0231,  ..., -0.0157, -0.0048, -0.0210],
        ...,
        [-0.0100,  0.0002, -0.0191,  ...,  0.0123,  0.0022, -0.0257],
        [ 0.0428, -0.0037,  0.0073,  ..., -0.0168,  0.0043, -0.0133],
        [ 0.0117,  0.0195, -0.0333,  ...,  0.0041, -0.0196, -0.0012]],
       dtype=torch.float16), 'model.layers.7.input_layernorm.weight': tensor([0.3242, 0.3652, 0.3340,  ..., 0.3203, 0.3574, 0.3320],
       dtype=torch.float16), 'model.layers.7.post_attention_layernorm.weight': tensor([0.2383, 0.2197, 0.2236,  ..., 0.2314, 0.2324, 0.2314],
       dtype=torch.float16), 'model.layers.8.self_attn.q_proj.weight': tensor([[-0.0004, -0.0152, -0.0297,  ..., -0.0065,  0.0065, -0.0091],
        [-0.0125, -0.0141, -0.0328,  ...,  0.0038, -0.0112,  0.0025],
        [-0.0400, -0.0028, -0.0129,  ..., -0.0023,  0.0260, -0.0321],
        ...,
        [-0.0062,  0.0861,  0.0443,  ..., -0.0247, -0.0285, -0.0468],
        [ 0.0012, -0.0596, -0.0192,  ...,  0.0352,  0.0269, -0.0008],
        [-0.0648, -0.0531, -0.0116,  ..., -0.0541,  0.0303, -0.0170]],
       dtype=torch.float16), 'model.layers.8.self_attn.k_proj.weight': tensor([[-0.0032, -0.0058, -0.0180,  ..., -0.0109,  0.0052,  0.0049],
        [-0.0125,  0.0011, -0.0050,  ...,  0.0228, -0.0019,  0.0143],
        [-0.0167,  0.0023,  0.0027,  ...,  0.0063, -0.0082, -0.0249],
        ...,
        [ 0.0031, -0.0395, -0.0067,  ..., -0.0295, -0.0149,  0.0230],
        [ 0.0078,  0.0294,  0.0184,  ..., -0.0301,  0.0431, -0.0562],
        [ 0.0190, -0.0026, -0.0326,  ...,  0.0140,  0.0077, -0.0147]],
       dtype=torch.float16), 'model.layers.8.self_attn.v_proj.weight': tensor([[-0.0287, -0.0166,  0.0045,  ..., -0.0193, -0.0085, -0.0096],
        [-0.0234, -0.0132,  0.0059,  ...,  0.0352,  0.0096,  0.0248],
        [-0.0082,  0.0140,  0.0135,  ..., -0.0079,  0.0031, -0.0204],
        ...,
        [ 0.0319, -0.0149,  0.0065,  ...,  0.0218, -0.0201,  0.0271],
        [ 0.0327, -0.0165,  0.0041,  ...,  0.0074, -0.0036,  0.0023],
        [ 0.0126, -0.0004, -0.0005,  ..., -0.0017,  0.0009, -0.0126]],
       dtype=torch.float16), 'model.layers.8.self_attn.o_proj.weight': tensor([[ 0.0177,  0.0157, -0.0148,  ..., -0.0109,  0.0026,  0.0176],
        [ 0.0054,  0.0004, -0.0322,  ..., -0.0121, -0.0108, -0.0186],
        [ 0.0025,  0.0138, -0.0094,  ..., -0.0011,  0.0121,  0.0166],
        ...,
        [-0.0150,  0.0233, -0.0010,  ...,  0.0010, -0.0001, -0.0027],
        [ 0.0086,  0.0015, -0.0089,  ...,  0.0043,  0.0054, -0.0251],
        [-0.0232, -0.0003, -0.0096,  ...,  0.0193, -0.0100,  0.0087]],
       dtype=torch.float16), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0158, -0.0021, -0.0490,  ...,  0.0059, -0.0245, -0.0163],
        [-0.0002, -0.0475,  0.0061,  ..., -0.0033, -0.0370,  0.0276],
        [ 0.0212,  0.0191,  0.0176,  ...,  0.0272,  0.0241, -0.0056],
        ...,
        [-0.0111,  0.0015,  0.0134,  ...,  0.0221,  0.0168,  0.0057],
        [-0.0146,  0.0039,  0.0056,  ..., -0.0016, -0.0165,  0.0145],
        [-0.0243,  0.0096, -0.0066,  ..., -0.0134,  0.0060,  0.0033]],
       dtype=torch.float16), 'model.layers.8.mlp.up_proj.weight': tensor([[-0.0055,  0.0251, -0.0157,  ...,  0.0298,  0.0039, -0.0158],
        [-0.0517,  0.0134, -0.0384,  ...,  0.0145, -0.0113, -0.0159],
        [ 0.0176, -0.0004,  0.0102,  ..., -0.0102, -0.0179,  0.0334],
        ...,
        [-0.0138,  0.0403, -0.0309,  ...,  0.0130,  0.0027,  0.0163],
        [ 0.0054, -0.0047, -0.0058,  ..., -0.0160,  0.0193, -0.0173],
        [-0.0224,  0.0174, -0.0155,  ..., -0.0185, -0.0012, -0.0002]],
       dtype=torch.float16), 'model.layers.8.mlp.down_proj.weight': tensor([[-0.0099, -0.0094,  0.0129,  ...,  0.0072,  0.0198, -0.0290],
        [ 0.0178,  0.0132, -0.0227,  ..., -0.0072,  0.0143, -0.0171],
        [ 0.0061, -0.0186, -0.0251,  ..., -0.0091, -0.0019,  0.0038],
        ...,
        [ 0.0090, -0.0205, -0.0343,  ...,  0.0038,  0.0098, -0.0160],
        [ 0.0096,  0.0107, -0.0036,  ..., -0.0060, -0.0068, -0.0226],
        [-0.0031,  0.0103,  0.0024,  ...,  0.0047,  0.0011,  0.0048]],
       dtype=torch.float16), 'model.layers.8.input_layernorm.weight': tensor([0.3301, 0.3477, 0.3320,  ..., 0.3203, 0.3398, 0.3242],
       dtype=torch.float16), 'model.layers.8.post_attention_layernorm.weight': tensor([0.2422, 0.2314, 0.2236,  ..., 0.2363, 0.2324, 0.2305],
       dtype=torch.float16), 'model.layers.9.self_attn.q_proj.weight': tensor([[-0.0147,  0.0026,  0.0210,  ..., -0.0103, -0.0100, -0.0244],
        [-0.0023, -0.0385,  0.0208,  ..., -0.0013, -0.0039,  0.0068],
        [ 0.0012, -0.0021, -0.0153,  ..., -0.0283, -0.0279, -0.0179],
        ...,
        [-0.0006, -0.0509,  0.0130,  ...,  0.0190,  0.0121, -0.0163],
        [ 0.0161, -0.0186,  0.0037,  ...,  0.0068,  0.0028,  0.0125],
        [-0.0003,  0.0516,  0.0195,  ..., -0.0563,  0.0534, -0.0034]],
       dtype=torch.float16), 'model.layers.9.self_attn.k_proj.weight': tensor([[-0.0307,  0.0100, -0.0252,  ..., -0.0017, -0.0205, -0.0061],
        [-0.0069,  0.0352,  0.0098,  ..., -0.0149,  0.0085,  0.0003],
        [-0.0164, -0.0064,  0.0345,  ...,  0.0036, -0.0246, -0.0038],
        ...,
        [ 0.0229, -0.0136, -0.0035,  ..., -0.0085,  0.0241,  0.0240],
        [ 0.0319,  0.0002,  0.0217,  ...,  0.0495, -0.0169,  0.0517],
        [ 0.0084, -0.0259,  0.0257,  ...,  0.0061,  0.0235, -0.0248]],
       dtype=torch.float16), 'model.layers.9.self_attn.v_proj.weight': tensor([[-0.0064,  0.0087,  0.0034,  ...,  0.0043, -0.0216, -0.0148],
        [-0.0142, -0.0147, -0.0031,  ...,  0.0340, -0.0037, -0.0044],
        [ 0.0071, -0.0220,  0.0211,  ..., -0.0274,  0.0032, -0.0137],
        ...,
        [-0.0094, -0.0083,  0.0037,  ...,  0.0052, -0.0218, -0.0055],
        [-0.0172, -0.0003, -0.0087,  ..., -0.0159,  0.0021, -0.0135],
        [ 0.0245,  0.0242, -0.0037,  ..., -0.0092, -0.0047, -0.0060]],
       dtype=torch.float16), 'model.layers.9.self_attn.o_proj.weight': tensor([[ 0.0102,  0.0094,  0.0113,  ..., -0.0143,  0.0007, -0.0113],
        [-0.0017, -0.0193, -0.0068,  ..., -0.0033,  0.0041,  0.0140],
        [-0.0407, -0.0316,  0.0091,  ...,  0.0292,  0.0020,  0.0106],
        ...,
        [ 0.0148, -0.0133,  0.0091,  ...,  0.0057,  0.0059, -0.0098],
        [ 0.0072,  0.0159,  0.0002,  ...,  0.0084,  0.0001,  0.0006],
        [ 0.0189,  0.0456, -0.0234,  ..., -0.0009,  0.0104,  0.0045]],
       dtype=torch.float16), 'model.layers.9.mlp.gate_proj.weight': tensor([[-0.0097,  0.0258,  0.0002,  ..., -0.0271, -0.0084,  0.0018],
        [-0.0202,  0.0319,  0.0322,  ...,  0.0281,  0.0377,  0.0024],
        [ 0.0390,  0.0285, -0.0269,  ..., -0.0217,  0.0120,  0.0011],
        ...,
        [-0.0204, -0.0079, -0.0243,  ...,  0.0019, -0.0409,  0.0066],
        [-0.0061, -0.0243,  0.0275,  ..., -0.0112,  0.0039,  0.0113],
        [ 0.0146, -0.0229, -0.0039,  ...,  0.0122, -0.0083,  0.0163]],
       dtype=torch.float16), 'model.layers.9.mlp.up_proj.weight': tensor([[-0.0143,  0.0186,  0.0150,  ..., -0.0016, -0.0087,  0.0038],
        [ 0.0086, -0.0010,  0.0079,  ...,  0.0153,  0.0204, -0.0192],
        [-0.0182, -0.0051, -0.0223,  ..., -0.0026, -0.0114,  0.0033],
        ...,
        [ 0.0029,  0.0126, -0.0075,  ..., -0.0150, -0.0307, -0.0130],
        [ 0.0031,  0.0218, -0.0348,  ..., -0.0351, -0.0096, -0.0163],
        [ 0.0102, -0.0337, -0.0058,  ..., -0.0190,  0.0217, -0.0074]],
       dtype=torch.float16), 'model.layers.9.mlp.down_proj.weight': tensor([[-0.0030,  0.0313, -0.0411,  ...,  0.0004, -0.0109,  0.0136],
        [ 0.0216, -0.0283, -0.0173,  ..., -0.0057, -0.0223, -0.0278],
        [-0.0026, -0.0015,  0.0022,  ..., -0.0155,  0.0007, -0.0026],
        ...,
        [-0.0101,  0.0194,  0.0052,  ..., -0.0095, -0.0285,  0.0141],
        [-0.0309,  0.0034,  0.0155,  ..., -0.0204, -0.0034, -0.0333],
        [ 0.0165,  0.0171,  0.0078,  ...,  0.0404,  0.0161,  0.0167]],
       dtype=torch.float16), 'model.layers.9.input_layernorm.weight': tensor([0.3535, 0.3633, 0.3281,  ..., 0.3477, 0.3477, 0.3438],
       dtype=torch.float16), 'model.layers.9.post_attention_layernorm.weight': tensor([0.2490, 0.2334, 0.2285,  ..., 0.2451, 0.2422, 0.2383],
       dtype=torch.float16), 'model.layers.10.self_attn.q_proj.weight': tensor([[-3.6449e-03,  3.8357e-03,  2.0087e-05,  ..., -2.7161e-03,
         -6.6376e-03, -1.4206e-02],
        [-9.7427e-03, -4.9667e-03,  2.0599e-02,  ..., -1.9287e-02,
          6.4575e-02, -3.7270e-03],
        [-1.3718e-02, -1.5106e-02,  2.1040e-04,  ...,  3.4210e-02,
         -9.4452e-03, -1.4389e-02],
        ...,
        [ 3.2104e-02,  6.3049e-02, -1.7929e-02,  ...,  3.7445e-02,
          3.3508e-02, -9.3842e-03],
        [-6.6040e-02,  5.6519e-02, -2.7695e-03,  ..., -6.0577e-02,
         -5.7068e-03, -3.6221e-03],
        [-4.9713e-02, -2.1591e-02, -7.7477e-03,  ..., -1.2627e-02,
         -3.6346e-02, -9.3536e-03]], dtype=torch.float16), 'model.layers.10.self_attn.k_proj.weight': tensor([[-0.0320,  0.0131, -0.0093,  ..., -0.0153,  0.0091, -0.0001],
        [-0.0056,  0.0082, -0.0056,  ..., -0.0057, -0.0101,  0.0133],
        [-0.0008, -0.0022,  0.0067,  ..., -0.0274,  0.0042,  0.0012],
        ...,
        [-0.0464, -0.0599,  0.0127,  ...,  0.0291, -0.0853,  0.0117],
        [-0.0345, -0.0131,  0.0234,  ..., -0.0141, -0.0415, -0.0148],
        [-0.0192,  0.0225, -0.0224,  ...,  0.0083,  0.0425, -0.0002]],
       dtype=torch.float16), 'model.layers.10.self_attn.v_proj.weight': tensor([[-0.0387,  0.0081, -0.0087,  ...,  0.0097,  0.0140,  0.0083],
        [-0.0083,  0.0136,  0.0120,  ..., -0.0067, -0.0419,  0.0195],
        [ 0.0170, -0.0150,  0.0130,  ...,  0.0145,  0.0079, -0.0095],
        ...,
        [ 0.0214,  0.0277,  0.0017,  ...,  0.0253,  0.0023, -0.0228],
        [-0.0040,  0.0057, -0.0005,  ...,  0.0020,  0.0113, -0.0018],
        [ 0.0172,  0.0061, -0.0238,  ..., -0.0072, -0.0071,  0.0242]],
       dtype=torch.float16), 'model.layers.10.self_attn.o_proj.weight': tensor([[-0.0057,  0.0007, -0.0348,  ...,  0.0022,  0.0056,  0.0074],
        [ 0.0006, -0.0118,  0.0126,  ...,  0.0058,  0.0132,  0.0075],
        [ 0.0153, -0.0353, -0.0162,  ...,  0.0007, -0.0036, -0.0031],
        ...,
        [-0.0021,  0.0080, -0.0197,  ..., -0.0031, -0.0003,  0.0199],
        [ 0.0090, -0.0164, -0.0207,  ...,  0.0118,  0.0087,  0.0109],
        [ 0.0075, -0.0081, -0.0278,  ...,  0.0101, -0.0039,  0.0009]],
       dtype=torch.float16), 'model.layers.10.mlp.gate_proj.weight': tensor([[-0.0255, -0.0464, -0.0296,  ...,  0.0059, -0.0014, -0.0041],
        [-0.0152, -0.0224, -0.0173,  ...,  0.0032,  0.0152,  0.0143],
        [-0.0210, -0.0214,  0.0097,  ...,  0.0347, -0.0098,  0.0017],
        ...,
        [-0.0465, -0.0077,  0.0100,  ...,  0.0039, -0.0303,  0.0208],
        [ 0.0046,  0.0114,  0.0203,  ...,  0.0042, -0.0112, -0.0007],
        [-0.0159, -0.0042, -0.0147,  ..., -0.0145,  0.0072, -0.0121]],
       dtype=torch.float16), 'model.layers.10.mlp.up_proj.weight': tensor([[-0.0320, -0.0040, -0.0427,  ...,  0.0109, -0.0067, -0.0190],
        [-0.0074,  0.0061,  0.0065,  ...,  0.0190,  0.0319, -0.0167],
        [-0.0080, -0.0042,  0.0192,  ...,  0.0319, -0.0360,  0.0033],
        ...,
        [ 0.0242,  0.0213, -0.0094,  ..., -0.0432, -0.0039,  0.0027],
        [-0.0012, -0.0116, -0.0232,  ...,  0.0270, -0.0056,  0.0214],
        [-0.0042,  0.0167, -0.0049,  ..., -0.0009,  0.0034,  0.0205]],
       dtype=torch.float16), 'model.layers.10.mlp.down_proj.weight': tensor([[-0.0152, -0.0201, -0.0101,  ...,  0.0302, -0.0133,  0.0010],
        [-0.0054,  0.0221, -0.0139,  ..., -0.0116,  0.0119, -0.0105],
        [-0.0275, -0.0021,  0.0208,  ..., -0.0218, -0.0254,  0.0118],
        ...,
        [ 0.0098, -0.0068, -0.0057,  ...,  0.0063,  0.0142,  0.0074],
        [-0.0106,  0.0519, -0.0189,  ...,  0.0284,  0.0307, -0.0305],
        [-0.0471,  0.0020, -0.0252,  ..., -0.0184, -0.0151,  0.0109]],
       dtype=torch.float16), 'model.layers.10.input_layernorm.weight': tensor([0.3652, 0.3594, 0.3223,  ..., 0.3398, 0.3496, 0.3379],
       dtype=torch.float16), 'model.layers.10.post_attention_layernorm.weight': tensor([0.2500, 0.2383, 0.2285,  ..., 0.2432, 0.2432, 0.2432],
       dtype=torch.float16), 'model.layers.11.self_attn.q_proj.weight': tensor([[ 0.0161, -0.0006, -0.0169,  ...,  0.0251, -0.0088,  0.0062],
        [-0.0113,  0.0006,  0.0061,  ...,  0.0169,  0.0102,  0.0040],
        [ 0.0104,  0.0213, -0.0237,  ..., -0.0047, -0.0055,  0.0015],
        ...,
        [ 0.0066,  0.0024,  0.0322,  ...,  0.0338,  0.0438, -0.0291],
        [ 0.0504,  0.0148, -0.0166,  ..., -0.0151,  0.0161, -0.0268],
        [ 0.0818, -0.0201, -0.0214,  ..., -0.0201,  0.0410,  0.0539]],
       dtype=torch.float16), 'model.layers.11.self_attn.k_proj.weight': tensor([[-0.0052,  0.0221,  0.0030,  ..., -0.0179,  0.0177, -0.0154],
        [ 0.0012,  0.0016, -0.0310,  ..., -0.0106,  0.0045,  0.0256],
        [ 0.0298, -0.0297,  0.0027,  ...,  0.0140,  0.0046,  0.0079],
        ...,
        [-0.0032,  0.0288,  0.0043,  ..., -0.0189, -0.0055,  0.0403],
        [ 0.0598, -0.0065, -0.0142,  ..., -0.0078,  0.0050, -0.0079],
        [ 0.0110,  0.0065,  0.0253,  ..., -0.0007,  0.0569,  0.0267]],
       dtype=torch.float16), 'model.layers.11.self_attn.v_proj.weight': tensor([[ 9.6436e-03,  1.0605e-03, -4.5738e-03,  ..., -2.2232e-02,
         -1.0233e-03,  7.4806e-03],
        [ 2.6855e-03, -6.0806e-03, -1.6937e-02,  ..., -5.5611e-05,
          3.7360e-04, -2.7130e-02],
        [ 2.9392e-03,  9.2468e-03, -7.0686e-03,  ...,  1.6724e-02,
          1.0735e-02, -2.5055e-02],
        ...,
        [-2.0782e-02,  7.5455e-03, -1.4633e-02,  ...,  8.2016e-03,
         -1.7349e-02, -2.2812e-03],
        [-9.9487e-03,  1.0506e-02, -1.1917e-02,  ..., -1.3245e-02,
         -1.7868e-02,  3.2711e-03],
        [ 1.7990e-02, -2.1179e-02, -1.4639e-03,  ..., -4.0344e-02,
          1.8826e-03, -1.2375e-02]], dtype=torch.float16), 'model.layers.11.self_attn.o_proj.weight': tensor([[-0.0191, -0.0035,  0.0060,  ...,  0.0097,  0.0109,  0.0016],
        [-0.0016, -0.0260,  0.0116,  ..., -0.0118, -0.0028, -0.0255],
        [-0.0051, -0.0058,  0.0210,  ...,  0.0021, -0.0066,  0.0139],
        ...,
        [ 0.0016, -0.0042,  0.0228,  ...,  0.0024, -0.0016, -0.0029],
        [ 0.0077,  0.0177,  0.0082,  ...,  0.0172,  0.0129, -0.0298],
        [-0.0027, -0.0047,  0.0054,  ..., -0.0081, -0.0022, -0.0107]],
       dtype=torch.float16), 'model.layers.11.mlp.gate_proj.weight': tensor([[-0.0440, -0.0086,  0.0052,  ...,  0.0062, -0.0116,  0.0425],
        [ 0.0074, -0.0107,  0.0206,  ...,  0.0087, -0.0197, -0.0413],
        [-0.0010, -0.0459, -0.0289,  ..., -0.0025, -0.0084, -0.0026],
        ...,
        [-0.0202, -0.0397, -0.0216,  ..., -0.0041, -0.0321,  0.0039],
        [ 0.0090, -0.0044, -0.0364,  ..., -0.0127,  0.0069,  0.0010],
        [ 0.0023,  0.0186,  0.0080,  ...,  0.0468, -0.0007, -0.0140]],
       dtype=torch.float16), 'model.layers.11.mlp.up_proj.weight': tensor([[-0.0093,  0.0016, -0.0275,  ...,  0.0240,  0.0097,  0.0313],
        [ 0.0179, -0.0028, -0.0222,  ...,  0.0172, -0.0467,  0.0077],
        [-0.0064, -0.0369,  0.0014,  ..., -0.0048, -0.0177,  0.0154],
        ...,
        [ 0.0408,  0.0105, -0.0095,  ...,  0.0014, -0.0005,  0.0161],
        [-0.0116,  0.0200,  0.0059,  ...,  0.0163,  0.0094,  0.0065],
        [-0.0041,  0.0019, -0.0054,  ..., -0.0172, -0.0005,  0.0250]],
       dtype=torch.float16), 'model.layers.11.mlp.down_proj.weight': tensor([[-0.0162,  0.0454,  0.0091,  ...,  0.0194,  0.0163, -0.0040],
        [-0.0136, -0.0092, -0.0251,  ..., -0.0202, -0.0090,  0.0154],
        [-0.0237, -0.0169,  0.0102,  ...,  0.0052, -0.0217, -0.0031],
        ...,
        [ 0.0215,  0.0262, -0.0104,  ..., -0.0017, -0.0003,  0.0087],
        [-0.0111, -0.0290, -0.0306,  ..., -0.0254, -0.0089,  0.0139],
        [ 0.0362,  0.0240,  0.0214,  ..., -0.0028, -0.0135,  0.0383]],
       dtype=torch.float16), 'model.layers.11.input_layernorm.weight': tensor([0.3965, 0.3965, 0.3652,  ..., 0.3848, 0.3828, 0.3711],
       dtype=torch.float16), 'model.layers.11.post_attention_layernorm.weight': tensor([0.2598, 0.2471, 0.2383,  ..., 0.2578, 0.2559, 0.2559],
       dtype=torch.float16), 'model.layers.12.self_attn.q_proj.weight': tensor([[-0.0093, -0.0171,  0.0036,  ...,  0.0262, -0.0099,  0.0055],
        [ 0.0065, -0.0070, -0.0075,  ..., -0.0127,  0.0223,  0.0202],
        [ 0.0106,  0.0411, -0.0328,  ...,  0.0061,  0.0025, -0.0291],
        ...,
        [ 0.0094,  0.0321, -0.0197,  ..., -0.0311, -0.0004, -0.0008],
        [ 0.0424, -0.0059,  0.0097,  ...,  0.0322,  0.0067, -0.0247],
        [ 0.0332,  0.0143, -0.0364,  ..., -0.0210,  0.0215,  0.0238]],
       dtype=torch.float16), 'model.layers.12.self_attn.k_proj.weight': tensor([[ 0.0099, -0.0011, -0.0045,  ...,  0.0193, -0.0024, -0.0102],
        [ 0.0073,  0.0208, -0.0157,  ..., -0.0014, -0.0157, -0.0293],
        [-0.0113, -0.0283,  0.0173,  ...,  0.0087,  0.0026,  0.0026],
        ...,
        [ 0.0132,  0.0322, -0.0148,  ..., -0.0355, -0.0164, -0.0242],
        [-0.0381,  0.0037,  0.0226,  ..., -0.0282,  0.0146, -0.0006],
        [-0.0007,  0.0322,  0.0109,  ...,  0.0129, -0.0465, -0.0404]],
       dtype=torch.float16), 'model.layers.12.self_attn.v_proj.weight': tensor([[ 0.0064,  0.0072,  0.0069,  ..., -0.0077,  0.0109, -0.0189],
        [-0.0275,  0.0104, -0.0036,  ..., -0.0175, -0.0006,  0.0191],
        [-0.0148, -0.0132,  0.0088,  ..., -0.0069,  0.0475, -0.0107],
        ...,
        [ 0.0081, -0.0017, -0.0150,  ..., -0.0068, -0.0115, -0.0013],
        [-0.0010, -0.0147, -0.0047,  ...,  0.0034,  0.0109,  0.0122],
        [ 0.0225,  0.0017,  0.0007,  ...,  0.0178,  0.0139, -0.0070]],
       dtype=torch.float16), 'model.layers.12.self_attn.o_proj.weight': tensor([[ 0.0277,  0.0071, -0.0019,  ..., -0.0012,  0.0083, -0.0061],
        [-0.0092, -0.0141, -0.0014,  ..., -0.0108,  0.0061, -0.0138],
        [ 0.0068, -0.0023, -0.0018,  ...,  0.0037, -0.0232,  0.0125],
        ...,
        [ 0.0032, -0.0023,  0.0126,  ..., -0.0084, -0.0009,  0.0019],
        [-0.0108, -0.0346, -0.0278,  ..., -0.0121,  0.0109,  0.0143],
        [ 0.0210,  0.0093,  0.0084,  ...,  0.0209, -0.0084, -0.0171]],
       dtype=torch.float16), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0057, -0.0110,  0.0123,  ..., -0.0042,  0.0268, -0.0024],
        [-0.0266, -0.0214,  0.0172,  ...,  0.0121,  0.0153,  0.0057],
        [-0.0005,  0.0258, -0.0114,  ..., -0.0099, -0.0289, -0.0045],
        ...,
        [-0.0024,  0.0108,  0.0106,  ..., -0.0328,  0.0070,  0.0276],
        [-0.0325, -0.0083,  0.0082,  ...,  0.0103,  0.0123, -0.0085],
        [ 0.0045, -0.0267, -0.0056,  ..., -0.0053, -0.0018, -0.0202]],
       dtype=torch.float16), 'model.layers.12.mlp.up_proj.weight': tensor([[ 2.9488e-03,  1.7151e-02,  3.6030e-03,  ..., -9.1076e-05,
          1.3832e-02,  1.5427e-02],
        [-3.6373e-03, -1.4801e-02, -1.3435e-02,  ...,  6.5842e-03,
         -7.0915e-03,  2.4414e-02],
        [ 1.4610e-02, -1.2291e-02,  7.4959e-03,  ..., -4.1534e-02,
          4.9171e-03,  1.6441e-03],
        ...,
        [-2.6154e-02, -3.3844e-02, -7.3738e-03,  ...,  1.6922e-02,
         -1.5038e-02,  3.0403e-03],
        [-1.5144e-03, -4.3915e-02, -8.0156e-04,  ...,  1.3924e-02,
          3.0556e-03, -1.5656e-02],
        [ 2.2144e-03, -2.8961e-02,  3.7813e-04,  ...,  3.2440e-02,
         -3.6602e-03, -3.8300e-02]], dtype=torch.float16), 'model.layers.12.mlp.down_proj.weight': tensor([[ 0.0081, -0.0018, -0.0294,  ..., -0.0123,  0.0035,  0.0029],
        [ 0.0170, -0.0288,  0.0046,  ..., -0.0004, -0.0089, -0.0230],
        [ 0.0200,  0.0030,  0.0241,  ...,  0.0043, -0.0012, -0.0281],
        ...,
        [ 0.0183, -0.0085, -0.0380,  ...,  0.0313, -0.0193, -0.0176],
        [-0.0259,  0.0179,  0.0106,  ..., -0.0092,  0.0359, -0.0229],
        [ 0.0075,  0.0262,  0.0221,  ..., -0.0381,  0.0273, -0.0022]],
       dtype=torch.float16), 'model.layers.12.input_layernorm.weight': tensor([0.4062, 0.4023, 0.3691,  ..., 0.3848, 0.3867, 0.3887],
       dtype=torch.float16), 'model.layers.12.post_attention_layernorm.weight': tensor([0.2656, 0.2520, 0.2432,  ..., 0.2656, 0.2617, 0.2598],
       dtype=torch.float16), 'model.layers.13.self_attn.q_proj.weight': tensor([[-0.0002, -0.0013, -0.0132,  ...,  0.0055, -0.0150, -0.0128],
        [-0.0118, -0.0142,  0.0031,  ..., -0.0004,  0.0004, -0.0026],
        [-0.0175,  0.0138,  0.0197,  ..., -0.0115, -0.0075, -0.0069],
        ...,
        [ 0.0483,  0.0084,  0.0043,  ...,  0.0573,  0.0140, -0.0512],
        [ 0.0078,  0.0083, -0.0259,  ...,  0.0091,  0.0111, -0.0104],
        [-0.0040, -0.0248, -0.0212,  ..., -0.0068,  0.0285, -0.0065]],
       dtype=torch.float16), 'model.layers.13.self_attn.k_proj.weight': tensor([[ 0.0134,  0.0048, -0.0030,  ..., -0.0130,  0.0337,  0.0125],
        [ 0.0155,  0.0307, -0.0005,  ..., -0.0055,  0.0136,  0.0046],
        [-0.0007, -0.0130,  0.0334,  ..., -0.0083,  0.0110, -0.0375],
        ...,
        [ 0.0375,  0.0356,  0.0033,  ...,  0.0048, -0.0061, -0.0118],
        [-0.0010,  0.0045,  0.0287,  ..., -0.0342, -0.0217,  0.0352],
        [-0.0229, -0.0535, -0.0142,  ..., -0.0378, -0.0310,  0.0118]],
       dtype=torch.float16), 'model.layers.13.self_attn.v_proj.weight': tensor([[ 0.0149,  0.0064, -0.0058,  ..., -0.0005,  0.0173,  0.0124],
        [-0.0029,  0.0087,  0.0005,  ...,  0.0233, -0.0065, -0.0029],
        [ 0.0146, -0.0016, -0.0023,  ..., -0.0212,  0.0366, -0.0090],
        ...,
        [-0.0011,  0.0251, -0.0052,  ..., -0.0111,  0.0272, -0.0211],
        [-0.0103,  0.0104,  0.0128,  ...,  0.0017,  0.0274,  0.0058],
        [-0.0045, -0.0064,  0.0239,  ...,  0.0154, -0.0026,  0.0374]],
       dtype=torch.float16), 'model.layers.13.self_attn.o_proj.weight': tensor([[-0.0035,  0.0010, -0.0044,  ..., -0.0015, -0.0045, -0.0012],
        [ 0.0222,  0.0148,  0.0101,  ..., -0.0146, -0.0108,  0.0024],
        [ 0.0118,  0.0055,  0.0036,  ...,  0.0065, -0.0233, -0.0088],
        ...,
        [-0.0102,  0.0102,  0.0194,  ..., -0.0114, -0.0154, -0.0165],
        [ 0.0083, -0.0005,  0.0301,  ..., -0.0037, -0.0268, -0.0238],
        [ 0.0100,  0.0019,  0.0086,  ...,  0.0171, -0.0083, -0.0238]],
       dtype=torch.float16), 'model.layers.13.mlp.gate_proj.weight': tensor([[ 0.0249, -0.0034, -0.0082,  ...,  0.0114,  0.0034, -0.0122],
        [-0.0141,  0.0452,  0.0071,  ...,  0.0416, -0.0012, -0.0260],
        [ 0.0035, -0.0199, -0.0103,  ...,  0.0047, -0.0093, -0.0152],
        ...,
        [ 0.0153, -0.0196,  0.0202,  ..., -0.0065,  0.0133,  0.0111],
        [ 0.0154, -0.0125,  0.0203,  ...,  0.0181,  0.0106, -0.0270],
        [ 0.0028,  0.0392,  0.0161,  ..., -0.0045,  0.0059,  0.0285]],
       dtype=torch.float16), 'model.layers.13.mlp.up_proj.weight': tensor([[-0.0423,  0.0199, -0.0013,  ...,  0.0037,  0.0091,  0.0011],
        [ 0.0138, -0.0066,  0.0247,  ...,  0.0468,  0.0286,  0.0224],
        [ 0.0281, -0.0344,  0.0093,  ...,  0.0069,  0.0009, -0.0082],
        ...,
        [-0.0130, -0.0038,  0.0297,  ...,  0.0190, -0.0247,  0.0139],
        [-0.0103, -0.0171,  0.0079,  ...,  0.0177,  0.0563,  0.0096],
        [ 0.0117, -0.0212,  0.0179,  ..., -0.0185, -0.0004,  0.0269]],
       dtype=torch.float16), 'model.layers.13.mlp.down_proj.weight': tensor([[-0.0062, -0.0036, -0.0027,  ...,  0.0226, -0.0265, -0.0220],
        [-0.0117,  0.0470, -0.0413,  ..., -0.0018,  0.0133, -0.0090],
        [ 0.0081,  0.0038,  0.0183,  ...,  0.0015, -0.0249, -0.0031],
        ...,
        [ 0.0058,  0.0077,  0.0354,  ..., -0.0014, -0.0209,  0.0290],
        [ 0.0167, -0.0015,  0.0188,  ..., -0.0109,  0.0164, -0.0045],
        [ 0.0029, -0.0229,  0.0393,  ...,  0.0041,  0.0022,  0.0325]],
       dtype=torch.float16), 'model.layers.13.input_layernorm.weight': tensor([0.4199, 0.4121, 0.3770,  ..., 0.3926, 0.3848, 0.3965],
       dtype=torch.float16), 'model.layers.13.post_attention_layernorm.weight': tensor([0.2715, 0.2598, 0.2539,  ..., 0.2715, 0.2734, 0.2656],
       dtype=torch.float16), 'model.layers.14.self_attn.q_proj.weight': tensor([[-0.0088, -0.0028,  0.0195,  ..., -0.0054,  0.0162,  0.0367],
        [ 0.0097,  0.0160, -0.0124,  ..., -0.0348, -0.0203, -0.0406],
        [-0.0202, -0.0112,  0.0171,  ...,  0.0106,  0.0140, -0.0339],
        ...,
        [-0.0201,  0.0005, -0.0295,  ...,  0.0018,  0.0130, -0.0074],
        [ 0.0269, -0.0389,  0.0497,  ..., -0.0134,  0.0061, -0.0092],
        [-0.0175, -0.0090, -0.0035,  ...,  0.0170,  0.0184, -0.0447]],
       dtype=torch.float16), 'model.layers.14.self_attn.k_proj.weight': tensor([[-0.0143, -0.0049,  0.0068,  ..., -0.0091,  0.0271,  0.0431],
        [ 0.0191,  0.0324, -0.0204,  ..., -0.0030, -0.0276, -0.0050],
        [-0.0183,  0.0034,  0.0196,  ...,  0.0239,  0.0110,  0.0012],
        ...,
        [-0.0387, -0.0029,  0.0264,  ..., -0.0049,  0.0017, -0.0254],
        [-0.0293,  0.0005,  0.0153,  ..., -0.0359, -0.0144,  0.0012],
        [-0.0202,  0.0292,  0.0236,  ...,  0.0703,  0.0087, -0.0386]],
       dtype=torch.float16), 'model.layers.14.self_attn.v_proj.weight': tensor([[ 7.4310e-03,  7.7629e-03, -3.8025e-02,  ..., -3.4210e-02,
         -5.2032e-03,  1.2451e-02],
        [-1.0204e-03, -2.5452e-02, -3.0117e-03,  ...,  1.0887e-02,
         -5.2512e-05, -3.2425e-03],
        [ 2.6276e-02, -1.5022e-02,  2.2659e-03,  ..., -5.5466e-03,
          2.3460e-03,  8.2321e-03],
        ...,
        [ 1.5747e-02, -1.1642e-02,  1.5343e-02,  ...,  1.5533e-02,
         -1.1597e-02,  2.6016e-03],
        [-1.1391e-02,  2.2583e-02, -3.5553e-02,  ..., -7.8058e-04,
         -8.8654e-03, -2.5574e-02],
        [ 3.5992e-03,  2.3102e-02, -2.2568e-02,  ..., -5.2261e-03,
         -3.3932e-03,  1.8295e-02]], dtype=torch.float16), 'model.layers.14.self_attn.o_proj.weight': tensor([[-0.0108,  0.0044, -0.0227,  ..., -0.0021,  0.0010, -0.0110],
        [ 0.0080,  0.0304,  0.0077,  ...,  0.0221, -0.0049,  0.0021],
        [ 0.0060,  0.0082,  0.0024,  ...,  0.0075,  0.0206,  0.0054],
        ...,
        [ 0.0245, -0.0073,  0.0008,  ..., -0.0073, -0.0022,  0.0139],
        [-0.0025,  0.0010, -0.0195,  ..., -0.0021,  0.0362,  0.0155],
        [-0.0085, -0.0104, -0.0139,  ..., -0.0070,  0.0146,  0.0060]],
       dtype=torch.float16), 'model.layers.14.mlp.gate_proj.weight': tensor([[-0.0084,  0.0011, -0.0090,  ...,  0.0102, -0.0185, -0.0064],
        [ 0.0296,  0.0080, -0.0390,  ...,  0.0377,  0.0119, -0.0075],
        [ 0.0095,  0.0148, -0.0004,  ..., -0.0081,  0.0108, -0.0179],
        ...,
        [ 0.0065,  0.0105, -0.0190,  ...,  0.0003, -0.0047,  0.0004],
        [ 0.0033,  0.0159,  0.0201,  ..., -0.0192,  0.0087,  0.0073],
        [ 0.0200,  0.0017,  0.0183,  ..., -0.0106, -0.0248,  0.0258]],
       dtype=torch.float16), 'model.layers.14.mlp.up_proj.weight': tensor([[ 0.0052,  0.0099,  0.0201,  ..., -0.0153,  0.0073,  0.0048],
        [ 0.0269,  0.0089, -0.0300,  ...,  0.0064,  0.0262,  0.0104],
        [ 0.0012, -0.0055,  0.0300,  ..., -0.0013,  0.0177, -0.0023],
        ...,
        [-0.0164, -0.0013, -0.0479,  ..., -0.0145, -0.0116, -0.0048],
        [-0.0415,  0.0074, -0.0075,  ..., -0.0081,  0.0239, -0.0144],
        [ 0.0029,  0.0235,  0.0122,  ...,  0.0086, -0.0140,  0.0131]],
       dtype=torch.float16), 'model.layers.14.mlp.down_proj.weight': tensor([[ 0.0100,  0.0243,  0.0113,  ..., -0.0290, -0.0019, -0.0056],
        [ 0.0121,  0.0222, -0.0091,  ...,  0.0131, -0.0032,  0.0189],
        [ 0.0080, -0.0420,  0.0119,  ...,  0.0042, -0.0302,  0.0124],
        ...,
        [ 0.0005,  0.0152, -0.0169,  ..., -0.0046, -0.0100, -0.0109],
        [ 0.0242,  0.0335,  0.0364,  ..., -0.0051, -0.0155,  0.0210],
        [-0.0245,  0.0057, -0.0101,  ..., -0.0300,  0.0070,  0.0187]],
       dtype=torch.float16), 'model.layers.14.input_layernorm.weight': tensor([0.4219, 0.4297, 0.3789,  ..., 0.4141, 0.4062, 0.3984],
       dtype=torch.float16), 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2734, 0.2656,  ..., 0.2871, 0.2832, 0.2793],
       dtype=torch.float16), 'model.layers.15.self_attn.q_proj.weight': tensor([[-0.0194, -0.0154, -0.0142,  ...,  0.0138, -0.0084,  0.0010],
        [ 0.0363, -0.0190,  0.0038,  ..., -0.0058,  0.0144,  0.0015],
        [ 0.0084, -0.0132,  0.0030,  ...,  0.0098, -0.0134, -0.0160],
        ...,
        [-0.0477, -0.0267,  0.0071,  ..., -0.0063, -0.0128,  0.0200],
        [-0.0155, -0.0536,  0.0174,  ...,  0.0155, -0.0015,  0.0025],
        [ 0.0236,  0.0251,  0.0278,  ..., -0.0140, -0.0227, -0.0165]],
       dtype=torch.float16), 'model.layers.15.self_attn.k_proj.weight': tensor([[ 0.0209, -0.0054, -0.0045,  ..., -0.0027,  0.0014,  0.0044],
        [ 0.0111, -0.0042, -0.0052,  ..., -0.0015,  0.0046, -0.0135],
        [-0.0021,  0.0020, -0.0083,  ..., -0.0007,  0.0133, -0.0119],
        ...,
        [-0.0540, -0.0380,  0.0168,  ...,  0.0214,  0.0069, -0.0060],
        [ 0.0092,  0.0011,  0.0159,  ...,  0.0275, -0.0217,  0.0132],
        [-0.0067, -0.0060,  0.0341,  ..., -0.0027, -0.0171,  0.0033]],
       dtype=torch.float16), 'model.layers.15.self_attn.v_proj.weight': tensor([[ 0.0088,  0.0023,  0.0053,  ...,  0.0037,  0.0141,  0.0177],
        [-0.0096, -0.0142,  0.0151,  ...,  0.0168,  0.0018,  0.0224],
        [ 0.0075, -0.0377, -0.0064,  ..., -0.0365,  0.0073,  0.0073],
        ...,
        [-0.0038, -0.0107,  0.0116,  ...,  0.0066,  0.0181, -0.0141],
        [ 0.0056, -0.0006, -0.0311,  ...,  0.0116,  0.0151, -0.0054],
        [ 0.0169,  0.0104,  0.0152,  ..., -0.0160,  0.0075,  0.0077]],
       dtype=torch.float16), 'model.layers.15.self_attn.o_proj.weight': tensor([[ 0.0012,  0.0029, -0.0154,  ...,  0.0104, -0.0127,  0.0282],
        [-0.0046, -0.0112, -0.0177,  ...,  0.0099, -0.0261,  0.0198],
        [ 0.0020, -0.0083,  0.0008,  ...,  0.0102, -0.0070,  0.0095],
        ...,
        [-0.0089, -0.0197,  0.0142,  ..., -0.0044, -0.0201, -0.0100],
        [ 0.0005, -0.0017, -0.0072,  ...,  0.0113,  0.0051,  0.0044],
        [-0.0241,  0.0053,  0.0263,  ..., -0.0118, -0.0254, -0.0296]],
       dtype=torch.float16), 'model.layers.15.mlp.gate_proj.weight': tensor([[-0.0145,  0.0259, -0.0075,  ...,  0.0116, -0.0298,  0.0140],
        [ 0.0069, -0.0101,  0.0278,  ..., -0.0192,  0.0056,  0.0099],
        [ 0.0088, -0.0179, -0.0112,  ...,  0.0231, -0.0539, -0.0260],
        ...,
        [-0.0106, -0.0046,  0.0301,  ..., -0.0094,  0.0175,  0.0069],
        [-0.0124, -0.0172,  0.0103,  ..., -0.0082, -0.0106, -0.0440],
        [ 0.0040, -0.0142, -0.0008,  ...,  0.0002,  0.0071, -0.0001]],
       dtype=torch.float16), 'model.layers.15.mlp.up_proj.weight': tensor([[-1.2886e-02, -9.5215e-03,  2.7924e-02,  ...,  1.2367e-02,
          1.1269e-02, -4.3579e-02],
        [-1.5732e-02,  4.2908e-02,  2.9343e-02,  ...,  1.0506e-02,
          7.6866e-03,  3.9864e-03],
        [-4.2419e-02, -7.7896e-03, -4.7994e-04,  ..., -1.5518e-02,
          1.5602e-02, -1.0269e-02],
        ...,
        [-6.7863e-03, -2.3376e-02, -7.8659e-03,  ...,  8.5068e-03,
         -4.8757e-05, -4.9782e-03],
        [ 2.7618e-02, -5.3329e-03,  7.8354e-03,  ..., -1.0330e-02,
          1.5747e-02,  5.7030e-04],
        [-7.5302e-03, -2.7130e-02, -9.7809e-03,  ...,  4.5633e-04,
         -1.2245e-02,  1.1940e-03]], dtype=torch.float16), 'model.layers.15.mlp.down_proj.weight': tensor([[-1.2512e-02, -6.8245e-03, -1.6098e-02,  ...,  2.5909e-02,
          9.1171e-03, -1.0674e-02],
        [ 1.0666e-02, -1.1749e-02, -2.6199e-02,  ..., -1.1993e-02,
         -2.3163e-02,  1.6129e-02],
        [ 3.8452e-02,  4.4830e-02, -1.5747e-02,  ..., -1.1589e-02,
          3.4302e-02,  1.8906e-02],
        ...,
        [-4.5853e-03, -3.9978e-02,  6.3210e-03,  ...,  9.4833e-03,
          5.5046e-03,  7.1466e-05],
        [-4.1779e-02, -1.7502e-02, -1.1826e-03,  ..., -2.9480e-02,
         -1.5137e-02,  7.0038e-03],
        [ 1.5354e-03,  2.3773e-02, -6.3553e-03,  ..., -1.7715e-02,
         -3.2593e-02, -2.0401e-02]], dtype=torch.float16), 'model.layers.15.input_layernorm.weight': tensor([0.4160, 0.4102, 0.3809,  ..., 0.3867, 0.3945, 0.3945],
       dtype=torch.float16), 'model.layers.15.post_attention_layernorm.weight': tensor([0.2930, 0.2793, 0.2793,  ..., 0.2969, 0.2910, 0.2891],
       dtype=torch.float16), 'model.layers.16.self_attn.q_proj.weight': tensor([[ 0.0090,  0.0135, -0.0253,  ...,  0.0048,  0.0263, -0.0078],
        [ 0.0172, -0.0415,  0.0228,  ...,  0.0170,  0.0186, -0.0237],
        [-0.0128, -0.0067,  0.0088,  ..., -0.0257,  0.0021, -0.0261],
        ...,
        [ 0.0328, -0.0378, -0.0080,  ..., -0.0196,  0.0181, -0.0271],
        [-0.0166, -0.0170,  0.0283,  ...,  0.0018, -0.0181,  0.0157],
        [ 0.0046,  0.0219,  0.0146,  ..., -0.0030, -0.0327, -0.0095]],
       dtype=torch.float16), 'model.layers.16.self_attn.k_proj.weight': tensor([[-0.0072,  0.0235,  0.0023,  ...,  0.0131,  0.0227,  0.0217],
        [ 0.0223, -0.0315,  0.0097,  ..., -0.0058, -0.0194, -0.0077],
        [ 0.0272, -0.0056, -0.0197,  ..., -0.0234,  0.0092, -0.0277],
        ...,
        [ 0.0239,  0.0135, -0.0127,  ..., -0.0233, -0.0399, -0.0581],
        [ 0.0161,  0.0086,  0.0133,  ...,  0.0302,  0.0043,  0.0115],
        [-0.0444,  0.0565,  0.0591,  ...,  0.0017, -0.0147,  0.0274]],
       dtype=torch.float16), 'model.layers.16.self_attn.v_proj.weight': tensor([[-0.0166,  0.0066, -0.0049,  ...,  0.0065, -0.0008, -0.0020],
        [-0.0576, -0.0069,  0.0042,  ...,  0.0035,  0.0128, -0.0267],
        [-0.0069, -0.0133, -0.0021,  ..., -0.0211,  0.0416,  0.0151],
        ...,
        [ 0.0040, -0.0079,  0.0167,  ..., -0.0125, -0.0001,  0.0166],
        [-0.0169,  0.0023,  0.0052,  ...,  0.0389, -0.0043,  0.0089],
        [ 0.0118,  0.0102,  0.0083,  ..., -0.0158, -0.0042, -0.0301]],
       dtype=torch.float16), 'model.layers.16.self_attn.o_proj.weight': tensor([[ 0.0388, -0.0079, -0.0170,  ...,  0.0112, -0.0126,  0.0047],
        [-0.0246,  0.0107, -0.0208,  ...,  0.0039, -0.0083,  0.0016],
        [-0.0285, -0.0177, -0.0134,  ..., -0.0021,  0.0259,  0.0170],
        ...,
        [-0.0030, -0.0207,  0.0029,  ...,  0.0046, -0.0266,  0.0010],
        [-0.0073,  0.0199,  0.0344,  ..., -0.0005,  0.0009, -0.0051],
        [-0.0192,  0.0035,  0.0066,  ...,  0.0018,  0.0024,  0.0109]],
       dtype=torch.float16), 'model.layers.16.mlp.gate_proj.weight': tensor([[-0.0275, -0.0157, -0.0233,  ...,  0.0007, -0.0003,  0.0085],
        [ 0.0313,  0.0157, -0.0098,  ...,  0.0153,  0.0087,  0.0166],
        [ 0.0027,  0.0056,  0.0041,  ..., -0.0008, -0.0035, -0.0189],
        ...,
        [-0.0086,  0.0085,  0.0053,  ...,  0.0223,  0.0300,  0.0286],
        [-0.0033, -0.0147,  0.0094,  ...,  0.0099,  0.0210,  0.0115],
        [ 0.0256,  0.0212,  0.0310,  ..., -0.0399,  0.0148, -0.0203]],
       dtype=torch.float16), 'model.layers.16.mlp.up_proj.weight': tensor([[-0.0403,  0.0147,  0.0066,  ...,  0.0294, -0.0128,  0.0091],
        [ 0.0156, -0.0131,  0.0048,  ...,  0.0215, -0.0303, -0.0077],
        [-0.0078, -0.0256, -0.0064,  ..., -0.0124, -0.0047,  0.0258],
        ...,
        [-0.0096,  0.0263, -0.0066,  ...,  0.0095, -0.0235, -0.0248],
        [-0.0098,  0.0216, -0.0177,  ...,  0.0097, -0.0052,  0.0185],
        [ 0.0099,  0.0079, -0.0118,  ...,  0.0013, -0.0239, -0.0209]],
       dtype=torch.float16), 'model.layers.16.mlp.down_proj.weight': tensor([[-0.0236,  0.0045,  0.0134,  ...,  0.0206, -0.0091, -0.0008],
        [-0.0233, -0.0041, -0.0123,  ...,  0.0286,  0.0018, -0.0002],
        [-0.0142,  0.0049, -0.0120,  ...,  0.0201, -0.0042, -0.0009],
        ...,
        [ 0.0143, -0.0248, -0.0242,  ...,  0.0203,  0.0178, -0.0020],
        [ 0.0227,  0.0019, -0.0097,  ..., -0.0214, -0.0128, -0.0098],
        [ 0.0107, -0.0168, -0.0371,  ...,  0.0256, -0.0010, -0.0141]],
       dtype=torch.float16), 'model.layers.16.input_layernorm.weight': tensor([0.4180, 0.4219, 0.3906,  ..., 0.3984, 0.4160, 0.4082],
       dtype=torch.float16), 'model.layers.16.post_attention_layernorm.weight': tensor([0.3164, 0.2949, 0.2988,  ..., 0.3105, 0.3086, 0.3047],
       dtype=torch.float16), 'model.layers.17.self_attn.q_proj.weight': tensor([[-0.0125, -0.0138,  0.0065,  ...,  0.0073, -0.0072, -0.0107],
        [ 0.0094, -0.0095,  0.0169,  ...,  0.0019, -0.0260,  0.0081],
        [-0.0130, -0.0020, -0.0129,  ...,  0.0152, -0.0114,  0.0020],
        ...,
        [ 0.0362, -0.0261,  0.0562,  ..., -0.0142, -0.0178,  0.0079],
        [ 0.0282, -0.0184,  0.0462,  ...,  0.0094, -0.0215, -0.0601],
        [ 0.0126, -0.0017,  0.0116,  ...,  0.0320,  0.0013,  0.0742]],
       dtype=torch.float16), 'model.layers.17.self_attn.k_proj.weight': tensor([[-0.0127, -0.0063,  0.0040,  ..., -0.0014,  0.0197,  0.0079],
        [ 0.0078,  0.0072,  0.0041,  ...,  0.0103,  0.0002, -0.0138],
        [ 0.0077, -0.0085,  0.0012,  ...,  0.0154, -0.0231, -0.0079],
        ...,
        [ 0.0041, -0.0500, -0.0091,  ..., -0.0221,  0.0599, -0.0676],
        [ 0.0275,  0.0191,  0.0122,  ..., -0.0132, -0.0267, -0.0225],
        [-0.0380, -0.0470, -0.0048,  ...,  0.0278,  0.0259, -0.0048]],
       dtype=torch.float16), 'model.layers.17.self_attn.v_proj.weight': tensor([[-0.0122,  0.0105,  0.0024,  ...,  0.0239, -0.0088, -0.0096],
        [-0.0039, -0.0155, -0.0111,  ...,  0.0116, -0.0257, -0.0144],
        [ 0.0174,  0.0158, -0.0024,  ...,  0.0018, -0.0111, -0.0288],
        ...,
        [ 0.0010, -0.0043,  0.0143,  ...,  0.0121,  0.0051, -0.0155],
        [ 0.0189, -0.0031, -0.0388,  ..., -0.0152, -0.0034, -0.0341],
        [-0.0093, -0.0103, -0.0053,  ...,  0.0055,  0.0081,  0.0092]],
       dtype=torch.float16), 'model.layers.17.self_attn.o_proj.weight': tensor([[-0.0049, -0.0105,  0.0036,  ..., -0.0197,  0.0008, -0.0131],
        [-0.0116, -0.0207,  0.0218,  ...,  0.0219, -0.0174,  0.0221],
        [ 0.0098, -0.0111, -0.0045,  ..., -0.0186, -0.0138, -0.0218],
        ...,
        [-0.0109,  0.0140, -0.0118,  ..., -0.0310, -0.0329, -0.0185],
        [-0.0070,  0.0101, -0.0009,  ..., -0.0287,  0.0044,  0.0065],
        [-0.0155, -0.0129,  0.0072,  ...,  0.0329, -0.0223,  0.0173]],
       dtype=torch.float16), 'model.layers.17.mlp.gate_proj.weight': tensor([[-0.0341,  0.0291,  0.0243,  ...,  0.0059,  0.0021,  0.0031],
        [-0.0008,  0.0264,  0.0270,  ...,  0.0185,  0.0077,  0.0121],
        [ 0.0100,  0.0120, -0.0222,  ...,  0.0171,  0.0307, -0.0055],
        ...,
        [-0.0114, -0.0160, -0.0122,  ..., -0.0103, -0.0229, -0.0157],
        [ 0.0041,  0.0033,  0.0092,  ...,  0.0065,  0.0431, -0.0114],
        [-0.0032,  0.0208,  0.0144,  ..., -0.0138, -0.0018, -0.0032]],
       dtype=torch.float16), 'model.layers.17.mlp.up_proj.weight': tensor([[-0.0169, -0.0280, -0.0067,  ...,  0.0061,  0.0168, -0.0130],
        [-0.0231,  0.0152,  0.0278,  ...,  0.0003,  0.0016,  0.0020],
        [-0.0010, -0.0031,  0.0035,  ...,  0.0089, -0.0150,  0.0119],
        ...,
        [ 0.0138,  0.0168,  0.0068,  ...,  0.0064, -0.0204, -0.0130],
        [-0.0162, -0.0182, -0.0103,  ..., -0.0115, -0.0220,  0.0159],
        [-0.0032,  0.0038, -0.0083,  ...,  0.0034, -0.0360, -0.0131]],
       dtype=torch.float16), 'model.layers.17.mlp.down_proj.weight': tensor([[ 0.0260, -0.0225,  0.0134,  ...,  0.0120, -0.0079, -0.0022],
        [ 0.0285,  0.0301,  0.0086,  ...,  0.0063, -0.0083,  0.0336],
        [-0.0263, -0.0165, -0.0178,  ...,  0.0121, -0.0150, -0.0046],
        ...,
        [ 0.0067, -0.0222, -0.0068,  ..., -0.0141, -0.0051, -0.0367],
        [ 0.0015,  0.0053, -0.0114,  ..., -0.0275, -0.0274,  0.0174],
        [-0.0009, -0.0200,  0.0189,  ..., -0.0368, -0.0108,  0.0045]],
       dtype=torch.float16), 'model.layers.17.input_layernorm.weight': tensor([0.4316, 0.4336, 0.4043,  ..., 0.4238, 0.4277, 0.4062],
       dtype=torch.float16), 'model.layers.17.post_attention_layernorm.weight': tensor([0.3320, 0.3164, 0.3145,  ..., 0.3320, 0.3301, 0.3223],
       dtype=torch.float16), 'model.layers.18.self_attn.q_proj.weight': tensor([[ 0.0067,  0.0054,  0.0022,  ..., -0.0046, -0.0363,  0.0100],
        [ 0.0022, -0.0133,  0.0213,  ...,  0.0001,  0.0255,  0.0434],
        [ 0.0111, -0.0257, -0.0097,  ...,  0.0015, -0.0081,  0.0164],
        ...,
        [-0.0324,  0.0133,  0.0033,  ...,  0.0230,  0.0055,  0.0155],
        [ 0.0622, -0.0166, -0.0270,  ...,  0.0574,  0.0266,  0.0184],
        [ 0.0301,  0.0155,  0.0043,  ...,  0.0281,  0.0549, -0.0513]],
       dtype=torch.float16), 'model.layers.18.self_attn.k_proj.weight': tensor([[-0.0115,  0.0326, -0.0141,  ...,  0.0089, -0.0094, -0.0243],
        [ 0.0082, -0.0191,  0.0162,  ...,  0.0176,  0.0292,  0.0015],
        [ 0.0123, -0.0097, -0.0019,  ...,  0.0210, -0.0017,  0.0248],
        ...,
        [-0.1082, -0.0282, -0.0618,  ...,  0.0203, -0.0044, -0.0386],
        [ 0.0520,  0.0363, -0.0182,  ...,  0.0459,  0.0646, -0.0261],
        [-0.0487, -0.0503, -0.0435,  ...,  0.0343, -0.0235, -0.0319]],
       dtype=torch.float16), 'model.layers.18.self_attn.v_proj.weight': tensor([[-0.0296,  0.0286, -0.0176,  ...,  0.0053,  0.0276,  0.0051],
        [ 0.0173,  0.0070, -0.0124,  ..., -0.0175,  0.0382, -0.0023],
        [ 0.0001,  0.0193,  0.0009,  ...,  0.0046, -0.0021, -0.0077],
        ...,
        [ 0.0137,  0.0160, -0.0047,  ..., -0.0077, -0.0233,  0.0025],
        [ 0.0073, -0.0028,  0.0031,  ...,  0.0136,  0.0159,  0.0355],
        [-0.0068,  0.0012,  0.0111,  ..., -0.0062, -0.0200,  0.0024]],
       dtype=torch.float16), 'model.layers.18.self_attn.o_proj.weight': tensor([[-0.0180,  0.0188, -0.0144,  ...,  0.0118,  0.0222,  0.0198],
        [-0.0003, -0.0400,  0.0047,  ..., -0.0010, -0.0070, -0.0164],
        [ 0.0022, -0.0141,  0.0099,  ...,  0.0279,  0.0158,  0.0373],
        ...,
        [-0.0351, -0.0236, -0.0248,  ...,  0.0230,  0.0176, -0.0098],
        [ 0.0128,  0.0511,  0.0149,  ...,  0.0131, -0.0084, -0.0367],
        [-0.0119, -0.0472, -0.0218,  ..., -0.0158,  0.0139, -0.0140]],
       dtype=torch.float16), 'model.layers.18.mlp.gate_proj.weight': tensor([[ 0.0147, -0.0038,  0.0166,  ..., -0.0080,  0.0101, -0.0105],
        [-0.0428,  0.0071, -0.0162,  ..., -0.0086, -0.0150, -0.0096],
        [-0.0190,  0.0073,  0.0444,  ..., -0.0250,  0.0031,  0.0038],
        ...,
        [-0.0438, -0.0219, -0.0285,  ..., -0.0296, -0.0218, -0.0233],
        [ 0.0015,  0.0197,  0.0297,  ..., -0.0164, -0.0011,  0.0164],
        [ 0.0040, -0.0041,  0.0039,  ...,  0.0107, -0.0188, -0.0050]],
       dtype=torch.float16), 'model.layers.18.mlp.up_proj.weight': tensor([[ 0.0165,  0.0081,  0.0298,  ..., -0.0004,  0.0271, -0.0095],
        [-0.0201,  0.0243, -0.0282,  ..., -0.0057, -0.0087, -0.0003],
        [-0.0311, -0.0098,  0.0076,  ...,  0.0074,  0.0209,  0.0261],
        ...,
        [-0.0012,  0.0045,  0.0046,  ...,  0.0238, -0.0075,  0.0040],
        [-0.0094, -0.0048, -0.0210,  ...,  0.0134,  0.0343,  0.0362],
        [ 0.0087,  0.0248,  0.0111,  ..., -0.0163,  0.0135,  0.0152]],
       dtype=torch.float16), 'model.layers.18.mlp.down_proj.weight': tensor([[ 0.0152,  0.0034, -0.0323,  ...,  0.0311,  0.0165,  0.0073],
        [ 0.0117, -0.0078,  0.0196,  ...,  0.0007, -0.0016, -0.0021],
        [ 0.0172, -0.0250, -0.0335,  ...,  0.0177,  0.0036,  0.0148],
        ...,
        [-0.0127,  0.0210,  0.0102,  ...,  0.0230, -0.0081, -0.0087],
        [-0.0160,  0.0116,  0.0182,  ...,  0.0120,  0.0356,  0.0087],
        [-0.0091,  0.0257,  0.0244,  ..., -0.0073,  0.0167,  0.0157]],
       dtype=torch.float16), 'model.layers.18.input_layernorm.weight': tensor([0.4570, 0.4551, 0.4316,  ..., 0.4375, 0.4512, 0.4355],
       dtype=torch.float16), 'model.layers.18.post_attention_layernorm.weight': tensor([0.3477, 0.3340, 0.3320,  ..., 0.3477, 0.3496, 0.3457],
       dtype=torch.float16), 'model.layers.19.self_attn.q_proj.weight': tensor([[ 5.5275e-03,  7.6294e-03, -9.7961e-03,  ..., -1.0323e-02,
         -3.1209e-04,  8.8806e-03],
        [ 2.6894e-03, -2.5539e-03,  3.1719e-03,  ..., -4.7493e-03,
          2.9022e-02,  1.7868e-02],
        [ 5.2185e-03,  2.1896e-02,  4.5896e-05,  ...,  8.6498e-04,
          1.5182e-02,  3.0727e-03],
        ...,
        [-1.4160e-02, -1.4923e-02,  1.0290e-03,  ..., -4.4189e-02,
         -3.1805e-04,  2.4979e-02],
        [ 4.7226e-03,  4.8279e-02,  2.3041e-02,  ...,  5.4077e-02,
          2.9755e-02, -2.9358e-02],
        [-1.5991e-02,  4.9011e-02,  5.8014e-02,  ..., -6.6414e-03,
         -4.1382e-02, -1.4290e-02]], dtype=torch.float16), 'model.layers.19.self_attn.k_proj.weight': tensor([[ 0.0216,  0.0117,  0.0022,  ..., -0.0116, -0.0213, -0.0106],
        [-0.0142,  0.0180, -0.0159,  ...,  0.0100,  0.0034,  0.0251],
        [-0.0157,  0.0043, -0.0122,  ...,  0.0044,  0.0137,  0.0252],
        ...,
        [ 0.0005,  0.0502, -0.0095,  ..., -0.0208,  0.0299, -0.0225],
        [-0.0653, -0.0269, -0.0101,  ...,  0.0084,  0.0184, -0.0099],
        [-0.0202,  0.0115, -0.0150,  ..., -0.0266,  0.0129,  0.0399]],
       dtype=torch.float16), 'model.layers.19.self_attn.v_proj.weight': tensor([[-0.0011, -0.0055, -0.0055,  ..., -0.0020,  0.0005,  0.0070],
        [-0.0020,  0.0188, -0.0031,  ...,  0.0351, -0.0211,  0.0162],
        [-0.0448, -0.0359, -0.0080,  ..., -0.0085, -0.0002,  0.0056],
        ...,
        [ 0.0013, -0.0373, -0.0014,  ...,  0.0010, -0.0002, -0.0166],
        [ 0.0145, -0.0095, -0.0219,  ..., -0.0066, -0.0073, -0.0058],
        [-0.0033,  0.0275,  0.0008,  ..., -0.0254, -0.0120,  0.0062]],
       dtype=torch.float16), 'model.layers.19.self_attn.o_proj.weight': tensor([[ 0.0296, -0.0517,  0.0258,  ...,  0.0012,  0.0066, -0.0257],
        [ 0.0307, -0.0164, -0.0036,  ..., -0.0145, -0.0012, -0.0030],
        [-0.0033, -0.0176, -0.0195,  ...,  0.0010,  0.0150,  0.0012],
        ...,
        [ 0.0123, -0.0018,  0.0002,  ...,  0.0056, -0.0152,  0.0122],
        [ 0.0089, -0.0057, -0.0186,  ..., -0.0244, -0.0204,  0.0051],
        [ 0.0127,  0.0175,  0.0140,  ..., -0.0233, -0.0083,  0.0153]],
       dtype=torch.float16), 'model.layers.19.mlp.gate_proj.weight': tensor([[-0.0082,  0.0010,  0.0049,  ..., -0.0039,  0.0037, -0.0065],
        [ 0.0145,  0.0183,  0.0011,  ..., -0.0036,  0.0125, -0.0351],
        [-0.0169, -0.0121, -0.0127,  ..., -0.0433,  0.0002,  0.0285],
        ...,
        [-0.0016,  0.0101, -0.0004,  ..., -0.0291, -0.0092, -0.0010],
        [-0.0475, -0.0082,  0.0029,  ..., -0.0074, -0.0217,  0.0107],
        [-0.0205, -0.0197,  0.0153,  ...,  0.0069,  0.0052, -0.0020]],
       dtype=torch.float16), 'model.layers.19.mlp.up_proj.weight': tensor([[ 0.0020, -0.0107,  0.0096,  ...,  0.0065,  0.0100,  0.0032],
        [-0.0134, -0.0063, -0.0158,  ...,  0.0269, -0.0230, -0.0070],
        [ 0.0094,  0.0039,  0.0094,  ..., -0.0246, -0.0129,  0.0532],
        ...,
        [ 0.0142,  0.0140,  0.0074,  ...,  0.0136, -0.0170,  0.0311],
        [ 0.0013,  0.0262,  0.0249,  ..., -0.0094,  0.0361, -0.0004],
        [-0.0002, -0.0181, -0.0124,  ..., -0.0027,  0.0045,  0.0140]],
       dtype=torch.float16), 'model.layers.19.mlp.down_proj.weight': tensor([[-0.0026, -0.0278,  0.0015,  ...,  0.0057, -0.0235,  0.0278],
        [-0.0050, -0.0306, -0.0208,  ...,  0.0139,  0.0175, -0.0169],
        [-0.0209, -0.0261,  0.0290,  ...,  0.0159, -0.0008,  0.0071],
        ...,
        [-0.0104, -0.0050,  0.0274,  ...,  0.0129,  0.0162,  0.0012],
        [ 0.0065, -0.0093, -0.0501,  ...,  0.0219, -0.0086, -0.0152],
        [ 0.0041, -0.0093, -0.0342,  ...,  0.0006,  0.0090,  0.0042]],
       dtype=torch.float16), 'model.layers.19.input_layernorm.weight': tensor([0.4570, 0.4629, 0.4395,  ..., 0.4316, 0.4395, 0.4414],
       dtype=torch.float16), 'model.layers.19.post_attention_layernorm.weight': tensor([0.3613, 0.3477, 0.3457,  ..., 0.3574, 0.3555, 0.3594],
       dtype=torch.float16), 'model.layers.20.self_attn.q_proj.weight': tensor([[-3.3512e-03,  2.7599e-03,  2.2141e-02,  ...,  3.8643e-03,
          3.5381e-03, -2.3499e-02],
        [ 1.8127e-02, -2.1729e-02, -4.8876e-06,  ..., -6.9809e-03,
         -1.2131e-02,  1.7120e-02],
        [ 7.9117e-03, -6.8665e-03, -1.8326e-02,  ...,  1.7166e-02,
          7.0038e-03,  8.3780e-04],
        ...,
        [-3.1219e-02, -5.3162e-02,  1.0094e-02,  ..., -1.0918e-02,
          3.9520e-02,  1.1047e-02],
        [-8.0872e-02, -1.9455e-02,  1.1688e-02,  ...,  8.7585e-03,
          2.6505e-02,  8.3389e-03],
        [ 2.6978e-02,  2.4643e-03, -5.2071e-03,  ..., -1.9089e-02,
         -5.4512e-03, -1.3123e-03]], dtype=torch.float16), 'model.layers.20.self_attn.k_proj.weight': tensor([[-5.6038e-03,  7.3128e-03,  3.8834e-03,  ..., -1.6464e-02,
         -3.4750e-05,  3.6964e-03],
        [-3.7003e-04,  8.7585e-03,  4.4060e-03,  ..., -2.0161e-03,
          4.6120e-03,  1.1047e-02],
        [ 1.4694e-02,  2.8610e-03, -1.1185e-02,  ..., -1.5091e-02,
          1.4725e-03,  1.9836e-02],
        ...,
        [ 2.0256e-03,  4.9706e-03, -1.7044e-02,  ..., -2.3407e-02,
          2.5925e-02,  3.5919e-02],
        [-2.4094e-02,  2.4918e-02,  2.4490e-03,  ...,  2.1759e-02,
          3.0762e-02,  5.1605e-02],
        [-1.5228e-02, -3.0060e-02, -1.5793e-02,  ...,  2.0111e-02,
         -2.3468e-02,  5.2704e-02]], dtype=torch.float16), 'model.layers.20.self_attn.v_proj.weight': tensor([[-7.1526e-03, -1.8005e-02,  1.3290e-02,  ..., -2.7752e-03,
          1.9043e-02,  1.1086e-02],
        [-1.5945e-02, -3.7201e-02,  5.2223e-03,  ..., -1.2299e-02,
          3.4332e-04,  9.0942e-03],
        [-3.0174e-03, -1.3779e-02,  3.5763e-03,  ..., -2.5085e-02,
          9.9301e-05,  6.9046e-04],
        ...,
        [ 9.6893e-03, -1.2962e-02, -2.5940e-03,  ...,  2.4796e-02,
         -7.9269e-03,  9.0103e-03],
        [ 1.8799e-02,  1.4400e-03, -9.5062e-03,  ...,  8.0681e-04,
          1.1032e-02, -1.3542e-02],
        [ 2.3708e-03, -3.8452e-03,  2.4155e-02,  ..., -5.8403e-03,
         -1.1604e-02, -4.0283e-02]], dtype=torch.float16), 'model.layers.20.self_attn.o_proj.weight': tensor([[-0.0066,  0.0037,  0.0200,  ..., -0.0024,  0.0155, -0.0167],
        [ 0.0103, -0.0098, -0.0066,  ..., -0.0050, -0.0065,  0.0191],
        [ 0.0099, -0.0022, -0.0135,  ..., -0.0240,  0.0092,  0.0103],
        ...,
        [-0.0074, -0.0039,  0.0135,  ...,  0.0168, -0.0150,  0.0116],
        [-0.0101,  0.0031, -0.0113,  ...,  0.0121, -0.0273,  0.0036],
        [ 0.0107, -0.0183, -0.0039,  ...,  0.0065, -0.0230,  0.0195]],
       dtype=torch.float16), 'model.layers.20.mlp.gate_proj.weight': tensor([[ 0.0012, -0.0088, -0.0118,  ...,  0.0177, -0.0055,  0.0139],
        [-0.0275,  0.0091, -0.0060,  ..., -0.0098, -0.0143,  0.0149],
        [-0.0167, -0.0078,  0.0665,  ..., -0.0155,  0.0111, -0.0063],
        ...,
        [-0.0048, -0.0114,  0.0241,  ..., -0.0145,  0.0109, -0.0033],
        [ 0.0093,  0.0071,  0.0046,  ...,  0.0154,  0.0030,  0.0123],
        [-0.0032, -0.0308, -0.0070,  ...,  0.0059, -0.0142, -0.0134]],
       dtype=torch.float16), 'model.layers.20.mlp.up_proj.weight': tensor([[-0.0601, -0.0002, -0.0019,  ...,  0.0153, -0.0108, -0.0119],
        [-0.0098,  0.0006, -0.0098,  ..., -0.0502, -0.0143,  0.0372],
        [ 0.0060,  0.0302,  0.0182,  ...,  0.0070, -0.0175,  0.0047],
        ...,
        [-0.0139,  0.0211, -0.0016,  ..., -0.0180, -0.0043, -0.0030],
        [ 0.0155, -0.0318, -0.0148,  ...,  0.0031, -0.0208, -0.0377],
        [ 0.0145, -0.0241,  0.0311,  ..., -0.0039, -0.0222,  0.0036]],
       dtype=torch.float16), 'model.layers.20.mlp.down_proj.weight': tensor([[-0.0016,  0.0202, -0.0034,  ...,  0.0053, -0.0169, -0.0248],
        [ 0.0021,  0.0127, -0.0073,  ...,  0.0044, -0.0178,  0.0143],
        [-0.0127,  0.0180, -0.0242,  ..., -0.0042,  0.0238, -0.0053],
        ...,
        [-0.0375,  0.0276,  0.0056,  ...,  0.0026, -0.0002, -0.0114],
        [-0.0156,  0.0062, -0.0158,  ...,  0.0057,  0.0178, -0.0025],
        [ 0.0120, -0.0131,  0.0019,  ..., -0.0029, -0.0063, -0.0147]],
       dtype=torch.float16), 'model.layers.20.input_layernorm.weight': tensor([0.4590, 0.4688, 0.4395,  ..., 0.4414, 0.4375, 0.4590],
       dtype=torch.float16), 'model.layers.20.post_attention_layernorm.weight': tensor([0.3711, 0.3633, 0.3535,  ..., 0.3672, 0.3672, 0.3691],
       dtype=torch.float16), 'model.layers.21.self_attn.q_proj.weight': tensor([[-0.0138, -0.0057,  0.0144,  ..., -0.0153, -0.0030,  0.0070],
        [ 0.0252,  0.0060, -0.0012,  ...,  0.0031,  0.0002,  0.0141],
        [-0.0117, -0.0101,  0.0026,  ...,  0.0280,  0.0023,  0.0066],
        ...,
        [-0.0025, -0.0157,  0.0354,  ..., -0.0107, -0.0593,  0.0191],
        [-0.0115,  0.0166,  0.0210,  ...,  0.0295,  0.0328,  0.0014],
        [-0.0795, -0.0016, -0.0130,  ..., -0.0056,  0.0264, -0.0380]],
       dtype=torch.float16), 'model.layers.21.self_attn.k_proj.weight': tensor([[-1.3864e-04,  4.9858e-03, -3.4065e-03,  ...,  7.4348e-03,
          3.9625e-04,  1.0353e-02],
        [-8.3685e-05,  7.3128e-03,  1.9882e-02,  ...,  6.2561e-03,
          9.4681e-03,  8.8806e-03],
        [ 1.8494e-02,  2.9202e-03,  2.8900e-02,  ...,  1.5823e-02,
          1.2871e-02,  1.4816e-02],
        ...,
        [-1.8295e-02,  2.6428e-02,  1.5945e-03,  ...,  2.5818e-02,
         -1.9394e-02,  4.6265e-02],
        [ 2.0866e-03, -3.1281e-03, -1.4458e-02,  ..., -2.2232e-02,
          3.1250e-02,  1.6203e-03],
        [-1.8906e-02, -8.1329e-03, -3.1433e-02,  ...,  7.8888e-03,
         -7.5493e-03,  5.9235e-02]], dtype=torch.float16), 'model.layers.21.self_attn.v_proj.weight': tensor([[ 0.0032,  0.0054, -0.0003,  ...,  0.0005,  0.0223, -0.0286],
        [-0.0232,  0.0240, -0.0079,  ...,  0.0211, -0.0195,  0.0266],
        [ 0.0280, -0.0030,  0.0003,  ..., -0.0232,  0.0258, -0.0058],
        ...,
        [-0.0056, -0.0269,  0.0320,  ..., -0.0065,  0.0038, -0.0102],
        [-0.0154, -0.0090,  0.0156,  ...,  0.0048, -0.0052,  0.0086],
        [-0.0069,  0.0157, -0.0162,  ...,  0.0070, -0.0155, -0.0029]],
       dtype=torch.float16), 'model.layers.21.self_attn.o_proj.weight': tensor([[-0.0118, -0.0017,  0.0116,  ..., -0.0132,  0.0231,  0.0102],
        [-0.0058,  0.0267, -0.0098,  ..., -0.0189,  0.0061, -0.0112],
        [-0.0298, -0.0130,  0.0119,  ...,  0.0249,  0.0273,  0.0079],
        ...,
        [ 0.0198, -0.0042, -0.0136,  ...,  0.0248, -0.0006,  0.0144],
        [ 0.0152, -0.0136,  0.0135,  ..., -0.0006,  0.0018, -0.0185],
        [-0.0264,  0.0155, -0.0134,  ...,  0.0298, -0.0163,  0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.gate_proj.weight': tensor([[-0.0058, -0.0234,  0.0144,  ..., -0.0285,  0.0456,  0.0089],
        [ 0.0061,  0.0061,  0.0039,  ..., -0.0275,  0.0574,  0.0085],
        [ 0.0084,  0.0064,  0.0049,  ..., -0.0498,  0.0041, -0.0245],
        ...,
        [ 0.0102, -0.0292, -0.0215,  ...,  0.0331, -0.0270,  0.0024],
        [-0.0010,  0.0293,  0.0065,  ...,  0.0160, -0.0249,  0.0030],
        [ 0.0093, -0.0124, -0.0017,  ..., -0.0182,  0.0064, -0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.up_proj.weight': tensor([[ 0.0276, -0.0258, -0.0142,  ...,  0.0225,  0.0422, -0.0112],
        [-0.0261, -0.0107,  0.0040,  ...,  0.0379,  0.0453, -0.0010],
        [ 0.0133, -0.0011, -0.0018,  ...,  0.0067, -0.0079, -0.0061],
        ...,
        [-0.0461, -0.0002,  0.0137,  ...,  0.0162, -0.0095, -0.0118],
        [-0.0100, -0.0107,  0.0042,  ..., -0.0188, -0.0023,  0.0027],
        [-0.0051, -0.0337, -0.0248,  ..., -0.0035, -0.0055, -0.0260]],
       dtype=torch.float16), 'model.layers.21.mlp.down_proj.weight': tensor([[ 0.0117,  0.0132,  0.0028,  ...,  0.0198,  0.0068,  0.0062],
        [ 0.0095, -0.0029, -0.0151,  ...,  0.0037, -0.0319, -0.0163],
        [-0.0061,  0.0059,  0.0132,  ..., -0.0084,  0.0412,  0.0299],
        ...,
        [-0.0106,  0.0375,  0.0182,  ..., -0.0093, -0.0024,  0.0179],
        [ 0.0125,  0.0007, -0.0043,  ..., -0.0493, -0.0052,  0.0049],
        [ 0.0089,  0.0014,  0.0242,  ..., -0.0152,  0.0267, -0.0278]],
       dtype=torch.float16), 'model.layers.21.input_layernorm.weight': tensor([0.4805, 0.4883, 0.4688,  ..., 0.4609, 0.4805, 0.4824],
       dtype=torch.float16), 'model.layers.21.post_attention_layernorm.weight': tensor([0.3770, 0.3730, 0.3652,  ..., 0.3848, 0.3789, 0.3828],
       dtype=torch.float16), 'model.layers.22.self_attn.q_proj.weight': tensor([[-0.0249, -0.0096, -0.0046,  ...,  0.0535, -0.0391,  0.0201],
        [-0.0361, -0.0200, -0.0063,  ..., -0.0361,  0.0211, -0.0515],
        [-0.0322,  0.0232, -0.0146,  ...,  0.0286,  0.0173, -0.0100],
        ...,
        [ 0.0094,  0.0199,  0.0122,  ...,  0.0116,  0.0576, -0.0013],
        [-0.0323,  0.0064, -0.0220,  ...,  0.0465,  0.0088, -0.0131],
        [ 0.0380, -0.0125,  0.0065,  ..., -0.0505,  0.0111,  0.0195]],
       dtype=torch.float16), 'model.layers.22.self_attn.k_proj.weight': tensor([[-0.0130, -0.0065,  0.0037,  ...,  0.0139, -0.0164, -0.0157],
        [ 0.0106, -0.0099,  0.0312,  ..., -0.0320,  0.0375, -0.0140],
        [-0.0207,  0.0286, -0.0425,  ...,  0.0614,  0.0035, -0.0076],
        ...,
        [ 0.0210,  0.0074, -0.0286,  ..., -0.0204, -0.0135,  0.0172],
        [-0.0150, -0.0424,  0.0025,  ..., -0.0002, -0.0132, -0.0070],
        [ 0.0240, -0.0025,  0.0283,  ...,  0.0377, -0.0425,  0.0131]],
       dtype=torch.float16), 'model.layers.22.self_attn.v_proj.weight': tensor([[-0.0201,  0.0126, -0.0017,  ..., -0.0395, -0.0264,  0.0152],
        [-0.0346, -0.0108,  0.0072,  ..., -0.0269, -0.0413, -0.0159],
        [ 0.0243, -0.0267, -0.0040,  ...,  0.0528, -0.0026, -0.0139],
        ...,
        [-0.0104, -0.0462, -0.0226,  ...,  0.0124, -0.0114,  0.0218],
        [-0.0375, -0.0086,  0.0181,  ..., -0.0198,  0.0020, -0.0155],
        [ 0.0007,  0.0152, -0.0433,  ...,  0.0020, -0.0053,  0.0264]],
       dtype=torch.float16), 'model.layers.22.self_attn.o_proj.weight': tensor([[ 0.0263,  0.0156, -0.0218,  ..., -0.0026, -0.0353,  0.0123],
        [ 0.0242,  0.0126,  0.0108,  ...,  0.0045, -0.0100, -0.0247],
        [ 0.0046,  0.0026, -0.0081,  ..., -0.0232,  0.0110,  0.0107],
        ...,
        [-0.0008, -0.0238, -0.0129,  ..., -0.0138, -0.0166,  0.0042],
        [ 0.0259, -0.0104, -0.0196,  ..., -0.0260, -0.0027,  0.0137],
        [ 0.0039, -0.0258,  0.0213,  ...,  0.0115,  0.0122,  0.0111]],
       dtype=torch.float16), 'model.layers.22.mlp.gate_proj.weight': tensor([[-0.0284, -0.0156,  0.0184,  ...,  0.0108,  0.0197, -0.0452],
        [ 0.0226, -0.0165,  0.0014,  ...,  0.0043,  0.0029,  0.0221],
        [ 0.0005, -0.0069,  0.0054,  ...,  0.0142,  0.0002, -0.0003],
        ...,
        [-0.0043, -0.0079,  0.0014,  ..., -0.0152,  0.0073,  0.0022],
        [ 0.0095,  0.0165, -0.0293,  ..., -0.0035,  0.0127, -0.0289],
        [-0.0101,  0.0012,  0.0053,  ..., -0.0148,  0.0278,  0.0245]],
       dtype=torch.float16), 'model.layers.22.mlp.up_proj.weight': tensor([[ 0.0293,  0.0162, -0.0013,  ...,  0.0170,  0.0276,  0.0071],
        [ 0.0198,  0.0076,  0.0164,  ..., -0.0117, -0.0078,  0.0030],
        [ 0.0086, -0.0282, -0.0375,  ...,  0.0255,  0.0104,  0.0061],
        ...,
        [-0.0032, -0.0006, -0.0185,  ..., -0.0040,  0.0057,  0.0067],
        [ 0.0126, -0.0111, -0.0286,  ..., -0.0226,  0.0108, -0.0270],
        [-0.0014,  0.0023, -0.0036,  ..., -0.0440, -0.0598,  0.0154]],
       dtype=torch.float16), 'model.layers.22.mlp.down_proj.weight': tensor([[ 1.3527e-02, -5.1918e-03,  1.2299e-02,  ..., -1.8967e-02,
         -4.1428e-03, -3.6041e-02],
        [ 5.5885e-03,  2.6581e-02, -4.9362e-03,  ..., -1.1017e-02,
          1.4084e-02, -2.6627e-02],
        [-9.6512e-03,  3.9363e-04,  4.1962e-03,  ...,  1.2886e-02,
          4.5013e-03,  1.7517e-02],
        ...,
        [ 1.8250e-02, -8.5297e-03, -4.5288e-02,  ..., -2.8934e-03,
         -1.2947e-02, -1.7014e-02],
        [-1.1414e-02, -4.8767e-02,  1.1642e-02,  ...,  1.9028e-02,
         -2.7069e-02,  3.1433e-02],
        [ 1.4130e-02,  3.7551e-06, -3.1067e-02,  ..., -3.3903e-04,
         -1.8875e-02,  2.1286e-03]], dtype=torch.float16), 'model.layers.22.input_layernorm.weight': tensor([0.4883, 0.4922, 0.4805,  ..., 0.4688, 0.5000, 0.4902],
       dtype=torch.float16), 'model.layers.22.post_attention_layernorm.weight': tensor([0.3867, 0.3848, 0.3848,  ..., 0.3965, 0.3945, 0.3965],
       dtype=torch.float16), 'model.layers.23.self_attn.q_proj.weight': tensor([[-0.0039, -0.0179,  0.0076,  ..., -0.0155, -0.0002,  0.0023],
        [ 0.0042,  0.0015,  0.0140,  ..., -0.0166, -0.0002,  0.0083],
        [-0.0038,  0.0028,  0.0219,  ...,  0.0002, -0.0167,  0.0066],
        ...,
        [-0.0211,  0.0670,  0.0119,  ..., -0.0314, -0.0684, -0.0263],
        [-0.0411, -0.0311,  0.0199,  ..., -0.0232,  0.0020,  0.0060],
        [ 0.0047, -0.0559, -0.0093,  ...,  0.0072,  0.0403, -0.0026]],
       dtype=torch.float16), 'model.layers.23.self_attn.k_proj.weight': tensor([[-0.0030,  0.0121,  0.0090,  ...,  0.0010, -0.0083,  0.0059],
        [-0.0224,  0.0057, -0.0117,  ...,  0.0093,  0.0254,  0.0036],
        [ 0.0182,  0.0078, -0.0185,  ...,  0.0181,  0.0016, -0.0107],
        ...,
        [ 0.0067,  0.0374,  0.0580,  ..., -0.0332, -0.0120, -0.0131],
        [ 0.0034, -0.0352, -0.0113,  ..., -0.0232, -0.0226,  0.0194],
        [-0.0173, -0.0081, -0.0259,  ...,  0.0043,  0.0060, -0.0084]],
       dtype=torch.float16), 'model.layers.23.self_attn.v_proj.weight': tensor([[-0.0028,  0.0343, -0.0120,  ..., -0.0097, -0.0016, -0.0112],
        [-0.0093, -0.0038, -0.0190,  ..., -0.0033, -0.0097,  0.0105],
        [ 0.0111, -0.0211, -0.0208,  ...,  0.0130, -0.0508, -0.0305],
        ...,
        [ 0.0070,  0.0084,  0.0091,  ..., -0.0020,  0.0338,  0.0089],
        [ 0.0261,  0.0316, -0.0011,  ...,  0.0070,  0.0022, -0.0127],
        [-0.0201, -0.0131, -0.0540,  ...,  0.0057,  0.0076, -0.0381]],
       dtype=torch.float16), 'model.layers.23.self_attn.o_proj.weight': tensor([[-0.0019,  0.0019, -0.0202,  ..., -0.0179,  0.0104, -0.0070],
        [-0.0127, -0.0213, -0.0022,  ..., -0.0004,  0.0100, -0.0021],
        [ 0.0130,  0.0094,  0.0306,  ..., -0.0228, -0.0026, -0.0276],
        ...,
        [ 0.0290, -0.0114,  0.0348,  ..., -0.0162,  0.0113, -0.0013],
        [-0.0044,  0.0202, -0.0200,  ...,  0.0056, -0.0164,  0.0007],
        [ 0.0013, -0.0023, -0.0177,  ..., -0.0060,  0.0059, -0.0296]],
       dtype=torch.float16), 'model.layers.23.mlp.gate_proj.weight': tensor([[-1.1848e-02,  3.4424e-02, -1.0048e-02,  ..., -7.0152e-03,
          3.2776e-02,  9.2316e-03],
        [-1.4702e-02,  4.7729e-02, -1.7593e-02,  ...,  7.1678e-03,
         -1.8631e-02,  2.5070e-02],
        [-3.2349e-02,  1.4786e-02,  2.6913e-03,  ...,  1.5274e-02,
         -6.7444e-02,  1.2131e-02],
        ...,
        [-3.1548e-03,  1.9089e-02,  3.1509e-03,  ..., -8.1863e-03,
          7.2556e-03, -2.4643e-03],
        [-2.0828e-02,  3.8971e-02,  2.9430e-03,  ...,  3.3021e-05,
          7.8201e-03, -2.8381e-02],
        [ 8.8692e-04,  8.5144e-03,  1.6830e-02,  ..., -7.6561e-03,
          1.5450e-02, -1.6495e-02]], dtype=torch.float16), 'model.layers.23.mlp.up_proj.weight': tensor([[ 0.0283,  0.0066,  0.0351,  ...,  0.0134, -0.0322, -0.0074],
        [-0.0003,  0.0065, -0.0196,  ..., -0.0043, -0.0111,  0.0061],
        [-0.0177,  0.0038, -0.0218,  ...,  0.0182,  0.0106, -0.0052],
        ...,
        [-0.0084, -0.0166,  0.0116,  ...,  0.0093,  0.0408,  0.0053],
        [ 0.0036,  0.0078, -0.0382,  ...,  0.0106,  0.0070,  0.0220],
        [ 0.0014,  0.0079, -0.0071,  ...,  0.0070, -0.0126,  0.0127]],
       dtype=torch.float16), 'model.layers.23.mlp.down_proj.weight': tensor([[-0.0008,  0.0069, -0.0182,  ..., -0.0434, -0.0227,  0.0330],
        [-0.0012,  0.0231, -0.0064,  ...,  0.0257,  0.0306,  0.0021],
        [-0.0066, -0.0139, -0.0233,  ...,  0.0102,  0.0330, -0.0052],
        ...,
        [ 0.0001, -0.0050,  0.0135,  ...,  0.0180,  0.0037, -0.0187],
        [ 0.0296, -0.0114, -0.0007,  ..., -0.0026,  0.0101,  0.0058],
        [ 0.0031, -0.0307, -0.0152,  ..., -0.0104,  0.0204, -0.0025]],
       dtype=torch.float16), 'model.layers.23.input_layernorm.weight': tensor([0.5156, 0.5312, 0.5117,  ..., 0.5039, 0.5352, 0.5273],
       dtype=torch.float16), 'model.layers.23.post_attention_layernorm.weight': tensor([0.4043, 0.4023, 0.3965,  ..., 0.4043, 0.4121, 0.4062],
       dtype=torch.float16), 'model.layers.24.self_attn.q_proj.weight': tensor([[ 0.0204, -0.0176,  0.0145,  ...,  0.0364, -0.0300,  0.0106],
        [ 0.0215,  0.0088,  0.0012,  ..., -0.0026,  0.0186, -0.0139],
        [-0.0056, -0.0111, -0.0277,  ...,  0.0088, -0.0132,  0.0202],
        ...,
        [-0.0147,  0.0136, -0.0193,  ...,  0.0181, -0.0004, -0.0123],
        [-0.0288,  0.0078,  0.0070,  ...,  0.0100, -0.0323, -0.0062],
        [-0.0231, -0.0385, -0.0181,  ..., -0.0132,  0.0128,  0.0677]],
       dtype=torch.float16), 'model.layers.24.self_attn.k_proj.weight': tensor([[ 0.0235, -0.0035, -0.0125,  ...,  0.0110, -0.0008,  0.0021],
        [ 0.0118, -0.0169,  0.0035,  ..., -0.0216,  0.0245,  0.0066],
        [ 0.0097,  0.0045, -0.0445,  ...,  0.0204,  0.0171, -0.0175],
        ...,
        [ 0.0344,  0.0036,  0.0493,  ...,  0.0161,  0.0179, -0.0516],
        [-0.0119,  0.0177,  0.0127,  ...,  0.0320, -0.0181,  0.0027],
        [-0.0318, -0.0295, -0.0190,  ...,  0.0139, -0.0048,  0.0518]],
       dtype=torch.float16), 'model.layers.24.self_attn.v_proj.weight': tensor([[ 0.0212, -0.0251, -0.0028,  ..., -0.0041, -0.0040,  0.0113],
        [ 0.0288, -0.0173, -0.0054,  ..., -0.0646, -0.0470, -0.0240],
        [-0.0579, -0.0169, -0.0134,  ..., -0.0156, -0.0121, -0.0027],
        ...,
        [ 0.0011, -0.0192,  0.0171,  ...,  0.0272,  0.0067,  0.0217],
        [-0.0034, -0.0157, -0.0141,  ...,  0.0332, -0.0036,  0.0038],
        [ 0.0172,  0.0228,  0.0187,  ...,  0.0274, -0.0135, -0.0108]],
       dtype=torch.float16), 'model.layers.24.self_attn.o_proj.weight': tensor([[-0.0016,  0.0144,  0.0280,  ...,  0.0066, -0.0051, -0.0141],
        [-0.0118,  0.0308,  0.0156,  ...,  0.0195,  0.0282, -0.0186],
        [-0.0057, -0.0029,  0.0094,  ..., -0.0232,  0.0084, -0.0049],
        ...,
        [ 0.0045,  0.0179,  0.0119,  ..., -0.0027, -0.0031, -0.0005],
        [ 0.0508,  0.0096, -0.0061,  ...,  0.0075, -0.0257, -0.0106],
        [ 0.0026,  0.0155,  0.0109,  ...,  0.0046, -0.0261,  0.0131]],
       dtype=torch.float16), 'model.layers.24.mlp.gate_proj.weight': tensor([[-0.0267, -0.0104,  0.0093,  ..., -0.0031, -0.0058,  0.0011],
        [ 0.0075, -0.0302, -0.0231,  ...,  0.0075,  0.0110, -0.0131],
        [ 0.0014, -0.0466,  0.0257,  ...,  0.0015, -0.0532, -0.0207],
        ...,
        [ 0.0042, -0.0358, -0.0088,  ...,  0.0080,  0.0152, -0.0062],
        [ 0.0094,  0.0158,  0.0041,  ...,  0.0043,  0.0011,  0.0048],
        [-0.0410,  0.0326,  0.0009,  ...,  0.0294, -0.0074, -0.0473]],
       dtype=torch.float16), 'model.layers.24.mlp.up_proj.weight': tensor([[ 0.0016, -0.0057,  0.0201,  ...,  0.0262,  0.0025,  0.0263],
        [-0.0026,  0.0136, -0.0327,  ..., -0.0081, -0.0044, -0.0171],
        [ 0.0114, -0.0520,  0.0097,  ...,  0.0402,  0.0179, -0.0341],
        ...,
        [ 0.0115, -0.0207, -0.0147,  ..., -0.0067,  0.0112,  0.0111],
        [ 0.0412, -0.0033,  0.0132,  ...,  0.0025,  0.0054, -0.0100],
        [-0.0056, -0.0197,  0.0203,  ...,  0.0303,  0.0333,  0.0164]],
       dtype=torch.float16), 'model.layers.24.mlp.down_proj.weight': tensor([[-0.0052, -0.0114, -0.0357,  ...,  0.0015,  0.0022, -0.0194],
        [ 0.0278, -0.0030,  0.0175,  ..., -0.0015,  0.0048, -0.0508],
        [ 0.0195,  0.0135, -0.0284,  ...,  0.0095,  0.0215,  0.0078],
        ...,
        [-0.0092,  0.0149, -0.0204,  ..., -0.0330, -0.0109, -0.0146],
        [ 0.0112,  0.0248,  0.0120,  ...,  0.0257, -0.0255,  0.0133],
        [-0.0171, -0.0086,  0.0033,  ...,  0.0172, -0.0154, -0.0324]],
       dtype=torch.float16), 'model.layers.24.input_layernorm.weight': tensor([0.4980, 0.5273, 0.5195,  ..., 0.4863, 0.5234, 0.5156],
       dtype=torch.float16), 'model.layers.24.post_attention_layernorm.weight': tensor([0.4219, 0.4180, 0.4180,  ..., 0.4199, 0.4258, 0.4219],
       dtype=torch.float16), 'model.layers.25.self_attn.q_proj.weight': tensor([[ 1.7204e-03, -1.9974e-02, -2.5269e-02,  ...,  1.2192e-02,
         -9.5139e-03,  4.5357e-03],
        [-1.3947e-02,  3.5877e-03,  2.3804e-02,  ..., -1.4412e-02,
         -3.4485e-03,  2.4557e-05],
        [ 9.1629e-03,  8.6136e-03,  3.9368e-03,  ..., -1.1436e-02,
         -2.0157e-02, -1.5068e-02],
        ...,
        [ 5.5756e-02,  4.5746e-02,  2.2964e-03,  ...,  4.9858e-03,
          1.5762e-02, -2.6688e-02],
        [-6.3721e-02, -5.0293e-02, -1.2497e-02,  ..., -1.0338e-02,
         -2.1088e-02,  4.0932e-03],
        [ 3.9978e-02, -4.3365e-02, -2.2217e-02,  ...,  3.9279e-05,
          1.0757e-02, -2.6917e-02]], dtype=torch.float16), 'model.layers.25.self_attn.k_proj.weight': tensor([[-5.6648e-03, -1.3237e-02, -1.2611e-02,  ...,  1.5726e-03,
          1.6232e-03,  1.4572e-03],
        [-1.4183e-02, -1.4297e-02,  2.7120e-05,  ..., -3.4618e-03,
         -2.1515e-02,  7.6561e-03],
        [-8.5354e-04,  1.9426e-03,  4.9133e-03,  ...,  6.0310e-03,
         -6.0654e-03,  7.2212e-03],
        ...,
        [ 1.3847e-02,  4.8248e-02, -9.6283e-03,  ..., -5.4504e-02,
         -5.6427e-02,  3.7598e-02],
        [ 3.4454e-02, -3.4393e-02,  4.3602e-03,  ..., -8.3771e-03,
          2.8229e-03,  1.0277e-02],
        [-7.9346e-03, -2.7908e-02,  3.2768e-03,  ...,  3.6316e-02,
          8.8501e-03, -2.9388e-02]], dtype=torch.float16), 'model.layers.25.self_attn.v_proj.weight': tensor([[ 0.0173,  0.0201,  0.0084,  ...,  0.0248, -0.0133, -0.0128],
        [-0.0143, -0.0107,  0.0099,  ...,  0.0090, -0.0273, -0.0127],
        [-0.0150,  0.0164, -0.0202,  ..., -0.0099,  0.0054, -0.0090],
        ...,
        [-0.0186, -0.0324, -0.0026,  ...,  0.0150,  0.0097,  0.0189],
        [-0.0152,  0.0089,  0.0258,  ..., -0.0068,  0.0044, -0.0216],
        [-0.0386, -0.0105, -0.0145,  ...,  0.0065,  0.0192,  0.0297]],
       dtype=torch.float16), 'model.layers.25.self_attn.o_proj.weight': tensor([[ 1.9470e-02,  1.0475e-02,  1.3229e-02,  ...,  1.4595e-02,
          2.8362e-03,  3.7861e-03],
        [-2.6352e-02, -9.8953e-03, -1.6998e-02,  ...,  2.6093e-02,
         -7.1945e-03, -1.3523e-03],
        [-8.1863e-03, -1.5879e-03,  2.5925e-02,  ..., -1.9821e-02,
         -1.3336e-02, -1.3371e-03],
        ...,
        [-1.3893e-02,  2.3819e-02, -2.7676e-03,  ...,  1.0544e-02,
          1.3359e-02,  2.7084e-02],
        [-4.1842e-05, -2.7664e-02, -3.7750e-02,  ..., -2.3926e-02,
         -1.6037e-02,  2.2125e-03],
        [-2.4704e-02, -8.4839e-03, -1.3412e-02,  ..., -3.7964e-02,
         -2.0554e-02, -1.3344e-02]], dtype=torch.float16), 'model.layers.25.mlp.gate_proj.weight': tensor([[ 0.0037, -0.0402,  0.0397,  ..., -0.0020, -0.0228,  0.0070],
        [-0.0239, -0.0074, -0.0153,  ...,  0.0345,  0.0486,  0.0262],
        [-0.0017,  0.0171, -0.0012,  ...,  0.0176,  0.0161,  0.0310],
        ...,
        [-0.0347,  0.0086,  0.0019,  ..., -0.0027, -0.0130,  0.0004],
        [ 0.0218,  0.0088,  0.0610,  ...,  0.0170,  0.0224,  0.0062],
        [-0.0047, -0.0022, -0.0174,  ...,  0.0450,  0.0030, -0.0100]],
       dtype=torch.float16), 'model.layers.25.mlp.up_proj.weight': tensor([[-0.0265, -0.0114,  0.0169,  ...,  0.0016,  0.0052, -0.0100],
        [-0.0138, -0.0033,  0.0076,  ..., -0.0056,  0.0163,  0.0114],
        [ 0.0298,  0.0056,  0.0224,  ..., -0.0136, -0.0282, -0.0026],
        ...,
        [ 0.0102,  0.0049,  0.0475,  ...,  0.0056, -0.0394, -0.0210],
        [-0.0387, -0.0015, -0.0307,  ..., -0.0457, -0.0228, -0.0002],
        [-0.0147, -0.0097,  0.0229,  ...,  0.0258, -0.0055,  0.0242]],
       dtype=torch.float16), 'model.layers.25.mlp.down_proj.weight': tensor([[ 0.0289, -0.0159,  0.0110,  ...,  0.0204, -0.0067,  0.0310],
        [-0.0150, -0.0020,  0.0045,  ...,  0.0100, -0.0012,  0.0230],
        [ 0.0123,  0.0103, -0.0082,  ..., -0.0229,  0.0118, -0.0181],
        ...,
        [ 0.0188, -0.0142, -0.0232,  ..., -0.0466, -0.0010,  0.0237],
        [ 0.0065, -0.0114,  0.0031,  ...,  0.0045,  0.0039,  0.0058],
        [-0.0111, -0.0243,  0.0161,  ..., -0.0298, -0.0061, -0.0051]],
       dtype=torch.float16), 'model.layers.25.input_layernorm.weight': tensor([0.5547, 0.5703, 0.5547,  ..., 0.5547, 0.5742, 0.5625],
       dtype=torch.float16), 'model.layers.25.post_attention_layernorm.weight': tensor([0.4316, 0.4316, 0.4297,  ..., 0.4355, 0.4336, 0.4395],
       dtype=torch.float16), 'model.layers.26.self_attn.q_proj.weight': tensor([[ 0.0299, -0.0067, -0.0090,  ..., -0.0101,  0.0408,  0.0010],
        [-0.0050, -0.0182,  0.0142,  ...,  0.0062, -0.0230,  0.0177],
        [-0.0064,  0.0024,  0.0114,  ...,  0.0050, -0.0381, -0.0195],
        ...,
        [ 0.0009, -0.0125, -0.0078,  ...,  0.0158,  0.0216,  0.0021],
        [ 0.0070, -0.0182, -0.0230,  ...,  0.0060, -0.0005, -0.0075],
        [-0.0146,  0.0520,  0.0271,  ..., -0.0072, -0.0645, -0.0416]],
       dtype=torch.float16), 'model.layers.26.self_attn.k_proj.weight': tensor([[ 0.0220,  0.0199, -0.0121,  ..., -0.0308,  0.0384,  0.0029],
        [-0.0267,  0.0055,  0.0148,  ...,  0.0016,  0.0168,  0.0291],
        [ 0.0129,  0.0286,  0.0004,  ..., -0.0190, -0.0591, -0.0098],
        ...,
        [ 0.0247,  0.0246,  0.0012,  ..., -0.0466, -0.0545,  0.0259],
        [-0.0216, -0.0389, -0.0074,  ...,  0.0483,  0.0228, -0.0051],
        [-0.0171,  0.0094, -0.0132,  ...,  0.0006, -0.0198, -0.0154]],
       dtype=torch.float16), 'model.layers.26.self_attn.v_proj.weight': tensor([[ 0.0506, -0.0262, -0.0245,  ..., -0.0152,  0.0105, -0.0191],
        [-0.0491, -0.0213,  0.0254,  ...,  0.0101, -0.0062,  0.0016],
        [ 0.0013, -0.0020, -0.0238,  ..., -0.0061,  0.0042, -0.0306],
        ...,
        [-0.0236, -0.0176, -0.0008,  ...,  0.0428, -0.0050,  0.0086],
        [ 0.0039, -0.0365, -0.0094,  ..., -0.0166, -0.0242, -0.0042],
        [ 0.0092,  0.0188, -0.0045,  ...,  0.0071,  0.0064,  0.0172]],
       dtype=torch.float16), 'model.layers.26.self_attn.o_proj.weight': tensor([[ 0.0108, -0.0005, -0.0306,  ...,  0.0052,  0.0149,  0.0272],
        [ 0.0067,  0.0455,  0.0062,  ..., -0.0016,  0.0462, -0.0053],
        [ 0.0013,  0.0102, -0.0247,  ..., -0.0226,  0.0037, -0.0018],
        ...,
        [ 0.0307,  0.0040,  0.0108,  ..., -0.0002,  0.0182,  0.0043],
        [-0.0128,  0.0049, -0.0096,  ...,  0.0135, -0.0017, -0.0425],
        [ 0.0257,  0.0072,  0.0050,  ..., -0.0276,  0.0283, -0.0160]],
       dtype=torch.float16), 'model.layers.26.mlp.gate_proj.weight': tensor([[ 0.0187,  0.0045,  0.0131,  ...,  0.0258,  0.0262, -0.0261],
        [-0.0062,  0.0102, -0.0258,  ..., -0.0255, -0.0266,  0.0190],
        [ 0.0022, -0.0109,  0.0007,  ...,  0.0060,  0.0038, -0.0172],
        ...,
        [-0.0065,  0.0356, -0.0078,  ..., -0.0015, -0.0380, -0.0219],
        [-0.0150,  0.0138,  0.0250,  ...,  0.0159,  0.0240,  0.0123],
        [ 0.0182, -0.0038, -0.0058,  ..., -0.0301, -0.0062, -0.0043]],
       dtype=torch.float16), 'model.layers.26.mlp.up_proj.weight': tensor([[-0.0168,  0.0401,  0.0018,  ...,  0.0049, -0.0029, -0.0195],
        [-0.0410, -0.0193,  0.0116,  ...,  0.0265, -0.0069,  0.0175],
        [ 0.0082, -0.0065, -0.0241,  ...,  0.0146, -0.0218, -0.0152],
        ...,
        [ 0.0058, -0.0324,  0.0059,  ...,  0.0126,  0.0300, -0.0139],
        [-0.0445,  0.0100,  0.0505,  ...,  0.0299, -0.0133,  0.0091],
        [ 0.0003, -0.0191,  0.0266,  ..., -0.0121,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.layers.26.mlp.down_proj.weight': tensor([[-0.0157, -0.0151, -0.0184,  ...,  0.0317,  0.0165,  0.0026],
        [ 0.0194,  0.0122,  0.0013,  ...,  0.0555,  0.0187, -0.0188],
        [-0.0182,  0.0041, -0.0274,  ..., -0.0111,  0.0171,  0.0083],
        ...,
        [-0.0175, -0.0124, -0.0203,  ...,  0.0105,  0.0436, -0.0020],
        [-0.0128, -0.0142, -0.0195,  ...,  0.0095,  0.0033,  0.0230],
        [ 0.0049, -0.0129, -0.0006,  ...,  0.0101,  0.0221,  0.0164]],
       dtype=torch.float16), 'model.layers.26.input_layernorm.weight': tensor([0.5312, 0.5469, 0.5469,  ..., 0.5234, 0.5508, 0.5547],
       dtype=torch.float16), 'model.layers.26.post_attention_layernorm.weight': tensor([0.4492, 0.4492, 0.4375,  ..., 0.4512, 0.4590, 0.4590],
       dtype=torch.float16), 'model.layers.27.self_attn.q_proj.weight': tensor([[-0.0292,  0.0145,  0.0077,  ..., -0.0038,  0.0122,  0.0435],
        [-0.0134,  0.0433,  0.0299,  ..., -0.0242,  0.0111,  0.0059],
        [-0.0217, -0.0236,  0.0096,  ...,  0.0025, -0.0223,  0.0289],
        ...,
        [-0.0505,  0.0273, -0.0095,  ...,  0.0185, -0.0201, -0.0225],
        [-0.0039,  0.0271,  0.0072,  ...,  0.0084,  0.0002,  0.0258],
        [-0.0235, -0.0104,  0.0114,  ...,  0.0226,  0.0154, -0.0077]],
       dtype=torch.float16), 'model.layers.27.self_attn.k_proj.weight': tensor([[-0.0173, -0.0195,  0.0098,  ..., -0.0015, -0.0104,  0.0059],
        [-0.0029,  0.0090,  0.0194,  ...,  0.0424, -0.0081, -0.0110],
        [ 0.0017, -0.0138,  0.0081,  ..., -0.0129,  0.0021, -0.0088],
        ...,
        [-0.0041, -0.0153,  0.0362,  ...,  0.0069, -0.0344, -0.0087],
        [ 0.0248, -0.0192, -0.0473,  ...,  0.0660, -0.0128,  0.0439],
        [ 0.0315,  0.0143, -0.0021,  ..., -0.0374, -0.0376,  0.0114]],
       dtype=torch.float16), 'model.layers.27.self_attn.v_proj.weight': tensor([[ 0.0174, -0.0144, -0.0334,  ...,  0.0311,  0.0319, -0.0054],
        [ 0.0185,  0.0108,  0.0118,  ...,  0.0023, -0.0246,  0.0214],
        [-0.0263, -0.0055,  0.0169,  ..., -0.0106,  0.0546, -0.0242],
        ...,
        [ 0.0146, -0.0203, -0.0192,  ...,  0.0176, -0.0095, -0.0034],
        [ 0.0059, -0.0240, -0.0200,  ..., -0.0100, -0.0106, -0.0184],
        [ 0.0211, -0.0241, -0.0149,  ..., -0.0229, -0.0193,  0.0111]],
       dtype=torch.float16), 'model.layers.27.self_attn.o_proj.weight': tensor([[ 0.0038, -0.0119,  0.0095,  ...,  0.0242,  0.0067, -0.0269],
        [ 0.0054,  0.0286, -0.0241,  ..., -0.0172, -0.0162,  0.0058],
        [-0.0047, -0.0113, -0.0132,  ...,  0.0162,  0.0009, -0.0092],
        ...,
        [ 0.0251, -0.0114, -0.0128,  ...,  0.0111,  0.0484, -0.0008],
        [ 0.0368, -0.0221, -0.0091,  ..., -0.0011, -0.0006,  0.0184],
        [ 0.0446,  0.0125,  0.0281,  ..., -0.0113, -0.0002, -0.0220]],
       dtype=torch.float16), 'model.layers.27.mlp.gate_proj.weight': tensor([[ 0.0450,  0.0128, -0.0067,  ...,  0.0097,  0.0032, -0.0147],
        [-0.0158,  0.0018, -0.0322,  ...,  0.0303,  0.0333,  0.0226],
        [ 0.0075,  0.0203, -0.0080,  ..., -0.0125, -0.0238,  0.0320],
        ...,
        [ 0.0358,  0.0211,  0.0024,  ..., -0.0008,  0.0165, -0.0047],
        [-0.0144,  0.0255, -0.0209,  ..., -0.0090, -0.0178,  0.0073],
        [ 0.0026, -0.0184, -0.0149,  ..., -0.0166, -0.0047, -0.0048]],
       dtype=torch.float16), 'model.layers.27.mlp.up_proj.weight': tensor([[-0.0049,  0.0078,  0.0265,  ..., -0.0012,  0.0131, -0.0389],
        [-0.0102,  0.0028, -0.0278,  ...,  0.0119, -0.0223, -0.0237],
        [ 0.0258,  0.0162,  0.0435,  ...,  0.0278,  0.0015, -0.0196],
        ...,
        [-0.0044,  0.0250,  0.0330,  ..., -0.0218,  0.0206, -0.0381],
        [ 0.0097,  0.0212,  0.0149,  ...,  0.0130, -0.0131, -0.0248],
        [-0.0111,  0.0048, -0.0053,  ..., -0.0063, -0.0244, -0.0093]],
       dtype=torch.float16), 'model.layers.27.mlp.down_proj.weight': tensor([[ 2.4376e-03, -2.2705e-02,  3.4363e-02,  ..., -1.9394e-02,
          1.9669e-02, -1.1414e-02],
        [ 8.0466e-05,  1.3931e-02, -9.4910e-03,  ..., -1.9272e-02,
         -3.1616e-02,  1.2093e-02],
        [ 4.6478e-02,  1.3847e-02,  5.7602e-03,  ..., -3.2166e-02,
          4.1733e-03,  2.9587e-02],
        ...,
        [-7.6523e-03,  1.0971e-02,  1.5335e-02,  ...,  7.5302e-03,
         -4.5685e-02,  2.5742e-02],
        [-2.2018e-02, -3.3932e-03, -1.7227e-02,  ...,  2.2934e-02,
         -9.0866e-03,  2.0813e-02],
        [ 4.7493e-03,  1.7471e-02, -9.1858e-03,  ...,  1.9531e-02,
         -2.3441e-03, -4.7493e-03]], dtype=torch.float16), 'model.layers.27.input_layernorm.weight': tensor([0.5625, 0.5625, 0.5586,  ..., 0.5547, 0.5625, 0.5703],
       dtype=torch.float16), 'model.layers.27.post_attention_layernorm.weight': tensor([0.4688, 0.4629, 0.4531,  ..., 0.4668, 0.4707, 0.4688],
       dtype=torch.float16), 'model.layers.28.self_attn.q_proj.weight': tensor([[-3.2127e-05, -1.9119e-02, -7.1669e-04,  ..., -1.4694e-02,
         -9.0561e-03, -1.0872e-02],
        [ 1.1421e-02, -1.8387e-02, -2.4986e-03,  ...,  1.3634e-02,
          5.4283e-03, -3.9635e-03],
        [ 1.4305e-02,  6.4993e-04, -1.0948e-02,  ..., -3.7956e-03,
         -2.4414e-02,  2.4261e-02],
        ...,
        [-1.1253e-02,  2.4719e-02, -5.3101e-02,  ...,  1.6006e-02,
         -7.5684e-03, -3.9825e-02],
        [ 1.6541e-02, -2.6855e-02, -1.2665e-02,  ...,  2.0569e-02,
          3.2928e-02, -6.5002e-02],
        [ 1.9409e-02,  1.4633e-02, -4.5654e-02,  ...,  4.5868e-02,
          1.4122e-02, -3.6987e-02]], dtype=torch.float16), 'model.layers.28.self_attn.k_proj.weight': tensor([[-0.0036, -0.0034,  0.0078,  ..., -0.0043,  0.0148, -0.0134],
        [-0.0133, -0.0068, -0.0168,  ..., -0.0066,  0.0050,  0.0043],
        [ 0.0061,  0.0063, -0.0146,  ..., -0.0197, -0.0112,  0.0050],
        ...,
        [-0.0251, -0.0133, -0.0040,  ..., -0.0014, -0.0604, -0.0040],
        [ 0.0462, -0.0221,  0.0039,  ...,  0.0161,  0.0397,  0.0285],
        [ 0.0180, -0.0042,  0.0045,  ..., -0.0038, -0.0185, -0.0136]],
       dtype=torch.float16), 'model.layers.28.self_attn.v_proj.weight': tensor([[-0.0240,  0.0090,  0.0227,  ..., -0.0210, -0.0288,  0.0260],
        [ 0.0231, -0.0178, -0.0135,  ..., -0.0447,  0.0313, -0.0163],
        [-0.0102,  0.0174, -0.0021,  ...,  0.0075, -0.0479,  0.0167],
        ...,
        [ 0.0193,  0.0043, -0.0005,  ...,  0.0143, -0.0064, -0.0217],
        [ 0.0511,  0.0041,  0.0421,  ...,  0.0019,  0.0046, -0.0031],
        [ 0.0181,  0.0192, -0.0485,  ...,  0.0328, -0.0048,  0.0090]],
       dtype=torch.float16), 'model.layers.28.self_attn.o_proj.weight': tensor([[ 1.1208e-02,  2.4567e-02, -4.1473e-02,  ..., -3.4485e-02,
          1.7929e-02, -9.8646e-05],
        [-1.2238e-02, -2.0905e-02, -2.8381e-03,  ..., -1.7075e-02,
          2.7145e-02,  3.2501e-02],
        [ 2.7863e-02,  1.7838e-02, -5.3741e-02,  ...,  2.2293e-02,
          1.5701e-02, -1.6464e-02],
        ...,
        [ 2.5444e-03, -4.4098e-03,  3.4332e-02,  ..., -9.8801e-03,
         -3.9917e-02, -6.6757e-03],
        [-7.5188e-03, -5.8655e-02, -1.8112e-02,  ...,  2.0889e-02,
         -2.8183e-02, -2.7084e-02],
        [-4.3823e-02, -4.1618e-03, -1.0742e-02,  ..., -1.9196e-02,
         -8.0719e-03,  4.2839e-03]], dtype=torch.float16), 'model.layers.28.mlp.gate_proj.weight': tensor([[-0.0007,  0.0031, -0.0068,  ...,  0.0274, -0.0111,  0.0312],
        [-0.0257,  0.0139, -0.0106,  ...,  0.0121,  0.0034,  0.0177],
        [ 0.0099,  0.0288,  0.0274,  ...,  0.0168,  0.0038,  0.0067],
        ...,
        [-0.0053,  0.0228,  0.0102,  ...,  0.0135,  0.0128, -0.0202],
        [ 0.0124, -0.0344, -0.0104,  ..., -0.0197, -0.0044, -0.0032],
        [-0.0318,  0.0149,  0.0106,  ..., -0.0078, -0.0112,  0.0179]],
       dtype=torch.float16), 'model.layers.28.mlp.up_proj.weight': tensor([[ 0.0224,  0.0047,  0.0220,  ...,  0.0277,  0.0156,  0.0114],
        [-0.0177, -0.0260, -0.0041,  ..., -0.0033, -0.0355, -0.0220],
        [ 0.0064,  0.0259, -0.0073,  ...,  0.0068,  0.0073, -0.0160],
        ...,
        [-0.0055, -0.0151,  0.0324,  ..., -0.0026,  0.0111, -0.0013],
        [-0.0215,  0.0078, -0.0074,  ...,  0.0127, -0.0099, -0.0497],
        [-0.0093, -0.0252, -0.0048,  ..., -0.0067,  0.0076,  0.0080]],
       dtype=torch.float16), 'model.layers.28.mlp.down_proj.weight': tensor([[ 0.0077,  0.0342, -0.0055,  ...,  0.0029, -0.0016, -0.0298],
        [-0.0009, -0.0338,  0.0198,  ..., -0.0268, -0.0070, -0.0280],
        [-0.0241,  0.0253, -0.0140,  ...,  0.0032,  0.0074, -0.0012],
        ...,
        [ 0.0106, -0.0143, -0.0053,  ..., -0.0309, -0.0309,  0.0070],
        [-0.0170, -0.0194,  0.0628,  ..., -0.0242, -0.0061,  0.0128],
        [-0.0234,  0.0108, -0.0081,  ...,  0.0294,  0.0295, -0.0142]],
       dtype=torch.float16), 'model.layers.28.input_layernorm.weight': tensor([0.5781, 0.5859, 0.5664,  ..., 0.5547, 0.5742, 0.5742],
       dtype=torch.float16), 'model.layers.28.post_attention_layernorm.weight': tensor([0.4805, 0.4785, 0.4648,  ..., 0.4785, 0.4727, 0.4727],
       dtype=torch.float16), 'model.layers.29.self_attn.q_proj.weight': tensor([[ 0.0060,  0.0026, -0.0075,  ...,  0.0002, -0.0110,  0.0094],
        [-0.0288, -0.0180, -0.0257,  ..., -0.0128, -0.0063, -0.0059],
        [-0.0291,  0.0377, -0.0024,  ..., -0.0022, -0.0156,  0.0146],
        ...,
        [ 0.0005,  0.0704, -0.0331,  ...,  0.0133, -0.0080, -0.0352],
        [-0.0236, -0.0242,  0.0169,  ..., -0.0142, -0.0230,  0.0260],
        [ 0.0005, -0.0416, -0.0127,  ...,  0.0132,  0.0065, -0.0391]],
       dtype=torch.float16), 'model.layers.29.self_attn.k_proj.weight': tensor([[ 0.0357, -0.0135, -0.0162,  ...,  0.0005,  0.0101, -0.0023],
        [-0.0177,  0.0316, -0.0048,  ..., -0.0086,  0.0006, -0.0218],
        [ 0.0214,  0.0079,  0.0186,  ...,  0.0193,  0.0339, -0.0014],
        ...,
        [-0.0317,  0.0448,  0.0010,  ..., -0.0091,  0.0024, -0.0117],
        [ 0.0014, -0.0123, -0.0701,  ..., -0.0106, -0.0095, -0.0427],
        [ 0.0107, -0.0124, -0.0583,  ..., -0.0584, -0.0144,  0.0027]],
       dtype=torch.float16), 'model.layers.29.self_attn.v_proj.weight': tensor([[ 0.0110,  0.0064,  0.0324,  ...,  0.0194,  0.0085,  0.0135],
        [-0.0017,  0.0247,  0.0385,  ..., -0.0199,  0.0092, -0.0022],
        [-0.0130,  0.0104, -0.0103,  ...,  0.0083,  0.0268,  0.0188],
        ...,
        [ 0.0067,  0.0294,  0.0116,  ..., -0.0203, -0.0125, -0.0172],
        [ 0.0001,  0.0276, -0.0236,  ...,  0.0186,  0.0294, -0.0053],
        [-0.0033, -0.0211,  0.0092,  ..., -0.0019, -0.0083,  0.0262]],
       dtype=torch.float16), 'model.layers.29.self_attn.o_proj.weight': tensor([[-6.3057e-03,  3.2288e-02,  3.3630e-02,  ...,  5.8222e-04,
         -1.7517e-02, -6.4850e-03],
        [-2.0340e-02, -2.5772e-02, -1.2833e-02,  ...,  1.2199e-02,
         -2.8244e-02,  1.2634e-02],
        [ 2.6093e-02,  2.8381e-02, -8.5678e-03,  ..., -3.7781e-02,
          1.7441e-02, -2.1240e-02],
        ...,
        [-2.8381e-02, -1.6617e-02,  2.8061e-02,  ..., -7.0839e-03,
         -7.8201e-03, -1.4076e-02],
        [-1.3969e-02, -1.0399e-02,  3.3966e-02,  ..., -4.7803e-05,
         -2.0554e-02,  4.7226e-03],
        [ 1.5411e-02,  3.9749e-03, -3.4275e-03,  ...,  4.1122e-03,
          1.9104e-02, -2.8473e-02]], dtype=torch.float16), 'model.layers.29.mlp.gate_proj.weight': tensor([[ 0.0161,  0.0169, -0.0145,  ..., -0.0036, -0.0243,  0.0359],
        [ 0.0034,  0.0243, -0.0081,  ..., -0.0228,  0.0151,  0.0046],
        [ 0.0371, -0.0013, -0.0085,  ..., -0.0063,  0.0206,  0.0335],
        ...,
        [-0.0048,  0.0104, -0.0152,  ...,  0.0026,  0.0065,  0.0039],
        [ 0.0079,  0.0031, -0.0292,  ..., -0.0222, -0.0051,  0.0174],
        [-0.0031,  0.0190, -0.0012,  ...,  0.0228, -0.0130, -0.0158]],
       dtype=torch.float16), 'model.layers.29.mlp.up_proj.weight': tensor([[-0.0069,  0.0021,  0.0118,  ...,  0.0150,  0.0049,  0.0057],
        [ 0.0012,  0.0072,  0.0320,  ...,  0.0089, -0.0199,  0.0363],
        [-0.0076, -0.0212, -0.0125,  ..., -0.0495,  0.0085, -0.0360],
        ...,
        [ 0.0260,  0.0129,  0.0126,  ...,  0.0124,  0.0245,  0.0357],
        [-0.0250, -0.0191, -0.0051,  ...,  0.0142,  0.0133,  0.0017],
        [ 0.0065, -0.0030,  0.0111,  ..., -0.0080,  0.0094,  0.0100]],
       dtype=torch.float16), 'model.layers.29.mlp.down_proj.weight': tensor([[ 0.0411,  0.0098, -0.0018,  ...,  0.0168, -0.0244, -0.0152],
        [ 0.0184,  0.0098,  0.0223,  ...,  0.0344,  0.0027,  0.0017],
        [ 0.0008, -0.0209, -0.0160,  ..., -0.0007,  0.0110, -0.0271],
        ...,
        [ 0.0088, -0.0090,  0.0057,  ..., -0.0189, -0.0051, -0.0197],
        [ 0.0228,  0.0159,  0.0265,  ...,  0.0094, -0.0411,  0.0024],
        [ 0.0148, -0.0185, -0.0088,  ..., -0.0158, -0.0135,  0.0045]],
       dtype=torch.float16), 'model.layers.29.input_layernorm.weight': tensor([0.5430, 0.5586, 0.5391,  ..., 0.5312, 0.5586, 0.5625],
       dtype=torch.float16), 'model.layers.29.post_attention_layernorm.weight': tensor([0.4902, 0.4922, 0.4785,  ..., 0.4785, 0.4922, 0.4805],
       dtype=torch.float16), 'model.layers.30.self_attn.q_proj.weight': tensor([[-0.0041, -0.0047,  0.0075,  ..., -0.0091, -0.0045,  0.0028],
        [ 0.0163,  0.0142,  0.0050,  ..., -0.0033, -0.0027, -0.0191],
        [-0.0086, -0.0204,  0.0428,  ...,  0.0224,  0.0053, -0.0305],
        ...,
        [-0.0093, -0.0009, -0.0012,  ...,  0.0209, -0.0119,  0.0017],
        [-0.0005, -0.0218, -0.0206,  ...,  0.0153,  0.0086, -0.0354],
        [-0.0708, -0.0093,  0.0420,  ..., -0.0094, -0.0046, -0.0015]],
       dtype=torch.float16), 'model.layers.30.self_attn.k_proj.weight': tensor([[ 0.0262, -0.0208,  0.0015,  ..., -0.0112,  0.0095,  0.0076],
        [ 0.0337,  0.0127,  0.0035,  ..., -0.0041, -0.0045,  0.0022],
        [-0.0044, -0.0148,  0.0216,  ...,  0.0055, -0.0088, -0.0004],
        ...,
        [ 0.0057,  0.0255,  0.0007,  ...,  0.0564, -0.0037, -0.0002],
        [ 0.0107, -0.0630,  0.0325,  ...,  0.0062, -0.0082, -0.0273],
        [-0.0373, -0.0082,  0.0209,  ...,  0.0079,  0.0169, -0.0247]],
       dtype=torch.float16), 'model.layers.30.self_attn.v_proj.weight': tensor([[-0.0035, -0.0291,  0.0310,  ..., -0.0268, -0.0363,  0.0307],
        [ 0.0073,  0.0172,  0.0300,  ..., -0.0118,  0.0262,  0.0019],
        [-0.0203,  0.0174, -0.0189,  ...,  0.0050, -0.0255, -0.0103],
        ...,
        [ 0.0184, -0.0039, -0.0030,  ..., -0.0245,  0.0030,  0.0241],
        [-0.0072, -0.0434,  0.0219,  ...,  0.0296, -0.0089,  0.0216],
        [-0.0088,  0.0059,  0.0193,  ..., -0.0144, -0.0613, -0.0227]],
       dtype=torch.float16), 'model.layers.30.self_attn.o_proj.weight': tensor([[-0.0074,  0.0176, -0.0070,  ...,  0.0119, -0.0119, -0.0202],
        [-0.0116, -0.0252, -0.0082,  ...,  0.0136, -0.0305, -0.0236],
        [-0.0294, -0.0029,  0.0179,  ..., -0.0482, -0.0128, -0.0113],
        ...,
        [ 0.0068,  0.0052,  0.0028,  ..., -0.0247,  0.0106,  0.0177],
        [ 0.0227, -0.0089,  0.0036,  ...,  0.0353, -0.0069,  0.0047],
        [-0.0028,  0.0133, -0.0032,  ..., -0.0048,  0.0101, -0.0147]],
       dtype=torch.float16), 'model.layers.30.mlp.gate_proj.weight': tensor([[-0.0422, -0.0289, -0.0057,  ...,  0.0138, -0.0067, -0.0003],
        [-0.0175,  0.0047,  0.0389,  ..., -0.0063, -0.0058,  0.0305],
        [-0.0219, -0.0067, -0.0307,  ...,  0.0154, -0.0004, -0.0035],
        ...,
        [-0.0204, -0.0261,  0.0121,  ..., -0.0081, -0.0219, -0.0244],
        [ 0.0268,  0.0282, -0.0097,  ...,  0.0118, -0.0396, -0.0025],
        [-0.0012, -0.0307, -0.0203,  ..., -0.0023,  0.0182, -0.0061]],
       dtype=torch.float16), 'model.layers.30.mlp.up_proj.weight': tensor([[ 0.0034,  0.0162,  0.0123,  ...,  0.0126,  0.0213, -0.0029],
        [-0.0196, -0.0118,  0.0388,  ...,  0.0008, -0.0193, -0.0033],
        [-0.0327, -0.0235, -0.0368,  ..., -0.0176,  0.0011,  0.0209],
        ...,
        [-0.0163, -0.0128,  0.0153,  ...,  0.0128, -0.0097, -0.0216],
        [-0.0081,  0.0077, -0.0097,  ...,  0.0053, -0.0229,  0.0164],
        [-0.0030, -0.0283,  0.0003,  ..., -0.0168,  0.0070,  0.0171]],
       dtype=torch.float16), 'model.layers.30.mlp.down_proj.weight': tensor([[ 2.2812e-02, -1.3634e-02, -3.0258e-02,  ...,  3.1342e-02,
         -7.2098e-03, -8.8263e-04],
        [ 2.5818e-02,  4.8409e-03,  4.3427e-02,  ...,  1.2611e-02,
          1.6594e-03, -7.8888e-03],
        [ 3.6883e-04, -3.0899e-03, -2.1591e-02,  ...,  3.1242e-03,
          1.0376e-02,  2.0767e-02],
        ...,
        [-3.1921e-02,  6.3400e-03, -2.4643e-02,  ...,  1.8341e-02,
         -2.4780e-02, -9.6664e-03],
        [-4.3750e-05, -1.9287e-02,  2.8934e-03,  ...,  1.9730e-02,
          2.3232e-03,  1.2312e-03],
        [-8.7738e-03, -1.4030e-02, -2.5955e-02,  ...,  1.0109e-02,
          3.0589e-04, -1.9150e-02]], dtype=torch.float16), 'model.layers.30.input_layernorm.weight': tensor([0.5859, 0.6016, 0.5664,  ..., 0.5586, 0.5781, 0.6016],
       dtype=torch.float16), 'model.layers.30.post_attention_layernorm.weight': tensor([0.4824, 0.5039, 0.4824,  ..., 0.4883, 0.4980, 0.4863],
       dtype=torch.float16), 'model.layers.31.self_attn.q_proj.weight': tensor([[-0.0350,  0.0179,  0.0228,  ...,  0.0133, -0.0005, -0.0199],
        [-0.0200, -0.0252, -0.0369,  ...,  0.0008, -0.0122, -0.0238],
        [-0.0219,  0.0272,  0.0192,  ..., -0.0004,  0.0037,  0.0022],
        ...,
        [ 0.0171, -0.0177, -0.0151,  ..., -0.0145,  0.0273, -0.0253],
        [-0.0265,  0.0056, -0.0053,  ..., -0.0029,  0.0124,  0.0107],
        [-0.0533, -0.0123,  0.0282,  ...,  0.0389, -0.0044,  0.0329]],
       dtype=torch.float16), 'model.layers.31.self_attn.k_proj.weight': tensor([[-0.0058, -0.0082,  0.0132,  ..., -0.0011, -0.0107, -0.0206],
        [ 0.0245, -0.0202,  0.0109,  ..., -0.0002,  0.0066, -0.0021],
        [ 0.0027,  0.0117, -0.0064,  ...,  0.0055, -0.0005, -0.0275],
        ...,
        [ 0.0315, -0.0261, -0.0244,  ..., -0.0081, -0.0101, -0.0515],
        [ 0.0134,  0.0200,  0.0124,  ..., -0.0259, -0.0236,  0.0204],
        [-0.0787, -0.0352,  0.0162,  ..., -0.0131,  0.0023, -0.0065]],
       dtype=torch.float16), 'model.layers.31.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0230, -0.0018,  ...,  0.0031,  0.0012,  0.0155],
        [ 0.0281,  0.0153,  0.0112,  ...,  0.0094,  0.0336,  0.0164],
        [ 0.0143, -0.0011, -0.0159,  ...,  0.0129,  0.0024,  0.0344],
        ...,
        [-0.0017, -0.0013, -0.0144,  ..., -0.0160, -0.0032,  0.0248],
        [ 0.0126, -0.0183,  0.0156,  ..., -0.0102, -0.0292,  0.0144],
        [-0.0103, -0.0228,  0.0264,  ...,  0.0243, -0.0042,  0.0403]],
       dtype=torch.float16), 'model.layers.31.self_attn.o_proj.weight': tensor([[ 0.0089,  0.0304, -0.0052,  ..., -0.0004, -0.0148, -0.0504],
        [-0.0065,  0.0034, -0.0314,  ...,  0.0269, -0.0200, -0.0146],
        [ 0.0102,  0.0023,  0.0032,  ..., -0.0174,  0.0214,  0.0120],
        ...,
        [ 0.0077, -0.0209,  0.0315,  ..., -0.0161, -0.0128, -0.0216],
        [ 0.0010,  0.0138, -0.0207,  ..., -0.0174, -0.0141, -0.0177],
        [ 0.0062,  0.0165, -0.0088,  ...,  0.0295, -0.0164,  0.0075]],
       dtype=torch.float16), 'model.layers.31.mlp.gate_proj.weight': tensor([[ 0.0088, -0.0101,  0.0378,  ...,  0.0157,  0.0179,  0.0108],
        [-0.0751, -0.0179,  0.0038,  ...,  0.0049, -0.0193,  0.0181],
        [ 0.0142,  0.0066, -0.0107,  ..., -0.0041, -0.0197, -0.0075],
        ...,
        [-0.0168, -0.0297,  0.0126,  ..., -0.0009,  0.0242,  0.0329],
        [ 0.0417,  0.0298, -0.0222,  ...,  0.0354, -0.0096, -0.0061],
        [ 0.0174, -0.0382, -0.0287,  ..., -0.0177,  0.0085,  0.0057]],
       dtype=torch.float16), 'model.layers.31.mlp.up_proj.weight': tensor([[-0.0397, -0.0182,  0.0206,  ...,  0.0010, -0.0187,  0.0024],
        [ 0.0275,  0.0354,  0.0046,  ..., -0.0228,  0.0012, -0.0013],
        [-0.0043,  0.0044, -0.0210,  ...,  0.0143,  0.0034, -0.0117],
        ...,
        [ 0.0134, -0.0182,  0.0072,  ...,  0.0026,  0.0326, -0.0186],
        [ 0.0055,  0.0044, -0.0258,  ...,  0.0280,  0.0101, -0.0022],
        [ 0.0409, -0.0411, -0.0085,  ..., -0.0104,  0.0099,  0.0237]],
       dtype=torch.float16), 'model.layers.31.mlp.down_proj.weight': tensor([[-1.2767e-04, -2.5101e-02, -9.8572e-03,  ..., -3.8147e-02,
         -1.4954e-02,  2.7756e-02],
        [ 3.8208e-02,  3.5248e-03, -3.6736e-03,  ..., -5.2691e-04,
         -1.6205e-02,  1.3901e-02],
        [-1.2566e-02, -1.2192e-02,  2.5131e-02,  ...,  3.0304e-02,
         -1.5383e-03,  2.3193e-02],
        ...,
        [ 4.7088e-05,  2.8351e-02, -2.0237e-03,  ...,  1.1597e-02,
          5.3177e-03,  1.7136e-02],
        [-9.8515e-04,  4.7424e-02, -5.3787e-03,  ..., -7.3509e-03,
          2.3331e-02,  1.7090e-02],
        [ 2.6001e-02, -3.8910e-02,  1.8829e-02,  ...,  4.1313e-03,
          1.2999e-03,  2.6016e-02]], dtype=torch.float16), 'model.layers.31.input_layernorm.weight': tensor([0.4961, 0.4980, 0.4453,  ..., 0.4375, 0.4727, 0.4922],
       dtype=torch.float16), 'model.layers.31.post_attention_layernorm.weight': tensor([0.4414, 0.4434, 0.4531,  ..., 0.4336, 0.4219, 0.4375],
       dtype=torch.float16), 'model.norm.weight': tensor([2.0000, 2.0469, 1.9453,  ..., 1.8594, 1.9453, 1.7656],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding': tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight': tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,
            2.1957e-02,  5.0011e-03],
          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,
            7.5417e-03, -1.2230e-02],
          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,
            5.3940e-03, -1.2283e-02],
          ...,
          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,
           -2.3239e-02, -2.4017e-02],
          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,
            1.5745e-03, -4.1771e-03],
          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,
            4.0169e-03, -6.7177e-03]],

         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,
            2.4185e-02,  5.8136e-03],
          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,
            5.4970e-03, -1.4351e-02],
          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,
            5.5618e-03, -1.2390e-02],
          ...,
          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,
            3.9816e-04, -5.1346e-03],
          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,
            2.2552e-02,  1.2917e-02],
          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,
            1.8158e-02,  9.2745e-04]],

         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,
            1.1757e-02,  5.7259e-03],
          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,
           -4.2191e-03, -7.1831e-03],
          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,
            1.3041e-04, -7.3051e-03],
          ...,
          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,
           -9.8267e-03, -6.7825e-03],
          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,
            6.3400e-03,  5.3177e-03],
          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,
            6.5193e-03,  2.9850e-04]]],


        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,
           -8.4381e-03,  2.0447e-02],
          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,
            3.5906e-04,  1.5945e-02],
          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,
           -2.7924e-02, -3.2177e-03],
          ...,
          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,
           -5.4741e-03, -5.9624e-03],
          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,
           -2.7969e-02, -1.8875e-02],
          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,
            7.1335e-03,  4.6478e-02]],

         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,
           -1.1604e-02,  1.7593e-02],
          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,
            3.4976e-04,  1.4732e-02],
          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,
           -3.2684e-02, -7.0076e-03],
          ...,
          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,
           -1.1253e-02, -9.8648e-03],
          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,
           -3.7231e-02, -2.6505e-02],
          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,
           -4.2000e-03,  3.9368e-02]],

         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,
           -1.2558e-02,  1.7303e-02],
          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,
            4.3440e-04,  1.5656e-02],
          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,
           -2.9968e-02, -6.5422e-03],
          ...,
          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,
           -8.7967e-03, -8.7662e-03],
          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,
           -3.0518e-02, -2.4918e-02],
          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,
           -7.3242e-04,  3.8818e-02]]],


        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,
            1.4229e-02,  1.8768e-02],
          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,
            5.4283e-03,  6.6032e-03],
          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,
            2.5959e-03,  6.8703e-03],
          ...,
          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,
            1.4397e-02,  1.2421e-02],
          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,
            2.2766e-02,  2.2659e-02],
          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,
            2.2263e-02,  2.5238e-02]],

         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,
            1.9653e-02,  2.8290e-02],
          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,
            6.0501e-03,  1.2810e-02],
          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,
           -5.9271e-04,  8.8959e-03],
          ...,
          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,
            2.4902e-02,  2.6871e-02],
          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,
            3.3569e-02,  3.9612e-02],
          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,
            3.9276e-02,  4.6051e-02]],

         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,
            2.1042e-02,  2.9053e-02],
          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,
            7.7019e-03,  1.2169e-02],
          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,
            3.3913e-03,  9.0408e-03],
          ...,
          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,
            8.0795e-03,  1.4221e-02],
          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,
            1.1887e-02,  1.8204e-02],
          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,
            1.5701e-02,  2.2247e-02]]],


        ...,


        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,
            3.1686e-04, -3.0446e-04],
          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,
           -2.2995e-04, -1.6510e-04],
          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,
           -5.0831e-04,  5.9748e-04],
          ...,
          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,
           -9.3746e-04, -6.7472e-04],
          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,
           -1.4048e-03, -1.3056e-03],
          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,
            3.2640e-04,  1.7679e-04]],

         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,
            1.0500e-03, -5.0831e-04],
          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,
            1.0071e-03, -4.9925e-04],
          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,
            8.0919e-04,  9.7132e-04],
          ...,
          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,
            6.2895e-04,  4.0889e-04],
          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,
           -2.8610e-04,  1.9038e-04],
          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,
            1.4138e-04,  4.2319e-04]],

         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,
           -4.3130e-04, -5.6791e-04],
          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,
            1.9002e-04,  1.8311e-04],
          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,
            2.3186e-05, -5.7578e-05],
          ...,
          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,
            1.3471e-04,  6.5708e-04],
          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,
            1.0538e-04, -4.9019e-04],
          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,
           -4.1580e-04,  5.5599e-04]]],


        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,
            6.1874e-03,  2.6535e-02],
          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,
           -1.7639e-02, -3.2768e-03],
          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,
           -2.7237e-02, -5.5046e-03],
          ...,
          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,
            2.8503e-02,  3.6499e-02],
          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,
           -2.3010e-02,  5.0926e-03],
          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,
           -3.9276e-02,  1.3908e-02]],

         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,
            2.8896e-03,  2.2415e-02],
          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,
           -1.8616e-02, -6.5308e-03],
          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,
           -3.0472e-02, -9.3613e-03],
          ...,
          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,
            2.6001e-02,  3.4241e-02],
          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,
           -3.0487e-02, -9.5701e-04],
          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,
           -5.1422e-02,  4.2267e-03]],

         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,
           -2.1572e-03,  1.6891e-02],
          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,
           -2.1347e-02, -9.2316e-03],
          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,
           -2.9694e-02, -1.2733e-02],
          ...,
          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,
            1.9257e-02,  2.4582e-02],
          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,
           -3.1281e-02, -9.1248e-03],
          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,
           -5.2246e-02, -2.8057e-03]]],


        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,
            8.1863e-03, -4.8248e-02],
          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,
            9.3689e-03, -3.8544e-02],
          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,
            2.3956e-02, -1.1154e-02],
          ...,
          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,
           -1.8654e-03, -1.9440e-02],
          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,
            8.4381e-03,  1.4282e-02],
          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,
            1.6689e-03,  1.6891e-02]],

         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,
            1.5839e-02, -4.3243e-02],
          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,
            1.8433e-02, -3.1799e-02],
          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,
            2.9694e-02, -5.4817e-03],
          ...,
          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,
           -1.5268e-03, -1.4626e-02],
          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,
            8.5602e-03,  2.0035e-02],
          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,
           -2.3785e-03,  1.9150e-02]],

         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,
            2.1317e-02, -3.0197e-02],
          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,
            2.4658e-02, -1.7670e-02],
          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,
            3.4302e-02,  4.5395e-03],
          ...,
          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,
            4.1656e-03, -5.9814e-03],
          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,
            1.6068e-02,  2.5879e-02],
          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,
            2.2964e-03,  2.2339e-02]]]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight': tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],
        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],
        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],
        ...,
        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],
        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],
        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight': tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias': tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight': tensor([[-1.1724e-04,  8.3399e-04, -1.5700e-04,  ..., -4.8332e-03,
          1.3428e-02,  3.2604e-05],
        [-4.4703e-05, -9.5272e-04,  1.2279e-04,  ...,  1.9855e-03,
         -1.3626e-02, -4.1783e-05],
        [ 6.6280e-04,  1.0419e-04,  9.0420e-05,  ..., -2.1820e-02,
          4.1199e-03,  3.2187e-06],
        ...,
        [-5.2512e-05, -2.9278e-04, -3.6895e-05,  ...,  8.8196e-03,
         -4.2796e-04, -3.0100e-05],
        [ 7.5936e-05, -6.5148e-05, -9.0182e-05,  ...,  8.1682e-04,
         -6.0844e-03,  1.9014e-05],
        [-6.3896e-05,  9.8705e-05,  4.9829e-05,  ..., -1.2579e-03,
         -7.1793e-03,  2.3961e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias': tensor([ 0.0577, -0.0588, -0.0266,  ..., -0.0147, -0.0175,  0.0096],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight': tensor([[ 2.4986e-04, -1.5283e-04, -5.8556e-04,  ...,  3.3607e-03,
         -9.5901e-03,  5.5373e-05],
        [-3.4356e-04, -1.5092e-04,  5.2691e-05,  ...,  2.5725e-04,
          1.0010e-02, -6.2883e-05],
        [ 6.7472e-04, -9.6798e-05,  2.5392e-04,  ..., -1.0386e-03,
         -1.9531e-02, -1.2141e-04],
        ...,
        [ 2.9850e-04,  4.0436e-04, -9.7811e-05,  ...,  4.6654e-03,
         -2.2392e-03, -6.6221e-05],
        [ 3.2973e-04, -3.2961e-05, -2.1207e-04,  ...,  1.1917e-02,
          3.4637e-03,  6.9439e-05],
        [ 2.1458e-06,  4.7874e-04,  4.8459e-05,  ..., -1.1612e-02,
          2.6779e-03, -8.3089e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias': tensor([-0.0277,  0.0222, -0.0355,  ...,  0.0123,  0.0105, -0.0041],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight': tensor([[-2.6703e-05, -1.3638e-04, -8.3923e-05,  ...,  4.2152e-03,
         -2.7649e-02, -7.5042e-05],
        [-1.6391e-04,  9.0241e-05,  5.4836e-05,  ..., -1.5821e-03,
          2.9831e-02,  7.0333e-05],
        [ 4.7588e-04,  7.6008e-04, -1.0198e-04,  ..., -1.7090e-02,
          4.1809e-02,  1.5020e-04],
        ...,
        [ 6.9141e-05,  7.0274e-05,  8.6784e-05,  ..., -4.3411e-03,
          1.1421e-02, -3.8803e-05],
        [-1.8144e-04,  1.4305e-06, -2.5940e-04,  ...,  1.5802e-03,
         -1.8799e-04,  1.6689e-05],
        [-1.2624e-04,  9.4473e-05,  5.3406e-05,  ..., -1.4961e-02,
         -5.8937e-04,  4.2021e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias': tensor([ 1.5693, -1.6172, -0.8213,  ..., -1.2852, -0.0976,  0.7852],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight': tensor([[-0.0073,  0.0083, -0.0076,  ..., -0.0090, -0.0080,  0.0038],
        [ 0.0107,  0.0062,  0.0133,  ..., -0.0036,  0.0022,  0.0034],
        [-0.0065,  0.0033,  0.0139,  ...,  0.0069,  0.0004, -0.0009],
        ...,
        [-0.0002, -0.0035, -0.0027,  ..., -0.0046, -0.0187,  0.0087],
        [-0.0093,  0.0047, -0.0083,  ...,  0.0006, -0.0013, -0.0006],
        [ 0.0092,  0.0003,  0.0016,  ...,  0.0016, -0.0045,  0.0045]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias': tensor([-0.0263, -0.0654,  0.0031,  ...,  0.1759, -0.0438,  0.0020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight': tensor([8.3113e-04, 2.9087e-03, 1.1456e-04,  ..., 6.9092e-01, 3.5498e-01,
        2.4021e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias': tensor([ 6.9141e-06,  7.7629e-04, -8.8811e-05,  ..., -3.6816e-01,
         1.7981e-01, -1.0854e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight': tensor([[ 4.2367e-04, -2.1219e-05,  5.9605e-08,  ..., -5.6458e-03,
         -1.2026e-03, -6.4087e-04],
        [ 6.1340e-03,  1.3588e-02, -3.5858e-04,  ..., -3.5954e-03,
         -7.6485e-04,  6.7101e-03],
        [ 1.3552e-03,  1.2817e-03, -2.0266e-06,  ..., -2.8351e-02,
         -1.2054e-03,  1.4830e-03],
        ...,
        [-2.4002e-02, -1.0193e-02,  2.1684e-04,  ..., -2.5864e-03,
         -1.1841e-02,  5.9166e-03],
        [ 4.1008e-04,  4.2856e-05, -1.1921e-07,  ..., -5.0697e-03,
         -7.7248e-04, -6.3896e-04],
        [-6.3753e-04, -2.3392e-02, -2.6226e-04,  ..., -4.2801e-03,
          2.7962e-03, -8.1863e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias': tensor([-0.6826, -0.3130, -0.8076,  ..., -0.2166, -0.6538, -0.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight': tensor([[-0.0037, -0.0032,  0.0043,  ...,  0.0117, -0.0042, -0.0073],
        [ 0.0017,  0.0183, -0.0100,  ..., -0.0255,  0.0024,  0.0209],
        [ 0.0033,  0.0024, -0.0029,  ...,  0.0037,  0.0032, -0.0154],
        ...,
        [ 0.0015, -0.0007, -0.0035,  ...,  0.0049,  0.0009,  0.0082],
        [-0.0060,  0.0064,  0.0067,  ..., -0.0009, -0.0061,  0.0016],
        [ 0.0007, -0.0034, -0.0020,  ..., -0.0091,  0.0009,  0.0035]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias': tensor([-0.0185, -0.1009,  0.0397,  ..., -0.0955, -0.1080, -0.0239],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight': tensor([2.8296e-01, 5.9082e-01, 1.0455e-04,  ..., 2.0195e+00, 7.7490e-01,
        2.9736e-01], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias': tensor([2.1988e-02, 2.1716e-01, 9.2089e-05,  ..., 2.6318e-01, 4.5020e-01,
        5.0903e-02], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight': tensor([[-3.9864e-03,  1.4374e-02, -2.8610e-03,  ...,  1.0399e-02,
         -2.8076e-02,  5.1155e-03],
        [ 8.1024e-03,  2.2583e-03,  1.1635e-02,  ..., -7.1716e-03,
         -7.5607e-03,  2.5375e-02],
        [ 9.5596e-03,  1.1284e-02, -3.6469e-03,  ..., -6.6757e-03,
         -1.2465e-03, -1.1475e-02],
        ...,
        [ 7.7188e-05, -1.6190e-02,  3.6583e-03,  ...,  2.1240e-02,
          4.3907e-03, -1.0063e-02],
        [ 1.5762e-02,  1.7273e-02, -3.3447e-02,  ..., -2.2507e-03,
         -1.2947e-02,  1.1726e-02],
        [-2.2697e-04,  1.2230e-02, -4.3411e-03,  ...,  3.3436e-03,
         -4.9973e-03,  5.5504e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias': tensor([-0.0012,  0.0081,  0.0097,  ...,  0.0535,  0.0071,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight': tensor([[ 0.0077,  0.0006,  0.0053,  ..., -0.0067,  0.0008,  0.0013],
        [ 0.0230, -0.0166, -0.0004,  ...,  0.0092, -0.0118, -0.0134],
        [-0.0103,  0.0013,  0.0111,  ..., -0.0549, -0.0047,  0.0056],
        ...,
        [ 0.0119,  0.0002, -0.0045,  ...,  0.0001,  0.0034, -0.0075],
        [-0.0129, -0.0114,  0.0075,  ..., -0.0030,  0.0044,  0.0061],
        [-0.0006, -0.0018,  0.0009,  ..., -0.0068, -0.0205, -0.0002]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias': tensor([ 0.0038, -0.0079, -0.1469,  ..., -0.0014, -0.0041,  0.0007],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight': tensor([[-2.4929e-03,  4.6706e-04, -1.8919e-04,  ...,  6.1684e-03,
         -2.4582e-02,  8.7051e-03],
        [ 6.5422e-03,  4.3602e-03,  1.5930e-02,  ..., -6.5994e-03,
          8.2169e-03,  6.1111e-03],
        [ 1.0727e-02, -9.2239e-03, -7.5698e-06,  ...,  3.7136e-03,
          1.6861e-02,  3.5305e-03],
        ...,
        [-2.3708e-03,  6.6452e-03,  5.9052e-03,  ..., -1.0399e-02,
          2.9945e-04, -9.6989e-04],
        [ 3.0609e-02,  1.3458e-02, -3.3386e-02,  ..., -1.3857e-03,
          3.5801e-03,  1.3245e-02],
        [-3.2291e-03,  4.7607e-03, -1.8759e-03,  ...,  6.1035e-04,
          4.9515e-03, -5.3520e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias': tensor([-0.1035,  0.8804,  1.4414,  ..., -2.2109, -0.1892,  0.0048],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight': tensor([[-0.0013, -0.0215,  0.0011,  ..., -0.0115,  0.0102, -0.0012],
        [-0.0010,  0.0065, -0.0018,  ..., -0.0036,  0.0112, -0.0025],
        [ 0.0015, -0.0069, -0.0120,  ..., -0.0047, -0.0009, -0.0056],
        ...,
        [ 0.0053, -0.0177,  0.0780,  ..., -0.0228, -0.0122,  0.0151],
        [-0.0086, -0.0019,  0.0054,  ...,  0.0081, -0.0049,  0.0067],
        [-0.0037,  0.0063, -0.0005,  ...,  0.0054,  0.0045, -0.0036]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias': tensor([-0.0204, -0.0210,  0.0255,  ..., -0.0381, -0.0211, -0.0043],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight': tensor([0.3650, 0.7476, 0.0972,  ..., 0.8521, 0.4248, 0.2639],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias': tensor([-0.0482, -0.1315,  0.0198,  ..., -0.1031, -0.0545,  0.0076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight': tensor([[ 0.0026,  0.0065,  0.0155,  ..., -0.0063,  0.0479, -0.0807],
        [ 0.0002, -0.0075,  0.0009,  ..., -0.0009, -0.0030,  0.0036],
        [ 0.0070, -0.0211,  0.0002,  ..., -0.0094,  0.0178, -0.0043],
        ...,
        [ 0.0026, -0.0113,  0.0019,  ..., -0.0057, -0.0008,  0.0038],
        [-0.0059,  0.0099,  0.0010,  ...,  0.0037, -0.0142, -0.0178],
        [ 0.0160,  0.0002,  0.0312,  ..., -0.0003, -0.0056, -0.0220]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias': tensor([-0.1216, -0.6841, -0.5278,  ..., -0.7573, -0.0995, -0.3076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight': tensor([[ 0.0008, -0.0008, -0.0176,  ..., -0.0029, -0.0098, -0.0047],
        [-0.0157,  0.0059,  0.0156,  ...,  0.0064, -0.0005, -0.0058],
        [ 0.0051, -0.0005,  0.0091,  ..., -0.0056, -0.0015,  0.0059],
        ...,
        [ 0.0030, -0.0024,  0.0040,  ...,  0.0014,  0.0002,  0.0047],
        [ 0.0007, -0.0015,  0.0031,  ..., -0.0015,  0.0046, -0.0055],
        [ 0.0299,  0.0036,  0.0020,  ...,  0.0047,  0.0134,  0.0043]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias': tensor([ 0.0244, -0.0645,  0.0788,  ..., -0.0807, -0.1028, -0.0836],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight': tensor([0.4128, 0.9854, 0.1910,  ..., 0.7715, 0.5596, 0.5142],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias': tensor([-0.0198, -0.1075, -0.0195,  ...,  0.0887,  0.1349,  0.0288],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight': tensor([[-0.0085,  0.0006, -0.0289,  ...,  0.0041,  0.0569, -0.0674],
        [-0.0052,  0.0245, -0.0213,  ..., -0.0084,  0.0220, -0.0248],
        [-0.0135, -0.0092,  0.0144,  ...,  0.0162,  0.0298, -0.0357],
        ...,
        [-0.0062,  0.0068,  0.0082,  ...,  0.0119,  0.0132, -0.0033],
        [-0.0083,  0.0247, -0.0094,  ..., -0.0040, -0.0122,  0.0142],
        [-0.0048, -0.0044, -0.0164,  ...,  0.0119, -0.0213, -0.0117]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias': tensor([ 0.0234,  0.0084, -0.0015,  ...,  0.0951,  0.0065,  0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight': tensor([[ 0.0164,  0.0053, -0.0065,  ..., -0.0008,  0.0037, -0.0120],
        [-0.0057, -0.0036, -0.0029,  ..., -0.0013,  0.0026, -0.0108],
        [-0.0081,  0.0057,  0.0067,  ...,  0.0028, -0.0068, -0.0023],
        ...,
        [-0.0249,  0.0121,  0.0107,  ...,  0.0037,  0.0007,  0.0044],
        [ 0.0115,  0.0107,  0.0118,  ...,  0.0015, -0.0038, -0.0073],
        [-0.0073,  0.0032, -0.0060,  ...,  0.0023, -0.0074,  0.0047]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias': tensor([-0.0014, -0.0060,  0.0129,  ...,  0.1081,  0.0069,  0.0455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight': tensor([[-0.0067, -0.0208, -0.0222,  ...,  0.0014,  0.0279, -0.0558],
        [-0.0030,  0.0016, -0.0191,  ...,  0.0001, -0.0169, -0.0034],
        [-0.0079, -0.0049,  0.0074,  ..., -0.0163, -0.0186, -0.0105],
        ...,
        [ 0.0002, -0.0036,  0.0084,  ..., -0.0038,  0.0105, -0.0002],
        [-0.0035, -0.0039, -0.0118,  ..., -0.0067, -0.0292,  0.0361],
        [-0.0044, -0.0008, -0.0187,  ...,  0.0014, -0.0064, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias': tensor([ 0.1927, -0.0745, -0.0890,  ...,  0.6807,  0.7334, -0.5073],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight': tensor([[-2.4796e-02,  3.3035e-03, -5.1379e-05,  ...,  2.5177e-02,
         -2.3010e-02,  1.2245e-02],
        [-2.7504e-03,  1.5330e-04, -1.1650e-02,  ..., -8.4229e-03,
         -4.1389e-03, -6.9275e-03],
        [-1.2238e-02, -7.1983e-03, -1.0323e-02,  ..., -1.6312e-02,
         -5.9547e-03, -1.4572e-03],
        ...,
        [-1.8501e-03,  5.0354e-04, -6.7101e-03,  ..., -7.3471e-03,
         -2.3518e-03, -1.8501e-03],
        [ 5.4131e-03, -4.4937e-03,  1.2329e-02,  ..., -7.1716e-04,
          9.8038e-04,  7.2708e-03],
        [ 1.0040e-02,  6.5422e-03,  9.2163e-03,  ..., -4.5815e-03,
         -1.1330e-03, -2.6169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias': tensor([ 0.0182, -0.0970,  0.0244,  ..., -0.0159, -0.0449, -0.0308],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight': tensor([0.5078, 0.3108, 0.4004,  ..., 1.4219, 0.5015, 0.3591],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias': tensor([-0.0750, -0.0109,  0.0618,  ..., -0.0417,  0.0176, -0.0477],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight': tensor([[-0.0066, -0.0264,  0.0131,  ..., -0.0004,  0.0194, -0.0154],
        [ 0.0097,  0.0090, -0.0017,  ...,  0.0023, -0.0030,  0.0246],
        [-0.0057,  0.0093,  0.0011,  ..., -0.0040,  0.0003,  0.0128],
        ...,
        [ 0.0005, -0.0012, -0.0009,  ...,  0.0011, -0.0034, -0.0059],
        [ 0.0002,  0.0115,  0.0158,  ...,  0.0040,  0.0015,  0.0208],
        [-0.0148,  0.0111, -0.0085,  ...,  0.0049, -0.0076, -0.0022]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias': tensor([-0.2452, -0.3076, -0.4565,  ..., -0.1678, -0.2119, -0.5581],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight': tensor([[ 1.3428e-03, -3.5172e-03,  9.3317e-04,  ..., -5.0354e-03,
          4.3907e-03,  2.0161e-03],
        [ 1.2999e-03, -1.6678e-02, -4.5662e-03,  ..., -4.4584e-04,
          1.3359e-02, -3.9558e-03],
        [-1.8829e-02,  5.2261e-03,  4.7760e-03,  ...,  8.3113e-04,
         -1.8860e-02,  1.0452e-03],
        ...,
        [-7.8201e-03,  8.4305e-04, -2.1601e-04,  ..., -5.6207e-05,
          4.8339e-05,  1.7557e-03],
        [-4.5300e-05, -7.9498e-03, -9.6178e-04,  ...,  3.4180e-03,
         -1.0208e-02,  2.4460e-02],
        [ 6.0883e-03,  3.3398e-03, -3.7789e-04,  ...,  1.5259e-02,
          6.6223e-03,  6.8169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias': tensor([ 0.0453, -0.0798, -0.0027,  ..., -0.0154, -0.1379, -0.0307],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight': tensor([0.6362, 0.5508, 0.3787,  ..., 1.3506, 0.4011, 0.4910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias': tensor([-0.0338, -0.0840, -0.0964,  ..., -0.0491,  0.0855, -0.2158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight': tensor([[ 0.0149, -0.0155, -0.0083,  ...,  0.0066,  0.0086, -0.0173],
        [ 0.0067,  0.0134,  0.0050,  ..., -0.0056, -0.0293, -0.0028],
        [ 0.0041, -0.0027, -0.0011,  ...,  0.0060,  0.0020, -0.0035],
        ...,
        [ 0.0110, -0.0188,  0.0174,  ..., -0.0223,  0.0017, -0.0122],
        [ 0.0165, -0.0201, -0.0204,  ..., -0.0262, -0.0232, -0.0039],
        [ 0.0062, -0.0148,  0.0194,  ...,  0.0090, -0.0007, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias': tensor([-0.0385, -0.0122,  0.0262,  ...,  0.1536,  0.0992, -0.0590],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight': tensor([[ 0.0275, -0.0126, -0.0067,  ...,  0.0002,  0.0201,  0.0163],
        [-0.0074,  0.0475,  0.0058,  ..., -0.0040,  0.0014,  0.0004],
        [-0.0100, -0.0039, -0.0155,  ...,  0.0009, -0.0079,  0.0033],
        ...,
        [ 0.0009,  0.0007,  0.0107,  ...,  0.0007,  0.0007, -0.0059],
        [-0.0008,  0.0147,  0.0066,  ...,  0.0022, -0.0062, -0.0033],
        [-0.0195, -0.0065,  0.0118,  ..., -0.0030,  0.0058,  0.0028]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias': tensor([ 0.0095, -0.0516,  0.0111,  ..., -0.0145,  0.0041,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight': tensor([[ 2.7618e-02,  1.0513e-02,  4.2725e-03,  ...,  6.3095e-03,
         -8.5907e-03, -1.3008e-02],
        [ 2.4605e-03,  1.8875e-02, -3.9787e-03,  ..., -5.7335e-03,
         -2.1698e-02,  5.3406e-03],
        [-5.1880e-04, -1.0147e-02, -1.0471e-03,  ...,  1.0002e-02,
          1.0025e-02, -1.6159e-02],
        ...,
        [ 1.4210e-03, -1.6434e-02,  5.2299e-03,  ..., -1.5053e-02,
          1.1284e-02,  1.2054e-03],
        [ 1.5579e-02,  1.5251e-02, -3.5915e-03,  ..., -2.6520e-02,
         -1.4130e-02, -7.7133e-03],
        [ 1.0399e-02, -2.2491e-02,  3.2783e-06,  ...,  8.3542e-03,
         -6.7215e-03,  1.6525e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias': tensor([-0.1852, -0.5479, -0.1450,  ..., -0.9072, -0.3499, -0.3457],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight': tensor([[-2.1683e-02,  2.3556e-03, -1.9245e-03,  ..., -9.4910e-03,
          1.6251e-02,  1.2527e-02],
        [ 6.4430e-03, -3.8055e-02, -3.1567e-03,  ..., -2.6455e-03,
         -2.1515e-02,  1.1864e-02],
        [ 5.2147e-03, -8.5602e-03,  1.5732e-02,  ..., -1.2611e-02,
          7.3395e-03, -1.2505e-02],
        ...,
        [-1.1325e-04,  3.4676e-03, -1.1169e-02,  ..., -1.0071e-02,
         -5.4538e-05, -1.7357e-03],
        [-6.8245e-03, -1.0139e-02,  1.4579e-04,  ...,  2.0309e-02,
          1.3527e-02, -3.0098e-03],
        [-1.7868e-02,  6.0368e-04, -6.7101e-03,  ...,  6.6853e-04,
         -3.0327e-03,  3.0651e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias': tensor([-0.0147, -0.0586,  0.0197,  ...,  0.0204, -0.1210,  0.0171],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight': tensor([0.7456, 0.3557, 0.6133,  ..., 2.2637, 0.5059, 0.3938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias': tensor([-0.0006,  0.0249,  0.0189,  ..., -0.1539, -0.0345,  0.0151],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight': tensor([[ 0.0034,  0.0025,  0.0007,  ..., -0.0021, -0.0065,  0.0058],
        [ 0.0011, -0.0024, -0.0028,  ..., -0.0094, -0.0078, -0.0065],
        [-0.0051, -0.0246, -0.0075,  ..., -0.0073,  0.0121,  0.0036],
        ...,
        [ 0.0077,  0.0038, -0.0011,  ..., -0.0060, -0.0017,  0.0005],
        [-0.0208, -0.0176, -0.0064,  ..., -0.0076, -0.0137, -0.0056],
        [-0.0240,  0.0082, -0.0047,  ..., -0.0105, -0.0069, -0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias': tensor([-0.0952, -0.1888, -0.1597,  ..., -0.2030, -0.3225, -0.3745],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight': tensor([[ 0.0074, -0.0074,  0.0041,  ...,  0.0181,  0.0235,  0.0145],
        [ 0.0106,  0.0015, -0.0078,  ..., -0.0323, -0.0017,  0.0073],
        [-0.0059, -0.0090, -0.0087,  ...,  0.0023,  0.0091,  0.0240],
        ...,
        [ 0.0054,  0.0013, -0.0012,  ..., -0.0047, -0.0021, -0.0053],
        [-0.0028,  0.0165,  0.0051,  ...,  0.0006, -0.0043, -0.0041],
        [-0.0045,  0.0066,  0.0154,  ..., -0.0027,  0.0146, -0.0076]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias': tensor([ 0.0139, -0.0796,  0.0050,  ...,  0.0715, -0.1787,  0.0414],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight': tensor([0.9761, 0.5317, 0.6523,  ..., 0.0116, 0.5054, 0.5391],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias': tensor([ 0.0585,  0.0282,  0.0207,  ...,  0.3896, -0.0784, -0.1201],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight': tensor([[ 2.0187e-02,  9.6970e-03,  1.7242e-02,  ..., -2.5925e-02,
         -1.5945e-02,  6.4671e-05],
        [ 1.0201e-02, -7.3357e-03,  3.3722e-02,  ...,  8.9111e-03,
         -3.2410e-02,  5.5122e-03],
        [ 9.6817e-03, -2.4231e-02,  5.7907e-03,  ...,  4.0955e-02,
          2.2415e-02, -1.8143e-02],
        ...,
        [-2.4857e-02, -2.5803e-02, -3.2673e-03,  ..., -1.3596e-02,
          3.6240e-03, -5.7650e-04],
        [-6.4754e-04,  2.4719e-02, -3.0411e-02,  ..., -1.3008e-02,
          5.0879e-04, -1.9455e-02],
        [ 1.7380e-02, -2.3804e-02,  1.2428e-02,  ..., -4.4670e-03,
         -4.2297e-02,  9.2545e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias': tensor([-0.0362, -0.0177,  0.0258,  ...,  0.0230,  0.0147,  0.0451],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight': tensor([[-0.0050,  0.0089,  0.0017,  ..., -0.0001, -0.0173, -0.0087],
        [ 0.0064, -0.0170,  0.0071,  ..., -0.0039,  0.0387, -0.0100],
        [-0.0151,  0.0005, -0.0012,  ..., -0.0011, -0.0048,  0.0012],
        ...,
        [ 0.0129, -0.0303, -0.0177,  ...,  0.0005,  0.0013,  0.0006],
        [ 0.0157,  0.0140, -0.0101,  ...,  0.0011,  0.0336, -0.0216],
        [ 0.0171, -0.0183, -0.0061,  ...,  0.0016, -0.0197, -0.0110]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias': tensor([ 0.0241, -0.0481, -0.0028,  ...,  0.0268,  0.0064, -0.0023],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight': tensor([[ 0.0075,  0.0013, -0.0144,  ..., -0.0114, -0.0454, -0.0086],
        [-0.0035, -0.0501,  0.0037,  ..., -0.0065, -0.0287,  0.0070],
        [ 0.0061, -0.0005,  0.0146,  ...,  0.0271,  0.0069, -0.0366],
        ...,
        [-0.0107,  0.0089, -0.0109,  ..., -0.0074, -0.0206, -0.0009],
        [-0.0004, -0.0072, -0.0339,  ..., -0.0124, -0.0053, -0.0094],
        [ 0.0051, -0.0136, -0.0062,  ..., -0.0015, -0.0242, -0.0031]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias': tensor([-0.4634, -0.0086,  0.2761,  ..., -0.2158, -0.2346, -0.2240],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight': tensor([[-2.6817e-03, -4.3983e-03,  1.3580e-03,  ..., -2.4681e-03,
         -1.6296e-02, -1.9119e-02],
        [-6.3057e-03,  1.3931e-02,  2.0657e-03,  ...,  2.4063e-02,
         -2.3544e-02,  2.3361e-02],
        [ 4.4098e-03,  2.9049e-03,  3.0816e-05,  ...,  1.9028e-02,
          1.2093e-02,  9.4528e-03],
        ...,
        [-6.3095e-03,  7.6141e-03, -4.4861e-03,  ..., -6.6261e-03,
         -6.6795e-03, -3.0851e-04],
        [ 1.7075e-02, -3.9612e-02,  9.1248e-03,  ...,  1.1742e-02,
         -3.6469e-02,  2.8046e-02],
        [ 8.2626e-03,  1.3752e-03, -1.0185e-02,  ...,  6.5994e-04,
          1.5320e-02,  1.1871e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias': tensor([ 0.0089, -0.0782,  0.0222,  ..., -0.0115, -0.1763,  0.0233],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight': tensor([0.7534, 0.5015, 0.7891,  ..., 1.1660, 0.6074, 0.5796],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias': tensor([ 0.0149, -0.0122,  0.0052,  ..., -0.1028,  0.0337, -0.0357],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight': tensor([[ 0.0072, -0.0114, -0.0013,  ..., -0.0066,  0.0127,  0.0151],
        [-0.0095,  0.0185,  0.0141,  ..., -0.0075,  0.0141,  0.0101],
        [-0.0018,  0.0118,  0.0032,  ..., -0.0046,  0.0148,  0.0008],
        ...,
        [ 0.0204,  0.0075,  0.0235,  ..., -0.0079,  0.0030, -0.0164],
        [ 0.0157, -0.0033, -0.0008,  ..., -0.0085,  0.0043, -0.0139],
        [-0.0009, -0.0003,  0.0257,  ..., -0.0072, -0.0059, -0.0217]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias': tensor([-0.2440, -0.3796, -0.5205,  ..., -0.2163, -0.4248, -0.2197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight': tensor([[-1.6296e-02,  6.4087e-03, -1.4839e-03,  ..., -2.2827e-02,
          1.9302e-02,  1.6346e-03],
        [ 5.0888e-03, -1.3763e-02,  5.1537e-03,  ..., -1.9989e-02,
         -2.7637e-03, -1.0567e-02],
        [ 2.8763e-03, -5.1460e-03, -5.6326e-05,  ..., -7.1030e-03,
         -9.8724e-03, -2.3098e-03],
        ...,
        [-5.3024e-03, -2.0905e-03,  2.9635e-04,  ..., -5.4092e-03,
          2.0993e-04,  2.4395e-03],
        [-9.9411e-03, -1.4748e-02, -2.4283e-04,  ...,  1.8127e-02,
          3.3779e-03,  2.1927e-02],
        [-5.7182e-03,  1.5316e-03,  1.1997e-03,  ...,  2.5387e-03,
         -5.6725e-03,  4.6387e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias': tensor([-0.0155, -0.0524, -0.0402,  ...,  0.1025, -0.1437, -0.0174],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight': tensor([1.1230, 0.5190, 1.0762,  ..., 0.0112, 0.6738, 0.7544],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias': tensor([ 0.0829, -0.0929, -0.0049,  ...,  0.1129, -0.0392, -0.0677],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight': tensor([[ 0.0035, -0.0081,  0.0270,  ..., -0.0032,  0.0041,  0.0172],
        [-0.0174,  0.0256,  0.0060,  ..., -0.0001,  0.0052, -0.0038],
        [ 0.0038,  0.0144, -0.0161,  ..., -0.0028,  0.0033,  0.0003],
        ...,
        [-0.0023, -0.0123, -0.0080,  ...,  0.0256,  0.0213, -0.0097],
        [-0.0147,  0.0030,  0.0045,  ...,  0.0211,  0.0161, -0.0218],
        [-0.0035,  0.0147,  0.0030,  ..., -0.0244, -0.0005, -0.0255]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias': tensor([-0.0187, -0.0076,  0.0053,  ...,  0.0369,  0.0955,  0.0978],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight': tensor([[-0.0090,  0.0047, -0.0008,  ..., -0.0064, -0.0025, -0.0247],
        [-0.0128, -0.0091,  0.0087,  ...,  0.0024, -0.0012,  0.0007],
        [ 0.0101, -0.0021, -0.0005,  ...,  0.0017,  0.0007, -0.0170],
        ...,
        [-0.0120,  0.0108,  0.0011,  ..., -0.0008, -0.0032,  0.0003],
        [-0.0157, -0.0033,  0.0135,  ..., -0.0007, -0.0310, -0.0129],
        [ 0.0124, -0.0001,  0.0213,  ..., -0.0014, -0.0043, -0.0239]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias': tensor([-0.0186, -0.0071, -0.0258,  ..., -0.0043, -0.0113, -0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight': tensor([[-1.7075e-02,  3.0457e-02,  8.3542e-03,  ..., -8.0032e-03,
          1.6724e-02, -1.0490e-02],
        [-1.2169e-02,  8.2474e-03, -4.2725e-03,  ..., -9.4366e-04,
         -4.9591e-03, -1.0300e-02],
        [ 1.0185e-03, -1.2466e-02, -3.0880e-03,  ..., -3.4428e-03,
         -1.3107e-02,  6.5384e-03],
        ...,
        [ 1.5793e-02,  2.0809e-03,  1.9424e-02,  ...,  2.6367e-02,
          1.0529e-02, -2.1439e-02],
        [-5.6992e-03,  4.1580e-04,  3.8116e-02,  ...,  1.6739e-02,
         -9.0103e-03, -1.6327e-02],
        [ 2.8789e-05, -9.8114e-03,  1.0004e-03,  ..., -2.2293e-02,
         -3.0365e-02,  6.1569e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias': tensor([-0.0072, -1.4619,  0.3447,  ..., -0.6147, -0.3474, -0.6455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight': tensor([[ 5.2567e-03,  1.1238e-02, -6.8092e-03,  ..., -8.0013e-04,
          1.5930e-02, -1.4336e-02],
        [-6.6223e-03,  1.9255e-03, -1.6006e-02,  ..., -2.0706e-02,
         -1.1848e-02, -1.1147e-02],
        [ 2.3087e-02,  1.1986e-02, -1.7288e-02,  ...,  5.7144e-03,
          1.4824e-02, -1.6876e-02],
        ...,
        [ 1.6647e-02,  5.3596e-03, -1.5154e-03,  ..., -2.9736e-03,
          1.8129e-03,  1.0559e-02],
        [ 4.1847e-03,  8.3694e-03,  1.2535e-02,  ..., -1.0323e-02,
          1.6327e-02, -3.2544e-05],
        [ 1.0185e-03, -2.1400e-03, -4.4098e-03,  ..., -4.6120e-03,
          6.0921e-03,  1.5152e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias': tensor([-0.0087, -0.0482, -0.0096,  ..., -0.0479, -0.1366,  0.0062],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight': tensor([0.8506, 0.6484, 0.8960,  ..., 1.2539, 0.7212, 0.8564],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias': tensor([-0.0077,  0.0670, -0.0532,  ..., -0.1699, -0.0490,  0.0434],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight': tensor([[ 0.0058,  0.0115,  0.0089,  ..., -0.0020, -0.0053,  0.0026],
        [-0.0017, -0.0024,  0.0162,  ...,  0.0009, -0.0208, -0.0094],
        [-0.0388, -0.0012, -0.0004,  ...,  0.0032, -0.0029, -0.0226],
        ...,
        [ 0.0085,  0.0130,  0.0209,  ..., -0.0057, -0.0040, -0.0012],
        [ 0.0260,  0.0055,  0.0095,  ..., -0.0008,  0.0056, -0.0098],
        [ 0.0116,  0.0073, -0.0117,  ...,  0.0011, -0.0095, -0.0163]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias': tensor([-0.4192, -0.2394, -0.3069,  ..., -0.3667, -0.2563, -0.1315],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight': tensor([[ 0.0154, -0.0020, -0.0083,  ...,  0.0161, -0.0060,  0.0146],
        [ 0.0042,  0.0226,  0.0055,  ...,  0.0110,  0.0033,  0.0034],
        [ 0.0140, -0.0083,  0.0006,  ...,  0.0085,  0.0010,  0.0007],
        ...,
        [-0.0025, -0.0010, -0.0020,  ...,  0.0007, -0.0030, -0.0018],
        [-0.0141, -0.0032, -0.0003,  ...,  0.0106, -0.0021, -0.0400],
        [ 0.0069,  0.0051, -0.0135,  ..., -0.0115,  0.0067, -0.0104]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias': tensor([-0.0416,  0.0127, -0.0229,  ...,  0.0723, -0.0145, -0.0363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight': tensor([1.1514, 0.7275, 1.1299,  ..., 1.0918, 0.8794, 1.1055],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias': tensor([ 0.0418, -0.1718, -0.0305,  ...,  0.0424, -0.2144, -0.0068],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight': tensor([[ 0.0195, -0.0016, -0.0010,  ...,  0.1302, -0.0123, -0.0063],
        [-0.0176,  0.0024, -0.0196,  ..., -0.1481, -0.0101, -0.0231],
        [-0.0042, -0.0077,  0.0033,  ...,  0.0850, -0.0172,  0.0256],
        ...,
        [ 0.0024, -0.0123,  0.0282,  ..., -0.0123,  0.0272,  0.0247],
        [ 0.0084, -0.0235,  0.0189,  ...,  0.0040, -0.0171,  0.0120],
        [ 0.0308, -0.0003,  0.0095,  ..., -0.0054, -0.0117, -0.0379]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias': tensor([-0.0049,  0.0073,  0.0145,  ...,  0.0185, -0.0033,  0.0204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight': tensor([[ 0.0096,  0.0166, -0.0025,  ..., -0.0005,  0.0005,  0.0034],
        [ 0.0066,  0.0109, -0.0074,  ...,  0.0010,  0.0079, -0.0095],
        [-0.0074, -0.0047,  0.0016,  ...,  0.0002,  0.0039,  0.0040],
        ...,
        [-0.0159,  0.0166, -0.0176,  ...,  0.0020, -0.0064,  0.0302],
        [ 0.0316, -0.0076, -0.0238,  ..., -0.0002, -0.0032, -0.0157],
        [-0.0096, -0.0192,  0.0207,  ..., -0.0009, -0.0289, -0.0082]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias': tensor([ 0.0264, -0.0288,  0.0074,  ...,  0.0075, -0.0047,  0.0190],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight': tensor([[ 0.0136, -0.0235, -0.0059,  ...,  0.0935,  0.0115, -0.0124],
        [-0.0146, -0.0224,  0.0003,  ..., -0.1112, -0.0056, -0.0134],
        [-0.0018,  0.0100,  0.0052,  ...,  0.0525,  0.0120,  0.0163],
        ...,
        [ 0.0338,  0.0004,  0.0047,  ..., -0.0146,  0.0189, -0.0173],
        [ 0.0022, -0.0096, -0.0040,  ...,  0.0011, -0.0013,  0.0135],
        [ 0.0178,  0.0135,  0.0019,  ..., -0.0075,  0.0044, -0.0363]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias': tensor([ 0.2430,  0.3418, -0.1379,  ...,  0.0247,  1.4775,  0.2130],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight': tensor([[-0.0026,  0.0052,  0.0064,  ...,  0.0172, -0.0226,  0.0066],
        [-0.0029,  0.0043, -0.0091,  ..., -0.0054, -0.0009,  0.0137],
        [-0.0161,  0.0021,  0.0049,  ...,  0.0088,  0.0251, -0.0076],
        ...,
        [ 0.0092,  0.0003, -0.0009,  ..., -0.0040,  0.0036,  0.0044],
        [ 0.0016, -0.0087,  0.0108,  ..., -0.0028, -0.0046,  0.0207],
        [ 0.0181, -0.0077, -0.0030,  ..., -0.0368, -0.0015,  0.0158]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias': tensor([-0.0217,  0.0017,  0.0176,  ...,  0.0564, -0.0415, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight': tensor([0.8926, 0.8076, 1.0293,  ..., 2.0488, 0.9590, 0.9756],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias': tensor([-0.1279, -0.0777, -0.0509,  ..., -0.2275, -0.0558,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight': tensor([[ 0.0265,  0.0048,  0.0027,  ..., -0.0071,  0.0051,  0.0187],
        [ 0.0004,  0.0177,  0.0098,  ..., -0.0020, -0.0084,  0.0181],
        [-0.0045,  0.0070, -0.0007,  ..., -0.0080, -0.0070, -0.0316],
        ...,
        [-0.0285,  0.0282,  0.0047,  ...,  0.0006, -0.0079,  0.0194],
        [-0.0049, -0.0312, -0.0060,  ..., -0.0043,  0.0310, -0.0003],
        [ 0.0185,  0.0199,  0.0079,  ..., -0.0067, -0.0297, -0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias': tensor([-0.1132, -0.1494, -0.4023,  ..., -0.2355, -0.3335, -0.2045],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight': tensor([[-0.0180,  0.0037,  0.0069,  ..., -0.0019, -0.0086, -0.0024],
        [-0.0006, -0.0030, -0.0042,  ..., -0.0177,  0.0375, -0.0014],
        [-0.0129, -0.0050, -0.0065,  ...,  0.0015, -0.0005, -0.0149],
        ...,
        [ 0.0031,  0.0014, -0.0087,  ..., -0.0003,  0.0073,  0.0014],
        [ 0.0105,  0.0060,  0.0064,  ..., -0.0005, -0.0007,  0.0372],
        [-0.0087, -0.0052,  0.0026,  ..., -0.0113, -0.0085,  0.0098]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias': tensor([-0.0068,  0.0179, -0.0552,  ...,  0.1210, -0.0750, -0.1090],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight': tensor([1.1914, 0.9712, 1.2656,  ..., 0.1719, 0.9092, 1.1973],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias': tensor([-0.0956, -0.1851, -0.0547,  ...,  0.2583, -0.0542,  0.0387],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight': tensor([[ 0.0076, -0.0117, -0.0114,  ...,  0.0770, -0.0048, -0.0017],
        [-0.0195, -0.0001, -0.0053,  ...,  0.0370, -0.0298,  0.0023],
        [-0.0094, -0.0034,  0.0132,  ...,  0.0014,  0.0088, -0.0013],
        ...,
        [ 0.0047, -0.0200, -0.0213,  ..., -0.0028, -0.0125, -0.0193],
        [-0.0028,  0.0018, -0.0313,  ..., -0.0143, -0.0024,  0.0085],
        [-0.0081, -0.0074,  0.0052,  ..., -0.0006, -0.0049, -0.0085]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias': tensor([ 0.0311, -0.0070, -0.0134,  ...,  0.0024, -0.0121, -0.0230],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight': tensor([[ 0.0104, -0.0064, -0.0062,  ...,  0.0015,  0.0052, -0.0058],
        [ 0.0179, -0.0065, -0.0221,  ..., -0.0002, -0.0032, -0.0219],
        [-0.0078,  0.0084, -0.0027,  ..., -0.0003,  0.0120,  0.0011],
        ...,
        [-0.0272, -0.0105,  0.0010,  ..., -0.0082,  0.0024,  0.0062],
        [ 0.0284, -0.0029, -0.0178,  ..., -0.0007, -0.0008, -0.0054],
        [-0.0113,  0.0083,  0.0034,  ..., -0.0102,  0.0250,  0.0115]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias': tensor([ 0.0282,  0.0175, -0.0284,  ...,  0.0397, -0.0209, -0.1344],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight': tensor([[ 0.0094, -0.0159, -0.0203,  ...,  0.0367, -0.0055, -0.0276],
        [ 0.0029, -0.0178, -0.0045,  ..., -0.0709, -0.0047, -0.0184],
        [-0.0128,  0.0083,  0.0116,  ..., -0.0014,  0.0039,  0.0124],
        ...,
        [-0.0292,  0.0131, -0.0025,  ...,  0.0003, -0.0127, -0.0156],
        [-0.0237,  0.0121, -0.0025,  ..., -0.0010,  0.0081, -0.0145],
        [ 0.0137,  0.0139,  0.0163,  ...,  0.0071,  0.0116, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias': tensor([-1.8535,  0.1802,  2.3398,  ..., -0.0595, -0.0338,  0.0305],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight': tensor([[ 0.0028, -0.0249,  0.0077,  ...,  0.0163, -0.0069, -0.0036],
        [ 0.0140, -0.0086,  0.0026,  ...,  0.0077,  0.0073, -0.0239],
        [ 0.0044,  0.0041, -0.0237,  ..., -0.0202, -0.0074,  0.0211],
        ...,
        [-0.0025,  0.0102, -0.0030,  ...,  0.0096,  0.0018,  0.0186],
        [ 0.0052, -0.0034,  0.0046,  ..., -0.0001,  0.0089, -0.0238],
        [-0.0090,  0.0134,  0.0052,  ..., -0.0156, -0.0131,  0.0157]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias': tensor([ 0.0039,  0.0259, -0.0086,  ..., -0.0503, -0.0064, -0.0460],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight': tensor([1.1934, 1.1006, 1.2510,  ..., 1.4092, 1.1592, 1.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias': tensor([ 0.0223, -0.0916,  0.0971,  ..., -0.2983, -0.0408,  0.0070],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight': tensor([[-0.0150,  0.0078,  0.0025,  ..., -0.0011, -0.0016,  0.0092],
        [-0.0219,  0.0313,  0.0128,  ...,  0.0032,  0.0150,  0.0033],
        [-0.0176, -0.0190,  0.0216,  ...,  0.0038, -0.0361,  0.0145],
        ...,
        [ 0.0060, -0.0061, -0.0066,  ...,  0.0027, -0.0050, -0.0172],
        [-0.0283, -0.0057,  0.0115,  ..., -0.0054, -0.0136, -0.0057],
        [-0.0160,  0.0153, -0.0277,  ..., -0.0289, -0.0194,  0.0007]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias': tensor([-0.1221, -0.2144, -0.4114,  ..., -0.1118, -0.1782, -0.3628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight': tensor([[-0.0016,  0.0125, -0.0344,  ..., -0.0221,  0.0044, -0.0154],
        [-0.0039, -0.0351,  0.0205,  ...,  0.0108, -0.0206, -0.0023],
        [ 0.0063, -0.0273, -0.0012,  ...,  0.0131,  0.0057, -0.0150],
        ...,
        [-0.0002, -0.0069,  0.0022,  ..., -0.0065,  0.0032,  0.0088],
        [ 0.0108, -0.0061, -0.0134,  ..., -0.0061,  0.0058, -0.0083],
        [ 0.0133,  0.0173,  0.0049,  ...,  0.0188, -0.0199, -0.0074]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias': tensor([-0.0200,  0.0232, -0.0657,  ...,  0.1028, -0.0782, -0.1134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight': tensor([1.2578, 1.1084, 1.2061,  ..., 0.5884, 1.0264, 1.2910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias': tensor([-0.0061, -0.0651,  0.0878,  ...,  0.1716,  0.1021, -0.0355],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight': tensor([[-0.0184, -0.0017,  0.0284,  ..., -0.0922, -0.0121,  0.0085],
        [ 0.0216,  0.0109,  0.0091,  ..., -0.0531,  0.0165, -0.0052],
        [-0.0036,  0.0282,  0.0128,  ...,  0.0421, -0.0305, -0.0203],
        ...,
        [-0.0003, -0.0044, -0.0082,  ..., -0.0171,  0.0052,  0.0071],
        [ 0.0136, -0.0294, -0.0073,  ..., -0.0191, -0.0179,  0.0170],
        [-0.0079,  0.0298, -0.0092,  ...,  0.0071,  0.0015,  0.0033]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias': tensor([-0.0044, -0.0038, -0.0472,  ...,  0.0818,  0.0363, -0.0465],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight': tensor([[ 1.9028e-02,  3.3264e-03, -1.4641e-02,  ..., -4.6754e-04,
         -1.4366e-02,  1.6556e-02],
        [ 2.1267e-04, -1.5457e-02, -3.2166e-02,  ..., -2.4629e-04,
          5.9090e-03, -9.8267e-03],
        [-1.2535e-02, -1.2222e-02,  9.6970e-03,  ...,  1.7128e-03,
         -2.1992e-03,  3.7842e-03],
        ...,
        [ 1.0918e-02,  1.8097e-02,  1.2695e-02,  ...,  4.8494e-04,
          5.1918e-03, -1.9058e-02],
        [ 9.9792e-03, -1.2085e-02,  6.0320e-04,  ...,  3.4790e-03,
          1.0284e-02,  2.8300e-04],
        [ 2.2034e-02, -1.5373e-03, -2.1362e-02,  ...,  4.9706e-03,
         -4.9174e-05, -6.5117e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias': tensor([ 0.0094,  0.0439, -0.0031,  ..., -0.0485, -0.1193,  0.0170],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight': tensor([[-1.2352e-02,  2.3239e-02,  5.5618e-03,  ..., -5.1178e-02,
         -2.8687e-02,  2.2531e-05],
        [-1.0605e-02, -2.5497e-02,  1.1894e-02,  ..., -2.0462e-02,
         -8.5449e-04,  4.6265e-02],
        [ 8.6212e-03, -9.3765e-03,  5.9357e-03,  ...,  2.0432e-02,
         -2.2537e-02,  4.4495e-02],
        ...,
        [ 1.3062e-02, -5.5428e-03,  1.0025e-02,  ..., -4.5746e-02,
          6.3477e-03,  2.0248e-02],
        [ 9.6588e-03, -1.4442e-02, -2.0096e-02,  ...,  6.9542e-03,
          5.9013e-03, -3.3588e-03],
        [-5.3177e-03,  2.2705e-02, -2.1713e-02,  ...,  2.4307e-02,
          1.5465e-02, -8.3237e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias': tensor([ 0.0542, -0.0733,  0.2440,  ..., -0.3313, -0.1129,  0.1049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight': tensor([[-0.0227,  0.0130, -0.0113,  ..., -0.0045,  0.0108, -0.0190],
        [-0.0057, -0.0069,  0.0119,  ..., -0.0068,  0.0143,  0.0030],
        [ 0.0062,  0.0204,  0.0161,  ..., -0.0079, -0.0057,  0.0308],
        ...,
        [ 0.0001,  0.0003,  0.0048,  ...,  0.0089, -0.0032,  0.0210],
        [-0.0079,  0.0007,  0.0030,  ...,  0.0093, -0.0068, -0.0121],
        [-0.0154,  0.0158, -0.0231,  ..., -0.0158,  0.0141, -0.0072]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias': tensor([-0.0179,  0.0685, -0.0152,  ..., -0.0815,  0.0257,  0.0175],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight': tensor([1.1738, 1.1582, 1.1592,  ..., 1.5869, 1.1748, 1.2314],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias': tensor([-0.0068,  0.0917, -0.0354,  ..., -0.3271, -0.1141, -0.0543],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight': tensor([[-0.0195, -0.0128, -0.0054,  ..., -0.0029, -0.0047,  0.0116],
        [-0.0031, -0.0199,  0.0011,  ..., -0.0044,  0.0127,  0.0019],
        [ 0.0130, -0.0056,  0.0037,  ..., -0.0005,  0.0237,  0.0081],
        ...,
        [ 0.0115,  0.0130, -0.0272,  ...,  0.0021,  0.0227,  0.0057],
        [-0.0035,  0.0108, -0.0211,  ..., -0.0011,  0.0154, -0.0001],
        [-0.0336,  0.0183,  0.0121,  ..., -0.0012, -0.0093,  0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias': tensor([-0.3628, -0.2211, -0.1648,  ..., -0.2524, -0.2686, -0.2517],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight': tensor([[-4.5166e-03,  7.6828e-03,  1.3664e-02,  ..., -2.5959e-03,
         -2.0126e-02, -7.1602e-03],
        [-1.4015e-02,  2.0084e-03,  6.2370e-03,  ...,  1.9714e-02,
         -4.8294e-03, -2.3682e-02],
        [-4.3793e-03,  6.3400e-03,  5.3253e-03,  ...,  9.2888e-04,
          7.6599e-03, -1.8555e-02],
        ...,
        [-4.1809e-03, -1.8768e-03,  4.0741e-03,  ..., -1.5802e-03,
         -3.6144e-03,  8.3983e-05],
        [-2.7523e-03, -2.6489e-02, -1.3283e-02,  ...,  3.4904e-03,
         -1.4786e-02,  6.2981e-03],
        [-3.0880e-03, -2.1713e-02, -1.7853e-02,  ...,  1.1139e-02,
          7.2784e-03, -1.2558e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias': tensor([-0.0283,  0.0284, -0.0329,  ...,  0.0671, -0.0050, -0.0488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight': tensor([1.2725, 1.2539, 1.2041,  ..., 0.7529, 1.0645, 1.2422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias': tensor([ 0.0019, -0.0140,  0.0246,  ...,  0.2150, -0.1251, -0.2118],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0117,  0.0046,  ..., -0.0265, -0.0033,  0.0070],
        [ 0.0061,  0.0207, -0.0110,  ...,  0.0132,  0.0091,  0.0226],
        [-0.0012,  0.0130,  0.0031,  ...,  0.0025,  0.0157,  0.0028],
        ...,
        [ 0.0178,  0.0099,  0.0200,  ...,  0.0006, -0.0303, -0.0324],
        [-0.0035,  0.0138,  0.0245,  ..., -0.0032, -0.0065,  0.0055],
        [-0.0023,  0.0024, -0.0018,  ...,  0.0053,  0.0023, -0.0070]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias': tensor([ 0.1105, -0.0046,  0.0618,  ...,  0.0103, -0.0147,  0.0179],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight': tensor([[ 0.0128, -0.0147,  0.0370,  ..., -0.0059,  0.0019, -0.0157],
        [-0.0200,  0.0040, -0.0021,  ..., -0.0084, -0.0056, -0.0079],
        [-0.0030, -0.0037, -0.0301,  ..., -0.0076,  0.0190,  0.0188],
        ...,
        [ 0.0036,  0.0197, -0.0007,  ..., -0.0078,  0.0181, -0.0004],
        [-0.0112,  0.0034, -0.0117,  ...,  0.0041, -0.0017, -0.0116],
        [-0.0199,  0.0032, -0.0224,  ..., -0.0046,  0.0289,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias': tensor([-0.0085, -0.0267, -0.0139,  ..., -0.0130,  0.0113,  0.0014],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight': tensor([[-5.2223e-03, -1.1261e-02,  2.0859e-02,  ..., -3.4424e-02,
          5.4245e-03,  3.5515e-03],
        [ 2.7637e-03,  4.4861e-03,  5.6877e-03,  ...,  6.7830e-05,
         -1.3123e-02,  1.6266e-02],
        [-7.9575e-03,  6.3133e-03,  1.7059e-02,  ...,  2.5711e-03,
         -5.4283e-03, -1.0437e-02],
        ...,
        [-1.2264e-03,  2.9633e-02, -8.0185e-03,  ...,  1.4366e-02,
          2.8824e-02, -1.8001e-05],
        [ 5.7316e-04,  8.2397e-03,  1.8951e-02,  ...,  1.4248e-03,
          1.8433e-02, -1.7624e-02],
        [ 6.5842e-03,  2.7451e-02, -1.9012e-02,  ...,  1.1887e-02,
         -7.3357e-03,  1.1284e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias': tensor([-0.8462,  0.0103, -1.0879,  ..., -0.1941,  0.1663, -1.2803],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight': tensor([[-0.0020,  0.0252,  0.0039,  ...,  0.0061, -0.0123,  0.0283],
        [ 0.0043,  0.0004, -0.0082,  ..., -0.0251,  0.0068,  0.0017],
        [-0.0231,  0.0006,  0.0164,  ...,  0.0248,  0.0101,  0.0125],
        ...,
        [ 0.0080,  0.0312,  0.0238,  ...,  0.0045,  0.0003,  0.0054],
        [ 0.0077,  0.0073, -0.0009,  ..., -0.0016,  0.0038, -0.0133],
        [ 0.0194, -0.0053, -0.0238,  ...,  0.0249, -0.0041,  0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias': tensor([-0.0205,  0.0181, -0.0017,  ..., -0.0779,  0.0408, -0.0200],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight': tensor([1.1533, 1.2090, 1.1787,  ..., 1.6367, 1.1729, 1.2188],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias': tensor([-0.0550,  0.0990, -0.0018,  ..., -0.1779, -0.0518, -0.0147],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight': tensor([[-0.0073, -0.0223,  0.0130,  ..., -0.0079, -0.0028,  0.0022],
        [-0.0071,  0.0068,  0.0017,  ..., -0.0123, -0.0179, -0.0108],
        [ 0.0072,  0.0217,  0.0110,  ...,  0.0060,  0.0005,  0.0016],
        ...,
        [ 0.0225, -0.0085,  0.0064,  ...,  0.0007,  0.0014, -0.0003],
        [-0.0191,  0.0245,  0.0085,  ..., -0.0102, -0.0108, -0.0063],
        [ 0.0290, -0.0322, -0.0287,  ..., -0.0045,  0.0156, -0.0153]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias': tensor([-0.4795, -0.1469, -0.1043,  ..., -0.2998, -0.2252, -0.3262],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight': tensor([[-0.0205,  0.0170, -0.0019,  ...,  0.0084,  0.0040,  0.0268],
        [ 0.0060,  0.0025, -0.0069,  ...,  0.0071, -0.0261,  0.0028],
        [ 0.0291, -0.0064, -0.0019,  ..., -0.0131,  0.0078, -0.0294],
        ...,
        [-0.0110,  0.0011, -0.0081,  ..., -0.0030,  0.0036, -0.0003],
        [-0.0195,  0.0083,  0.0063,  ...,  0.0095, -0.0105,  0.0214],
        [-0.0028,  0.0316,  0.0016,  ..., -0.0094, -0.0051,  0.0145]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias': tensor([ 0.0411, -0.0040, -0.0517,  ...,  0.1116,  0.0086, -0.0608],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight': tensor([1.3838, 1.2871, 1.2334,  ..., 0.6108, 1.1768, 1.2568],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias': tensor([-0.2367,  0.0573,  0.1235,  ...,  0.2408,  0.0240, -0.0257],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight': tensor([[-0.0176,  0.0033,  0.0183,  ..., -0.0038,  0.0074,  0.0088],
        [-0.0091,  0.0276, -0.0216,  ...,  0.0220,  0.0110,  0.0020],
        [-0.0428, -0.0160,  0.0246,  ...,  0.0130, -0.0163, -0.0116],
        ...,
        [ 0.0326,  0.0183, -0.0093,  ...,  0.0212, -0.0169,  0.0020],
        [ 0.0131,  0.0204,  0.0034,  ...,  0.0138,  0.0030,  0.0125],
        [ 0.0216,  0.0034,  0.0112,  ..., -0.0203,  0.0063, -0.0135]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias': tensor([-0.0005,  0.0142, -0.0017,  ...,  0.0816, -0.0667,  0.0688],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight': tensor([[-0.0305, -0.0173,  0.0406,  ...,  0.0054,  0.0093, -0.0001],
        [ 0.0040,  0.0132, -0.0068,  ..., -0.0034, -0.0217, -0.0175],
        [-0.0051,  0.0121, -0.0121,  ..., -0.0104, -0.0141, -0.0050],
        ...,
        [ 0.0016,  0.0205, -0.0056,  ..., -0.0040, -0.0046,  0.0020],
        [ 0.0378,  0.0040, -0.0073,  ...,  0.0001, -0.0014,  0.0133],
        [ 0.0088, -0.0021, -0.0040,  ..., -0.0019,  0.0257, -0.0056]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias': tensor([-0.0842, -0.0092,  0.0031,  ...,  0.0677, -0.0071,  0.0129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight': tensor([[ 0.0169, -0.0117, -0.0191,  ...,  0.0101, -0.0038,  0.0100],
        [-0.0080,  0.0092,  0.0094,  ...,  0.0197, -0.0175, -0.0183],
        [-0.0264, -0.0041,  0.0021,  ...,  0.0114,  0.0084, -0.0139],
        ...,
        [-0.0015,  0.0094,  0.0175,  ...,  0.0220, -0.0158,  0.0012],
        [-0.0012,  0.0214, -0.0034,  ...,  0.0166, -0.0191,  0.0039],
        [ 0.0204, -0.0130,  0.0074,  ..., -0.0208,  0.0063, -0.0040]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias': tensor([ 0.0173,  0.2045, -0.1959,  ..., -0.0136, -0.0571, -0.2710],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight': tensor([[ 1.1879e-02, -8.7357e-03, -2.2980e-02,  ..., -5.5885e-03,
         -2.6260e-02,  1.4985e-04],
        [ 2.3117e-02, -1.8127e-02,  2.0111e-02,  ..., -5.3711e-03,
         -3.0880e-03, -2.6855e-03],
        [-7.4577e-03,  5.7449e-03, -2.7313e-02,  ...,  2.7695e-03,
          7.9803e-03,  1.0475e-02],
        ...,
        [-1.1810e-02,  1.0620e-02,  1.4153e-02,  ...,  7.8049e-03,
          7.3671e-04,  2.8267e-03],
        [ 6.1150e-03,  1.5244e-02,  2.3621e-02,  ...,  9.0599e-05,
          2.7008e-03, -3.2196e-02],
        [ 3.8743e-04, -6.6109e-03, -1.4534e-02,  ...,  1.1330e-03,
         -1.8280e-02, -3.4065e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias': tensor([-0.0230,  0.0388, -0.0072,  ..., -0.0651,  0.0296, -0.0002],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight': tensor([1.2031, 1.2344, 1.1543,  ..., 1.5986, 1.2275, 1.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias': tensor([-0.0587,  0.0094, -0.0588,  ..., -0.2544, -0.1669, -0.0670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight': tensor([[-0.0105, -0.0159, -0.0260,  ..., -0.0012,  0.0033,  0.0001],
        [ 0.0232, -0.0237,  0.0074,  ..., -0.0032,  0.0108,  0.0003],
        [ 0.0088,  0.0072,  0.0034,  ...,  0.0001, -0.0065,  0.0012],
        ...,
        [ 0.0007, -0.0093,  0.0181,  ..., -0.0021, -0.0059,  0.0082],
        [ 0.0024,  0.0102, -0.0177,  ..., -0.0005, -0.0069, -0.0302],
        [ 0.0112,  0.0245,  0.0004,  ...,  0.0030, -0.0044,  0.0190]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias': tensor([-0.1327, -0.2241, -0.0568,  ..., -0.2708, -0.3245, -0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight': tensor([[ 1.0185e-02, -1.1162e-02, -2.3911e-02,  ...,  2.9709e-02,
         -1.3023e-02, -1.1803e-02],
        [ 8.2092e-03, -4.3631e-04, -3.1257e-04,  ..., -1.3252e-02,
          5.4598e-05, -1.8997e-02],
        [ 5.5885e-03,  1.8112e-02,  9.0179e-03,  ..., -3.1700e-03,
          8.4686e-03, -3.6144e-03],
        ...,
        [ 4.7798e-03,  3.0174e-03, -3.5143e-04,  ...,  5.4665e-03,
         -3.4122e-03, -4.2953e-03],
        [ 3.2082e-03, -1.4816e-02, -9.4986e-04,  ..., -1.9455e-02,
         -9.8825e-05,  9.9869e-03],
        [-7.2784e-03, -5.8289e-03, -3.9062e-03,  ...,  5.5122e-03,
         -2.4323e-02, -2.7542e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias': tensor([ 0.0389,  0.0069, -0.0129,  ...,  0.0417,  0.0218,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight': tensor([1.4287, 1.3613, 1.2949,  ..., 1.0137, 1.1826, 1.3213],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias': tensor([-0.1137,  0.0275,  0.0679,  ...,  0.1796,  0.0205, -0.2534],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight': tensor([[ 0.0030,  0.0209, -0.0001,  ..., -0.0044,  0.0148,  0.0093],
        [-0.0027, -0.0116,  0.0012,  ...,  0.0060, -0.0152, -0.0084],
        [-0.0064,  0.0066, -0.0148,  ..., -0.0031, -0.0160,  0.0061],
        ...,
        [ 0.0134, -0.0141, -0.0170,  ...,  0.0031, -0.0175,  0.0096],
        [ 0.0032, -0.0072,  0.0027,  ...,  0.0026,  0.0248,  0.0016],
        [ 0.0372, -0.0190,  0.0259,  ..., -0.0076,  0.0134,  0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias': tensor([ 0.0132, -0.0158,  0.0312,  ...,  0.1599,  0.0190, -0.0702],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight': tensor([[-0.0019,  0.0161, -0.0136,  ...,  0.0041,  0.0124, -0.0042],
        [ 0.0003, -0.0210,  0.0050,  ...,  0.0030, -0.0272,  0.0083],
        [-0.0101, -0.0327, -0.0195,  ..., -0.0035,  0.0067, -0.0172],
        ...,
        [ 0.0214, -0.0060, -0.0126,  ..., -0.0054, -0.0032,  0.0097],
        [-0.0153, -0.0010, -0.0009,  ...,  0.0023, -0.0131,  0.0013],
        [ 0.0080,  0.0060,  0.0053,  ..., -0.0054, -0.0073,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias': tensor([-0.0223, -0.0200, -0.0063,  ..., -0.0170, -0.0150,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight': tensor([[-0.0132,  0.0006,  0.0249,  ..., -0.0071,  0.0142, -0.0221],
        [-0.0046,  0.0369, -0.0272,  ...,  0.0017,  0.0163,  0.0032],
        [-0.0089, -0.0084,  0.0370,  ..., -0.0099,  0.0085,  0.0120],
        ...,
        [ 0.0223, -0.0226, -0.0282,  ...,  0.0133, -0.0224, -0.0005],
        [ 0.0005, -0.0127, -0.0058,  ..., -0.0071,  0.0076, -0.0049],
        [-0.0067,  0.0026,  0.0143,  ...,  0.0054, -0.0011,  0.0246]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias': tensor([-0.0499, -0.0381,  0.5078,  ..., -0.0939, -1.3535,  0.2761],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight': tensor([[ 0.0038,  0.0181,  0.0089,  ..., -0.0054,  0.0091,  0.0008],
        [-0.0116,  0.0084,  0.0211,  ...,  0.0138,  0.0282, -0.0086],
        [ 0.0388,  0.0029,  0.0070,  ..., -0.0161,  0.0043, -0.0173],
        ...,
        [ 0.0053, -0.0073, -0.0049,  ...,  0.0171, -0.0165,  0.0032],
        [ 0.0020, -0.0032,  0.0069,  ...,  0.0089,  0.0018,  0.0021],
        [ 0.0025, -0.0044,  0.0106,  ..., -0.0193,  0.0141, -0.0083]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias': tensor([ 0.0060,  0.0680,  0.0354,  ..., -0.0553,  0.0136,  0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight': tensor([1.2344, 1.2090, 1.1689,  ..., 1.8428, 1.1562, 1.2676],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias': tensor([-0.0174, -0.0716, -0.1256,  ..., -0.2900, -0.1460,  0.1504],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight': tensor([[-0.0042, -0.0027,  0.0133,  ..., -0.0005,  0.0226, -0.0110],
        [ 0.0404,  0.0308,  0.0195,  ...,  0.0055, -0.0234,  0.0145],
        [-0.0008, -0.0259, -0.0103,  ...,  0.0008,  0.0100,  0.0084],
        ...,
        [ 0.0190, -0.0154,  0.0061,  ..., -0.0111, -0.0397,  0.0165],
        [ 0.0025, -0.0002,  0.0089,  ..., -0.0010, -0.0172, -0.0077],
        [ 0.0183, -0.0069, -0.0037,  ...,  0.0029, -0.0036,  0.0130]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias': tensor([-0.2314, -0.3215, -0.0735,  ..., -0.3020, -0.1613, -0.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight': tensor([[ 1.0155e-02,  3.2532e-02,  8.2626e-03,  ..., -6.4468e-03,
         -4.7760e-03,  5.5432e-06],
        [-1.1612e-02,  1.7509e-03,  2.4841e-02,  ...,  8.9645e-03,
         -2.5436e-02, -8.4152e-03],
        [ 1.5182e-02,  7.3395e-03,  6.1264e-03,  ..., -1.5427e-02,
         -1.8677e-02,  1.9806e-02],
        ...,
        [-5.6686e-03,  6.3848e-04,  4.5128e-03,  ..., -9.9792e-03,
          1.1284e-02,  6.5231e-04],
        [-3.6335e-03,  3.6285e-02, -9.9277e-04,  ...,  4.8828e-03,
          9.6283e-03,  1.3008e-02],
        [ 9.3918e-03, -2.1927e-02, -1.4038e-02,  ...,  1.3329e-02,
          5.4359e-03,  3.3169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias': tensor([0.0373, 0.0198, 0.0018,  ..., 0.0559, 0.0675, 0.0106],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight': tensor([1.4990, 1.4297, 1.3555,  ..., 0.9502, 1.1816, 1.4072],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias': tensor([-0.1736, -0.0029,  0.0179,  ...,  0.2495,  0.0637, -0.1158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight': tensor([[ 0.0138, -0.0022,  0.0212,  ...,  0.0048,  0.0084,  0.0082],
        [-0.0165, -0.0025,  0.0060,  ...,  0.0063,  0.0062, -0.0098],
        [ 0.0116,  0.0009,  0.0094,  ...,  0.0054,  0.0176,  0.0027],
        ...,
        [ 0.0160, -0.0161,  0.0148,  ..., -0.0268,  0.0052,  0.0090],
        [-0.0136,  0.0253, -0.0004,  ...,  0.0156,  0.0059,  0.0038],
        [-0.0080,  0.0130, -0.0251,  ...,  0.0136, -0.0164,  0.0184]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias': tensor([ 0.1146,  1.0303,  0.1827,  ...,  0.0439,  0.0025, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0085, -0.0074,  ...,  0.0006, -0.0214, -0.0142],
        [ 0.0022,  0.0155, -0.0111,  ..., -0.0004, -0.0232, -0.0101],
        [-0.0139,  0.0073, -0.0043,  ..., -0.0005, -0.0110, -0.0235],
        ...,
        [ 0.0153,  0.0130, -0.0090,  ...,  0.0045,  0.0109,  0.0025],
        [ 0.0072,  0.0052, -0.0024,  ..., -0.0120,  0.0016, -0.0072],
        [ 0.0013, -0.0272, -0.0105,  ..., -0.0043,  0.0004, -0.0020]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias': tensor([ 0.0573, -0.0360, -0.0042,  ...,  0.0485, -0.0465,  0.0206],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight': tensor([[ 0.0094,  0.0003,  0.0279,  ...,  0.0015, -0.0191,  0.0090],
        [ 0.0041, -0.0014,  0.0020,  ...,  0.0017, -0.0018,  0.0040],
        [-0.0280,  0.0335,  0.0134,  ...,  0.0017,  0.0047, -0.0206],
        ...,
        [-0.0081, -0.0019,  0.0095,  ..., -0.0111, -0.0239,  0.0087],
        [-0.0195, -0.0019,  0.0218,  ...,  0.0267,  0.0121, -0.0089],
        [-0.0340, -0.0066,  0.0098,  ...,  0.0160,  0.0019, -0.0100]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias': tensor([ 0.2460,  1.7949,  0.0708,  ..., -0.2112,  0.1188,  0.6323],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight': tensor([[ 0.0051,  0.0107, -0.0119,  ..., -0.0148,  0.0005, -0.0302],
        [-0.0066, -0.0071, -0.0048,  ..., -0.0226, -0.0094,  0.0276],
        [ 0.0101,  0.0083,  0.0168,  ..., -0.0064,  0.0009, -0.0152],
        ...,
        [ 0.0094, -0.0071,  0.0016,  ..., -0.0147,  0.0114,  0.0020],
        [ 0.0223,  0.0076,  0.0287,  ..., -0.0214,  0.0006,  0.0041],
        [ 0.0177,  0.0222,  0.0063,  ...,  0.0065,  0.0120, -0.0114]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias': tensor([ 0.0267, -0.0057, -0.0027,  ..., -0.0531, -0.0267,  0.0482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight': tensor([1.2383, 1.2549, 1.2197,  ..., 1.8193, 1.1484, 1.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias': tensor([ 0.1250, -0.0352,  0.1172,  ..., -0.1227, -0.0328,  0.1005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight': tensor([[-0.0007, -0.0112,  0.0090,  ..., -0.0016,  0.0087,  0.0027],
        [ 0.0122, -0.0152,  0.0042,  ..., -0.0079, -0.0033, -0.0148],
        [ 0.0095, -0.0118, -0.0270,  ...,  0.0040,  0.0046, -0.0246],
        ...,
        [-0.0209, -0.0194, -0.0025,  ..., -0.0006, -0.0144,  0.0085],
        [ 0.0016,  0.0133,  0.0006,  ..., -0.0033, -0.0143,  0.0128],
        [-0.0106,  0.0115,  0.0019,  ..., -0.0046, -0.0505,  0.0052]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias': tensor([-0.3506, -0.3098, -0.0692,  ..., -0.3076, -0.2494, -0.4229],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight': tensor([[-0.0116,  0.0186, -0.0109,  ...,  0.0093, -0.0051, -0.0192],
        [ 0.0115,  0.0091,  0.0046,  ...,  0.0060, -0.0104, -0.0086],
        [-0.0004,  0.0162,  0.0221,  ...,  0.0048,  0.0374,  0.0092],
        ...,
        [-0.0029,  0.0068, -0.0073,  ...,  0.0019, -0.0060,  0.0068],
        [ 0.0121, -0.0012, -0.0035,  ..., -0.0168, -0.0036, -0.0015],
        [ 0.0085, -0.0005,  0.0138,  ..., -0.0026,  0.0074, -0.0113]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias': tensor([ 0.0374, -0.0088, -0.0430,  ...,  0.0654, -0.0126, -0.0253],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight': tensor([1.5195, 1.3818, 1.3984,  ..., 0.8403, 1.2627, 1.5020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias': tensor([-0.1865,  0.1162,  0.4048,  ...,  0.2292,  0.4202, -0.0959],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight': tensor([[ 0.0295,  0.0205, -0.0174,  ...,  0.0181,  0.0055,  0.0153],
        [ 0.0159, -0.0236, -0.0138,  ...,  0.0058,  0.0019,  0.0084],
        [-0.0116, -0.0219,  0.0080,  ...,  0.0020, -0.0022,  0.0255],
        ...,
        [-0.0140,  0.0030, -0.0549,  ...,  0.0038, -0.0079,  0.0469],
        [-0.0193,  0.0216, -0.0092,  ...,  0.0083,  0.0186,  0.0123],
        [ 0.0039,  0.0084,  0.0082,  ..., -0.0016, -0.0041, -0.0187]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias': tensor([-0.0278, -0.0587, -0.0110,  ..., -0.0826, -0.0213, -0.0725],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight': tensor([[-0.0007,  0.0020,  0.0042,  ..., -0.0033, -0.0094, -0.0123],
        [ 0.0162,  0.0139,  0.0239,  ..., -0.0017, -0.0188,  0.0138],
        [-0.0234,  0.0133, -0.0101,  ..., -0.0029, -0.0003,  0.0196],
        ...,
        [ 0.0244,  0.0202,  0.0058,  ..., -0.0130,  0.0092, -0.0032],
        [ 0.0215,  0.0236, -0.0171,  ..., -0.0159, -0.0069,  0.0134],
        [-0.0087,  0.0025,  0.0248,  ..., -0.0004,  0.0047, -0.0208]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias': tensor([-0.0305,  0.0005, -0.0124,  ..., -0.0511, -0.0883,  0.0079],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight': tensor([[-0.0156,  0.0022, -0.0072,  ...,  0.0036,  0.0290,  0.0180],
        [-0.0003,  0.0088, -0.0014,  ..., -0.0144, -0.0101,  0.0001],
        [-0.0141, -0.0287,  0.0098,  ..., -0.0024,  0.0292,  0.0254],
        ...,
        [-0.0255,  0.0364, -0.0171,  ...,  0.0032,  0.0116, -0.0182],
        [-0.0159,  0.0349, -0.0009,  ..., -0.0083, -0.0006, -0.0242],
        [-0.0239,  0.0287,  0.0045,  ...,  0.0057, -0.0037, -0.0132]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias': tensor([-0.2856, -0.3130, -0.2024,  ...,  0.1942, -0.0307, -0.0692],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight': tensor([[ 0.0021, -0.0248,  0.0393,  ..., -0.0213, -0.0080,  0.0129],
        [-0.0123, -0.0083,  0.0236,  ..., -0.0091, -0.0172, -0.0205],
        [-0.0194, -0.0024,  0.0146,  ..., -0.0071,  0.0185, -0.0175],
        ...,
        [-0.0277,  0.0011, -0.0187,  ...,  0.0559,  0.0597, -0.0009],
        [ 0.0156,  0.0051, -0.0020,  ..., -0.0031,  0.0066,  0.0040],
        [-0.0057, -0.0281, -0.0138,  ...,  0.0075, -0.0093,  0.0108]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias': tensor([ 0.0077,  0.0031,  0.0012,  ..., -0.0701,  0.0300,  0.0083],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight': tensor([1.2822, 1.2529, 1.2988,  ..., 2.2090, 1.1758, 1.3721],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias': tensor([ 0.1495, -0.0801, -0.0723,  ..., -0.1654, -0.0899,  0.0350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight': tensor([[ 0.0063,  0.0413,  0.0369,  ...,  0.0064,  0.0150,  0.0227],
        [ 0.0141,  0.0154,  0.0189,  ...,  0.0018,  0.0107,  0.0041],
        [-0.0081, -0.0167,  0.0103,  ..., -0.0018, -0.0027,  0.0110],
        ...,
        [ 0.0142,  0.0290,  0.0162,  ..., -0.0030,  0.0042,  0.0023],
        [ 0.0167,  0.0140,  0.0168,  ..., -0.0036, -0.0046,  0.0118],
        [-0.0082,  0.0164,  0.0227,  ...,  0.0009, -0.0199, -0.0222]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias': tensor([-0.2788, -0.1959, -0.3855,  ..., -0.3228, -0.2610, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight': tensor([[-6.8474e-03, -1.1681e-02, -1.7517e-02,  ...,  1.0986e-02,
         -1.8341e-02,  2.0432e-02],
        [ 1.1215e-02, -7.8430e-03, -6.9542e-03,  ...,  1.2108e-02,
         -9.6741e-03, -1.2093e-02],
        [ 1.2321e-02, -2.7924e-02, -2.8896e-03,  ...,  4.8676e-03,
         -2.0275e-03, -1.2695e-02],
        ...,
        [-2.5902e-03,  1.4412e-02, -3.3092e-03,  ..., -2.8193e-05,
          6.4087e-04, -7.4434e-04],
        [-1.8280e-02, -8.6746e-03,  9.6130e-03,  ...,  4.2915e-03,
         -1.1269e-02,  2.3453e-02],
        [-6.6452e-03, -2.1088e-02, -1.2444e-02,  ..., -3.5534e-03,
         -7.8659e-03,  2.5589e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias': tensor([ 0.0329,  0.0112, -0.0181,  ...,  0.0332,  0.0061, -0.0410],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight': tensor([1.6201, 1.4990, 1.4219,  ..., 0.7642, 1.2715, 1.4961],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias': tensor([-0.1376, -0.0238, -0.0118,  ...,  0.3352,  0.1462, -0.0976],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight': tensor([[ 0.0070,  0.0068,  0.0031,  ...,  0.0113, -0.0308, -0.0060],
        [ 0.0026, -0.0039,  0.0043,  ..., -0.0343, -0.0066,  0.0307],
        [-0.0036,  0.0332, -0.0028,  ...,  0.0011, -0.0337,  0.0031],
        ...,
        [-0.0229, -0.0187, -0.0097,  ..., -0.0007,  0.0183, -0.0038],
        [ 0.0047,  0.0152, -0.0175,  ...,  0.0070,  0.0130, -0.0114],
        [-0.0206,  0.0068, -0.0252,  ...,  0.0070, -0.0134, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias': tensor([ 0.1860, -0.2378,  0.0005,  ...,  0.0031,  0.1797, -0.0522],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight': tensor([[-0.0298, -0.0140,  0.0248,  ...,  0.0035, -0.0014, -0.0059],
        [-0.0006, -0.0080,  0.0046,  ...,  0.0036,  0.0106, -0.0112],
        [ 0.0055,  0.0188,  0.0175,  ...,  0.0029, -0.0033, -0.0018],
        ...,
        [ 0.0039, -0.0129,  0.0162,  ...,  0.0032, -0.0222, -0.0056],
        [-0.0039, -0.0104,  0.0050,  ..., -0.0019,  0.0213, -0.0076],
        [ 0.0024,  0.0067, -0.0013,  ..., -0.0021,  0.0013,  0.0046]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias': tensor([ 0.0186, -0.0095,  0.0066,  ...,  0.0210,  0.0131,  0.0208],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight': tensor([[ 0.0029, -0.0233, -0.0027,  ...,  0.0144, -0.0352, -0.0105],
        [-0.0247, -0.0116,  0.0012,  ..., -0.0372,  0.0113, -0.0128],
        [ 0.0080, -0.0012, -0.0150,  ...,  0.0013, -0.0024,  0.0199],
        ...,
        [-0.0113, -0.0235, -0.0017,  ...,  0.0006, -0.0010, -0.0029],
        [ 0.0197, -0.0205, -0.0153,  ...,  0.0061,  0.0182,  0.0045],
        [-0.0173, -0.0083,  0.0412,  ...,  0.0141, -0.0057,  0.0143]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias': tensor([ 0.2690, -0.1337,  0.1326,  ...,  0.5728, -0.2661, -0.0468],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight': tensor([[ 0.0029,  0.0160,  0.0056,  ...,  0.0018,  0.0077, -0.0090],
        [ 0.0110, -0.0064,  0.0049,  ...,  0.0272,  0.0262,  0.0051],
        [-0.0114, -0.0032,  0.0054,  ...,  0.0236, -0.0132, -0.0082],
        ...,
        [-0.0007,  0.0021, -0.0044,  ..., -0.0028, -0.0311, -0.0200],
        [-0.0074, -0.0073, -0.0035,  ..., -0.0198, -0.0346, -0.0070],
        [-0.0123, -0.0216,  0.0046,  ...,  0.0036,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias': tensor([-0.0063, -0.0193, -0.0133,  ...,  0.0398,  0.0332,  0.0196],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight': tensor([1.3359, 1.2266, 1.2646,  ..., 1.9346, 1.1377, 1.3818],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias': tensor([ 0.1417,  0.0006,  0.0168,  ...,  0.0170, -0.0730,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight': tensor([[ 0.0115,  0.0003, -0.0145,  ..., -0.0144, -0.0194, -0.0104],
        [-0.0015,  0.0058,  0.0179,  ..., -0.0030,  0.0044, -0.0100],
        [-0.0029,  0.0045,  0.0084,  ..., -0.0206,  0.0133,  0.0283],
        ...,
        [ 0.0059, -0.0118, -0.0161,  ..., -0.0221, -0.0054,  0.0157],
        [ 0.0215, -0.0010,  0.0022,  ...,  0.0130,  0.0179,  0.0099],
        [ 0.0113,  0.0054, -0.0108,  ...,  0.0036,  0.0090, -0.0237]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias': tensor([-0.2153, -0.2783, -0.3320,  ..., -0.1221, -0.1306, -0.2898],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight': tensor([[-0.0038, -0.0308,  0.0166,  ..., -0.0028, -0.0180,  0.0016],
        [ 0.0179,  0.0086,  0.0044,  ...,  0.0105,  0.0129, -0.0061],
        [-0.0078, -0.0048,  0.0276,  ...,  0.0158, -0.0102,  0.0017],
        ...,
        [-0.0093,  0.0032, -0.0129,  ...,  0.0116, -0.0041, -0.0039],
        [-0.0126,  0.0043,  0.0086,  ...,  0.0042, -0.0106,  0.0038],
        [-0.0054, -0.0066, -0.0067,  ..., -0.0130, -0.0257,  0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias': tensor([ 0.0253, -0.0025, -0.0242,  ...,  0.0955,  0.0208, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight': tensor([1.6533, 1.5479, 1.5508,  ..., 0.4094, 1.3984, 1.6689],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias': tensor([-0.2152,  0.1279,  0.3982,  ...,  0.3850,  0.3862, -0.2152],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight': tensor([[ 0.0007,  0.0003,  0.0054,  ...,  0.0126,  0.0008,  0.0107],
        [-0.0359,  0.0132, -0.0041,  ..., -0.0473,  0.0050, -0.0005],
        [ 0.0122, -0.0012, -0.0178,  ..., -0.0031,  0.0207, -0.0100],
        ...,
        [ 0.0512, -0.0152, -0.0452,  ...,  0.0250, -0.0268,  0.0074],
        [ 0.0115,  0.0260, -0.0071,  ...,  0.0085,  0.0057,  0.0017],
        [ 0.0223, -0.0031, -0.0004,  ...,  0.0035, -0.0175,  0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias': tensor([-0.8135, -0.1840,  0.0576,  ..., -0.0189,  0.0277,  0.0699],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight': tensor([[ 2.6184e-02,  6.5842e-03, -6.6528e-03,  ...,  2.3901e-05,
          1.5297e-02, -1.9302e-02],
        [ 4.0741e-03,  3.0079e-03,  3.1090e-03,  ..., -9.0485e-03,
          1.0986e-02,  4.2953e-03],
        [ 4.1504e-03,  1.6336e-03, -1.1185e-02,  ...,  5.6496e-03,
          2.0889e-02, -1.3113e-04],
        ...,
        [-3.6945e-03,  1.4648e-02, -8.8348e-03,  ...,  8.1711e-03,
         -2.6073e-03,  1.3008e-02],
        [ 1.9562e-02, -1.5762e-02,  7.0877e-03,  ...,  6.5517e-04,
         -2.1744e-02, -2.0233e-02],
        [ 1.8417e-02, -1.2039e-02, -9.2239e-03,  ..., -4.6659e-04,
         -1.3191e-02, -7.4272e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias': tensor([ 0.0088,  0.0188,  0.0441,  ..., -0.0099, -0.0044,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight': tensor([[-0.0029,  0.0020, -0.0026,  ...,  0.0042, -0.0110, -0.0049],
        [-0.0278,  0.0302,  0.0003,  ..., -0.0331,  0.0236,  0.0125],
        [ 0.0239,  0.0206,  0.0083,  ..., -0.0029,  0.0212, -0.0040],
        ...,
        [ 0.0231,  0.0166, -0.0169,  ...,  0.0415, -0.0144,  0.0037],
        [ 0.0159,  0.0033, -0.0034,  ...,  0.0044, -0.0091,  0.0034],
        [ 0.0106, -0.0117, -0.0165,  ...,  0.0030, -0.0196,  0.0211]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias': tensor([-2.5234,  0.2341, -0.3838,  ..., -0.0643,  0.1272,  0.1238],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight': tensor([[-0.0296, -0.0036,  0.0027,  ...,  0.0065,  0.0073, -0.0128],
        [-0.0154, -0.0153,  0.0213,  ...,  0.0241,  0.0144,  0.0159],
        [-0.0073, -0.0148,  0.0064,  ...,  0.0165,  0.0177,  0.0191],
        ...,
        [-0.0013,  0.0025, -0.0111,  ..., -0.0081,  0.0079,  0.0101],
        [-0.0041, -0.0076, -0.0202,  ..., -0.0055,  0.0170,  0.0018],
        [ 0.0106, -0.0025,  0.0060,  ...,  0.0055, -0.0079,  0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias': tensor([ 0.0107, -0.0549,  0.0179,  ...,  0.0266,  0.0321, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight': tensor([1.3027, 1.2529, 1.3281,  ..., 1.4834, 1.1562, 1.3789],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias': tensor([ 0.1531,  0.0493, -0.0565,  ..., -0.0096, -0.0239, -0.0371],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight': tensor([[ 0.0043,  0.0120,  0.0113,  ..., -0.0241, -0.0064, -0.0090],
        [ 0.0006, -0.0211, -0.0018,  ..., -0.0029, -0.0108,  0.0110],
        [ 0.0030,  0.0094, -0.0028,  ..., -0.0025, -0.0057,  0.0185],
        ...,
        [-0.0027, -0.0314, -0.0122,  ..., -0.0098, -0.0206, -0.0127],
        [-0.0042,  0.0269, -0.0155,  ..., -0.0024, -0.0119, -0.0034],
        [-0.0102,  0.0069, -0.0109,  ..., -0.0012,  0.0015, -0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias': tensor([-0.2781, -0.2573, -0.3364,  ..., -0.3469, -0.2040, -0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight': tensor([[ 0.0010, -0.0122,  0.0169,  ...,  0.0076, -0.0051,  0.0080],
        [ 0.0136, -0.0151, -0.0033,  ..., -0.0080,  0.0146, -0.0023],
        [ 0.0173, -0.0216,  0.0123,  ...,  0.0066, -0.0024, -0.0003],
        ...,
        [-0.0117,  0.0076, -0.0053,  ...,  0.0010,  0.0026,  0.0003],
        [-0.0175,  0.0074, -0.0194,  ..., -0.0246, -0.0096, -0.0045],
        [ 0.0076,  0.0037,  0.0206,  ...,  0.0206, -0.0109,  0.0051]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias': tensor([ 0.0366, -0.0981, -0.0667,  ...,  0.0356,  0.0194, -0.0255],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight': tensor([1.7695, 1.6426, 1.7236,  ..., 0.6680, 1.5166, 1.7900],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias': tensor([-0.1890,  0.3459,  0.1487,  ...,  0.4136,  0.4312, -0.1221],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight': tensor([[ 0.0141,  0.0079,  0.0303,  ..., -0.0145,  0.0041,  0.0001],
        [-0.0112,  0.0048,  0.0240,  ..., -0.0055, -0.0139,  0.0003],
        [ 0.0167,  0.0107,  0.0269,  ..., -0.0065,  0.0130, -0.0072],
        ...,
        [-0.0014,  0.0062,  0.0020,  ..., -0.0017,  0.0170, -0.0246],
        [-0.0123, -0.0318, -0.0099,  ..., -0.0016, -0.0070, -0.0297],
        [ 0.0025,  0.0103,  0.0089,  ...,  0.0022,  0.0038,  0.0318]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias': tensor([-0.0931,  0.0089, -0.0538,  ...,  0.1041,  0.1436,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight': tensor([[-0.0085,  0.0049, -0.0003,  ...,  0.0036, -0.0302,  0.0040],
        [ 0.0075, -0.0265, -0.0065,  ..., -0.0031,  0.0134, -0.0018],
        [-0.0087, -0.0006, -0.0056,  ...,  0.0055,  0.0154,  0.0372],
        ...,
        [-0.0022, -0.0078,  0.0144,  ...,  0.0019, -0.0084,  0.0115],
        [ 0.0047, -0.0127, -0.0223,  ..., -0.0021, -0.0109,  0.0101],
        [-0.0105, -0.0005, -0.0008,  ..., -0.0030, -0.0079, -0.0039]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias': tensor([-0.0321,  0.0378,  0.0632,  ...,  0.0502, -0.0048, -0.0005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight': tensor([[-0.0095, -0.0095,  0.0312,  ...,  0.0022, -0.0092,  0.0262],
        [-0.0264, -0.0028, -0.0018,  ..., -0.0075, -0.0155, -0.0109],
        [-0.0025, -0.0001,  0.0389,  ..., -0.0119,  0.0128, -0.0002],
        ...,
        [ 0.0271, -0.0069,  0.0122,  ...,  0.0018,  0.0167, -0.0080],
        [ 0.0080, -0.0216,  0.0023,  ...,  0.0015, -0.0140,  0.0002],
        [-0.0039,  0.0055,  0.0021,  ...,  0.0071, -0.0103,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias': tensor([-0.2311,  0.2390, -0.0950,  ...,  0.0876,  0.1581,  0.0798],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight': tensor([[-0.0281, -0.0058,  0.0026,  ..., -0.0079,  0.0053, -0.0023],
        [ 0.0130, -0.0057, -0.0072,  ..., -0.0006, -0.0015, -0.0051],
        [-0.0112,  0.0132,  0.0089,  ..., -0.0184,  0.0022, -0.0036],
        ...,
        [ 0.0086,  0.0047, -0.0106,  ..., -0.0117, -0.0147, -0.0069],
        [ 0.0147, -0.0031, -0.0165,  ...,  0.0125, -0.0091,  0.0107],
        [ 0.0214,  0.0008, -0.0262,  ..., -0.0205, -0.0144,  0.0057]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias': tensor([-0.0645, -0.0639,  0.0044,  ..., -0.0346, -0.0156, -0.0320],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight': tensor([1.3975, 1.3584, 1.4883,  ..., 1.8799, 1.3203, 1.4980],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias': tensor([ 0.0757, -0.1133, -0.0580,  ..., -0.0255, -0.0899, -0.1061],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight': tensor([[-7.1793e-03,  4.6234e-03,  1.7502e-02,  ..., -1.0124e-02,
          1.3245e-02, -6.4430e-03],
        [-1.6571e-02,  1.1040e-02, -5.1537e-03,  ..., -6.7616e-04,
         -2.2491e-02, -9.1019e-03],
        [-7.6675e-04,  2.2156e-02,  1.0216e-02,  ..., -4.4708e-03,
         -1.6510e-02, -2.4704e-02],
        ...,
        [-2.9205e-02, -7.1602e-03,  8.7559e-05,  ..., -9.7656e-03,
          1.6312e-02,  2.7145e-02],
        [-1.2413e-02,  6.9084e-03,  2.4399e-02,  ..., -7.0381e-03,
         -7.9803e-03,  9.6130e-03],
        [ 6.4039e-04, -4.3259e-03,  4.3121e-02,  ..., -3.9101e-03,
         -1.3245e-02,  1.4565e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias': tensor([-0.3418, -0.2771, -0.3467,  ..., -0.3992, -0.2385, -0.2927],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight': tensor([[-9.4452e-03,  1.2772e-02,  1.8539e-02,  ..., -2.6276e-02,
          4.2343e-04, -1.3672e-02],
        [ 3.2593e-02,  8.7070e-04, -2.8477e-03,  ..., -8.7814e-03,
          1.1383e-02, -3.0182e-02],
        [-4.3488e-03, -2.7359e-02,  1.8482e-03,  ..., -6.5002e-03,
          2.6016e-02,  3.3539e-02],
        ...,
        [-4.1504e-03,  1.6251e-02,  7.8354e-03,  ...,  1.4816e-02,
         -1.9627e-03, -6.3002e-05],
        [ 6.4125e-03, -1.6647e-02,  4.3945e-03,  ...,  1.2833e-02,
         -1.5268e-03, -1.7975e-02],
        [-1.8167e-03, -1.1734e-02, -1.4511e-02,  ...,  3.0396e-02,
          1.1108e-02, -9.7580e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias': tensor([-0.0361, -0.0392,  0.0150,  ..., -0.0163,  0.0041, -0.0078],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight': tensor([2.1113, 2.0137, 2.0352,  ..., 0.7090, 1.8164, 2.2012],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias': tensor([-0.1631, -0.1508,  0.1484,  ...,  0.4434,  0.6812, -0.3279],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight': tensor([[-9.9716e-03, -2.5208e-02,  8.4457e-03,  ...,  1.3168e-02,
         -5.3942e-05, -2.8748e-02],
        [-3.1233e-05,  1.3992e-02, -2.2476e-02,  ...,  6.3232e-02,
         -1.4221e-02, -1.4404e-02],
        [-5.1785e-04, -3.1403e-02,  6.5517e-04,  ..., -1.0399e-02,
          1.1505e-02, -2.8076e-03],
        ...,
        [-6.2132e-04, -1.0201e-02,  1.3947e-02,  ..., -5.4810e-02,
         -8.1787e-03, -2.0981e-02],
        [ 9.8572e-03, -1.7899e-02,  1.1734e-02,  ..., -4.1885e-03,
          1.4870e-02,  1.1244e-03],
        [ 1.5884e-02,  2.2827e-02,  4.2000e-03,  ..., -4.3091e-02,
         -2.2690e-02, -1.3191e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias': tensor([ 0.2656, -0.2185,  0.0432,  ..., -0.1787, -0.2061,  0.0742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight': tensor([[ 0.0261,  0.0077, -0.0120,  ..., -0.0027, -0.0164, -0.0107],
        [-0.0080,  0.0102,  0.0077,  ...,  0.0039,  0.0010, -0.0050],
        [ 0.0017, -0.0101, -0.0256,  ...,  0.0058, -0.0145, -0.0055],
        ...,
        [-0.0161,  0.0100, -0.0047,  ..., -0.0049, -0.0208,  0.0245],
        [ 0.0115, -0.0098,  0.0141,  ...,  0.0035, -0.0129, -0.0005],
        [-0.0111, -0.0270,  0.0220,  ..., -0.0022, -0.0052, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias': tensor([-0.0182,  0.0114,  0.1055,  ..., -0.0048, -0.0138,  0.0093],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight': tensor([[-0.0116, -0.0250, -0.0204,  ...,  0.0060, -0.0022, -0.0020],
        [ 0.0243,  0.0011, -0.0106,  ...,  0.0480, -0.0213,  0.0138],
        [ 0.0116, -0.0210, -0.0045,  ..., -0.0067, -0.0268, -0.0189],
        ...,
        [ 0.0013,  0.0050,  0.0468,  ..., -0.0500,  0.0203,  0.0043],
        [ 0.0273, -0.0117,  0.0099,  ..., -0.0033, -0.0067,  0.0015],
        [-0.0062,  0.0012,  0.0167,  ..., -0.0361, -0.0010,  0.0275]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias': tensor([ 0.2439, -0.1146,  0.0887,  ...,  0.2213,  0.1515, -0.0186],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight': tensor([[-3.0136e-02,  1.2367e-02, -9.5749e-03,  ...,  1.8692e-02,
          9.2697e-03, -4.0054e-03],
        [-3.6682e-02, -9.7504e-03,  7.6950e-05,  ..., -1.0941e-02,
          8.2474e-03, -8.6546e-04],
        [ 1.9424e-02, -2.1729e-02,  5.8022e-03,  ...,  6.4888e-03,
         -4.6577e-03, -6.9504e-03],
        ...,
        [-7.0953e-03, -1.1024e-02,  1.4248e-03,  ...,  3.1490e-03,
         -7.8735e-03, -1.8097e-02],
        [ 1.8778e-03, -1.1490e-02, -8.2855e-03,  ..., -1.9104e-02,
          7.3166e-03, -8.8959e-03],
        [-8.1558e-03,  1.7426e-02,  1.1551e-02,  ..., -4.8790e-03,
          5.9700e-03,  9.9030e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias': tensor([-0.0732,  0.0212,  0.0239,  ...,  0.0091, -0.0001, -0.0141],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight': tensor([1.3848, 1.3320, 1.4814,  ..., 1.5195, 1.3164, 1.4180],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias': tensor([ 0.0473, -0.0936, -0.0594,  ...,  0.0325,  0.0149, -0.0659],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight': tensor([[ 1.5793e-02, -8.3160e-03,  2.2156e-02,  ...,  1.8814e-02,
         -5.4436e-03, -1.1604e-02],
        [ 1.5007e-02, -9.5978e-03, -2.5284e-02,  ..., -1.6510e-02,
         -3.3539e-02, -2.3102e-02],
        [-2.1622e-02,  2.0309e-02,  2.1801e-03,  ...,  7.5798e-03,
          1.4145e-02, -7.3433e-03],
        ...,
        [-4.5624e-03, -2.5757e-02,  6.9199e-03,  ...,  3.5572e-03,
          1.4694e-02, -2.2339e-02],
        [-9.1791e-06,  7.1487e-03, -1.3298e-02,  ...,  5.6610e-03,
          4.4975e-03,  1.1978e-02],
        [-5.8289e-03,  5.1689e-03, -1.4862e-02,  ...,  1.8585e-02,
          9.6655e-04,  1.1856e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias': tensor([-0.2683, -0.3921, -0.3279,  ..., -0.3718, -0.2028, -0.3127],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight': tensor([[-0.0059, -0.0140,  0.0130,  ...,  0.0043,  0.0292, -0.0014],
        [ 0.0265, -0.0073, -0.0116,  ..., -0.0211,  0.0206,  0.0263],
        [ 0.0022, -0.0233,  0.0002,  ...,  0.0067, -0.0096, -0.0120],
        ...,
        [ 0.0080, -0.0016,  0.0073,  ..., -0.0021, -0.0057, -0.0010],
        [ 0.0048, -0.0163, -0.0040,  ...,  0.0130, -0.0188,  0.0429],
        [-0.0011, -0.0383, -0.0151,  ..., -0.0132,  0.0248,  0.0216]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias': tensor([ 0.0359,  0.0342,  0.0545,  ...,  0.0745, -0.0070,  0.0030],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight': tensor([2.5176, 2.3496, 2.4785,  ..., 0.5151, 2.0352, 2.4492],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias': tensor([-0.2339, -0.0297,  0.1533,  ...,  0.4067,  0.7363, -0.2054],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0246, -0.0315,  ...,  0.0246, -0.0050,  0.0121],
        [ 0.0096,  0.0193,  0.0106,  ..., -0.0207, -0.0075,  0.0043],
        [ 0.0199,  0.0022, -0.0148,  ..., -0.0771, -0.0211,  0.0064],
        ...,
        [ 0.0369,  0.0040, -0.0087,  ..., -0.0215,  0.0106,  0.0167],
        [-0.0061, -0.0050, -0.0032,  ..., -0.0078,  0.0147,  0.0186],
        [ 0.0009,  0.0079, -0.0195,  ..., -0.0096, -0.0309,  0.0012]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias': tensor([ 0.0911, -0.1252, -0.4846,  ...,  0.0673, -0.0733,  0.0197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight': tensor([[ 0.0141,  0.0237,  0.0094,  ..., -0.0007, -0.0127, -0.0134],
        [ 0.0092, -0.0071,  0.0201,  ...,  0.0027, -0.0176, -0.0013],
        [ 0.0039, -0.0016, -0.0055,  ...,  0.0065, -0.0001, -0.0049],
        ...,
        [ 0.0073, -0.0355, -0.0101,  ...,  0.0047, -0.0010, -0.0099],
        [-0.0019,  0.0097, -0.0335,  ..., -0.0019,  0.0006, -0.0019],
        [ 0.0030, -0.0076,  0.0026,  ..., -0.0004,  0.0043, -0.0152]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias': tensor([ 0.0290,  0.0252,  0.0343,  ...,  0.0027, -0.0045, -0.0545],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight': tensor([[ 0.0060, -0.0019, -0.0088,  ...,  0.0198, -0.0025, -0.0177],
        [ 0.0059,  0.0067,  0.0215,  ..., -0.0244, -0.0294,  0.0024],
        [ 0.0271,  0.0004, -0.0182,  ..., -0.0876,  0.0076, -0.0006],
        ...,
        [-0.0081,  0.0160, -0.0380,  ..., -0.0249, -0.0083,  0.0045],
        [ 0.0112, -0.0182, -0.0261,  ..., -0.0056, -0.0009, -0.0319],
        [ 0.0435,  0.0031,  0.0118,  ..., -0.0163,  0.0102, -0.0193]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias': tensor([ 0.0622,  0.0999, -0.5308,  ..., -0.1455,  0.0368, -0.1086],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight': tensor([[ 4.6425e-03, -2.0313e-03,  2.7237e-02,  ...,  1.0216e-02,
         -2.0187e-02,  1.1955e-02],
        [-5.8823e-03,  2.6627e-02,  7.8506e-03,  ...,  3.9864e-03,
         -1.8646e-02,  2.6762e-05],
        [-5.6601e-04,  5.0240e-03,  2.1591e-02,  ...,  1.1375e-02,
          6.1035e-03,  7.7581e-04],
        ...,
        [ 9.0256e-03, -4.1656e-03, -1.2932e-02,  ...,  9.0778e-05,
          1.9577e-02, -6.6452e-03],
        [ 1.5488e-02,  5.1928e-04,  1.3100e-02,  ..., -2.1057e-02,
         -4.6921e-03,  1.0338e-02],
        [ 3.2501e-03, -2.0432e-02, -2.8076e-02,  ..., -8.2169e-03,
         -2.1858e-03,  3.8376e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias': tensor([ 0.0169,  0.0075, -0.0464,  ...,  0.0064, -0.0125, -0.0271],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight': tensor([1.4844, 1.5352, 1.5859,  ..., 1.5234, 1.4395, 1.5938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias': tensor([ 0.1630, -0.0892, -0.0373,  ..., -0.0082, -0.0609, -0.1628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight': tensor([[-0.0057, -0.0090,  0.0211,  ...,  0.0072, -0.0180, -0.0063],
        [ 0.0278,  0.0188,  0.0136,  ..., -0.0074,  0.0133, -0.0087],
        [-0.0168,  0.0028, -0.0226,  ..., -0.0184, -0.0072, -0.0020],
        ...,
        [ 0.0011, -0.0155, -0.0045,  ..., -0.0092, -0.0268,  0.0125],
        [ 0.0054, -0.0030,  0.0160,  ...,  0.0257, -0.0181, -0.0068],
        [ 0.0045,  0.0018,  0.0164,  ..., -0.0108, -0.0191, -0.0004]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias': tensor([-0.2793, -0.3452, -0.2959,  ..., -0.1838, -0.1981, -0.2494],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight': tensor([[-0.0017, -0.0146,  0.0010,  ...,  0.0037, -0.0001,  0.0201],
        [ 0.0174, -0.0161, -0.0016,  ..., -0.0007, -0.0096, -0.0005],
        [ 0.0072,  0.0077, -0.0210,  ...,  0.0165, -0.0019, -0.0208],
        ...,
        [ 0.0195, -0.0092,  0.0151,  ..., -0.0062, -0.0071, -0.0216],
        [ 0.0159,  0.0006,  0.0077,  ..., -0.0073,  0.0030,  0.0091],
        [ 0.0062,  0.0206,  0.0089,  ...,  0.0090, -0.0033, -0.0063]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias': tensor([0.0065, 0.0102, 0.0046,  ..., 0.0065, 0.0796, 0.0695],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight': tensor([2.6719, 2.5625, 2.7695,  ..., 0.6802, 2.2539, 2.7422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias': tensor([-0.0354,  0.2776,  0.4175,  ...,  0.5674,  0.5327, -0.4670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight': tensor([[-0.0087,  0.0027,  0.0113,  ..., -0.0616,  0.0051, -0.0137],
        [-0.0173,  0.0047,  0.0124,  ...,  0.0239, -0.0160,  0.0129],
        [ 0.0097, -0.0005, -0.0050,  ...,  0.0011,  0.0099, -0.0130],
        ...,
        [-0.0052,  0.0120,  0.0098,  ..., -0.0244,  0.0038,  0.0010],
        [ 0.0119, -0.0235, -0.0134,  ..., -0.0140, -0.0140,  0.0065],
        [ 0.0291,  0.0226, -0.0254,  ..., -0.0035, -0.0137,  0.0350]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias': tensor([ 0.2783, -0.2036, -0.0648,  ...,  0.1705,  0.1809,  0.1080],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight': tensor([[-0.0184,  0.0137,  0.0067,  ..., -0.0029,  0.0099,  0.0297],
        [-0.0110,  0.0184,  0.0020,  ...,  0.0024, -0.0151,  0.0009],
        [ 0.0191, -0.0126,  0.0212,  ...,  0.0024, -0.0348,  0.0026],
        ...,
        [ 0.0005,  0.0007, -0.0011,  ...,  0.0046, -0.0222, -0.0393],
        [ 0.0117,  0.0042,  0.0002,  ..., -0.0006,  0.0005, -0.0083],
        [-0.0062,  0.0128,  0.0124,  ..., -0.0037, -0.0134,  0.0008]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias': tensor([-0.0114,  0.0300,  0.0252,  ..., -0.0060,  0.0197,  0.0400],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight': tensor([[ 1.4931e-02, -1.2466e-02,  2.4918e-02,  ..., -5.9814e-02,
         -4.3068e-03,  1.2131e-02],
        [-1.6464e-02, -9.9030e-03, -1.1108e-02,  ...,  2.3956e-02,
         -3.6163e-02,  1.1703e-02],
        [ 1.0757e-02,  2.5730e-03, -7.3338e-04,  ...,  2.4662e-03,
          6.1493e-03,  6.6528e-03],
        ...,
        [ 5.1003e-03, -7.8678e-06,  5.1041e-03,  ..., -4.5410e-02,
         -3.1738e-02,  1.8631e-02],
        [ 1.7502e-02, -4.1084e-03,  3.9978e-03,  ..., -1.8753e-02,
         -2.2335e-03,  2.1057e-03],
        [ 1.7303e-02,  6.7902e-03,  1.1360e-02,  ...,  8.0719e-03,
         -5.0278e-03,  2.1713e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias': tensor([-0.2339,  0.0393, -0.0323,  ..., -0.1953,  0.0200,  0.0049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight': tensor([[ 0.0254,  0.0050,  0.0049,  ...,  0.0120, -0.0121,  0.0091],
        [ 0.0248, -0.0193, -0.0093,  ..., -0.0044, -0.0032,  0.0151],
        [ 0.0053,  0.0182, -0.0142,  ..., -0.0130, -0.0033, -0.0087],
        ...,
        [ 0.0006, -0.0051, -0.0173,  ...,  0.0031, -0.0128,  0.0099],
        [ 0.0081, -0.0134,  0.0246,  ...,  0.0185, -0.0136,  0.0109],
        [-0.0261, -0.0152, -0.0080,  ...,  0.0230, -0.0056,  0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias': tensor([-0.0083,  0.0091, -0.0955,  ..., -0.0067,  0.0003, -0.0047],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight': tensor([1.5762, 1.4580, 1.5850,  ..., 1.7383, 1.4209, 1.5967],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias': tensor([ 0.1272, -0.2208, -0.0098,  ..., -0.0831, -0.0858, -0.1576],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight': tensor([[-0.0051,  0.0014, -0.0012,  ...,  0.0091, -0.0065, -0.0086],
        [-0.0191,  0.0118,  0.0002,  ..., -0.0095, -0.0148,  0.0134],
        [-0.0012, -0.0324,  0.0047,  ..., -0.0084,  0.0050, -0.0089],
        ...,
        [ 0.0005, -0.0097, -0.0229,  ..., -0.0036, -0.0164, -0.0044],
        [ 0.0058, -0.0019, -0.0019,  ...,  0.0053,  0.0177,  0.0073],
        [ 0.0128,  0.0044, -0.0019,  ..., -0.0147,  0.0180, -0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias': tensor([-0.1597, -0.3298, -0.3066,  ..., -0.3003, -0.3157, -0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight': tensor([[-0.0060, -0.0143,  0.0279,  ..., -0.0150,  0.0291,  0.0124],
        [ 0.0095, -0.0208, -0.0114,  ...,  0.0116, -0.0289,  0.0051],
        [-0.0165,  0.0403, -0.0052,  ...,  0.0008, -0.0144, -0.0153],
        ...,
        [-0.0120,  0.0119, -0.0007,  ...,  0.0051,  0.0161, -0.0073],
        [ 0.0291,  0.0090, -0.0140,  ...,  0.0286,  0.0029, -0.0079],
        [ 0.0233, -0.0179, -0.0138,  ..., -0.0036, -0.0180, -0.0041]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias': tensor([ 0.0113,  0.0318, -0.0128,  ..., -0.0561, -0.0155,  0.0321],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight': tensor([2.7773, 2.7402, 2.7402,  ..., 0.8696, 2.4961, 2.8711],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias': tensor([-0.1473, -0.0198,  0.2091,  ...,  0.4590,  0.5410, -0.2742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight': tensor([[ 0.0005, -0.0174, -0.0133,  ..., -0.0195,  0.0176,  0.0196],
        [ 0.0332, -0.0111, -0.0092,  ..., -0.0143,  0.0277, -0.0138],
        [-0.0094,  0.0108, -0.0135,  ..., -0.0078, -0.0209, -0.0013],
        ...,
        [ 0.0136,  0.0224,  0.0235,  ..., -0.0533, -0.0095,  0.0097],
        [-0.0183, -0.0031, -0.0219,  ..., -0.0209, -0.0113,  0.0082],
        [ 0.0187,  0.0257,  0.0352,  ..., -0.0150,  0.0010,  0.0060]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias': tensor([-0.2089,  0.1558,  0.3555,  ...,  0.0323,  0.1013,  0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight': tensor([[-0.0096,  0.0058, -0.0198,  ...,  0.0084,  0.0249,  0.0066],
        [ 0.0346, -0.0048, -0.0196,  ..., -0.0008, -0.0481, -0.0151],
        [-0.0034,  0.0091,  0.0039,  ..., -0.0047,  0.0017, -0.0073],
        ...,
        [-0.0277, -0.0315,  0.0064,  ..., -0.0131, -0.0027,  0.0125],
        [ 0.0013,  0.0095,  0.0286,  ..., -0.0024,  0.0112,  0.0018],
        [-0.0154,  0.0043, -0.0169,  ...,  0.0051,  0.0013, -0.0213]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias': tensor([0.0214, 0.0242, 0.0006,  ..., 0.0194, 0.0418, 0.0340],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight': tensor([[-0.0110, -0.0187, -0.0399,  ..., -0.0132,  0.0016,  0.0080],
        [ 0.0197,  0.0169,  0.0061,  ..., -0.0240,  0.0292,  0.0127],
        [-0.0047, -0.0227, -0.0048,  ..., -0.0150, -0.0014,  0.0108],
        ...,
        [-0.0113,  0.0006, -0.0214,  ..., -0.0389, -0.0254,  0.0096],
        [ 0.0066,  0.0193,  0.0392,  ...,  0.0004,  0.0306, -0.0154],
        [-0.0041,  0.0141, -0.0124,  ..., -0.0156, -0.0206,  0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias': tensor([-0.0377, -0.0410, -0.0185,  ..., -0.2778,  0.1395,  0.1525],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight': tensor([[-1.2112e-03,  2.4259e-05, -4.5753e-04,  ...,  4.1847e-03,
          3.2597e-03, -3.2745e-02],
        [-1.3557e-02, -5.1613e-03,  2.0218e-02,  ..., -7.0801e-03,
         -2.9678e-02, -3.8872e-03],
        [-2.0355e-02, -4.8676e-03,  1.2039e-02,  ...,  1.1337e-02,
         -5.5161e-03, -1.0376e-02],
        ...,
        [ 1.2032e-02,  1.7944e-02, -4.4212e-03,  ...,  3.3722e-02,
         -1.9394e-02, -2.0691e-02],
        [-1.6998e-02,  2.0340e-02, -9.7885e-03,  ..., -4.0588e-03,
          4.5967e-03, -7.2937e-03],
        [-1.6357e-02, -1.8204e-02,  1.9684e-02,  ...,  1.2749e-02,
         -2.2552e-02, -1.4832e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias': tensor([-0.0427,  0.0264, -0.0947,  ..., -0.0744, -0.0230, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight': tensor([1.6475, 1.5273, 1.6768,  ..., 1.8574, 1.4951, 1.6426],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias': tensor([-0.0313, -0.3167, -0.0297,  ..., -0.0391, -0.0746, -0.2402],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight': tensor([[-0.0260, -0.0154,  0.0028,  ..., -0.0228, -0.0295, -0.0447],
        [ 0.0029, -0.0058,  0.0197,  ...,  0.0138,  0.0183,  0.0026],
        [ 0.0218, -0.0178,  0.0015,  ..., -0.0087,  0.0014,  0.0125],
        ...,
        [ 0.0404,  0.0179, -0.0153,  ...,  0.0049,  0.0196, -0.0120],
        [ 0.0015, -0.0189,  0.0088,  ...,  0.0184, -0.0162, -0.0341],
        [ 0.0035, -0.0139, -0.0161,  ...,  0.0040, -0.0222, -0.0067]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias': tensor([-0.3091, -0.1617, -0.2668,  ..., -0.2510, -0.2261, -0.2350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight': tensor([[-0.0030, -0.0123, -0.0188,  ...,  0.0186, -0.0332, -0.0181],
        [ 0.0014, -0.0037, -0.0307,  ..., -0.0058,  0.0160,  0.0274],
        [ 0.0273, -0.0119, -0.0110,  ..., -0.0013, -0.0041, -0.0059],
        ...,
        [ 0.0018, -0.0187, -0.0384,  ...,  0.0141,  0.0053,  0.0090],
        [ 0.0151, -0.0128, -0.0045,  ...,  0.0167, -0.0064,  0.0077],
        [ 0.0001,  0.0021,  0.0336,  ..., -0.0046, -0.0128,  0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias': tensor([ 0.1198, -0.0191,  0.1595,  ..., -0.0292, -0.0284, -0.0580],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight': tensor([3.1777, 3.2344, 3.2090,  ..., 1.1455, 2.6172, 3.2363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias': tensor([-0.3699,  0.0534, -0.3181,  ...,  0.1720,  0.3350, -0.2013],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight': tensor([[ 0.0132,  0.0254, -0.0020,  ..., -0.0305,  0.0047,  0.0051],
        [ 0.0022, -0.0257,  0.0199,  ..., -0.0184,  0.0286,  0.0047],
        [-0.0092, -0.0116,  0.0196,  ..., -0.0357,  0.0290,  0.0171],
        ...,
        [ 0.0071, -0.0053,  0.0001,  ..., -0.0139, -0.0043, -0.0191],
        [-0.0128,  0.0084, -0.0034,  ..., -0.0035, -0.0175, -0.0111],
        [ 0.0023, -0.0036, -0.0063,  ...,  0.0125, -0.0132,  0.0166]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias': tensor([ 2.2266,  1.3135, -0.9771,  ...,  0.3726,  2.3047,  0.1869],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight': tensor([[-0.0117,  0.0124, -0.0160,  ...,  0.0026,  0.0036,  0.0293],
        [ 0.0022, -0.0097, -0.0008,  ..., -0.0094,  0.0017, -0.0152],
        [-0.0117, -0.0052, -0.0132,  ...,  0.0201,  0.0020, -0.0049],
        ...,
        [ 0.0122, -0.0035, -0.0111,  ..., -0.0017,  0.0214,  0.0207],
        [-0.0134,  0.0110, -0.0031,  ...,  0.0010,  0.0070,  0.0225],
        [ 0.0003,  0.0153,  0.0004,  ...,  0.0096,  0.0122,  0.0161]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias': tensor([ 0.0095, -0.0149, -0.0342,  ...,  0.0316,  0.0107, -0.0553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight': tensor([[ 2.4475e-02,  1.0361e-02, -3.1738e-03,  ...,  6.3629e-03,
         -4.1161e-03,  4.0770e-05],
        [ 6.4735e-03, -1.1032e-02, -4.1046e-03,  ...,  2.4471e-03,
         -7.7009e-04,  3.3226e-03],
        [-2.2324e-02, -5.0497e-04, -2.1210e-02,  ..., -6.5186e-02,
         -3.9253e-03, -4.9324e-03],
        ...,
        [ 7.4692e-03, -2.1229e-03, -2.2095e-02,  ..., -3.7079e-02,
         -3.3173e-02,  2.9621e-03],
        [-2.3987e-02, -1.8463e-03, -3.8791e-04,  ..., -1.6312e-02,
         -2.0157e-02,  1.9180e-02],
        [ 5.5695e-03, -1.0750e-02,  1.4153e-03,  ...,  1.7136e-02,
         -1.8829e-02, -3.1219e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias': tensor([ 0.0942, -0.0380, -0.0066,  ..., -0.2206,  0.0908,  0.0343],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight': tensor([[ 0.0108, -0.0169,  0.0143,  ..., -0.0040, -0.0186, -0.0120],
        [-0.0099,  0.0158, -0.0007,  ..., -0.0126,  0.0125, -0.0013],
        [ 0.0059, -0.0186,  0.0080,  ...,  0.0038,  0.0261, -0.0122],
        ...,
        [ 0.0193, -0.0006, -0.0168,  ..., -0.0111, -0.0033,  0.0045],
        [ 0.0071,  0.0175, -0.0099,  ...,  0.0238,  0.0111,  0.0132],
        [ 0.0269,  0.0227,  0.0074,  ..., -0.0048, -0.0153, -0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias': tensor([ 0.1117, -0.0344, -0.0097,  ..., -0.0479, -0.0558, -0.0235],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight': tensor([1.5781, 1.5361, 1.5830,  ..., 0.8071, 1.4404, 1.7129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias': tensor([ 0.0493, -0.2202, -0.1034,  ...,  0.0678, -0.1000, -0.2034],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight': tensor([[-0.0206, -0.0153,  0.0054,  ...,  0.0216,  0.0042, -0.0064],
        [-0.0240,  0.0083,  0.0154,  ..., -0.0026,  0.0077, -0.0042],
        [ 0.0143,  0.0016,  0.0010,  ...,  0.0362,  0.0050,  0.0193],
        ...,
        [ 0.0191,  0.0038,  0.0125,  ..., -0.0049, -0.0139, -0.0164],
        [ 0.0050,  0.0037,  0.0237,  ..., -0.0271,  0.0079, -0.0093],
        [ 0.0163,  0.0038, -0.0141,  ..., -0.0026, -0.0191,  0.0084]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias': tensor([-0.2673, -0.2559, -0.2236,  ..., -0.2888, -0.2781, -0.0958],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight': tensor([[-0.0093, -0.0160, -0.0221,  ...,  0.0137, -0.0174, -0.0188],
        [-0.0096,  0.0156, -0.0179,  ..., -0.0231,  0.0060, -0.0123],
        [ 0.0032, -0.0022,  0.0147,  ..., -0.0053,  0.0070,  0.0076],
        ...,
        [-0.0122, -0.0089,  0.0011,  ...,  0.0205,  0.0041, -0.0117],
        [ 0.0056, -0.0073, -0.0155,  ..., -0.0081, -0.0361,  0.0044],
        [ 0.0310,  0.0010,  0.0081,  ..., -0.0060, -0.0118, -0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias': tensor([-0.0192, -0.0717,  0.1105,  ..., -0.1528,  0.0851, -0.0401],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight': tensor([3.1602, 3.0371, 2.9180,  ..., 1.5098, 2.5527, 3.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias': tensor([ 0.2227,  0.6216, -0.4958,  ...,  0.2568,  0.0677, -0.4553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight': tensor([[ 0.0037,  0.0141,  0.0131,  ...,  0.0058,  0.0128,  0.0105],
        [ 0.0020, -0.0168, -0.0078,  ...,  0.0242, -0.0173, -0.0008],
        [ 0.0030,  0.0062, -0.0284,  ..., -0.0097,  0.0236,  0.0083],
        ...,
        [-0.0080, -0.0243, -0.0079,  ..., -0.0201, -0.0240, -0.0208],
        [ 0.0029,  0.0056,  0.0167,  ...,  0.0065, -0.0012, -0.0019],
        [-0.0047, -0.0198, -0.0200,  ...,  0.0153,  0.0093, -0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias': tensor([ 0.9746, -1.5684,  4.0703,  ..., -4.7695,  2.3730,  0.0641],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight': tensor([[-0.0094,  0.0040, -0.0081,  ...,  0.0087,  0.0034, -0.0086],
        [-0.0218, -0.0027,  0.0096,  ...,  0.0072, -0.0114, -0.0138],
        [-0.0069,  0.0196,  0.0128,  ...,  0.0089, -0.0430,  0.0282],
        ...,
        [ 0.0080, -0.0076,  0.0247,  ..., -0.0006,  0.0264, -0.0060],
        [-0.0081,  0.0084,  0.0222,  ...,  0.0080, -0.0070,  0.0124],
        [-0.0113,  0.0073,  0.0137,  ..., -0.0100, -0.0085,  0.0073]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias': tensor([-0.0650, -0.0600,  0.0630,  ..., -0.0726,  0.0070, -0.1204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight': tensor([[ 0.0016,  0.0027, -0.0018,  ...,  0.0349, -0.0049, -0.0009],
        [ 0.0076,  0.0003, -0.0250,  ...,  0.0064,  0.0064,  0.0147],
        [-0.0011, -0.0325, -0.0602,  ...,  0.0003, -0.0238,  0.0107],
        ...,
        [ 0.0233,  0.0226,  0.0270,  ...,  0.0236, -0.0239, -0.0167],
        [ 0.0041, -0.0097, -0.0143,  ..., -0.0173, -0.0098,  0.0124],
        [ 0.0090, -0.0034,  0.0003,  ...,  0.0278,  0.0114,  0.0061]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias': tensor([-0.4348, -0.0033, -0.1771,  ..., -0.0897,  0.1703,  0.3945],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight': tensor([[ 0.0021,  0.0206, -0.0078,  ..., -0.0072, -0.0010,  0.0115],
        [ 0.0005,  0.0042, -0.0142,  ...,  0.0190, -0.0119, -0.0008],
        [ 0.0061, -0.0182,  0.0112,  ..., -0.0376, -0.0023, -0.0042],
        ...,
        [-0.0143,  0.0111, -0.0015,  ..., -0.0087,  0.0175, -0.0019],
        [-0.0039,  0.0022,  0.0231,  ..., -0.0050,  0.0082, -0.0150],
        [ 0.0005, -0.0005, -0.0158,  ..., -0.0120, -0.0067, -0.0141]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias': tensor([-0.0269, -0.0574,  0.0638,  ..., -0.1498,  0.0551, -0.1482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight': tensor([1.5703, 1.8379, 1.9336,  ..., 0.8516, 1.4707, 1.7686],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias': tensor([0.3889, 0.2372, 0.1531,  ..., 0.6260, 0.2163, 0.1549],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight': tensor([[-1.1892e-03,  3.9005e-03, -5.7487e-03,  ...,  4.7989e-03,
         -4.2915e-03, -2.5539e-03],
        [ 1.5236e-02, -2.3232e-03, -3.3325e-02,  ...,  2.3758e-02,
         -1.0595e-03, -3.8986e-03],
        [ 2.0737e-02,  7.2479e-03, -3.0842e-03,  ..., -5.4207e-03,
          2.6047e-02, -1.4210e-03],
        ...,
        [ 7.4120e-03, -2.9163e-03,  3.3661e-02,  ..., -4.4785e-03,
          9.1400e-03, -1.5297e-02],
        [-4.3964e-04,  8.5297e-03, -1.5350e-02,  ..., -1.3519e-02,
         -6.6490e-03,  5.9700e-04],
        [-7.5579e-05,  1.0449e-04,  8.8196e-03,  ..., -1.0658e-02,
         -6.6032e-03, -5.4703e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias': tensor([-0.3184, -0.2345, -0.2834,  ..., -0.2498, -0.1849, -0.2729],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight': tensor([[ 0.0369,  0.0093, -0.0179,  ..., -0.0141, -0.0035,  0.0064],
        [ 0.0050,  0.0101,  0.0117,  ...,  0.0070, -0.0066, -0.0147],
        [-0.0015,  0.0263,  0.0119,  ..., -0.0270,  0.0052, -0.0028],
        ...,
        [ 0.0133,  0.0236, -0.0152,  ...,  0.0251, -0.0268, -0.0321],
        [ 0.0021, -0.0061,  0.0079,  ..., -0.0029,  0.0145, -0.0033],
        [-0.0097,  0.0175, -0.0111,  ..., -0.0278, -0.0016, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias': tensor([-0.1587, -0.0068,  0.1970,  ...,  0.0549, -0.0199,  0.0069],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight': tensor([2.5664, 2.3809, 2.5742,  ..., 1.8262, 2.4121, 2.7520],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias': tensor([ 0.1838,  0.3330, -0.2296,  ..., -0.1086,  0.5938, -0.2812],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight': tensor([[ 0.0305, -0.0035, -0.0098,  ...,  0.0054, -0.0111,  0.0049],
        [-0.0194,  0.0099,  0.0032,  ...,  0.0125,  0.0277, -0.0057],
        [ 0.0115,  0.0072, -0.0170,  ...,  0.0162,  0.0032,  0.0142],
        ...,
        [ 0.0076, -0.0034,  0.0187,  ...,  0.0278, -0.0174, -0.0046],
        [-0.0037, -0.0002,  0.0051,  ..., -0.0108,  0.0012,  0.0065],
        [-0.0047, -0.0013,  0.0154,  ...,  0.0158, -0.0106,  0.0013]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias': tensor([-0.0001,  0.0002, -0.0072,  ...,  0.0011, -0.0007, -0.0008],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight': tensor([[ 0.0221, -0.0052,  0.0127,  ..., -0.0090, -0.0092, -0.0165],
        [-0.0569, -0.0251, -0.0167,  ..., -0.0070, -0.0093, -0.0182],
        [-0.0159, -0.0159,  0.0239,  ...,  0.0133,  0.0071,  0.0088],
        ...,
        [ 0.0025,  0.0141, -0.0087,  ...,  0.0007, -0.0157, -0.0012],
        [ 0.0053,  0.0023, -0.0199,  ...,  0.0264,  0.0148, -0.0300],
        [-0.0040,  0.0095, -0.0180,  ..., -0.0396, -0.0316, -0.0156]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias': tensor([-0.0095, -0.0084,  0.0243,  ...,  0.1217, -0.0273,  0.0116],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight': tensor([[ 1.3329e-02, -5.8022e-03,  2.2945e-03,  ...,  1.0509e-03,
          2.1591e-02, -3.7422e-03],
        [-1.7593e-02,  9.9182e-03,  2.1652e-02,  ..., -1.7380e-02,
         -1.1452e-02, -1.1536e-02],
        [-4.2648e-03,  3.6955e-06,  8.7585e-03,  ...,  5.5428e-03,
          1.0963e-02, -8.2855e-03],
        ...,
        [ 2.6302e-03, -6.2828e-03,  1.8387e-02,  ...,  2.4658e-02,
         -1.4015e-02, -1.8509e-02],
        [-1.9140e-03, -1.3588e-02, -1.2770e-03,  ..., -1.8143e-02,
         -2.0309e-02, -2.0172e-02],
        [-1.6346e-03,  5.2338e-03, -1.7044e-02,  ..., -4.7073e-03,
          1.5930e-02,  1.8097e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias': tensor([ 0.0486, -0.0525, -1.9268,  ...,  0.0309,  0.1466, -0.0662],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight': tensor([[-0.0204,  0.0447, -0.0052,  ...,  0.0069,  0.0077,  0.0218],
        [ 0.0017,  0.0142, -0.0191,  ...,  0.0062, -0.0003,  0.0145],
        [-0.0078,  0.0171, -0.0142,  ..., -0.0220,  0.0106,  0.0089],
        ...,
        [-0.0215, -0.0144, -0.0043,  ...,  0.0026, -0.0030,  0.0222],
        [ 0.0184,  0.0181,  0.0050,  ...,  0.0064, -0.0177,  0.0218],
        [ 0.0176,  0.0081, -0.0153,  ..., -0.0053,  0.0065,  0.0165]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias': tensor([-0.2126,  0.1382,  0.1891,  ...,  0.0073,  0.0610, -0.0497],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight': tensor([1.5518, 1.4453, 1.4551,  ..., 0.8970, 1.4531, 1.5488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias': tensor([-0.0075, -0.0621, -0.0674,  ..., -0.0965, -0.1760, -0.1098],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight': tensor([[ 0.0173, -0.0038, -0.0434,  ..., -0.0142, -0.0269,  0.0163],
        [ 0.0112,  0.0112, -0.0199,  ...,  0.0013,  0.0100, -0.0072],
        [-0.0037, -0.0045, -0.0143,  ..., -0.0011, -0.0073, -0.0100],
        ...,
        [-0.0162, -0.0028, -0.0142,  ...,  0.0240, -0.0207, -0.0169],
        [ 0.0084,  0.0172, -0.0097,  ..., -0.0170, -0.0171, -0.0099],
        [ 0.0414, -0.0024, -0.0073,  ..., -0.0142,  0.0116,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias': tensor([-0.2035, -0.6177, -0.2632,  ..., -0.2837, -0.4905, -0.3960],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight': tensor([[-0.0123, -0.0106,  0.0170,  ..., -0.0074, -0.0057,  0.0038],
        [ 0.0014, -0.0104, -0.0019,  ...,  0.0073,  0.0064, -0.0129],
        [-0.0083, -0.0003,  0.0169,  ...,  0.0021,  0.0054,  0.0217],
        ...,
        [-0.0205, -0.0112, -0.0028,  ..., -0.0033,  0.0101,  0.0241],
        [ 0.0122, -0.0082,  0.0100,  ..., -0.0086,  0.0083, -0.0369],
        [ 0.0042, -0.0036,  0.0006,  ..., -0.0066,  0.0024,  0.0018]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias': tensor([ 0.0215, -0.1328, -0.1233,  ..., -0.1167,  0.0634,  0.0916],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight': tensor([1.6230, 1.6143, 1.6387,  ..., 1.4531, 1.7188, 1.8516],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias': tensor([-0.0200, -0.0892,  0.0742,  ...,  0.0301,  0.1517, -0.2600],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight': tensor([0.9370, 1.0215, 0.9346,  ..., 0.8223, 1.0596, 1.0498],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias': tensor([-0.0060,  0.1511, -0.0550,  ...,  0.2749,  0.0767,  0.0092],
       dtype=torch.float16), 'model.mm_projector.weight': tensor([[ 0.0146, -0.0205,  0.0012,  ..., -0.0031,  0.0012,  0.0303],
        [-0.0171, -0.0206,  0.0222,  ..., -0.0004, -0.0091,  0.0158],
        [-0.0268,  0.0079,  0.0197,  ...,  0.0101, -0.0107, -0.0302],
        ...,
        [-0.0294, -0.0090, -0.0311,  ...,  0.0186,  0.0271,  0.0182],
        [-0.0015,  0.0020, -0.0037,  ..., -0.0047,  0.0262,  0.0250],
        [ 0.0222, -0.0136, -0.0244,  ...,  0.0256, -0.0265,  0.0118]]), 'model.mm_projector.bias': tensor([ 0.0182,  0.0159, -0.0257,  ..., -0.0040, -0.0171,  0.0039]), 'model.perceiver.latents': tensor([[-0.0775,  1.8258,  0.4430,  ...,  1.1632, -0.4815,  0.8964],
        [ 1.0758, -1.8714,  0.3169,  ...,  0.8139, -0.0478, -0.7570],
        [ 1.3009, -0.5558, -1.7875,  ...,  1.4591,  1.2320,  0.2759],
        ...,
        [-0.0673, -0.3394, -0.7632,  ...,  1.9019,  0.1544,  0.4039],
        [ 1.1100,  1.7288,  0.5438,  ..., -0.5245, -0.3141, -0.4610],
        [-0.6055, -0.2925, -0.2452,  ..., -1.7884,  1.3677, -0.5699]]), 'model.perceiver.frame_embs': tensor([[-0.4952, -0.6528, -0.2392,  ..., -0.3496, -0.6231, -0.6526],
        [ 0.4010, -1.1334, -2.0880,  ...,  0.2614, -1.8531,  0.5307],
        [ 0.5009,  1.6081,  0.6591,  ...,  0.5973,  0.6787,  1.6912],
        ...,
        [ 1.2011,  0.1232,  0.3102,  ..., -1.1122, -0.3374,  0.4550],
        [ 0.2832,  1.2080,  1.2561,  ..., -0.7005, -0.1680,  1.0780],
        [-0.1536,  0.4162,  1.7596,  ...,  0.0704,  0.9481,  1.7778]]), 'model.perceiver.media_time_embs': tensor([[[-1.2279,  0.4415, -2.2783,  ..., -0.2120,  0.0848,  0.6382]],

        [[ 2.6330,  1.5134, -2.3619,  ...,  0.4609, -0.3594,  1.7854]],

        [[ 0.4446, -1.5262, -0.1216,  ...,  0.9112,  2.9200,  1.6478]],

        [[ 0.3881,  1.3203,  0.3406,  ..., -0.9854,  0.5857,  1.2511]]]), 'model.perceiver.layers.0.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.to_q.weight': tensor([[-1.4704e-02, -7.5841e-03, -1.3226e-02,  ...,  1.1944e-02,
         -5.0096e-04,  1.3004e-02],
        [-1.3213e-02,  7.6457e-03,  3.3092e-03,  ...,  8.7336e-03,
         -4.1322e-03, -1.2654e-02],
        [ 9.0921e-03, -1.4908e-02, -7.5590e-03,  ...,  1.4404e-02,
          5.2936e-03, -5.9031e-03],
        ...,
        [ 1.4537e-02,  1.3955e-02, -8.4881e-03,  ...,  6.6906e-05,
         -4.4287e-03,  8.6049e-03],
        [-5.0555e-03, -7.5648e-03,  9.2420e-03,  ...,  1.0353e-02,
          2.2643e-03,  2.8368e-03],
        [-6.9711e-03, -1.1335e-02, -1.3385e-02,  ..., -3.8848e-03,
          1.4953e-02, -2.8596e-03]]), 'model.perceiver.layers.0.0.to_kv.weight': tensor([[ 0.0072, -0.0028,  0.0040,  ...,  0.0088,  0.0066,  0.0153],
        [ 0.0008,  0.0149, -0.0065,  ...,  0.0125,  0.0031,  0.0086],
        [ 0.0037,  0.0121, -0.0099,  ...,  0.0023,  0.0109,  0.0040],
        ...,
        [ 0.0064, -0.0141,  0.0035,  ...,  0.0048, -0.0002, -0.0002],
        [-0.0089, -0.0025, -0.0156,  ...,  0.0070, -0.0114, -0.0068],
        [ 0.0119, -0.0155,  0.0046,  ...,  0.0072, -0.0107, -0.0092]]), 'model.perceiver.layers.0.0.to_out.weight': tensor([[ 0.0316,  0.0115,  0.0275,  ..., -0.0350,  0.0143,  0.0150],
        [ 0.0265, -0.0215, -0.0165,  ...,  0.0185, -0.0432,  0.0401],
        [-0.0200,  0.0173, -0.0015,  ...,  0.0319,  0.0090, -0.0159],
        ...,
        [-0.0084,  0.0161,  0.0381,  ...,  0.0303, -0.0387,  0.0255],
        [ 0.0377,  0.0015, -0.0312,  ...,  0.0341,  0.0096,  0.0148],
        [-0.0165,  0.0110, -0.0041,  ...,  0.0141, -0.0375, -0.0407]]), 'model.perceiver.layers.0.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.1.1.weight': tensor([[-0.0155, -0.0133, -0.0096,  ...,  0.0119,  0.0066, -0.0135],
        [-0.0073,  0.0113,  0.0133,  ..., -0.0047, -0.0012, -0.0013],
        [-0.0097,  0.0010, -0.0141,  ..., -0.0002, -0.0002, -0.0007],
        ...,
        [-0.0056,  0.0036,  0.0024,  ..., -0.0110, -0.0128, -0.0138],
        [-0.0089,  0.0038,  0.0029,  ...,  0.0044, -0.0138, -0.0043],
        [ 0.0094,  0.0067, -0.0037,  ...,  0.0001,  0.0073,  0.0111]]), 'model.perceiver.layers.0.1.3.weight': tensor([[-1.6760e-03,  5.5821e-03, -6.9912e-03,  ...,  4.4083e-03,
         -8.8784e-05,  6.9745e-03],
        [-2.1678e-03,  2.6978e-03,  2.2344e-03,  ..., -2.7215e-03,
         -5.1974e-03,  6.1116e-03],
        [ 3.5477e-03,  1.5593e-03, -6.7486e-03,  ...,  2.8843e-03,
          1.3587e-03,  3.6747e-03],
        ...,
        [-2.2269e-04,  1.3429e-03,  6.3803e-03,  ...,  7.4280e-03,
         -1.1823e-04, -3.0294e-03],
        [ 1.5354e-03,  7.3358e-03,  7.0962e-03,  ...,  3.4329e-03,
         -4.3145e-03,  2.4500e-04],
        [ 4.5147e-03, -3.5901e-03, -6.4491e-03,  ...,  2.3434e-03,
          5.9806e-03, -7.1963e-03]]), 'model.perceiver.layers.1.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.to_q.weight': tensor([[ 5.2977e-03, -6.3797e-04,  5.2918e-03,  ...,  6.4116e-03,
          5.9717e-03, -4.3141e-03],
        [-6.3643e-03, -1.9273e-03,  1.2315e-02,  ..., -1.0608e-02,
          1.1195e-02, -3.9472e-03],
        [-1.1227e-02, -9.0232e-05,  5.0526e-03,  ...,  1.0269e-03,
         -5.6981e-03,  1.9962e-03],
        ...,
        [ 9.8655e-03,  7.3824e-03,  3.1934e-03,  ...,  1.1066e-02,
         -9.6723e-03,  8.2727e-03],
        [-9.1320e-03, -2.4084e-03,  9.8141e-03,  ..., -6.2091e-04,
          1.3875e-02,  1.2951e-02],
        [ 9.0434e-03, -8.2465e-03,  9.9489e-03,  ..., -1.5214e-02,
         -2.2942e-04,  3.9039e-03]]), 'model.perceiver.layers.1.0.to_kv.weight': tensor([[-0.0087,  0.0072,  0.0141,  ..., -0.0054,  0.0113, -0.0147],
        [-0.0075,  0.0113, -0.0028,  ..., -0.0104, -0.0064, -0.0009],
        [ 0.0129, -0.0153, -0.0095,  ...,  0.0109,  0.0011, -0.0087],
        ...,
        [-0.0092,  0.0009, -0.0039,  ..., -0.0017,  0.0019, -0.0059],
        [-0.0151, -0.0085, -0.0004,  ...,  0.0089,  0.0095,  0.0009],
        [ 0.0107,  0.0155, -0.0018,  ..., -0.0065,  0.0014, -0.0014]]), 'model.perceiver.layers.1.0.to_out.weight': tensor([[-0.0207, -0.0085, -0.0376,  ...,  0.0427,  0.0052,  0.0208],
        [-0.0231, -0.0279, -0.0428,  ...,  0.0002,  0.0441, -0.0394],
        [ 0.0410, -0.0087, -0.0364,  ...,  0.0290, -0.0097, -0.0112],
        ...,
        [ 0.0011,  0.0259,  0.0421,  ..., -0.0043, -0.0240, -0.0363],
        [ 0.0051, -0.0439, -0.0122,  ...,  0.0253,  0.0068, -0.0048],
        [-0.0199,  0.0323,  0.0027,  ..., -0.0423, -0.0085,  0.0046]]), 'model.perceiver.layers.1.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.1.1.weight': tensor([[ 0.0023,  0.0076, -0.0020,  ..., -0.0089,  0.0155, -0.0043],
        [-0.0043,  0.0114, -0.0075,  ...,  0.0100,  0.0018, -0.0118],
        [ 0.0033,  0.0074,  0.0133,  ..., -0.0015, -0.0051,  0.0063],
        ...,
        [-0.0094, -0.0046, -0.0023,  ..., -0.0010, -0.0053, -0.0140],
        [-0.0091,  0.0142, -0.0035,  ..., -0.0106, -0.0078, -0.0104],
        [-0.0106,  0.0020, -0.0101,  ...,  0.0135, -0.0082, -0.0081]]), 'model.perceiver.layers.1.1.3.weight': tensor([[ 4.0481e-04,  1.1180e-03,  1.7450e-03,  ...,  2.3659e-03,
          5.7099e-03,  7.1664e-03],
        [-7.6730e-03,  7.1088e-03,  2.3916e-03,  ...,  1.0534e-03,
          2.5844e-03,  6.4637e-03],
        [ 5.4178e-03,  2.3467e-03, -6.9069e-03,  ..., -2.1753e-03,
         -3.0188e-03, -6.2153e-03],
        ...,
        [-4.3891e-03, -3.4294e-03,  4.4313e-03,  ..., -3.2541e-04,
         -5.7575e-03,  5.9139e-03],
        [-3.7889e-03,  4.3903e-03,  5.3080e-03,  ..., -1.6239e-05,
         -1.4863e-03,  5.3874e-03],
        [-6.7254e-03, -7.2134e-03, -1.4228e-03,  ..., -5.6506e-03,
         -2.1270e-03,  1.6422e-03]]), 'model.perceiver.layers.2.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.to_q.weight': tensor([[ 0.0141,  0.0037,  0.0005,  ..., -0.0065,  0.0074, -0.0008],
        [-0.0005, -0.0127, -0.0114,  ...,  0.0120,  0.0150, -0.0114],
        [-0.0128,  0.0029,  0.0133,  ...,  0.0051, -0.0102, -0.0148],
        ...,
        [-0.0089,  0.0037,  0.0012,  ..., -0.0144,  0.0107, -0.0122],
        [ 0.0082,  0.0004, -0.0121,  ...,  0.0099, -0.0092,  0.0077],
        [-0.0062,  0.0054, -0.0003,  ...,  0.0034, -0.0107,  0.0119]]), 'model.perceiver.layers.2.0.to_kv.weight': tensor([[-6.8995e-03,  9.6169e-03,  6.7928e-03,  ...,  1.7136e-03,
         -5.5034e-03,  5.3880e-03],
        [-4.6552e-03,  7.7299e-03,  1.0177e-02,  ...,  1.3296e-02,
          9.3844e-03,  2.8301e-03],
        [-5.2352e-03,  2.5611e-03,  3.7998e-03,  ..., -1.1558e-02,
          5.5656e-03,  1.0674e-02],
        ...,
        [-5.7471e-03, -1.2511e-02,  2.8886e-03,  ..., -1.9175e-03,
          1.3816e-02, -1.3354e-02],
        [ 1.3816e-02, -1.3979e-02,  3.8703e-03,  ...,  1.8370e-03,
          8.2351e-03,  7.1101e-03],
        [ 1.3496e-02, -9.1561e-03, -1.6613e-05,  ..., -1.3268e-02,
          1.2763e-02,  7.3536e-03]]), 'model.perceiver.layers.2.0.to_out.weight': tensor([[-0.0115,  0.0207, -0.0411,  ...,  0.0258, -0.0302,  0.0039],
        [ 0.0243,  0.0323, -0.0400,  ...,  0.0346, -0.0223,  0.0206],
        [-0.0209,  0.0384,  0.0040,  ...,  0.0007, -0.0208,  0.0156],
        ...,
        [ 0.0439, -0.0163,  0.0276,  ..., -0.0197,  0.0400, -0.0279],
        [-0.0184, -0.0017, -0.0239,  ..., -0.0120, -0.0317,  0.0107],
        [-0.0123, -0.0163,  0.0003,  ..., -0.0380, -0.0353,  0.0037]]), 'model.perceiver.layers.2.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.1.1.weight': tensor([[-0.0045,  0.0153,  0.0127,  ..., -0.0073, -0.0149,  0.0034],
        [ 0.0111,  0.0082,  0.0056,  ...,  0.0051,  0.0029, -0.0117],
        [-0.0009,  0.0104, -0.0008,  ...,  0.0144,  0.0060,  0.0082],
        ...,
        [-0.0100, -0.0103, -0.0056,  ...,  0.0026, -0.0032,  0.0097],
        [ 0.0062, -0.0063,  0.0032,  ...,  0.0126,  0.0077,  0.0094],
        [ 0.0106, -0.0006, -0.0129,  ..., -0.0107, -0.0114, -0.0108]]), 'model.perceiver.layers.2.1.3.weight': tensor([[-0.0067, -0.0062,  0.0003,  ...,  0.0058, -0.0040,  0.0063],
        [ 0.0029, -0.0066, -0.0041,  ..., -0.0044,  0.0052,  0.0027],
        [ 0.0045,  0.0069,  0.0073,  ..., -0.0005, -0.0059,  0.0027],
        ...,
        [ 0.0008,  0.0078, -0.0054,  ..., -0.0023,  0.0026,  0.0033],
        [-0.0053,  0.0025, -0.0002,  ...,  0.0058,  0.0055, -0.0054],
        [ 0.0077, -0.0008, -0.0004,  ...,  0.0076,  0.0026,  0.0070]]), 'model.perceiver.layers.3.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.to_q.weight': tensor([[ 1.0633e-02, -1.2471e-03, -2.3833e-03,  ..., -7.6105e-03,
         -9.8486e-03,  1.1911e-02],
        [-5.8148e-04,  1.0101e-02,  4.1783e-03,  ..., -2.3154e-03,
         -5.5717e-05, -3.2462e-03],
        [ 1.1174e-02, -1.1500e-02, -3.3345e-03,  ..., -7.5652e-03,
         -1.0056e-02,  8.4344e-03],
        ...,
        [-1.4019e-02,  4.6863e-03, -1.4317e-02,  ...,  1.8775e-04,
          1.3536e-03,  8.7696e-03],
        [-1.0840e-02, -1.2693e-02, -3.3658e-06,  ..., -1.1692e-02,
         -5.3945e-03,  6.5563e-04],
        [-1.0610e-02,  3.1723e-03, -5.1512e-03,  ..., -7.0612e-03,
         -1.5318e-02, -3.6349e-03]]), 'model.perceiver.layers.3.0.to_kv.weight': tensor([[ 0.0121, -0.0023,  0.0139,  ..., -0.0121, -0.0153,  0.0013],
        [-0.0155,  0.0005,  0.0040,  ...,  0.0141,  0.0135,  0.0129],
        [ 0.0060,  0.0114, -0.0036,  ...,  0.0090,  0.0017, -0.0142],
        ...,
        [-0.0095, -0.0040, -0.0077,  ...,  0.0102,  0.0033,  0.0096],
        [-0.0072, -0.0156,  0.0139,  ...,  0.0150,  0.0074,  0.0037],
        [ 0.0083,  0.0019,  0.0090,  ...,  0.0049, -0.0111,  0.0017]]), 'model.perceiver.layers.3.0.to_out.weight': tensor([[-0.0388,  0.0254, -0.0107,  ...,  0.0437,  0.0031, -0.0413],
        [-0.0108,  0.0416,  0.0197,  ..., -0.0157,  0.0063, -0.0218],
        [ 0.0245,  0.0427,  0.0394,  ..., -0.0060,  0.0432,  0.0341],
        ...,
        [ 0.0291,  0.0004, -0.0294,  ..., -0.0307,  0.0112,  0.0052],
        [-0.0280,  0.0166, -0.0101,  ..., -0.0322, -0.0179, -0.0119],
        [-0.0357, -0.0081, -0.0115,  ..., -0.0420, -0.0119, -0.0027]]), 'model.perceiver.layers.3.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.1.1.weight': tensor([[ 0.0063, -0.0104, -0.0050,  ..., -0.0017,  0.0108, -0.0137],
        [ 0.0070, -0.0051,  0.0069,  ..., -0.0105,  0.0009, -0.0075],
        [-0.0114, -0.0082, -0.0022,  ..., -0.0144, -0.0010, -0.0131],
        ...,
        [-0.0046, -0.0014,  0.0041,  ...,  0.0084, -0.0150, -0.0058],
        [ 0.0045, -0.0029, -0.0023,  ...,  0.0146,  0.0038,  0.0033],
        [-0.0035,  0.0011, -0.0057,  ...,  0.0026,  0.0041, -0.0131]]), 'model.perceiver.layers.3.1.3.weight': tensor([[ 7.0668e-03, -3.4410e-03,  6.8712e-03,  ...,  5.1035e-03,
         -1.6844e-03, -4.4956e-03],
        [ 6.3631e-03, -1.2669e-03, -1.0860e-03,  ...,  5.2634e-03,
          6.8032e-03,  1.5526e-03],
        [-2.4784e-03, -7.1736e-03,  5.3887e-03,  ..., -6.5986e-03,
          4.3546e-03, -1.0314e-03],
        ...,
        [-3.6970e-03,  9.0849e-04, -2.2583e-04,  ..., -1.5251e-04,
          2.6071e-05,  3.5888e-03],
        [-4.7207e-04,  7.1302e-03,  3.6978e-03,  ..., -9.8386e-04,
         -7.2296e-03,  6.8818e-04],
        [ 6.3785e-03,  5.9076e-03, -4.7310e-03,  ..., -3.5202e-03,
         -5.1668e-03,  1.2220e-03]]), 'model.perceiver.layers.4.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.to_q.weight': tensor([[ 0.0149, -0.0111,  0.0066,  ...,  0.0013, -0.0081,  0.0028],
        [ 0.0038,  0.0093, -0.0030,  ..., -0.0048,  0.0037,  0.0094],
        [-0.0036, -0.0021,  0.0133,  ..., -0.0055, -0.0129,  0.0140],
        ...,
        [-0.0064,  0.0050, -0.0035,  ..., -0.0048, -0.0017,  0.0139],
        [ 0.0082, -0.0154, -0.0105,  ..., -0.0103, -0.0127,  0.0098],
        [-0.0143,  0.0048, -0.0145,  ..., -0.0127,  0.0124, -0.0056]]), 'model.perceiver.layers.4.0.to_kv.weight': tensor([[-0.0139,  0.0131,  0.0096,  ..., -0.0134, -0.0127, -0.0141],
        [ 0.0092, -0.0136, -0.0085,  ...,  0.0096,  0.0023, -0.0004],
        [ 0.0093,  0.0148,  0.0049,  ..., -0.0065, -0.0143, -0.0023],
        ...,
        [-0.0036,  0.0093,  0.0112,  ...,  0.0003, -0.0151,  0.0087],
        [ 0.0101, -0.0133, -0.0078,  ...,  0.0028,  0.0105, -0.0144],
        [ 0.0107, -0.0011, -0.0049,  ...,  0.0073,  0.0087,  0.0094]]), 'model.perceiver.layers.4.0.to_out.weight': tensor([[-0.0101, -0.0312,  0.0058,  ...,  0.0023,  0.0185,  0.0328],
        [ 0.0084, -0.0214,  0.0081,  ..., -0.0267,  0.0020, -0.0283],
        [ 0.0352,  0.0194, -0.0023,  ...,  0.0147,  0.0241, -0.0107],
        ...,
        [ 0.0403, -0.0388, -0.0334,  ...,  0.0177,  0.0438,  0.0128],
        [-0.0170,  0.0441,  0.0319,  ..., -0.0416,  0.0350,  0.0234],
        [-0.0433,  0.0069, -0.0161,  ..., -0.0098,  0.0012,  0.0103]]), 'model.perceiver.layers.4.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.1.1.weight': tensor([[ 0.0095,  0.0003, -0.0109,  ..., -0.0063,  0.0123, -0.0113],
        [ 0.0037, -0.0052, -0.0120,  ..., -0.0096, -0.0149,  0.0095],
        [ 0.0109, -0.0019,  0.0132,  ..., -0.0133,  0.0015,  0.0116],
        ...,
        [-0.0056, -0.0154, -0.0137,  ...,  0.0022,  0.0138,  0.0137],
        [ 0.0109,  0.0127, -0.0015,  ...,  0.0036,  0.0110, -0.0151],
        [ 0.0096, -0.0144, -0.0055,  ..., -0.0032, -0.0044,  0.0045]]), 'model.perceiver.layers.4.1.3.weight': tensor([[-0.0063, -0.0062, -0.0010,  ...,  0.0032,  0.0033,  0.0006],
        [-0.0003, -0.0042,  0.0004,  ..., -0.0062,  0.0001, -0.0022],
        [-0.0042, -0.0027,  0.0016,  ..., -0.0028, -0.0026, -0.0058],
        ...,
        [-0.0069, -0.0042,  0.0010,  ...,  0.0075, -0.0072,  0.0006],
        [ 0.0019,  0.0072, -0.0012,  ..., -0.0005, -0.0062,  0.0010],
        [ 0.0045,  0.0010, -0.0071,  ..., -0.0032,  0.0069, -0.0057]]), 'model.perceiver.layers.5.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.to_q.weight': tensor([[ 0.0148,  0.0093, -0.0076,  ..., -0.0117,  0.0044, -0.0042],
        [ 0.0129, -0.0007, -0.0148,  ...,  0.0123,  0.0112, -0.0099],
        [ 0.0110, -0.0137,  0.0125,  ..., -0.0076, -0.0116, -0.0052],
        ...,
        [-0.0003, -0.0100,  0.0031,  ...,  0.0128, -0.0017, -0.0097],
        [-0.0022, -0.0088, -0.0081,  ..., -0.0083, -0.0087,  0.0017],
        [ 0.0024,  0.0054, -0.0005,  ...,  0.0073, -0.0120, -0.0089]]), 'model.perceiver.layers.5.0.to_kv.weight': tensor([[-0.0084, -0.0126, -0.0118,  ...,  0.0129, -0.0038, -0.0115],
        [-0.0075,  0.0120,  0.0020,  ...,  0.0036,  0.0124, -0.0051],
        [-0.0016,  0.0075,  0.0024,  ..., -0.0128, -0.0072, -0.0107],
        ...,
        [-0.0068,  0.0135, -0.0008,  ...,  0.0154,  0.0057, -0.0035],
        [-0.0016, -0.0030,  0.0056,  ..., -0.0011, -0.0029, -0.0015],
        [ 0.0028, -0.0047,  0.0105,  ..., -0.0030,  0.0047, -0.0053]]), 'model.perceiver.layers.5.0.to_out.weight': tensor([[ 0.0230,  0.0328,  0.0249,  ..., -0.0209,  0.0256,  0.0237],
        [-0.0263, -0.0026, -0.0365,  ..., -0.0099, -0.0379, -0.0033],
        [ 0.0373,  0.0183, -0.0253,  ..., -0.0226,  0.0072, -0.0368],
        ...,
        [-0.0434,  0.0324, -0.0268,  ..., -0.0065, -0.0209,  0.0064],
        [-0.0194,  0.0385,  0.0116,  ...,  0.0311,  0.0209, -0.0143],
        [ 0.0399, -0.0429, -0.0247,  ...,  0.0310,  0.0332, -0.0270]]), 'model.perceiver.layers.5.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.1.1.weight': tensor([[-0.0036, -0.0070,  0.0133,  ...,  0.0006,  0.0072,  0.0013],
        [-0.0137,  0.0006, -0.0113,  ...,  0.0062, -0.0055,  0.0116],
        [-0.0117,  0.0131, -0.0020,  ..., -0.0057,  0.0155,  0.0140],
        ...,
        [-0.0017,  0.0068,  0.0021,  ...,  0.0156, -0.0059, -0.0085],
        [ 0.0030,  0.0115,  0.0147,  ...,  0.0018, -0.0116,  0.0139],
        [-0.0131, -0.0152,  0.0117,  ...,  0.0033,  0.0150,  0.0019]]), 'model.perceiver.layers.5.1.3.weight': tensor([[-3.3735e-03, -2.4099e-03,  1.1816e-03,  ..., -1.7870e-04,
         -1.9584e-03,  2.5234e-03],
        [-1.0574e-03,  3.8456e-03,  5.2159e-04,  ...,  2.5573e-03,
          5.1845e-03,  5.8910e-03],
        [-3.4836e-03, -3.3110e-03,  3.2490e-03,  ...,  1.2087e-03,
          4.6494e-03, -8.3389e-04],
        ...,
        [-1.6959e-03, -4.6113e-03, -7.5554e-03,  ...,  6.5133e-03,
         -7.3832e-03, -3.8054e-03],
        [ 2.7195e-03, -3.9816e-03, -5.6581e-04,  ..., -5.9048e-03,
         -1.6128e-03,  5.2380e-03],
        [ 4.6749e-03, -5.3607e-04,  3.0658e-05,  ..., -6.4944e-03,
         -7.0124e-03, -4.5391e-03]]), 'model.perceiver.norm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.norm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'lm_head.weight': tensor([[-0.0058, -0.0009, -0.0071,  ...,  0.0035, -0.0099,  0.0190],
        [-0.0278,  0.0547, -0.0115,  ..., -0.0232,  0.0147,  0.0332],
        [-0.0140, -0.0099,  0.0201,  ..., -0.0344,  0.0142, -0.0150],
        ...,
        [-0.0243,  0.0031,  0.0008,  ..., -0.0046,  0.0029, -0.0072],
        [ 0.0070,  0.0007,  0.0051,  ..., -0.0131, -0.0103, -0.0041],
        [-0.0041, -0.0077, -0.0308,  ...,  0.0179,  0.0084,  0.0356]],
       dtype=torch.float16)}
[INFO] Medical save done, finish
[2023-11-15 07:14:29,656] [INFO] [launch.py:347:main] Process 65072 exits successfully.
[2023-11-15 07:14:29,656] [INFO] [launch.py:347:main] Process 65070 exits successfully.
[2023-11-15 07:14:30,658] [INFO] [launch.py:347:main] Process 65068 exits successfully.
[INFO] medical_state_dict: {'model.embed_tokens.weight': tensor([[-0.0013,  0.0004, -0.0018,  ...,  0.0004, -0.0038, -0.0033],
        [ 0.0011, -0.0046, -0.0005,  ..., -0.0079, -0.0010,  0.0003],
        [ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
        ...,
        [-0.0052,  0.0041, -0.0056,  ..., -0.0011,  0.0072,  0.0068],
        [ 0.0075, -0.0039,  0.0058,  ...,  0.0447,  0.0135, -0.0091],
        [-0.0026,  0.0215, -0.0237,  ..., -0.0354,  0.0114,  0.0210]],
       dtype=torch.float16), 'model.layers.0.self_attn.q_proj.weight': tensor([[-9.6512e-03, -1.4015e-02, -1.5736e-03,  ...,  2.1338e-05,
          1.3115e-02, -3.8280e-03],
        [ 2.9144e-02,  4.8027e-03,  5.9013e-03,  ..., -1.3435e-02,
         -8.2550e-03,  1.8204e-02],
        [-1.3481e-02,  1.8463e-02, -3.4637e-03,  ...,  6.7596e-03,
          2.8107e-02, -7.3576e-04],
        ...,
        [ 1.1032e-02,  1.4496e-02, -1.0233e-03,  ..., -2.4509e-03,
         -9.9945e-03,  1.9012e-02],
        [ 2.2018e-02,  9.6817e-03,  3.0251e-03,  ..., -2.1957e-02,
         -2.9984e-02, -1.5228e-02],
        [-4.3945e-03, -3.2215e-03,  2.4204e-03,  ...,  1.5717e-02,
          2.7542e-02, -3.5992e-03]], dtype=torch.float16), 'model.layers.0.self_attn.k_proj.weight': tensor([[-1.8356e-02,  4.0359e-03, -1.2512e-03,  ...,  1.7609e-02,
         -8.6746e-03, -1.4610e-02],
        [ 1.5823e-02,  6.5346e-03,  2.6360e-03,  ..., -1.8021e-02,
          1.6815e-02,  2.4765e-02],
        [ 2.4891e-04, -2.5513e-02,  9.2087e-03,  ...,  1.0544e-02,
         -2.4979e-02, -1.9958e-02],
        ...,
        [ 1.5572e-02,  6.2644e-05,  2.2449e-03,  ..., -7.4625e-04,
          1.9274e-03,  5.2757e-03],
        [-1.0864e-02,  2.2339e-02, -8.3771e-03,  ...,  2.7027e-03,
          1.7319e-02, -7.6866e-03],
        [ 5.8746e-03,  5.1308e-04,  6.3248e-03,  ...,  7.2708e-03,
         -1.2901e-02,  6.5727e-03]], dtype=torch.float16), 'model.layers.0.self_attn.v_proj.weight': tensor([[ 0.0007,  0.0044,  0.0010,  ...,  0.0090,  0.0010,  0.0093],
        [-0.0099, -0.0005, -0.0035,  ..., -0.0119,  0.0113,  0.0107],
        [ 0.0048,  0.0068, -0.0029,  ...,  0.0021, -0.0156, -0.0190],
        ...,
        [-0.0073, -0.0050,  0.0162,  ...,  0.0033,  0.0020, -0.0007],
        [-0.0006,  0.0075, -0.0048,  ...,  0.0051,  0.0155,  0.0017],
        [-0.0032,  0.0046,  0.0082,  ..., -0.0016, -0.0035,  0.0023]],
       dtype=torch.float16), 'model.layers.0.self_attn.o_proj.weight': tensor([[ 1.3628e-03, -3.9444e-03,  3.8643e-03,  ...,  2.2564e-03,
          2.7990e-04, -8.9340e-03],
        [-2.4300e-03,  5.6076e-03,  1.1387e-03,  ..., -1.7481e-03,
          2.0924e-03,  5.7678e-03],
        [-3.3474e-03, -7.6914e-04,  2.4796e-03,  ..., -2.0561e-03,
         -6.5956e-03, -8.0681e-04],
        ...,
        [ 4.8943e-03, -1.4791e-03,  7.6332e-03,  ...,  2.2650e-06,
          4.2534e-03,  3.3951e-03],
        [-2.9583e-03, -1.8663e-03, -1.1358e-03,  ...,  5.2490e-03,
         -5.8899e-03, -2.8267e-03],
        [ 4.0221e-04, -1.2932e-03,  3.3665e-03,  ...,  6.5804e-03,
         -4.6806e-03, -5.0964e-03]], dtype=torch.float16), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0081,  0.0134,  0.0292,  ..., -0.0172,  0.0053,  0.0193],
        [-0.0028, -0.0027,  0.0029,  ...,  0.0147, -0.0076,  0.0114],
        [-0.0002, -0.0256,  0.0180,  ..., -0.0189,  0.0257,  0.0206],
        ...,
        [ 0.0058, -0.0258,  0.0025,  ..., -0.0036, -0.0106,  0.0365],
        [ 0.0223,  0.0168, -0.0171,  ..., -0.0017, -0.0030, -0.0196],
        [-0.0070, -0.0135, -0.0268,  ..., -0.0042,  0.0025, -0.0229]],
       dtype=torch.float16), 'model.layers.0.mlp.up_proj.weight': tensor([[-0.0072, -0.0297,  0.0135,  ..., -0.0198, -0.0236,  0.0091],
        [-0.0119, -0.0311,  0.0110,  ...,  0.0178,  0.0034,  0.0087],
        [-0.0066,  0.0157, -0.0102,  ..., -0.0231,  0.0132,  0.0038],
        ...,
        [-0.0121, -0.0005, -0.0019,  ...,  0.0259, -0.0082,  0.0114],
        [-0.0198,  0.0047,  0.0170,  ..., -0.0023, -0.0186,  0.0037],
        [ 0.0142,  0.0268, -0.0009,  ...,  0.0088, -0.0174, -0.0420]],
       dtype=torch.float16), 'model.layers.0.mlp.down_proj.weight': tensor([[ 0.0044, -0.0123,  0.0141,  ..., -0.0181, -0.0041, -0.0016],
        [-0.0006, -0.0026,  0.0135,  ...,  0.0106, -0.0167,  0.0315],
        [ 0.0044,  0.0371,  0.0019,  ..., -0.0117,  0.0212,  0.0207],
        ...,
        [-0.0078, -0.0106,  0.0062,  ...,  0.0204, -0.0163,  0.0254],
        [-0.0202,  0.0401,  0.0176,  ..., -0.0138, -0.0104, -0.0290],
        [ 0.0179, -0.0031, -0.0126,  ...,  0.0003, -0.0050, -0.0296]],
       dtype=torch.float16), 'model.layers.0.input_layernorm.weight': tensor([ 0.0193,  0.0087, -0.0008,  ...,  0.0058,  0.0089,  0.0019],
       dtype=torch.float16), 'model.layers.0.post_attention_layernorm.weight': tensor([0.0530, 0.0537, 0.0498,  ..., 0.0540, 0.0569, 0.0491],
       dtype=torch.float16), 'model.layers.1.self_attn.q_proj.weight': tensor([[-0.0228, -0.0012, -0.0327,  ..., -0.0147, -0.0572,  0.0403],
        [-0.0012, -0.0125,  0.0112,  ..., -0.0081, -0.0516,  0.0322],
        [ 0.0274,  0.0308,  0.0248,  ..., -0.0133, -0.0764,  0.0221],
        ...,
        [-0.0004,  0.0029,  0.0050,  ..., -0.0099, -0.0020, -0.0116],
        [-0.0018, -0.0048, -0.0055,  ...,  0.0103,  0.0032,  0.0117],
        [ 0.0002,  0.0064,  0.0077,  ..., -0.0088,  0.0019, -0.0165]],
       dtype=torch.float16), 'model.layers.1.self_attn.k_proj.weight': tensor([[-0.0254,  0.0089,  0.0425,  ...,  0.0178,  0.0165, -0.0135],
        [-0.0323,  0.0092, -0.0083,  ..., -0.0091,  0.0150, -0.0595],
        [-0.0262,  0.0288, -0.0696,  ...,  0.0352,  0.0172, -0.0609],
        ...,
        [-0.0149,  0.0229,  0.0028,  ...,  0.0081, -0.0048,  0.0070],
        [ 0.0114, -0.0230, -0.0001,  ..., -0.0092,  0.0033, -0.0068],
        [-0.0111,  0.0184,  0.0055,  ...,  0.0007, -0.0071,  0.0058]],
       dtype=torch.float16), 'model.layers.1.self_attn.v_proj.weight': tensor([[ 6.8245e-03, -4.9133e-03,  1.0071e-03,  ..., -4.8561e-03,
         -2.9144e-02, -2.2125e-02],
        [-5.1346e-03,  4.9515e-03, -3.3360e-03,  ...,  2.7618e-03,
          1.1398e-02,  3.1982e-02],
        [ 3.6736e-03, -1.1612e-02,  8.0032e-03,  ..., -2.2590e-05,
         -1.4648e-03, -3.3340e-03],
        ...,
        [-3.6926e-03,  5.3062e-03,  7.3509e-03,  ..., -2.7981e-03,
         -1.4305e-03,  2.2399e-04],
        [-7.8735e-03, -3.1986e-03,  7.9422e-03,  ..., -6.5727e-03,
          8.4534e-03, -5.7817e-06],
        [ 1.0643e-03,  6.4468e-03,  8.0719e-03,  ..., -6.3095e-03,
         -2.6455e-03,  1.0246e-02]], dtype=torch.float16), 'model.layers.1.self_attn.o_proj.weight': tensor([[ 0.0024, -0.0163,  0.0091,  ..., -0.0058, -0.0015, -0.0006],
        [-0.0016, -0.0059, -0.0052,  ...,  0.0035, -0.0019,  0.0037],
        [ 0.0247,  0.0128, -0.0125,  ...,  0.0022, -0.0027,  0.0011],
        ...,
        [ 0.0058,  0.0022,  0.0012,  ..., -0.0011, -0.0004, -0.0001],
        [ 0.0036, -0.0075,  0.0050,  ..., -0.0054,  0.0002,  0.0056],
        [-0.0017, -0.0238,  0.0015,  ..., -0.0021, -0.0055,  0.0007]],
       dtype=torch.float16), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0305, -0.0128,  0.0422,  ..., -0.0312, -0.0152, -0.0100],
        [-0.0312, -0.0045, -0.0312,  ...,  0.0140, -0.0307, -0.0427],
        [-0.0055, -0.0319,  0.0095,  ..., -0.0064, -0.0123, -0.0204],
        ...,
        [-0.0385,  0.0105, -0.0028,  ..., -0.0023,  0.0122,  0.0004],
        [-0.0149, -0.0031, -0.0339,  ...,  0.0217,  0.0198, -0.0084],
        [-0.0266,  0.0121,  0.0041,  ...,  0.0391,  0.0065, -0.0430]],
       dtype=torch.float16), 'model.layers.1.mlp.up_proj.weight': tensor([[-0.0034,  0.0414, -0.0204,  ...,  0.0118,  0.0263, -0.0124],
        [ 0.0071, -0.0067, -0.0129,  ..., -0.0086,  0.0069,  0.0108],
        [ 0.0309, -0.0436,  0.0134,  ...,  0.0177, -0.0427,  0.0297],
        ...,
        [-0.0148, -0.0275,  0.0184,  ...,  0.0293,  0.0069, -0.0238],
        [ 0.0356,  0.0030, -0.0164,  ...,  0.0032, -0.0060, -0.0045],
        [-0.0108, -0.0150, -0.0105,  ..., -0.0249, -0.0061,  0.0173]],
       dtype=torch.float16), 'model.layers.1.mlp.down_proj.weight': tensor([[ 0.0107,  0.0179,  0.0578,  ..., -0.0177,  0.0072, -0.0210],
        [ 0.0088,  0.0063, -0.0363,  ...,  0.0069, -0.0142,  0.0028],
        [-0.0113, -0.0138, -0.0245,  ...,  0.0014, -0.0134,  0.0023],
        ...,
        [-0.0099, -0.0073, -0.0143,  ...,  0.0442, -0.0065,  0.0090],
        [-0.0116,  0.0203,  0.0101,  ..., -0.0278, -0.0228,  0.0261],
        [ 0.0262, -0.0061, -0.0175,  ..., -0.0080, -0.0135,  0.0338]],
       dtype=torch.float16), 'model.layers.1.input_layernorm.weight': tensor([0.1050, 0.0967, 0.0884,  ..., 0.0518, 0.0781, 0.0608],
       dtype=torch.float16), 'model.layers.1.post_attention_layernorm.weight': tensor([0.0986, 0.0991, 0.0957,  ..., 0.1060, 0.1006, 0.1001],
       dtype=torch.float16), 'model.layers.2.self_attn.q_proj.weight': tensor([[-0.0236, -0.0038,  0.0098,  ..., -0.0133, -0.0098, -0.0003],
        [-0.0190,  0.0037, -0.0345,  ..., -0.0344, -0.0162,  0.0232],
        [-0.0165,  0.0366, -0.0252,  ..., -0.0018, -0.0211,  0.0159],
        ...,
        [-0.0526,  0.0145, -0.0261,  ..., -0.0085, -0.0328, -0.0351],
        [ 0.0019, -0.0063,  0.0003,  ..., -0.0023, -0.0186,  0.0160],
        [-0.0048, -0.0168,  0.0231,  ...,  0.0604, -0.0444,  0.0058]],
       dtype=torch.float16), 'model.layers.2.self_attn.k_proj.weight': tensor([[ 0.0004,  0.0156, -0.0085,  ..., -0.0106, -0.0010,  0.0175],
        [ 0.0163, -0.0154, -0.0090,  ...,  0.0110, -0.0093, -0.0075],
        [ 0.0128,  0.0151,  0.0360,  ..., -0.0084,  0.0124,  0.0131],
        ...,
        [ 0.0299,  0.0465, -0.0237,  ...,  0.0386, -0.0369,  0.0006],
        [-0.0072, -0.0126, -0.0009,  ...,  0.0045,  0.0003, -0.0041],
        [ 0.0020, -0.0215, -0.0021,  ..., -0.0809, -0.0249,  0.0965]],
       dtype=torch.float16), 'model.layers.2.self_attn.v_proj.weight': tensor([[-7.3767e-04,  6.2332e-03,  1.5961e-02,  ...,  3.8208e-02,
         -3.6240e-03, -6.9313e-03],
        [ 5.0621e-03,  1.1269e-02, -2.1118e-02,  ..., -7.7972e-03,
          7.8506e-03, -1.4595e-02],
        [-6.8617e-04,  1.8463e-02,  3.3112e-03,  ..., -2.0950e-02,
         -3.0457e-02, -2.9480e-02],
        ...,
        [-5.3465e-05, -2.5360e-02, -2.0248e-02,  ..., -1.0956e-02,
         -9.5272e-04,  3.3970e-03],
        [-3.7140e-02, -7.9775e-04,  1.4175e-02,  ..., -1.0040e-02,
         -6.6071e-03, -1.5135e-03],
        [-1.1009e-02,  1.4809e-02,  4.5662e-03,  ..., -5.1880e-03,
          1.8234e-02, -7.3395e-03]], dtype=torch.float16), 'model.layers.2.self_attn.o_proj.weight': tensor([[ 0.0041,  0.0149,  0.0103,  ...,  0.0196,  0.0020, -0.0260],
        [ 0.0006, -0.0130,  0.0079,  ...,  0.0049, -0.0125, -0.0198],
        [-0.0215,  0.0032, -0.0169,  ..., -0.0224, -0.0103,  0.0078],
        ...,
        [-0.0046, -0.0235,  0.0281,  ..., -0.0049, -0.0220,  0.0198],
        [ 0.0184, -0.0113,  0.0301,  ...,  0.0192, -0.0004, -0.0239],
        [-0.0107,  0.0023,  0.0075,  ..., -0.0129,  0.0050, -0.0142]],
       dtype=torch.float16), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0072,  0.0239, -0.0107,  ..., -0.0090,  0.0302, -0.0034],
        [ 0.0013,  0.0012, -0.0015,  ...,  0.0126, -0.0138, -0.0115],
        [-0.0069, -0.0083,  0.0255,  ..., -0.0112,  0.0158,  0.0069],
        ...,
        [ 0.0342, -0.0119, -0.0193,  ..., -0.0285, -0.0400, -0.0150],
        [-0.0113, -0.0116, -0.0017,  ...,  0.0174, -0.0425,  0.0180],
        [-0.0015,  0.0111,  0.0085,  ..., -0.0133, -0.0261,  0.0048]],
       dtype=torch.float16), 'model.layers.2.mlp.up_proj.weight': tensor([[-0.0008, -0.0006,  0.0139,  ..., -0.0152,  0.0090, -0.0034],
        [ 0.0053, -0.0186, -0.0090,  ...,  0.0056,  0.0114,  0.0062],
        [ 0.0306,  0.0189,  0.0293,  ..., -0.0141, -0.0088,  0.0175],
        ...,
        [-0.0071, -0.0148,  0.0009,  ..., -0.0116, -0.0025,  0.0209],
        [ 0.0155, -0.0129,  0.0144,  ...,  0.0003,  0.0049, -0.0228],
        [-0.0146, -0.0302, -0.0243,  ..., -0.0050,  0.0011, -0.0050]],
       dtype=torch.float16), 'model.layers.2.mlp.down_proj.weight': tensor([[ 0.0146,  0.0174,  0.0375,  ..., -0.0273, -0.0011, -0.0335],
        [ 0.0209, -0.0227, -0.0188,  ...,  0.0180,  0.0023, -0.0226],
        [ 0.0438, -0.0178,  0.0010,  ..., -0.0302,  0.0004, -0.0330],
        ...,
        [-0.0133,  0.0283, -0.0105,  ..., -0.0015, -0.0013, -0.0135],
        [-0.0211,  0.0298,  0.0079,  ...,  0.0158, -0.0182, -0.0113],
        [ 0.0315,  0.0117, -0.0220,  ...,  0.0192, -0.0449, -0.0119]],
       dtype=torch.float16), 'model.layers.2.input_layernorm.weight': tensor([0.1729, 0.1787, 0.1709,  ..., 0.1768, 0.1680, 0.1748],
       dtype=torch.float16), 'model.layers.2.post_attention_layernorm.weight': tensor([0.1338, 0.1377, 0.1367,  ..., 0.1367, 0.1387, 0.1367],
       dtype=torch.float16), 'model.layers.3.self_attn.q_proj.weight': tensor([[ 0.0001,  0.0111,  0.0058,  ...,  0.0241,  0.0127,  0.0220],
        [-0.0121,  0.0172, -0.0149,  ..., -0.0432,  0.0006, -0.0074],
        [ 0.0129,  0.0027, -0.0203,  ...,  0.0116, -0.0187, -0.0406],
        ...,
        [ 0.0717, -0.0696,  0.0428,  ..., -0.0779, -0.0139,  0.0070],
        [-0.0797,  0.0404, -0.0023,  ...,  0.0363,  0.0769,  0.0251],
        [-0.0153, -0.0497,  0.0779,  ..., -0.0225, -0.0032, -0.0130]],
       dtype=torch.float16), 'model.layers.3.self_attn.k_proj.weight': tensor([[ 0.0074, -0.0077, -0.0088,  ..., -0.0140,  0.0067,  0.0404],
        [-0.0116,  0.0102, -0.0252,  ...,  0.0031, -0.0150, -0.0390],
        [ 0.0029, -0.0079,  0.0005,  ...,  0.0074, -0.0090, -0.0374],
        ...,
        [ 0.0884, -0.0848,  0.0065,  ..., -0.0621,  0.0024,  0.0343],
        [-0.0830,  0.0328,  0.0418,  ...,  0.0079,  0.0463, -0.0032],
        [ 0.0020, -0.0524,  0.0955,  ..., -0.0163,  0.0029, -0.0172]],
       dtype=torch.float16), 'model.layers.3.self_attn.v_proj.weight': tensor([[-0.0039,  0.0125, -0.0059,  ..., -0.0148,  0.0063, -0.0150],
        [-0.0113,  0.0269, -0.0179,  ..., -0.0122, -0.0101, -0.0094],
        [ 0.0024, -0.0062,  0.0057,  ..., -0.0406, -0.0087, -0.0281],
        ...,
        [-0.0131, -0.0097, -0.0019,  ...,  0.0023, -0.0041, -0.0064],
        [ 0.0055, -0.0019,  0.0020,  ...,  0.0007, -0.0084,  0.0018],
        [-0.0120, -0.0069,  0.0093,  ..., -0.0012, -0.0018,  0.0084]],
       dtype=torch.float16), 'model.layers.3.self_attn.o_proj.weight': tensor([[-2.7054e-02,  5.7945e-03, -1.2451e-02,  ...,  2.7256e-03,
         -1.1616e-03, -2.2335e-03],
        [ 2.4536e-02, -2.4429e-02, -1.0193e-02,  ...,  6.5651e-03,
         -2.5272e-03, -2.3193e-03],
        [-3.7498e-03, -1.3260e-02,  1.9197e-03,  ...,  2.6493e-03,
          3.3932e-03,  8.3084e-03],
        ...,
        [ 1.1963e-02,  1.3344e-02,  1.3680e-02,  ...,  1.3313e-03,
          7.1793e-03,  9.9335e-03],
        [ 1.7960e-02,  2.6199e-02,  2.9206e-06,  ...,  3.6945e-03,
         -1.1940e-03, -2.8419e-03],
        [ 8.5297e-03, -9.2773e-03,  1.0519e-03,  ..., -6.4993e-04,
          5.8823e-03,  1.0956e-02]], dtype=torch.float16), 'model.layers.3.mlp.gate_proj.weight': tensor([[ 0.0009, -0.0099, -0.0182,  ..., -0.0315,  0.0460,  0.0153],
        [ 0.0189,  0.0017, -0.0123,  ..., -0.0025, -0.0261, -0.0161],
        [-0.0253,  0.0021, -0.0174,  ...,  0.0050, -0.0040, -0.0361],
        ...,
        [-0.0003,  0.0394,  0.0065,  ...,  0.0199, -0.0123, -0.0001],
        [-0.0057,  0.0087, -0.0060,  ...,  0.0003, -0.0041, -0.0112],
        [-0.0025, -0.0155,  0.0031,  ...,  0.0264, -0.0254,  0.0148]],
       dtype=torch.float16), 'model.layers.3.mlp.up_proj.weight': tensor([[-0.0160,  0.0154,  0.0104,  ...,  0.0014,  0.0186, -0.0085],
        [-0.0123, -0.0174,  0.0343,  ...,  0.0175,  0.0141, -0.0052],
        [-0.0005, -0.0031, -0.0144,  ..., -0.0012,  0.0091, -0.0125],
        ...,
        [-0.0042, -0.0016, -0.0006,  ...,  0.0215,  0.0084, -0.0228],
        [ 0.0052, -0.0099, -0.0050,  ...,  0.0113, -0.0249, -0.0080],
        [ 0.0486, -0.0004, -0.0031,  ...,  0.0433,  0.0057,  0.0085]],
       dtype=torch.float16), 'model.layers.3.mlp.down_proj.weight': tensor([[ 0.0014, -0.0079, -0.0008,  ..., -0.0033,  0.0087,  0.0142],
        [ 0.0225,  0.0028,  0.0088,  ..., -0.0140, -0.0148, -0.0148],
        [ 0.0144,  0.0119, -0.0174,  ..., -0.0200, -0.0066,  0.0060],
        ...,
        [ 0.0280, -0.0107, -0.0166,  ...,  0.0040,  0.0193,  0.0221],
        [-0.0217,  0.0099, -0.0106,  ..., -0.0006, -0.0170,  0.0130],
        [ 0.0110, -0.0169, -0.0266,  ...,  0.0033,  0.0121,  0.0063]],
       dtype=torch.float16), 'model.layers.3.input_layernorm.weight': tensor([0.2852, 0.2852, 0.2832,  ..., 0.2812, 0.2910, 0.2969],
       dtype=torch.float16), 'model.layers.3.post_attention_layernorm.weight': tensor([0.1738, 0.1748, 0.1689,  ..., 0.1719, 0.1719, 0.1758],
       dtype=torch.float16), 'model.layers.4.self_attn.q_proj.weight': tensor([[-0.0206, -0.0058,  0.0019,  ..., -0.0113, -0.0038,  0.0106],
        [ 0.0190, -0.0170, -0.0051,  ...,  0.0039, -0.0259, -0.0004],
        [-0.0124, -0.0312,  0.0122,  ..., -0.0027, -0.0195, -0.0239],
        ...,
        [ 0.0246,  0.0004, -0.0039,  ...,  0.0032,  0.0244, -0.0600],
        [-0.0293,  0.0085,  0.0295,  ..., -0.0561,  0.0037,  0.0337],
        [-0.0074, -0.0351,  0.0680,  ...,  0.0638,  0.0376, -0.0406]],
       dtype=torch.float16), 'model.layers.4.self_attn.k_proj.weight': tensor([[-0.0037,  0.0210, -0.0139,  ..., -0.0044,  0.0025, -0.0019],
        [-0.0307, -0.0041, -0.0032,  ..., -0.0014,  0.0142, -0.0028],
        [ 0.0089, -0.0021, -0.0143,  ...,  0.0076,  0.0189,  0.0352],
        ...,
        [-0.0089,  0.1188,  0.0593,  ...,  0.0388, -0.0216, -0.0060],
        [ 0.0320,  0.0533, -0.0162,  ...,  0.0641, -0.0399,  0.0720],
        [ 0.0100,  0.0640,  0.0195,  ..., -0.0011,  0.0424, -0.0209]],
       dtype=torch.float16), 'model.layers.4.self_attn.v_proj.weight': tensor([[-3.6507e-03, -8.4000e-03,  1.2493e-03,  ..., -6.4735e-03,
         -3.6030e-03, -6.0320e-05],
        [-1.4557e-02,  3.6133e-02,  5.1346e-03,  ...,  3.2978e-03,
          1.1721e-03,  2.7237e-03],
        [ 1.0719e-02, -6.2370e-03, -3.4729e-02,  ...,  5.4436e-03,
         -1.3771e-03, -1.8631e-02],
        ...,
        [-3.3283e-03, -8.3771e-03, -2.2263e-02,  ..., -9.6893e-03,
         -1.1740e-03,  3.3360e-03],
        [-2.0599e-03, -1.0277e-02, -1.9855e-03,  ...,  7.9956e-03,
         -1.5678e-03,  4.0550e-03],
        [-2.6131e-04, -1.7914e-02, -3.6087e-03,  ..., -5.3263e-04,
         -5.2681e-03,  1.1940e-02]], dtype=torch.float16), 'model.layers.4.self_attn.o_proj.weight': tensor([[ 0.0270,  0.0083, -0.0050,  ..., -0.0021, -0.0267, -0.0015],
        [ 0.0075, -0.0009, -0.0082,  ...,  0.0017, -0.0215,  0.0036],
        [-0.0045,  0.0041, -0.0073,  ..., -0.0134,  0.0101, -0.0084],
        ...,
        [-0.0148,  0.0272, -0.0037,  ..., -0.0209,  0.0081, -0.0208],
        [ 0.0033, -0.0025, -0.0150,  ..., -0.0094, -0.0004, -0.0059],
        [ 0.0100,  0.0215, -0.0056,  ..., -0.0007,  0.0051,  0.0010]],
       dtype=torch.float16), 'model.layers.4.mlp.gate_proj.weight': tensor([[-0.0053,  0.0065, -0.0110,  ..., -0.0182, -0.0035, -0.0159],
        [-0.0267,  0.0111,  0.0142,  ...,  0.0066,  0.0154, -0.0106],
        [-0.0136, -0.0220, -0.0006,  ...,  0.0055, -0.0028,  0.0260],
        ...,
        [ 0.0008, -0.0025,  0.0095,  ..., -0.0211,  0.0097, -0.0120],
        [-0.0265,  0.0148, -0.0281,  ...,  0.0098,  0.0180, -0.0102],
        [ 0.0017, -0.0143, -0.0135,  ..., -0.0124,  0.0221,  0.0190]],
       dtype=torch.float16), 'model.layers.4.mlp.up_proj.weight': tensor([[-1.6373e-02, -5.6725e-03, -4.0833e-02,  ...,  8.6670e-03,
         -8.2254e-04, -5.4932e-03],
        [-2.2400e-02, -4.0680e-02,  5.3253e-03,  ..., -8.6517e-03,
          9.8953e-03, -2.4872e-02],
        [-1.2989e-03,  2.9587e-02,  7.5042e-05,  ..., -2.8885e-02,
         -1.1322e-02,  8.4839e-03],
        ...,
        [-8.8882e-03, -3.1769e-02, -7.3433e-03,  ...,  1.2138e-02,
         -6.8016e-03,  5.5023e-02],
        [ 1.2787e-02, -1.0330e-02, -1.5060e-02,  ..., -4.2175e-02,
         -1.6281e-02,  9.5596e-03],
        [ 3.7937e-03,  1.3062e-02,  8.8272e-03,  ...,  3.7594e-03,
         -3.4237e-03, -2.4376e-03]], dtype=torch.float16), 'model.layers.4.mlp.down_proj.weight': tensor([[ 2.3834e-02, -4.2458e-03,  2.3529e-02,  ..., -1.9836e-02,
         -8.3983e-05,  2.9861e-02],
        [-5.7335e-03, -4.8859e-02,  4.5746e-02,  ..., -2.4323e-02,
         -2.1210e-02, -7.2365e-03],
        [-2.9135e-04, -2.7969e-02,  1.6556e-02,  ...,  1.1406e-02,
         -2.8000e-03,  2.2263e-02],
        ...,
        [-3.4393e-02, -1.9779e-03, -9.8801e-03,  ...,  2.4658e-02,
          2.1534e-03,  1.5030e-02],
        [-7.8430e-03,  1.8177e-03, -2.0020e-02,  ...,  1.2718e-02,
         -4.1931e-02, -1.1818e-02],
        [ 1.6479e-02, -3.2135e-02, -1.5076e-02,  ..., -3.5000e-03,
         -4.4739e-02, -2.3956e-02]], dtype=torch.float16), 'model.layers.4.input_layernorm.weight': tensor([0.2617, 0.2676, 0.2617,  ..., 0.2578, 0.2656, 0.2734],
       dtype=torch.float16), 'model.layers.4.post_attention_layernorm.weight': tensor([0.1914, 0.1895, 0.1855,  ..., 0.1904, 0.1885, 0.1895],
       dtype=torch.float16), 'model.layers.5.self_attn.q_proj.weight': tensor([[-0.0089, -0.0005, -0.0254,  ..., -0.0074, -0.0164,  0.0120],
        [-0.0202,  0.0197,  0.0401,  ..., -0.0054, -0.0094, -0.0347],
        [ 0.0045,  0.0043, -0.0135,  ...,  0.0205, -0.0172,  0.0105],
        ...,
        [-0.0121,  0.0095, -0.0033,  ...,  0.0542,  0.0104,  0.0356],
        [ 0.0433,  0.0046,  0.0262,  ..., -0.0415, -0.0351, -0.0303],
        [ 0.0103,  0.0194,  0.0370,  ..., -0.0282, -0.0147, -0.0007]],
       dtype=torch.float16), 'model.layers.5.self_attn.k_proj.weight': tensor([[-0.0049,  0.0373,  0.0067,  ...,  0.0198, -0.0056, -0.0016],
        [ 0.0006,  0.0027, -0.0324,  ...,  0.0231, -0.0123,  0.0318],
        [-0.0116, -0.0233,  0.0013,  ...,  0.0026, -0.0059,  0.0032],
        ...,
        [ 0.0031, -0.0016, -0.0228,  ...,  0.0397,  0.0098, -0.0320],
        [ 0.0524,  0.0166, -0.0242,  ..., -0.0012, -0.0159, -0.0361],
        [-0.0242, -0.0217,  0.0421,  ..., -0.0155, -0.0347,  0.0102]],
       dtype=torch.float16), 'model.layers.5.self_attn.v_proj.weight': tensor([[-3.0975e-02,  6.6643e-03,  9.8114e-03,  ...,  2.2919e-02,
          7.3671e-05,  2.3392e-02],
        [ 3.9635e-03,  1.0124e-02, -1.8448e-02,  ..., -1.1353e-02,
          3.7670e-03, -1.3893e-02],
        [ 2.2354e-02,  2.4128e-03, -2.9063e-04,  ..., -2.4063e-02,
          2.8976e-02,  1.1208e-02],
        ...,
        [ 2.0477e-02,  1.1581e-02,  1.0353e-02,  ...,  3.7048e-02,
         -5.7449e-03,  1.1454e-03],
        [-5.3596e-03,  3.0289e-03, -4.7684e-03,  ...,  9.9945e-04,
         -9.2010e-03,  8.7404e-04],
        [-1.2375e-02, -6.2561e-03,  2.1561e-02,  ..., -9.5673e-03,
         -9.2545e-03, -1.5900e-02]], dtype=torch.float16), 'model.layers.5.self_attn.o_proj.weight': tensor([[-0.0155, -0.0091,  0.0050,  ..., -0.0181, -0.0074,  0.0271],
        [ 0.0017,  0.0016, -0.0094,  ..., -0.0182,  0.0043,  0.0034],
        [-0.0014, -0.0026,  0.0131,  ...,  0.0181,  0.0119,  0.0234],
        ...,
        [ 0.0181,  0.0066, -0.0060,  ...,  0.0162,  0.0306, -0.0247],
        [-0.0016,  0.0017, -0.0038,  ..., -0.0184, -0.0139, -0.0013],
        [ 0.0051,  0.0035, -0.0148,  ..., -0.0011, -0.0060, -0.0158]],
       dtype=torch.float16), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0002, -0.0082, -0.0302,  ...,  0.0003, -0.0062, -0.0114],
        [ 0.0216, -0.0073, -0.0212,  ...,  0.0374, -0.0015,  0.0022],
        [ 0.0123,  0.0039, -0.0196,  ...,  0.0148,  0.0164, -0.0348],
        ...,
        [ 0.0065,  0.0096,  0.0416,  ..., -0.0671,  0.0157, -0.0199],
        [-0.0280,  0.0043,  0.0038,  ...,  0.0014,  0.0170, -0.0017],
        [ 0.0282, -0.0299, -0.0141,  ..., -0.0040, -0.0043, -0.0409]],
       dtype=torch.float16), 'model.layers.5.mlp.up_proj.weight': tensor([[-0.0063, -0.0135, -0.0069,  ..., -0.0147,  0.0037, -0.0168],
        [-0.0320, -0.0062,  0.0009,  ...,  0.0124,  0.0182,  0.0228],
        [-0.0019,  0.0090,  0.0094,  ...,  0.0040,  0.0080,  0.0185],
        ...,
        [ 0.0077,  0.0239, -0.0076,  ..., -0.0109,  0.0145,  0.0252],
        [ 0.0447, -0.0130, -0.0292,  ..., -0.0080, -0.0179,  0.0240],
        [ 0.0085,  0.0172,  0.0130,  ..., -0.0103, -0.0041, -0.0160]],
       dtype=torch.float16), 'model.layers.5.mlp.down_proj.weight': tensor([[-0.0074, -0.0270, -0.0031,  ...,  0.0008,  0.0067,  0.0141],
        [-0.0113,  0.0156,  0.0281,  ...,  0.0215,  0.0064, -0.0341],
        [ 0.0131,  0.0207,  0.0143,  ..., -0.0241, -0.0463,  0.0110],
        ...,
        [ 0.0110, -0.0240, -0.0051,  ...,  0.0063, -0.0257, -0.0186],
        [-0.0034, -0.0391,  0.0152,  ...,  0.0161,  0.0156, -0.0515],
        [ 0.0212,  0.0142, -0.0118,  ...,  0.0309,  0.0092, -0.0177]],
       dtype=torch.float16), 'model.layers.5.input_layernorm.weight': tensor([0.2617, 0.2695, 0.2637,  ..., 0.2500, 0.2695, 0.2676],
       dtype=torch.float16), 'model.layers.5.post_attention_layernorm.weight': tensor([0.2090, 0.1953, 0.1934,  ..., 0.2051, 0.2021, 0.2051],
       dtype=torch.float16), 'model.layers.6.self_attn.q_proj.weight': tensor([[-9.7351e-03, -1.1505e-02,  6.6071e-03,  ..., -3.3630e-02,
         -6.4468e-03, -4.9515e-03],
        [ 4.4250e-03, -6.5613e-03,  5.6343e-03,  ...,  1.4587e-02,
          3.5286e-03, -3.1464e-02],
        [-1.7654e-02,  2.4216e-02, -3.8513e-02,  ...,  3.0502e-02,
         -4.8431e-02, -3.2272e-03],
        ...,
        [ 1.2878e-02,  9.0103e-03, -3.7628e-02,  ...,  2.3987e-02,
          2.7657e-03,  1.5497e-03],
        [ 3.5614e-02,  3.2532e-02,  5.3329e-03,  ..., -9.7885e-03,
         -9.6497e-02, -2.0844e-02],
        [-6.3538e-02, -5.3558e-02, -4.8697e-05,  ...,  1.7288e-02,
          5.1155e-03,  8.5220e-03]], dtype=torch.float16), 'model.layers.6.self_attn.k_proj.weight': tensor([[ 0.0139, -0.0106,  0.0204,  ..., -0.0071,  0.0222,  0.0589],
        [-0.0198, -0.0036,  0.0422,  ...,  0.0071, -0.0126,  0.0158],
        [-0.0102, -0.0131, -0.0068,  ..., -0.0006, -0.0307, -0.0107],
        ...,
        [ 0.0214, -0.0376, -0.0183,  ...,  0.0607, -0.0023, -0.0482],
        [-0.0199,  0.0045, -0.0262,  ..., -0.0461, -0.0408,  0.0156],
        [-0.0544, -0.0241, -0.0399,  ...,  0.0161, -0.0420, -0.0188]],
       dtype=torch.float16), 'model.layers.6.self_attn.v_proj.weight': tensor([[ 0.0140,  0.0336,  0.0101,  ...,  0.0127, -0.0017,  0.0078],
        [ 0.0381, -0.0063, -0.0095,  ...,  0.0046, -0.0005,  0.0038],
        [-0.0079, -0.0024,  0.0124,  ...,  0.0101,  0.0240,  0.0046],
        ...,
        [-0.0221, -0.0061,  0.0052,  ...,  0.0010, -0.0165,  0.0085],
        [-0.0243, -0.0088, -0.0003,  ..., -0.0012, -0.0083,  0.0198],
        [ 0.0311,  0.0049,  0.0161,  ..., -0.0222,  0.0005, -0.0030]],
       dtype=torch.float16), 'model.layers.6.self_attn.o_proj.weight': tensor([[ 0.0112, -0.0127, -0.0365,  ..., -0.0135,  0.0086,  0.0113],
        [-0.0260,  0.0067, -0.0001,  ..., -0.0224,  0.0014, -0.0022],
        [ 0.0019, -0.0115, -0.0042,  ...,  0.0106,  0.0079,  0.0094],
        ...,
        [-0.0053, -0.0143, -0.0063,  ...,  0.0074, -0.0062,  0.0256],
        [-0.0204,  0.0092, -0.0014,  ..., -0.0024,  0.0081, -0.0214],
        [-0.0201, -0.0129,  0.0079,  ..., -0.0237,  0.0066,  0.0064]],
       dtype=torch.float16), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0222,  0.0260, -0.0189,  ..., -0.0039, -0.0074, -0.0042],
        [ 0.0321,  0.0016, -0.0231,  ...,  0.0066,  0.0205,  0.0123],
        [-0.0146,  0.0217, -0.0156,  ..., -0.0187,  0.0011,  0.0088],
        ...,
        [ 0.0056, -0.0261,  0.0048,  ...,  0.0091, -0.0184, -0.0066],
        [ 0.0083,  0.0047, -0.0169,  ..., -0.0235, -0.0025, -0.0016],
        [-0.0396, -0.0513,  0.0267,  ..., -0.0413, -0.0027,  0.0164]],
       dtype=torch.float16), 'model.layers.6.mlp.up_proj.weight': tensor([[-0.0147, -0.0145, -0.0228,  ...,  0.0067, -0.0053, -0.0105],
        [ 0.0071, -0.0485,  0.0392,  ...,  0.0123,  0.0003, -0.0055],
        [-0.0220, -0.0162, -0.0241,  ...,  0.0055,  0.0135,  0.0216],
        ...,
        [-0.0267,  0.0002,  0.0167,  ...,  0.0149, -0.0019,  0.0385],
        [ 0.0244,  0.0173, -0.0063,  ..., -0.0283,  0.0101,  0.0017],
        [-0.0249,  0.0287, -0.0220,  ...,  0.0081, -0.0178, -0.0498]],
       dtype=torch.float16), 'model.layers.6.mlp.down_proj.weight': tensor([[-0.0122,  0.0100, -0.0043,  ...,  0.0013,  0.0143,  0.0160],
        [-0.0081, -0.0157,  0.0045,  ..., -0.0036, -0.0266, -0.0125],
        [ 0.0030,  0.0159, -0.0086,  ...,  0.0244,  0.0240,  0.0227],
        ...,
        [ 0.0110, -0.0024,  0.0207,  ...,  0.0316, -0.0336, -0.0099],
        [ 0.0216, -0.0065,  0.0070,  ...,  0.0098, -0.0135, -0.0126],
        [ 0.0152, -0.0165, -0.0085,  ...,  0.0319, -0.0050,  0.0079]],
       dtype=torch.float16), 'model.layers.6.input_layernorm.weight': tensor([0.3223, 0.3613, 0.3242,  ..., 0.3145, 0.3359, 0.3223],
       dtype=torch.float16), 'model.layers.6.post_attention_layernorm.weight': tensor([0.2217, 0.2129, 0.2090,  ..., 0.2227, 0.2168, 0.2178],
       dtype=torch.float16), 'model.layers.7.self_attn.q_proj.weight': tensor([[-6.2637e-03, -1.0843e-03, -8.1658e-06,  ..., -3.4428e-03,
         -2.0752e-02, -6.3477e-03],
        [-1.0460e-02,  1.4365e-04, -1.0338e-03,  ...,  1.2947e-02,
         -3.6564e-03, -1.6739e-02],
        [ 5.0201e-03,  6.6719e-03, -3.1158e-02,  ..., -2.0416e-02,
         -7.5684e-03,  9.1553e-03],
        ...,
        [-1.5259e-03, -3.3752e-02, -2.5040e-02,  ..., -1.2718e-02,
          3.4180e-02,  3.5553e-02],
        [ 1.3344e-02,  5.2917e-02, -4.0039e-02,  ..., -1.1269e-02,
         -6.7383e-02, -5.6915e-02],
        [ 7.9102e-02, -2.4200e-02, -1.8158e-02,  ...,  8.2947e-02,
          3.1113e-02, -4.3716e-03]], dtype=torch.float16), 'model.layers.7.self_attn.k_proj.weight': tensor([[ 0.0032, -0.0077, -0.0123,  ...,  0.0064,  0.0024, -0.0099],
        [-0.0070, -0.0178,  0.0048,  ..., -0.0072,  0.0043,  0.0185],
        [-0.0024, -0.0103,  0.0107,  ..., -0.0082, -0.0065, -0.0179],
        ...,
        [ 0.0429,  0.0077,  0.0243,  ...,  0.0351,  0.0396,  0.0282],
        [ 0.0400,  0.0500, -0.0002,  ..., -0.0307, -0.0344, -0.0016],
        [ 0.0403,  0.0058,  0.0104,  ..., -0.0012,  0.0019, -0.0272]],
       dtype=torch.float16), 'model.layers.7.self_attn.v_proj.weight': tensor([[-1.4038e-02,  5.2605e-03,  1.2993e-02,  ...,  2.8549e-02,
          4.2191e-03, -1.3847e-02],
        [ 2.6672e-02, -2.6993e-02,  4.3640e-03,  ...,  2.0035e-02,
         -1.8890e-02, -1.5915e-02],
        [-6.8970e-03, -1.0094e-02, -3.4523e-03,  ..., -1.8097e-02,
          1.1665e-02, -7.9453e-05],
        ...,
        [-1.3485e-03, -3.8300e-02,  2.7924e-03,  ...,  5.7297e-03,
         -6.9427e-03, -4.0016e-03],
        [-3.7872e-02,  1.9394e-02, -2.7618e-02,  ..., -1.8707e-02,
          1.0628e-02, -1.9252e-04],
        [-7.4272e-03,  2.6951e-03, -8.4991e-03,  ...,  2.0401e-02,
          7.3357e-03,  1.1787e-02]], dtype=torch.float16), 'model.layers.7.self_attn.o_proj.weight': tensor([[ 0.0116, -0.0154,  0.0014,  ...,  0.0091, -0.0194,  0.0053],
        [-0.0066,  0.0281,  0.0115,  ..., -0.0417, -0.0176, -0.0100],
        [ 0.0047, -0.0011, -0.0201,  ..., -0.0096, -0.0059, -0.0107],
        ...,
        [-0.0163, -0.0252, -0.0036,  ...,  0.0259, -0.0186,  0.0010],
        [-0.0226,  0.0085,  0.0167,  ...,  0.0080, -0.0130,  0.0153],
        [ 0.0028, -0.0002,  0.0005,  ...,  0.0060, -0.0161,  0.0039]],
       dtype=torch.float16), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 7.7896e-03,  4.7340e-03, -5.0850e-03,  ..., -4.3983e-03,
         -3.3386e-02, -7.2746e-03],
        [-3.1647e-02,  1.0490e-02, -8.5449e-03,  ..., -4.9400e-03,
         -3.8891e-03,  2.0676e-03],
        [ 1.7075e-02, -3.0640e-02, -8.4043e-06,  ...,  2.5543e-02,
         -2.7069e-02,  3.4237e-03],
        ...,
        [ 1.6441e-03,  2.0504e-03, -1.4145e-02,  ..., -2.0462e-02,
          4.6463e-03, -2.1713e-02],
        [ 2.6989e-03,  1.8036e-02,  1.2131e-02,  ..., -4.7798e-03,
          6.1493e-03, -3.0258e-02],
        [ 1.9714e-02, -1.6556e-02, -1.0773e-02,  ...,  1.7761e-02,
          1.8799e-02, -6.9962e-03]], dtype=torch.float16), 'model.layers.7.mlp.up_proj.weight': tensor([[ 0.0250,  0.0014, -0.0038,  ...,  0.0224, -0.0396,  0.0026],
        [-0.0110, -0.0190,  0.0299,  ...,  0.0095, -0.0108,  0.0154],
        [ 0.0259, -0.0214,  0.0107,  ..., -0.0126,  0.0181, -0.0352],
        ...,
        [-0.0019, -0.0023, -0.0150,  ..., -0.0095, -0.0177,  0.0024],
        [ 0.0003,  0.0084,  0.0167,  ..., -0.0071,  0.0215, -0.0067],
        [-0.0245, -0.0151,  0.0063,  ...,  0.0170,  0.0119,  0.0050]],
       dtype=torch.float16), 'model.layers.7.mlp.down_proj.weight': tensor([[-0.0079, -0.0069,  0.0050,  ..., -0.0115, -0.0060, -0.0211],
        [-0.0095, -0.0072,  0.0217,  ..., -0.0125,  0.0093,  0.0047],
        [ 0.0106,  0.0077,  0.0231,  ..., -0.0157, -0.0048, -0.0210],
        ...,
        [-0.0100,  0.0002, -0.0191,  ...,  0.0123,  0.0022, -0.0257],
        [ 0.0428, -0.0037,  0.0073,  ..., -0.0168,  0.0043, -0.0133],
        [ 0.0117,  0.0195, -0.0333,  ...,  0.0041, -0.0196, -0.0012]],
       dtype=torch.float16), 'model.layers.7.input_layernorm.weight': tensor([0.3242, 0.3652, 0.3340,  ..., 0.3203, 0.3574, 0.3320],
       dtype=torch.float16), 'model.layers.7.post_attention_layernorm.weight': tensor([0.2383, 0.2197, 0.2236,  ..., 0.2314, 0.2324, 0.2314],
       dtype=torch.float16), 'model.layers.8.self_attn.q_proj.weight': tensor([[-0.0004, -0.0152, -0.0297,  ..., -0.0065,  0.0065, -0.0091],
        [-0.0125, -0.0141, -0.0328,  ...,  0.0038, -0.0112,  0.0025],
        [-0.0400, -0.0028, -0.0129,  ..., -0.0023,  0.0260, -0.0321],
        ...,
        [-0.0062,  0.0861,  0.0443,  ..., -0.0247, -0.0285, -0.0468],
        [ 0.0012, -0.0596, -0.0192,  ...,  0.0352,  0.0269, -0.0008],
        [-0.0648, -0.0531, -0.0116,  ..., -0.0541,  0.0303, -0.0170]],
       dtype=torch.float16), 'model.layers.8.self_attn.k_proj.weight': tensor([[-0.0032, -0.0058, -0.0180,  ..., -0.0109,  0.0052,  0.0049],
        [-0.0125,  0.0011, -0.0050,  ...,  0.0228, -0.0019,  0.0143],
        [-0.0167,  0.0023,  0.0027,  ...,  0.0063, -0.0082, -0.0249],
        ...,
        [ 0.0031, -0.0395, -0.0067,  ..., -0.0295, -0.0149,  0.0230],
        [ 0.0078,  0.0294,  0.0184,  ..., -0.0301,  0.0431, -0.0562],
        [ 0.0190, -0.0026, -0.0326,  ...,  0.0140,  0.0077, -0.0147]],
       dtype=torch.float16), 'model.layers.8.self_attn.v_proj.weight': tensor([[-0.0287, -0.0166,  0.0045,  ..., -0.0193, -0.0085, -0.0096],
        [-0.0234, -0.0132,  0.0059,  ...,  0.0352,  0.0096,  0.0248],
        [-0.0082,  0.0140,  0.0135,  ..., -0.0079,  0.0031, -0.0204],
        ...,
        [ 0.0319, -0.0149,  0.0065,  ...,  0.0218, -0.0201,  0.0271],
        [ 0.0327, -0.0165,  0.0041,  ...,  0.0074, -0.0036,  0.0023],
        [ 0.0126, -0.0004, -0.0005,  ..., -0.0017,  0.0009, -0.0126]],
       dtype=torch.float16), 'model.layers.8.self_attn.o_proj.weight': tensor([[ 0.0177,  0.0157, -0.0148,  ..., -0.0109,  0.0026,  0.0176],
        [ 0.0054,  0.0004, -0.0322,  ..., -0.0121, -0.0108, -0.0186],
        [ 0.0025,  0.0138, -0.0094,  ..., -0.0011,  0.0121,  0.0166],
        ...,
        [-0.0150,  0.0233, -0.0010,  ...,  0.0010, -0.0001, -0.0027],
        [ 0.0086,  0.0015, -0.0089,  ...,  0.0043,  0.0054, -0.0251],
        [-0.0232, -0.0003, -0.0096,  ...,  0.0193, -0.0100,  0.0087]],
       dtype=torch.float16), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0158, -0.0021, -0.0490,  ...,  0.0059, -0.0245, -0.0163],
        [-0.0002, -0.0475,  0.0061,  ..., -0.0033, -0.0370,  0.0276],
        [ 0.0212,  0.0191,  0.0176,  ...,  0.0272,  0.0241, -0.0056],
        ...,
        [-0.0111,  0.0015,  0.0134,  ...,  0.0221,  0.0168,  0.0057],
        [-0.0146,  0.0039,  0.0056,  ..., -0.0016, -0.0165,  0.0145],
        [-0.0243,  0.0096, -0.0066,  ..., -0.0134,  0.0060,  0.0033]],
       dtype=torch.float16), 'model.layers.8.mlp.up_proj.weight': tensor([[-0.0055,  0.0251, -0.0157,  ...,  0.0298,  0.0039, -0.0158],
        [-0.0517,  0.0134, -0.0384,  ...,  0.0145, -0.0113, -0.0159],
        [ 0.0176, -0.0004,  0.0102,  ..., -0.0102, -0.0179,  0.0334],
        ...,
        [-0.0138,  0.0403, -0.0309,  ...,  0.0130,  0.0027,  0.0163],
        [ 0.0054, -0.0047, -0.0058,  ..., -0.0160,  0.0193, -0.0173],
        [-0.0224,  0.0174, -0.0155,  ..., -0.0185, -0.0012, -0.0002]],
       dtype=torch.float16), 'model.layers.8.mlp.down_proj.weight': tensor([[-0.0099, -0.0094,  0.0129,  ...,  0.0072,  0.0198, -0.0290],
        [ 0.0178,  0.0132, -0.0227,  ..., -0.0072,  0.0143, -0.0171],
        [ 0.0061, -0.0186, -0.0251,  ..., -0.0091, -0.0019,  0.0038],
        ...,
        [ 0.0090, -0.0205, -0.0343,  ...,  0.0038,  0.0098, -0.0160],
        [ 0.0096,  0.0107, -0.0036,  ..., -0.0060, -0.0068, -0.0226],
        [-0.0031,  0.0103,  0.0024,  ...,  0.0047,  0.0011,  0.0048]],
       dtype=torch.float16), 'model.layers.8.input_layernorm.weight': tensor([0.3301, 0.3477, 0.3320,  ..., 0.3203, 0.3398, 0.3242],
       dtype=torch.float16), 'model.layers.8.post_attention_layernorm.weight': tensor([0.2422, 0.2314, 0.2236,  ..., 0.2363, 0.2324, 0.2305],
       dtype=torch.float16), 'model.layers.9.self_attn.q_proj.weight': tensor([[-0.0147,  0.0026,  0.0210,  ..., -0.0103, -0.0100, -0.0244],
        [-0.0023, -0.0385,  0.0208,  ..., -0.0013, -0.0039,  0.0068],
        [ 0.0012, -0.0021, -0.0153,  ..., -0.0283, -0.0279, -0.0179],
        ...,
        [-0.0006, -0.0509,  0.0130,  ...,  0.0190,  0.0121, -0.0163],
        [ 0.0161, -0.0186,  0.0037,  ...,  0.0068,  0.0028,  0.0125],
        [-0.0003,  0.0516,  0.0195,  ..., -0.0563,  0.0534, -0.0034]],
       dtype=torch.float16), 'model.layers.9.self_attn.k_proj.weight': tensor([[-0.0307,  0.0100, -0.0252,  ..., -0.0017, -0.0205, -0.0061],
        [-0.0069,  0.0352,  0.0098,  ..., -0.0149,  0.0085,  0.0003],
        [-0.0164, -0.0064,  0.0345,  ...,  0.0036, -0.0246, -0.0038],
        ...,
        [ 0.0229, -0.0136, -0.0035,  ..., -0.0085,  0.0241,  0.0240],
        [ 0.0319,  0.0002,  0.0217,  ...,  0.0495, -0.0169,  0.0517],
        [ 0.0084, -0.0259,  0.0257,  ...,  0.0061,  0.0235, -0.0248]],
       dtype=torch.float16), 'model.layers.9.self_attn.v_proj.weight': tensor([[-0.0064,  0.0087,  0.0034,  ...,  0.0043, -0.0216, -0.0148],
        [-0.0142, -0.0147, -0.0031,  ...,  0.0340, -0.0037, -0.0044],
        [ 0.0071, -0.0220,  0.0211,  ..., -0.0274,  0.0032, -0.0137],
        ...,
        [-0.0094, -0.0083,  0.0037,  ...,  0.0052, -0.0218, -0.0055],
        [-0.0172, -0.0003, -0.0087,  ..., -0.0159,  0.0021, -0.0135],
        [ 0.0245,  0.0242, -0.0037,  ..., -0.0092, -0.0047, -0.0060]],
       dtype=torch.float16), 'model.layers.9.self_attn.o_proj.weight': tensor([[ 0.0102,  0.0094,  0.0113,  ..., -0.0143,  0.0007, -0.0113],
        [-0.0017, -0.0193, -0.0068,  ..., -0.0033,  0.0041,  0.0140],
        [-0.0407, -0.0316,  0.0091,  ...,  0.0292,  0.0020,  0.0106],
        ...,
        [ 0.0148, -0.0133,  0.0091,  ...,  0.0057,  0.0059, -0.0098],
        [ 0.0072,  0.0159,  0.0002,  ...,  0.0084,  0.0001,  0.0006],
        [ 0.0189,  0.0456, -0.0234,  ..., -0.0009,  0.0104,  0.0045]],
       dtype=torch.float16), 'model.layers.9.mlp.gate_proj.weight': tensor([[-0.0097,  0.0258,  0.0002,  ..., -0.0271, -0.0084,  0.0018],
        [-0.0202,  0.0319,  0.0322,  ...,  0.0281,  0.0377,  0.0024],
        [ 0.0390,  0.0285, -0.0269,  ..., -0.0217,  0.0120,  0.0011],
        ...,
        [-0.0204, -0.0079, -0.0243,  ...,  0.0019, -0.0409,  0.0066],
        [-0.0061, -0.0243,  0.0275,  ..., -0.0112,  0.0039,  0.0113],
        [ 0.0146, -0.0229, -0.0039,  ...,  0.0122, -0.0083,  0.0163]],
       dtype=torch.float16), 'model.layers.9.mlp.up_proj.weight': tensor([[-0.0143,  0.0186,  0.0150,  ..., -0.0016, -0.0087,  0.0038],
        [ 0.0086, -0.0010,  0.0079,  ...,  0.0153,  0.0204, -0.0192],
        [-0.0182, -0.0051, -0.0223,  ..., -0.0026, -0.0114,  0.0033],
        ...,
        [ 0.0029,  0.0126, -0.0075,  ..., -0.0150, -0.0307, -0.0130],
        [ 0.0031,  0.0218, -0.0348,  ..., -0.0351, -0.0096, -0.0163],
        [ 0.0102, -0.0337, -0.0058,  ..., -0.0190,  0.0217, -0.0074]],
       dtype=torch.float16), 'model.layers.9.mlp.down_proj.weight': tensor([[-0.0030,  0.0313, -0.0411,  ...,  0.0004, -0.0109,  0.0136],
        [ 0.0216, -0.0283, -0.0173,  ..., -0.0057, -0.0223, -0.0278],
        [-0.0026, -0.0015,  0.0022,  ..., -0.0155,  0.0007, -0.0026],
        ...,
        [-0.0101,  0.0194,  0.0052,  ..., -0.0095, -0.0285,  0.0141],
        [-0.0309,  0.0034,  0.0155,  ..., -0.0204, -0.0034, -0.0333],
        [ 0.0165,  0.0171,  0.0078,  ...,  0.0404,  0.0161,  0.0167]],
       dtype=torch.float16), 'model.layers.9.input_layernorm.weight': tensor([0.3535, 0.3633, 0.3281,  ..., 0.3477, 0.3477, 0.3438],
       dtype=torch.float16), 'model.layers.9.post_attention_layernorm.weight': tensor([0.2490, 0.2334, 0.2285,  ..., 0.2451, 0.2422, 0.2383],
       dtype=torch.float16), 'model.layers.10.self_attn.q_proj.weight': tensor([[-3.6449e-03,  3.8357e-03,  2.0087e-05,  ..., -2.7161e-03,
         -6.6376e-03, -1.4206e-02],
        [-9.7427e-03, -4.9667e-03,  2.0599e-02,  ..., -1.9287e-02,
          6.4575e-02, -3.7270e-03],
        [-1.3718e-02, -1.5106e-02,  2.1040e-04,  ...,  3.4210e-02,
         -9.4452e-03, -1.4389e-02],
        ...,
        [ 3.2104e-02,  6.3049e-02, -1.7929e-02,  ...,  3.7445e-02,
          3.3508e-02, -9.3842e-03],
        [-6.6040e-02,  5.6519e-02, -2.7695e-03,  ..., -6.0577e-02,
         -5.7068e-03, -3.6221e-03],
        [-4.9713e-02, -2.1591e-02, -7.7477e-03,  ..., -1.2627e-02,
         -3.6346e-02, -9.3536e-03]], dtype=torch.float16), 'model.layers.10.self_attn.k_proj.weight': tensor([[-0.0320,  0.0131, -0.0093,  ..., -0.0153,  0.0091, -0.0001],
        [-0.0056,  0.0082, -0.0056,  ..., -0.0057, -0.0101,  0.0133],
        [-0.0008, -0.0022,  0.0067,  ..., -0.0274,  0.0042,  0.0012],
        ...,
        [-0.0464, -0.0599,  0.0127,  ...,  0.0291, -0.0853,  0.0117],
        [-0.0345, -0.0131,  0.0234,  ..., -0.0141, -0.0415, -0.0148],
        [-0.0192,  0.0225, -0.0224,  ...,  0.0083,  0.0425, -0.0002]],
       dtype=torch.float16), 'model.layers.10.self_attn.v_proj.weight': tensor([[-0.0387,  0.0081, -0.0087,  ...,  0.0097,  0.0140,  0.0083],
        [-0.0083,  0.0136,  0.0120,  ..., -0.0067, -0.0419,  0.0195],
        [ 0.0170, -0.0150,  0.0130,  ...,  0.0145,  0.0079, -0.0095],
        ...,
        [ 0.0214,  0.0277,  0.0017,  ...,  0.0253,  0.0023, -0.0228],
        [-0.0040,  0.0057, -0.0005,  ...,  0.0020,  0.0113, -0.0018],
        [ 0.0172,  0.0061, -0.0238,  ..., -0.0072, -0.0071,  0.0242]],
       dtype=torch.float16), 'model.layers.10.self_attn.o_proj.weight': tensor([[-0.0057,  0.0007, -0.0348,  ...,  0.0022,  0.0056,  0.0074],
        [ 0.0006, -0.0118,  0.0126,  ...,  0.0058,  0.0132,  0.0075],
        [ 0.0153, -0.0353, -0.0162,  ...,  0.0007, -0.0036, -0.0031],
        ...,
        [-0.0021,  0.0080, -0.0197,  ..., -0.0031, -0.0003,  0.0199],
        [ 0.0090, -0.0164, -0.0207,  ...,  0.0118,  0.0087,  0.0109],
        [ 0.0075, -0.0081, -0.0278,  ...,  0.0101, -0.0039,  0.0009]],
       dtype=torch.float16), 'model.layers.10.mlp.gate_proj.weight': tensor([[-0.0255, -0.0464, -0.0296,  ...,  0.0059, -0.0014, -0.0041],
        [-0.0152, -0.0224, -0.0173,  ...,  0.0032,  0.0152,  0.0143],
        [-0.0210, -0.0214,  0.0097,  ...,  0.0347, -0.0098,  0.0017],
        ...,
        [-0.0465, -0.0077,  0.0100,  ...,  0.0039, -0.0303,  0.0208],
        [ 0.0046,  0.0114,  0.0203,  ...,  0.0042, -0.0112, -0.0007],
        [-0.0159, -0.0042, -0.0147,  ..., -0.0145,  0.0072, -0.0121]],
       dtype=torch.float16), 'model.layers.10.mlp.up_proj.weight': tensor([[-0.0320, -0.0040, -0.0427,  ...,  0.0109, -0.0067, -0.0190],
        [-0.0074,  0.0061,  0.0065,  ...,  0.0190,  0.0319, -0.0167],
        [-0.0080, -0.0042,  0.0192,  ...,  0.0319, -0.0360,  0.0033],
        ...,
        [ 0.0242,  0.0213, -0.0094,  ..., -0.0432, -0.0039,  0.0027],
        [-0.0012, -0.0116, -0.0232,  ...,  0.0270, -0.0056,  0.0214],
        [-0.0042,  0.0167, -0.0049,  ..., -0.0009,  0.0034,  0.0205]],
       dtype=torch.float16), 'model.layers.10.mlp.down_proj.weight': tensor([[-0.0152, -0.0201, -0.0101,  ...,  0.0302, -0.0133,  0.0010],
        [-0.0054,  0.0221, -0.0139,  ..., -0.0116,  0.0119, -0.0105],
        [-0.0275, -0.0021,  0.0208,  ..., -0.0218, -0.0254,  0.0118],
        ...,
        [ 0.0098, -0.0068, -0.0057,  ...,  0.0063,  0.0142,  0.0074],
        [-0.0106,  0.0519, -0.0189,  ...,  0.0284,  0.0307, -0.0305],
        [-0.0471,  0.0020, -0.0252,  ..., -0.0184, -0.0151,  0.0109]],
       dtype=torch.float16), 'model.layers.10.input_layernorm.weight': tensor([0.3652, 0.3594, 0.3223,  ..., 0.3398, 0.3496, 0.3379],
       dtype=torch.float16), 'model.layers.10.post_attention_layernorm.weight': tensor([0.2500, 0.2383, 0.2285,  ..., 0.2432, 0.2432, 0.2432],
       dtype=torch.float16), 'model.layers.11.self_attn.q_proj.weight': tensor([[ 0.0161, -0.0006, -0.0169,  ...,  0.0251, -0.0088,  0.0062],
        [-0.0113,  0.0006,  0.0061,  ...,  0.0169,  0.0102,  0.0040],
        [ 0.0104,  0.0213, -0.0237,  ..., -0.0047, -0.0055,  0.0015],
        ...,
        [ 0.0066,  0.0024,  0.0322,  ...,  0.0338,  0.0438, -0.0291],
        [ 0.0504,  0.0148, -0.0166,  ..., -0.0151,  0.0161, -0.0268],
        [ 0.0818, -0.0201, -0.0214,  ..., -0.0201,  0.0410,  0.0539]],
       dtype=torch.float16), 'model.layers.11.self_attn.k_proj.weight': tensor([[-0.0052,  0.0221,  0.0030,  ..., -0.0179,  0.0177, -0.0154],
        [ 0.0012,  0.0016, -0.0310,  ..., -0.0106,  0.0045,  0.0256],
        [ 0.0298, -0.0297,  0.0027,  ...,  0.0140,  0.0046,  0.0079],
        ...,
        [-0.0032,  0.0288,  0.0043,  ..., -0.0189, -0.0055,  0.0403],
        [ 0.0598, -0.0065, -0.0142,  ..., -0.0078,  0.0050, -0.0079],
        [ 0.0110,  0.0065,  0.0253,  ..., -0.0007,  0.0569,  0.0267]],
       dtype=torch.float16), 'model.layers.11.self_attn.v_proj.weight': tensor([[ 9.6436e-03,  1.0605e-03, -4.5738e-03,  ..., -2.2232e-02,
         -1.0233e-03,  7.4806e-03],
        [ 2.6855e-03, -6.0806e-03, -1.6937e-02,  ..., -5.5611e-05,
          3.7360e-04, -2.7130e-02],
        [ 2.9392e-03,  9.2468e-03, -7.0686e-03,  ...,  1.6724e-02,
          1.0735e-02, -2.5055e-02],
        ...,
        [-2.0782e-02,  7.5455e-03, -1.4633e-02,  ...,  8.2016e-03,
         -1.7349e-02, -2.2812e-03],
        [-9.9487e-03,  1.0506e-02, -1.1917e-02,  ..., -1.3245e-02,
         -1.7868e-02,  3.2711e-03],
        [ 1.7990e-02, -2.1179e-02, -1.4639e-03,  ..., -4.0344e-02,
          1.8826e-03, -1.2375e-02]], dtype=torch.float16), 'model.layers.11.self_attn.o_proj.weight': tensor([[-0.0191, -0.0035,  0.0060,  ...,  0.0097,  0.0109,  0.0016],
        [-0.0016, -0.0260,  0.0116,  ..., -0.0118, -0.0028, -0.0255],
        [-0.0051, -0.0058,  0.0210,  ...,  0.0021, -0.0066,  0.0139],
        ...,
        [ 0.0016, -0.0042,  0.0228,  ...,  0.0024, -0.0016, -0.0029],
        [ 0.0077,  0.0177,  0.0082,  ...,  0.0172,  0.0129, -0.0298],
        [-0.0027, -0.0047,  0.0054,  ..., -0.0081, -0.0022, -0.0107]],
       dtype=torch.float16), 'model.layers.11.mlp.gate_proj.weight': tensor([[-0.0440, -0.0086,  0.0052,  ...,  0.0062, -0.0116,  0.0425],
        [ 0.0074, -0.0107,  0.0206,  ...,  0.0087, -0.0197, -0.0413],
        [-0.0010, -0.0459, -0.0289,  ..., -0.0025, -0.0084, -0.0026],
        ...,
        [-0.0202, -0.0397, -0.0216,  ..., -0.0041, -0.0321,  0.0039],
        [ 0.0090, -0.0044, -0.0364,  ..., -0.0127,  0.0069,  0.0010],
        [ 0.0023,  0.0186,  0.0080,  ...,  0.0468, -0.0007, -0.0140]],
       dtype=torch.float16), 'model.layers.11.mlp.up_proj.weight': tensor([[-0.0093,  0.0016, -0.0275,  ...,  0.0240,  0.0097,  0.0313],
        [ 0.0179, -0.0028, -0.0222,  ...,  0.0172, -0.0467,  0.0077],
        [-0.0064, -0.0369,  0.0014,  ..., -0.0048, -0.0177,  0.0154],
        ...,
        [ 0.0408,  0.0105, -0.0095,  ...,  0.0014, -0.0005,  0.0161],
        [-0.0116,  0.0200,  0.0059,  ...,  0.0163,  0.0094,  0.0065],
        [-0.0041,  0.0019, -0.0054,  ..., -0.0172, -0.0005,  0.0250]],
       dtype=torch.float16), 'model.layers.11.mlp.down_proj.weight': tensor([[-0.0162,  0.0454,  0.0091,  ...,  0.0194,  0.0163, -0.0040],
        [-0.0136, -0.0092, -0.0251,  ..., -0.0202, -0.0090,  0.0154],
        [-0.0237, -0.0169,  0.0102,  ...,  0.0052, -0.0217, -0.0031],
        ...,
        [ 0.0215,  0.0262, -0.0104,  ..., -0.0017, -0.0003,  0.0087],
        [-0.0111, -0.0290, -0.0306,  ..., -0.0254, -0.0089,  0.0139],
        [ 0.0362,  0.0240,  0.0214,  ..., -0.0028, -0.0135,  0.0383]],
       dtype=torch.float16), 'model.layers.11.input_layernorm.weight': tensor([0.3965, 0.3965, 0.3652,  ..., 0.3848, 0.3828, 0.3711],
       dtype=torch.float16), 'model.layers.11.post_attention_layernorm.weight': tensor([0.2598, 0.2471, 0.2383,  ..., 0.2578, 0.2559, 0.2559],
       dtype=torch.float16), 'model.layers.12.self_attn.q_proj.weight': tensor([[-0.0093, -0.0171,  0.0036,  ...,  0.0262, -0.0099,  0.0055],
        [ 0.0065, -0.0070, -0.0075,  ..., -0.0127,  0.0223,  0.0202],
        [ 0.0106,  0.0411, -0.0328,  ...,  0.0061,  0.0025, -0.0291],
        ...,
        [ 0.0094,  0.0321, -0.0197,  ..., -0.0311, -0.0004, -0.0008],
        [ 0.0424, -0.0059,  0.0097,  ...,  0.0322,  0.0067, -0.0247],
        [ 0.0332,  0.0143, -0.0364,  ..., -0.0210,  0.0215,  0.0238]],
       dtype=torch.float16), 'model.layers.12.self_attn.k_proj.weight': tensor([[ 0.0099, -0.0011, -0.0045,  ...,  0.0193, -0.0024, -0.0102],
        [ 0.0073,  0.0208, -0.0157,  ..., -0.0014, -0.0157, -0.0293],
        [-0.0113, -0.0283,  0.0173,  ...,  0.0087,  0.0026,  0.0026],
        ...,
        [ 0.0132,  0.0322, -0.0148,  ..., -0.0355, -0.0164, -0.0242],
        [-0.0381,  0.0037,  0.0226,  ..., -0.0282,  0.0146, -0.0006],
        [-0.0007,  0.0322,  0.0109,  ...,  0.0129, -0.0465, -0.0404]],
       dtype=torch.float16), 'model.layers.12.self_attn.v_proj.weight': tensor([[ 0.0064,  0.0072,  0.0069,  ..., -0.0077,  0.0109, -0.0189],
        [-0.0275,  0.0104, -0.0036,  ..., -0.0175, -0.0006,  0.0191],
        [-0.0148, -0.0132,  0.0088,  ..., -0.0069,  0.0475, -0.0107],
        ...,
        [ 0.0081, -0.0017, -0.0150,  ..., -0.0068, -0.0115, -0.0013],
        [-0.0010, -0.0147, -0.0047,  ...,  0.0034,  0.0109,  0.0122],
        [ 0.0225,  0.0017,  0.0007,  ...,  0.0178,  0.0139, -0.0070]],
       dtype=torch.float16), 'model.layers.12.self_attn.o_proj.weight': tensor([[ 0.0277,  0.0071, -0.0019,  ..., -0.0012,  0.0083, -0.0061],
        [-0.0092, -0.0141, -0.0014,  ..., -0.0108,  0.0061, -0.0138],
        [ 0.0068, -0.0023, -0.0018,  ...,  0.0037, -0.0232,  0.0125],
        ...,
        [ 0.0032, -0.0023,  0.0126,  ..., -0.0084, -0.0009,  0.0019],
        [-0.0108, -0.0346, -0.0278,  ..., -0.0121,  0.0109,  0.0143],
        [ 0.0210,  0.0093,  0.0084,  ...,  0.0209, -0.0084, -0.0171]],
       dtype=torch.float16), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0057, -0.0110,  0.0123,  ..., -0.0042,  0.0268, -0.0024],
        [-0.0266, -0.0214,  0.0172,  ...,  0.0121,  0.0153,  0.0057],
        [-0.0005,  0.0258, -0.0114,  ..., -0.0099, -0.0289, -0.0045],
        ...,
        [-0.0024,  0.0108,  0.0106,  ..., -0.0328,  0.0070,  0.0276],
        [-0.0325, -0.0083,  0.0082,  ...,  0.0103,  0.0123, -0.0085],
        [ 0.0045, -0.0267, -0.0056,  ..., -0.0053, -0.0018, -0.0202]],
       dtype=torch.float16), 'model.layers.12.mlp.up_proj.weight': tensor([[ 2.9488e-03,  1.7151e-02,  3.6030e-03,  ..., -9.1076e-05,
          1.3832e-02,  1.5427e-02],
        [-3.6373e-03, -1.4801e-02, -1.3435e-02,  ...,  6.5842e-03,
         -7.0915e-03,  2.4414e-02],
        [ 1.4610e-02, -1.2291e-02,  7.4959e-03,  ..., -4.1534e-02,
          4.9171e-03,  1.6441e-03],
        ...,
        [-2.6154e-02, -3.3844e-02, -7.3738e-03,  ...,  1.6922e-02,
         -1.5038e-02,  3.0403e-03],
        [-1.5144e-03, -4.3915e-02, -8.0156e-04,  ...,  1.3924e-02,
          3.0556e-03, -1.5656e-02],
        [ 2.2144e-03, -2.8961e-02,  3.7813e-04,  ...,  3.2440e-02,
         -3.6602e-03, -3.8300e-02]], dtype=torch.float16), 'model.layers.12.mlp.down_proj.weight': tensor([[ 0.0081, -0.0018, -0.0294,  ..., -0.0123,  0.0035,  0.0029],
        [ 0.0170, -0.0288,  0.0046,  ..., -0.0004, -0.0089, -0.0230],
        [ 0.0200,  0.0030,  0.0241,  ...,  0.0043, -0.0012, -0.0281],
        ...,
        [ 0.0183, -0.0085, -0.0380,  ...,  0.0313, -0.0193, -0.0176],
        [-0.0259,  0.0179,  0.0106,  ..., -0.0092,  0.0359, -0.0229],
        [ 0.0075,  0.0262,  0.0221,  ..., -0.0381,  0.0273, -0.0022]],
       dtype=torch.float16), 'model.layers.12.input_layernorm.weight': tensor([0.4062, 0.4023, 0.3691,  ..., 0.3848, 0.3867, 0.3887],
       dtype=torch.float16), 'model.layers.12.post_attention_layernorm.weight': tensor([0.2656, 0.2520, 0.2432,  ..., 0.2656, 0.2617, 0.2598],
       dtype=torch.float16), 'model.layers.13.self_attn.q_proj.weight': tensor([[-0.0002, -0.0013, -0.0132,  ...,  0.0055, -0.0150, -0.0128],
        [-0.0118, -0.0142,  0.0031,  ..., -0.0004,  0.0004, -0.0026],
        [-0.0175,  0.0138,  0.0197,  ..., -0.0115, -0.0075, -0.0069],
        ...,
        [ 0.0483,  0.0084,  0.0043,  ...,  0.0573,  0.0140, -0.0512],
        [ 0.0078,  0.0083, -0.0259,  ...,  0.0091,  0.0111, -0.0104],
        [-0.0040, -0.0248, -0.0212,  ..., -0.0068,  0.0285, -0.0065]],
       dtype=torch.float16), 'model.layers.13.self_attn.k_proj.weight': tensor([[ 0.0134,  0.0048, -0.0030,  ..., -0.0130,  0.0337,  0.0125],
        [ 0.0155,  0.0307, -0.0005,  ..., -0.0055,  0.0136,  0.0046],
        [-0.0007, -0.0130,  0.0334,  ..., -0.0083,  0.0110, -0.0375],
        ...,
        [ 0.0375,  0.0356,  0.0033,  ...,  0.0048, -0.0061, -0.0118],
        [-0.0010,  0.0045,  0.0287,  ..., -0.0342, -0.0217,  0.0352],
        [-0.0229, -0.0535, -0.0142,  ..., -0.0378, -0.0310,  0.0118]],
       dtype=torch.float16), 'model.layers.13.self_attn.v_proj.weight': tensor([[ 0.0149,  0.0064, -0.0058,  ..., -0.0005,  0.0173,  0.0124],
        [-0.0029,  0.0087,  0.0005,  ...,  0.0233, -0.0065, -0.0029],
        [ 0.0146, -0.0016, -0.0023,  ..., -0.0212,  0.0366, -0.0090],
        ...,
        [-0.0011,  0.0251, -0.0052,  ..., -0.0111,  0.0272, -0.0211],
        [-0.0103,  0.0104,  0.0128,  ...,  0.0017,  0.0274,  0.0058],
        [-0.0045, -0.0064,  0.0239,  ...,  0.0154, -0.0026,  0.0374]],
       dtype=torch.float16), 'model.layers.13.self_attn.o_proj.weight': tensor([[-0.0035,  0.0010, -0.0044,  ..., -0.0015, -0.0045, -0.0012],
        [ 0.0222,  0.0148,  0.0101,  ..., -0.0146, -0.0108,  0.0024],
        [ 0.0118,  0.0055,  0.0036,  ...,  0.0065, -0.0233, -0.0088],
        ...,
        [-0.0102,  0.0102,  0.0194,  ..., -0.0114, -0.0154, -0.0165],
        [ 0.0083, -0.0005,  0.0301,  ..., -0.0037, -0.0268, -0.0238],
        [ 0.0100,  0.0019,  0.0086,  ...,  0.0171, -0.0083, -0.0238]],
       dtype=torch.float16), 'model.layers.13.mlp.gate_proj.weight': tensor([[ 0.0249, -0.0034, -0.0082,  ...,  0.0114,  0.0034, -0.0122],
        [-0.0141,  0.0452,  0.0071,  ...,  0.0416, -0.0012, -0.0260],
        [ 0.0035, -0.0199, -0.0103,  ...,  0.0047, -0.0093, -0.0152],
        ...,
        [ 0.0153, -0.0196,  0.0202,  ..., -0.0065,  0.0133,  0.0111],
        [ 0.0154, -0.0125,  0.0203,  ...,  0.0181,  0.0106, -0.0270],
        [ 0.0028,  0.0392,  0.0161,  ..., -0.0045,  0.0059,  0.0285]],
       dtype=torch.float16), 'model.layers.13.mlp.up_proj.weight': tensor([[-0.0423,  0.0199, -0.0013,  ...,  0.0037,  0.0091,  0.0011],
        [ 0.0138, -0.0066,  0.0247,  ...,  0.0468,  0.0286,  0.0224],
        [ 0.0281, -0.0344,  0.0093,  ...,  0.0069,  0.0009, -0.0082],
        ...,
        [-0.0130, -0.0038,  0.0297,  ...,  0.0190, -0.0247,  0.0139],
        [-0.0103, -0.0171,  0.0079,  ...,  0.0177,  0.0563,  0.0096],
        [ 0.0117, -0.0212,  0.0179,  ..., -0.0185, -0.0004,  0.0269]],
       dtype=torch.float16), 'model.layers.13.mlp.down_proj.weight': tensor([[-0.0062, -0.0036, -0.0027,  ...,  0.0226, -0.0265, -0.0220],
        [-0.0117,  0.0470, -0.0413,  ..., -0.0018,  0.0133, -0.0090],
        [ 0.0081,  0.0038,  0.0183,  ...,  0.0015, -0.0249, -0.0031],
        ...,
        [ 0.0058,  0.0077,  0.0354,  ..., -0.0014, -0.0209,  0.0290],
        [ 0.0167, -0.0015,  0.0188,  ..., -0.0109,  0.0164, -0.0045],
        [ 0.0029, -0.0229,  0.0393,  ...,  0.0041,  0.0022,  0.0325]],
       dtype=torch.float16), 'model.layers.13.input_layernorm.weight': tensor([0.4199, 0.4121, 0.3770,  ..., 0.3926, 0.3848, 0.3965],
       dtype=torch.float16), 'model.layers.13.post_attention_layernorm.weight': tensor([0.2715, 0.2598, 0.2539,  ..., 0.2715, 0.2734, 0.2656],
       dtype=torch.float16), 'model.layers.14.self_attn.q_proj.weight': tensor([[-0.0088, -0.0028,  0.0195,  ..., -0.0054,  0.0162,  0.0367],
        [ 0.0097,  0.0160, -0.0124,  ..., -0.0348, -0.0203, -0.0406],
        [-0.0202, -0.0112,  0.0171,  ...,  0.0106,  0.0140, -0.0339],
        ...,
        [-0.0201,  0.0005, -0.0295,  ...,  0.0018,  0.0130, -0.0074],
        [ 0.0269, -0.0389,  0.0497,  ..., -0.0134,  0.0061, -0.0092],
        [-0.0175, -0.0090, -0.0035,  ...,  0.0170,  0.0184, -0.0447]],
       dtype=torch.float16), 'model.layers.14.self_attn.k_proj.weight': tensor([[-0.0143, -0.0049,  0.0068,  ..., -0.0091,  0.0271,  0.0431],
        [ 0.0191,  0.0324, -0.0204,  ..., -0.0030, -0.0276, -0.0050],
        [-0.0183,  0.0034,  0.0196,  ...,  0.0239,  0.0110,  0.0012],
        ...,
        [-0.0387, -0.0029,  0.0264,  ..., -0.0049,  0.0017, -0.0254],
        [-0.0293,  0.0005,  0.0153,  ..., -0.0359, -0.0144,  0.0012],
        [-0.0202,  0.0292,  0.0236,  ...,  0.0703,  0.0087, -0.0386]],
       dtype=torch.float16), 'model.layers.14.self_attn.v_proj.weight': tensor([[ 7.4310e-03,  7.7629e-03, -3.8025e-02,  ..., -3.4210e-02,
         -5.2032e-03,  1.2451e-02],
        [-1.0204e-03, -2.5452e-02, -3.0117e-03,  ...,  1.0887e-02,
         -5.2512e-05, -3.2425e-03],
        [ 2.6276e-02, -1.5022e-02,  2.2659e-03,  ..., -5.5466e-03,
          2.3460e-03,  8.2321e-03],
        ...,
        [ 1.5747e-02, -1.1642e-02,  1.5343e-02,  ...,  1.5533e-02,
         -1.1597e-02,  2.6016e-03],
        [-1.1391e-02,  2.2583e-02, -3.5553e-02,  ..., -7.8058e-04,
         -8.8654e-03, -2.5574e-02],
        [ 3.5992e-03,  2.3102e-02, -2.2568e-02,  ..., -5.2261e-03,
         -3.3932e-03,  1.8295e-02]], dtype=torch.float16), 'model.layers.14.self_attn.o_proj.weight': tensor([[-0.0108,  0.0044, -0.0227,  ..., -0.0021,  0.0010, -0.0110],
        [ 0.0080,  0.0304,  0.0077,  ...,  0.0221, -0.0049,  0.0021],
        [ 0.0060,  0.0082,  0.0024,  ...,  0.0075,  0.0206,  0.0054],
        ...,
        [ 0.0245, -0.0073,  0.0008,  ..., -0.0073, -0.0022,  0.0139],
        [-0.0025,  0.0010, -0.0195,  ..., -0.0021,  0.0362,  0.0155],
        [-0.0085, -0.0104, -0.0139,  ..., -0.0070,  0.0146,  0.0060]],
       dtype=torch.float16), 'model.layers.14.mlp.gate_proj.weight': tensor([[-0.0084,  0.0011, -0.0090,  ...,  0.0102, -0.0185, -0.0064],
        [ 0.0296,  0.0080, -0.0390,  ...,  0.0377,  0.0119, -0.0075],
        [ 0.0095,  0.0148, -0.0004,  ..., -0.0081,  0.0108, -0.0179],
        ...,
        [ 0.0065,  0.0105, -0.0190,  ...,  0.0003, -0.0047,  0.0004],
        [ 0.0033,  0.0159,  0.0201,  ..., -0.0192,  0.0087,  0.0073],
        [ 0.0200,  0.0017,  0.0183,  ..., -0.0106, -0.0248,  0.0258]],
       dtype=torch.float16), 'model.layers.14.mlp.up_proj.weight': tensor([[ 0.0052,  0.0099,  0.0201,  ..., -0.0153,  0.0073,  0.0048],
        [ 0.0269,  0.0089, -0.0300,  ...,  0.0064,  0.0262,  0.0104],
        [ 0.0012, -0.0055,  0.0300,  ..., -0.0013,  0.0177, -0.0023],
        ...,
        [-0.0164, -0.0013, -0.0479,  ..., -0.0145, -0.0116, -0.0048],
        [-0.0415,  0.0074, -0.0075,  ..., -0.0081,  0.0239, -0.0144],
        [ 0.0029,  0.0235,  0.0122,  ...,  0.0086, -0.0140,  0.0131]],
       dtype=torch.float16), 'model.layers.14.mlp.down_proj.weight': tensor([[ 0.0100,  0.0243,  0.0113,  ..., -0.0290, -0.0019, -0.0056],
        [ 0.0121,  0.0222, -0.0091,  ...,  0.0131, -0.0032,  0.0189],
        [ 0.0080, -0.0420,  0.0119,  ...,  0.0042, -0.0302,  0.0124],
        ...,
        [ 0.0005,  0.0152, -0.0169,  ..., -0.0046, -0.0100, -0.0109],
        [ 0.0242,  0.0335,  0.0364,  ..., -0.0051, -0.0155,  0.0210],
        [-0.0245,  0.0057, -0.0101,  ..., -0.0300,  0.0070,  0.0187]],
       dtype=torch.float16), 'model.layers.14.input_layernorm.weight': tensor([0.4219, 0.4297, 0.3789,  ..., 0.4141, 0.4062, 0.3984],
       dtype=torch.float16), 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2734, 0.2656,  ..., 0.2871, 0.2832, 0.2793],
       dtype=torch.float16), 'model.layers.15.self_attn.q_proj.weight': tensor([[-0.0194, -0.0154, -0.0142,  ...,  0.0138, -0.0084,  0.0010],
        [ 0.0363, -0.0190,  0.0038,  ..., -0.0058,  0.0144,  0.0015],
        [ 0.0084, -0.0132,  0.0030,  ...,  0.0098, -0.0134, -0.0160],
        ...,
        [-0.0477, -0.0267,  0.0071,  ..., -0.0063, -0.0128,  0.0200],
        [-0.0155, -0.0536,  0.0174,  ...,  0.0155, -0.0015,  0.0025],
        [ 0.0236,  0.0251,  0.0278,  ..., -0.0140, -0.0227, -0.0165]],
       dtype=torch.float16), 'model.layers.15.self_attn.k_proj.weight': tensor([[ 0.0209, -0.0054, -0.0045,  ..., -0.0027,  0.0014,  0.0044],
        [ 0.0111, -0.0042, -0.0052,  ..., -0.0015,  0.0046, -0.0135],
        [-0.0021,  0.0020, -0.0083,  ..., -0.0007,  0.0133, -0.0119],
        ...,
        [-0.0540, -0.0380,  0.0168,  ...,  0.0214,  0.0069, -0.0060],
        [ 0.0092,  0.0011,  0.0159,  ...,  0.0275, -0.0217,  0.0132],
        [-0.0067, -0.0060,  0.0341,  ..., -0.0027, -0.0171,  0.0033]],
       dtype=torch.float16), 'model.layers.15.self_attn.v_proj.weight': tensor([[ 0.0088,  0.0023,  0.0053,  ...,  0.0037,  0.0141,  0.0177],
        [-0.0096, -0.0142,  0.0151,  ...,  0.0168,  0.0018,  0.0224],
        [ 0.0075, -0.0377, -0.0064,  ..., -0.0365,  0.0073,  0.0073],
        ...,
        [-0.0038, -0.0107,  0.0116,  ...,  0.0066,  0.0181, -0.0141],
        [ 0.0056, -0.0006, -0.0311,  ...,  0.0116,  0.0151, -0.0054],
        [ 0.0169,  0.0104,  0.0152,  ..., -0.0160,  0.0075,  0.0077]],
       dtype=torch.float16), 'model.layers.15.self_attn.o_proj.weight': tensor([[ 0.0012,  0.0029, -0.0154,  ...,  0.0104, -0.0127,  0.0282],
        [-0.0046, -0.0112, -0.0177,  ...,  0.0099, -0.0261,  0.0198],
        [ 0.0020, -0.0083,  0.0008,  ...,  0.0102, -0.0070,  0.0095],
        ...,
        [-0.0089, -0.0197,  0.0142,  ..., -0.0044, -0.0201, -0.0100],
        [ 0.0005, -0.0017, -0.0072,  ...,  0.0113,  0.0051,  0.0044],
        [-0.0241,  0.0053,  0.0263,  ..., -0.0118, -0.0254, -0.0296]],
       dtype=torch.float16), 'model.layers.15.mlp.gate_proj.weight': tensor([[-0.0145,  0.0259, -0.0075,  ...,  0.0116, -0.0298,  0.0140],
        [ 0.0069, -0.0101,  0.0278,  ..., -0.0192,  0.0056,  0.0099],
        [ 0.0088, -0.0179, -0.0112,  ...,  0.0231, -0.0539, -0.0260],
        ...,
        [-0.0106, -0.0046,  0.0301,  ..., -0.0094,  0.0175,  0.0069],
        [-0.0124, -0.0172,  0.0103,  ..., -0.0082, -0.0106, -0.0440],
        [ 0.0040, -0.0142, -0.0008,  ...,  0.0002,  0.0071, -0.0001]],
       dtype=torch.float16), 'model.layers.15.mlp.up_proj.weight': tensor([[-1.2886e-02, -9.5215e-03,  2.7924e-02,  ...,  1.2367e-02,
          1.1269e-02, -4.3579e-02],
        [-1.5732e-02,  4.2908e-02,  2.9343e-02,  ...,  1.0506e-02,
          7.6866e-03,  3.9864e-03],
        [-4.2419e-02, -7.7896e-03, -4.7994e-04,  ..., -1.5518e-02,
          1.5602e-02, -1.0269e-02],
        ...,
        [-6.7863e-03, -2.3376e-02, -7.8659e-03,  ...,  8.5068e-03,
         -4.8757e-05, -4.9782e-03],
        [ 2.7618e-02, -5.3329e-03,  7.8354e-03,  ..., -1.0330e-02,
          1.5747e-02,  5.7030e-04],
        [-7.5302e-03, -2.7130e-02, -9.7809e-03,  ...,  4.5633e-04,
         -1.2245e-02,  1.1940e-03]], dtype=torch.float16), 'model.layers.15.mlp.down_proj.weight': tensor([[-1.2512e-02, -6.8245e-03, -1.6098e-02,  ...,  2.5909e-02,
          9.1171e-03, -1.0674e-02],
        [ 1.0666e-02, -1.1749e-02, -2.6199e-02,  ..., -1.1993e-02,
         -2.3163e-02,  1.6129e-02],
        [ 3.8452e-02,  4.4830e-02, -1.5747e-02,  ..., -1.1589e-02,
          3.4302e-02,  1.8906e-02],
        ...,
        [-4.5853e-03, -3.9978e-02,  6.3210e-03,  ...,  9.4833e-03,
          5.5046e-03,  7.1466e-05],
        [-4.1779e-02, -1.7502e-02, -1.1826e-03,  ..., -2.9480e-02,
         -1.5137e-02,  7.0038e-03],
        [ 1.5354e-03,  2.3773e-02, -6.3553e-03,  ..., -1.7715e-02,
         -3.2593e-02, -2.0401e-02]], dtype=torch.float16), 'model.layers.15.input_layernorm.weight': tensor([0.4160, 0.4102, 0.3809,  ..., 0.3867, 0.3945, 0.3945],
       dtype=torch.float16), 'model.layers.15.post_attention_layernorm.weight': tensor([0.2930, 0.2793, 0.2793,  ..., 0.2969, 0.2910, 0.2891],
       dtype=torch.float16), 'model.layers.16.self_attn.q_proj.weight': tensor([[ 0.0090,  0.0135, -0.0253,  ...,  0.0048,  0.0263, -0.0078],
        [ 0.0172, -0.0415,  0.0228,  ...,  0.0170,  0.0186, -0.0237],
        [-0.0128, -0.0067,  0.0088,  ..., -0.0257,  0.0021, -0.0261],
        ...,
        [ 0.0328, -0.0378, -0.0080,  ..., -0.0196,  0.0181, -0.0271],
        [-0.0166, -0.0170,  0.0283,  ...,  0.0018, -0.0181,  0.0157],
        [ 0.0046,  0.0219,  0.0146,  ..., -0.0030, -0.0327, -0.0095]],
       dtype=torch.float16), 'model.layers.16.self_attn.k_proj.weight': tensor([[-0.0072,  0.0235,  0.0023,  ...,  0.0131,  0.0227,  0.0217],
        [ 0.0223, -0.0315,  0.0097,  ..., -0.0058, -0.0194, -0.0077],
        [ 0.0272, -0.0056, -0.0197,  ..., -0.0234,  0.0092, -0.0277],
        ...,
        [ 0.0239,  0.0135, -0.0127,  ..., -0.0233, -0.0399, -0.0581],
        [ 0.0161,  0.0086,  0.0133,  ...,  0.0302,  0.0043,  0.0115],
        [-0.0444,  0.0565,  0.0591,  ...,  0.0017, -0.0147,  0.0274]],
       dtype=torch.float16), 'model.layers.16.self_attn.v_proj.weight': tensor([[-0.0166,  0.0066, -0.0049,  ...,  0.0065, -0.0008, -0.0020],
        [-0.0576, -0.0069,  0.0042,  ...,  0.0035,  0.0128, -0.0267],
        [-0.0069, -0.0133, -0.0021,  ..., -0.0211,  0.0416,  0.0151],
        ...,
        [ 0.0040, -0.0079,  0.0167,  ..., -0.0125, -0.0001,  0.0166],
        [-0.0169,  0.0023,  0.0052,  ...,  0.0389, -0.0043,  0.0089],
        [ 0.0118,  0.0102,  0.0083,  ..., -0.0158, -0.0042, -0.0301]],
       dtype=torch.float16), 'model.layers.16.self_attn.o_proj.weight': tensor([[ 0.0388, -0.0079, -0.0170,  ...,  0.0112, -0.0126,  0.0047],
        [-0.0246,  0.0107, -0.0208,  ...,  0.0039, -0.0083,  0.0016],
        [-0.0285, -0.0177, -0.0134,  ..., -0.0021,  0.0259,  0.0170],
        ...,
        [-0.0030, -0.0207,  0.0029,  ...,  0.0046, -0.0266,  0.0010],
        [-0.0073,  0.0199,  0.0344,  ..., -0.0005,  0.0009, -0.0051],
        [-0.0192,  0.0035,  0.0066,  ...,  0.0018,  0.0024,  0.0109]],
       dtype=torch.float16), 'model.layers.16.mlp.gate_proj.weight': tensor([[-0.0275, -0.0157, -0.0233,  ...,  0.0007, -0.0003,  0.0085],
        [ 0.0313,  0.0157, -0.0098,  ...,  0.0153,  0.0087,  0.0166],
        [ 0.0027,  0.0056,  0.0041,  ..., -0.0008, -0.0035, -0.0189],
        ...,
        [-0.0086,  0.0085,  0.0053,  ...,  0.0223,  0.0300,  0.0286],
        [-0.0033, -0.0147,  0.0094,  ...,  0.0099,  0.0210,  0.0115],
        [ 0.0256,  0.0212,  0.0310,  ..., -0.0399,  0.0148, -0.0203]],
       dtype=torch.float16), 'model.layers.16.mlp.up_proj.weight': tensor([[-0.0403,  0.0147,  0.0066,  ...,  0.0294, -0.0128,  0.0091],
        [ 0.0156, -0.0131,  0.0048,  ...,  0.0215, -0.0303, -0.0077],
        [-0.0078, -0.0256, -0.0064,  ..., -0.0124, -0.0047,  0.0258],
        ...,
        [-0.0096,  0.0263, -0.0066,  ...,  0.0095, -0.0235, -0.0248],
        [-0.0098,  0.0216, -0.0177,  ...,  0.0097, -0.0052,  0.0185],
        [ 0.0099,  0.0079, -0.0118,  ...,  0.0013, -0.0239, -0.0209]],
       dtype=torch.float16), 'model.layers.16.mlp.down_proj.weight': tensor([[-0.0236,  0.0045,  0.0134,  ...,  0.0206, -0.0091, -0.0008],
        [-0.0233, -0.0041, -0.0123,  ...,  0.0286,  0.0018, -0.0002],
        [-0.0142,  0.0049, -0.0120,  ...,  0.0201, -0.0042, -0.0009],
        ...,
        [ 0.0143, -0.0248, -0.0242,  ...,  0.0203,  0.0178, -0.0020],
        [ 0.0227,  0.0019, -0.0097,  ..., -0.0214, -0.0128, -0.0098],
        [ 0.0107, -0.0168, -0.0371,  ...,  0.0256, -0.0010, -0.0141]],
       dtype=torch.float16), 'model.layers.16.input_layernorm.weight': tensor([0.4180, 0.4219, 0.3906,  ..., 0.3984, 0.4160, 0.4082],
       dtype=torch.float16), 'model.layers.16.post_attention_layernorm.weight': tensor([0.3164, 0.2949, 0.2988,  ..., 0.3105, 0.3086, 0.3047],
       dtype=torch.float16), 'model.layers.17.self_attn.q_proj.weight': tensor([[-0.0125, -0.0138,  0.0065,  ...,  0.0073, -0.0072, -0.0107],
        [ 0.0094, -0.0095,  0.0169,  ...,  0.0019, -0.0260,  0.0081],
        [-0.0130, -0.0020, -0.0129,  ...,  0.0152, -0.0114,  0.0020],
        ...,
        [ 0.0362, -0.0261,  0.0562,  ..., -0.0142, -0.0178,  0.0079],
        [ 0.0282, -0.0184,  0.0462,  ...,  0.0094, -0.0215, -0.0601],
        [ 0.0126, -0.0017,  0.0116,  ...,  0.0320,  0.0013,  0.0742]],
       dtype=torch.float16), 'model.layers.17.self_attn.k_proj.weight': tensor([[-0.0127, -0.0063,  0.0040,  ..., -0.0014,  0.0197,  0.0079],
        [ 0.0078,  0.0072,  0.0041,  ...,  0.0103,  0.0002, -0.0138],
        [ 0.0077, -0.0085,  0.0012,  ...,  0.0154, -0.0231, -0.0079],
        ...,
        [ 0.0041, -0.0500, -0.0091,  ..., -0.0221,  0.0599, -0.0676],
        [ 0.0275,  0.0191,  0.0122,  ..., -0.0132, -0.0267, -0.0225],
        [-0.0380, -0.0470, -0.0048,  ...,  0.0278,  0.0259, -0.0048]],
       dtype=torch.float16), 'model.layers.17.self_attn.v_proj.weight': tensor([[-0.0122,  0.0105,  0.0024,  ...,  0.0239, -0.0088, -0.0096],
        [-0.0039, -0.0155, -0.0111,  ...,  0.0116, -0.0257, -0.0144],
        [ 0.0174,  0.0158, -0.0024,  ...,  0.0018, -0.0111, -0.0288],
        ...,
        [ 0.0010, -0.0043,  0.0143,  ...,  0.0121,  0.0051, -0.0155],
        [ 0.0189, -0.0031, -0.0388,  ..., -0.0152, -0.0034, -0.0341],
        [-0.0093, -0.0103, -0.0053,  ...,  0.0055,  0.0081,  0.0092]],
       dtype=torch.float16), 'model.layers.17.self_attn.o_proj.weight': tensor([[-0.0049, -0.0105,  0.0036,  ..., -0.0197,  0.0008, -0.0131],
        [-0.0116, -0.0207,  0.0218,  ...,  0.0219, -0.0174,  0.0221],
        [ 0.0098, -0.0111, -0.0045,  ..., -0.0186, -0.0138, -0.0218],
        ...,
        [-0.0109,  0.0140, -0.0118,  ..., -0.0310, -0.0329, -0.0185],
        [-0.0070,  0.0101, -0.0009,  ..., -0.0287,  0.0044,  0.0065],
        [-0.0155, -0.0129,  0.0072,  ...,  0.0329, -0.0223,  0.0173]],
       dtype=torch.float16), 'model.layers.17.mlp.gate_proj.weight': tensor([[-0.0341,  0.0291,  0.0243,  ...,  0.0059,  0.0021,  0.0031],
        [-0.0008,  0.0264,  0.0270,  ...,  0.0185,  0.0077,  0.0121],
        [ 0.0100,  0.0120, -0.0222,  ...,  0.0171,  0.0307, -0.0055],
        ...,
        [-0.0114, -0.0160, -0.0122,  ..., -0.0103, -0.0229, -0.0157],
        [ 0.0041,  0.0033,  0.0092,  ...,  0.0065,  0.0431, -0.0114],
        [-0.0032,  0.0208,  0.0144,  ..., -0.0138, -0.0018, -0.0032]],
       dtype=torch.float16), 'model.layers.17.mlp.up_proj.weight': tensor([[-0.0169, -0.0280, -0.0067,  ...,  0.0061,  0.0168, -0.0130],
        [-0.0231,  0.0152,  0.0278,  ...,  0.0003,  0.0016,  0.0020],
        [-0.0010, -0.0031,  0.0035,  ...,  0.0089, -0.0150,  0.0119],
        ...,
        [ 0.0138,  0.0168,  0.0068,  ...,  0.0064, -0.0204, -0.0130],
        [-0.0162, -0.0182, -0.0103,  ..., -0.0115, -0.0220,  0.0159],
        [-0.0032,  0.0038, -0.0083,  ...,  0.0034, -0.0360, -0.0131]],
       dtype=torch.float16), 'model.layers.17.mlp.down_proj.weight': tensor([[ 0.0260, -0.0225,  0.0134,  ...,  0.0120, -0.0079, -0.0022],
        [ 0.0285,  0.0301,  0.0086,  ...,  0.0063, -0.0083,  0.0336],
        [-0.0263, -0.0165, -0.0178,  ...,  0.0121, -0.0150, -0.0046],
        ...,
        [ 0.0067, -0.0222, -0.0068,  ..., -0.0141, -0.0051, -0.0367],
        [ 0.0015,  0.0053, -0.0114,  ..., -0.0275, -0.0274,  0.0174],
        [-0.0009, -0.0200,  0.0189,  ..., -0.0368, -0.0108,  0.0045]],
       dtype=torch.float16), 'model.layers.17.input_layernorm.weight': tensor([0.4316, 0.4336, 0.4043,  ..., 0.4238, 0.4277, 0.4062],
       dtype=torch.float16), 'model.layers.17.post_attention_layernorm.weight': tensor([0.3320, 0.3164, 0.3145,  ..., 0.3320, 0.3301, 0.3223],
       dtype=torch.float16), 'model.layers.18.self_attn.q_proj.weight': tensor([[ 0.0067,  0.0054,  0.0022,  ..., -0.0046, -0.0363,  0.0100],
        [ 0.0022, -0.0133,  0.0213,  ...,  0.0001,  0.0255,  0.0434],
        [ 0.0111, -0.0257, -0.0097,  ...,  0.0015, -0.0081,  0.0164],
        ...,
        [-0.0324,  0.0133,  0.0033,  ...,  0.0230,  0.0055,  0.0155],
        [ 0.0622, -0.0166, -0.0270,  ...,  0.0574,  0.0266,  0.0184],
        [ 0.0301,  0.0155,  0.0043,  ...,  0.0281,  0.0549, -0.0513]],
       dtype=torch.float16), 'model.layers.18.self_attn.k_proj.weight': tensor([[-0.0115,  0.0326, -0.0141,  ...,  0.0089, -0.0094, -0.0243],
        [ 0.0082, -0.0191,  0.0162,  ...,  0.0176,  0.0292,  0.0015],
        [ 0.0123, -0.0097, -0.0019,  ...,  0.0210, -0.0017,  0.0248],
        ...,
        [-0.1082, -0.0282, -0.0618,  ...,  0.0203, -0.0044, -0.0386],
        [ 0.0520,  0.0363, -0.0182,  ...,  0.0459,  0.0646, -0.0261],
        [-0.0487, -0.0503, -0.0435,  ...,  0.0343, -0.0235, -0.0319]],
       dtype=torch.float16), 'model.layers.18.self_attn.v_proj.weight': tensor([[-0.0296,  0.0286, -0.0176,  ...,  0.0053,  0.0276,  0.0051],
        [ 0.0173,  0.0070, -0.0124,  ..., -0.0175,  0.0382, -0.0023],
        [ 0.0001,  0.0193,  0.0009,  ...,  0.0046, -0.0021, -0.0077],
        ...,
        [ 0.0137,  0.0160, -0.0047,  ..., -0.0077, -0.0233,  0.0025],
        [ 0.0073, -0.0028,  0.0031,  ...,  0.0136,  0.0159,  0.0355],
        [-0.0068,  0.0012,  0.0111,  ..., -0.0062, -0.0200,  0.0024]],
       dtype=torch.float16), 'model.layers.18.self_attn.o_proj.weight': tensor([[-0.0180,  0.0188, -0.0144,  ...,  0.0118,  0.0222,  0.0198],
        [-0.0003, -0.0400,  0.0047,  ..., -0.0010, -0.0070, -0.0164],
        [ 0.0022, -0.0141,  0.0099,  ...,  0.0279,  0.0158,  0.0373],
        ...,
        [-0.0351, -0.0236, -0.0248,  ...,  0.0230,  0.0176, -0.0098],
        [ 0.0128,  0.0511,  0.0149,  ...,  0.0131, -0.0084, -0.0367],
        [-0.0119, -0.0472, -0.0218,  ..., -0.0158,  0.0139, -0.0140]],
       dtype=torch.float16), 'model.layers.18.mlp.gate_proj.weight': tensor([[ 0.0147, -0.0038,  0.0166,  ..., -0.0080,  0.0101, -0.0105],
        [-0.0428,  0.0071, -0.0162,  ..., -0.0086, -0.0150, -0.0096],
        [-0.0190,  0.0073,  0.0444,  ..., -0.0250,  0.0031,  0.0038],
        ...,
        [-0.0438, -0.0219, -0.0285,  ..., -0.0296, -0.0218, -0.0233],
        [ 0.0015,  0.0197,  0.0297,  ..., -0.0164, -0.0011,  0.0164],
        [ 0.0040, -0.0041,  0.0039,  ...,  0.0107, -0.0188, -0.0050]],
       dtype=torch.float16), 'model.layers.18.mlp.up_proj.weight': tensor([[ 0.0165,  0.0081,  0.0298,  ..., -0.0004,  0.0271, -0.0095],
        [-0.0201,  0.0243, -0.0282,  ..., -0.0057, -0.0087, -0.0003],
        [-0.0311, -0.0098,  0.0076,  ...,  0.0074,  0.0209,  0.0261],
        ...,
        [-0.0012,  0.0045,  0.0046,  ...,  0.0238, -0.0075,  0.0040],
        [-0.0094, -0.0048, -0.0210,  ...,  0.0134,  0.0343,  0.0362],
        [ 0.0087,  0.0248,  0.0111,  ..., -0.0163,  0.0135,  0.0152]],
       dtype=torch.float16), 'model.layers.18.mlp.down_proj.weight': tensor([[ 0.0152,  0.0034, -0.0323,  ...,  0.0311,  0.0165,  0.0073],
        [ 0.0117, -0.0078,  0.0196,  ...,  0.0007, -0.0016, -0.0021],
        [ 0.0172, -0.0250, -0.0335,  ...,  0.0177,  0.0036,  0.0148],
        ...,
        [-0.0127,  0.0210,  0.0102,  ...,  0.0230, -0.0081, -0.0087],
        [-0.0160,  0.0116,  0.0182,  ...,  0.0120,  0.0356,  0.0087],
        [-0.0091,  0.0257,  0.0244,  ..., -0.0073,  0.0167,  0.0157]],
       dtype=torch.float16), 'model.layers.18.input_layernorm.weight': tensor([0.4570, 0.4551, 0.4316,  ..., 0.4375, 0.4512, 0.4355],
       dtype=torch.float16), 'model.layers.18.post_attention_layernorm.weight': tensor([0.3477, 0.3340, 0.3320,  ..., 0.3477, 0.3496, 0.3457],
       dtype=torch.float16), 'model.layers.19.self_attn.q_proj.weight': tensor([[ 5.5275e-03,  7.6294e-03, -9.7961e-03,  ..., -1.0323e-02,
         -3.1209e-04,  8.8806e-03],
        [ 2.6894e-03, -2.5539e-03,  3.1719e-03,  ..., -4.7493e-03,
          2.9022e-02,  1.7868e-02],
        [ 5.2185e-03,  2.1896e-02,  4.5896e-05,  ...,  8.6498e-04,
          1.5182e-02,  3.0727e-03],
        ...,
        [-1.4160e-02, -1.4923e-02,  1.0290e-03,  ..., -4.4189e-02,
         -3.1805e-04,  2.4979e-02],
        [ 4.7226e-03,  4.8279e-02,  2.3041e-02,  ...,  5.4077e-02,
          2.9755e-02, -2.9358e-02],
        [-1.5991e-02,  4.9011e-02,  5.8014e-02,  ..., -6.6414e-03,
         -4.1382e-02, -1.4290e-02]], dtype=torch.float16), 'model.layers.19.self_attn.k_proj.weight': tensor([[ 0.0216,  0.0117,  0.0022,  ..., -0.0116, -0.0213, -0.0106],
        [-0.0142,  0.0180, -0.0159,  ...,  0.0100,  0.0034,  0.0251],
        [-0.0157,  0.0043, -0.0122,  ...,  0.0044,  0.0137,  0.0252],
        ...,
        [ 0.0005,  0.0502, -0.0095,  ..., -0.0208,  0.0299, -0.0225],
        [-0.0653, -0.0269, -0.0101,  ...,  0.0084,  0.0184, -0.0099],
        [-0.0202,  0.0115, -0.0150,  ..., -0.0266,  0.0129,  0.0399]],
       dtype=torch.float16), 'model.layers.19.self_attn.v_proj.weight': tensor([[-0.0011, -0.0055, -0.0055,  ..., -0.0020,  0.0005,  0.0070],
        [-0.0020,  0.0188, -0.0031,  ...,  0.0351, -0.0211,  0.0162],
        [-0.0448, -0.0359, -0.0080,  ..., -0.0085, -0.0002,  0.0056],
        ...,
        [ 0.0013, -0.0373, -0.0014,  ...,  0.0010, -0.0002, -0.0166],
        [ 0.0145, -0.0095, -0.0219,  ..., -0.0066, -0.0073, -0.0058],
        [-0.0033,  0.0275,  0.0008,  ..., -0.0254, -0.0120,  0.0062]],
       dtype=torch.float16), 'model.layers.19.self_attn.o_proj.weight': tensor([[ 0.0296, -0.0517,  0.0258,  ...,  0.0012,  0.0066, -0.0257],
        [ 0.0307, -0.0164, -0.0036,  ..., -0.0145, -0.0012, -0.0030],
        [-0.0033, -0.0176, -0.0195,  ...,  0.0010,  0.0150,  0.0012],
        ...,
        [ 0.0123, -0.0018,  0.0002,  ...,  0.0056, -0.0152,  0.0122],
        [ 0.0089, -0.0057, -0.0186,  ..., -0.0244, -0.0204,  0.0051],
        [ 0.0127,  0.0175,  0.0140,  ..., -0.0233, -0.0083,  0.0153]],
       dtype=torch.float16), 'model.layers.19.mlp.gate_proj.weight': tensor([[-0.0082,  0.0010,  0.0049,  ..., -0.0039,  0.0037, -0.0065],
        [ 0.0145,  0.0183,  0.0011,  ..., -0.0036,  0.0125, -0.0351],
        [-0.0169, -0.0121, -0.0127,  ..., -0.0433,  0.0002,  0.0285],
        ...,
        [-0.0016,  0.0101, -0.0004,  ..., -0.0291, -0.0092, -0.0010],
        [-0.0475, -0.0082,  0.0029,  ..., -0.0074, -0.0217,  0.0107],
        [-0.0205, -0.0197,  0.0153,  ...,  0.0069,  0.0052, -0.0020]],
       dtype=torch.float16), 'model.layers.19.mlp.up_proj.weight': tensor([[ 0.0020, -0.0107,  0.0096,  ...,  0.0065,  0.0100,  0.0032],
        [-0.0134, -0.0063, -0.0158,  ...,  0.0269, -0.0230, -0.0070],
        [ 0.0094,  0.0039,  0.0094,  ..., -0.0246, -0.0129,  0.0532],
        ...,
        [ 0.0142,  0.0140,  0.0074,  ...,  0.0136, -0.0170,  0.0311],
        [ 0.0013,  0.0262,  0.0249,  ..., -0.0094,  0.0361, -0.0004],
        [-0.0002, -0.0181, -0.0124,  ..., -0.0027,  0.0045,  0.0140]],
       dtype=torch.float16), 'model.layers.19.mlp.down_proj.weight': tensor([[-0.0026, -0.0278,  0.0015,  ...,  0.0057, -0.0235,  0.0278],
        [-0.0050, -0.0306, -0.0208,  ...,  0.0139,  0.0175, -0.0169],
        [-0.0209, -0.0261,  0.0290,  ...,  0.0159, -0.0008,  0.0071],
        ...,
        [-0.0104, -0.0050,  0.0274,  ...,  0.0129,  0.0162,  0.0012],
        [ 0.0065, -0.0093, -0.0501,  ...,  0.0219, -0.0086, -0.0152],
        [ 0.0041, -0.0093, -0.0342,  ...,  0.0006,  0.0090,  0.0042]],
       dtype=torch.float16), 'model.layers.19.input_layernorm.weight': tensor([0.4570, 0.4629, 0.4395,  ..., 0.4316, 0.4395, 0.4414],
       dtype=torch.float16), 'model.layers.19.post_attention_layernorm.weight': tensor([0.3613, 0.3477, 0.3457,  ..., 0.3574, 0.3555, 0.3594],
       dtype=torch.float16), 'model.layers.20.self_attn.q_proj.weight': tensor([[-3.3512e-03,  2.7599e-03,  2.2141e-02,  ...,  3.8643e-03,
          3.5381e-03, -2.3499e-02],
        [ 1.8127e-02, -2.1729e-02, -4.8876e-06,  ..., -6.9809e-03,
         -1.2131e-02,  1.7120e-02],
        [ 7.9117e-03, -6.8665e-03, -1.8326e-02,  ...,  1.7166e-02,
          7.0038e-03,  8.3780e-04],
        ...,
        [-3.1219e-02, -5.3162e-02,  1.0094e-02,  ..., -1.0918e-02,
          3.9520e-02,  1.1047e-02],
        [-8.0872e-02, -1.9455e-02,  1.1688e-02,  ...,  8.7585e-03,
          2.6505e-02,  8.3389e-03],
        [ 2.6978e-02,  2.4643e-03, -5.2071e-03,  ..., -1.9089e-02,
         -5.4512e-03, -1.3123e-03]], dtype=torch.float16), 'model.layers.20.self_attn.k_proj.weight': tensor([[-5.6038e-03,  7.3128e-03,  3.8834e-03,  ..., -1.6464e-02,
         -3.4750e-05,  3.6964e-03],
        [-3.7003e-04,  8.7585e-03,  4.4060e-03,  ..., -2.0161e-03,
          4.6120e-03,  1.1047e-02],
        [ 1.4694e-02,  2.8610e-03, -1.1185e-02,  ..., -1.5091e-02,
          1.4725e-03,  1.9836e-02],
        ...,
        [ 2.0256e-03,  4.9706e-03, -1.7044e-02,  ..., -2.3407e-02,
          2.5925e-02,  3.5919e-02],
        [-2.4094e-02,  2.4918e-02,  2.4490e-03,  ...,  2.1759e-02,
          3.0762e-02,  5.1605e-02],
        [-1.5228e-02, -3.0060e-02, -1.5793e-02,  ...,  2.0111e-02,
         -2.3468e-02,  5.2704e-02]], dtype=torch.float16), 'model.layers.20.self_attn.v_proj.weight': tensor([[-7.1526e-03, -1.8005e-02,  1.3290e-02,  ..., -2.7752e-03,
          1.9043e-02,  1.1086e-02],
        [-1.5945e-02, -3.7201e-02,  5.2223e-03,  ..., -1.2299e-02,
          3.4332e-04,  9.0942e-03],
        [-3.0174e-03, -1.3779e-02,  3.5763e-03,  ..., -2.5085e-02,
          9.9301e-05,  6.9046e-04],
        ...,
        [ 9.6893e-03, -1.2962e-02, -2.5940e-03,  ...,  2.4796e-02,
         -7.9269e-03,  9.0103e-03],
        [ 1.8799e-02,  1.4400e-03, -9.5062e-03,  ...,  8.0681e-04,
          1.1032e-02, -1.3542e-02],
        [ 2.3708e-03, -3.8452e-03,  2.4155e-02,  ..., -5.8403e-03,
         -1.1604e-02, -4.0283e-02]], dtype=torch.float16), 'model.layers.20.self_attn.o_proj.weight': tensor([[-0.0066,  0.0037,  0.0200,  ..., -0.0024,  0.0155, -0.0167],
        [ 0.0103, -0.0098, -0.0066,  ..., -0.0050, -0.0065,  0.0191],
        [ 0.0099, -0.0022, -0.0135,  ..., -0.0240,  0.0092,  0.0103],
        ...,
        [-0.0074, -0.0039,  0.0135,  ...,  0.0168, -0.0150,  0.0116],
        [-0.0101,  0.0031, -0.0113,  ...,  0.0121, -0.0273,  0.0036],
        [ 0.0107, -0.0183, -0.0039,  ...,  0.0065, -0.0230,  0.0195]],
       dtype=torch.float16), 'model.layers.20.mlp.gate_proj.weight': tensor([[ 0.0012, -0.0088, -0.0118,  ...,  0.0177, -0.0055,  0.0139],
        [-0.0275,  0.0091, -0.0060,  ..., -0.0098, -0.0143,  0.0149],
        [-0.0167, -0.0078,  0.0665,  ..., -0.0155,  0.0111, -0.0063],
        ...,
        [-0.0048, -0.0114,  0.0241,  ..., -0.0145,  0.0109, -0.0033],
        [ 0.0093,  0.0071,  0.0046,  ...,  0.0154,  0.0030,  0.0123],
        [-0.0032, -0.0308, -0.0070,  ...,  0.0059, -0.0142, -0.0134]],
       dtype=torch.float16), 'model.layers.20.mlp.up_proj.weight': tensor([[-0.0601, -0.0002, -0.0019,  ...,  0.0153, -0.0108, -0.0119],
        [-0.0098,  0.0006, -0.0098,  ..., -0.0502, -0.0143,  0.0372],
        [ 0.0060,  0.0302,  0.0182,  ...,  0.0070, -0.0175,  0.0047],
        ...,
        [-0.0139,  0.0211, -0.0016,  ..., -0.0180, -0.0043, -0.0030],
        [ 0.0155, -0.0318, -0.0148,  ...,  0.0031, -0.0208, -0.0377],
        [ 0.0145, -0.0241,  0.0311,  ..., -0.0039, -0.0222,  0.0036]],
       dtype=torch.float16), 'model.layers.20.mlp.down_proj.weight': tensor([[-0.0016,  0.0202, -0.0034,  ...,  0.0053, -0.0169, -0.0248],
        [ 0.0021,  0.0127, -0.0073,  ...,  0.0044, -0.0178,  0.0143],
        [-0.0127,  0.0180, -0.0242,  ..., -0.0042,  0.0238, -0.0053],
        ...,
        [-0.0375,  0.0276,  0.0056,  ...,  0.0026, -0.0002, -0.0114],
        [-0.0156,  0.0062, -0.0158,  ...,  0.0057,  0.0178, -0.0025],
        [ 0.0120, -0.0131,  0.0019,  ..., -0.0029, -0.0063, -0.0147]],
       dtype=torch.float16), 'model.layers.20.input_layernorm.weight': tensor([0.4590, 0.4688, 0.4395,  ..., 0.4414, 0.4375, 0.4590],
       dtype=torch.float16), 'model.layers.20.post_attention_layernorm.weight': tensor([0.3711, 0.3633, 0.3535,  ..., 0.3672, 0.3672, 0.3691],
       dtype=torch.float16), 'model.layers.21.self_attn.q_proj.weight': tensor([[-0.0138, -0.0057,  0.0144,  ..., -0.0153, -0.0030,  0.0070],
        [ 0.0252,  0.0060, -0.0012,  ...,  0.0031,  0.0002,  0.0141],
        [-0.0117, -0.0101,  0.0026,  ...,  0.0280,  0.0023,  0.0066],
        ...,
        [-0.0025, -0.0157,  0.0354,  ..., -0.0107, -0.0593,  0.0191],
        [-0.0115,  0.0166,  0.0210,  ...,  0.0295,  0.0328,  0.0014],
        [-0.0795, -0.0016, -0.0130,  ..., -0.0056,  0.0264, -0.0380]],
       dtype=torch.float16), 'model.layers.21.self_attn.k_proj.weight': tensor([[-1.3864e-04,  4.9858e-03, -3.4065e-03,  ...,  7.4348e-03,
          3.9625e-04,  1.0353e-02],
        [-8.3685e-05,  7.3128e-03,  1.9882e-02,  ...,  6.2561e-03,
          9.4681e-03,  8.8806e-03],
        [ 1.8494e-02,  2.9202e-03,  2.8900e-02,  ...,  1.5823e-02,
          1.2871e-02,  1.4816e-02],
        ...,
        [-1.8295e-02,  2.6428e-02,  1.5945e-03,  ...,  2.5818e-02,
         -1.9394e-02,  4.6265e-02],
        [ 2.0866e-03, -3.1281e-03, -1.4458e-02,  ..., -2.2232e-02,
          3.1250e-02,  1.6203e-03],
        [-1.8906e-02, -8.1329e-03, -3.1433e-02,  ...,  7.8888e-03,
         -7.5493e-03,  5.9235e-02]], dtype=torch.float16), 'model.layers.21.self_attn.v_proj.weight': tensor([[ 0.0032,  0.0054, -0.0003,  ...,  0.0005,  0.0223, -0.0286],
        [-0.0232,  0.0240, -0.0079,  ...,  0.0211, -0.0195,  0.0266],
        [ 0.0280, -0.0030,  0.0003,  ..., -0.0232,  0.0258, -0.0058],
        ...,
        [-0.0056, -0.0269,  0.0320,  ..., -0.0065,  0.0038, -0.0102],
        [-0.0154, -0.0090,  0.0156,  ...,  0.0048, -0.0052,  0.0086],
        [-0.0069,  0.0157, -0.0162,  ...,  0.0070, -0.0155, -0.0029]],
       dtype=torch.float16), 'model.layers.21.self_attn.o_proj.weight': tensor([[-0.0118, -0.0017,  0.0116,  ..., -0.0132,  0.0231,  0.0102],
        [-0.0058,  0.0267, -0.0098,  ..., -0.0189,  0.0061, -0.0112],
        [-0.0298, -0.0130,  0.0119,  ...,  0.0249,  0.0273,  0.0079],
        ...,
        [ 0.0198, -0.0042, -0.0136,  ...,  0.0248, -0.0006,  0.0144],
        [ 0.0152, -0.0136,  0.0135,  ..., -0.0006,  0.0018, -0.0185],
        [-0.0264,  0.0155, -0.0134,  ...,  0.0298, -0.0163,  0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.gate_proj.weight': tensor([[-0.0058, -0.0234,  0.0144,  ..., -0.0285,  0.0456,  0.0089],
        [ 0.0061,  0.0061,  0.0039,  ..., -0.0275,  0.0574,  0.0085],
        [ 0.0084,  0.0064,  0.0049,  ..., -0.0498,  0.0041, -0.0245],
        ...,
        [ 0.0102, -0.0292, -0.0215,  ...,  0.0331, -0.0270,  0.0024],
        [-0.0010,  0.0293,  0.0065,  ...,  0.0160, -0.0249,  0.0030],
        [ 0.0093, -0.0124, -0.0017,  ..., -0.0182,  0.0064, -0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.up_proj.weight': tensor([[ 0.0276, -0.0258, -0.0142,  ...,  0.0225,  0.0422, -0.0112],
        [-0.0261, -0.0107,  0.0040,  ...,  0.0379,  0.0453, -0.0010],
        [ 0.0133, -0.0011, -0.0018,  ...,  0.0067, -0.0079, -0.0061],
        ...,
        [-0.0461, -0.0002,  0.0137,  ...,  0.0162, -0.0095, -0.0118],
        [-0.0100, -0.0107,  0.0042,  ..., -0.0188, -0.0023,  0.0027],
        [-0.0051, -0.0337, -0.0248,  ..., -0.0035, -0.0055, -0.0260]],
       dtype=torch.float16), 'model.layers.21.mlp.down_proj.weight': tensor([[ 0.0117,  0.0132,  0.0028,  ...,  0.0198,  0.0068,  0.0062],
        [ 0.0095, -0.0029, -0.0151,  ...,  0.0037, -0.0319, -0.0163],
        [-0.0061,  0.0059,  0.0132,  ..., -0.0084,  0.0412,  0.0299],
        ...,
        [-0.0106,  0.0375,  0.0182,  ..., -0.0093, -0.0024,  0.0179],
        [ 0.0125,  0.0007, -0.0043,  ..., -0.0493, -0.0052,  0.0049],
        [ 0.0089,  0.0014,  0.0242,  ..., -0.0152,  0.0267, -0.0278]],
       dtype=torch.float16), 'model.layers.21.input_layernorm.weight': tensor([0.4805, 0.4883, 0.4688,  ..., 0.4609, 0.4805, 0.4824],
       dtype=torch.float16), 'model.layers.21.post_attention_layernorm.weight': tensor([0.3770, 0.3730, 0.3652,  ..., 0.3848, 0.3789, 0.3828],
       dtype=torch.float16), 'model.layers.22.self_attn.q_proj.weight': tensor([[-0.0249, -0.0096, -0.0046,  ...,  0.0535, -0.0391,  0.0201],
        [-0.0361, -0.0200, -0.0063,  ..., -0.0361,  0.0211, -0.0515],
        [-0.0322,  0.0232, -0.0146,  ...,  0.0286,  0.0173, -0.0100],
        ...,
        [ 0.0094,  0.0199,  0.0122,  ...,  0.0116,  0.0576, -0.0013],
        [-0.0323,  0.0064, -0.0220,  ...,  0.0465,  0.0088, -0.0131],
        [ 0.0380, -0.0125,  0.0065,  ..., -0.0505,  0.0111,  0.0195]],
       dtype=torch.float16), 'model.layers.22.self_attn.k_proj.weight': tensor([[-0.0130, -0.0065,  0.0037,  ...,  0.0139, -0.0164, -0.0157],
        [ 0.0106, -0.0099,  0.0312,  ..., -0.0320,  0.0375, -0.0140],
        [-0.0207,  0.0286, -0.0425,  ...,  0.0614,  0.0035, -0.0076],
        ...,
        [ 0.0210,  0.0074, -0.0286,  ..., -0.0204, -0.0135,  0.0172],
        [-0.0150, -0.0424,  0.0025,  ..., -0.0002, -0.0132, -0.0070],
        [ 0.0240, -0.0025,  0.0283,  ...,  0.0377, -0.0425,  0.0131]],
       dtype=torch.float16), 'model.layers.22.self_attn.v_proj.weight': tensor([[-0.0201,  0.0126, -0.0017,  ..., -0.0395, -0.0264,  0.0152],
        [-0.0346, -0.0108,  0.0072,  ..., -0.0269, -0.0413, -0.0159],
        [ 0.0243, -0.0267, -0.0040,  ...,  0.0528, -0.0026, -0.0139],
        ...,
        [-0.0104, -0.0462, -0.0226,  ...,  0.0124, -0.0114,  0.0218],
        [-0.0375, -0.0086,  0.0181,  ..., -0.0198,  0.0020, -0.0155],
        [ 0.0007,  0.0152, -0.0433,  ...,  0.0020, -0.0053,  0.0264]],
       dtype=torch.float16), 'model.layers.22.self_attn.o_proj.weight': tensor([[ 0.0263,  0.0156, -0.0218,  ..., -0.0026, -0.0353,  0.0123],
        [ 0.0242,  0.0126,  0.0108,  ...,  0.0045, -0.0100, -0.0247],
        [ 0.0046,  0.0026, -0.0081,  ..., -0.0232,  0.0110,  0.0107],
        ...,
        [-0.0008, -0.0238, -0.0129,  ..., -0.0138, -0.0166,  0.0042],
        [ 0.0259, -0.0104, -0.0196,  ..., -0.0260, -0.0027,  0.0137],
        [ 0.0039, -0.0258,  0.0213,  ...,  0.0115,  0.0122,  0.0111]],
       dtype=torch.float16), 'model.layers.22.mlp.gate_proj.weight': tensor([[-0.0284, -0.0156,  0.0184,  ...,  0.0108,  0.0197, -0.0452],
        [ 0.0226, -0.0165,  0.0014,  ...,  0.0043,  0.0029,  0.0221],
        [ 0.0005, -0.0069,  0.0054,  ...,  0.0142,  0.0002, -0.0003],
        ...,
        [-0.0043, -0.0079,  0.0014,  ..., -0.0152,  0.0073,  0.0022],
        [ 0.0095,  0.0165, -0.0293,  ..., -0.0035,  0.0127, -0.0289],
        [-0.0101,  0.0012,  0.0053,  ..., -0.0148,  0.0278,  0.0245]],
       dtype=torch.float16), 'model.layers.22.mlp.up_proj.weight': tensor([[ 0.0293,  0.0162, -0.0013,  ...,  0.0170,  0.0276,  0.0071],
        [ 0.0198,  0.0076,  0.0164,  ..., -0.0117, -0.0078,  0.0030],
        [ 0.0086, -0.0282, -0.0375,  ...,  0.0255,  0.0104,  0.0061],
        ...,
        [-0.0032, -0.0006, -0.0185,  ..., -0.0040,  0.0057,  0.0067],
        [ 0.0126, -0.0111, -0.0286,  ..., -0.0226,  0.0108, -0.0270],
        [-0.0014,  0.0023, -0.0036,  ..., -0.0440, -0.0598,  0.0154]],
       dtype=torch.float16), 'model.layers.22.mlp.down_proj.weight': tensor([[ 1.3527e-02, -5.1918e-03,  1.2299e-02,  ..., -1.8967e-02,
         -4.1428e-03, -3.6041e-02],
        [ 5.5885e-03,  2.6581e-02, -4.9362e-03,  ..., -1.1017e-02,
          1.4084e-02, -2.6627e-02],
        [-9.6512e-03,  3.9363e-04,  4.1962e-03,  ...,  1.2886e-02,
          4.5013e-03,  1.7517e-02],
        ...,
        [ 1.8250e-02, -8.5297e-03, -4.5288e-02,  ..., -2.8934e-03,
         -1.2947e-02, -1.7014e-02],
        [-1.1414e-02, -4.8767e-02,  1.1642e-02,  ...,  1.9028e-02,
         -2.7069e-02,  3.1433e-02],
        [ 1.4130e-02,  3.7551e-06, -3.1067e-02,  ..., -3.3903e-04,
         -1.8875e-02,  2.1286e-03]], dtype=torch.float16), 'model.layers.22.input_layernorm.weight': tensor([0.4883, 0.4922, 0.4805,  ..., 0.4688, 0.5000, 0.4902],
       dtype=torch.float16), 'model.layers.22.post_attention_layernorm.weight': tensor([0.3867, 0.3848, 0.3848,  ..., 0.3965, 0.3945, 0.3965],
       dtype=torch.float16), 'model.layers.23.self_attn.q_proj.weight': tensor([[-0.0039, -0.0179,  0.0076,  ..., -0.0155, -0.0002,  0.0023],
        [ 0.0042,  0.0015,  0.0140,  ..., -0.0166, -0.0002,  0.0083],
        [-0.0038,  0.0028,  0.0219,  ...,  0.0002, -0.0167,  0.0066],
        ...,
        [-0.0211,  0.0670,  0.0119,  ..., -0.0314, -0.0684, -0.0263],
        [-0.0411, -0.0311,  0.0199,  ..., -0.0232,  0.0020,  0.0060],
        [ 0.0047, -0.0559, -0.0093,  ...,  0.0072,  0.0403, -0.0026]],
       dtype=torch.float16), 'model.layers.23.self_attn.k_proj.weight': tensor([[-0.0030,  0.0121,  0.0090,  ...,  0.0010, -0.0083,  0.0059],
        [-0.0224,  0.0057, -0.0117,  ...,  0.0093,  0.0254,  0.0036],
        [ 0.0182,  0.0078, -0.0185,  ...,  0.0181,  0.0016, -0.0107],
        ...,
        [ 0.0067,  0.0374,  0.0580,  ..., -0.0332, -0.0120, -0.0131],
        [ 0.0034, -0.0352, -0.0113,  ..., -0.0232, -0.0226,  0.0194],
        [-0.0173, -0.0081, -0.0259,  ...,  0.0043,  0.0060, -0.0084]],
       dtype=torch.float16), 'model.layers.23.self_attn.v_proj.weight': tensor([[-0.0028,  0.0343, -0.0120,  ..., -0.0097, -0.0016, -0.0112],
        [-0.0093, -0.0038, -0.0190,  ..., -0.0033, -0.0097,  0.0105],
        [ 0.0111, -0.0211, -0.0208,  ...,  0.0130, -0.0508, -0.0305],
        ...,
        [ 0.0070,  0.0084,  0.0091,  ..., -0.0020,  0.0338,  0.0089],
        [ 0.0261,  0.0316, -0.0011,  ...,  0.0070,  0.0022, -0.0127],
        [-0.0201, -0.0131, -0.0540,  ...,  0.0057,  0.0076, -0.0381]],
       dtype=torch.float16), 'model.layers.23.self_attn.o_proj.weight': tensor([[-0.0019,  0.0019, -0.0202,  ..., -0.0179,  0.0104, -0.0070],
        [-0.0127, -0.0213, -0.0022,  ..., -0.0004,  0.0100, -0.0021],
        [ 0.0130,  0.0094,  0.0306,  ..., -0.0228, -0.0026, -0.0276],
        ...,
        [ 0.0290, -0.0114,  0.0348,  ..., -0.0162,  0.0113, -0.0013],
        [-0.0044,  0.0202, -0.0200,  ...,  0.0056, -0.0164,  0.0007],
        [ 0.0013, -0.0023, -0.0177,  ..., -0.0060,  0.0059, -0.0296]],
       dtype=torch.float16), 'model.layers.23.mlp.gate_proj.weight': tensor([[-1.1848e-02,  3.4424e-02, -1.0048e-02,  ..., -7.0152e-03,
          3.2776e-02,  9.2316e-03],
        [-1.4702e-02,  4.7729e-02, -1.7593e-02,  ...,  7.1678e-03,
         -1.8631e-02,  2.5070e-02],
        [-3.2349e-02,  1.4786e-02,  2.6913e-03,  ...,  1.5274e-02,
         -6.7444e-02,  1.2131e-02],
        ...,
        [-3.1548e-03,  1.9089e-02,  3.1509e-03,  ..., -8.1863e-03,
          7.2556e-03, -2.4643e-03],
        [-2.0828e-02,  3.8971e-02,  2.9430e-03,  ...,  3.3021e-05,
          7.8201e-03, -2.8381e-02],
        [ 8.8692e-04,  8.5144e-03,  1.6830e-02,  ..., -7.6561e-03,
          1.5450e-02, -1.6495e-02]], dtype=torch.float16), 'model.layers.23.mlp.up_proj.weight': tensor([[ 0.0283,  0.0066,  0.0351,  ...,  0.0134, -0.0322, -0.0074],
        [-0.0003,  0.0065, -0.0196,  ..., -0.0043, -0.0111,  0.0061],
        [-0.0177,  0.0038, -0.0218,  ...,  0.0182,  0.0106, -0.0052],
        ...,
        [-0.0084, -0.0166,  0.0116,  ...,  0.0093,  0.0408,  0.0053],
        [ 0.0036,  0.0078, -0.0382,  ...,  0.0106,  0.0070,  0.0220],
        [ 0.0014,  0.0079, -0.0071,  ...,  0.0070, -0.0126,  0.0127]],
       dtype=torch.float16), 'model.layers.23.mlp.down_proj.weight': tensor([[-0.0008,  0.0069, -0.0182,  ..., -0.0434, -0.0227,  0.0330],
        [-0.0012,  0.0231, -0.0064,  ...,  0.0257,  0.0306,  0.0021],
        [-0.0066, -0.0139, -0.0233,  ...,  0.0102,  0.0330, -0.0052],
        ...,
        [ 0.0001, -0.0050,  0.0135,  ...,  0.0180,  0.0037, -0.0187],
        [ 0.0296, -0.0114, -0.0007,  ..., -0.0026,  0.0101,  0.0058],
        [ 0.0031, -0.0307, -0.0152,  ..., -0.0104,  0.0204, -0.0025]],
       dtype=torch.float16), 'model.layers.23.input_layernorm.weight': tensor([0.5156, 0.5312, 0.5117,  ..., 0.5039, 0.5352, 0.5273],
       dtype=torch.float16), 'model.layers.23.post_attention_layernorm.weight': tensor([0.4043, 0.4023, 0.3965,  ..., 0.4043, 0.4121, 0.4062],
       dtype=torch.float16), 'model.layers.24.self_attn.q_proj.weight': tensor([[ 0.0204, -0.0176,  0.0145,  ...,  0.0364, -0.0300,  0.0106],
        [ 0.0215,  0.0088,  0.0012,  ..., -0.0026,  0.0186, -0.0139],
        [-0.0056, -0.0111, -0.0277,  ...,  0.0088, -0.0132,  0.0202],
        ...,
        [-0.0147,  0.0136, -0.0193,  ...,  0.0181, -0.0004, -0.0123],
        [-0.0288,  0.0078,  0.0070,  ...,  0.0100, -0.0323, -0.0062],
        [-0.0231, -0.0385, -0.0181,  ..., -0.0132,  0.0128,  0.0677]],
       dtype=torch.float16), 'model.layers.24.self_attn.k_proj.weight': tensor([[ 0.0235, -0.0035, -0.0125,  ...,  0.0110, -0.0008,  0.0021],
        [ 0.0118, -0.0169,  0.0035,  ..., -0.0216,  0.0245,  0.0066],
        [ 0.0097,  0.0045, -0.0445,  ...,  0.0204,  0.0171, -0.0175],
        ...,
        [ 0.0344,  0.0036,  0.0493,  ...,  0.0161,  0.0179, -0.0516],
        [-0.0119,  0.0177,  0.0127,  ...,  0.0320, -0.0181,  0.0027],
        [-0.0318, -0.0295, -0.0190,  ...,  0.0139, -0.0048,  0.0518]],
       dtype=torch.float16), 'model.layers.24.self_attn.v_proj.weight': tensor([[ 0.0212, -0.0251, -0.0028,  ..., -0.0041, -0.0040,  0.0113],
        [ 0.0288, -0.0173, -0.0054,  ..., -0.0646, -0.0470, -0.0240],
        [-0.0579, -0.0169, -0.0134,  ..., -0.0156, -0.0121, -0.0027],
        ...,
        [ 0.0011, -0.0192,  0.0171,  ...,  0.0272,  0.0067,  0.0217],
        [-0.0034, -0.0157, -0.0141,  ...,  0.0332, -0.0036,  0.0038],
        [ 0.0172,  0.0228,  0.0187,  ...,  0.0274, -0.0135, -0.0108]],
       dtype=torch.float16), 'model.layers.24.self_attn.o_proj.weight': tensor([[-0.0016,  0.0144,  0.0280,  ...,  0.0066, -0.0051, -0.0141],
        [-0.0118,  0.0308,  0.0156,  ...,  0.0195,  0.0282, -0.0186],
        [-0.0057, -0.0029,  0.0094,  ..., -0.0232,  0.0084, -0.0049],
        ...,
        [ 0.0045,  0.0179,  0.0119,  ..., -0.0027, -0.0031, -0.0005],
        [ 0.0508,  0.0096, -0.0061,  ...,  0.0075, -0.0257, -0.0106],
        [ 0.0026,  0.0155,  0.0109,  ...,  0.0046, -0.0261,  0.0131]],
       dtype=torch.float16), 'model.layers.24.mlp.gate_proj.weight': tensor([[-0.0267, -0.0104,  0.0093,  ..., -0.0031, -0.0058,  0.0011],
        [ 0.0075, -0.0302, -0.0231,  ...,  0.0075,  0.0110, -0.0131],
        [ 0.0014, -0.0466,  0.0257,  ...,  0.0015, -0.0532, -0.0207],
        ...,
        [ 0.0042, -0.0358, -0.0088,  ...,  0.0080,  0.0152, -0.0062],
        [ 0.0094,  0.0158,  0.0041,  ...,  0.0043,  0.0011,  0.0048],
        [-0.0410,  0.0326,  0.0009,  ...,  0.0294, -0.0074, -0.0473]],
       dtype=torch.float16), 'model.layers.24.mlp.up_proj.weight': tensor([[ 0.0016, -0.0057,  0.0201,  ...,  0.0262,  0.0025,  0.0263],
        [-0.0026,  0.0136, -0.0327,  ..., -0.0081, -0.0044, -0.0171],
        [ 0.0114, -0.0520,  0.0097,  ...,  0.0402,  0.0179, -0.0341],
        ...,
        [ 0.0115, -0.0207, -0.0147,  ..., -0.0067,  0.0112,  0.0111],
        [ 0.0412, -0.0033,  0.0132,  ...,  0.0025,  0.0054, -0.0100],
        [-0.0056, -0.0197,  0.0203,  ...,  0.0303,  0.0333,  0.0164]],
       dtype=torch.float16), 'model.layers.24.mlp.down_proj.weight': tensor([[-0.0052, -0.0114, -0.0357,  ...,  0.0015,  0.0022, -0.0194],
        [ 0.0278, -0.0030,  0.0175,  ..., -0.0015,  0.0048, -0.0508],
        [ 0.0195,  0.0135, -0.0284,  ...,  0.0095,  0.0215,  0.0078],
        ...,
        [-0.0092,  0.0149, -0.0204,  ..., -0.0330, -0.0109, -0.0146],
        [ 0.0112,  0.0248,  0.0120,  ...,  0.0257, -0.0255,  0.0133],
        [-0.0171, -0.0086,  0.0033,  ...,  0.0172, -0.0154, -0.0324]],
       dtype=torch.float16), 'model.layers.24.input_layernorm.weight': tensor([0.4980, 0.5273, 0.5195,  ..., 0.4863, 0.5234, 0.5156],
       dtype=torch.float16), 'model.layers.24.post_attention_layernorm.weight': tensor([0.4219, 0.4180, 0.4180,  ..., 0.4199, 0.4258, 0.4219],
       dtype=torch.float16), 'model.layers.25.self_attn.q_proj.weight': tensor([[ 1.7204e-03, -1.9974e-02, -2.5269e-02,  ...,  1.2192e-02,
         -9.5139e-03,  4.5357e-03],
        [-1.3947e-02,  3.5877e-03,  2.3804e-02,  ..., -1.4412e-02,
         -3.4485e-03,  2.4557e-05],
        [ 9.1629e-03,  8.6136e-03,  3.9368e-03,  ..., -1.1436e-02,
         -2.0157e-02, -1.5068e-02],
        ...,
        [ 5.5756e-02,  4.5746e-02,  2.2964e-03,  ...,  4.9858e-03,
          1.5762e-02, -2.6688e-02],
        [-6.3721e-02, -5.0293e-02, -1.2497e-02,  ..., -1.0338e-02,
         -2.1088e-02,  4.0932e-03],
        [ 3.9978e-02, -4.3365e-02, -2.2217e-02,  ...,  3.9279e-05,
          1.0757e-02, -2.6917e-02]], dtype=torch.float16), 'model.layers.25.self_attn.k_proj.weight': tensor([[-5.6648e-03, -1.3237e-02, -1.2611e-02,  ...,  1.5726e-03,
          1.6232e-03,  1.4572e-03],
        [-1.4183e-02, -1.4297e-02,  2.7120e-05,  ..., -3.4618e-03,
         -2.1515e-02,  7.6561e-03],
        [-8.5354e-04,  1.9426e-03,  4.9133e-03,  ...,  6.0310e-03,
         -6.0654e-03,  7.2212e-03],
        ...,
        [ 1.3847e-02,  4.8248e-02, -9.6283e-03,  ..., -5.4504e-02,
         -5.6427e-02,  3.7598e-02],
        [ 3.4454e-02, -3.4393e-02,  4.3602e-03,  ..., -8.3771e-03,
          2.8229e-03,  1.0277e-02],
        [-7.9346e-03, -2.7908e-02,  3.2768e-03,  ...,  3.6316e-02,
          8.8501e-03, -2.9388e-02]], dtype=torch.float16), 'model.layers.25.self_attn.v_proj.weight': tensor([[ 0.0173,  0.0201,  0.0084,  ...,  0.0248, -0.0133, -0.0128],
        [-0.0143, -0.0107,  0.0099,  ...,  0.0090, -0.0273, -0.0127],
        [-0.0150,  0.0164, -0.0202,  ..., -0.0099,  0.0054, -0.0090],
        ...,
        [-0.0186, -0.0324, -0.0026,  ...,  0.0150,  0.0097,  0.0189],
        [-0.0152,  0.0089,  0.0258,  ..., -0.0068,  0.0044, -0.0216],
        [-0.0386, -0.0105, -0.0145,  ...,  0.0065,  0.0192,  0.0297]],
       dtype=torch.float16), 'model.layers.25.self_attn.o_proj.weight': tensor([[ 1.9470e-02,  1.0475e-02,  1.3229e-02,  ...,  1.4595e-02,
          2.8362e-03,  3.7861e-03],
        [-2.6352e-02, -9.8953e-03, -1.6998e-02,  ...,  2.6093e-02,
         -7.1945e-03, -1.3523e-03],
        [-8.1863e-03, -1.5879e-03,  2.5925e-02,  ..., -1.9821e-02,
         -1.3336e-02, -1.3371e-03],
        ...,
        [-1.3893e-02,  2.3819e-02, -2.7676e-03,  ...,  1.0544e-02,
          1.3359e-02,  2.7084e-02],
        [-4.1842e-05, -2.7664e-02, -3.7750e-02,  ..., -2.3926e-02,
         -1.6037e-02,  2.2125e-03],
        [-2.4704e-02, -8.4839e-03, -1.3412e-02,  ..., -3.7964e-02,
         -2.0554e-02, -1.3344e-02]], dtype=torch.float16), 'model.layers.25.mlp.gate_proj.weight': tensor([[ 0.0037, -0.0402,  0.0397,  ..., -0.0020, -0.0228,  0.0070],
        [-0.0239, -0.0074, -0.0153,  ...,  0.0345,  0.0486,  0.0262],
        [-0.0017,  0.0171, -0.0012,  ...,  0.0176,  0.0161,  0.0310],
        ...,
        [-0.0347,  0.0086,  0.0019,  ..., -0.0027, -0.0130,  0.0004],
        [ 0.0218,  0.0088,  0.0610,  ...,  0.0170,  0.0224,  0.0062],
        [-0.0047, -0.0022, -0.0174,  ...,  0.0450,  0.0030, -0.0100]],
       dtype=torch.float16), 'model.layers.25.mlp.up_proj.weight': tensor([[-0.0265, -0.0114,  0.0169,  ...,  0.0016,  0.0052, -0.0100],
        [-0.0138, -0.0033,  0.0076,  ..., -0.0056,  0.0163,  0.0114],
        [ 0.0298,  0.0056,  0.0224,  ..., -0.0136, -0.0282, -0.0026],
        ...,
        [ 0.0102,  0.0049,  0.0475,  ...,  0.0056, -0.0394, -0.0210],
        [-0.0387, -0.0015, -0.0307,  ..., -0.0457, -0.0228, -0.0002],
        [-0.0147, -0.0097,  0.0229,  ...,  0.0258, -0.0055,  0.0242]],
       dtype=torch.float16), 'model.layers.25.mlp.down_proj.weight': tensor([[ 0.0289, -0.0159,  0.0110,  ...,  0.0204, -0.0067,  0.0310],
        [-0.0150, -0.0020,  0.0045,  ...,  0.0100, -0.0012,  0.0230],
        [ 0.0123,  0.0103, -0.0082,  ..., -0.0229,  0.0118, -0.0181],
        ...,
        [ 0.0188, -0.0142, -0.0232,  ..., -0.0466, -0.0010,  0.0237],
        [ 0.0065, -0.0114,  0.0031,  ...,  0.0045,  0.0039,  0.0058],
        [-0.0111, -0.0243,  0.0161,  ..., -0.0298, -0.0061, -0.0051]],
       dtype=torch.float16), 'model.layers.25.input_layernorm.weight': tensor([0.5547, 0.5703, 0.5547,  ..., 0.5547, 0.5742, 0.5625],
       dtype=torch.float16), 'model.layers.25.post_attention_layernorm.weight': tensor([0.4316, 0.4316, 0.4297,  ..., 0.4355, 0.4336, 0.4395],
       dtype=torch.float16), 'model.layers.26.self_attn.q_proj.weight': tensor([[ 0.0299, -0.0067, -0.0090,  ..., -0.0101,  0.0408,  0.0010],
        [-0.0050, -0.0182,  0.0142,  ...,  0.0062, -0.0230,  0.0177],
        [-0.0064,  0.0024,  0.0114,  ...,  0.0050, -0.0381, -0.0195],
        ...,
        [ 0.0009, -0.0125, -0.0078,  ...,  0.0158,  0.0216,  0.0021],
        [ 0.0070, -0.0182, -0.0230,  ...,  0.0060, -0.0005, -0.0075],
        [-0.0146,  0.0520,  0.0271,  ..., -0.0072, -0.0645, -0.0416]],
       dtype=torch.float16), 'model.layers.26.self_attn.k_proj.weight': tensor([[ 0.0220,  0.0199, -0.0121,  ..., -0.0308,  0.0384,  0.0029],
        [-0.0267,  0.0055,  0.0148,  ...,  0.0016,  0.0168,  0.0291],
        [ 0.0129,  0.0286,  0.0004,  ..., -0.0190, -0.0591, -0.0098],
        ...,
        [ 0.0247,  0.0246,  0.0012,  ..., -0.0466, -0.0545,  0.0259],
        [-0.0216, -0.0389, -0.0074,  ...,  0.0483,  0.0228, -0.0051],
        [-0.0171,  0.0094, -0.0132,  ...,  0.0006, -0.0198, -0.0154]],
       dtype=torch.float16), 'model.layers.26.self_attn.v_proj.weight': tensor([[ 0.0506, -0.0262, -0.0245,  ..., -0.0152,  0.0105, -0.0191],
        [-0.0491, -0.0213,  0.0254,  ...,  0.0101, -0.0062,  0.0016],
        [ 0.0013, -0.0020, -0.0238,  ..., -0.0061,  0.0042, -0.0306],
        ...,
        [-0.0236, -0.0176, -0.0008,  ...,  0.0428, -0.0050,  0.0086],
        [ 0.0039, -0.0365, -0.0094,  ..., -0.0166, -0.0242, -0.0042],
        [ 0.0092,  0.0188, -0.0045,  ...,  0.0071,  0.0064,  0.0172]],
       dtype=torch.float16), 'model.layers.26.self_attn.o_proj.weight': tensor([[ 0.0108, -0.0005, -0.0306,  ...,  0.0052,  0.0149,  0.0272],
        [ 0.0067,  0.0455,  0.0062,  ..., -0.0016,  0.0462, -0.0053],
        [ 0.0013,  0.0102, -0.0247,  ..., -0.0226,  0.0037, -0.0018],
        ...,
        [ 0.0307,  0.0040,  0.0108,  ..., -0.0002,  0.0182,  0.0043],
        [-0.0128,  0.0049, -0.0096,  ...,  0.0135, -0.0017, -0.0425],
        [ 0.0257,  0.0072,  0.0050,  ..., -0.0276,  0.0283, -0.0160]],
       dtype=torch.float16), 'model.layers.26.mlp.gate_proj.weight': tensor([[ 0.0187,  0.0045,  0.0131,  ...,  0.0258,  0.0262, -0.0261],
        [-0.0062,  0.0102, -0.0258,  ..., -0.0255, -0.0266,  0.0190],
        [ 0.0022, -0.0109,  0.0007,  ...,  0.0060,  0.0038, -0.0172],
        ...,
        [-0.0065,  0.0356, -0.0078,  ..., -0.0015, -0.0380, -0.0219],
        [-0.0150,  0.0138,  0.0250,  ...,  0.0159,  0.0240,  0.0123],
        [ 0.0182, -0.0038, -0.0058,  ..., -0.0301, -0.0062, -0.0043]],
       dtype=torch.float16), 'model.layers.26.mlp.up_proj.weight': tensor([[-0.0168,  0.0401,  0.0018,  ...,  0.0049, -0.0029, -0.0195],
        [-0.0410, -0.0193,  0.0116,  ...,  0.0265, -0.0069,  0.0175],
        [ 0.0082, -0.0065, -0.0241,  ...,  0.0146, -0.0218, -0.0152],
        ...,
        [ 0.0058, -0.0324,  0.0059,  ...,  0.0126,  0.0300, -0.0139],
        [-0.0445,  0.0100,  0.0505,  ...,  0.0299, -0.0133,  0.0091],
        [ 0.0003, -0.0191,  0.0266,  ..., -0.0121,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.layers.26.mlp.down_proj.weight': tensor([[-0.0157, -0.0151, -0.0184,  ...,  0.0317,  0.0165,  0.0026],
        [ 0.0194,  0.0122,  0.0013,  ...,  0.0555,  0.0187, -0.0188],
        [-0.0182,  0.0041, -0.0274,  ..., -0.0111,  0.0171,  0.0083],
        ...,
        [-0.0175, -0.0124, -0.0203,  ...,  0.0105,  0.0436, -0.0020],
        [-0.0128, -0.0142, -0.0195,  ...,  0.0095,  0.0033,  0.0230],
        [ 0.0049, -0.0129, -0.0006,  ...,  0.0101,  0.0221,  0.0164]],
       dtype=torch.float16), 'model.layers.26.input_layernorm.weight': tensor([0.5312, 0.5469, 0.5469,  ..., 0.5234, 0.5508, 0.5547],
       dtype=torch.float16), 'model.layers.26.post_attention_layernorm.weight': tensor([0.4492, 0.4492, 0.4375,  ..., 0.4512, 0.4590, 0.4590],
       dtype=torch.float16), 'model.layers.27.self_attn.q_proj.weight': tensor([[-0.0292,  0.0145,  0.0077,  ..., -0.0038,  0.0122,  0.0435],
        [-0.0134,  0.0433,  0.0299,  ..., -0.0242,  0.0111,  0.0059],
        [-0.0217, -0.0236,  0.0096,  ...,  0.0025, -0.0223,  0.0289],
        ...,
        [-0.0505,  0.0273, -0.0095,  ...,  0.0185, -0.0201, -0.0225],
        [-0.0039,  0.0271,  0.0072,  ...,  0.0084,  0.0002,  0.0258],
        [-0.0235, -0.0104,  0.0114,  ...,  0.0226,  0.0154, -0.0077]],
       dtype=torch.float16), 'model.layers.27.self_attn.k_proj.weight': tensor([[-0.0173, -0.0195,  0.0098,  ..., -0.0015, -0.0104,  0.0059],
        [-0.0029,  0.0090,  0.0194,  ...,  0.0424, -0.0081, -0.0110],
        [ 0.0017, -0.0138,  0.0081,  ..., -0.0129,  0.0021, -0.0088],
        ...,
        [-0.0041, -0.0153,  0.0362,  ...,  0.0069, -0.0344, -0.0087],
        [ 0.0248, -0.0192, -0.0473,  ...,  0.0660, -0.0128,  0.0439],
        [ 0.0315,  0.0143, -0.0021,  ..., -0.0374, -0.0376,  0.0114]],
       dtype=torch.float16), 'model.layers.27.self_attn.v_proj.weight': tensor([[ 0.0174, -0.0144, -0.0334,  ...,  0.0311,  0.0319, -0.0054],
        [ 0.0185,  0.0108,  0.0118,  ...,  0.0023, -0.0246,  0.0214],
        [-0.0263, -0.0055,  0.0169,  ..., -0.0106,  0.0546, -0.0242],
        ...,
        [ 0.0146, -0.0203, -0.0192,  ...,  0.0176, -0.0095, -0.0034],
        [ 0.0059, -0.0240, -0.0200,  ..., -0.0100, -0.0106, -0.0184],
        [ 0.0211, -0.0241, -0.0149,  ..., -0.0229, -0.0193,  0.0111]],
       dtype=torch.float16), 'model.layers.27.self_attn.o_proj.weight': tensor([[ 0.0038, -0.0119,  0.0095,  ...,  0.0242,  0.0067, -0.0269],
        [ 0.0054,  0.0286, -0.0241,  ..., -0.0172, -0.0162,  0.0058],
        [-0.0047, -0.0113, -0.0132,  ...,  0.0162,  0.0009, -0.0092],
        ...,
        [ 0.0251, -0.0114, -0.0128,  ...,  0.0111,  0.0484, -0.0008],
        [ 0.0368, -0.0221, -0.0091,  ..., -0.0011, -0.0006,  0.0184],
        [ 0.0446,  0.0125,  0.0281,  ..., -0.0113, -0.0002, -0.0220]],
       dtype=torch.float16), 'model.layers.27.mlp.gate_proj.weight': tensor([[ 0.0450,  0.0128, -0.0067,  ...,  0.0097,  0.0032, -0.0147],
        [-0.0158,  0.0018, -0.0322,  ...,  0.0303,  0.0333,  0.0226],
        [ 0.0075,  0.0203, -0.0080,  ..., -0.0125, -0.0238,  0.0320],
        ...,
        [ 0.0358,  0.0211,  0.0024,  ..., -0.0008,  0.0165, -0.0047],
        [-0.0144,  0.0255, -0.0209,  ..., -0.0090, -0.0178,  0.0073],
        [ 0.0026, -0.0184, -0.0149,  ..., -0.0166, -0.0047, -0.0048]],
       dtype=torch.float16), 'model.layers.27.mlp.up_proj.weight': tensor([[-0.0049,  0.0078,  0.0265,  ..., -0.0012,  0.0131, -0.0389],
        [-0.0102,  0.0028, -0.0278,  ...,  0.0119, -0.0223, -0.0237],
        [ 0.0258,  0.0162,  0.0435,  ...,  0.0278,  0.0015, -0.0196],
        ...,
        [-0.0044,  0.0250,  0.0330,  ..., -0.0218,  0.0206, -0.0381],
        [ 0.0097,  0.0212,  0.0149,  ...,  0.0130, -0.0131, -0.0248],
        [-0.0111,  0.0048, -0.0053,  ..., -0.0063, -0.0244, -0.0093]],
       dtype=torch.float16), 'model.layers.27.mlp.down_proj.weight': tensor([[ 2.4376e-03, -2.2705e-02,  3.4363e-02,  ..., -1.9394e-02,
          1.9669e-02, -1.1414e-02],
        [ 8.0466e-05,  1.3931e-02, -9.4910e-03,  ..., -1.9272e-02,
         -3.1616e-02,  1.2093e-02],
        [ 4.6478e-02,  1.3847e-02,  5.7602e-03,  ..., -3.2166e-02,
          4.1733e-03,  2.9587e-02],
        ...,
        [-7.6523e-03,  1.0971e-02,  1.5335e-02,  ...,  7.5302e-03,
         -4.5685e-02,  2.5742e-02],
        [-2.2018e-02, -3.3932e-03, -1.7227e-02,  ...,  2.2934e-02,
         -9.0866e-03,  2.0813e-02],
        [ 4.7493e-03,  1.7471e-02, -9.1858e-03,  ...,  1.9531e-02,
         -2.3441e-03, -4.7493e-03]], dtype=torch.float16), 'model.layers.27.input_layernorm.weight': tensor([0.5625, 0.5625, 0.5586,  ..., 0.5547, 0.5625, 0.5703],
       dtype=torch.float16), 'model.layers.27.post_attention_layernorm.weight': tensor([0.4688, 0.4629, 0.4531,  ..., 0.4668, 0.4707, 0.4688],
       dtype=torch.float16), 'model.layers.28.self_attn.q_proj.weight': tensor([[-3.2127e-05, -1.9119e-02, -7.1669e-04,  ..., -1.4694e-02,
         -9.0561e-03, -1.0872e-02],
        [ 1.1421e-02, -1.8387e-02, -2.4986e-03,  ...,  1.3634e-02,
          5.4283e-03, -3.9635e-03],
        [ 1.4305e-02,  6.4993e-04, -1.0948e-02,  ..., -3.7956e-03,
         -2.4414e-02,  2.4261e-02],
        ...,
        [-1.1253e-02,  2.4719e-02, -5.3101e-02,  ...,  1.6006e-02,
         -7.5684e-03, -3.9825e-02],
        [ 1.6541e-02, -2.6855e-02, -1.2665e-02,  ...,  2.0569e-02,
          3.2928e-02, -6.5002e-02],
        [ 1.9409e-02,  1.4633e-02, -4.5654e-02,  ...,  4.5868e-02,
          1.4122e-02, -3.6987e-02]], dtype=torch.float16), 'model.layers.28.self_attn.k_proj.weight': tensor([[-0.0036, -0.0034,  0.0078,  ..., -0.0043,  0.0148, -0.0134],
        [-0.0133, -0.0068, -0.0168,  ..., -0.0066,  0.0050,  0.0043],
        [ 0.0061,  0.0063, -0.0146,  ..., -0.0197, -0.0112,  0.0050],
        ...,
        [-0.0251, -0.0133, -0.0040,  ..., -0.0014, -0.0604, -0.0040],
        [ 0.0462, -0.0221,  0.0039,  ...,  0.0161,  0.0397,  0.0285],
        [ 0.0180, -0.0042,  0.0045,  ..., -0.0038, -0.0185, -0.0136]],
       dtype=torch.float16), 'model.layers.28.self_attn.v_proj.weight': tensor([[-0.0240,  0.0090,  0.0227,  ..., -0.0210, -0.0288,  0.0260],
        [ 0.0231, -0.0178, -0.0135,  ..., -0.0447,  0.0313, -0.0163],
        [-0.0102,  0.0174, -0.0021,  ...,  0.0075, -0.0479,  0.0167],
        ...,
        [ 0.0193,  0.0043, -0.0005,  ...,  0.0143, -0.0064, -0.0217],
        [ 0.0511,  0.0041,  0.0421,  ...,  0.0019,  0.0046, -0.0031],
        [ 0.0181,  0.0192, -0.0485,  ...,  0.0328, -0.0048,  0.0090]],
       dtype=torch.float16), 'model.layers.28.self_attn.o_proj.weight': tensor([[ 1.1208e-02,  2.4567e-02, -4.1473e-02,  ..., -3.4485e-02,
          1.7929e-02, -9.8646e-05],
        [-1.2238e-02, -2.0905e-02, -2.8381e-03,  ..., -1.7075e-02,
          2.7145e-02,  3.2501e-02],
        [ 2.7863e-02,  1.7838e-02, -5.3741e-02,  ...,  2.2293e-02,
          1.5701e-02, -1.6464e-02],
        ...,
        [ 2.5444e-03, -4.4098e-03,  3.4332e-02,  ..., -9.8801e-03,
         -3.9917e-02, -6.6757e-03],
        [-7.5188e-03, -5.8655e-02, -1.8112e-02,  ...,  2.0889e-02,
         -2.8183e-02, -2.7084e-02],
        [-4.3823e-02, -4.1618e-03, -1.0742e-02,  ..., -1.9196e-02,
         -8.0719e-03,  4.2839e-03]], dtype=torch.float16), 'model.layers.28.mlp.gate_proj.weight': tensor([[-0.0007,  0.0031, -0.0068,  ...,  0.0274, -0.0111,  0.0312],
        [-0.0257,  0.0139, -0.0106,  ...,  0.0121,  0.0034,  0.0177],
        [ 0.0099,  0.0288,  0.0274,  ...,  0.0168,  0.0038,  0.0067],
        ...,
        [-0.0053,  0.0228,  0.0102,  ...,  0.0135,  0.0128, -0.0202],
        [ 0.0124, -0.0344, -0.0104,  ..., -0.0197, -0.0044, -0.0032],
        [-0.0318,  0.0149,  0.0106,  ..., -0.0078, -0.0112,  0.0179]],
       dtype=torch.float16), 'model.layers.28.mlp.up_proj.weight': tensor([[ 0.0224,  0.0047,  0.0220,  ...,  0.0277,  0.0156,  0.0114],
        [-0.0177, -0.0260, -0.0041,  ..., -0.0033, -0.0355, -0.0220],
        [ 0.0064,  0.0259, -0.0073,  ...,  0.0068,  0.0073, -0.0160],
        ...,
        [-0.0055, -0.0151,  0.0324,  ..., -0.0026,  0.0111, -0.0013],
        [-0.0215,  0.0078, -0.0074,  ...,  0.0127, -0.0099, -0.0497],
        [-0.0093, -0.0252, -0.0048,  ..., -0.0067,  0.0076,  0.0080]],
       dtype=torch.float16), 'model.layers.28.mlp.down_proj.weight': tensor([[ 0.0077,  0.0342, -0.0055,  ...,  0.0029, -0.0016, -0.0298],
        [-0.0009, -0.0338,  0.0198,  ..., -0.0268, -0.0070, -0.0280],
        [-0.0241,  0.0253, -0.0140,  ...,  0.0032,  0.0074, -0.0012],
        ...,
        [ 0.0106, -0.0143, -0.0053,  ..., -0.0309, -0.0309,  0.0070],
        [-0.0170, -0.0194,  0.0628,  ..., -0.0242, -0.0061,  0.0128],
        [-0.0234,  0.0108, -0.0081,  ...,  0.0294,  0.0295, -0.0142]],
       dtype=torch.float16), 'model.layers.28.input_layernorm.weight': tensor([0.5781, 0.5859, 0.5664,  ..., 0.5547, 0.5742, 0.5742],
       dtype=torch.float16), 'model.layers.28.post_attention_layernorm.weight': tensor([0.4805, 0.4785, 0.4648,  ..., 0.4785, 0.4727, 0.4727],
       dtype=torch.float16), 'model.layers.29.self_attn.q_proj.weight': tensor([[ 0.0060,  0.0026, -0.0075,  ...,  0.0002, -0.0110,  0.0094],
        [-0.0288, -0.0180, -0.0257,  ..., -0.0128, -0.0063, -0.0059],
        [-0.0291,  0.0377, -0.0024,  ..., -0.0022, -0.0156,  0.0146],
        ...,
        [ 0.0005,  0.0704, -0.0331,  ...,  0.0133, -0.0080, -0.0352],
        [-0.0236, -0.0242,  0.0169,  ..., -0.0142, -0.0230,  0.0260],
        [ 0.0005, -0.0416, -0.0127,  ...,  0.0132,  0.0065, -0.0391]],
       dtype=torch.float16), 'model.layers.29.self_attn.k_proj.weight': tensor([[ 0.0357, -0.0135, -0.0162,  ...,  0.0005,  0.0101, -0.0023],
        [-0.0177,  0.0316, -0.0048,  ..., -0.0086,  0.0006, -0.0218],
        [ 0.0214,  0.0079,  0.0186,  ...,  0.0193,  0.0339, -0.0014],
        ...,
        [-0.0317,  0.0448,  0.0010,  ..., -0.0091,  0.0024, -0.0117],
        [ 0.0014, -0.0123, -0.0701,  ..., -0.0106, -0.0095, -0.0427],
        [ 0.0107, -0.0124, -0.0583,  ..., -0.0584, -0.0144,  0.0027]],
       dtype=torch.float16), 'model.layers.29.self_attn.v_proj.weight': tensor([[ 0.0110,  0.0064,  0.0324,  ...,  0.0194,  0.0085,  0.0135],
        [-0.0017,  0.0247,  0.0385,  ..., -0.0199,  0.0092, -0.0022],
        [-0.0130,  0.0104, -0.0103,  ...,  0.0083,  0.0268,  0.0188],
        ...,
        [ 0.0067,  0.0294,  0.0116,  ..., -0.0203, -0.0125, -0.0172],
        [ 0.0001,  0.0276, -0.0236,  ...,  0.0186,  0.0294, -0.0053],
        [-0.0033, -0.0211,  0.0092,  ..., -0.0019, -0.0083,  0.0262]],
       dtype=torch.float16), 'model.layers.29.self_attn.o_proj.weight': tensor([[-6.3057e-03,  3.2288e-02,  3.3630e-02,  ...,  5.8222e-04,
         -1.7517e-02, -6.4850e-03],
        [-2.0340e-02, -2.5772e-02, -1.2833e-02,  ...,  1.2199e-02,
         -2.8244e-02,  1.2634e-02],
        [ 2.6093e-02,  2.8381e-02, -8.5678e-03,  ..., -3.7781e-02,
          1.7441e-02, -2.1240e-02],
        ...,
        [-2.8381e-02, -1.6617e-02,  2.8061e-02,  ..., -7.0839e-03,
         -7.8201e-03, -1.4076e-02],
        [-1.3969e-02, -1.0399e-02,  3.3966e-02,  ..., -4.7803e-05,
         -2.0554e-02,  4.7226e-03],
        [ 1.5411e-02,  3.9749e-03, -3.4275e-03,  ...,  4.1122e-03,
          1.9104e-02, -2.8473e-02]], dtype=torch.float16), 'model.layers.29.mlp.gate_proj.weight': tensor([[ 0.0161,  0.0169, -0.0145,  ..., -0.0036, -0.0243,  0.0359],
        [ 0.0034,  0.0243, -0.0081,  ..., -0.0228,  0.0151,  0.0046],
        [ 0.0371, -0.0013, -0.0085,  ..., -0.0063,  0.0206,  0.0335],
        ...,
        [-0.0048,  0.0104, -0.0152,  ...,  0.0026,  0.0065,  0.0039],
        [ 0.0079,  0.0031, -0.0292,  ..., -0.0222, -0.0051,  0.0174],
        [-0.0031,  0.0190, -0.0012,  ...,  0.0228, -0.0130, -0.0158]],
       dtype=torch.float16), 'model.layers.29.mlp.up_proj.weight': tensor([[-0.0069,  0.0021,  0.0118,  ...,  0.0150,  0.0049,  0.0057],
        [ 0.0012,  0.0072,  0.0320,  ...,  0.0089, -0.0199,  0.0363],
        [-0.0076, -0.0212, -0.0125,  ..., -0.0495,  0.0085, -0.0360],
        ...,
        [ 0.0260,  0.0129,  0.0126,  ...,  0.0124,  0.0245,  0.0357],
        [-0.0250, -0.0191, -0.0051,  ...,  0.0142,  0.0133,  0.0017],
        [ 0.0065, -0.0030,  0.0111,  ..., -0.0080,  0.0094,  0.0100]],
       dtype=torch.float16), 'model.layers.29.mlp.down_proj.weight': tensor([[ 0.0411,  0.0098, -0.0018,  ...,  0.0168, -0.0244, -0.0152],
        [ 0.0184,  0.0098,  0.0223,  ...,  0.0344,  0.0027,  0.0017],
        [ 0.0008, -0.0209, -0.0160,  ..., -0.0007,  0.0110, -0.0271],
        ...,
        [ 0.0088, -0.0090,  0.0057,  ..., -0.0189, -0.0051, -0.0197],
        [ 0.0228,  0.0159,  0.0265,  ...,  0.0094, -0.0411,  0.0024],
        [ 0.0148, -0.0185, -0.0088,  ..., -0.0158, -0.0135,  0.0045]],
       dtype=torch.float16), 'model.layers.29.input_layernorm.weight': tensor([0.5430, 0.5586, 0.5391,  ..., 0.5312, 0.5586, 0.5625],
       dtype=torch.float16), 'model.layers.29.post_attention_layernorm.weight': tensor([0.4902, 0.4922, 0.4785,  ..., 0.4785, 0.4922, 0.4805],
       dtype=torch.float16), 'model.layers.30.self_attn.q_proj.weight': tensor([[-0.0041, -0.0047,  0.0075,  ..., -0.0091, -0.0045,  0.0028],
        [ 0.0163,  0.0142,  0.0050,  ..., -0.0033, -0.0027, -0.0191],
        [-0.0086, -0.0204,  0.0428,  ...,  0.0224,  0.0053, -0.0305],
        ...,
        [-0.0093, -0.0009, -0.0012,  ...,  0.0209, -0.0119,  0.0017],
        [-0.0005, -0.0218, -0.0206,  ...,  0.0153,  0.0086, -0.0354],
        [-0.0708, -0.0093,  0.0420,  ..., -0.0094, -0.0046, -0.0015]],
       dtype=torch.float16), 'model.layers.30.self_attn.k_proj.weight': tensor([[ 0.0262, -0.0208,  0.0015,  ..., -0.0112,  0.0095,  0.0076],
        [ 0.0337,  0.0127,  0.0035,  ..., -0.0041, -0.0045,  0.0022],
        [-0.0044, -0.0148,  0.0216,  ...,  0.0055, -0.0088, -0.0004],
        ...,
        [ 0.0057,  0.0255,  0.0007,  ...,  0.0564, -0.0037, -0.0002],
        [ 0.0107, -0.0630,  0.0325,  ...,  0.0062, -0.0082, -0.0273],
        [-0.0373, -0.0082,  0.0209,  ...,  0.0079,  0.0169, -0.0247]],
       dtype=torch.float16), 'model.layers.30.self_attn.v_proj.weight': tensor([[-0.0035, -0.0291,  0.0310,  ..., -0.0268, -0.0363,  0.0307],
        [ 0.0073,  0.0172,  0.0300,  ..., -0.0118,  0.0262,  0.0019],
        [-0.0203,  0.0174, -0.0189,  ...,  0.0050, -0.0255, -0.0103],
        ...,
        [ 0.0184, -0.0039, -0.0030,  ..., -0.0245,  0.0030,  0.0241],
        [-0.0072, -0.0434,  0.0219,  ...,  0.0296, -0.0089,  0.0216],
        [-0.0088,  0.0059,  0.0193,  ..., -0.0144, -0.0613, -0.0227]],
       dtype=torch.float16), 'model.layers.30.self_attn.o_proj.weight': tensor([[-0.0074,  0.0176, -0.0070,  ...,  0.0119, -0.0119, -0.0202],
        [-0.0116, -0.0252, -0.0082,  ...,  0.0136, -0.0305, -0.0236],
        [-0.0294, -0.0029,  0.0179,  ..., -0.0482, -0.0128, -0.0113],
        ...,
        [ 0.0068,  0.0052,  0.0028,  ..., -0.0247,  0.0106,  0.0177],
        [ 0.0227, -0.0089,  0.0036,  ...,  0.0353, -0.0069,  0.0047],
        [-0.0028,  0.0133, -0.0032,  ..., -0.0048,  0.0101, -0.0147]],
       dtype=torch.float16), 'model.layers.30.mlp.gate_proj.weight': tensor([[-0.0422, -0.0289, -0.0057,  ...,  0.0138, -0.0067, -0.0003],
        [-0.0175,  0.0047,  0.0389,  ..., -0.0063, -0.0058,  0.0305],
        [-0.0219, -0.0067, -0.0307,  ...,  0.0154, -0.0004, -0.0035],
        ...,
        [-0.0204, -0.0261,  0.0121,  ..., -0.0081, -0.0219, -0.0244],
        [ 0.0268,  0.0282, -0.0097,  ...,  0.0118, -0.0396, -0.0025],
        [-0.0012, -0.0307, -0.0203,  ..., -0.0023,  0.0182, -0.0061]],
       dtype=torch.float16), 'model.layers.30.mlp.up_proj.weight': tensor([[ 0.0034,  0.0162,  0.0123,  ...,  0.0126,  0.0213, -0.0029],
        [-0.0196, -0.0118,  0.0388,  ...,  0.0008, -0.0193, -0.0033],
        [-0.0327, -0.0235, -0.0368,  ..., -0.0176,  0.0011,  0.0209],
        ...,
        [-0.0163, -0.0128,  0.0153,  ...,  0.0128, -0.0097, -0.0216],
        [-0.0081,  0.0077, -0.0097,  ...,  0.0053, -0.0229,  0.0164],
        [-0.0030, -0.0283,  0.0003,  ..., -0.0168,  0.0070,  0.0171]],
       dtype=torch.float16), 'model.layers.30.mlp.down_proj.weight': tensor([[ 2.2812e-02, -1.3634e-02, -3.0258e-02,  ...,  3.1342e-02,
         -7.2098e-03, -8.8263e-04],
        [ 2.5818e-02,  4.8409e-03,  4.3427e-02,  ...,  1.2611e-02,
          1.6594e-03, -7.8888e-03],
        [ 3.6883e-04, -3.0899e-03, -2.1591e-02,  ...,  3.1242e-03,
          1.0376e-02,  2.0767e-02],
        ...,
        [-3.1921e-02,  6.3400e-03, -2.4643e-02,  ...,  1.8341e-02,
         -2.4780e-02, -9.6664e-03],
        [-4.3750e-05, -1.9287e-02,  2.8934e-03,  ...,  1.9730e-02,
          2.3232e-03,  1.2312e-03],
        [-8.7738e-03, -1.4030e-02, -2.5955e-02,  ...,  1.0109e-02,
          3.0589e-04, -1.9150e-02]], dtype=torch.float16), 'model.layers.30.input_layernorm.weight': tensor([0.5859, 0.6016, 0.5664,  ..., 0.5586, 0.5781, 0.6016],
       dtype=torch.float16), 'model.layers.30.post_attention_layernorm.weight': tensor([0.4824, 0.5039, 0.4824,  ..., 0.4883, 0.4980, 0.4863],
       dtype=torch.float16), 'model.layers.31.self_attn.q_proj.weight': tensor([[-0.0350,  0.0179,  0.0228,  ...,  0.0133, -0.0005, -0.0199],
        [-0.0200, -0.0252, -0.0369,  ...,  0.0008, -0.0122, -0.0238],
        [-0.0219,  0.0272,  0.0192,  ..., -0.0004,  0.0037,  0.0022],
        ...,
        [ 0.0171, -0.0177, -0.0151,  ..., -0.0145,  0.0273, -0.0253],
        [-0.0265,  0.0056, -0.0053,  ..., -0.0029,  0.0124,  0.0107],
        [-0.0533, -0.0123,  0.0282,  ...,  0.0389, -0.0044,  0.0329]],
       dtype=torch.float16), 'model.layers.31.self_attn.k_proj.weight': tensor([[-0.0058, -0.0082,  0.0132,  ..., -0.0011, -0.0107, -0.0206],
        [ 0.0245, -0.0202,  0.0109,  ..., -0.0002,  0.0066, -0.0021],
        [ 0.0027,  0.0117, -0.0064,  ...,  0.0055, -0.0005, -0.0275],
        ...,
        [ 0.0315, -0.0261, -0.0244,  ..., -0.0081, -0.0101, -0.0515],
        [ 0.0134,  0.0200,  0.0124,  ..., -0.0259, -0.0236,  0.0204],
        [-0.0787, -0.0352,  0.0162,  ..., -0.0131,  0.0023, -0.0065]],
       dtype=torch.float16), 'model.layers.31.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0230, -0.0018,  ...,  0.0031,  0.0012,  0.0155],
        [ 0.0281,  0.0153,  0.0112,  ...,  0.0094,  0.0336,  0.0164],
        [ 0.0143, -0.0011, -0.0159,  ...,  0.0129,  0.0024,  0.0344],
        ...,
        [-0.0017, -0.0013, -0.0144,  ..., -0.0160, -0.0032,  0.0248],
        [ 0.0126, -0.0183,  0.0156,  ..., -0.0102, -0.0292,  0.0144],
        [-0.0103, -0.0228,  0.0264,  ...,  0.0243, -0.0042,  0.0403]],
       dtype=torch.float16), 'model.layers.31.self_attn.o_proj.weight': tensor([[ 0.0089,  0.0304, -0.0052,  ..., -0.0004, -0.0148, -0.0504],
        [-0.0065,  0.0034, -0.0314,  ...,  0.0269, -0.0200, -0.0146],
        [ 0.0102,  0.0023,  0.0032,  ..., -0.0174,  0.0214,  0.0120],
        ...,
        [ 0.0077, -0.0209,  0.0315,  ..., -0.0161, -0.0128, -0.0216],
        [ 0.0010,  0.0138, -0.0207,  ..., -0.0174, -0.0141, -0.0177],
        [ 0.0062,  0.0165, -0.0088,  ...,  0.0295, -0.0164,  0.0075]],
       dtype=torch.float16), 'model.layers.31.mlp.gate_proj.weight': tensor([[ 0.0088, -0.0101,  0.0378,  ...,  0.0157,  0.0179,  0.0108],
        [-0.0751, -0.0179,  0.0038,  ...,  0.0049, -0.0193,  0.0181],
        [ 0.0142,  0.0066, -0.0107,  ..., -0.0041, -0.0197, -0.0075],
        ...,
        [-0.0168, -0.0297,  0.0126,  ..., -0.0009,  0.0242,  0.0329],
        [ 0.0417,  0.0298, -0.0222,  ...,  0.0354, -0.0096, -0.0061],
        [ 0.0174, -0.0382, -0.0287,  ..., -0.0177,  0.0085,  0.0057]],
       dtype=torch.float16), 'model.layers.31.mlp.up_proj.weight': tensor([[-0.0397, -0.0182,  0.0206,  ...,  0.0010, -0.0187,  0.0024],
        [ 0.0275,  0.0354,  0.0046,  ..., -0.0228,  0.0012, -0.0013],
        [-0.0043,  0.0044, -0.0210,  ...,  0.0143,  0.0034, -0.0117],
        ...,
        [ 0.0134, -0.0182,  0.0072,  ...,  0.0026,  0.0326, -0.0186],
        [ 0.0055,  0.0044, -0.0258,  ...,  0.0280,  0.0101, -0.0022],
        [ 0.0409, -0.0411, -0.0085,  ..., -0.0104,  0.0099,  0.0237]],
       dtype=torch.float16), 'model.layers.31.mlp.down_proj.weight': tensor([[-1.2767e-04, -2.5101e-02, -9.8572e-03,  ..., -3.8147e-02,
         -1.4954e-02,  2.7756e-02],
        [ 3.8208e-02,  3.5248e-03, -3.6736e-03,  ..., -5.2691e-04,
         -1.6205e-02,  1.3901e-02],
        [-1.2566e-02, -1.2192e-02,  2.5131e-02,  ...,  3.0304e-02,
         -1.5383e-03,  2.3193e-02],
        ...,
        [ 4.7088e-05,  2.8351e-02, -2.0237e-03,  ...,  1.1597e-02,
          5.3177e-03,  1.7136e-02],
        [-9.8515e-04,  4.7424e-02, -5.3787e-03,  ..., -7.3509e-03,
          2.3331e-02,  1.7090e-02],
        [ 2.6001e-02, -3.8910e-02,  1.8829e-02,  ...,  4.1313e-03,
          1.2999e-03,  2.6016e-02]], dtype=torch.float16), 'model.layers.31.input_layernorm.weight': tensor([0.4961, 0.4980, 0.4453,  ..., 0.4375, 0.4727, 0.4922],
       dtype=torch.float16), 'model.layers.31.post_attention_layernorm.weight': tensor([0.4414, 0.4434, 0.4531,  ..., 0.4336, 0.4219, 0.4375],
       dtype=torch.float16), 'model.norm.weight': tensor([2.0000, 2.0469, 1.9453,  ..., 1.8594, 1.9453, 1.7656],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding': tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight': tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,
            2.1957e-02,  5.0011e-03],
          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,
            7.5417e-03, -1.2230e-02],
          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,
            5.3940e-03, -1.2283e-02],
          ...,
          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,
           -2.3239e-02, -2.4017e-02],
          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,
            1.5745e-03, -4.1771e-03],
          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,
            4.0169e-03, -6.7177e-03]],

         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,
            2.4185e-02,  5.8136e-03],
          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,
            5.4970e-03, -1.4351e-02],
          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,
            5.5618e-03, -1.2390e-02],
          ...,
          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,
            3.9816e-04, -5.1346e-03],
          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,
            2.2552e-02,  1.2917e-02],
          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,
            1.8158e-02,  9.2745e-04]],

         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,
            1.1757e-02,  5.7259e-03],
          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,
           -4.2191e-03, -7.1831e-03],
          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,
            1.3041e-04, -7.3051e-03],
          ...,
          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,
           -9.8267e-03, -6.7825e-03],
          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,
            6.3400e-03,  5.3177e-03],
          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,
            6.5193e-03,  2.9850e-04]]],


        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,
           -8.4381e-03,  2.0447e-02],
          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,
            3.5906e-04,  1.5945e-02],
          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,
           -2.7924e-02, -3.2177e-03],
          ...,
          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,
           -5.4741e-03, -5.9624e-03],
          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,
           -2.7969e-02, -1.8875e-02],
          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,
            7.1335e-03,  4.6478e-02]],

         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,
           -1.1604e-02,  1.7593e-02],
          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,
            3.4976e-04,  1.4732e-02],
          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,
           -3.2684e-02, -7.0076e-03],
          ...,
          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,
           -1.1253e-02, -9.8648e-03],
          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,
           -3.7231e-02, -2.6505e-02],
          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,
           -4.2000e-03,  3.9368e-02]],

         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,
           -1.2558e-02,  1.7303e-02],
          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,
            4.3440e-04,  1.5656e-02],
          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,
           -2.9968e-02, -6.5422e-03],
          ...,
          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,
           -8.7967e-03, -8.7662e-03],
          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,
           -3.0518e-02, -2.4918e-02],
          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,
           -7.3242e-04,  3.8818e-02]]],


        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,
            1.4229e-02,  1.8768e-02],
          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,
            5.4283e-03,  6.6032e-03],
          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,
            2.5959e-03,  6.8703e-03],
          ...,
          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,
            1.4397e-02,  1.2421e-02],
          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,
            2.2766e-02,  2.2659e-02],
          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,
            2.2263e-02,  2.5238e-02]],

         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,
            1.9653e-02,  2.8290e-02],
          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,
            6.0501e-03,  1.2810e-02],
          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,
           -5.9271e-04,  8.8959e-03],
          ...,
          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,
            2.4902e-02,  2.6871e-02],
          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,
            3.3569e-02,  3.9612e-02],
          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,
            3.9276e-02,  4.6051e-02]],

         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,
            2.1042e-02,  2.9053e-02],
          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,
            7.7019e-03,  1.2169e-02],
          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,
            3.3913e-03,  9.0408e-03],
          ...,
          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,
            8.0795e-03,  1.4221e-02],
          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,
            1.1887e-02,  1.8204e-02],
          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,
            1.5701e-02,  2.2247e-02]]],


        ...,


        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,
            3.1686e-04, -3.0446e-04],
          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,
           -2.2995e-04, -1.6510e-04],
          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,
           -5.0831e-04,  5.9748e-04],
          ...,
          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,
           -9.3746e-04, -6.7472e-04],
          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,
           -1.4048e-03, -1.3056e-03],
          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,
            3.2640e-04,  1.7679e-04]],

         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,
            1.0500e-03, -5.0831e-04],
          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,
            1.0071e-03, -4.9925e-04],
          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,
            8.0919e-04,  9.7132e-04],
          ...,
          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,
            6.2895e-04,  4.0889e-04],
          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,
           -2.8610e-04,  1.9038e-04],
          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,
            1.4138e-04,  4.2319e-04]],

         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,
           -4.3130e-04, -5.6791e-04],
          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,
            1.9002e-04,  1.8311e-04],
          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,
            2.3186e-05, -5.7578e-05],
          ...,
          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,
            1.3471e-04,  6.5708e-04],
          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,
            1.0538e-04, -4.9019e-04],
          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,
           -4.1580e-04,  5.5599e-04]]],


        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,
            6.1874e-03,  2.6535e-02],
          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,
           -1.7639e-02, -3.2768e-03],
          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,
           -2.7237e-02, -5.5046e-03],
          ...,
          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,
            2.8503e-02,  3.6499e-02],
          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,
           -2.3010e-02,  5.0926e-03],
          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,
           -3.9276e-02,  1.3908e-02]],

         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,
            2.8896e-03,  2.2415e-02],
          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,
           -1.8616e-02, -6.5308e-03],
          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,
           -3.0472e-02, -9.3613e-03],
          ...,
          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,
            2.6001e-02,  3.4241e-02],
          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,
           -3.0487e-02, -9.5701e-04],
          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,
           -5.1422e-02,  4.2267e-03]],

         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,
           -2.1572e-03,  1.6891e-02],
          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,
           -2.1347e-02, -9.2316e-03],
          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,
           -2.9694e-02, -1.2733e-02],
          ...,
          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,
            1.9257e-02,  2.4582e-02],
          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,
           -3.1281e-02, -9.1248e-03],
          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,
           -5.2246e-02, -2.8057e-03]]],


        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,
            8.1863e-03, -4.8248e-02],
          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,
            9.3689e-03, -3.8544e-02],
          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,
            2.3956e-02, -1.1154e-02],
          ...,
          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,
           -1.8654e-03, -1.9440e-02],
          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,
            8.4381e-03,  1.4282e-02],
          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,
            1.6689e-03,  1.6891e-02]],

         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,
            1.5839e-02, -4.3243e-02],
          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,
            1.8433e-02, -3.1799e-02],
          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,
            2.9694e-02, -5.4817e-03],
          ...,
          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,
           -1.5268e-03, -1.4626e-02],
          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,
            8.5602e-03,  2.0035e-02],
          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,
           -2.3785e-03,  1.9150e-02]],

         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,
            2.1317e-02, -3.0197e-02],
          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,
            2.4658e-02, -1.7670e-02],
          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,
            3.4302e-02,  4.5395e-03],
          ...,
          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,
            4.1656e-03, -5.9814e-03],
          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,
            1.6068e-02,  2.5879e-02],
          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,
            2.2964e-03,  2.2339e-02]]]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight': tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],
        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],
        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],
        ...,
        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],
        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],
        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight': tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias': tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight': tensor([[-1.1724e-04,  8.3399e-04, -1.5700e-04,  ..., -4.8332e-03,
          1.3428e-02,  3.2604e-05],
        [-4.4703e-05, -9.5272e-04,  1.2279e-04,  ...,  1.9855e-03,
         -1.3626e-02, -4.1783e-05],
        [ 6.6280e-04,  1.0419e-04,  9.0420e-05,  ..., -2.1820e-02,
          4.1199e-03,  3.2187e-06],
        ...,
        [-5.2512e-05, -2.9278e-04, -3.6895e-05,  ...,  8.8196e-03,
         -4.2796e-04, -3.0100e-05],
        [ 7.5936e-05, -6.5148e-05, -9.0182e-05,  ...,  8.1682e-04,
         -6.0844e-03,  1.9014e-05],
        [-6.3896e-05,  9.8705e-05,  4.9829e-05,  ..., -1.2579e-03,
         -7.1793e-03,  2.3961e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias': tensor([ 0.0577, -0.0588, -0.0266,  ..., -0.0147, -0.0175,  0.0096],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight': tensor([[ 2.4986e-04, -1.5283e-04, -5.8556e-04,  ...,  3.3607e-03,
         -9.5901e-03,  5.5373e-05],
        [-3.4356e-04, -1.5092e-04,  5.2691e-05,  ...,  2.5725e-04,
          1.0010e-02, -6.2883e-05],
        [ 6.7472e-04, -9.6798e-05,  2.5392e-04,  ..., -1.0386e-03,
         -1.9531e-02, -1.2141e-04],
        ...,
        [ 2.9850e-04,  4.0436e-04, -9.7811e-05,  ...,  4.6654e-03,
         -2.2392e-03, -6.6221e-05],
        [ 3.2973e-04, -3.2961e-05, -2.1207e-04,  ...,  1.1917e-02,
          3.4637e-03,  6.9439e-05],
        [ 2.1458e-06,  4.7874e-04,  4.8459e-05,  ..., -1.1612e-02,
          2.6779e-03, -8.3089e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias': tensor([-0.0277,  0.0222, -0.0355,  ...,  0.0123,  0.0105, -0.0041],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight': tensor([[-2.6703e-05, -1.3638e-04, -8.3923e-05,  ...,  4.2152e-03,
         -2.7649e-02, -7.5042e-05],
        [-1.6391e-04,  9.0241e-05,  5.4836e-05,  ..., -1.5821e-03,
          2.9831e-02,  7.0333e-05],
        [ 4.7588e-04,  7.6008e-04, -1.0198e-04,  ..., -1.7090e-02,
          4.1809e-02,  1.5020e-04],
        ...,
        [ 6.9141e-05,  7.0274e-05,  8.6784e-05,  ..., -4.3411e-03,
          1.1421e-02, -3.8803e-05],
        [-1.8144e-04,  1.4305e-06, -2.5940e-04,  ...,  1.5802e-03,
         -1.8799e-04,  1.6689e-05],
        [-1.2624e-04,  9.4473e-05,  5.3406e-05,  ..., -1.4961e-02,
         -5.8937e-04,  4.2021e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias': tensor([ 1.5693, -1.6172, -0.8213,  ..., -1.2852, -0.0976,  0.7852],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight': tensor([[-0.0073,  0.0083, -0.0076,  ..., -0.0090, -0.0080,  0.0038],
        [ 0.0107,  0.0062,  0.0133,  ..., -0.0036,  0.0022,  0.0034],
        [-0.0065,  0.0033,  0.0139,  ...,  0.0069,  0.0004, -0.0009],
        ...,
        [-0.0002, -0.0035, -0.0027,  ..., -0.0046, -0.0187,  0.0087],
        [-0.0093,  0.0047, -0.0083,  ...,  0.0006, -0.0013, -0.0006],
        [ 0.0092,  0.0003,  0.0016,  ...,  0.0016, -0.0045,  0.0045]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias': tensor([-0.0263, -0.0654,  0.0031,  ...,  0.1759, -0.0438,  0.0020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight': tensor([8.3113e-04, 2.9087e-03, 1.1456e-04,  ..., 6.9092e-01, 3.5498e-01,
        2.4021e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias': tensor([ 6.9141e-06,  7.7629e-04, -8.8811e-05,  ..., -3.6816e-01,
         1.7981e-01, -1.0854e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight': tensor([[ 4.2367e-04, -2.1219e-05,  5.9605e-08,  ..., -5.6458e-03,
         -1.2026e-03, -6.4087e-04],
        [ 6.1340e-03,  1.3588e-02, -3.5858e-04,  ..., -3.5954e-03,
         -7.6485e-04,  6.7101e-03],
        [ 1.3552e-03,  1.2817e-03, -2.0266e-06,  ..., -2.8351e-02,
         -1.2054e-03,  1.4830e-03],
        ...,
        [-2.4002e-02, -1.0193e-02,  2.1684e-04,  ..., -2.5864e-03,
         -1.1841e-02,  5.9166e-03],
        [ 4.1008e-04,  4.2856e-05, -1.1921e-07,  ..., -5.0697e-03,
         -7.7248e-04, -6.3896e-04],
        [-6.3753e-04, -2.3392e-02, -2.6226e-04,  ..., -4.2801e-03,
          2.7962e-03, -8.1863e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias': tensor([-0.6826, -0.3130, -0.8076,  ..., -0.2166, -0.6538, -0.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight': tensor([[-0.0037, -0.0032,  0.0043,  ...,  0.0117, -0.0042, -0.0073],
        [ 0.0017,  0.0183, -0.0100,  ..., -0.0255,  0.0024,  0.0209],
        [ 0.0033,  0.0024, -0.0029,  ...,  0.0037,  0.0032, -0.0154],
        ...,
        [ 0.0015, -0.0007, -0.0035,  ...,  0.0049,  0.0009,  0.0082],
        [-0.0060,  0.0064,  0.0067,  ..., -0.0009, -0.0061,  0.0016],
        [ 0.0007, -0.0034, -0.0020,  ..., -0.0091,  0.0009,  0.0035]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias': tensor([-0.0185, -0.1009,  0.0397,  ..., -0.0955, -0.1080, -0.0239],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight': tensor([2.8296e-01, 5.9082e-01, 1.0455e-04,  ..., 2.0195e+00, 7.7490e-01,
        2.9736e-01], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias': tensor([2.1988e-02, 2.1716e-01, 9.2089e-05,  ..., 2.6318e-01, 4.5020e-01,
        5.0903e-02], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight': tensor([[-3.9864e-03,  1.4374e-02, -2.8610e-03,  ...,  1.0399e-02,
         -2.8076e-02,  5.1155e-03],
        [ 8.1024e-03,  2.2583e-03,  1.1635e-02,  ..., -7.1716e-03,
         -7.5607e-03,  2.5375e-02],
        [ 9.5596e-03,  1.1284e-02, -3.6469e-03,  ..., -6.6757e-03,
         -1.2465e-03, -1.1475e-02],
        ...,
        [ 7.7188e-05, -1.6190e-02,  3.6583e-03,  ...,  2.1240e-02,
          4.3907e-03, -1.0063e-02],
        [ 1.5762e-02,  1.7273e-02, -3.3447e-02,  ..., -2.2507e-03,
         -1.2947e-02,  1.1726e-02],
        [-2.2697e-04,  1.2230e-02, -4.3411e-03,  ...,  3.3436e-03,
         -4.9973e-03,  5.5504e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias': tensor([-0.0012,  0.0081,  0.0097,  ...,  0.0535,  0.0071,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight': tensor([[ 0.0077,  0.0006,  0.0053,  ..., -0.0067,  0.0008,  0.0013],
        [ 0.0230, -0.0166, -0.0004,  ...,  0.0092, -0.0118, -0.0134],
        [-0.0103,  0.0013,  0.0111,  ..., -0.0549, -0.0047,  0.0056],
        ...,
        [ 0.0119,  0.0002, -0.0045,  ...,  0.0001,  0.0034, -0.0075],
        [-0.0129, -0.0114,  0.0075,  ..., -0.0030,  0.0044,  0.0061],
        [-0.0006, -0.0018,  0.0009,  ..., -0.0068, -0.0205, -0.0002]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias': tensor([ 0.0038, -0.0079, -0.1469,  ..., -0.0014, -0.0041,  0.0007],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight': tensor([[-2.4929e-03,  4.6706e-04, -1.8919e-04,  ...,  6.1684e-03,
         -2.4582e-02,  8.7051e-03],
        [ 6.5422e-03,  4.3602e-03,  1.5930e-02,  ..., -6.5994e-03,
          8.2169e-03,  6.1111e-03],
        [ 1.0727e-02, -9.2239e-03, -7.5698e-06,  ...,  3.7136e-03,
          1.6861e-02,  3.5305e-03],
        ...,
        [-2.3708e-03,  6.6452e-03,  5.9052e-03,  ..., -1.0399e-02,
          2.9945e-04, -9.6989e-04],
        [ 3.0609e-02,  1.3458e-02, -3.3386e-02,  ..., -1.3857e-03,
          3.5801e-03,  1.3245e-02],
        [-3.2291e-03,  4.7607e-03, -1.8759e-03,  ...,  6.1035e-04,
          4.9515e-03, -5.3520e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias': tensor([-0.1035,  0.8804,  1.4414,  ..., -2.2109, -0.1892,  0.0048],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight': tensor([[-0.0013, -0.0215,  0.0011,  ..., -0.0115,  0.0102, -0.0012],
        [-0.0010,  0.0065, -0.0018,  ..., -0.0036,  0.0112, -0.0025],
        [ 0.0015, -0.0069, -0.0120,  ..., -0.0047, -0.0009, -0.0056],
        ...,
        [ 0.0053, -0.0177,  0.0780,  ..., -0.0228, -0.0122,  0.0151],
        [-0.0086, -0.0019,  0.0054,  ...,  0.0081, -0.0049,  0.0067],
        [-0.0037,  0.0063, -0.0005,  ...,  0.0054,  0.0045, -0.0036]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias': tensor([-0.0204, -0.0210,  0.0255,  ..., -0.0381, -0.0211, -0.0043],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight': tensor([0.3650, 0.7476, 0.0972,  ..., 0.8521, 0.4248, 0.2639],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias': tensor([-0.0482, -0.1315,  0.0198,  ..., -0.1031, -0.0545,  0.0076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight': tensor([[ 0.0026,  0.0065,  0.0155,  ..., -0.0063,  0.0479, -0.0807],
        [ 0.0002, -0.0075,  0.0009,  ..., -0.0009, -0.0030,  0.0036],
        [ 0.0070, -0.0211,  0.0002,  ..., -0.0094,  0.0178, -0.0043],
        ...,
        [ 0.0026, -0.0113,  0.0019,  ..., -0.0057, -0.0008,  0.0038],
        [-0.0059,  0.0099,  0.0010,  ...,  0.0037, -0.0142, -0.0178],
        [ 0.0160,  0.0002,  0.0312,  ..., -0.0003, -0.0056, -0.0220]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias': tensor([-0.1216, -0.6841, -0.5278,  ..., -0.7573, -0.0995, -0.3076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight': tensor([[ 0.0008, -0.0008, -0.0176,  ..., -0.0029, -0.0098, -0.0047],
        [-0.0157,  0.0059,  0.0156,  ...,  0.0064, -0.0005, -0.0058],
        [ 0.0051, -0.0005,  0.0091,  ..., -0.0056, -0.0015,  0.0059],
        ...,
        [ 0.0030, -0.0024,  0.0040,  ...,  0.0014,  0.0002,  0.0047],
        [ 0.0007, -0.0015,  0.0031,  ..., -0.0015,  0.0046, -0.0055],
        [ 0.0299,  0.0036,  0.0020,  ...,  0.0047,  0.0134,  0.0043]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias': tensor([ 0.0244, -0.0645,  0.0788,  ..., -0.0807, -0.1028, -0.0836],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight': tensor([0.4128, 0.9854, 0.1910,  ..., 0.7715, 0.5596, 0.5142],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias': tensor([-0.0198, -0.1075, -0.0195,  ...,  0.0887,  0.1349,  0.0288],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight': tensor([[-0.0085,  0.0006, -0.0289,  ...,  0.0041,  0.0569, -0.0674],
        [-0.0052,  0.0245, -0.0213,  ..., -0.0084,  0.0220, -0.0248],
        [-0.0135, -0.0092,  0.0144,  ...,  0.0162,  0.0298, -0.0357],
        ...,
        [-0.0062,  0.0068,  0.0082,  ...,  0.0119,  0.0132, -0.0033],
        [-0.0083,  0.0247, -0.0094,  ..., -0.0040, -0.0122,  0.0142],
        [-0.0048, -0.0044, -0.0164,  ...,  0.0119, -0.0213, -0.0117]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias': tensor([ 0.0234,  0.0084, -0.0015,  ...,  0.0951,  0.0065,  0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight': tensor([[ 0.0164,  0.0053, -0.0065,  ..., -0.0008,  0.0037, -0.0120],
        [-0.0057, -0.0036, -0.0029,  ..., -0.0013,  0.0026, -0.0108],
        [-0.0081,  0.0057,  0.0067,  ...,  0.0028, -0.0068, -0.0023],
        ...,
        [-0.0249,  0.0121,  0.0107,  ...,  0.0037,  0.0007,  0.0044],
        [ 0.0115,  0.0107,  0.0118,  ...,  0.0015, -0.0038, -0.0073],
        [-0.0073,  0.0032, -0.0060,  ...,  0.0023, -0.0074,  0.0047]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias': tensor([-0.0014, -0.0060,  0.0129,  ...,  0.1081,  0.0069,  0.0455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight': tensor([[-0.0067, -0.0208, -0.0222,  ...,  0.0014,  0.0279, -0.0558],
        [-0.0030,  0.0016, -0.0191,  ...,  0.0001, -0.0169, -0.0034],
        [-0.0079, -0.0049,  0.0074,  ..., -0.0163, -0.0186, -0.0105],
        ...,
        [ 0.0002, -0.0036,  0.0084,  ..., -0.0038,  0.0105, -0.0002],
        [-0.0035, -0.0039, -0.0118,  ..., -0.0067, -0.0292,  0.0361],
        [-0.0044, -0.0008, -0.0187,  ...,  0.0014, -0.0064, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias': tensor([ 0.1927, -0.0745, -0.0890,  ...,  0.6807,  0.7334, -0.5073],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight': tensor([[-2.4796e-02,  3.3035e-03, -5.1379e-05,  ...,  2.5177e-02,
         -2.3010e-02,  1.2245e-02],
        [-2.7504e-03,  1.5330e-04, -1.1650e-02,  ..., -8.4229e-03,
         -4.1389e-03, -6.9275e-03],
        [-1.2238e-02, -7.1983e-03, -1.0323e-02,  ..., -1.6312e-02,
         -5.9547e-03, -1.4572e-03],
        ...,
        [-1.8501e-03,  5.0354e-04, -6.7101e-03,  ..., -7.3471e-03,
         -2.3518e-03, -1.8501e-03],
        [ 5.4131e-03, -4.4937e-03,  1.2329e-02,  ..., -7.1716e-04,
          9.8038e-04,  7.2708e-03],
        [ 1.0040e-02,  6.5422e-03,  9.2163e-03,  ..., -4.5815e-03,
         -1.1330e-03, -2.6169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias': tensor([ 0.0182, -0.0970,  0.0244,  ..., -0.0159, -0.0449, -0.0308],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight': tensor([0.5078, 0.3108, 0.4004,  ..., 1.4219, 0.5015, 0.3591],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias': tensor([-0.0750, -0.0109,  0.0618,  ..., -0.0417,  0.0176, -0.0477],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight': tensor([[-0.0066, -0.0264,  0.0131,  ..., -0.0004,  0.0194, -0.0154],
        [ 0.0097,  0.0090, -0.0017,  ...,  0.0023, -0.0030,  0.0246],
        [-0.0057,  0.0093,  0.0011,  ..., -0.0040,  0.0003,  0.0128],
        ...,
        [ 0.0005, -0.0012, -0.0009,  ...,  0.0011, -0.0034, -0.0059],
        [ 0.0002,  0.0115,  0.0158,  ...,  0.0040,  0.0015,  0.0208],
        [-0.0148,  0.0111, -0.0085,  ...,  0.0049, -0.0076, -0.0022]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias': tensor([-0.2452, -0.3076, -0.4565,  ..., -0.1678, -0.2119, -0.5581],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight': tensor([[ 1.3428e-03, -3.5172e-03,  9.3317e-04,  ..., -5.0354e-03,
          4.3907e-03,  2.0161e-03],
        [ 1.2999e-03, -1.6678e-02, -4.5662e-03,  ..., -4.4584e-04,
          1.3359e-02, -3.9558e-03],
        [-1.8829e-02,  5.2261e-03,  4.7760e-03,  ...,  8.3113e-04,
         -1.8860e-02,  1.0452e-03],
        ...,
        [-7.8201e-03,  8.4305e-04, -2.1601e-04,  ..., -5.6207e-05,
          4.8339e-05,  1.7557e-03],
        [-4.5300e-05, -7.9498e-03, -9.6178e-04,  ...,  3.4180e-03,
         -1.0208e-02,  2.4460e-02],
        [ 6.0883e-03,  3.3398e-03, -3.7789e-04,  ...,  1.5259e-02,
          6.6223e-03,  6.8169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias': tensor([ 0.0453, -0.0798, -0.0027,  ..., -0.0154, -0.1379, -0.0307],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight': tensor([0.6362, 0.5508, 0.3787,  ..., 1.3506, 0.4011, 0.4910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias': tensor([-0.0338, -0.0840, -0.0964,  ..., -0.0491,  0.0855, -0.2158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight': tensor([[ 0.0149, -0.0155, -0.0083,  ...,  0.0066,  0.0086, -0.0173],
        [ 0.0067,  0.0134,  0.0050,  ..., -0.0056, -0.0293, -0.0028],
        [ 0.0041, -0.0027, -0.0011,  ...,  0.0060,  0.0020, -0.0035],
        ...,
        [ 0.0110, -0.0188,  0.0174,  ..., -0.0223,  0.0017, -0.0122],
        [ 0.0165, -0.0201, -0.0204,  ..., -0.0262, -0.0232, -0.0039],
        [ 0.0062, -0.0148,  0.0194,  ...,  0.0090, -0.0007, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias': tensor([-0.0385, -0.0122,  0.0262,  ...,  0.1536,  0.0992, -0.0590],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight': tensor([[ 0.0275, -0.0126, -0.0067,  ...,  0.0002,  0.0201,  0.0163],
        [-0.0074,  0.0475,  0.0058,  ..., -0.0040,  0.0014,  0.0004],
        [-0.0100, -0.0039, -0.0155,  ...,  0.0009, -0.0079,  0.0033],
        ...,
        [ 0.0009,  0.0007,  0.0107,  ...,  0.0007,  0.0007, -0.0059],
        [-0.0008,  0.0147,  0.0066,  ...,  0.0022, -0.0062, -0.0033],
        [-0.0195, -0.0065,  0.0118,  ..., -0.0030,  0.0058,  0.0028]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias': tensor([ 0.0095, -0.0516,  0.0111,  ..., -0.0145,  0.0041,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight': tensor([[ 2.7618e-02,  1.0513e-02,  4.2725e-03,  ...,  6.3095e-03,
         -8.5907e-03, -1.3008e-02],
        [ 2.4605e-03,  1.8875e-02, -3.9787e-03,  ..., -5.7335e-03,
         -2.1698e-02,  5.3406e-03],
        [-5.1880e-04, -1.0147e-02, -1.0471e-03,  ...,  1.0002e-02,
          1.0025e-02, -1.6159e-02],
        ...,
        [ 1.4210e-03, -1.6434e-02,  5.2299e-03,  ..., -1.5053e-02,
          1.1284e-02,  1.2054e-03],
        [ 1.5579e-02,  1.5251e-02, -3.5915e-03,  ..., -2.6520e-02,
         -1.4130e-02, -7.7133e-03],
        [ 1.0399e-02, -2.2491e-02,  3.2783e-06,  ...,  8.3542e-03,
         -6.7215e-03,  1.6525e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias': tensor([-0.1852, -0.5479, -0.1450,  ..., -0.9072, -0.3499, -0.3457],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight': tensor([[-2.1683e-02,  2.3556e-03, -1.9245e-03,  ..., -9.4910e-03,
          1.6251e-02,  1.2527e-02],
        [ 6.4430e-03, -3.8055e-02, -3.1567e-03,  ..., -2.6455e-03,
         -2.1515e-02,  1.1864e-02],
        [ 5.2147e-03, -8.5602e-03,  1.5732e-02,  ..., -1.2611e-02,
          7.3395e-03, -1.2505e-02],
        ...,
        [-1.1325e-04,  3.4676e-03, -1.1169e-02,  ..., -1.0071e-02,
         -5.4538e-05, -1.7357e-03],
        [-6.8245e-03, -1.0139e-02,  1.4579e-04,  ...,  2.0309e-02,
          1.3527e-02, -3.0098e-03],
        [-1.7868e-02,  6.0368e-04, -6.7101e-03,  ...,  6.6853e-04,
         -3.0327e-03,  3.0651e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias': tensor([-0.0147, -0.0586,  0.0197,  ...,  0.0204, -0.1210,  0.0171],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight': tensor([0.7456, 0.3557, 0.6133,  ..., 2.2637, 0.5059, 0.3938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias': tensor([-0.0006,  0.0249,  0.0189,  ..., -0.1539, -0.0345,  0.0151],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight': tensor([[ 0.0034,  0.0025,  0.0007,  ..., -0.0021, -0.0065,  0.0058],
        [ 0.0011, -0.0024, -0.0028,  ..., -0.0094, -0.0078, -0.0065],
        [-0.0051, -0.0246, -0.0075,  ..., -0.0073,  0.0121,  0.0036],
        ...,
        [ 0.0077,  0.0038, -0.0011,  ..., -0.0060, -0.0017,  0.0005],
        [-0.0208, -0.0176, -0.0064,  ..., -0.0076, -0.0137, -0.0056],
        [-0.0240,  0.0082, -0.0047,  ..., -0.0105, -0.0069, -0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias': tensor([-0.0952, -0.1888, -0.1597,  ..., -0.2030, -0.3225, -0.3745],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight': tensor([[ 0.0074, -0.0074,  0.0041,  ...,  0.0181,  0.0235,  0.0145],
        [ 0.0106,  0.0015, -0.0078,  ..., -0.0323, -0.0017,  0.0073],
        [-0.0059, -0.0090, -0.0087,  ...,  0.0023,  0.0091,  0.0240],
        ...,
        [ 0.0054,  0.0013, -0.0012,  ..., -0.0047, -0.0021, -0.0053],
        [-0.0028,  0.0165,  0.0051,  ...,  0.0006, -0.0043, -0.0041],
        [-0.0045,  0.0066,  0.0154,  ..., -0.0027,  0.0146, -0.0076]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias': tensor([ 0.0139, -0.0796,  0.0050,  ...,  0.0715, -0.1787,  0.0414],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight': tensor([0.9761, 0.5317, 0.6523,  ..., 0.0116, 0.5054, 0.5391],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias': tensor([ 0.0585,  0.0282,  0.0207,  ...,  0.3896, -0.0784, -0.1201],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight': tensor([[ 2.0187e-02,  9.6970e-03,  1.7242e-02,  ..., -2.5925e-02,
         -1.5945e-02,  6.4671e-05],
        [ 1.0201e-02, -7.3357e-03,  3.3722e-02,  ...,  8.9111e-03,
         -3.2410e-02,  5.5122e-03],
        [ 9.6817e-03, -2.4231e-02,  5.7907e-03,  ...,  4.0955e-02,
          2.2415e-02, -1.8143e-02],
        ...,
        [-2.4857e-02, -2.5803e-02, -3.2673e-03,  ..., -1.3596e-02,
          3.6240e-03, -5.7650e-04],
        [-6.4754e-04,  2.4719e-02, -3.0411e-02,  ..., -1.3008e-02,
          5.0879e-04, -1.9455e-02],
        [ 1.7380e-02, -2.3804e-02,  1.2428e-02,  ..., -4.4670e-03,
         -4.2297e-02,  9.2545e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias': tensor([-0.0362, -0.0177,  0.0258,  ...,  0.0230,  0.0147,  0.0451],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight': tensor([[-0.0050,  0.0089,  0.0017,  ..., -0.0001, -0.0173, -0.0087],
        [ 0.0064, -0.0170,  0.0071,  ..., -0.0039,  0.0387, -0.0100],
        [-0.0151,  0.0005, -0.0012,  ..., -0.0011, -0.0048,  0.0012],
        ...,
        [ 0.0129, -0.0303, -0.0177,  ...,  0.0005,  0.0013,  0.0006],
        [ 0.0157,  0.0140, -0.0101,  ...,  0.0011,  0.0336, -0.0216],
        [ 0.0171, -0.0183, -0.0061,  ...,  0.0016, -0.0197, -0.0110]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias': tensor([ 0.0241, -0.0481, -0.0028,  ...,  0.0268,  0.0064, -0.0023],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight': tensor([[ 0.0075,  0.0013, -0.0144,  ..., -0.0114, -0.0454, -0.0086],
        [-0.0035, -0.0501,  0.0037,  ..., -0.0065, -0.0287,  0.0070],
        [ 0.0061, -0.0005,  0.0146,  ...,  0.0271,  0.0069, -0.0366],
        ...,
        [-0.0107,  0.0089, -0.0109,  ..., -0.0074, -0.0206, -0.0009],
        [-0.0004, -0.0072, -0.0339,  ..., -0.0124, -0.0053, -0.0094],
        [ 0.0051, -0.0136, -0.0062,  ..., -0.0015, -0.0242, -0.0031]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias': tensor([-0.4634, -0.0086,  0.2761,  ..., -0.2158, -0.2346, -0.2240],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight': tensor([[-2.6817e-03, -4.3983e-03,  1.3580e-03,  ..., -2.4681e-03,
         -1.6296e-02, -1.9119e-02],
        [-6.3057e-03,  1.3931e-02,  2.0657e-03,  ...,  2.4063e-02,
         -2.3544e-02,  2.3361e-02],
        [ 4.4098e-03,  2.9049e-03,  3.0816e-05,  ...,  1.9028e-02,
          1.2093e-02,  9.4528e-03],
        ...,
        [-6.3095e-03,  7.6141e-03, -4.4861e-03,  ..., -6.6261e-03,
         -6.6795e-03, -3.0851e-04],
        [ 1.7075e-02, -3.9612e-02,  9.1248e-03,  ...,  1.1742e-02,
         -3.6469e-02,  2.8046e-02],
        [ 8.2626e-03,  1.3752e-03, -1.0185e-02,  ...,  6.5994e-04,
          1.5320e-02,  1.1871e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias': tensor([ 0.0089, -0.0782,  0.0222,  ..., -0.0115, -0.1763,  0.0233],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight': tensor([0.7534, 0.5015, 0.7891,  ..., 1.1660, 0.6074, 0.5796],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias': tensor([ 0.0149, -0.0122,  0.0052,  ..., -0.1028,  0.0337, -0.0357],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight': tensor([[ 0.0072, -0.0114, -0.0013,  ..., -0.0066,  0.0127,  0.0151],
        [-0.0095,  0.0185,  0.0141,  ..., -0.0075,  0.0141,  0.0101],
        [-0.0018,  0.0118,  0.0032,  ..., -0.0046,  0.0148,  0.0008],
        ...,
        [ 0.0204,  0.0075,  0.0235,  ..., -0.0079,  0.0030, -0.0164],
        [ 0.0157, -0.0033, -0.0008,  ..., -0.0085,  0.0043, -0.0139],
        [-0.0009, -0.0003,  0.0257,  ..., -0.0072, -0.0059, -0.0217]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias': tensor([-0.2440, -0.3796, -0.5205,  ..., -0.2163, -0.4248, -0.2197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight': tensor([[-1.6296e-02,  6.4087e-03, -1.4839e-03,  ..., -2.2827e-02,
          1.9302e-02,  1.6346e-03],
        [ 5.0888e-03, -1.3763e-02,  5.1537e-03,  ..., -1.9989e-02,
         -2.7637e-03, -1.0567e-02],
        [ 2.8763e-03, -5.1460e-03, -5.6326e-05,  ..., -7.1030e-03,
         -9.8724e-03, -2.3098e-03],
        ...,
        [-5.3024e-03, -2.0905e-03,  2.9635e-04,  ..., -5.4092e-03,
          2.0993e-04,  2.4395e-03],
        [-9.9411e-03, -1.4748e-02, -2.4283e-04,  ...,  1.8127e-02,
          3.3779e-03,  2.1927e-02],
        [-5.7182e-03,  1.5316e-03,  1.1997e-03,  ...,  2.5387e-03,
         -5.6725e-03,  4.6387e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias': tensor([-0.0155, -0.0524, -0.0402,  ...,  0.1025, -0.1437, -0.0174],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight': tensor([1.1230, 0.5190, 1.0762,  ..., 0.0112, 0.6738, 0.7544],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias': tensor([ 0.0829, -0.0929, -0.0049,  ...,  0.1129, -0.0392, -0.0677],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight': tensor([[ 0.0035, -0.0081,  0.0270,  ..., -0.0032,  0.0041,  0.0172],
        [-0.0174,  0.0256,  0.0060,  ..., -0.0001,  0.0052, -0.0038],
        [ 0.0038,  0.0144, -0.0161,  ..., -0.0028,  0.0033,  0.0003],
        ...,
        [-0.0023, -0.0123, -0.0080,  ...,  0.0256,  0.0213, -0.0097],
        [-0.0147,  0.0030,  0.0045,  ...,  0.0211,  0.0161, -0.0218],
        [-0.0035,  0.0147,  0.0030,  ..., -0.0244, -0.0005, -0.0255]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias': tensor([-0.0187, -0.0076,  0.0053,  ...,  0.0369,  0.0955,  0.0978],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight': tensor([[-0.0090,  0.0047, -0.0008,  ..., -0.0064, -0.0025, -0.0247],
        [-0.0128, -0.0091,  0.0087,  ...,  0.0024, -0.0012,  0.0007],
        [ 0.0101, -0.0021, -0.0005,  ...,  0.0017,  0.0007, -0.0170],
        ...,
        [-0.0120,  0.0108,  0.0011,  ..., -0.0008, -0.0032,  0.0003],
        [-0.0157, -0.0033,  0.0135,  ..., -0.0007, -0.0310, -0.0129],
        [ 0.0124, -0.0001,  0.0213,  ..., -0.0014, -0.0043, -0.0239]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias': tensor([-0.0186, -0.0071, -0.0258,  ..., -0.0043, -0.0113, -0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight': tensor([[-1.7075e-02,  3.0457e-02,  8.3542e-03,  ..., -8.0032e-03,
          1.6724e-02, -1.0490e-02],
        [-1.2169e-02,  8.2474e-03, -4.2725e-03,  ..., -9.4366e-04,
         -4.9591e-03, -1.0300e-02],
        [ 1.0185e-03, -1.2466e-02, -3.0880e-03,  ..., -3.4428e-03,
         -1.3107e-02,  6.5384e-03],
        ...,
        [ 1.5793e-02,  2.0809e-03,  1.9424e-02,  ...,  2.6367e-02,
          1.0529e-02, -2.1439e-02],
        [-5.6992e-03,  4.1580e-04,  3.8116e-02,  ...,  1.6739e-02,
         -9.0103e-03, -1.6327e-02],
        [ 2.8789e-05, -9.8114e-03,  1.0004e-03,  ..., -2.2293e-02,
         -3.0365e-02,  6.1569e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias': tensor([-0.0072, -1.4619,  0.3447,  ..., -0.6147, -0.3474, -0.6455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight': tensor([[ 5.2567e-03,  1.1238e-02, -6.8092e-03,  ..., -8.0013e-04,
          1.5930e-02, -1.4336e-02],
        [-6.6223e-03,  1.9255e-03, -1.6006e-02,  ..., -2.0706e-02,
         -1.1848e-02, -1.1147e-02],
        [ 2.3087e-02,  1.1986e-02, -1.7288e-02,  ...,  5.7144e-03,
          1.4824e-02, -1.6876e-02],
        ...,
        [ 1.6647e-02,  5.3596e-03, -1.5154e-03,  ..., -2.9736e-03,
          1.8129e-03,  1.0559e-02],
        [ 4.1847e-03,  8.3694e-03,  1.2535e-02,  ..., -1.0323e-02,
          1.6327e-02, -3.2544e-05],
        [ 1.0185e-03, -2.1400e-03, -4.4098e-03,  ..., -4.6120e-03,
          6.0921e-03,  1.5152e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias': tensor([-0.0087, -0.0482, -0.0096,  ..., -0.0479, -0.1366,  0.0062],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight': tensor([0.8506, 0.6484, 0.8960,  ..., 1.2539, 0.7212, 0.8564],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias': tensor([-0.0077,  0.0670, -0.0532,  ..., -0.1699, -0.0490,  0.0434],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight': tensor([[ 0.0058,  0.0115,  0.0089,  ..., -0.0020, -0.0053,  0.0026],
        [-0.0017, -0.0024,  0.0162,  ...,  0.0009, -0.0208, -0.0094],
        [-0.0388, -0.0012, -0.0004,  ...,  0.0032, -0.0029, -0.0226],
        ...,
        [ 0.0085,  0.0130,  0.0209,  ..., -0.0057, -0.0040, -0.0012],
        [ 0.0260,  0.0055,  0.0095,  ..., -0.0008,  0.0056, -0.0098],
        [ 0.0116,  0.0073, -0.0117,  ...,  0.0011, -0.0095, -0.0163]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias': tensor([-0.4192, -0.2394, -0.3069,  ..., -0.3667, -0.2563, -0.1315],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight': tensor([[ 0.0154, -0.0020, -0.0083,  ...,  0.0161, -0.0060,  0.0146],
        [ 0.0042,  0.0226,  0.0055,  ...,  0.0110,  0.0033,  0.0034],
        [ 0.0140, -0.0083,  0.0006,  ...,  0.0085,  0.0010,  0.0007],
        ...,
        [-0.0025, -0.0010, -0.0020,  ...,  0.0007, -0.0030, -0.0018],
        [-0.0141, -0.0032, -0.0003,  ...,  0.0106, -0.0021, -0.0400],
        [ 0.0069,  0.0051, -0.0135,  ..., -0.0115,  0.0067, -0.0104]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias': tensor([-0.0416,  0.0127, -0.0229,  ...,  0.0723, -0.0145, -0.0363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight': tensor([1.1514, 0.7275, 1.1299,  ..., 1.0918, 0.8794, 1.1055],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias': tensor([ 0.0418, -0.1718, -0.0305,  ...,  0.0424, -0.2144, -0.0068],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight': tensor([[ 0.0195, -0.0016, -0.0010,  ...,  0.1302, -0.0123, -0.0063],
        [-0.0176,  0.0024, -0.0196,  ..., -0.1481, -0.0101, -0.0231],
        [-0.0042, -0.0077,  0.0033,  ...,  0.0850, -0.0172,  0.0256],
        ...,
        [ 0.0024, -0.0123,  0.0282,  ..., -0.0123,  0.0272,  0.0247],
        [ 0.0084, -0.0235,  0.0189,  ...,  0.0040, -0.0171,  0.0120],
        [ 0.0308, -0.0003,  0.0095,  ..., -0.0054, -0.0117, -0.0379]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias': tensor([-0.0049,  0.0073,  0.0145,  ...,  0.0185, -0.0033,  0.0204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight': tensor([[ 0.0096,  0.0166, -0.0025,  ..., -0.0005,  0.0005,  0.0034],
        [ 0.0066,  0.0109, -0.0074,  ...,  0.0010,  0.0079, -0.0095],
        [-0.0074, -0.0047,  0.0016,  ...,  0.0002,  0.0039,  0.0040],
        ...,
        [-0.0159,  0.0166, -0.0176,  ...,  0.0020, -0.0064,  0.0302],
        [ 0.0316, -0.0076, -0.0238,  ..., -0.0002, -0.0032, -0.0157],
        [-0.0096, -0.0192,  0.0207,  ..., -0.0009, -0.0289, -0.0082]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias': tensor([ 0.0264, -0.0288,  0.0074,  ...,  0.0075, -0.0047,  0.0190],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight': tensor([[ 0.0136, -0.0235, -0.0059,  ...,  0.0935,  0.0115, -0.0124],
        [-0.0146, -0.0224,  0.0003,  ..., -0.1112, -0.0056, -0.0134],
        [-0.0018,  0.0100,  0.0052,  ...,  0.0525,  0.0120,  0.0163],
        ...,
        [ 0.0338,  0.0004,  0.0047,  ..., -0.0146,  0.0189, -0.0173],
        [ 0.0022, -0.0096, -0.0040,  ...,  0.0011, -0.0013,  0.0135],
        [ 0.0178,  0.0135,  0.0019,  ..., -0.0075,  0.0044, -0.0363]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias': tensor([ 0.2430,  0.3418, -0.1379,  ...,  0.0247,  1.4775,  0.2130],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight': tensor([[-0.0026,  0.0052,  0.0064,  ...,  0.0172, -0.0226,  0.0066],
        [-0.0029,  0.0043, -0.0091,  ..., -0.0054, -0.0009,  0.0137],
        [-0.0161,  0.0021,  0.0049,  ...,  0.0088,  0.0251, -0.0076],
        ...,
        [ 0.0092,  0.0003, -0.0009,  ..., -0.0040,  0.0036,  0.0044],
        [ 0.0016, -0.0087,  0.0108,  ..., -0.0028, -0.0046,  0.0207],
        [ 0.0181, -0.0077, -0.0030,  ..., -0.0368, -0.0015,  0.0158]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias': tensor([-0.0217,  0.0017,  0.0176,  ...,  0.0564, -0.0415, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight': tensor([0.8926, 0.8076, 1.0293,  ..., 2.0488, 0.9590, 0.9756],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias': tensor([-0.1279, -0.0777, -0.0509,  ..., -0.2275, -0.0558,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight': tensor([[ 0.0265,  0.0048,  0.0027,  ..., -0.0071,  0.0051,  0.0187],
        [ 0.0004,  0.0177,  0.0098,  ..., -0.0020, -0.0084,  0.0181],
        [-0.0045,  0.0070, -0.0007,  ..., -0.0080, -0.0070, -0.0316],
        ...,
        [-0.0285,  0.0282,  0.0047,  ...,  0.0006, -0.0079,  0.0194],
        [-0.0049, -0.0312, -0.0060,  ..., -0.0043,  0.0310, -0.0003],
        [ 0.0185,  0.0199,  0.0079,  ..., -0.0067, -0.0297, -0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias': tensor([-0.1132, -0.1494, -0.4023,  ..., -0.2355, -0.3335, -0.2045],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight': tensor([[-0.0180,  0.0037,  0.0069,  ..., -0.0019, -0.0086, -0.0024],
        [-0.0006, -0.0030, -0.0042,  ..., -0.0177,  0.0375, -0.0014],
        [-0.0129, -0.0050, -0.0065,  ...,  0.0015, -0.0005, -0.0149],
        ...,
        [ 0.0031,  0.0014, -0.0087,  ..., -0.0003,  0.0073,  0.0014],
        [ 0.0105,  0.0060,  0.0064,  ..., -0.0005, -0.0007,  0.0372],
        [-0.0087, -0.0052,  0.0026,  ..., -0.0113, -0.0085,  0.0098]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias': tensor([-0.0068,  0.0179, -0.0552,  ...,  0.1210, -0.0750, -0.1090],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight': tensor([1.1914, 0.9712, 1.2656,  ..., 0.1719, 0.9092, 1.1973],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias': tensor([-0.0956, -0.1851, -0.0547,  ...,  0.2583, -0.0542,  0.0387],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight': tensor([[ 0.0076, -0.0117, -0.0114,  ...,  0.0770, -0.0048, -0.0017],
        [-0.0195, -0.0001, -0.0053,  ...,  0.0370, -0.0298,  0.0023],
        [-0.0094, -0.0034,  0.0132,  ...,  0.0014,  0.0088, -0.0013],
        ...,
        [ 0.0047, -0.0200, -0.0213,  ..., -0.0028, -0.0125, -0.0193],
        [-0.0028,  0.0018, -0.0313,  ..., -0.0143, -0.0024,  0.0085],
        [-0.0081, -0.0074,  0.0052,  ..., -0.0006, -0.0049, -0.0085]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias': tensor([ 0.0311, -0.0070, -0.0134,  ...,  0.0024, -0.0121, -0.0230],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight': tensor([[ 0.0104, -0.0064, -0.0062,  ...,  0.0015,  0.0052, -0.0058],
        [ 0.0179, -0.0065, -0.0221,  ..., -0.0002, -0.0032, -0.0219],
        [-0.0078,  0.0084, -0.0027,  ..., -0.0003,  0.0120,  0.0011],
        ...,
        [-0.0272, -0.0105,  0.0010,  ..., -0.0082,  0.0024,  0.0062],
        [ 0.0284, -0.0029, -0.0178,  ..., -0.0007, -0.0008, -0.0054],
        [-0.0113,  0.0083,  0.0034,  ..., -0.0102,  0.0250,  0.0115]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias': tensor([ 0.0282,  0.0175, -0.0284,  ...,  0.0397, -0.0209, -0.1344],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight': tensor([[ 0.0094, -0.0159, -0.0203,  ...,  0.0367, -0.0055, -0.0276],
        [ 0.0029, -0.0178, -0.0045,  ..., -0.0709, -0.0047, -0.0184],
        [-0.0128,  0.0083,  0.0116,  ..., -0.0014,  0.0039,  0.0124],
        ...,
        [-0.0292,  0.0131, -0.0025,  ...,  0.0003, -0.0127, -0.0156],
        [-0.0237,  0.0121, -0.0025,  ..., -0.0010,  0.0081, -0.0145],
        [ 0.0137,  0.0139,  0.0163,  ...,  0.0071,  0.0116, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias': tensor([-1.8535,  0.1802,  2.3398,  ..., -0.0595, -0.0338,  0.0305],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight': tensor([[ 0.0028, -0.0249,  0.0077,  ...,  0.0163, -0.0069, -0.0036],
        [ 0.0140, -0.0086,  0.0026,  ...,  0.0077,  0.0073, -0.0239],
        [ 0.0044,  0.0041, -0.0237,  ..., -0.0202, -0.0074,  0.0211],
        ...,
        [-0.0025,  0.0102, -0.0030,  ...,  0.0096,  0.0018,  0.0186],
        [ 0.0052, -0.0034,  0.0046,  ..., -0.0001,  0.0089, -0.0238],
        [-0.0090,  0.0134,  0.0052,  ..., -0.0156, -0.0131,  0.0157]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias': tensor([ 0.0039,  0.0259, -0.0086,  ..., -0.0503, -0.0064, -0.0460],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight': tensor([1.1934, 1.1006, 1.2510,  ..., 1.4092, 1.1592, 1.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias': tensor([ 0.0223, -0.0916,  0.0971,  ..., -0.2983, -0.0408,  0.0070],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight': tensor([[-0.0150,  0.0078,  0.0025,  ..., -0.0011, -0.0016,  0.0092],
        [-0.0219,  0.0313,  0.0128,  ...,  0.0032,  0.0150,  0.0033],
        [-0.0176, -0.0190,  0.0216,  ...,  0.0038, -0.0361,  0.0145],
        ...,
        [ 0.0060, -0.0061, -0.0066,  ...,  0.0027, -0.0050, -0.0172],
        [-0.0283, -0.0057,  0.0115,  ..., -0.0054, -0.0136, -0.0057],
        [-0.0160,  0.0153, -0.0277,  ..., -0.0289, -0.0194,  0.0007]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias': tensor([-0.1221, -0.2144, -0.4114,  ..., -0.1118, -0.1782, -0.3628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight': tensor([[-0.0016,  0.0125, -0.0344,  ..., -0.0221,  0.0044, -0.0154],
        [-0.0039, -0.0351,  0.0205,  ...,  0.0108, -0.0206, -0.0023],
        [ 0.0063, -0.0273, -0.0012,  ...,  0.0131,  0.0057, -0.0150],
        ...,
        [-0.0002, -0.0069,  0.0022,  ..., -0.0065,  0.0032,  0.0088],
        [ 0.0108, -0.0061, -0.0134,  ..., -0.0061,  0.0058, -0.0083],
        [ 0.0133,  0.0173,  0.0049,  ...,  0.0188, -0.0199, -0.0074]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias': tensor([-0.0200,  0.0232, -0.0657,  ...,  0.1028, -0.0782, -0.1134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight': tensor([1.2578, 1.1084, 1.2061,  ..., 0.5884, 1.0264, 1.2910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias': tensor([-0.0061, -0.0651,  0.0878,  ...,  0.1716,  0.1021, -0.0355],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight': tensor([[-0.0184, -0.0017,  0.0284,  ..., -0.0922, -0.0121,  0.0085],
        [ 0.0216,  0.0109,  0.0091,  ..., -0.0531,  0.0165, -0.0052],
        [-0.0036,  0.0282,  0.0128,  ...,  0.0421, -0.0305, -0.0203],
        ...,
        [-0.0003, -0.0044, -0.0082,  ..., -0.0171,  0.0052,  0.0071],
        [ 0.0136, -0.0294, -0.0073,  ..., -0.0191, -0.0179,  0.0170],
        [-0.0079,  0.0298, -0.0092,  ...,  0.0071,  0.0015,  0.0033]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias': tensor([-0.0044, -0.0038, -0.0472,  ...,  0.0818,  0.0363, -0.0465],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight': tensor([[ 1.9028e-02,  3.3264e-03, -1.4641e-02,  ..., -4.6754e-04,
         -1.4366e-02,  1.6556e-02],
        [ 2.1267e-04, -1.5457e-02, -3.2166e-02,  ..., -2.4629e-04,
          5.9090e-03, -9.8267e-03],
        [-1.2535e-02, -1.2222e-02,  9.6970e-03,  ...,  1.7128e-03,
         -2.1992e-03,  3.7842e-03],
        ...,
        [ 1.0918e-02,  1.8097e-02,  1.2695e-02,  ...,  4.8494e-04,
          5.1918e-03, -1.9058e-02],
        [ 9.9792e-03, -1.2085e-02,  6.0320e-04,  ...,  3.4790e-03,
          1.0284e-02,  2.8300e-04],
        [ 2.2034e-02, -1.5373e-03, -2.1362e-02,  ...,  4.9706e-03,
         -4.9174e-05, -6.5117e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias': tensor([ 0.0094,  0.0439, -0.0031,  ..., -0.0485, -0.1193,  0.0170],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight': tensor([[-1.2352e-02,  2.3239e-02,  5.5618e-03,  ..., -5.1178e-02,
         -2.8687e-02,  2.2531e-05],
        [-1.0605e-02, -2.5497e-02,  1.1894e-02,  ..., -2.0462e-02,
         -8.5449e-04,  4.6265e-02],
        [ 8.6212e-03, -9.3765e-03,  5.9357e-03,  ...,  2.0432e-02,
         -2.2537e-02,  4.4495e-02],
        ...,
        [ 1.3062e-02, -5.5428e-03,  1.0025e-02,  ..., -4.5746e-02,
          6.3477e-03,  2.0248e-02],
        [ 9.6588e-03, -1.4442e-02, -2.0096e-02,  ...,  6.9542e-03,
          5.9013e-03, -3.3588e-03],
        [-5.3177e-03,  2.2705e-02, -2.1713e-02,  ...,  2.4307e-02,
          1.5465e-02, -8.3237e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias': tensor([ 0.0542, -0.0733,  0.2440,  ..., -0.3313, -0.1129,  0.1049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight': tensor([[-0.0227,  0.0130, -0.0113,  ..., -0.0045,  0.0108, -0.0190],
        [-0.0057, -0.0069,  0.0119,  ..., -0.0068,  0.0143,  0.0030],
        [ 0.0062,  0.0204,  0.0161,  ..., -0.0079, -0.0057,  0.0308],
        ...,
        [ 0.0001,  0.0003,  0.0048,  ...,  0.0089, -0.0032,  0.0210],
        [-0.0079,  0.0007,  0.0030,  ...,  0.0093, -0.0068, -0.0121],
        [-0.0154,  0.0158, -0.0231,  ..., -0.0158,  0.0141, -0.0072]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias': tensor([-0.0179,  0.0685, -0.0152,  ..., -0.0815,  0.0257,  0.0175],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight': tensor([1.1738, 1.1582, 1.1592,  ..., 1.5869, 1.1748, 1.2314],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias': tensor([-0.0068,  0.0917, -0.0354,  ..., -0.3271, -0.1141, -0.0543],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight': tensor([[-0.0195, -0.0128, -0.0054,  ..., -0.0029, -0.0047,  0.0116],
        [-0.0031, -0.0199,  0.0011,  ..., -0.0044,  0.0127,  0.0019],
        [ 0.0130, -0.0056,  0.0037,  ..., -0.0005,  0.0237,  0.0081],
        ...,
        [ 0.0115,  0.0130, -0.0272,  ...,  0.0021,  0.0227,  0.0057],
        [-0.0035,  0.0108, -0.0211,  ..., -0.0011,  0.0154, -0.0001],
        [-0.0336,  0.0183,  0.0121,  ..., -0.0012, -0.0093,  0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias': tensor([-0.3628, -0.2211, -0.1648,  ..., -0.2524, -0.2686, -0.2517],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight': tensor([[-4.5166e-03,  7.6828e-03,  1.3664e-02,  ..., -2.5959e-03,
         -2.0126e-02, -7.1602e-03],
        [-1.4015e-02,  2.0084e-03,  6.2370e-03,  ...,  1.9714e-02,
         -4.8294e-03, -2.3682e-02],
        [-4.3793e-03,  6.3400e-03,  5.3253e-03,  ...,  9.2888e-04,
          7.6599e-03, -1.8555e-02],
        ...,
        [-4.1809e-03, -1.8768e-03,  4.0741e-03,  ..., -1.5802e-03,
         -3.6144e-03,  8.3983e-05],
        [-2.7523e-03, -2.6489e-02, -1.3283e-02,  ...,  3.4904e-03,
         -1.4786e-02,  6.2981e-03],
        [-3.0880e-03, -2.1713e-02, -1.7853e-02,  ...,  1.1139e-02,
          7.2784e-03, -1.2558e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias': tensor([-0.0283,  0.0284, -0.0329,  ...,  0.0671, -0.0050, -0.0488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight': tensor([1.2725, 1.2539, 1.2041,  ..., 0.7529, 1.0645, 1.2422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias': tensor([ 0.0019, -0.0140,  0.0246,  ...,  0.2150, -0.1251, -0.2118],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0117,  0.0046,  ..., -0.0265, -0.0033,  0.0070],
        [ 0.0061,  0.0207, -0.0110,  ...,  0.0132,  0.0091,  0.0226],
        [-0.0012,  0.0130,  0.0031,  ...,  0.0025,  0.0157,  0.0028],
        ...,
        [ 0.0178,  0.0099,  0.0200,  ...,  0.0006, -0.0303, -0.0324],
        [-0.0035,  0.0138,  0.0245,  ..., -0.0032, -0.0065,  0.0055],
        [-0.0023,  0.0024, -0.0018,  ...,  0.0053,  0.0023, -0.0070]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias': tensor([ 0.1105, -0.0046,  0.0618,  ...,  0.0103, -0.0147,  0.0179],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight': tensor([[ 0.0128, -0.0147,  0.0370,  ..., -0.0059,  0.0019, -0.0157],
        [-0.0200,  0.0040, -0.0021,  ..., -0.0084, -0.0056, -0.0079],
        [-0.0030, -0.0037, -0.0301,  ..., -0.0076,  0.0190,  0.0188],
        ...,
        [ 0.0036,  0.0197, -0.0007,  ..., -0.0078,  0.0181, -0.0004],
        [-0.0112,  0.0034, -0.0117,  ...,  0.0041, -0.0017, -0.0116],
        [-0.0199,  0.0032, -0.0224,  ..., -0.0046,  0.0289,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias': tensor([-0.0085, -0.0267, -0.0139,  ..., -0.0130,  0.0113,  0.0014],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight': tensor([[-5.2223e-03, -1.1261e-02,  2.0859e-02,  ..., -3.4424e-02,
          5.4245e-03,  3.5515e-03],
        [ 2.7637e-03,  4.4861e-03,  5.6877e-03,  ...,  6.7830e-05,
         -1.3123e-02,  1.6266e-02],
        [-7.9575e-03,  6.3133e-03,  1.7059e-02,  ...,  2.5711e-03,
         -5.4283e-03, -1.0437e-02],
        ...,
        [-1.2264e-03,  2.9633e-02, -8.0185e-03,  ...,  1.4366e-02,
          2.8824e-02, -1.8001e-05],
        [ 5.7316e-04,  8.2397e-03,  1.8951e-02,  ...,  1.4248e-03,
          1.8433e-02, -1.7624e-02],
        [ 6.5842e-03,  2.7451e-02, -1.9012e-02,  ...,  1.1887e-02,
         -7.3357e-03,  1.1284e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias': tensor([-0.8462,  0.0103, -1.0879,  ..., -0.1941,  0.1663, -1.2803],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight': tensor([[-0.0020,  0.0252,  0.0039,  ...,  0.0061, -0.0123,  0.0283],
        [ 0.0043,  0.0004, -0.0082,  ..., -0.0251,  0.0068,  0.0017],
        [-0.0231,  0.0006,  0.0164,  ...,  0.0248,  0.0101,  0.0125],
        ...,
        [ 0.0080,  0.0312,  0.0238,  ...,  0.0045,  0.0003,  0.0054],
        [ 0.0077,  0.0073, -0.0009,  ..., -0.0016,  0.0038, -0.0133],
        [ 0.0194, -0.0053, -0.0238,  ...,  0.0249, -0.0041,  0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias': tensor([-0.0205,  0.0181, -0.0017,  ..., -0.0779,  0.0408, -0.0200],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight': tensor([1.1533, 1.2090, 1.1787,  ..., 1.6367, 1.1729, 1.2188],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias': tensor([-0.0550,  0.0990, -0.0018,  ..., -0.1779, -0.0518, -0.0147],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight': tensor([[-0.0073, -0.0223,  0.0130,  ..., -0.0079, -0.0028,  0.0022],
        [-0.0071,  0.0068,  0.0017,  ..., -0.0123, -0.0179, -0.0108],
        [ 0.0072,  0.0217,  0.0110,  ...,  0.0060,  0.0005,  0.0016],
        ...,
        [ 0.0225, -0.0085,  0.0064,  ...,  0.0007,  0.0014, -0.0003],
        [-0.0191,  0.0245,  0.0085,  ..., -0.0102, -0.0108, -0.0063],
        [ 0.0290, -0.0322, -0.0287,  ..., -0.0045,  0.0156, -0.0153]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias': tensor([-0.4795, -0.1469, -0.1043,  ..., -0.2998, -0.2252, -0.3262],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight': tensor([[-0.0205,  0.0170, -0.0019,  ...,  0.0084,  0.0040,  0.0268],
        [ 0.0060,  0.0025, -0.0069,  ...,  0.0071, -0.0261,  0.0028],
        [ 0.0291, -0.0064, -0.0019,  ..., -0.0131,  0.0078, -0.0294],
        ...,
        [-0.0110,  0.0011, -0.0081,  ..., -0.0030,  0.0036, -0.0003],
        [-0.0195,  0.0083,  0.0063,  ...,  0.0095, -0.0105,  0.0214],
        [-0.0028,  0.0316,  0.0016,  ..., -0.0094, -0.0051,  0.0145]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias': tensor([ 0.0411, -0.0040, -0.0517,  ...,  0.1116,  0.0086, -0.0608],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight': tensor([1.3838, 1.2871, 1.2334,  ..., 0.6108, 1.1768, 1.2568],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias': tensor([-0.2367,  0.0573,  0.1235,  ...,  0.2408,  0.0240, -0.0257],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight': tensor([[-0.0176,  0.0033,  0.0183,  ..., -0.0038,  0.0074,  0.0088],
        [-0.0091,  0.0276, -0.0216,  ...,  0.0220,  0.0110,  0.0020],
        [-0.0428, -0.0160,  0.0246,  ...,  0.0130, -0.0163, -0.0116],
        ...,
        [ 0.0326,  0.0183, -0.0093,  ...,  0.0212, -0.0169,  0.0020],
        [ 0.0131,  0.0204,  0.0034,  ...,  0.0138,  0.0030,  0.0125],
        [ 0.0216,  0.0034,  0.0112,  ..., -0.0203,  0.0063, -0.0135]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias': tensor([-0.0005,  0.0142, -0.0017,  ...,  0.0816, -0.0667,  0.0688],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight': tensor([[-0.0305, -0.0173,  0.0406,  ...,  0.0054,  0.0093, -0.0001],
        [ 0.0040,  0.0132, -0.0068,  ..., -0.0034, -0.0217, -0.0175],
        [-0.0051,  0.0121, -0.0121,  ..., -0.0104, -0.0141, -0.0050],
        ...,
        [ 0.0016,  0.0205, -0.0056,  ..., -0.0040, -0.0046,  0.0020],
        [ 0.0378,  0.0040, -0.0073,  ...,  0.0001, -0.0014,  0.0133],
        [ 0.0088, -0.0021, -0.0040,  ..., -0.0019,  0.0257, -0.0056]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias': tensor([-0.0842, -0.0092,  0.0031,  ...,  0.0677, -0.0071,  0.0129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight': tensor([[ 0.0169, -0.0117, -0.0191,  ...,  0.0101, -0.0038,  0.0100],
        [-0.0080,  0.0092,  0.0094,  ...,  0.0197, -0.0175, -0.0183],
        [-0.0264, -0.0041,  0.0021,  ...,  0.0114,  0.0084, -0.0139],
        ...,
        [-0.0015,  0.0094,  0.0175,  ...,  0.0220, -0.0158,  0.0012],
        [-0.0012,  0.0214, -0.0034,  ...,  0.0166, -0.0191,  0.0039],
        [ 0.0204, -0.0130,  0.0074,  ..., -0.0208,  0.0063, -0.0040]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias': tensor([ 0.0173,  0.2045, -0.1959,  ..., -0.0136, -0.0571, -0.2710],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight': tensor([[ 1.1879e-02, -8.7357e-03, -2.2980e-02,  ..., -5.5885e-03,
         -2.6260e-02,  1.4985e-04],
        [ 2.3117e-02, -1.8127e-02,  2.0111e-02,  ..., -5.3711e-03,
         -3.0880e-03, -2.6855e-03],
        [-7.4577e-03,  5.7449e-03, -2.7313e-02,  ...,  2.7695e-03,
          7.9803e-03,  1.0475e-02],
        ...,
        [-1.1810e-02,  1.0620e-02,  1.4153e-02,  ...,  7.8049e-03,
          7.3671e-04,  2.8267e-03],
        [ 6.1150e-03,  1.5244e-02,  2.3621e-02,  ...,  9.0599e-05,
          2.7008e-03, -3.2196e-02],
        [ 3.8743e-04, -6.6109e-03, -1.4534e-02,  ...,  1.1330e-03,
         -1.8280e-02, -3.4065e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias': tensor([-0.0230,  0.0388, -0.0072,  ..., -0.0651,  0.0296, -0.0002],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight': tensor([1.2031, 1.2344, 1.1543,  ..., 1.5986, 1.2275, 1.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias': tensor([-0.0587,  0.0094, -0.0588,  ..., -0.2544, -0.1669, -0.0670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight': tensor([[-0.0105, -0.0159, -0.0260,  ..., -0.0012,  0.0033,  0.0001],
        [ 0.0232, -0.0237,  0.0074,  ..., -0.0032,  0.0108,  0.0003],
        [ 0.0088,  0.0072,  0.0034,  ...,  0.0001, -0.0065,  0.0012],
        ...,
        [ 0.0007, -0.0093,  0.0181,  ..., -0.0021, -0.0059,  0.0082],
        [ 0.0024,  0.0102, -0.0177,  ..., -0.0005, -0.0069, -0.0302],
        [ 0.0112,  0.0245,  0.0004,  ...,  0.0030, -0.0044,  0.0190]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias': tensor([-0.1327, -0.2241, -0.0568,  ..., -0.2708, -0.3245, -0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight': tensor([[ 1.0185e-02, -1.1162e-02, -2.3911e-02,  ...,  2.9709e-02,
         -1.3023e-02, -1.1803e-02],
        [ 8.2092e-03, -4.3631e-04, -3.1257e-04,  ..., -1.3252e-02,
          5.4598e-05, -1.8997e-02],
        [ 5.5885e-03,  1.8112e-02,  9.0179e-03,  ..., -3.1700e-03,
          8.4686e-03, -3.6144e-03],
        ...,
        [ 4.7798e-03,  3.0174e-03, -3.5143e-04,  ...,  5.4665e-03,
         -3.4122e-03, -4.2953e-03],
        [ 3.2082e-03, -1.4816e-02, -9.4986e-04,  ..., -1.9455e-02,
         -9.8825e-05,  9.9869e-03],
        [-7.2784e-03, -5.8289e-03, -3.9062e-03,  ...,  5.5122e-03,
         -2.4323e-02, -2.7542e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias': tensor([ 0.0389,  0.0069, -0.0129,  ...,  0.0417,  0.0218,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight': tensor([1.4287, 1.3613, 1.2949,  ..., 1.0137, 1.1826, 1.3213],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias': tensor([-0.1137,  0.0275,  0.0679,  ...,  0.1796,  0.0205, -0.2534],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight': tensor([[ 0.0030,  0.0209, -0.0001,  ..., -0.0044,  0.0148,  0.0093],
        [-0.0027, -0.0116,  0.0012,  ...,  0.0060, -0.0152, -0.0084],
        [-0.0064,  0.0066, -0.0148,  ..., -0.0031, -0.0160,  0.0061],
        ...,
        [ 0.0134, -0.0141, -0.0170,  ...,  0.0031, -0.0175,  0.0096],
        [ 0.0032, -0.0072,  0.0027,  ...,  0.0026,  0.0248,  0.0016],
        [ 0.0372, -0.0190,  0.0259,  ..., -0.0076,  0.0134,  0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias': tensor([ 0.0132, -0.0158,  0.0312,  ...,  0.1599,  0.0190, -0.0702],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight': tensor([[-0.0019,  0.0161, -0.0136,  ...,  0.0041,  0.0124, -0.0042],
        [ 0.0003, -0.0210,  0.0050,  ...,  0.0030, -0.0272,  0.0083],
        [-0.0101, -0.0327, -0.0195,  ..., -0.0035,  0.0067, -0.0172],
        ...,
        [ 0.0214, -0.0060, -0.0126,  ..., -0.0054, -0.0032,  0.0097],
        [-0.0153, -0.0010, -0.0009,  ...,  0.0023, -0.0131,  0.0013],
        [ 0.0080,  0.0060,  0.0053,  ..., -0.0054, -0.0073,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias': tensor([-0.0223, -0.0200, -0.0063,  ..., -0.0170, -0.0150,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight': tensor([[-0.0132,  0.0006,  0.0249,  ..., -0.0071,  0.0142, -0.0221],
        [-0.0046,  0.0369, -0.0272,  ...,  0.0017,  0.0163,  0.0032],
        [-0.0089, -0.0084,  0.0370,  ..., -0.0099,  0.0085,  0.0120],
        ...,
        [ 0.0223, -0.0226, -0.0282,  ...,  0.0133, -0.0224, -0.0005],
        [ 0.0005, -0.0127, -0.0058,  ..., -0.0071,  0.0076, -0.0049],
        [-0.0067,  0.0026,  0.0143,  ...,  0.0054, -0.0011,  0.0246]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias': tensor([-0.0499, -0.0381,  0.5078,  ..., -0.0939, -1.3535,  0.2761],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight': tensor([[ 0.0038,  0.0181,  0.0089,  ..., -0.0054,  0.0091,  0.0008],
        [-0.0116,  0.0084,  0.0211,  ...,  0.0138,  0.0282, -0.0086],
        [ 0.0388,  0.0029,  0.0070,  ..., -0.0161,  0.0043, -0.0173],
        ...,
        [ 0.0053, -0.0073, -0.0049,  ...,  0.0171, -0.0165,  0.0032],
        [ 0.0020, -0.0032,  0.0069,  ...,  0.0089,  0.0018,  0.0021],
        [ 0.0025, -0.0044,  0.0106,  ..., -0.0193,  0.0141, -0.0083]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias': tensor([ 0.0060,  0.0680,  0.0354,  ..., -0.0553,  0.0136,  0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight': tensor([1.2344, 1.2090, 1.1689,  ..., 1.8428, 1.1562, 1.2676],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias': tensor([-0.0174, -0.0716, -0.1256,  ..., -0.2900, -0.1460,  0.1504],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight': tensor([[-0.0042, -0.0027,  0.0133,  ..., -0.0005,  0.0226, -0.0110],
        [ 0.0404,  0.0308,  0.0195,  ...,  0.0055, -0.0234,  0.0145],
        [-0.0008, -0.0259, -0.0103,  ...,  0.0008,  0.0100,  0.0084],
        ...,
        [ 0.0190, -0.0154,  0.0061,  ..., -0.0111, -0.0397,  0.0165],
        [ 0.0025, -0.0002,  0.0089,  ..., -0.0010, -0.0172, -0.0077],
        [ 0.0183, -0.0069, -0.0037,  ...,  0.0029, -0.0036,  0.0130]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias': tensor([-0.2314, -0.3215, -0.0735,  ..., -0.3020, -0.1613, -0.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight': tensor([[ 1.0155e-02,  3.2532e-02,  8.2626e-03,  ..., -6.4468e-03,
         -4.7760e-03,  5.5432e-06],
        [-1.1612e-02,  1.7509e-03,  2.4841e-02,  ...,  8.9645e-03,
         -2.5436e-02, -8.4152e-03],
        [ 1.5182e-02,  7.3395e-03,  6.1264e-03,  ..., -1.5427e-02,
         -1.8677e-02,  1.9806e-02],
        ...,
        [-5.6686e-03,  6.3848e-04,  4.5128e-03,  ..., -9.9792e-03,
          1.1284e-02,  6.5231e-04],
        [-3.6335e-03,  3.6285e-02, -9.9277e-04,  ...,  4.8828e-03,
          9.6283e-03,  1.3008e-02],
        [ 9.3918e-03, -2.1927e-02, -1.4038e-02,  ...,  1.3329e-02,
          5.4359e-03,  3.3169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias': tensor([0.0373, 0.0198, 0.0018,  ..., 0.0559, 0.0675, 0.0106],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight': tensor([1.4990, 1.4297, 1.3555,  ..., 0.9502, 1.1816, 1.4072],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias': tensor([-0.1736, -0.0029,  0.0179,  ...,  0.2495,  0.0637, -0.1158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight': tensor([[ 0.0138, -0.0022,  0.0212,  ...,  0.0048,  0.0084,  0.0082],
        [-0.0165, -0.0025,  0.0060,  ...,  0.0063,  0.0062, -0.0098],
        [ 0.0116,  0.0009,  0.0094,  ...,  0.0054,  0.0176,  0.0027],
        ...,
        [ 0.0160, -0.0161,  0.0148,  ..., -0.0268,  0.0052,  0.0090],
        [-0.0136,  0.0253, -0.0004,  ...,  0.0156,  0.0059,  0.0038],
        [-0.0080,  0.0130, -0.0251,  ...,  0.0136, -0.0164,  0.0184]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias': tensor([ 0.1146,  1.0303,  0.1827,  ...,  0.0439,  0.0025, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0085, -0.0074,  ...,  0.0006, -0.0214, -0.0142],
        [ 0.0022,  0.0155, -0.0111,  ..., -0.0004, -0.0232, -0.0101],
        [-0.0139,  0.0073, -0.0043,  ..., -0.0005, -0.0110, -0.0235],
        ...,
        [ 0.0153,  0.0130, -0.0090,  ...,  0.0045,  0.0109,  0.0025],
        [ 0.0072,  0.0052, -0.0024,  ..., -0.0120,  0.0016, -0.0072],
        [ 0.0013, -0.0272, -0.0105,  ..., -0.0043,  0.0004, -0.0020]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias': tensor([ 0.0573, -0.0360, -0.0042,  ...,  0.0485, -0.0465,  0.0206],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight': tensor([[ 0.0094,  0.0003,  0.0279,  ...,  0.0015, -0.0191,  0.0090],
        [ 0.0041, -0.0014,  0.0020,  ...,  0.0017, -0.0018,  0.0040],
        [-0.0280,  0.0335,  0.0134,  ...,  0.0017,  0.0047, -0.0206],
        ...,
        [-0.0081, -0.0019,  0.0095,  ..., -0.0111, -0.0239,  0.0087],
        [-0.0195, -0.0019,  0.0218,  ...,  0.0267,  0.0121, -0.0089],
        [-0.0340, -0.0066,  0.0098,  ...,  0.0160,  0.0019, -0.0100]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias': tensor([ 0.2460,  1.7949,  0.0708,  ..., -0.2112,  0.1188,  0.6323],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight': tensor([[ 0.0051,  0.0107, -0.0119,  ..., -0.0148,  0.0005, -0.0302],
        [-0.0066, -0.0071, -0.0048,  ..., -0.0226, -0.0094,  0.0276],
        [ 0.0101,  0.0083,  0.0168,  ..., -0.0064,  0.0009, -0.0152],
        ...,
        [ 0.0094, -0.0071,  0.0016,  ..., -0.0147,  0.0114,  0.0020],
        [ 0.0223,  0.0076,  0.0287,  ..., -0.0214,  0.0006,  0.0041],
        [ 0.0177,  0.0222,  0.0063,  ...,  0.0065,  0.0120, -0.0114]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias': tensor([ 0.0267, -0.0057, -0.0027,  ..., -0.0531, -0.0267,  0.0482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight': tensor([1.2383, 1.2549, 1.2197,  ..., 1.8193, 1.1484, 1.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias': tensor([ 0.1250, -0.0352,  0.1172,  ..., -0.1227, -0.0328,  0.1005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight': tensor([[-0.0007, -0.0112,  0.0090,  ..., -0.0016,  0.0087,  0.0027],
        [ 0.0122, -0.0152,  0.0042,  ..., -0.0079, -0.0033, -0.0148],
        [ 0.0095, -0.0118, -0.0270,  ...,  0.0040,  0.0046, -0.0246],
        ...,
        [-0.0209, -0.0194, -0.0025,  ..., -0.0006, -0.0144,  0.0085],
        [ 0.0016,  0.0133,  0.0006,  ..., -0.0033, -0.0143,  0.0128],
        [-0.0106,  0.0115,  0.0019,  ..., -0.0046, -0.0505,  0.0052]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias': tensor([-0.3506, -0.3098, -0.0692,  ..., -0.3076, -0.2494, -0.4229],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight': tensor([[-0.0116,  0.0186, -0.0109,  ...,  0.0093, -0.0051, -0.0192],
        [ 0.0115,  0.0091,  0.0046,  ...,  0.0060, -0.0104, -0.0086],
        [-0.0004,  0.0162,  0.0221,  ...,  0.0048,  0.0374,  0.0092],
        ...,
        [-0.0029,  0.0068, -0.0073,  ...,  0.0019, -0.0060,  0.0068],
        [ 0.0121, -0.0012, -0.0035,  ..., -0.0168, -0.0036, -0.0015],
        [ 0.0085, -0.0005,  0.0138,  ..., -0.0026,  0.0074, -0.0113]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias': tensor([ 0.0374, -0.0088, -0.0430,  ...,  0.0654, -0.0126, -0.0253],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight': tensor([1.5195, 1.3818, 1.3984,  ..., 0.8403, 1.2627, 1.5020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias': tensor([-0.1865,  0.1162,  0.4048,  ...,  0.2292,  0.4202, -0.0959],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight': tensor([[ 0.0295,  0.0205, -0.0174,  ...,  0.0181,  0.0055,  0.0153],
        [ 0.0159, -0.0236, -0.0138,  ...,  0.0058,  0.0019,  0.0084],
        [-0.0116, -0.0219,  0.0080,  ...,  0.0020, -0.0022,  0.0255],
        ...,
        [-0.0140,  0.0030, -0.0549,  ...,  0.0038, -0.0079,  0.0469],
        [-0.0193,  0.0216, -0.0092,  ...,  0.0083,  0.0186,  0.0123],
        [ 0.0039,  0.0084,  0.0082,  ..., -0.0016, -0.0041, -0.0187]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias': tensor([-0.0278, -0.0587, -0.0110,  ..., -0.0826, -0.0213, -0.0725],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight': tensor([[-0.0007,  0.0020,  0.0042,  ..., -0.0033, -0.0094, -0.0123],
        [ 0.0162,  0.0139,  0.0239,  ..., -0.0017, -0.0188,  0.0138],
        [-0.0234,  0.0133, -0.0101,  ..., -0.0029, -0.0003,  0.0196],
        ...,
        [ 0.0244,  0.0202,  0.0058,  ..., -0.0130,  0.0092, -0.0032],
        [ 0.0215,  0.0236, -0.0171,  ..., -0.0159, -0.0069,  0.0134],
        [-0.0087,  0.0025,  0.0248,  ..., -0.0004,  0.0047, -0.0208]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias': tensor([-0.0305,  0.0005, -0.0124,  ..., -0.0511, -0.0883,  0.0079],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight': tensor([[-0.0156,  0.0022, -0.0072,  ...,  0.0036,  0.0290,  0.0180],
        [-0.0003,  0.0088, -0.0014,  ..., -0.0144, -0.0101,  0.0001],
        [-0.0141, -0.0287,  0.0098,  ..., -0.0024,  0.0292,  0.0254],
        ...,
        [-0.0255,  0.0364, -0.0171,  ...,  0.0032,  0.0116, -0.0182],
        [-0.0159,  0.0349, -0.0009,  ..., -0.0083, -0.0006, -0.0242],
        [-0.0239,  0.0287,  0.0045,  ...,  0.0057, -0.0037, -0.0132]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias': tensor([-0.2856, -0.3130, -0.2024,  ...,  0.1942, -0.0307, -0.0692],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight': tensor([[ 0.0021, -0.0248,  0.0393,  ..., -0.0213, -0.0080,  0.0129],
        [-0.0123, -0.0083,  0.0236,  ..., -0.0091, -0.0172, -0.0205],
        [-0.0194, -0.0024,  0.0146,  ..., -0.0071,  0.0185, -0.0175],
        ...,
        [-0.0277,  0.0011, -0.0187,  ...,  0.0559,  0.0597, -0.0009],
        [ 0.0156,  0.0051, -0.0020,  ..., -0.0031,  0.0066,  0.0040],
        [-0.0057, -0.0281, -0.0138,  ...,  0.0075, -0.0093,  0.0108]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias': tensor([ 0.0077,  0.0031,  0.0012,  ..., -0.0701,  0.0300,  0.0083],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight': tensor([1.2822, 1.2529, 1.2988,  ..., 2.2090, 1.1758, 1.3721],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias': tensor([ 0.1495, -0.0801, -0.0723,  ..., -0.1654, -0.0899,  0.0350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight': tensor([[ 0.0063,  0.0413,  0.0369,  ...,  0.0064,  0.0150,  0.0227],
        [ 0.0141,  0.0154,  0.0189,  ...,  0.0018,  0.0107,  0.0041],
        [-0.0081, -0.0167,  0.0103,  ..., -0.0018, -0.0027,  0.0110],
        ...,
        [ 0.0142,  0.0290,  0.0162,  ..., -0.0030,  0.0042,  0.0023],
        [ 0.0167,  0.0140,  0.0168,  ..., -0.0036, -0.0046,  0.0118],
        [-0.0082,  0.0164,  0.0227,  ...,  0.0009, -0.0199, -0.0222]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias': tensor([-0.2788, -0.1959, -0.3855,  ..., -0.3228, -0.2610, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight': tensor([[-6.8474e-03, -1.1681e-02, -1.7517e-02,  ...,  1.0986e-02,
         -1.8341e-02,  2.0432e-02],
        [ 1.1215e-02, -7.8430e-03, -6.9542e-03,  ...,  1.2108e-02,
         -9.6741e-03, -1.2093e-02],
        [ 1.2321e-02, -2.7924e-02, -2.8896e-03,  ...,  4.8676e-03,
         -2.0275e-03, -1.2695e-02],
        ...,
        [-2.5902e-03,  1.4412e-02, -3.3092e-03,  ..., -2.8193e-05,
          6.4087e-04, -7.4434e-04],
        [-1.8280e-02, -8.6746e-03,  9.6130e-03,  ...,  4.2915e-03,
         -1.1269e-02,  2.3453e-02],
        [-6.6452e-03, -2.1088e-02, -1.2444e-02,  ..., -3.5534e-03,
         -7.8659e-03,  2.5589e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias': tensor([ 0.0329,  0.0112, -0.0181,  ...,  0.0332,  0.0061, -0.0410],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight': tensor([1.6201, 1.4990, 1.4219,  ..., 0.7642, 1.2715, 1.4961],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias': tensor([-0.1376, -0.0238, -0.0118,  ...,  0.3352,  0.1462, -0.0976],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight': tensor([[ 0.0070,  0.0068,  0.0031,  ...,  0.0113, -0.0308, -0.0060],
        [ 0.0026, -0.0039,  0.0043,  ..., -0.0343, -0.0066,  0.0307],
        [-0.0036,  0.0332, -0.0028,  ...,  0.0011, -0.0337,  0.0031],
        ...,
        [-0.0229, -0.0187, -0.0097,  ..., -0.0007,  0.0183, -0.0038],
        [ 0.0047,  0.0152, -0.0175,  ...,  0.0070,  0.0130, -0.0114],
        [-0.0206,  0.0068, -0.0252,  ...,  0.0070, -0.0134, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias': tensor([ 0.1860, -0.2378,  0.0005,  ...,  0.0031,  0.1797, -0.0522],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight': tensor([[-0.0298, -0.0140,  0.0248,  ...,  0.0035, -0.0014, -0.0059],
        [-0.0006, -0.0080,  0.0046,  ...,  0.0036,  0.0106, -0.0112],
        [ 0.0055,  0.0188,  0.0175,  ...,  0.0029, -0.0033, -0.0018],
        ...,
        [ 0.0039, -0.0129,  0.0162,  ...,  0.0032, -0.0222, -0.0056],
        [-0.0039, -0.0104,  0.0050,  ..., -0.0019,  0.0213, -0.0076],
        [ 0.0024,  0.0067, -0.0013,  ..., -0.0021,  0.0013,  0.0046]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias': tensor([ 0.0186, -0.0095,  0.0066,  ...,  0.0210,  0.0131,  0.0208],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight': tensor([[ 0.0029, -0.0233, -0.0027,  ...,  0.0144, -0.0352, -0.0105],
        [-0.0247, -0.0116,  0.0012,  ..., -0.0372,  0.0113, -0.0128],
        [ 0.0080, -0.0012, -0.0150,  ...,  0.0013, -0.0024,  0.0199],
        ...,
        [-0.0113, -0.0235, -0.0017,  ...,  0.0006, -0.0010, -0.0029],
        [ 0.0197, -0.0205, -0.0153,  ...,  0.0061,  0.0182,  0.0045],
        [-0.0173, -0.0083,  0.0412,  ...,  0.0141, -0.0057,  0.0143]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias': tensor([ 0.2690, -0.1337,  0.1326,  ...,  0.5728, -0.2661, -0.0468],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight': tensor([[ 0.0029,  0.0160,  0.0056,  ...,  0.0018,  0.0077, -0.0090],
        [ 0.0110, -0.0064,  0.0049,  ...,  0.0272,  0.0262,  0.0051],
        [-0.0114, -0.0032,  0.0054,  ...,  0.0236, -0.0132, -0.0082],
        ...,
        [-0.0007,  0.0021, -0.0044,  ..., -0.0028, -0.0311, -0.0200],
        [-0.0074, -0.0073, -0.0035,  ..., -0.0198, -0.0346, -0.0070],
        [-0.0123, -0.0216,  0.0046,  ...,  0.0036,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias': tensor([-0.0063, -0.0193, -0.0133,  ...,  0.0398,  0.0332,  0.0196],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight': tensor([1.3359, 1.2266, 1.2646,  ..., 1.9346, 1.1377, 1.3818],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias': tensor([ 0.1417,  0.0006,  0.0168,  ...,  0.0170, -0.0730,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight': tensor([[ 0.0115,  0.0003, -0.0145,  ..., -0.0144, -0.0194, -0.0104],
        [-0.0015,  0.0058,  0.0179,  ..., -0.0030,  0.0044, -0.0100],
        [-0.0029,  0.0045,  0.0084,  ..., -0.0206,  0.0133,  0.0283],
        ...,
        [ 0.0059, -0.0118, -0.0161,  ..., -0.0221, -0.0054,  0.0157],
        [ 0.0215, -0.0010,  0.0022,  ...,  0.0130,  0.0179,  0.0099],
        [ 0.0113,  0.0054, -0.0108,  ...,  0.0036,  0.0090, -0.0237]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias': tensor([-0.2153, -0.2783, -0.3320,  ..., -0.1221, -0.1306, -0.2898],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight': tensor([[-0.0038, -0.0308,  0.0166,  ..., -0.0028, -0.0180,  0.0016],
        [ 0.0179,  0.0086,  0.0044,  ...,  0.0105,  0.0129, -0.0061],
        [-0.0078, -0.0048,  0.0276,  ...,  0.0158, -0.0102,  0.0017],
        ...,
        [-0.0093,  0.0032, -0.0129,  ...,  0.0116, -0.0041, -0.0039],
        [-0.0126,  0.0043,  0.0086,  ...,  0.0042, -0.0106,  0.0038],
        [-0.0054, -0.0066, -0.0067,  ..., -0.0130, -0.0257,  0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias': tensor([ 0.0253, -0.0025, -0.0242,  ...,  0.0955,  0.0208, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight': tensor([1.6533, 1.5479, 1.5508,  ..., 0.4094, 1.3984, 1.6689],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias': tensor([-0.2152,  0.1279,  0.3982,  ...,  0.3850,  0.3862, -0.2152],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight': tensor([[ 0.0007,  0.0003,  0.0054,  ...,  0.0126,  0.0008,  0.0107],
        [-0.0359,  0.0132, -0.0041,  ..., -0.0473,  0.0050, -0.0005],
        [ 0.0122, -0.0012, -0.0178,  ..., -0.0031,  0.0207, -0.0100],
        ...,
        [ 0.0512, -0.0152, -0.0452,  ...,  0.0250, -0.0268,  0.0074],
        [ 0.0115,  0.0260, -0.0071,  ...,  0.0085,  0.0057,  0.0017],
        [ 0.0223, -0.0031, -0.0004,  ...,  0.0035, -0.0175,  0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias': tensor([-0.8135, -0.1840,  0.0576,  ..., -0.0189,  0.0277,  0.0699],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight': tensor([[ 2.6184e-02,  6.5842e-03, -6.6528e-03,  ...,  2.3901e-05,
          1.5297e-02, -1.9302e-02],
        [ 4.0741e-03,  3.0079e-03,  3.1090e-03,  ..., -9.0485e-03,
          1.0986e-02,  4.2953e-03],
        [ 4.1504e-03,  1.6336e-03, -1.1185e-02,  ...,  5.6496e-03,
          2.0889e-02, -1.3113e-04],
        ...,
        [-3.6945e-03,  1.4648e-02, -8.8348e-03,  ...,  8.1711e-03,
         -2.6073e-03,  1.3008e-02],
        [ 1.9562e-02, -1.5762e-02,  7.0877e-03,  ...,  6.5517e-04,
         -2.1744e-02, -2.0233e-02],
        [ 1.8417e-02, -1.2039e-02, -9.2239e-03,  ..., -4.6659e-04,
         -1.3191e-02, -7.4272e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias': tensor([ 0.0088,  0.0188,  0.0441,  ..., -0.0099, -0.0044,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight': tensor([[-0.0029,  0.0020, -0.0026,  ...,  0.0042, -0.0110, -0.0049],
        [-0.0278,  0.0302,  0.0003,  ..., -0.0331,  0.0236,  0.0125],
        [ 0.0239,  0.0206,  0.0083,  ..., -0.0029,  0.0212, -0.0040],
        ...,
        [ 0.0231,  0.0166, -0.0169,  ...,  0.0415, -0.0144,  0.0037],
        [ 0.0159,  0.0033, -0.0034,  ...,  0.0044, -0.0091,  0.0034],
        [ 0.0106, -0.0117, -0.0165,  ...,  0.0030, -0.0196,  0.0211]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias': tensor([-2.5234,  0.2341, -0.3838,  ..., -0.0643,  0.1272,  0.1238],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight': tensor([[-0.0296, -0.0036,  0.0027,  ...,  0.0065,  0.0073, -0.0128],
        [-0.0154, -0.0153,  0.0213,  ...,  0.0241,  0.0144,  0.0159],
        [-0.0073, -0.0148,  0.0064,  ...,  0.0165,  0.0177,  0.0191],
        ...,
        [-0.0013,  0.0025, -0.0111,  ..., -0.0081,  0.0079,  0.0101],
        [-0.0041, -0.0076, -0.0202,  ..., -0.0055,  0.0170,  0.0018],
        [ 0.0106, -0.0025,  0.0060,  ...,  0.0055, -0.0079,  0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias': tensor([ 0.0107, -0.0549,  0.0179,  ...,  0.0266,  0.0321, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight': tensor([1.3027, 1.2529, 1.3281,  ..., 1.4834, 1.1562, 1.3789],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias': tensor([ 0.1531,  0.0493, -0.0565,  ..., -0.0096, -0.0239, -0.0371],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight': tensor([[ 0.0043,  0.0120,  0.0113,  ..., -0.0241, -0.0064, -0.0090],
        [ 0.0006, -0.0211, -0.0018,  ..., -0.0029, -0.0108,  0.0110],
        [ 0.0030,  0.0094, -0.0028,  ..., -0.0025, -0.0057,  0.0185],
        ...,
        [-0.0027, -0.0314, -0.0122,  ..., -0.0098, -0.0206, -0.0127],
        [-0.0042,  0.0269, -0.0155,  ..., -0.0024, -0.0119, -0.0034],
        [-0.0102,  0.0069, -0.0109,  ..., -0.0012,  0.0015, -0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias': tensor([-0.2781, -0.2573, -0.3364,  ..., -0.3469, -0.2040, -0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight': tensor([[ 0.0010, -0.0122,  0.0169,  ...,  0.0076, -0.0051,  0.0080],
        [ 0.0136, -0.0151, -0.0033,  ..., -0.0080,  0.0146, -0.0023],
        [ 0.0173, -0.0216,  0.0123,  ...,  0.0066, -0.0024, -0.0003],
        ...,
        [-0.0117,  0.0076, -0.0053,  ...,  0.0010,  0.0026,  0.0003],
        [-0.0175,  0.0074, -0.0194,  ..., -0.0246, -0.0096, -0.0045],
        [ 0.0076,  0.0037,  0.0206,  ...,  0.0206, -0.0109,  0.0051]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias': tensor([ 0.0366, -0.0981, -0.0667,  ...,  0.0356,  0.0194, -0.0255],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight': tensor([1.7695, 1.6426, 1.7236,  ..., 0.6680, 1.5166, 1.7900],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias': tensor([-0.1890,  0.3459,  0.1487,  ...,  0.4136,  0.4312, -0.1221],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight': tensor([[ 0.0141,  0.0079,  0.0303,  ..., -0.0145,  0.0041,  0.0001],
        [-0.0112,  0.0048,  0.0240,  ..., -0.0055, -0.0139,  0.0003],
        [ 0.0167,  0.0107,  0.0269,  ..., -0.0065,  0.0130, -0.0072],
        ...,
        [-0.0014,  0.0062,  0.0020,  ..., -0.0017,  0.0170, -0.0246],
        [-0.0123, -0.0318, -0.0099,  ..., -0.0016, -0.0070, -0.0297],
        [ 0.0025,  0.0103,  0.0089,  ...,  0.0022,  0.0038,  0.0318]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias': tensor([-0.0931,  0.0089, -0.0538,  ...,  0.1041,  0.1436,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight': tensor([[-0.0085,  0.0049, -0.0003,  ...,  0.0036, -0.0302,  0.0040],
        [ 0.0075, -0.0265, -0.0065,  ..., -0.0031,  0.0134, -0.0018],
        [-0.0087, -0.0006, -0.0056,  ...,  0.0055,  0.0154,  0.0372],
        ...,
        [-0.0022, -0.0078,  0.0144,  ...,  0.0019, -0.0084,  0.0115],
        [ 0.0047, -0.0127, -0.0223,  ..., -0.0021, -0.0109,  0.0101],
        [-0.0105, -0.0005, -0.0008,  ..., -0.0030, -0.0079, -0.0039]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias': tensor([-0.0321,  0.0378,  0.0632,  ...,  0.0502, -0.0048, -0.0005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight': tensor([[-0.0095, -0.0095,  0.0312,  ...,  0.0022, -0.0092,  0.0262],
        [-0.0264, -0.0028, -0.0018,  ..., -0.0075, -0.0155, -0.0109],
        [-0.0025, -0.0001,  0.0389,  ..., -0.0119,  0.0128, -0.0002],
        ...,
        [ 0.0271, -0.0069,  0.0122,  ...,  0.0018,  0.0167, -0.0080],
        [ 0.0080, -0.0216,  0.0023,  ...,  0.0015, -0.0140,  0.0002],
        [-0.0039,  0.0055,  0.0021,  ...,  0.0071, -0.0103,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias': tensor([-0.2311,  0.2390, -0.0950,  ...,  0.0876,  0.1581,  0.0798],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight': tensor([[-0.0281, -0.0058,  0.0026,  ..., -0.0079,  0.0053, -0.0023],
        [ 0.0130, -0.0057, -0.0072,  ..., -0.0006, -0.0015, -0.0051],
        [-0.0112,  0.0132,  0.0089,  ..., -0.0184,  0.0022, -0.0036],
        ...,
        [ 0.0086,  0.0047, -0.0106,  ..., -0.0117, -0.0147, -0.0069],
        [ 0.0147, -0.0031, -0.0165,  ...,  0.0125, -0.0091,  0.0107],
        [ 0.0214,  0.0008, -0.0262,  ..., -0.0205, -0.0144,  0.0057]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias': tensor([-0.0645, -0.0639,  0.0044,  ..., -0.0346, -0.0156, -0.0320],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight': tensor([1.3975, 1.3584, 1.4883,  ..., 1.8799, 1.3203, 1.4980],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias': tensor([ 0.0757, -0.1133, -0.0580,  ..., -0.0255, -0.0899, -0.1061],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight': tensor([[-7.1793e-03,  4.6234e-03,  1.7502e-02,  ..., -1.0124e-02,
          1.3245e-02, -6.4430e-03],
        [-1.6571e-02,  1.1040e-02, -5.1537e-03,  ..., -6.7616e-04,
         -2.2491e-02, -9.1019e-03],
        [-7.6675e-04,  2.2156e-02,  1.0216e-02,  ..., -4.4708e-03,
         -1.6510e-02, -2.4704e-02],
        ...,
        [-2.9205e-02, -7.1602e-03,  8.7559e-05,  ..., -9.7656e-03,
          1.6312e-02,  2.7145e-02],
        [-1.2413e-02,  6.9084e-03,  2.4399e-02,  ..., -7.0381e-03,
         -7.9803e-03,  9.6130e-03],
        [ 6.4039e-04, -4.3259e-03,  4.3121e-02,  ..., -3.9101e-03,
         -1.3245e-02,  1.4565e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias': tensor([-0.3418, -0.2771, -0.3467,  ..., -0.3992, -0.2385, -0.2927],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight': tensor([[-9.4452e-03,  1.2772e-02,  1.8539e-02,  ..., -2.6276e-02,
          4.2343e-04, -1.3672e-02],
        [ 3.2593e-02,  8.7070e-04, -2.8477e-03,  ..., -8.7814e-03,
          1.1383e-02, -3.0182e-02],
        [-4.3488e-03, -2.7359e-02,  1.8482e-03,  ..., -6.5002e-03,
          2.6016e-02,  3.3539e-02],
        ...,
        [-4.1504e-03,  1.6251e-02,  7.8354e-03,  ...,  1.4816e-02,
         -1.9627e-03, -6.3002e-05],
        [ 6.4125e-03, -1.6647e-02,  4.3945e-03,  ...,  1.2833e-02,
         -1.5268e-03, -1.7975e-02],
        [-1.8167e-03, -1.1734e-02, -1.4511e-02,  ...,  3.0396e-02,
          1.1108e-02, -9.7580e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias': tensor([-0.0361, -0.0392,  0.0150,  ..., -0.0163,  0.0041, -0.0078],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight': tensor([2.1113, 2.0137, 2.0352,  ..., 0.7090, 1.8164, 2.2012],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias': tensor([-0.1631, -0.1508,  0.1484,  ...,  0.4434,  0.6812, -0.3279],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight': tensor([[-9.9716e-03, -2.5208e-02,  8.4457e-03,  ...,  1.3168e-02,
         -5.3942e-05, -2.8748e-02],
        [-3.1233e-05,  1.3992e-02, -2.2476e-02,  ...,  6.3232e-02,
         -1.4221e-02, -1.4404e-02],
        [-5.1785e-04, -3.1403e-02,  6.5517e-04,  ..., -1.0399e-02,
          1.1505e-02, -2.8076e-03],
        ...,
        [-6.2132e-04, -1.0201e-02,  1.3947e-02,  ..., -5.4810e-02,
         -8.1787e-03, -2.0981e-02],
        [ 9.8572e-03, -1.7899e-02,  1.1734e-02,  ..., -4.1885e-03,
          1.4870e-02,  1.1244e-03],
        [ 1.5884e-02,  2.2827e-02,  4.2000e-03,  ..., -4.3091e-02,
         -2.2690e-02, -1.3191e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias': tensor([ 0.2656, -0.2185,  0.0432,  ..., -0.1787, -0.2061,  0.0742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight': tensor([[ 0.0261,  0.0077, -0.0120,  ..., -0.0027, -0.0164, -0.0107],
        [-0.0080,  0.0102,  0.0077,  ...,  0.0039,  0.0010, -0.0050],
        [ 0.0017, -0.0101, -0.0256,  ...,  0.0058, -0.0145, -0.0055],
        ...,
        [-0.0161,  0.0100, -0.0047,  ..., -0.0049, -0.0208,  0.0245],
        [ 0.0115, -0.0098,  0.0141,  ...,  0.0035, -0.0129, -0.0005],
        [-0.0111, -0.0270,  0.0220,  ..., -0.0022, -0.0052, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias': tensor([-0.0182,  0.0114,  0.1055,  ..., -0.0048, -0.0138,  0.0093],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight': tensor([[-0.0116, -0.0250, -0.0204,  ...,  0.0060, -0.0022, -0.0020],
        [ 0.0243,  0.0011, -0.0106,  ...,  0.0480, -0.0213,  0.0138],
        [ 0.0116, -0.0210, -0.0045,  ..., -0.0067, -0.0268, -0.0189],
        ...,
        [ 0.0013,  0.0050,  0.0468,  ..., -0.0500,  0.0203,  0.0043],
        [ 0.0273, -0.0117,  0.0099,  ..., -0.0033, -0.0067,  0.0015],
        [-0.0062,  0.0012,  0.0167,  ..., -0.0361, -0.0010,  0.0275]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias': tensor([ 0.2439, -0.1146,  0.0887,  ...,  0.2213,  0.1515, -0.0186],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight': tensor([[-3.0136e-02,  1.2367e-02, -9.5749e-03,  ...,  1.8692e-02,
          9.2697e-03, -4.0054e-03],
        [-3.6682e-02, -9.7504e-03,  7.6950e-05,  ..., -1.0941e-02,
          8.2474e-03, -8.6546e-04],
        [ 1.9424e-02, -2.1729e-02,  5.8022e-03,  ...,  6.4888e-03,
         -4.6577e-03, -6.9504e-03],
        ...,
        [-7.0953e-03, -1.1024e-02,  1.4248e-03,  ...,  3.1490e-03,
         -7.8735e-03, -1.8097e-02],
        [ 1.8778e-03, -1.1490e-02, -8.2855e-03,  ..., -1.9104e-02,
          7.3166e-03, -8.8959e-03],
        [-8.1558e-03,  1.7426e-02,  1.1551e-02,  ..., -4.8790e-03,
          5.9700e-03,  9.9030e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias': tensor([-0.0732,  0.0212,  0.0239,  ...,  0.0091, -0.0001, -0.0141],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight': tensor([1.3848, 1.3320, 1.4814,  ..., 1.5195, 1.3164, 1.4180],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias': tensor([ 0.0473, -0.0936, -0.0594,  ...,  0.0325,  0.0149, -0.0659],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight': tensor([[ 1.5793e-02, -8.3160e-03,  2.2156e-02,  ...,  1.8814e-02,
         -5.4436e-03, -1.1604e-02],
        [ 1.5007e-02, -9.5978e-03, -2.5284e-02,  ..., -1.6510e-02,
         -3.3539e-02, -2.3102e-02],
        [-2.1622e-02,  2.0309e-02,  2.1801e-03,  ...,  7.5798e-03,
          1.4145e-02, -7.3433e-03],
        ...,
        [-4.5624e-03, -2.5757e-02,  6.9199e-03,  ...,  3.5572e-03,
          1.4694e-02, -2.2339e-02],
        [-9.1791e-06,  7.1487e-03, -1.3298e-02,  ...,  5.6610e-03,
          4.4975e-03,  1.1978e-02],
        [-5.8289e-03,  5.1689e-03, -1.4862e-02,  ...,  1.8585e-02,
          9.6655e-04,  1.1856e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias': tensor([-0.2683, -0.3921, -0.3279,  ..., -0.3718, -0.2028, -0.3127],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight': tensor([[-0.0059, -0.0140,  0.0130,  ...,  0.0043,  0.0292, -0.0014],
        [ 0.0265, -0.0073, -0.0116,  ..., -0.0211,  0.0206,  0.0263],
        [ 0.0022, -0.0233,  0.0002,  ...,  0.0067, -0.0096, -0.0120],
        ...,
        [ 0.0080, -0.0016,  0.0073,  ..., -0.0021, -0.0057, -0.0010],
        [ 0.0048, -0.0163, -0.0040,  ...,  0.0130, -0.0188,  0.0429],
        [-0.0011, -0.0383, -0.0151,  ..., -0.0132,  0.0248,  0.0216]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias': tensor([ 0.0359,  0.0342,  0.0545,  ...,  0.0745, -0.0070,  0.0030],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight': tensor([2.5176, 2.3496, 2.4785,  ..., 0.5151, 2.0352, 2.4492],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias': tensor([-0.2339, -0.0297,  0.1533,  ...,  0.4067,  0.7363, -0.2054],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0246, -0.0315,  ...,  0.0246, -0.0050,  0.0121],
        [ 0.0096,  0.0193,  0.0106,  ..., -0.0207, -0.0075,  0.0043],
        [ 0.0199,  0.0022, -0.0148,  ..., -0.0771, -0.0211,  0.0064],
        ...,
        [ 0.0369,  0.0040, -0.0087,  ..., -0.0215,  0.0106,  0.0167],
        [-0.0061, -0.0050, -0.0032,  ..., -0.0078,  0.0147,  0.0186],
        [ 0.0009,  0.0079, -0.0195,  ..., -0.0096, -0.0309,  0.0012]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias': tensor([ 0.0911, -0.1252, -0.4846,  ...,  0.0673, -0.0733,  0.0197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight': tensor([[ 0.0141,  0.0237,  0.0094,  ..., -0.0007, -0.0127, -0.0134],
        [ 0.0092, -0.0071,  0.0201,  ...,  0.0027, -0.0176, -0.0013],
        [ 0.0039, -0.0016, -0.0055,  ...,  0.0065, -0.0001, -0.0049],
        ...,
        [ 0.0073, -0.0355, -0.0101,  ...,  0.0047, -0.0010, -0.0099],
        [-0.0019,  0.0097, -0.0335,  ..., -0.0019,  0.0006, -0.0019],
        [ 0.0030, -0.0076,  0.0026,  ..., -0.0004,  0.0043, -0.0152]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias': tensor([ 0.0290,  0.0252,  0.0343,  ...,  0.0027, -0.0045, -0.0545],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight': tensor([[ 0.0060, -0.0019, -0.0088,  ...,  0.0198, -0.0025, -0.0177],
        [ 0.0059,  0.0067,  0.0215,  ..., -0.0244, -0.0294,  0.0024],
        [ 0.0271,  0.0004, -0.0182,  ..., -0.0876,  0.0076, -0.0006],
        ...,
        [-0.0081,  0.0160, -0.0380,  ..., -0.0249, -0.0083,  0.0045],
        [ 0.0112, -0.0182, -0.0261,  ..., -0.0056, -0.0009, -0.0319],
        [ 0.0435,  0.0031,  0.0118,  ..., -0.0163,  0.0102, -0.0193]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias': tensor([ 0.0622,  0.0999, -0.5308,  ..., -0.1455,  0.0368, -0.1086],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight': tensor([[ 4.6425e-03, -2.0313e-03,  2.7237e-02,  ...,  1.0216e-02,
         -2.0187e-02,  1.1955e-02],
        [-5.8823e-03,  2.6627e-02,  7.8506e-03,  ...,  3.9864e-03,
         -1.8646e-02,  2.6762e-05],
        [-5.6601e-04,  5.0240e-03,  2.1591e-02,  ...,  1.1375e-02,
          6.1035e-03,  7.7581e-04],
        ...,
        [ 9.0256e-03, -4.1656e-03, -1.2932e-02,  ...,  9.0778e-05,
          1.9577e-02, -6.6452e-03],
        [ 1.5488e-02,  5.1928e-04,  1.3100e-02,  ..., -2.1057e-02,
         -4.6921e-03,  1.0338e-02],
        [ 3.2501e-03, -2.0432e-02, -2.8076e-02,  ..., -8.2169e-03,
         -2.1858e-03,  3.8376e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias': tensor([ 0.0169,  0.0075, -0.0464,  ...,  0.0064, -0.0125, -0.0271],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight': tensor([1.4844, 1.5352, 1.5859,  ..., 1.5234, 1.4395, 1.5938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias': tensor([ 0.1630, -0.0892, -0.0373,  ..., -0.0082, -0.0609, -0.1628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight': tensor([[-0.0057, -0.0090,  0.0211,  ...,  0.0072, -0.0180, -0.0063],
        [ 0.0278,  0.0188,  0.0136,  ..., -0.0074,  0.0133, -0.0087],
        [-0.0168,  0.0028, -0.0226,  ..., -0.0184, -0.0072, -0.0020],
        ...,
        [ 0.0011, -0.0155, -0.0045,  ..., -0.0092, -0.0268,  0.0125],
        [ 0.0054, -0.0030,  0.0160,  ...,  0.0257, -0.0181, -0.0068],
        [ 0.0045,  0.0018,  0.0164,  ..., -0.0108, -0.0191, -0.0004]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias': tensor([-0.2793, -0.3452, -0.2959,  ..., -0.1838, -0.1981, -0.2494],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight': tensor([[-0.0017, -0.0146,  0.0010,  ...,  0.0037, -0.0001,  0.0201],
        [ 0.0174, -0.0161, -0.0016,  ..., -0.0007, -0.0096, -0.0005],
        [ 0.0072,  0.0077, -0.0210,  ...,  0.0165, -0.0019, -0.0208],
        ...,
        [ 0.0195, -0.0092,  0.0151,  ..., -0.0062, -0.0071, -0.0216],
        [ 0.0159,  0.0006,  0.0077,  ..., -0.0073,  0.0030,  0.0091],
        [ 0.0062,  0.0206,  0.0089,  ...,  0.0090, -0.0033, -0.0063]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias': tensor([0.0065, 0.0102, 0.0046,  ..., 0.0065, 0.0796, 0.0695],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight': tensor([2.6719, 2.5625, 2.7695,  ..., 0.6802, 2.2539, 2.7422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias': tensor([-0.0354,  0.2776,  0.4175,  ...,  0.5674,  0.5327, -0.4670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight': tensor([[-0.0087,  0.0027,  0.0113,  ..., -0.0616,  0.0051, -0.0137],
        [-0.0173,  0.0047,  0.0124,  ...,  0.0239, -0.0160,  0.0129],
        [ 0.0097, -0.0005, -0.0050,  ...,  0.0011,  0.0099, -0.0130],
        ...,
        [-0.0052,  0.0120,  0.0098,  ..., -0.0244,  0.0038,  0.0010],
        [ 0.0119, -0.0235, -0.0134,  ..., -0.0140, -0.0140,  0.0065],
        [ 0.0291,  0.0226, -0.0254,  ..., -0.0035, -0.0137,  0.0350]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias': tensor([ 0.2783, -0.2036, -0.0648,  ...,  0.1705,  0.1809,  0.1080],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight': tensor([[-0.0184,  0.0137,  0.0067,  ..., -0.0029,  0.0099,  0.0297],
        [-0.0110,  0.0184,  0.0020,  ...,  0.0024, -0.0151,  0.0009],
        [ 0.0191, -0.0126,  0.0212,  ...,  0.0024, -0.0348,  0.0026],
        ...,
        [ 0.0005,  0.0007, -0.0011,  ...,  0.0046, -0.0222, -0.0393],
        [ 0.0117,  0.0042,  0.0002,  ..., -0.0006,  0.0005, -0.0083],
        [-0.0062,  0.0128,  0.0124,  ..., -0.0037, -0.0134,  0.0008]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias': tensor([-0.0114,  0.0300,  0.0252,  ..., -0.0060,  0.0197,  0.0400],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight': tensor([[ 1.4931e-02, -1.2466e-02,  2.4918e-02,  ..., -5.9814e-02,
         -4.3068e-03,  1.2131e-02],
        [-1.6464e-02, -9.9030e-03, -1.1108e-02,  ...,  2.3956e-02,
         -3.6163e-02,  1.1703e-02],
        [ 1.0757e-02,  2.5730e-03, -7.3338e-04,  ...,  2.4662e-03,
          6.1493e-03,  6.6528e-03],
        ...,
        [ 5.1003e-03, -7.8678e-06,  5.1041e-03,  ..., -4.5410e-02,
         -3.1738e-02,  1.8631e-02],
        [ 1.7502e-02, -4.1084e-03,  3.9978e-03,  ..., -1.8753e-02,
         -2.2335e-03,  2.1057e-03],
        [ 1.7303e-02,  6.7902e-03,  1.1360e-02,  ...,  8.0719e-03,
         -5.0278e-03,  2.1713e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias': tensor([-0.2339,  0.0393, -0.0323,  ..., -0.1953,  0.0200,  0.0049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight': tensor([[ 0.0254,  0.0050,  0.0049,  ...,  0.0120, -0.0121,  0.0091],
        [ 0.0248, -0.0193, -0.0093,  ..., -0.0044, -0.0032,  0.0151],
        [ 0.0053,  0.0182, -0.0142,  ..., -0.0130, -0.0033, -0.0087],
        ...,
        [ 0.0006, -0.0051, -0.0173,  ...,  0.0031, -0.0128,  0.0099],
        [ 0.0081, -0.0134,  0.0246,  ...,  0.0185, -0.0136,  0.0109],
        [-0.0261, -0.0152, -0.0080,  ...,  0.0230, -0.0056,  0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias': tensor([-0.0083,  0.0091, -0.0955,  ..., -0.0067,  0.0003, -0.0047],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight': tensor([1.5762, 1.4580, 1.5850,  ..., 1.7383, 1.4209, 1.5967],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias': tensor([ 0.1272, -0.2208, -0.0098,  ..., -0.0831, -0.0858, -0.1576],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight': tensor([[-0.0051,  0.0014, -0.0012,  ...,  0.0091, -0.0065, -0.0086],
        [-0.0191,  0.0118,  0.0002,  ..., -0.0095, -0.0148,  0.0134],
        [-0.0012, -0.0324,  0.0047,  ..., -0.0084,  0.0050, -0.0089],
        ...,
        [ 0.0005, -0.0097, -0.0229,  ..., -0.0036, -0.0164, -0.0044],
        [ 0.0058, -0.0019, -0.0019,  ...,  0.0053,  0.0177,  0.0073],
        [ 0.0128,  0.0044, -0.0019,  ..., -0.0147,  0.0180, -0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias': tensor([-0.1597, -0.3298, -0.3066,  ..., -0.3003, -0.3157, -0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight': tensor([[-0.0060, -0.0143,  0.0279,  ..., -0.0150,  0.0291,  0.0124],
        [ 0.0095, -0.0208, -0.0114,  ...,  0.0116, -0.0289,  0.0051],
        [-0.0165,  0.0403, -0.0052,  ...,  0.0008, -0.0144, -0.0153],
        ...,
        [-0.0120,  0.0119, -0.0007,  ...,  0.0051,  0.0161, -0.0073],
        [ 0.0291,  0.0090, -0.0140,  ...,  0.0286,  0.0029, -0.0079],
        [ 0.0233, -0.0179, -0.0138,  ..., -0.0036, -0.0180, -0.0041]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias': tensor([ 0.0113,  0.0318, -0.0128,  ..., -0.0561, -0.0155,  0.0321],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight': tensor([2.7773, 2.7402, 2.7402,  ..., 0.8696, 2.4961, 2.8711],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias': tensor([-0.1473, -0.0198,  0.2091,  ...,  0.4590,  0.5410, -0.2742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight': tensor([[ 0.0005, -0.0174, -0.0133,  ..., -0.0195,  0.0176,  0.0196],
        [ 0.0332, -0.0111, -0.0092,  ..., -0.0143,  0.0277, -0.0138],
        [-0.0094,  0.0108, -0.0135,  ..., -0.0078, -0.0209, -0.0013],
        ...,
        [ 0.0136,  0.0224,  0.0235,  ..., -0.0533, -0.0095,  0.0097],
        [-0.0183, -0.0031, -0.0219,  ..., -0.0209, -0.0113,  0.0082],
        [ 0.0187,  0.0257,  0.0352,  ..., -0.0150,  0.0010,  0.0060]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias': tensor([-0.2089,  0.1558,  0.3555,  ...,  0.0323,  0.1013,  0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight': tensor([[-0.0096,  0.0058, -0.0198,  ...,  0.0084,  0.0249,  0.0066],
        [ 0.0346, -0.0048, -0.0196,  ..., -0.0008, -0.0481, -0.0151],
        [-0.0034,  0.0091,  0.0039,  ..., -0.0047,  0.0017, -0.0073],
        ...,
        [-0.0277, -0.0315,  0.0064,  ..., -0.0131, -0.0027,  0.0125],
        [ 0.0013,  0.0095,  0.0286,  ..., -0.0024,  0.0112,  0.0018],
        [-0.0154,  0.0043, -0.0169,  ...,  0.0051,  0.0013, -0.0213]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias': tensor([0.0214, 0.0242, 0.0006,  ..., 0.0194, 0.0418, 0.0340],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight': tensor([[-0.0110, -0.0187, -0.0399,  ..., -0.0132,  0.0016,  0.0080],
        [ 0.0197,  0.0169,  0.0061,  ..., -0.0240,  0.0292,  0.0127],
        [-0.0047, -0.0227, -0.0048,  ..., -0.0150, -0.0014,  0.0108],
        ...,
        [-0.0113,  0.0006, -0.0214,  ..., -0.0389, -0.0254,  0.0096],
        [ 0.0066,  0.0193,  0.0392,  ...,  0.0004,  0.0306, -0.0154],
        [-0.0041,  0.0141, -0.0124,  ..., -0.0156, -0.0206,  0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias': tensor([-0.0377, -0.0410, -0.0185,  ..., -0.2778,  0.1395,  0.1525],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight': tensor([[-1.2112e-03,  2.4259e-05, -4.5753e-04,  ...,  4.1847e-03,
          3.2597e-03, -3.2745e-02],
        [-1.3557e-02, -5.1613e-03,  2.0218e-02,  ..., -7.0801e-03,
         -2.9678e-02, -3.8872e-03],
        [-2.0355e-02, -4.8676e-03,  1.2039e-02,  ...,  1.1337e-02,
         -5.5161e-03, -1.0376e-02],
        ...,
        [ 1.2032e-02,  1.7944e-02, -4.4212e-03,  ...,  3.3722e-02,
         -1.9394e-02, -2.0691e-02],
        [-1.6998e-02,  2.0340e-02, -9.7885e-03,  ..., -4.0588e-03,
          4.5967e-03, -7.2937e-03],
        [-1.6357e-02, -1.8204e-02,  1.9684e-02,  ...,  1.2749e-02,
         -2.2552e-02, -1.4832e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias': tensor([-0.0427,  0.0264, -0.0947,  ..., -0.0744, -0.0230, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight': tensor([1.6475, 1.5273, 1.6768,  ..., 1.8574, 1.4951, 1.6426],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias': tensor([-0.0313, -0.3167, -0.0297,  ..., -0.0391, -0.0746, -0.2402],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight': tensor([[-0.0260, -0.0154,  0.0028,  ..., -0.0228, -0.0295, -0.0447],
        [ 0.0029, -0.0058,  0.0197,  ...,  0.0138,  0.0183,  0.0026],
        [ 0.0218, -0.0178,  0.0015,  ..., -0.0087,  0.0014,  0.0125],
        ...,
        [ 0.0404,  0.0179, -0.0153,  ...,  0.0049,  0.0196, -0.0120],
        [ 0.0015, -0.0189,  0.0088,  ...,  0.0184, -0.0162, -0.0341],
        [ 0.0035, -0.0139, -0.0161,  ...,  0.0040, -0.0222, -0.0067]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias': tensor([-0.3091, -0.1617, -0.2668,  ..., -0.2510, -0.2261, -0.2350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight': tensor([[-0.0030, -0.0123, -0.0188,  ...,  0.0186, -0.0332, -0.0181],
        [ 0.0014, -0.0037, -0.0307,  ..., -0.0058,  0.0160,  0.0274],
        [ 0.0273, -0.0119, -0.0110,  ..., -0.0013, -0.0041, -0.0059],
        ...,
        [ 0.0018, -0.0187, -0.0384,  ...,  0.0141,  0.0053,  0.0090],
        [ 0.0151, -0.0128, -0.0045,  ...,  0.0167, -0.0064,  0.0077],
        [ 0.0001,  0.0021,  0.0336,  ..., -0.0046, -0.0128,  0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias': tensor([ 0.1198, -0.0191,  0.1595,  ..., -0.0292, -0.0284, -0.0580],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight': tensor([3.1777, 3.2344, 3.2090,  ..., 1.1455, 2.6172, 3.2363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias': tensor([-0.3699,  0.0534, -0.3181,  ...,  0.1720,  0.3350, -0.2013],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight': tensor([[ 0.0132,  0.0254, -0.0020,  ..., -0.0305,  0.0047,  0.0051],
        [ 0.0022, -0.0257,  0.0199,  ..., -0.0184,  0.0286,  0.0047],
        [-0.0092, -0.0116,  0.0196,  ..., -0.0357,  0.0290,  0.0171],
        ...,
        [ 0.0071, -0.0053,  0.0001,  ..., -0.0139, -0.0043, -0.0191],
        [-0.0128,  0.0084, -0.0034,  ..., -0.0035, -0.0175, -0.0111],
        [ 0.0023, -0.0036, -0.0063,  ...,  0.0125, -0.0132,  0.0166]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias': tensor([ 2.2266,  1.3135, -0.9771,  ...,  0.3726,  2.3047,  0.1869],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight': tensor([[-0.0117,  0.0124, -0.0160,  ...,  0.0026,  0.0036,  0.0293],
        [ 0.0022, -0.0097, -0.0008,  ..., -0.0094,  0.0017, -0.0152],
        [-0.0117, -0.0052, -0.0132,  ...,  0.0201,  0.0020, -0.0049],
        ...,
        [ 0.0122, -0.0035, -0.0111,  ..., -0.0017,  0.0214,  0.0207],
        [-0.0134,  0.0110, -0.0031,  ...,  0.0010,  0.0070,  0.0225],
        [ 0.0003,  0.0153,  0.0004,  ...,  0.0096,  0.0122,  0.0161]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias': tensor([ 0.0095, -0.0149, -0.0342,  ...,  0.0316,  0.0107, -0.0553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight': tensor([[ 2.4475e-02,  1.0361e-02, -3.1738e-03,  ...,  6.3629e-03,
         -4.1161e-03,  4.0770e-05],
        [ 6.4735e-03, -1.1032e-02, -4.1046e-03,  ...,  2.4471e-03,
         -7.7009e-04,  3.3226e-03],
        [-2.2324e-02, -5.0497e-04, -2.1210e-02,  ..., -6.5186e-02,
         -3.9253e-03, -4.9324e-03],
        ...,
        [ 7.4692e-03, -2.1229e-03, -2.2095e-02,  ..., -3.7079e-02,
         -3.3173e-02,  2.9621e-03],
        [-2.3987e-02, -1.8463e-03, -3.8791e-04,  ..., -1.6312e-02,
         -2.0157e-02,  1.9180e-02],
        [ 5.5695e-03, -1.0750e-02,  1.4153e-03,  ...,  1.7136e-02,
         -1.8829e-02, -3.1219e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias': tensor([ 0.0942, -0.0380, -0.0066,  ..., -0.2206,  0.0908,  0.0343],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight': tensor([[ 0.0108, -0.0169,  0.0143,  ..., -0.0040, -0.0186, -0.0120],
        [-0.0099,  0.0158, -0.0007,  ..., -0.0126,  0.0125, -0.0013],
        [ 0.0059, -0.0186,  0.0080,  ...,  0.0038,  0.0261, -0.0122],
        ...,
        [ 0.0193, -0.0006, -0.0168,  ..., -0.0111, -0.0033,  0.0045],
        [ 0.0071,  0.0175, -0.0099,  ...,  0.0238,  0.0111,  0.0132],
        [ 0.0269,  0.0227,  0.0074,  ..., -0.0048, -0.0153, -0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias': tensor([ 0.1117, -0.0344, -0.0097,  ..., -0.0479, -0.0558, -0.0235],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight': tensor([1.5781, 1.5361, 1.5830,  ..., 0.8071, 1.4404, 1.7129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias': tensor([ 0.0493, -0.2202, -0.1034,  ...,  0.0678, -0.1000, -0.2034],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight': tensor([[-0.0206, -0.0153,  0.0054,  ...,  0.0216,  0.0042, -0.0064],
        [-0.0240,  0.0083,  0.0154,  ..., -0.0026,  0.0077, -0.0042],
        [ 0.0143,  0.0016,  0.0010,  ...,  0.0362,  0.0050,  0.0193],
        ...,
        [ 0.0191,  0.0038,  0.0125,  ..., -0.0049, -0.0139, -0.0164],
        [ 0.0050,  0.0037,  0.0237,  ..., -0.0271,  0.0079, -0.0093],
        [ 0.0163,  0.0038, -0.0141,  ..., -0.0026, -0.0191,  0.0084]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias': tensor([-0.2673, -0.2559, -0.2236,  ..., -0.2888, -0.2781, -0.0958],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight': tensor([[-0.0093, -0.0160, -0.0221,  ...,  0.0137, -0.0174, -0.0188],
        [-0.0096,  0.0156, -0.0179,  ..., -0.0231,  0.0060, -0.0123],
        [ 0.0032, -0.0022,  0.0147,  ..., -0.0053,  0.0070,  0.0076],
        ...,
        [-0.0122, -0.0089,  0.0011,  ...,  0.0205,  0.0041, -0.0117],
        [ 0.0056, -0.0073, -0.0155,  ..., -0.0081, -0.0361,  0.0044],
        [ 0.0310,  0.0010,  0.0081,  ..., -0.0060, -0.0118, -0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias': tensor([-0.0192, -0.0717,  0.1105,  ..., -0.1528,  0.0851, -0.0401],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight': tensor([3.1602, 3.0371, 2.9180,  ..., 1.5098, 2.5527, 3.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias': tensor([ 0.2227,  0.6216, -0.4958,  ...,  0.2568,  0.0677, -0.4553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight': tensor([[ 0.0037,  0.0141,  0.0131,  ...,  0.0058,  0.0128,  0.0105],
        [ 0.0020, -0.0168, -0.0078,  ...,  0.0242, -0.0173, -0.0008],
        [ 0.0030,  0.0062, -0.0284,  ..., -0.0097,  0.0236,  0.0083],
        ...,
        [-0.0080, -0.0243, -0.0079,  ..., -0.0201, -0.0240, -0.0208],
        [ 0.0029,  0.0056,  0.0167,  ...,  0.0065, -0.0012, -0.0019],
        [-0.0047, -0.0198, -0.0200,  ...,  0.0153,  0.0093, -0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias': tensor([ 0.9746, -1.5684,  4.0703,  ..., -4.7695,  2.3730,  0.0641],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight': tensor([[-0.0094,  0.0040, -0.0081,  ...,  0.0087,  0.0034, -0.0086],
        [-0.0218, -0.0027,  0.0096,  ...,  0.0072, -0.0114, -0.0138],
        [-0.0069,  0.0196,  0.0128,  ...,  0.0089, -0.0430,  0.0282],
        ...,
        [ 0.0080, -0.0076,  0.0247,  ..., -0.0006,  0.0264, -0.0060],
        [-0.0081,  0.0084,  0.0222,  ...,  0.0080, -0.0070,  0.0124],
        [-0.0113,  0.0073,  0.0137,  ..., -0.0100, -0.0085,  0.0073]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias': tensor([-0.0650, -0.0600,  0.0630,  ..., -0.0726,  0.0070, -0.1204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight': tensor([[ 0.0016,  0.0027, -0.0018,  ...,  0.0349, -0.0049, -0.0009],
        [ 0.0076,  0.0003, -0.0250,  ...,  0.0064,  0.0064,  0.0147],
        [-0.0011, -0.0325, -0.0602,  ...,  0.0003, -0.0238,  0.0107],
        ...,
        [ 0.0233,  0.0226,  0.0270,  ...,  0.0236, -0.0239, -0.0167],
        [ 0.0041, -0.0097, -0.0143,  ..., -0.0173, -0.0098,  0.0124],
        [ 0.0090, -0.0034,  0.0003,  ...,  0.0278,  0.0114,  0.0061]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias': tensor([-0.4348, -0.0033, -0.1771,  ..., -0.0897,  0.1703,  0.3945],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight': tensor([[ 0.0021,  0.0206, -0.0078,  ..., -0.0072, -0.0010,  0.0115],
        [ 0.0005,  0.0042, -0.0142,  ...,  0.0190, -0.0119, -0.0008],
        [ 0.0061, -0.0182,  0.0112,  ..., -0.0376, -0.0023, -0.0042],
        ...,
        [-0.0143,  0.0111, -0.0015,  ..., -0.0087,  0.0175, -0.0019],
        [-0.0039,  0.0022,  0.0231,  ..., -0.0050,  0.0082, -0.0150],
        [ 0.0005, -0.0005, -0.0158,  ..., -0.0120, -0.0067, -0.0141]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias': tensor([-0.0269, -0.0574,  0.0638,  ..., -0.1498,  0.0551, -0.1482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight': tensor([1.5703, 1.8379, 1.9336,  ..., 0.8516, 1.4707, 1.7686],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias': tensor([0.3889, 0.2372, 0.1531,  ..., 0.6260, 0.2163, 0.1549],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight': tensor([[-1.1892e-03,  3.9005e-03, -5.7487e-03,  ...,  4.7989e-03,
         -4.2915e-03, -2.5539e-03],
        [ 1.5236e-02, -2.3232e-03, -3.3325e-02,  ...,  2.3758e-02,
         -1.0595e-03, -3.8986e-03],
        [ 2.0737e-02,  7.2479e-03, -3.0842e-03,  ..., -5.4207e-03,
          2.6047e-02, -1.4210e-03],
        ...,
        [ 7.4120e-03, -2.9163e-03,  3.3661e-02,  ..., -4.4785e-03,
          9.1400e-03, -1.5297e-02],
        [-4.3964e-04,  8.5297e-03, -1.5350e-02,  ..., -1.3519e-02,
         -6.6490e-03,  5.9700e-04],
        [-7.5579e-05,  1.0449e-04,  8.8196e-03,  ..., -1.0658e-02,
         -6.6032e-03, -5.4703e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias': tensor([-0.3184, -0.2345, -0.2834,  ..., -0.2498, -0.1849, -0.2729],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight': tensor([[ 0.0369,  0.0093, -0.0179,  ..., -0.0141, -0.0035,  0.0064],
        [ 0.0050,  0.0101,  0.0117,  ...,  0.0070, -0.0066, -0.0147],
        [-0.0015,  0.0263,  0.0119,  ..., -0.0270,  0.0052, -0.0028],
        ...,
        [ 0.0133,  0.0236, -0.0152,  ...,  0.0251, -0.0268, -0.0321],
        [ 0.0021, -0.0061,  0.0079,  ..., -0.0029,  0.0145, -0.0033],
        [-0.0097,  0.0175, -0.0111,  ..., -0.0278, -0.0016, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias': tensor([-0.1587, -0.0068,  0.1970,  ...,  0.0549, -0.0199,  0.0069],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight': tensor([2.5664, 2.3809, 2.5742,  ..., 1.8262, 2.4121, 2.7520],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias': tensor([ 0.1838,  0.3330, -0.2296,  ..., -0.1086,  0.5938, -0.2812],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight': tensor([[ 0.0305, -0.0035, -0.0098,  ...,  0.0054, -0.0111,  0.0049],
        [-0.0194,  0.0099,  0.0032,  ...,  0.0125,  0.0277, -0.0057],
        [ 0.0115,  0.0072, -0.0170,  ...,  0.0162,  0.0032,  0.0142],
        ...,
        [ 0.0076, -0.0034,  0.0187,  ...,  0.0278, -0.0174, -0.0046],
        [-0.0037, -0.0002,  0.0051,  ..., -0.0108,  0.0012,  0.0065],
        [-0.0047, -0.0013,  0.0154,  ...,  0.0158, -0.0106,  0.0013]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias': tensor([-0.0001,  0.0002, -0.0072,  ...,  0.0011, -0.0007, -0.0008],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight': tensor([[ 0.0221, -0.0052,  0.0127,  ..., -0.0090, -0.0092, -0.0165],
        [-0.0569, -0.0251, -0.0167,  ..., -0.0070, -0.0093, -0.0182],
        [-0.0159, -0.0159,  0.0239,  ...,  0.0133,  0.0071,  0.0088],
        ...,
        [ 0.0025,  0.0141, -0.0087,  ...,  0.0007, -0.0157, -0.0012],
        [ 0.0053,  0.0023, -0.0199,  ...,  0.0264,  0.0148, -0.0300],
        [-0.0040,  0.0095, -0.0180,  ..., -0.0396, -0.0316, -0.0156]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias': tensor([-0.0095, -0.0084,  0.0243,  ...,  0.1217, -0.0273,  0.0116],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight': tensor([[ 1.3329e-02, -5.8022e-03,  2.2945e-03,  ...,  1.0509e-03,
          2.1591e-02, -3.7422e-03],
        [-1.7593e-02,  9.9182e-03,  2.1652e-02,  ..., -1.7380e-02,
         -1.1452e-02, -1.1536e-02],
        [-4.2648e-03,  3.6955e-06,  8.7585e-03,  ...,  5.5428e-03,
          1.0963e-02, -8.2855e-03],
        ...,
        [ 2.6302e-03, -6.2828e-03,  1.8387e-02,  ...,  2.4658e-02,
         -1.4015e-02, -1.8509e-02],
        [-1.9140e-03, -1.3588e-02, -1.2770e-03,  ..., -1.8143e-02,
         -2.0309e-02, -2.0172e-02],
        [-1.6346e-03,  5.2338e-03, -1.7044e-02,  ..., -4.7073e-03,
          1.5930e-02,  1.8097e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias': tensor([ 0.0486, -0.0525, -1.9268,  ...,  0.0309,  0.1466, -0.0662],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight': tensor([[-0.0204,  0.0447, -0.0052,  ...,  0.0069,  0.0077,  0.0218],
        [ 0.0017,  0.0142, -0.0191,  ...,  0.0062, -0.0003,  0.0145],
        [-0.0078,  0.0171, -0.0142,  ..., -0.0220,  0.0106,  0.0089],
        ...,
        [-0.0215, -0.0144, -0.0043,  ...,  0.0026, -0.0030,  0.0222],
        [ 0.0184,  0.0181,  0.0050,  ...,  0.0064, -0.0177,  0.0218],
        [ 0.0176,  0.0081, -0.0153,  ..., -0.0053,  0.0065,  0.0165]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias': tensor([-0.2126,  0.1382,  0.1891,  ...,  0.0073,  0.0610, -0.0497],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight': tensor([1.5518, 1.4453, 1.4551,  ..., 0.8970, 1.4531, 1.5488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias': tensor([-0.0075, -0.0621, -0.0674,  ..., -0.0965, -0.1760, -0.1098],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight': tensor([[ 0.0173, -0.0038, -0.0434,  ..., -0.0142, -0.0269,  0.0163],
        [ 0.0112,  0.0112, -0.0199,  ...,  0.0013,  0.0100, -0.0072],
        [-0.0037, -0.0045, -0.0143,  ..., -0.0011, -0.0073, -0.0100],
        ...,
        [-0.0162, -0.0028, -0.0142,  ...,  0.0240, -0.0207, -0.0169],
        [ 0.0084,  0.0172, -0.0097,  ..., -0.0170, -0.0171, -0.0099],
        [ 0.0414, -0.0024, -0.0073,  ..., -0.0142,  0.0116,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias': tensor([-0.2035, -0.6177, -0.2632,  ..., -0.2837, -0.4905, -0.3960],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight': tensor([[-0.0123, -0.0106,  0.0170,  ..., -0.0074, -0.0057,  0.0038],
        [ 0.0014, -0.0104, -0.0019,  ...,  0.0073,  0.0064, -0.0129],
        [-0.0083, -0.0003,  0.0169,  ...,  0.0021,  0.0054,  0.0217],
        ...,
        [-0.0205, -0.0112, -0.0028,  ..., -0.0033,  0.0101,  0.0241],
        [ 0.0122, -0.0082,  0.0100,  ..., -0.0086,  0.0083, -0.0369],
        [ 0.0042, -0.0036,  0.0006,  ..., -0.0066,  0.0024,  0.0018]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias': tensor([ 0.0215, -0.1328, -0.1233,  ..., -0.1167,  0.0634,  0.0916],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight': tensor([1.6230, 1.6143, 1.6387,  ..., 1.4531, 1.7188, 1.8516],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias': tensor([-0.0200, -0.0892,  0.0742,  ...,  0.0301,  0.1517, -0.2600],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight': tensor([0.9370, 1.0215, 0.9346,  ..., 0.8223, 1.0596, 1.0498],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias': tensor([-0.0060,  0.1511, -0.0550,  ...,  0.2749,  0.0767,  0.0092],
       dtype=torch.float16), 'model.mm_projector.weight': tensor([[-0.0138, -0.0121,  0.0265,  ..., -0.0053, -0.0229,  0.0179],
        [-0.0141, -0.0210,  0.0103,  ...,  0.0079,  0.0016, -0.0041],
        [-0.0231,  0.0272, -0.0016,  ...,  0.0310,  0.0269, -0.0115],
        ...,
        [ 0.0208,  0.0213, -0.0247,  ..., -0.0042,  0.0282, -0.0243],
        [ 0.0209, -0.0089, -0.0178,  ...,  0.0184,  0.0149, -0.0164],
        [ 0.0230, -0.0242,  0.0060,  ..., -0.0077,  0.0134, -0.0084]]), 'model.mm_projector.bias': tensor([ 0.0233,  0.0146,  0.0245,  ..., -0.0065, -0.0033, -0.0218]), 'model.perceiver.latents': tensor([[ 0.9670, -0.2282, -0.1268,  ...,  1.6650,  0.9071,  0.0961],
        [-0.5960,  0.9235,  0.5711,  ...,  0.3014,  1.1110, -0.6985],
        [-0.3405, -0.2928,  1.3721,  ..., -0.9385, -0.2495,  0.3509],
        ...,
        [ 0.3653,  0.2367, -0.7613,  ...,  0.6695, -1.1336,  0.2120],
        [ 0.2782,  0.5709, -0.2710,  ...,  0.1927,  1.0209,  1.1475],
        [-0.9265, -0.8135,  1.0565,  ...,  2.2941, -0.1483, -1.7664]]), 'model.perceiver.frame_embs': tensor([[-1.4662e+00,  1.5520e-01,  2.0777e+00,  ...,  3.6579e-01,
          2.6706e-01, -3.3689e-01],
        [ 4.8336e-01, -5.5011e-01, -6.5585e-02,  ..., -7.1546e-01,
         -4.4807e-01, -4.7283e-01],
        [ 1.1652e+00, -2.8026e-01, -1.1607e-01,  ..., -1.2429e+00,
         -1.8903e-01, -9.3108e-02],
        ...,
        [-9.0425e-02, -2.0585e-03, -7.2921e-01,  ..., -1.1441e+00,
         -5.8907e-01, -1.2821e-01],
        [ 2.0442e-01,  2.8236e-01, -4.0468e-01,  ..., -4.5303e-01,
          7.5179e-01,  2.5641e-02],
        [ 6.8411e-01,  1.7833e+00, -1.7501e+00,  ..., -1.0582e+00,
          5.9469e-01,  3.2836e-01]]), 'model.perceiver.media_time_embs': tensor([[[-0.8343,  1.3702, -1.8166,  ..., -0.8543, -1.6116,  1.1844]],

        [[-1.2994,  1.6579,  1.1989,  ..., -0.4197,  2.0805, -0.7615]],

        [[-0.5903, -0.2771,  0.8598,  ..., -0.5948,  0.9634,  0.4764]],

        [[-0.6375, -0.1398, -1.0064,  ...,  1.4840, -0.4575,  0.4527]]]), 'model.perceiver.layers.0.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.to_q.weight': tensor([[-0.0126, -0.0030, -0.0134,  ..., -0.0017, -0.0037,  0.0067],
        [ 0.0023,  0.0084, -0.0049,  ..., -0.0147, -0.0023,  0.0028],
        [ 0.0070, -0.0032,  0.0133,  ...,  0.0138,  0.0029, -0.0131],
        ...,
        [-0.0016, -0.0024,  0.0145,  ...,  0.0021,  0.0032,  0.0052],
        [ 0.0002, -0.0095, -0.0011,  ..., -0.0142, -0.0144,  0.0108],
        [ 0.0037,  0.0091, -0.0076,  ...,  0.0136, -0.0058,  0.0025]]), 'model.perceiver.layers.0.0.to_kv.weight': tensor([[ 1.5367e-02,  1.0623e-02, -1.5515e-02,  ...,  3.1292e-03,
          7.2574e-03,  4.7563e-03],
        [ 2.6350e-03, -9.3293e-03,  2.4022e-03,  ...,  1.2302e-02,
          1.0163e-02,  1.4743e-02],
        [ 1.3758e-02, -3.4185e-05, -5.7776e-05,  ...,  1.3133e-02,
          4.4999e-03, -6.6710e-03],
        ...,
        [-8.2230e-03, -3.8376e-03, -1.2637e-02,  ..., -7.9460e-03,
         -1.5580e-02, -6.4146e-03],
        [-4.8646e-03,  1.4418e-02,  1.4467e-02,  ..., -9.9945e-03,
          1.4327e-02, -5.4401e-03],
        [-1.1771e-02, -6.8118e-03, -4.5962e-03,  ...,  1.1786e-02,
          1.1549e-02, -1.0452e-02]]), 'model.perceiver.layers.0.0.to_out.weight': tensor([[-0.0271,  0.0070,  0.0073,  ...,  0.0272, -0.0327, -0.0423],
        [ 0.0361, -0.0410, -0.0392,  ...,  0.0271,  0.0284, -0.0121],
        [ 0.0203,  0.0075,  0.0240,  ...,  0.0216, -0.0161,  0.0399],
        ...,
        [ 0.0332, -0.0292, -0.0005,  ..., -0.0055, -0.0378,  0.0240],
        [-0.0149,  0.0145,  0.0236,  ..., -0.0003, -0.0032,  0.0162],
        [-0.0204,  0.0026,  0.0261,  ...,  0.0042, -0.0299,  0.0239]]), 'model.perceiver.layers.0.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.1.1.weight': tensor([[ 0.0109,  0.0033, -0.0028,  ...,  0.0031,  0.0041, -0.0109],
        [ 0.0111,  0.0073, -0.0030,  ..., -0.0089, -0.0122,  0.0078],
        [-0.0143, -0.0066,  0.0120,  ..., -0.0003, -0.0081, -0.0110],
        ...,
        [ 0.0115,  0.0119,  0.0101,  ...,  0.0127,  0.0055, -0.0055],
        [ 0.0149,  0.0065,  0.0115,  ...,  0.0154, -0.0064, -0.0037],
        [-0.0098,  0.0024,  0.0081,  ..., -0.0107, -0.0075,  0.0016]]), 'model.perceiver.layers.0.1.3.weight': tensor([[ 0.0022, -0.0057,  0.0007,  ...,  0.0036,  0.0015,  0.0004],
        [-0.0014,  0.0056,  0.0064,  ..., -0.0052,  0.0006,  0.0067],
        [-0.0023,  0.0004, -0.0064,  ...,  0.0043,  0.0064, -0.0011],
        ...,
        [-0.0059, -0.0050,  0.0052,  ...,  0.0044,  0.0017, -0.0023],
        [ 0.0017, -0.0053,  0.0076,  ...,  0.0078,  0.0019,  0.0031],
        [ 0.0067,  0.0059, -0.0024,  ..., -0.0069,  0.0038, -0.0040]]), 'model.perceiver.layers.1.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.to_q.weight': tensor([[ 0.0136,  0.0017, -0.0047,  ...,  0.0091,  0.0060,  0.0041],
        [-0.0036,  0.0022,  0.0128,  ..., -0.0106, -0.0015,  0.0046],
        [-0.0105, -0.0128, -0.0095,  ..., -0.0081,  0.0115, -0.0146],
        ...,
        [ 0.0030,  0.0081,  0.0135,  ..., -0.0022, -0.0016,  0.0148],
        [-0.0101, -0.0063, -0.0081,  ...,  0.0065,  0.0054,  0.0058],
        [ 0.0040, -0.0083,  0.0132,  ..., -0.0036, -0.0026, -0.0146]]), 'model.perceiver.layers.1.0.to_kv.weight': tensor([[-0.0054, -0.0098,  0.0109,  ...,  0.0080,  0.0023,  0.0003],
        [ 0.0054,  0.0154, -0.0011,  ...,  0.0139, -0.0115,  0.0050],
        [-0.0109, -0.0122,  0.0153,  ..., -0.0081, -0.0057,  0.0004],
        ...,
        [-0.0007, -0.0144,  0.0114,  ...,  0.0038, -0.0012, -0.0099],
        [-0.0062,  0.0007,  0.0155,  ..., -0.0073, -0.0027, -0.0083],
        [-0.0058, -0.0016,  0.0123,  ..., -0.0030, -0.0048, -0.0112]]), 'model.perceiver.layers.1.0.to_out.weight': tensor([[ 3.3269e-02, -2.8556e-02,  2.1484e-02,  ...,  4.3324e-02,
          2.5123e-02,  3.0665e-02],
        [ 2.4494e-02,  1.3106e-02, -3.4031e-02,  ...,  4.0725e-02,
         -1.4771e-02, -3.1944e-02],
        [ 2.9883e-02, -1.9861e-02,  1.1918e-02,  ...,  3.1283e-02,
         -3.5877e-03, -2.8490e-02],
        ...,
        [ 7.1824e-03,  3.7823e-02, -3.9396e-02,  ..., -2.3561e-02,
         -9.7837e-03,  2.7095e-02],
        [-3.7572e-02,  3.1428e-02, -1.2288e-02,  ...,  3.4951e-02,
         -1.3996e-02, -2.0989e-02],
        [-3.2857e-02, -3.4396e-02,  6.6165e-05,  ..., -4.0365e-02,
         -2.9317e-02,  4.9685e-03]]), 'model.perceiver.layers.1.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.1.1.weight': tensor([[ 0.0066,  0.0037,  0.0107,  ...,  0.0045, -0.0133, -0.0024],
        [ 0.0046, -0.0078, -0.0023,  ...,  0.0016, -0.0154, -0.0108],
        [-0.0122, -0.0089,  0.0088,  ..., -0.0129, -0.0065,  0.0109],
        ...,
        [-0.0133,  0.0140, -0.0097,  ..., -0.0011, -0.0054, -0.0059],
        [ 0.0059, -0.0020,  0.0031,  ..., -0.0024, -0.0038,  0.0156],
        [ 0.0107,  0.0009, -0.0123,  ...,  0.0085,  0.0120,  0.0055]]), 'model.perceiver.layers.1.1.3.weight': tensor([[ 0.0078,  0.0034,  0.0050,  ...,  0.0057,  0.0060,  0.0042],
        [-0.0006,  0.0007,  0.0073,  ..., -0.0033, -0.0076,  0.0007],
        [ 0.0069, -0.0030, -0.0037,  ...,  0.0004,  0.0002, -0.0075],
        ...,
        [ 0.0023, -0.0022, -0.0043,  ..., -0.0064, -0.0047,  0.0003],
        [ 0.0034, -0.0022,  0.0025,  ..., -0.0060,  0.0050, -0.0014],
        [ 0.0043,  0.0017, -0.0028,  ...,  0.0058, -0.0038,  0.0028]]), 'model.perceiver.layers.2.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.to_q.weight': tensor([[ 0.0097, -0.0125,  0.0054,  ..., -0.0143, -0.0151,  0.0092],
        [ 0.0027,  0.0066, -0.0113,  ...,  0.0135,  0.0057,  0.0142],
        [-0.0091, -0.0018,  0.0070,  ...,  0.0124,  0.0023, -0.0045],
        ...,
        [ 0.0103, -0.0037,  0.0038,  ...,  0.0108, -0.0059,  0.0089],
        [-0.0032, -0.0081,  0.0113,  ..., -0.0105,  0.0153, -0.0005],
        [ 0.0078,  0.0020, -0.0131,  ..., -0.0087,  0.0003,  0.0123]]), 'model.perceiver.layers.2.0.to_kv.weight': tensor([[-0.0100, -0.0078,  0.0082,  ...,  0.0010, -0.0103,  0.0068],
        [ 0.0137,  0.0011,  0.0004,  ...,  0.0035,  0.0103, -0.0144],
        [-0.0125, -0.0077,  0.0134,  ..., -0.0047, -0.0069,  0.0056],
        ...,
        [ 0.0116,  0.0095,  0.0048,  ...,  0.0138, -0.0077,  0.0090],
        [ 0.0124, -0.0117,  0.0072,  ..., -0.0066, -0.0020, -0.0111],
        [-0.0126, -0.0116, -0.0009,  ..., -0.0148,  0.0033, -0.0124]]), 'model.perceiver.layers.2.0.to_out.weight': tensor([[ 0.0358,  0.0398,  0.0419,  ...,  0.0287,  0.0194, -0.0149],
        [-0.0120,  0.0128, -0.0332,  ...,  0.0190,  0.0271, -0.0435],
        [ 0.0037,  0.0355,  0.0021,  ...,  0.0204,  0.0256, -0.0389],
        ...,
        [-0.0038,  0.0117, -0.0195,  ...,  0.0028, -0.0117, -0.0310],
        [ 0.0440,  0.0292,  0.0438,  ..., -0.0390,  0.0223, -0.0359],
        [-0.0368,  0.0256, -0.0047,  ...,  0.0197,  0.0416, -0.0093]]), 'model.perceiver.layers.2.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.1.1.weight': tensor([[ 0.0096, -0.0154, -0.0071,  ...,  0.0121, -0.0099, -0.0080],
        [ 0.0031, -0.0035, -0.0094,  ...,  0.0131, -0.0087, -0.0062],
        [ 0.0075, -0.0125,  0.0089,  ...,  0.0075, -0.0072, -0.0053],
        ...,
        [-0.0133, -0.0043, -0.0089,  ...,  0.0117,  0.0033,  0.0086],
        [-0.0086, -0.0062,  0.0117,  ...,  0.0077, -0.0098,  0.0073],
        [-0.0139,  0.0121,  0.0025,  ..., -0.0149,  0.0049, -0.0155]]), 'model.perceiver.layers.2.1.3.weight': tensor([[ 0.0042, -0.0063, -0.0038,  ..., -0.0011, -0.0022,  0.0056],
        [-0.0075,  0.0072, -0.0045,  ..., -0.0059, -0.0067,  0.0063],
        [ 0.0022, -0.0030, -0.0022,  ..., -0.0027, -0.0062, -0.0070],
        ...,
        [-0.0027, -0.0009,  0.0039,  ...,  0.0068, -0.0018, -0.0048],
        [ 0.0023, -0.0056,  0.0049,  ..., -0.0048, -0.0028,  0.0064],
        [-0.0021,  0.0034,  0.0008,  ..., -0.0070, -0.0072,  0.0029]]), 'model.perceiver.layers.3.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.to_q.weight': tensor([[ 0.0058,  0.0055, -0.0077,  ..., -0.0137, -0.0052,  0.0004],
        [-0.0148,  0.0031,  0.0072,  ..., -0.0050,  0.0009,  0.0150],
        [-0.0024,  0.0053,  0.0099,  ...,  0.0025, -0.0030,  0.0027],
        ...,
        [-0.0048,  0.0037, -0.0032,  ...,  0.0143,  0.0067,  0.0037],
        [-0.0118, -0.0054, -0.0126,  ...,  0.0049,  0.0125,  0.0155],
        [-0.0023,  0.0131,  0.0014,  ...,  0.0128,  0.0076,  0.0073]]), 'model.perceiver.layers.3.0.to_kv.weight': tensor([[-0.0024, -0.0075,  0.0095,  ...,  0.0074,  0.0053,  0.0108],
        [ 0.0058,  0.0096, -0.0143,  ..., -0.0028,  0.0149,  0.0125],
        [-0.0119,  0.0022, -0.0057,  ...,  0.0014,  0.0039, -0.0044],
        ...,
        [-0.0132,  0.0091,  0.0067,  ...,  0.0023, -0.0149,  0.0021],
        [ 0.0146, -0.0017,  0.0090,  ..., -0.0153,  0.0134,  0.0075],
        [-0.0116,  0.0114, -0.0082,  ..., -0.0052, -0.0137,  0.0052]]), 'model.perceiver.layers.3.0.to_out.weight': tensor([[-0.0318, -0.0093, -0.0197,  ...,  0.0242, -0.0107,  0.0301],
        [ 0.0418,  0.0347,  0.0034,  ..., -0.0260, -0.0212,  0.0284],
        [-0.0236,  0.0155,  0.0220,  ..., -0.0140,  0.0142, -0.0131],
        ...,
        [-0.0346,  0.0083,  0.0049,  ...,  0.0073,  0.0423,  0.0233],
        [-0.0203,  0.0420,  0.0262,  ..., -0.0382,  0.0408,  0.0184],
        [ 0.0175,  0.0129, -0.0047,  ...,  0.0417, -0.0311, -0.0385]]), 'model.perceiver.layers.3.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.1.1.weight': tensor([[-0.0012, -0.0020,  0.0059,  ...,  0.0135, -0.0104, -0.0097],
        [-0.0042,  0.0139,  0.0029,  ..., -0.0088, -0.0022, -0.0047],
        [-0.0142,  0.0033, -0.0113,  ..., -0.0099, -0.0093,  0.0142],
        ...,
        [-0.0110, -0.0017,  0.0065,  ..., -0.0113,  0.0100, -0.0073],
        [-0.0056, -0.0124,  0.0017,  ...,  0.0109,  0.0090,  0.0073],
        [-0.0003, -0.0026,  0.0120,  ..., -0.0075, -0.0043, -0.0066]]), 'model.perceiver.layers.3.1.3.weight': tensor([[-0.0034,  0.0015, -0.0029,  ...,  0.0014,  0.0066,  0.0011],
        [-0.0042,  0.0023, -0.0037,  ..., -0.0012,  0.0018,  0.0053],
        [-0.0053, -0.0068, -0.0002,  ..., -0.0067,  0.0028, -0.0076],
        ...,
        [ 0.0032,  0.0003, -0.0005,  ..., -0.0050,  0.0022,  0.0045],
        [ 0.0033,  0.0065,  0.0053,  ...,  0.0015, -0.0039, -0.0056],
        [ 0.0059,  0.0038,  0.0062,  ...,  0.0006,  0.0016,  0.0076]]), 'model.perceiver.layers.4.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.to_q.weight': tensor([[-0.0009,  0.0120,  0.0139,  ...,  0.0105, -0.0082, -0.0027],
        [-0.0080, -0.0006,  0.0122,  ..., -0.0135,  0.0061,  0.0104],
        [ 0.0148, -0.0062,  0.0147,  ..., -0.0051, -0.0036,  0.0133],
        ...,
        [ 0.0070,  0.0072,  0.0093,  ...,  0.0030,  0.0005,  0.0030],
        [-0.0050,  0.0014,  0.0145,  ...,  0.0121,  0.0118,  0.0028],
        [ 0.0010, -0.0121,  0.0073,  ...,  0.0037,  0.0137,  0.0135]]), 'model.perceiver.layers.4.0.to_kv.weight': tensor([[-0.0110, -0.0133, -0.0009,  ...,  0.0148,  0.0032, -0.0055],
        [-0.0031,  0.0065, -0.0076,  ..., -0.0082, -0.0030, -0.0104],
        [-0.0032,  0.0027,  0.0060,  ..., -0.0147, -0.0077,  0.0060],
        ...,
        [ 0.0092,  0.0092,  0.0117,  ..., -0.0135,  0.0049, -0.0018],
        [-0.0080,  0.0082, -0.0028,  ...,  0.0062, -0.0040,  0.0049],
        [-0.0090, -0.0039, -0.0031,  ..., -0.0040,  0.0096, -0.0011]]), 'model.perceiver.layers.4.0.to_out.weight': tensor([[ 0.0055, -0.0137, -0.0356,  ...,  0.0175,  0.0246,  0.0007],
        [ 0.0281,  0.0338,  0.0156,  ...,  0.0339,  0.0350,  0.0376],
        [-0.0372,  0.0265,  0.0295,  ...,  0.0126, -0.0424, -0.0053],
        ...,
        [ 0.0092,  0.0310,  0.0404,  ..., -0.0134,  0.0414,  0.0078],
        [-0.0070, -0.0328, -0.0174,  ...,  0.0368,  0.0305, -0.0096],
        [ 0.0344,  0.0126, -0.0042,  ...,  0.0007,  0.0089,  0.0201]]), 'model.perceiver.layers.4.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.1.1.weight': tensor([[ 0.0103, -0.0075, -0.0140,  ..., -0.0147,  0.0106,  0.0009],
        [-0.0144,  0.0033, -0.0110,  ..., -0.0108, -0.0091, -0.0013],
        [ 0.0028,  0.0084,  0.0077,  ..., -0.0011, -0.0005,  0.0011],
        ...,
        [-0.0126, -0.0079, -0.0095,  ...,  0.0041, -0.0097,  0.0035],
        [ 0.0080,  0.0113, -0.0023,  ..., -0.0106, -0.0016,  0.0108],
        [ 0.0096, -0.0074, -0.0037,  ...,  0.0134, -0.0086, -0.0145]]), 'model.perceiver.layers.4.1.3.weight': tensor([[ 0.0038, -0.0053,  0.0042,  ...,  0.0031,  0.0007,  0.0021],
        [-0.0070,  0.0048, -0.0050,  ...,  0.0051, -0.0056,  0.0015],
        [-0.0009, -0.0011, -0.0005,  ...,  0.0043,  0.0064,  0.0024],
        ...,
        [ 0.0040,  0.0041, -0.0068,  ..., -0.0055,  0.0044,  0.0040],
        [-0.0028,  0.0030, -0.0070,  ..., -0.0067, -0.0046,  0.0050],
        [-0.0042,  0.0051,  0.0030,  ..., -0.0040,  0.0022, -0.0063]]), 'model.perceiver.layers.5.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.to_q.weight': tensor([[-0.0140, -0.0037, -0.0127,  ..., -0.0099, -0.0047, -0.0060],
        [-0.0095, -0.0087,  0.0049,  ..., -0.0035,  0.0145,  0.0042],
        [-0.0108,  0.0078,  0.0033,  ..., -0.0137, -0.0135, -0.0107],
        ...,
        [ 0.0043, -0.0091, -0.0140,  ...,  0.0120,  0.0105,  0.0041],
        [ 0.0140,  0.0034,  0.0007,  ...,  0.0037,  0.0106, -0.0154],
        [ 0.0099, -0.0024,  0.0081,  ..., -0.0089,  0.0140,  0.0133]]), 'model.perceiver.layers.5.0.to_kv.weight': tensor([[ 0.0079,  0.0061, -0.0014,  ...,  0.0126, -0.0044, -0.0003],
        [ 0.0001,  0.0055,  0.0081,  ...,  0.0084,  0.0050, -0.0042],
        [-0.0109,  0.0111, -0.0149,  ..., -0.0098, -0.0086,  0.0114],
        ...,
        [-0.0015, -0.0013, -0.0116,  ..., -0.0060, -0.0014,  0.0133],
        [-0.0006,  0.0067, -0.0010,  ..., -0.0075, -0.0136, -0.0059],
        [-0.0061,  0.0097, -0.0123,  ...,  0.0090, -0.0111, -0.0090]]), 'model.perceiver.layers.5.0.to_out.weight': tensor([[ 0.0225,  0.0142, -0.0231,  ...,  0.0038, -0.0420, -0.0410],
        [-0.0021, -0.0216, -0.0082,  ...,  0.0075,  0.0083,  0.0007],
        [ 0.0095, -0.0045,  0.0277,  ...,  0.0245, -0.0100, -0.0310],
        ...,
        [ 0.0296,  0.0302,  0.0084,  ..., -0.0156,  0.0238,  0.0149],
        [ 0.0019,  0.0265,  0.0332,  ..., -0.0233,  0.0206,  0.0004],
        [ 0.0015,  0.0366,  0.0191,  ..., -0.0093,  0.0315, -0.0217]]), 'model.perceiver.layers.5.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.1.1.weight': tensor([[ 1.3200e-02, -3.1317e-03,  9.4812e-05,  ..., -1.4390e-02,
          1.1477e-02, -3.5724e-03],
        [-1.1970e-02, -4.5971e-03, -5.3128e-03,  ...,  2.2737e-03,
          1.4411e-02, -1.1417e-02],
        [-1.5136e-02,  7.1546e-03, -4.4272e-03,  ..., -1.1269e-02,
          6.5040e-03,  2.9834e-03],
        ...,
        [-1.2569e-02, -1.0705e-04,  1.1169e-02,  ..., -8.3900e-03,
         -1.1735e-02, -6.6676e-04],
        [-6.7914e-03,  3.8675e-03,  1.5045e-02,  ..., -1.5507e-02,
          9.4595e-04, -1.2131e-02],
        [ 5.9751e-03,  8.6163e-03, -9.9246e-03,  ..., -1.4495e-02,
          2.0974e-03, -5.2657e-03]]), 'model.perceiver.layers.5.1.3.weight': tensor([[-0.0072,  0.0020, -0.0026,  ...,  0.0072, -0.0047,  0.0052],
        [-0.0053, -0.0075, -0.0020,  ..., -0.0078,  0.0050,  0.0047],
        [ 0.0025, -0.0068,  0.0017,  ...,  0.0009,  0.0015,  0.0049],
        ...,
        [-0.0073, -0.0012, -0.0046,  ...,  0.0044, -0.0035, -0.0037],
        [-0.0021, -0.0073,  0.0038,  ...,  0.0011,  0.0059,  0.0005],
        [-0.0004,  0.0039,  0.0041,  ..., -0.0060,  0.0043,  0.0050]]), 'model.perceiver.norm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.norm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'lm_head.weight': tensor([[-0.0058, -0.0009, -0.0071,  ...,  0.0035, -0.0099,  0.0190],
        [-0.0278,  0.0547, -0.0115,  ..., -0.0232,  0.0147,  0.0332],
        [-0.0140, -0.0099,  0.0201,  ..., -0.0344,  0.0142, -0.0150],
        ...,
        [-0.0243,  0.0031,  0.0008,  ..., -0.0046,  0.0029, -0.0072],
        [ 0.0070,  0.0007,  0.0051,  ..., -0.0131, -0.0103, -0.0041],
        [-0.0041, -0.0077, -0.0308,  ...,  0.0179,  0.0084,  0.0356]],
       dtype=torch.float16)}
[INFO] Medical save done, finish
[INFO] medical_state_dict: {'model.embed_tokens.weight': tensor([[-0.0013,  0.0004, -0.0018,  ...,  0.0004, -0.0038, -0.0033],
        [ 0.0011, -0.0046, -0.0005,  ..., -0.0079, -0.0010,  0.0003],
        [ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
        ...,
        [-0.0052,  0.0041, -0.0056,  ..., -0.0011,  0.0072,  0.0068],
        [ 0.0075, -0.0039,  0.0058,  ...,  0.0447,  0.0135, -0.0091],
        [-0.0026,  0.0215, -0.0237,  ..., -0.0354,  0.0114,  0.0210]],
       dtype=torch.float16), 'model.layers.0.self_attn.q_proj.weight': tensor([[-9.6512e-03, -1.4015e-02, -1.5736e-03,  ...,  2.1338e-05,
          1.3115e-02, -3.8280e-03],
        [ 2.9144e-02,  4.8027e-03,  5.9013e-03,  ..., -1.3435e-02,
         -8.2550e-03,  1.8204e-02],
        [-1.3481e-02,  1.8463e-02, -3.4637e-03,  ...,  6.7596e-03,
          2.8107e-02, -7.3576e-04],
        ...,
        [ 1.1032e-02,  1.4496e-02, -1.0233e-03,  ..., -2.4509e-03,
         -9.9945e-03,  1.9012e-02],
        [ 2.2018e-02,  9.6817e-03,  3.0251e-03,  ..., -2.1957e-02,
         -2.9984e-02, -1.5228e-02],
        [-4.3945e-03, -3.2215e-03,  2.4204e-03,  ...,  1.5717e-02,
          2.7542e-02, -3.5992e-03]], dtype=torch.float16), 'model.layers.0.self_attn.k_proj.weight': tensor([[-1.8356e-02,  4.0359e-03, -1.2512e-03,  ...,  1.7609e-02,
         -8.6746e-03, -1.4610e-02],
        [ 1.5823e-02,  6.5346e-03,  2.6360e-03,  ..., -1.8021e-02,
          1.6815e-02,  2.4765e-02],
        [ 2.4891e-04, -2.5513e-02,  9.2087e-03,  ...,  1.0544e-02,
         -2.4979e-02, -1.9958e-02],
        ...,
        [ 1.5572e-02,  6.2644e-05,  2.2449e-03,  ..., -7.4625e-04,
          1.9274e-03,  5.2757e-03],
        [-1.0864e-02,  2.2339e-02, -8.3771e-03,  ...,  2.7027e-03,
          1.7319e-02, -7.6866e-03],
        [ 5.8746e-03,  5.1308e-04,  6.3248e-03,  ...,  7.2708e-03,
         -1.2901e-02,  6.5727e-03]], dtype=torch.float16), 'model.layers.0.self_attn.v_proj.weight': tensor([[ 0.0007,  0.0044,  0.0010,  ...,  0.0090,  0.0010,  0.0093],
        [-0.0099, -0.0005, -0.0035,  ..., -0.0119,  0.0113,  0.0107],
        [ 0.0048,  0.0068, -0.0029,  ...,  0.0021, -0.0156, -0.0190],
        ...,
        [-0.0073, -0.0050,  0.0162,  ...,  0.0033,  0.0020, -0.0007],
        [-0.0006,  0.0075, -0.0048,  ...,  0.0051,  0.0155,  0.0017],
        [-0.0032,  0.0046,  0.0082,  ..., -0.0016, -0.0035,  0.0023]],
       dtype=torch.float16), 'model.layers.0.self_attn.o_proj.weight': tensor([[ 1.3628e-03, -3.9444e-03,  3.8643e-03,  ...,  2.2564e-03,
          2.7990e-04, -8.9340e-03],
        [-2.4300e-03,  5.6076e-03,  1.1387e-03,  ..., -1.7481e-03,
          2.0924e-03,  5.7678e-03],
        [-3.3474e-03, -7.6914e-04,  2.4796e-03,  ..., -2.0561e-03,
         -6.5956e-03, -8.0681e-04],
        ...,
        [ 4.8943e-03, -1.4791e-03,  7.6332e-03,  ...,  2.2650e-06,
          4.2534e-03,  3.3951e-03],
        [-2.9583e-03, -1.8663e-03, -1.1358e-03,  ...,  5.2490e-03,
         -5.8899e-03, -2.8267e-03],
        [ 4.0221e-04, -1.2932e-03,  3.3665e-03,  ...,  6.5804e-03,
         -4.6806e-03, -5.0964e-03]], dtype=torch.float16), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0081,  0.0134,  0.0292,  ..., -0.0172,  0.0053,  0.0193],
        [-0.0028, -0.0027,  0.0029,  ...,  0.0147, -0.0076,  0.0114],
        [-0.0002, -0.0256,  0.0180,  ..., -0.0189,  0.0257,  0.0206],
        ...,
        [ 0.0058, -0.0258,  0.0025,  ..., -0.0036, -0.0106,  0.0365],
        [ 0.0223,  0.0168, -0.0171,  ..., -0.0017, -0.0030, -0.0196],
        [-0.0070, -0.0135, -0.0268,  ..., -0.0042,  0.0025, -0.0229]],
       dtype=torch.float16), 'model.layers.0.mlp.up_proj.weight': tensor([[-0.0072, -0.0297,  0.0135,  ..., -0.0198, -0.0236,  0.0091],
        [-0.0119, -0.0311,  0.0110,  ...,  0.0178,  0.0034,  0.0087],
        [-0.0066,  0.0157, -0.0102,  ..., -0.0231,  0.0132,  0.0038],
        ...,
        [-0.0121, -0.0005, -0.0019,  ...,  0.0259, -0.0082,  0.0114],
        [-0.0198,  0.0047,  0.0170,  ..., -0.0023, -0.0186,  0.0037],
        [ 0.0142,  0.0268, -0.0009,  ...,  0.0088, -0.0174, -0.0420]],
       dtype=torch.float16), 'model.layers.0.mlp.down_proj.weight': tensor([[ 0.0044, -0.0123,  0.0141,  ..., -0.0181, -0.0041, -0.0016],
        [-0.0006, -0.0026,  0.0135,  ...,  0.0106, -0.0167,  0.0315],
        [ 0.0044,  0.0371,  0.0019,  ..., -0.0117,  0.0212,  0.0207],
        ...,
        [-0.0078, -0.0106,  0.0062,  ...,  0.0204, -0.0163,  0.0254],
        [-0.0202,  0.0401,  0.0176,  ..., -0.0138, -0.0104, -0.0290],
        [ 0.0179, -0.0031, -0.0126,  ...,  0.0003, -0.0050, -0.0296]],
       dtype=torch.float16), 'model.layers.0.input_layernorm.weight': tensor([ 0.0193,  0.0087, -0.0008,  ...,  0.0058,  0.0089,  0.0019],
       dtype=torch.float16), 'model.layers.0.post_attention_layernorm.weight': tensor([0.0530, 0.0537, 0.0498,  ..., 0.0540, 0.0569, 0.0491],
       dtype=torch.float16), 'model.layers.1.self_attn.q_proj.weight': tensor([[-0.0228, -0.0012, -0.0327,  ..., -0.0147, -0.0572,  0.0403],
        [-0.0012, -0.0125,  0.0112,  ..., -0.0081, -0.0516,  0.0322],
        [ 0.0274,  0.0308,  0.0248,  ..., -0.0133, -0.0764,  0.0221],
        ...,
        [-0.0004,  0.0029,  0.0050,  ..., -0.0099, -0.0020, -0.0116],
        [-0.0018, -0.0048, -0.0055,  ...,  0.0103,  0.0032,  0.0117],
        [ 0.0002,  0.0064,  0.0077,  ..., -0.0088,  0.0019, -0.0165]],
       dtype=torch.float16), 'model.layers.1.self_attn.k_proj.weight': tensor([[-0.0254,  0.0089,  0.0425,  ...,  0.0178,  0.0165, -0.0135],
        [-0.0323,  0.0092, -0.0083,  ..., -0.0091,  0.0150, -0.0595],
        [-0.0262,  0.0288, -0.0696,  ...,  0.0352,  0.0172, -0.0609],
        ...,
        [-0.0149,  0.0229,  0.0028,  ...,  0.0081, -0.0048,  0.0070],
        [ 0.0114, -0.0230, -0.0001,  ..., -0.0092,  0.0033, -0.0068],
        [-0.0111,  0.0184,  0.0055,  ...,  0.0007, -0.0071,  0.0058]],
       dtype=torch.float16), 'model.layers.1.self_attn.v_proj.weight': tensor([[ 6.8245e-03, -4.9133e-03,  1.0071e-03,  ..., -4.8561e-03,
         -2.9144e-02, -2.2125e-02],
        [-5.1346e-03,  4.9515e-03, -3.3360e-03,  ...,  2.7618e-03,
          1.1398e-02,  3.1982e-02],
        [ 3.6736e-03, -1.1612e-02,  8.0032e-03,  ..., -2.2590e-05,
         -1.4648e-03, -3.3340e-03],
        ...,
        [-3.6926e-03,  5.3062e-03,  7.3509e-03,  ..., -2.7981e-03,
         -1.4305e-03,  2.2399e-04],
        [-7.8735e-03, -3.1986e-03,  7.9422e-03,  ..., -6.5727e-03,
          8.4534e-03, -5.7817e-06],
        [ 1.0643e-03,  6.4468e-03,  8.0719e-03,  ..., -6.3095e-03,
         -2.6455e-03,  1.0246e-02]], dtype=torch.float16), 'model.layers.1.self_attn.o_proj.weight': tensor([[ 0.0024, -0.0163,  0.0091,  ..., -0.0058, -0.0015, -0.0006],
        [-0.0016, -0.0059, -0.0052,  ...,  0.0035, -0.0019,  0.0037],
        [ 0.0247,  0.0128, -0.0125,  ...,  0.0022, -0.0027,  0.0011],
        ...,
        [ 0.0058,  0.0022,  0.0012,  ..., -0.0011, -0.0004, -0.0001],
        [ 0.0036, -0.0075,  0.0050,  ..., -0.0054,  0.0002,  0.0056],
        [-0.0017, -0.0238,  0.0015,  ..., -0.0021, -0.0055,  0.0007]],
       dtype=torch.float16), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0305, -0.0128,  0.0422,  ..., -0.0312, -0.0152, -0.0100],
        [-0.0312, -0.0045, -0.0312,  ...,  0.0140, -0.0307, -0.0427],
        [-0.0055, -0.0319,  0.0095,  ..., -0.0064, -0.0123, -0.0204],
        ...,
        [-0.0385,  0.0105, -0.0028,  ..., -0.0023,  0.0122,  0.0004],
        [-0.0149, -0.0031, -0.0339,  ...,  0.0217,  0.0198, -0.0084],
        [-0.0266,  0.0121,  0.0041,  ...,  0.0391,  0.0065, -0.0430]],
       dtype=torch.float16), 'model.layers.1.mlp.up_proj.weight': tensor([[-0.0034,  0.0414, -0.0204,  ...,  0.0118,  0.0263, -0.0124],
        [ 0.0071, -0.0067, -0.0129,  ..., -0.0086,  0.0069,  0.0108],
        [ 0.0309, -0.0436,  0.0134,  ...,  0.0177, -0.0427,  0.0297],
        ...,
        [-0.0148, -0.0275,  0.0184,  ...,  0.0293,  0.0069, -0.0238],
        [ 0.0356,  0.0030, -0.0164,  ...,  0.0032, -0.0060, -0.0045],
        [-0.0108, -0.0150, -0.0105,  ..., -0.0249, -0.0061,  0.0173]],
       dtype=torch.float16), 'model.layers.1.mlp.down_proj.weight': tensor([[ 0.0107,  0.0179,  0.0578,  ..., -0.0177,  0.0072, -0.0210],
        [ 0.0088,  0.0063, -0.0363,  ...,  0.0069, -0.0142,  0.0028],
        [-0.0113, -0.0138, -0.0245,  ...,  0.0014, -0.0134,  0.0023],
        ...,
        [-0.0099, -0.0073, -0.0143,  ...,  0.0442, -0.0065,  0.0090],
        [-0.0116,  0.0203,  0.0101,  ..., -0.0278, -0.0228,  0.0261],
        [ 0.0262, -0.0061, -0.0175,  ..., -0.0080, -0.0135,  0.0338]],
       dtype=torch.float16), 'model.layers.1.input_layernorm.weight': tensor([0.1050, 0.0967, 0.0884,  ..., 0.0518, 0.0781, 0.0608],
       dtype=torch.float16), 'model.layers.1.post_attention_layernorm.weight': tensor([0.0986, 0.0991, 0.0957,  ..., 0.1060, 0.1006, 0.1001],
       dtype=torch.float16), 'model.layers.2.self_attn.q_proj.weight': tensor([[-0.0236, -0.0038,  0.0098,  ..., -0.0133, -0.0098, -0.0003],
        [-0.0190,  0.0037, -0.0345,  ..., -0.0344, -0.0162,  0.0232],
        [-0.0165,  0.0366, -0.0252,  ..., -0.0018, -0.0211,  0.0159],
        ...,
        [-0.0526,  0.0145, -0.0261,  ..., -0.0085, -0.0328, -0.0351],
        [ 0.0019, -0.0063,  0.0003,  ..., -0.0023, -0.0186,  0.0160],
        [-0.0048, -0.0168,  0.0231,  ...,  0.0604, -0.0444,  0.0058]],
       dtype=torch.float16), 'model.layers.2.self_attn.k_proj.weight': tensor([[ 0.0004,  0.0156, -0.0085,  ..., -0.0106, -0.0010,  0.0175],
        [ 0.0163, -0.0154, -0.0090,  ...,  0.0110, -0.0093, -0.0075],
        [ 0.0128,  0.0151,  0.0360,  ..., -0.0084,  0.0124,  0.0131],
        ...,
        [ 0.0299,  0.0465, -0.0237,  ...,  0.0386, -0.0369,  0.0006],
        [-0.0072, -0.0126, -0.0009,  ...,  0.0045,  0.0003, -0.0041],
        [ 0.0020, -0.0215, -0.0021,  ..., -0.0809, -0.0249,  0.0965]],
       dtype=torch.float16), 'model.layers.2.self_attn.v_proj.weight': tensor([[-7.3767e-04,  6.2332e-03,  1.5961e-02,  ...,  3.8208e-02,
         -3.6240e-03, -6.9313e-03],
        [ 5.0621e-03,  1.1269e-02, -2.1118e-02,  ..., -7.7972e-03,
          7.8506e-03, -1.4595e-02],
        [-6.8617e-04,  1.8463e-02,  3.3112e-03,  ..., -2.0950e-02,
         -3.0457e-02, -2.9480e-02],
        ...,
        [-5.3465e-05, -2.5360e-02, -2.0248e-02,  ..., -1.0956e-02,
         -9.5272e-04,  3.3970e-03],
        [-3.7140e-02, -7.9775e-04,  1.4175e-02,  ..., -1.0040e-02,
         -6.6071e-03, -1.5135e-03],
        [-1.1009e-02,  1.4809e-02,  4.5662e-03,  ..., -5.1880e-03,
          1.8234e-02, -7.3395e-03]], dtype=torch.float16), 'model.layers.2.self_attn.o_proj.weight': tensor([[ 0.0041,  0.0149,  0.0103,  ...,  0.0196,  0.0020, -0.0260],
        [ 0.0006, -0.0130,  0.0079,  ...,  0.0049, -0.0125, -0.0198],
        [-0.0215,  0.0032, -0.0169,  ..., -0.0224, -0.0103,  0.0078],
        ...,
        [-0.0046, -0.0235,  0.0281,  ..., -0.0049, -0.0220,  0.0198],
        [ 0.0184, -0.0113,  0.0301,  ...,  0.0192, -0.0004, -0.0239],
        [-0.0107,  0.0023,  0.0075,  ..., -0.0129,  0.0050, -0.0142]],
       dtype=torch.float16), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0072,  0.0239, -0.0107,  ..., -0.0090,  0.0302, -0.0034],
        [ 0.0013,  0.0012, -0.0015,  ...,  0.0126, -0.0138, -0.0115],
        [-0.0069, -0.0083,  0.0255,  ..., -0.0112,  0.0158,  0.0069],
        ...,
        [ 0.0342, -0.0119, -0.0193,  ..., -0.0285, -0.0400, -0.0150],
        [-0.0113, -0.0116, -0.0017,  ...,  0.0174, -0.0425,  0.0180],
        [-0.0015,  0.0111,  0.0085,  ..., -0.0133, -0.0261,  0.0048]],
       dtype=torch.float16), 'model.layers.2.mlp.up_proj.weight': tensor([[-0.0008, -0.0006,  0.0139,  ..., -0.0152,  0.0090, -0.0034],
        [ 0.0053, -0.0186, -0.0090,  ...,  0.0056,  0.0114,  0.0062],
        [ 0.0306,  0.0189,  0.0293,  ..., -0.0141, -0.0088,  0.0175],
        ...,
        [-0.0071, -0.0148,  0.0009,  ..., -0.0116, -0.0025,  0.0209],
        [ 0.0155, -0.0129,  0.0144,  ...,  0.0003,  0.0049, -0.0228],
        [-0.0146, -0.0302, -0.0243,  ..., -0.0050,  0.0011, -0.0050]],
       dtype=torch.float16), 'model.layers.2.mlp.down_proj.weight': tensor([[ 0.0146,  0.0174,  0.0375,  ..., -0.0273, -0.0011, -0.0335],
        [ 0.0209, -0.0227, -0.0188,  ...,  0.0180,  0.0023, -0.0226],
        [ 0.0438, -0.0178,  0.0010,  ..., -0.0302,  0.0004, -0.0330],
        ...,
        [-0.0133,  0.0283, -0.0105,  ..., -0.0015, -0.0013, -0.0135],
        [-0.0211,  0.0298,  0.0079,  ...,  0.0158, -0.0182, -0.0113],
        [ 0.0315,  0.0117, -0.0220,  ...,  0.0192, -0.0449, -0.0119]],
       dtype=torch.float16), 'model.layers.2.input_layernorm.weight': tensor([0.1729, 0.1787, 0.1709,  ..., 0.1768, 0.1680, 0.1748],
       dtype=torch.float16), 'model.layers.2.post_attention_layernorm.weight': tensor([0.1338, 0.1377, 0.1367,  ..., 0.1367, 0.1387, 0.1367],
       dtype=torch.float16), 'model.layers.3.self_attn.q_proj.weight': tensor([[ 0.0001,  0.0111,  0.0058,  ...,  0.0241,  0.0127,  0.0220],
        [-0.0121,  0.0172, -0.0149,  ..., -0.0432,  0.0006, -0.0074],
        [ 0.0129,  0.0027, -0.0203,  ...,  0.0116, -0.0187, -0.0406],
        ...,
        [ 0.0717, -0.0696,  0.0428,  ..., -0.0779, -0.0139,  0.0070],
        [-0.0797,  0.0404, -0.0023,  ...,  0.0363,  0.0769,  0.0251],
        [-0.0153, -0.0497,  0.0779,  ..., -0.0225, -0.0032, -0.0130]],
       dtype=torch.float16), 'model.layers.3.self_attn.k_proj.weight': tensor([[ 0.0074, -0.0077, -0.0088,  ..., -0.0140,  0.0067,  0.0404],
        [-0.0116,  0.0102, -0.0252,  ...,  0.0031, -0.0150, -0.0390],
        [ 0.0029, -0.0079,  0.0005,  ...,  0.0074, -0.0090, -0.0374],
        ...,
        [ 0.0884, -0.0848,  0.0065,  ..., -0.0621,  0.0024,  0.0343],
        [-0.0830,  0.0328,  0.0418,  ...,  0.0079,  0.0463, -0.0032],
        [ 0.0020, -0.0524,  0.0955,  ..., -0.0163,  0.0029, -0.0172]],
       dtype=torch.float16), 'model.layers.3.self_attn.v_proj.weight': tensor([[-0.0039,  0.0125, -0.0059,  ..., -0.0148,  0.0063, -0.0150],
        [-0.0113,  0.0269, -0.0179,  ..., -0.0122, -0.0101, -0.0094],
        [ 0.0024, -0.0062,  0.0057,  ..., -0.0406, -0.0087, -0.0281],
        ...,
        [-0.0131, -0.0097, -0.0019,  ...,  0.0023, -0.0041, -0.0064],
        [ 0.0055, -0.0019,  0.0020,  ...,  0.0007, -0.0084,  0.0018],
        [-0.0120, -0.0069,  0.0093,  ..., -0.0012, -0.0018,  0.0084]],
       dtype=torch.float16), 'model.layers.3.self_attn.o_proj.weight': tensor([[-2.7054e-02,  5.7945e-03, -1.2451e-02,  ...,  2.7256e-03,
         -1.1616e-03, -2.2335e-03],
        [ 2.4536e-02, -2.4429e-02, -1.0193e-02,  ...,  6.5651e-03,
         -2.5272e-03, -2.3193e-03],
        [-3.7498e-03, -1.3260e-02,  1.9197e-03,  ...,  2.6493e-03,
          3.3932e-03,  8.3084e-03],
        ...,
        [ 1.1963e-02,  1.3344e-02,  1.3680e-02,  ...,  1.3313e-03,
          7.1793e-03,  9.9335e-03],
        [ 1.7960e-02,  2.6199e-02,  2.9206e-06,  ...,  3.6945e-03,
         -1.1940e-03, -2.8419e-03],
        [ 8.5297e-03, -9.2773e-03,  1.0519e-03,  ..., -6.4993e-04,
          5.8823e-03,  1.0956e-02]], dtype=torch.float16), 'model.layers.3.mlp.gate_proj.weight': tensor([[ 0.0009, -0.0099, -0.0182,  ..., -0.0315,  0.0460,  0.0153],
        [ 0.0189,  0.0017, -0.0123,  ..., -0.0025, -0.0261, -0.0161],
        [-0.0253,  0.0021, -0.0174,  ...,  0.0050, -0.0040, -0.0361],
        ...,
        [-0.0003,  0.0394,  0.0065,  ...,  0.0199, -0.0123, -0.0001],
        [-0.0057,  0.0087, -0.0060,  ...,  0.0003, -0.0041, -0.0112],
        [-0.0025, -0.0155,  0.0031,  ...,  0.0264, -0.0254,  0.0148]],
       dtype=torch.float16), 'model.layers.3.mlp.up_proj.weight': tensor([[-0.0160,  0.0154,  0.0104,  ...,  0.0014,  0.0186, -0.0085],
        [-0.0123, -0.0174,  0.0343,  ...,  0.0175,  0.0141, -0.0052],
        [-0.0005, -0.0031, -0.0144,  ..., -0.0012,  0.0091, -0.0125],
        ...,
        [-0.0042, -0.0016, -0.0006,  ...,  0.0215,  0.0084, -0.0228],
        [ 0.0052, -0.0099, -0.0050,  ...,  0.0113, -0.0249, -0.0080],
        [ 0.0486, -0.0004, -0.0031,  ...,  0.0433,  0.0057,  0.0085]],
       dtype=torch.float16), 'model.layers.3.mlp.down_proj.weight': tensor([[ 0.0014, -0.0079, -0.0008,  ..., -0.0033,  0.0087,  0.0142],
        [ 0.0225,  0.0028,  0.0088,  ..., -0.0140, -0.0148, -0.0148],
        [ 0.0144,  0.0119, -0.0174,  ..., -0.0200, -0.0066,  0.0060],
        ...,
        [ 0.0280, -0.0107, -0.0166,  ...,  0.0040,  0.0193,  0.0221],
        [-0.0217,  0.0099, -0.0106,  ..., -0.0006, -0.0170,  0.0130],
        [ 0.0110, -0.0169, -0.0266,  ...,  0.0033,  0.0121,  0.0063]],
       dtype=torch.float16), 'model.layers.3.input_layernorm.weight': tensor([0.2852, 0.2852, 0.2832,  ..., 0.2812, 0.2910, 0.2969],
       dtype=torch.float16), 'model.layers.3.post_attention_layernorm.weight': tensor([0.1738, 0.1748, 0.1689,  ..., 0.1719, 0.1719, 0.1758],
       dtype=torch.float16), 'model.layers.4.self_attn.q_proj.weight': tensor([[-0.0206, -0.0058,  0.0019,  ..., -0.0113, -0.0038,  0.0106],
        [ 0.0190, -0.0170, -0.0051,  ...,  0.0039, -0.0259, -0.0004],
        [-0.0124, -0.0312,  0.0122,  ..., -0.0027, -0.0195, -0.0239],
        ...,
        [ 0.0246,  0.0004, -0.0039,  ...,  0.0032,  0.0244, -0.0600],
        [-0.0293,  0.0085,  0.0295,  ..., -0.0561,  0.0037,  0.0337],
        [-0.0074, -0.0351,  0.0680,  ...,  0.0638,  0.0376, -0.0406]],
       dtype=torch.float16), 'model.layers.4.self_attn.k_proj.weight': tensor([[-0.0037,  0.0210, -0.0139,  ..., -0.0044,  0.0025, -0.0019],
        [-0.0307, -0.0041, -0.0032,  ..., -0.0014,  0.0142, -0.0028],
        [ 0.0089, -0.0021, -0.0143,  ...,  0.0076,  0.0189,  0.0352],
        ...,
        [-0.0089,  0.1188,  0.0593,  ...,  0.0388, -0.0216, -0.0060],
        [ 0.0320,  0.0533, -0.0162,  ...,  0.0641, -0.0399,  0.0720],
        [ 0.0100,  0.0640,  0.0195,  ..., -0.0011,  0.0424, -0.0209]],
       dtype=torch.float16), 'model.layers.4.self_attn.v_proj.weight': tensor([[-3.6507e-03, -8.4000e-03,  1.2493e-03,  ..., -6.4735e-03,
         -3.6030e-03, -6.0320e-05],
        [-1.4557e-02,  3.6133e-02,  5.1346e-03,  ...,  3.2978e-03,
          1.1721e-03,  2.7237e-03],
        [ 1.0719e-02, -6.2370e-03, -3.4729e-02,  ...,  5.4436e-03,
         -1.3771e-03, -1.8631e-02],
        ...,
        [-3.3283e-03, -8.3771e-03, -2.2263e-02,  ..., -9.6893e-03,
         -1.1740e-03,  3.3360e-03],
        [-2.0599e-03, -1.0277e-02, -1.9855e-03,  ...,  7.9956e-03,
         -1.5678e-03,  4.0550e-03],
        [-2.6131e-04, -1.7914e-02, -3.6087e-03,  ..., -5.3263e-04,
         -5.2681e-03,  1.1940e-02]], dtype=torch.float16), 'model.layers.4.self_attn.o_proj.weight': tensor([[ 0.0270,  0.0083, -0.0050,  ..., -0.0021, -0.0267, -0.0015],
        [ 0.0075, -0.0009, -0.0082,  ...,  0.0017, -0.0215,  0.0036],
        [-0.0045,  0.0041, -0.0073,  ..., -0.0134,  0.0101, -0.0084],
        ...,
        [-0.0148,  0.0272, -0.0037,  ..., -0.0209,  0.0081, -0.0208],
        [ 0.0033, -0.0025, -0.0150,  ..., -0.0094, -0.0004, -0.0059],
        [ 0.0100,  0.0215, -0.0056,  ..., -0.0007,  0.0051,  0.0010]],
       dtype=torch.float16), 'model.layers.4.mlp.gate_proj.weight': tensor([[-0.0053,  0.0065, -0.0110,  ..., -0.0182, -0.0035, -0.0159],
        [-0.0267,  0.0111,  0.0142,  ...,  0.0066,  0.0154, -0.0106],
        [-0.0136, -0.0220, -0.0006,  ...,  0.0055, -0.0028,  0.0260],
        ...,
        [ 0.0008, -0.0025,  0.0095,  ..., -0.0211,  0.0097, -0.0120],
        [-0.0265,  0.0148, -0.0281,  ...,  0.0098,  0.0180, -0.0102],
        [ 0.0017, -0.0143, -0.0135,  ..., -0.0124,  0.0221,  0.0190]],
       dtype=torch.float16), 'model.layers.4.mlp.up_proj.weight': tensor([[-1.6373e-02, -5.6725e-03, -4.0833e-02,  ...,  8.6670e-03,
         -8.2254e-04, -5.4932e-03],
        [-2.2400e-02, -4.0680e-02,  5.3253e-03,  ..., -8.6517e-03,
          9.8953e-03, -2.4872e-02],
        [-1.2989e-03,  2.9587e-02,  7.5042e-05,  ..., -2.8885e-02,
         -1.1322e-02,  8.4839e-03],
        ...,
        [-8.8882e-03, -3.1769e-02, -7.3433e-03,  ...,  1.2138e-02,
         -6.8016e-03,  5.5023e-02],
        [ 1.2787e-02, -1.0330e-02, -1.5060e-02,  ..., -4.2175e-02,
         -1.6281e-02,  9.5596e-03],
        [ 3.7937e-03,  1.3062e-02,  8.8272e-03,  ...,  3.7594e-03,
         -3.4237e-03, -2.4376e-03]], dtype=torch.float16), 'model.layers.4.mlp.down_proj.weight': tensor([[ 2.3834e-02, -4.2458e-03,  2.3529e-02,  ..., -1.9836e-02,
         -8.3983e-05,  2.9861e-02],
        [-5.7335e-03, -4.8859e-02,  4.5746e-02,  ..., -2.4323e-02,
         -2.1210e-02, -7.2365e-03],
        [-2.9135e-04, -2.7969e-02,  1.6556e-02,  ...,  1.1406e-02,
         -2.8000e-03,  2.2263e-02],
        ...,
        [-3.4393e-02, -1.9779e-03, -9.8801e-03,  ...,  2.4658e-02,
          2.1534e-03,  1.5030e-02],
        [-7.8430e-03,  1.8177e-03, -2.0020e-02,  ...,  1.2718e-02,
         -4.1931e-02, -1.1818e-02],
        [ 1.6479e-02, -3.2135e-02, -1.5076e-02,  ..., -3.5000e-03,
         -4.4739e-02, -2.3956e-02]], dtype=torch.float16), 'model.layers.4.input_layernorm.weight': tensor([0.2617, 0.2676, 0.2617,  ..., 0.2578, 0.2656, 0.2734],
       dtype=torch.float16), 'model.layers.4.post_attention_layernorm.weight': tensor([0.1914, 0.1895, 0.1855,  ..., 0.1904, 0.1885, 0.1895],
       dtype=torch.float16), 'model.layers.5.self_attn.q_proj.weight': tensor([[-0.0089, -0.0005, -0.0254,  ..., -0.0074, -0.0164,  0.0120],
        [-0.0202,  0.0197,  0.0401,  ..., -0.0054, -0.0094, -0.0347],
        [ 0.0045,  0.0043, -0.0135,  ...,  0.0205, -0.0172,  0.0105],
        ...,
        [-0.0121,  0.0095, -0.0033,  ...,  0.0542,  0.0104,  0.0356],
        [ 0.0433,  0.0046,  0.0262,  ..., -0.0415, -0.0351, -0.0303],
        [ 0.0103,  0.0194,  0.0370,  ..., -0.0282, -0.0147, -0.0007]],
       dtype=torch.float16), 'model.layers.5.self_attn.k_proj.weight': tensor([[-0.0049,  0.0373,  0.0067,  ...,  0.0198, -0.0056, -0.0016],
        [ 0.0006,  0.0027, -0.0324,  ...,  0.0231, -0.0123,  0.0318],
        [-0.0116, -0.0233,  0.0013,  ...,  0.0026, -0.0059,  0.0032],
        ...,
        [ 0.0031, -0.0016, -0.0228,  ...,  0.0397,  0.0098, -0.0320],
        [ 0.0524,  0.0166, -0.0242,  ..., -0.0012, -0.0159, -0.0361],
        [-0.0242, -0.0217,  0.0421,  ..., -0.0155, -0.0347,  0.0102]],
       dtype=torch.float16), 'model.layers.5.self_attn.v_proj.weight': tensor([[-3.0975e-02,  6.6643e-03,  9.8114e-03,  ...,  2.2919e-02,
          7.3671e-05,  2.3392e-02],
        [ 3.9635e-03,  1.0124e-02, -1.8448e-02,  ..., -1.1353e-02,
          3.7670e-03, -1.3893e-02],
        [ 2.2354e-02,  2.4128e-03, -2.9063e-04,  ..., -2.4063e-02,
          2.8976e-02,  1.1208e-02],
        ...,
        [ 2.0477e-02,  1.1581e-02,  1.0353e-02,  ...,  3.7048e-02,
         -5.7449e-03,  1.1454e-03],
        [-5.3596e-03,  3.0289e-03, -4.7684e-03,  ...,  9.9945e-04,
         -9.2010e-03,  8.7404e-04],
        [-1.2375e-02, -6.2561e-03,  2.1561e-02,  ..., -9.5673e-03,
         -9.2545e-03, -1.5900e-02]], dtype=torch.float16), 'model.layers.5.self_attn.o_proj.weight': tensor([[-0.0155, -0.0091,  0.0050,  ..., -0.0181, -0.0074,  0.0271],
        [ 0.0017,  0.0016, -0.0094,  ..., -0.0182,  0.0043,  0.0034],
        [-0.0014, -0.0026,  0.0131,  ...,  0.0181,  0.0119,  0.0234],
        ...,
        [ 0.0181,  0.0066, -0.0060,  ...,  0.0162,  0.0306, -0.0247],
        [-0.0016,  0.0017, -0.0038,  ..., -0.0184, -0.0139, -0.0013],
        [ 0.0051,  0.0035, -0.0148,  ..., -0.0011, -0.0060, -0.0158]],
       dtype=torch.float16), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0002, -0.0082, -0.0302,  ...,  0.0003, -0.0062, -0.0114],
        [ 0.0216, -0.0073, -0.0212,  ...,  0.0374, -0.0015,  0.0022],
        [ 0.0123,  0.0039, -0.0196,  ...,  0.0148,  0.0164, -0.0348],
        ...,
        [ 0.0065,  0.0096,  0.0416,  ..., -0.0671,  0.0157, -0.0199],
        [-0.0280,  0.0043,  0.0038,  ...,  0.0014,  0.0170, -0.0017],
        [ 0.0282, -0.0299, -0.0141,  ..., -0.0040, -0.0043, -0.0409]],
       dtype=torch.float16), 'model.layers.5.mlp.up_proj.weight': tensor([[-0.0063, -0.0135, -0.0069,  ..., -0.0147,  0.0037, -0.0168],
        [-0.0320, -0.0062,  0.0009,  ...,  0.0124,  0.0182,  0.0228],
        [-0.0019,  0.0090,  0.0094,  ...,  0.0040,  0.0080,  0.0185],
        ...,
        [ 0.0077,  0.0239, -0.0076,  ..., -0.0109,  0.0145,  0.0252],
        [ 0.0447, -0.0130, -0.0292,  ..., -0.0080, -0.0179,  0.0240],
        [ 0.0085,  0.0172,  0.0130,  ..., -0.0103, -0.0041, -0.0160]],
       dtype=torch.float16), 'model.layers.5.mlp.down_proj.weight': tensor([[-0.0074, -0.0270, -0.0031,  ...,  0.0008,  0.0067,  0.0141],
        [-0.0113,  0.0156,  0.0281,  ...,  0.0215,  0.0064, -0.0341],
        [ 0.0131,  0.0207,  0.0143,  ..., -0.0241, -0.0463,  0.0110],
        ...,
        [ 0.0110, -0.0240, -0.0051,  ...,  0.0063, -0.0257, -0.0186],
        [-0.0034, -0.0391,  0.0152,  ...,  0.0161,  0.0156, -0.0515],
        [ 0.0212,  0.0142, -0.0118,  ...,  0.0309,  0.0092, -0.0177]],
       dtype=torch.float16), 'model.layers.5.input_layernorm.weight': tensor([0.2617, 0.2695, 0.2637,  ..., 0.2500, 0.2695, 0.2676],
       dtype=torch.float16), 'model.layers.5.post_attention_layernorm.weight': tensor([0.2090, 0.1953, 0.1934,  ..., 0.2051, 0.2021, 0.2051],
       dtype=torch.float16), 'model.layers.6.self_attn.q_proj.weight': tensor([[-9.7351e-03, -1.1505e-02,  6.6071e-03,  ..., -3.3630e-02,
         -6.4468e-03, -4.9515e-03],
        [ 4.4250e-03, -6.5613e-03,  5.6343e-03,  ...,  1.4587e-02,
          3.5286e-03, -3.1464e-02],
        [-1.7654e-02,  2.4216e-02, -3.8513e-02,  ...,  3.0502e-02,
         -4.8431e-02, -3.2272e-03],
        ...,
        [ 1.2878e-02,  9.0103e-03, -3.7628e-02,  ...,  2.3987e-02,
          2.7657e-03,  1.5497e-03],
        [ 3.5614e-02,  3.2532e-02,  5.3329e-03,  ..., -9.7885e-03,
         -9.6497e-02, -2.0844e-02],
        [-6.3538e-02, -5.3558e-02, -4.8697e-05,  ...,  1.7288e-02,
          5.1155e-03,  8.5220e-03]], dtype=torch.float16), 'model.layers.6.self_attn.k_proj.weight': tensor([[ 0.0139, -0.0106,  0.0204,  ..., -0.0071,  0.0222,  0.0589],
        [-0.0198, -0.0036,  0.0422,  ...,  0.0071, -0.0126,  0.0158],
        [-0.0102, -0.0131, -0.0068,  ..., -0.0006, -0.0307, -0.0107],
        ...,
        [ 0.0214, -0.0376, -0.0183,  ...,  0.0607, -0.0023, -0.0482],
        [-0.0199,  0.0045, -0.0262,  ..., -0.0461, -0.0408,  0.0156],
        [-0.0544, -0.0241, -0.0399,  ...,  0.0161, -0.0420, -0.0188]],
       dtype=torch.float16), 'model.layers.6.self_attn.v_proj.weight': tensor([[ 0.0140,  0.0336,  0.0101,  ...,  0.0127, -0.0017,  0.0078],
        [ 0.0381, -0.0063, -0.0095,  ...,  0.0046, -0.0005,  0.0038],
        [-0.0079, -0.0024,  0.0124,  ...,  0.0101,  0.0240,  0.0046],
        ...,
        [-0.0221, -0.0061,  0.0052,  ...,  0.0010, -0.0165,  0.0085],
        [-0.0243, -0.0088, -0.0003,  ..., -0.0012, -0.0083,  0.0198],
        [ 0.0311,  0.0049,  0.0161,  ..., -0.0222,  0.0005, -0.0030]],
       dtype=torch.float16), 'model.layers.6.self_attn.o_proj.weight': tensor([[ 0.0112, -0.0127, -0.0365,  ..., -0.0135,  0.0086,  0.0113],
        [-0.0260,  0.0067, -0.0001,  ..., -0.0224,  0.0014, -0.0022],
        [ 0.0019, -0.0115, -0.0042,  ...,  0.0106,  0.0079,  0.0094],
        ...,
        [-0.0053, -0.0143, -0.0063,  ...,  0.0074, -0.0062,  0.0256],
        [-0.0204,  0.0092, -0.0014,  ..., -0.0024,  0.0081, -0.0214],
        [-0.0201, -0.0129,  0.0079,  ..., -0.0237,  0.0066,  0.0064]],
       dtype=torch.float16), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0222,  0.0260, -0.0189,  ..., -0.0039, -0.0074, -0.0042],
        [ 0.0321,  0.0016, -0.0231,  ...,  0.0066,  0.0205,  0.0123],
        [-0.0146,  0.0217, -0.0156,  ..., -0.0187,  0.0011,  0.0088],
        ...,
        [ 0.0056, -0.0261,  0.0048,  ...,  0.0091, -0.0184, -0.0066],
        [ 0.0083,  0.0047, -0.0169,  ..., -0.0235, -0.0025, -0.0016],
        [-0.0396, -0.0513,  0.0267,  ..., -0.0413, -0.0027,  0.0164]],
       dtype=torch.float16), 'model.layers.6.mlp.up_proj.weight': tensor([[-0.0147, -0.0145, -0.0228,  ...,  0.0067, -0.0053, -0.0105],
        [ 0.0071, -0.0485,  0.0392,  ...,  0.0123,  0.0003, -0.0055],
        [-0.0220, -0.0162, -0.0241,  ...,  0.0055,  0.0135,  0.0216],
        ...,
        [-0.0267,  0.0002,  0.0167,  ...,  0.0149, -0.0019,  0.0385],
        [ 0.0244,  0.0173, -0.0063,  ..., -0.0283,  0.0101,  0.0017],
        [-0.0249,  0.0287, -0.0220,  ...,  0.0081, -0.0178, -0.0498]],
       dtype=torch.float16), 'model.layers.6.mlp.down_proj.weight': tensor([[-0.0122,  0.0100, -0.0043,  ...,  0.0013,  0.0143,  0.0160],
        [-0.0081, -0.0157,  0.0045,  ..., -0.0036, -0.0266, -0.0125],
        [ 0.0030,  0.0159, -0.0086,  ...,  0.0244,  0.0240,  0.0227],
        ...,
        [ 0.0110, -0.0024,  0.0207,  ...,  0.0316, -0.0336, -0.0099],
        [ 0.0216, -0.0065,  0.0070,  ...,  0.0098, -0.0135, -0.0126],
        [ 0.0152, -0.0165, -0.0085,  ...,  0.0319, -0.0050,  0.0079]],
       dtype=torch.float16), 'model.layers.6.input_layernorm.weight': tensor([0.3223, 0.3613, 0.3242,  ..., 0.3145, 0.3359, 0.3223],
       dtype=torch.float16), 'model.layers.6.post_attention_layernorm.weight': tensor([0.2217, 0.2129, 0.2090,  ..., 0.2227, 0.2168, 0.2178],
       dtype=torch.float16), 'model.layers.7.self_attn.q_proj.weight': tensor([[-6.2637e-03, -1.0843e-03, -8.1658e-06,  ..., -3.4428e-03,
         -2.0752e-02, -6.3477e-03],
        [-1.0460e-02,  1.4365e-04, -1.0338e-03,  ...,  1.2947e-02,
         -3.6564e-03, -1.6739e-02],
        [ 5.0201e-03,  6.6719e-03, -3.1158e-02,  ..., -2.0416e-02,
         -7.5684e-03,  9.1553e-03],
        ...,
        [-1.5259e-03, -3.3752e-02, -2.5040e-02,  ..., -1.2718e-02,
          3.4180e-02,  3.5553e-02],
        [ 1.3344e-02,  5.2917e-02, -4.0039e-02,  ..., -1.1269e-02,
         -6.7383e-02, -5.6915e-02],
        [ 7.9102e-02, -2.4200e-02, -1.8158e-02,  ...,  8.2947e-02,
          3.1113e-02, -4.3716e-03]], dtype=torch.float16), 'model.layers.7.self_attn.k_proj.weight': tensor([[ 0.0032, -0.0077, -0.0123,  ...,  0.0064,  0.0024, -0.0099],
        [-0.0070, -0.0178,  0.0048,  ..., -0.0072,  0.0043,  0.0185],
        [-0.0024, -0.0103,  0.0107,  ..., -0.0082, -0.0065, -0.0179],
        ...,
        [ 0.0429,  0.0077,  0.0243,  ...,  0.0351,  0.0396,  0.0282],
        [ 0.0400,  0.0500, -0.0002,  ..., -0.0307, -0.0344, -0.0016],
        [ 0.0403,  0.0058,  0.0104,  ..., -0.0012,  0.0019, -0.0272]],
       dtype=torch.float16), 'model.layers.7.self_attn.v_proj.weight': tensor([[-1.4038e-02,  5.2605e-03,  1.2993e-02,  ...,  2.8549e-02,
          4.2191e-03, -1.3847e-02],
        [ 2.6672e-02, -2.6993e-02,  4.3640e-03,  ...,  2.0035e-02,
         -1.8890e-02, -1.5915e-02],
        [-6.8970e-03, -1.0094e-02, -3.4523e-03,  ..., -1.8097e-02,
          1.1665e-02, -7.9453e-05],
        ...,
        [-1.3485e-03, -3.8300e-02,  2.7924e-03,  ...,  5.7297e-03,
         -6.9427e-03, -4.0016e-03],
        [-3.7872e-02,  1.9394e-02, -2.7618e-02,  ..., -1.8707e-02,
          1.0628e-02, -1.9252e-04],
        [-7.4272e-03,  2.6951e-03, -8.4991e-03,  ...,  2.0401e-02,
          7.3357e-03,  1.1787e-02]], dtype=torch.float16), 'model.layers.7.self_attn.o_proj.weight': tensor([[ 0.0116, -0.0154,  0.0014,  ...,  0.0091, -0.0194,  0.0053],
        [-0.0066,  0.0281,  0.0115,  ..., -0.0417, -0.0176, -0.0100],
        [ 0.0047, -0.0011, -0.0201,  ..., -0.0096, -0.0059, -0.0107],
        ...,
        [-0.0163, -0.0252, -0.0036,  ...,  0.0259, -0.0186,  0.0010],
        [-0.0226,  0.0085,  0.0167,  ...,  0.0080, -0.0130,  0.0153],
        [ 0.0028, -0.0002,  0.0005,  ...,  0.0060, -0.0161,  0.0039]],
       dtype=torch.float16), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 7.7896e-03,  4.7340e-03, -5.0850e-03,  ..., -4.3983e-03,
         -3.3386e-02, -7.2746e-03],
        [-3.1647e-02,  1.0490e-02, -8.5449e-03,  ..., -4.9400e-03,
         -3.8891e-03,  2.0676e-03],
        [ 1.7075e-02, -3.0640e-02, -8.4043e-06,  ...,  2.5543e-02,
         -2.7069e-02,  3.4237e-03],
        ...,
        [ 1.6441e-03,  2.0504e-03, -1.4145e-02,  ..., -2.0462e-02,
          4.6463e-03, -2.1713e-02],
        [ 2.6989e-03,  1.8036e-02,  1.2131e-02,  ..., -4.7798e-03,
          6.1493e-03, -3.0258e-02],
        [ 1.9714e-02, -1.6556e-02, -1.0773e-02,  ...,  1.7761e-02,
          1.8799e-02, -6.9962e-03]], dtype=torch.float16), 'model.layers.7.mlp.up_proj.weight': tensor([[ 0.0250,  0.0014, -0.0038,  ...,  0.0224, -0.0396,  0.0026],
        [-0.0110, -0.0190,  0.0299,  ...,  0.0095, -0.0108,  0.0154],
        [ 0.0259, -0.0214,  0.0107,  ..., -0.0126,  0.0181, -0.0352],
        ...,
        [-0.0019, -0.0023, -0.0150,  ..., -0.0095, -0.0177,  0.0024],
        [ 0.0003,  0.0084,  0.0167,  ..., -0.0071,  0.0215, -0.0067],
        [-0.0245, -0.0151,  0.0063,  ...,  0.0170,  0.0119,  0.0050]],
       dtype=torch.float16), 'model.layers.7.mlp.down_proj.weight': tensor([[-0.0079, -0.0069,  0.0050,  ..., -0.0115, -0.0060, -0.0211],
        [-0.0095, -0.0072,  0.0217,  ..., -0.0125,  0.0093,  0.0047],
        [ 0.0106,  0.0077,  0.0231,  ..., -0.0157, -0.0048, -0.0210],
        ...,
        [-0.0100,  0.0002, -0.0191,  ...,  0.0123,  0.0022, -0.0257],
        [ 0.0428, -0.0037,  0.0073,  ..., -0.0168,  0.0043, -0.0133],
        [ 0.0117,  0.0195, -0.0333,  ...,  0.0041, -0.0196, -0.0012]],
       dtype=torch.float16), 'model.layers.7.input_layernorm.weight': tensor([0.3242, 0.3652, 0.3340,  ..., 0.3203, 0.3574, 0.3320],
       dtype=torch.float16), 'model.layers.7.post_attention_layernorm.weight': tensor([0.2383, 0.2197, 0.2236,  ..., 0.2314, 0.2324, 0.2314],
       dtype=torch.float16), 'model.layers.8.self_attn.q_proj.weight': tensor([[-0.0004, -0.0152, -0.0297,  ..., -0.0065,  0.0065, -0.0091],
        [-0.0125, -0.0141, -0.0328,  ...,  0.0038, -0.0112,  0.0025],
        [-0.0400, -0.0028, -0.0129,  ..., -0.0023,  0.0260, -0.0321],
        ...,
        [-0.0062,  0.0861,  0.0443,  ..., -0.0247, -0.0285, -0.0468],
        [ 0.0012, -0.0596, -0.0192,  ...,  0.0352,  0.0269, -0.0008],
        [-0.0648, -0.0531, -0.0116,  ..., -0.0541,  0.0303, -0.0170]],
       dtype=torch.float16), 'model.layers.8.self_attn.k_proj.weight': tensor([[-0.0032, -0.0058, -0.0180,  ..., -0.0109,  0.0052,  0.0049],
        [-0.0125,  0.0011, -0.0050,  ...,  0.0228, -0.0019,  0.0143],
        [-0.0167,  0.0023,  0.0027,  ...,  0.0063, -0.0082, -0.0249],
        ...,
        [ 0.0031, -0.0395, -0.0067,  ..., -0.0295, -0.0149,  0.0230],
        [ 0.0078,  0.0294,  0.0184,  ..., -0.0301,  0.0431, -0.0562],
        [ 0.0190, -0.0026, -0.0326,  ...,  0.0140,  0.0077, -0.0147]],
       dtype=torch.float16), 'model.layers.8.self_attn.v_proj.weight': tensor([[-0.0287, -0.0166,  0.0045,  ..., -0.0193, -0.0085, -0.0096],
        [-0.0234, -0.0132,  0.0059,  ...,  0.0352,  0.0096,  0.0248],
        [-0.0082,  0.0140,  0.0135,  ..., -0.0079,  0.0031, -0.0204],
        ...,
        [ 0.0319, -0.0149,  0.0065,  ...,  0.0218, -0.0201,  0.0271],
        [ 0.0327, -0.0165,  0.0041,  ...,  0.0074, -0.0036,  0.0023],
        [ 0.0126, -0.0004, -0.0005,  ..., -0.0017,  0.0009, -0.0126]],
       dtype=torch.float16), 'model.layers.8.self_attn.o_proj.weight': tensor([[ 0.0177,  0.0157, -0.0148,  ..., -0.0109,  0.0026,  0.0176],
        [ 0.0054,  0.0004, -0.0322,  ..., -0.0121, -0.0108, -0.0186],
        [ 0.0025,  0.0138, -0.0094,  ..., -0.0011,  0.0121,  0.0166],
        ...,
        [-0.0150,  0.0233, -0.0010,  ...,  0.0010, -0.0001, -0.0027],
        [ 0.0086,  0.0015, -0.0089,  ...,  0.0043,  0.0054, -0.0251],
        [-0.0232, -0.0003, -0.0096,  ...,  0.0193, -0.0100,  0.0087]],
       dtype=torch.float16), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0158, -0.0021, -0.0490,  ...,  0.0059, -0.0245, -0.0163],
        [-0.0002, -0.0475,  0.0061,  ..., -0.0033, -0.0370,  0.0276],
        [ 0.0212,  0.0191,  0.0176,  ...,  0.0272,  0.0241, -0.0056],
        ...,
        [-0.0111,  0.0015,  0.0134,  ...,  0.0221,  0.0168,  0.0057],
        [-0.0146,  0.0039,  0.0056,  ..., -0.0016, -0.0165,  0.0145],
        [-0.0243,  0.0096, -0.0066,  ..., -0.0134,  0.0060,  0.0033]],
       dtype=torch.float16), 'model.layers.8.mlp.up_proj.weight': tensor([[-0.0055,  0.0251, -0.0157,  ...,  0.0298,  0.0039, -0.0158],
        [-0.0517,  0.0134, -0.0384,  ...,  0.0145, -0.0113, -0.0159],
        [ 0.0176, -0.0004,  0.0102,  ..., -0.0102, -0.0179,  0.0334],
        ...,
        [-0.0138,  0.0403, -0.0309,  ...,  0.0130,  0.0027,  0.0163],
        [ 0.0054, -0.0047, -0.0058,  ..., -0.0160,  0.0193, -0.0173],
        [-0.0224,  0.0174, -0.0155,  ..., -0.0185, -0.0012, -0.0002]],
       dtype=torch.float16), 'model.layers.8.mlp.down_proj.weight': tensor([[-0.0099, -0.0094,  0.0129,  ...,  0.0072,  0.0198, -0.0290],
        [ 0.0178,  0.0132, -0.0227,  ..., -0.0072,  0.0143, -0.0171],
        [ 0.0061, -0.0186, -0.0251,  ..., -0.0091, -0.0019,  0.0038],
        ...,
        [ 0.0090, -0.0205, -0.0343,  ...,  0.0038,  0.0098, -0.0160],
        [ 0.0096,  0.0107, -0.0036,  ..., -0.0060, -0.0068, -0.0226],
        [-0.0031,  0.0103,  0.0024,  ...,  0.0047,  0.0011,  0.0048]],
       dtype=torch.float16), 'model.layers.8.input_layernorm.weight': tensor([0.3301, 0.3477, 0.3320,  ..., 0.3203, 0.3398, 0.3242],
       dtype=torch.float16), 'model.layers.8.post_attention_layernorm.weight': tensor([0.2422, 0.2314, 0.2236,  ..., 0.2363, 0.2324, 0.2305],
       dtype=torch.float16), 'model.layers.9.self_attn.q_proj.weight': tensor([[-0.0147,  0.0026,  0.0210,  ..., -0.0103, -0.0100, -0.0244],
        [-0.0023, -0.0385,  0.0208,  ..., -0.0013, -0.0039,  0.0068],
        [ 0.0012, -0.0021, -0.0153,  ..., -0.0283, -0.0279, -0.0179],
        ...,
        [-0.0006, -0.0509,  0.0130,  ...,  0.0190,  0.0121, -0.0163],
        [ 0.0161, -0.0186,  0.0037,  ...,  0.0068,  0.0028,  0.0125],
        [-0.0003,  0.0516,  0.0195,  ..., -0.0563,  0.0534, -0.0034]],
       dtype=torch.float16), 'model.layers.9.self_attn.k_proj.weight': tensor([[-0.0307,  0.0100, -0.0252,  ..., -0.0017, -0.0205, -0.0061],
        [-0.0069,  0.0352,  0.0098,  ..., -0.0149,  0.0085,  0.0003],
        [-0.0164, -0.0064,  0.0345,  ...,  0.0036, -0.0246, -0.0038],
        ...,
        [ 0.0229, -0.0136, -0.0035,  ..., -0.0085,  0.0241,  0.0240],
        [ 0.0319,  0.0002,  0.0217,  ...,  0.0495, -0.0169,  0.0517],
        [ 0.0084, -0.0259,  0.0257,  ...,  0.0061,  0.0235, -0.0248]],
       dtype=torch.float16), 'model.layers.9.self_attn.v_proj.weight': tensor([[-0.0064,  0.0087,  0.0034,  ...,  0.0043, -0.0216, -0.0148],
        [-0.0142, -0.0147, -0.0031,  ...,  0.0340, -0.0037, -0.0044],
        [ 0.0071, -0.0220,  0.0211,  ..., -0.0274,  0.0032, -0.0137],
        ...,
        [-0.0094, -0.0083,  0.0037,  ...,  0.0052, -0.0218, -0.0055],
        [-0.0172, -0.0003, -0.0087,  ..., -0.0159,  0.0021, -0.0135],
        [ 0.0245,  0.0242, -0.0037,  ..., -0.0092, -0.0047, -0.0060]],
       dtype=torch.float16), 'model.layers.9.self_attn.o_proj.weight': tensor([[ 0.0102,  0.0094,  0.0113,  ..., -0.0143,  0.0007, -0.0113],
        [-0.0017, -0.0193, -0.0068,  ..., -0.0033,  0.0041,  0.0140],
        [-0.0407, -0.0316,  0.0091,  ...,  0.0292,  0.0020,  0.0106],
        ...,
        [ 0.0148, -0.0133,  0.0091,  ...,  0.0057,  0.0059, -0.0098],
        [ 0.0072,  0.0159,  0.0002,  ...,  0.0084,  0.0001,  0.0006],
        [ 0.0189,  0.0456, -0.0234,  ..., -0.0009,  0.0104,  0.0045]],
       dtype=torch.float16), 'model.layers.9.mlp.gate_proj.weight': tensor([[-0.0097,  0.0258,  0.0002,  ..., -0.0271, -0.0084,  0.0018],
        [-0.0202,  0.0319,  0.0322,  ...,  0.0281,  0.0377,  0.0024],
        [ 0.0390,  0.0285, -0.0269,  ..., -0.0217,  0.0120,  0.0011],
        ...,
        [-0.0204, -0.0079, -0.0243,  ...,  0.0019, -0.0409,  0.0066],
        [-0.0061, -0.0243,  0.0275,  ..., -0.0112,  0.0039,  0.0113],
        [ 0.0146, -0.0229, -0.0039,  ...,  0.0122, -0.0083,  0.0163]],
       dtype=torch.float16), 'model.layers.9.mlp.up_proj.weight': tensor([[-0.0143,  0.0186,  0.0150,  ..., -0.0016, -0.0087,  0.0038],
        [ 0.0086, -0.0010,  0.0079,  ...,  0.0153,  0.0204, -0.0192],
        [-0.0182, -0.0051, -0.0223,  ..., -0.0026, -0.0114,  0.0033],
        ...,
        [ 0.0029,  0.0126, -0.0075,  ..., -0.0150, -0.0307, -0.0130],
        [ 0.0031,  0.0218, -0.0348,  ..., -0.0351, -0.0096, -0.0163],
        [ 0.0102, -0.0337, -0.0058,  ..., -0.0190,  0.0217, -0.0074]],
       dtype=torch.float16), 'model.layers.9.mlp.down_proj.weight': tensor([[-0.0030,  0.0313, -0.0411,  ...,  0.0004, -0.0109,  0.0136],
        [ 0.0216, -0.0283, -0.0173,  ..., -0.0057, -0.0223, -0.0278],
        [-0.0026, -0.0015,  0.0022,  ..., -0.0155,  0.0007, -0.0026],
        ...,
        [-0.0101,  0.0194,  0.0052,  ..., -0.0095, -0.0285,  0.0141],
        [-0.0309,  0.0034,  0.0155,  ..., -0.0204, -0.0034, -0.0333],
        [ 0.0165,  0.0171,  0.0078,  ...,  0.0404,  0.0161,  0.0167]],
       dtype=torch.float16), 'model.layers.9.input_layernorm.weight': tensor([0.3535, 0.3633, 0.3281,  ..., 0.3477, 0.3477, 0.3438],
       dtype=torch.float16), 'model.layers.9.post_attention_layernorm.weight': tensor([0.2490, 0.2334, 0.2285,  ..., 0.2451, 0.2422, 0.2383],
       dtype=torch.float16), 'model.layers.10.self_attn.q_proj.weight': tensor([[-3.6449e-03,  3.8357e-03,  2.0087e-05,  ..., -2.7161e-03,
         -6.6376e-03, -1.4206e-02],
        [-9.7427e-03, -4.9667e-03,  2.0599e-02,  ..., -1.9287e-02,
          6.4575e-02, -3.7270e-03],
        [-1.3718e-02, -1.5106e-02,  2.1040e-04,  ...,  3.4210e-02,
         -9.4452e-03, -1.4389e-02],
        ...,
        [ 3.2104e-02,  6.3049e-02, -1.7929e-02,  ...,  3.7445e-02,
          3.3508e-02, -9.3842e-03],
        [-6.6040e-02,  5.6519e-02, -2.7695e-03,  ..., -6.0577e-02,
         -5.7068e-03, -3.6221e-03],
        [-4.9713e-02, -2.1591e-02, -7.7477e-03,  ..., -1.2627e-02,
         -3.6346e-02, -9.3536e-03]], dtype=torch.float16), 'model.layers.10.self_attn.k_proj.weight': tensor([[-0.0320,  0.0131, -0.0093,  ..., -0.0153,  0.0091, -0.0001],
        [-0.0056,  0.0082, -0.0056,  ..., -0.0057, -0.0101,  0.0133],
        [-0.0008, -0.0022,  0.0067,  ..., -0.0274,  0.0042,  0.0012],
        ...,
        [-0.0464, -0.0599,  0.0127,  ...,  0.0291, -0.0853,  0.0117],
        [-0.0345, -0.0131,  0.0234,  ..., -0.0141, -0.0415, -0.0148],
        [-0.0192,  0.0225, -0.0224,  ...,  0.0083,  0.0425, -0.0002]],
       dtype=torch.float16), 'model.layers.10.self_attn.v_proj.weight': tensor([[-0.0387,  0.0081, -0.0087,  ...,  0.0097,  0.0140,  0.0083],
        [-0.0083,  0.0136,  0.0120,  ..., -0.0067, -0.0419,  0.0195],
        [ 0.0170, -0.0150,  0.0130,  ...,  0.0145,  0.0079, -0.0095],
        ...,
        [ 0.0214,  0.0277,  0.0017,  ...,  0.0253,  0.0023, -0.0228],
        [-0.0040,  0.0057, -0.0005,  ...,  0.0020,  0.0113, -0.0018],
        [ 0.0172,  0.0061, -0.0238,  ..., -0.0072, -0.0071,  0.0242]],
       dtype=torch.float16), 'model.layers.10.self_attn.o_proj.weight': tensor([[-0.0057,  0.0007, -0.0348,  ...,  0.0022,  0.0056,  0.0074],
        [ 0.0006, -0.0118,  0.0126,  ...,  0.0058,  0.0132,  0.0075],
        [ 0.0153, -0.0353, -0.0162,  ...,  0.0007, -0.0036, -0.0031],
        ...,
        [-0.0021,  0.0080, -0.0197,  ..., -0.0031, -0.0003,  0.0199],
        [ 0.0090, -0.0164, -0.0207,  ...,  0.0118,  0.0087,  0.0109],
        [ 0.0075, -0.0081, -0.0278,  ...,  0.0101, -0.0039,  0.0009]],
       dtype=torch.float16), 'model.layers.10.mlp.gate_proj.weight': tensor([[-0.0255, -0.0464, -0.0296,  ...,  0.0059, -0.0014, -0.0041],
        [-0.0152, -0.0224, -0.0173,  ...,  0.0032,  0.0152,  0.0143],
        [-0.0210, -0.0214,  0.0097,  ...,  0.0347, -0.0098,  0.0017],
        ...,
        [-0.0465, -0.0077,  0.0100,  ...,  0.0039, -0.0303,  0.0208],
        [ 0.0046,  0.0114,  0.0203,  ...,  0.0042, -0.0112, -0.0007],
        [-0.0159, -0.0042, -0.0147,  ..., -0.0145,  0.0072, -0.0121]],
       dtype=torch.float16), 'model.layers.10.mlp.up_proj.weight': tensor([[-0.0320, -0.0040, -0.0427,  ...,  0.0109, -0.0067, -0.0190],
        [-0.0074,  0.0061,  0.0065,  ...,  0.0190,  0.0319, -0.0167],
        [-0.0080, -0.0042,  0.0192,  ...,  0.0319, -0.0360,  0.0033],
        ...,
        [ 0.0242,  0.0213, -0.0094,  ..., -0.0432, -0.0039,  0.0027],
        [-0.0012, -0.0116, -0.0232,  ...,  0.0270, -0.0056,  0.0214],
        [-0.0042,  0.0167, -0.0049,  ..., -0.0009,  0.0034,  0.0205]],
       dtype=torch.float16), 'model.layers.10.mlp.down_proj.weight': tensor([[-0.0152, -0.0201, -0.0101,  ...,  0.0302, -0.0133,  0.0010],
        [-0.0054,  0.0221, -0.0139,  ..., -0.0116,  0.0119, -0.0105],
        [-0.0275, -0.0021,  0.0208,  ..., -0.0218, -0.0254,  0.0118],
        ...,
        [ 0.0098, -0.0068, -0.0057,  ...,  0.0063,  0.0142,  0.0074],
        [-0.0106,  0.0519, -0.0189,  ...,  0.0284,  0.0307, -0.0305],
        [-0.0471,  0.0020, -0.0252,  ..., -0.0184, -0.0151,  0.0109]],
       dtype=torch.float16), 'model.layers.10.input_layernorm.weight': tensor([0.3652, 0.3594, 0.3223,  ..., 0.3398, 0.3496, 0.3379],
       dtype=torch.float16), 'model.layers.10.post_attention_layernorm.weight': tensor([0.2500, 0.2383, 0.2285,  ..., 0.2432, 0.2432, 0.2432],
       dtype=torch.float16), 'model.layers.11.self_attn.q_proj.weight': tensor([[ 0.0161, -0.0006, -0.0169,  ...,  0.0251, -0.0088,  0.0062],
        [-0.0113,  0.0006,  0.0061,  ...,  0.0169,  0.0102,  0.0040],
        [ 0.0104,  0.0213, -0.0237,  ..., -0.0047, -0.0055,  0.0015],
        ...,
        [ 0.0066,  0.0024,  0.0322,  ...,  0.0338,  0.0438, -0.0291],
        [ 0.0504,  0.0148, -0.0166,  ..., -0.0151,  0.0161, -0.0268],
        [ 0.0818, -0.0201, -0.0214,  ..., -0.0201,  0.0410,  0.0539]],
       dtype=torch.float16), 'model.layers.11.self_attn.k_proj.weight': tensor([[-0.0052,  0.0221,  0.0030,  ..., -0.0179,  0.0177, -0.0154],
        [ 0.0012,  0.0016, -0.0310,  ..., -0.0106,  0.0045,  0.0256],
        [ 0.0298, -0.0297,  0.0027,  ...,  0.0140,  0.0046,  0.0079],
        ...,
        [-0.0032,  0.0288,  0.0043,  ..., -0.0189, -0.0055,  0.0403],
        [ 0.0598, -0.0065, -0.0142,  ..., -0.0078,  0.0050, -0.0079],
        [ 0.0110,  0.0065,  0.0253,  ..., -0.0007,  0.0569,  0.0267]],
       dtype=torch.float16), 'model.layers.11.self_attn.v_proj.weight': tensor([[ 9.6436e-03,  1.0605e-03, -4.5738e-03,  ..., -2.2232e-02,
         -1.0233e-03,  7.4806e-03],
        [ 2.6855e-03, -6.0806e-03, -1.6937e-02,  ..., -5.5611e-05,
          3.7360e-04, -2.7130e-02],
        [ 2.9392e-03,  9.2468e-03, -7.0686e-03,  ...,  1.6724e-02,
          1.0735e-02, -2.5055e-02],
        ...,
        [-2.0782e-02,  7.5455e-03, -1.4633e-02,  ...,  8.2016e-03,
         -1.7349e-02, -2.2812e-03],
        [-9.9487e-03,  1.0506e-02, -1.1917e-02,  ..., -1.3245e-02,
         -1.7868e-02,  3.2711e-03],
        [ 1.7990e-02, -2.1179e-02, -1.4639e-03,  ..., -4.0344e-02,
          1.8826e-03, -1.2375e-02]], dtype=torch.float16), 'model.layers.11.self_attn.o_proj.weight': tensor([[-0.0191, -0.0035,  0.0060,  ...,  0.0097,  0.0109,  0.0016],
        [-0.0016, -0.0260,  0.0116,  ..., -0.0118, -0.0028, -0.0255],
        [-0.0051, -0.0058,  0.0210,  ...,  0.0021, -0.0066,  0.0139],
        ...,
        [ 0.0016, -0.0042,  0.0228,  ...,  0.0024, -0.0016, -0.0029],
        [ 0.0077,  0.0177,  0.0082,  ...,  0.0172,  0.0129, -0.0298],
        [-0.0027, -0.0047,  0.0054,  ..., -0.0081, -0.0022, -0.0107]],
       dtype=torch.float16), 'model.layers.11.mlp.gate_proj.weight': tensor([[-0.0440, -0.0086,  0.0052,  ...,  0.0062, -0.0116,  0.0425],
        [ 0.0074, -0.0107,  0.0206,  ...,  0.0087, -0.0197, -0.0413],
        [-0.0010, -0.0459, -0.0289,  ..., -0.0025, -0.0084, -0.0026],
        ...,
        [-0.0202, -0.0397, -0.0216,  ..., -0.0041, -0.0321,  0.0039],
        [ 0.0090, -0.0044, -0.0364,  ..., -0.0127,  0.0069,  0.0010],
        [ 0.0023,  0.0186,  0.0080,  ...,  0.0468, -0.0007, -0.0140]],
       dtype=torch.float16), 'model.layers.11.mlp.up_proj.weight': tensor([[-0.0093,  0.0016, -0.0275,  ...,  0.0240,  0.0097,  0.0313],
        [ 0.0179, -0.0028, -0.0222,  ...,  0.0172, -0.0467,  0.0077],
        [-0.0064, -0.0369,  0.0014,  ..., -0.0048, -0.0177,  0.0154],
        ...,
        [ 0.0408,  0.0105, -0.0095,  ...,  0.0014, -0.0005,  0.0161],
        [-0.0116,  0.0200,  0.0059,  ...,  0.0163,  0.0094,  0.0065],
        [-0.0041,  0.0019, -0.0054,  ..., -0.0172, -0.0005,  0.0250]],
       dtype=torch.float16), 'model.layers.11.mlp.down_proj.weight': tensor([[-0.0162,  0.0454,  0.0091,  ...,  0.0194,  0.0163, -0.0040],
        [-0.0136, -0.0092, -0.0251,  ..., -0.0202, -0.0090,  0.0154],
        [-0.0237, -0.0169,  0.0102,  ...,  0.0052, -0.0217, -0.0031],
        ...,
        [ 0.0215,  0.0262, -0.0104,  ..., -0.0017, -0.0003,  0.0087],
        [-0.0111, -0.0290, -0.0306,  ..., -0.0254, -0.0089,  0.0139],
        [ 0.0362,  0.0240,  0.0214,  ..., -0.0028, -0.0135,  0.0383]],
       dtype=torch.float16), 'model.layers.11.input_layernorm.weight': tensor([0.3965, 0.3965, 0.3652,  ..., 0.3848, 0.3828, 0.3711],
       dtype=torch.float16), 'model.layers.11.post_attention_layernorm.weight': tensor([0.2598, 0.2471, 0.2383,  ..., 0.2578, 0.2559, 0.2559],
       dtype=torch.float16), 'model.layers.12.self_attn.q_proj.weight': tensor([[-0.0093, -0.0171,  0.0036,  ...,  0.0262, -0.0099,  0.0055],
        [ 0.0065, -0.0070, -0.0075,  ..., -0.0127,  0.0223,  0.0202],
        [ 0.0106,  0.0411, -0.0328,  ...,  0.0061,  0.0025, -0.0291],
        ...,
        [ 0.0094,  0.0321, -0.0197,  ..., -0.0311, -0.0004, -0.0008],
        [ 0.0424, -0.0059,  0.0097,  ...,  0.0322,  0.0067, -0.0247],
        [ 0.0332,  0.0143, -0.0364,  ..., -0.0210,  0.0215,  0.0238]],
       dtype=torch.float16), 'model.layers.12.self_attn.k_proj.weight': tensor([[ 0.0099, -0.0011, -0.0045,  ...,  0.0193, -0.0024, -0.0102],
        [ 0.0073,  0.0208, -0.0157,  ..., -0.0014, -0.0157, -0.0293],
        [-0.0113, -0.0283,  0.0173,  ...,  0.0087,  0.0026,  0.0026],
        ...,
        [ 0.0132,  0.0322, -0.0148,  ..., -0.0355, -0.0164, -0.0242],
        [-0.0381,  0.0037,  0.0226,  ..., -0.0282,  0.0146, -0.0006],
        [-0.0007,  0.0322,  0.0109,  ...,  0.0129, -0.0465, -0.0404]],
       dtype=torch.float16), 'model.layers.12.self_attn.v_proj.weight': tensor([[ 0.0064,  0.0072,  0.0069,  ..., -0.0077,  0.0109, -0.0189],
        [-0.0275,  0.0104, -0.0036,  ..., -0.0175, -0.0006,  0.0191],
        [-0.0148, -0.0132,  0.0088,  ..., -0.0069,  0.0475, -0.0107],
        ...,
        [ 0.0081, -0.0017, -0.0150,  ..., -0.0068, -0.0115, -0.0013],
        [-0.0010, -0.0147, -0.0047,  ...,  0.0034,  0.0109,  0.0122],
        [ 0.0225,  0.0017,  0.0007,  ...,  0.0178,  0.0139, -0.0070]],
       dtype=torch.float16), 'model.layers.12.self_attn.o_proj.weight': tensor([[ 0.0277,  0.0071, -0.0019,  ..., -0.0012,  0.0083, -0.0061],
        [-0.0092, -0.0141, -0.0014,  ..., -0.0108,  0.0061, -0.0138],
        [ 0.0068, -0.0023, -0.0018,  ...,  0.0037, -0.0232,  0.0125],
        ...,
        [ 0.0032, -0.0023,  0.0126,  ..., -0.0084, -0.0009,  0.0019],
        [-0.0108, -0.0346, -0.0278,  ..., -0.0121,  0.0109,  0.0143],
        [ 0.0210,  0.0093,  0.0084,  ...,  0.0209, -0.0084, -0.0171]],
       dtype=torch.float16), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0057, -0.0110,  0.0123,  ..., -0.0042,  0.0268, -0.0024],
        [-0.0266, -0.0214,  0.0172,  ...,  0.0121,  0.0153,  0.0057],
        [-0.0005,  0.0258, -0.0114,  ..., -0.0099, -0.0289, -0.0045],
        ...,
        [-0.0024,  0.0108,  0.0106,  ..., -0.0328,  0.0070,  0.0276],
        [-0.0325, -0.0083,  0.0082,  ...,  0.0103,  0.0123, -0.0085],
        [ 0.0045, -0.0267, -0.0056,  ..., -0.0053, -0.0018, -0.0202]],
       dtype=torch.float16), 'model.layers.12.mlp.up_proj.weight': tensor([[ 2.9488e-03,  1.7151e-02,  3.6030e-03,  ..., -9.1076e-05,
          1.3832e-02,  1.5427e-02],
        [-3.6373e-03, -1.4801e-02, -1.3435e-02,  ...,  6.5842e-03,
         -7.0915e-03,  2.4414e-02],
        [ 1.4610e-02, -1.2291e-02,  7.4959e-03,  ..., -4.1534e-02,
          4.9171e-03,  1.6441e-03],
        ...,
        [-2.6154e-02, -3.3844e-02, -7.3738e-03,  ...,  1.6922e-02,
         -1.5038e-02,  3.0403e-03],
        [-1.5144e-03, -4.3915e-02, -8.0156e-04,  ...,  1.3924e-02,
          3.0556e-03, -1.5656e-02],
        [ 2.2144e-03, -2.8961e-02,  3.7813e-04,  ...,  3.2440e-02,
         -3.6602e-03, -3.8300e-02]], dtype=torch.float16), 'model.layers.12.mlp.down_proj.weight': tensor([[ 0.0081, -0.0018, -0.0294,  ..., -0.0123,  0.0035,  0.0029],
        [ 0.0170, -0.0288,  0.0046,  ..., -0.0004, -0.0089, -0.0230],
        [ 0.0200,  0.0030,  0.0241,  ...,  0.0043, -0.0012, -0.0281],
        ...,
        [ 0.0183, -0.0085, -0.0380,  ...,  0.0313, -0.0193, -0.0176],
        [-0.0259,  0.0179,  0.0106,  ..., -0.0092,  0.0359, -0.0229],
        [ 0.0075,  0.0262,  0.0221,  ..., -0.0381,  0.0273, -0.0022]],
       dtype=torch.float16), 'model.layers.12.input_layernorm.weight': tensor([0.4062, 0.4023, 0.3691,  ..., 0.3848, 0.3867, 0.3887],
       dtype=torch.float16), 'model.layers.12.post_attention_layernorm.weight': tensor([0.2656, 0.2520, 0.2432,  ..., 0.2656, 0.2617, 0.2598],
       dtype=torch.float16), 'model.layers.13.self_attn.q_proj.weight': tensor([[-0.0002, -0.0013, -0.0132,  ...,  0.0055, -0.0150, -0.0128],
        [-0.0118, -0.0142,  0.0031,  ..., -0.0004,  0.0004, -0.0026],
        [-0.0175,  0.0138,  0.0197,  ..., -0.0115, -0.0075, -0.0069],
        ...,
        [ 0.0483,  0.0084,  0.0043,  ...,  0.0573,  0.0140, -0.0512],
        [ 0.0078,  0.0083, -0.0259,  ...,  0.0091,  0.0111, -0.0104],
        [-0.0040, -0.0248, -0.0212,  ..., -0.0068,  0.0285, -0.0065]],
       dtype=torch.float16), 'model.layers.13.self_attn.k_proj.weight': tensor([[ 0.0134,  0.0048, -0.0030,  ..., -0.0130,  0.0337,  0.0125],
        [ 0.0155,  0.0307, -0.0005,  ..., -0.0055,  0.0136,  0.0046],
        [-0.0007, -0.0130,  0.0334,  ..., -0.0083,  0.0110, -0.0375],
        ...,
        [ 0.0375,  0.0356,  0.0033,  ...,  0.0048, -0.0061, -0.0118],
        [-0.0010,  0.0045,  0.0287,  ..., -0.0342, -0.0217,  0.0352],
        [-0.0229, -0.0535, -0.0142,  ..., -0.0378, -0.0310,  0.0118]],
       dtype=torch.float16), 'model.layers.13.self_attn.v_proj.weight': tensor([[ 0.0149,  0.0064, -0.0058,  ..., -0.0005,  0.0173,  0.0124],
        [-0.0029,  0.0087,  0.0005,  ...,  0.0233, -0.0065, -0.0029],
        [ 0.0146, -0.0016, -0.0023,  ..., -0.0212,  0.0366, -0.0090],
        ...,
        [-0.0011,  0.0251, -0.0052,  ..., -0.0111,  0.0272, -0.0211],
        [-0.0103,  0.0104,  0.0128,  ...,  0.0017,  0.0274,  0.0058],
        [-0.0045, -0.0064,  0.0239,  ...,  0.0154, -0.0026,  0.0374]],
       dtype=torch.float16), 'model.layers.13.self_attn.o_proj.weight': tensor([[-0.0035,  0.0010, -0.0044,  ..., -0.0015, -0.0045, -0.0012],
        [ 0.0222,  0.0148,  0.0101,  ..., -0.0146, -0.0108,  0.0024],
        [ 0.0118,  0.0055,  0.0036,  ...,  0.0065, -0.0233, -0.0088],
        ...,
        [-0.0102,  0.0102,  0.0194,  ..., -0.0114, -0.0154, -0.0165],
        [ 0.0083, -0.0005,  0.0301,  ..., -0.0037, -0.0268, -0.0238],
        [ 0.0100,  0.0019,  0.0086,  ...,  0.0171, -0.0083, -0.0238]],
       dtype=torch.float16), 'model.layers.13.mlp.gate_proj.weight': tensor([[ 0.0249, -0.0034, -0.0082,  ...,  0.0114,  0.0034, -0.0122],
        [-0.0141,  0.0452,  0.0071,  ...,  0.0416, -0.0012, -0.0260],
        [ 0.0035, -0.0199, -0.0103,  ...,  0.0047, -0.0093, -0.0152],
        ...,
        [ 0.0153, -0.0196,  0.0202,  ..., -0.0065,  0.0133,  0.0111],
        [ 0.0154, -0.0125,  0.0203,  ...,  0.0181,  0.0106, -0.0270],
        [ 0.0028,  0.0392,  0.0161,  ..., -0.0045,  0.0059,  0.0285]],
       dtype=torch.float16), 'model.layers.13.mlp.up_proj.weight': tensor([[-0.0423,  0.0199, -0.0013,  ...,  0.0037,  0.0091,  0.0011],
        [ 0.0138, -0.0066,  0.0247,  ...,  0.0468,  0.0286,  0.0224],
        [ 0.0281, -0.0344,  0.0093,  ...,  0.0069,  0.0009, -0.0082],
        ...,
        [-0.0130, -0.0038,  0.0297,  ...,  0.0190, -0.0247,  0.0139],
        [-0.0103, -0.0171,  0.0079,  ...,  0.0177,  0.0563,  0.0096],
        [ 0.0117, -0.0212,  0.0179,  ..., -0.0185, -0.0004,  0.0269]],
       dtype=torch.float16), 'model.layers.13.mlp.down_proj.weight': tensor([[-0.0062, -0.0036, -0.0027,  ...,  0.0226, -0.0265, -0.0220],
        [-0.0117,  0.0470, -0.0413,  ..., -0.0018,  0.0133, -0.0090],
        [ 0.0081,  0.0038,  0.0183,  ...,  0.0015, -0.0249, -0.0031],
        ...,
        [ 0.0058,  0.0077,  0.0354,  ..., -0.0014, -0.0209,  0.0290],
        [ 0.0167, -0.0015,  0.0188,  ..., -0.0109,  0.0164, -0.0045],
        [ 0.0029, -0.0229,  0.0393,  ...,  0.0041,  0.0022,  0.0325]],
       dtype=torch.float16), 'model.layers.13.input_layernorm.weight': tensor([0.4199, 0.4121, 0.3770,  ..., 0.3926, 0.3848, 0.3965],
       dtype=torch.float16), 'model.layers.13.post_attention_layernorm.weight': tensor([0.2715, 0.2598, 0.2539,  ..., 0.2715, 0.2734, 0.2656],
       dtype=torch.float16), 'model.layers.14.self_attn.q_proj.weight': tensor([[-0.0088, -0.0028,  0.0195,  ..., -0.0054,  0.0162,  0.0367],
        [ 0.0097,  0.0160, -0.0124,  ..., -0.0348, -0.0203, -0.0406],
        [-0.0202, -0.0112,  0.0171,  ...,  0.0106,  0.0140, -0.0339],
        ...,
        [-0.0201,  0.0005, -0.0295,  ...,  0.0018,  0.0130, -0.0074],
        [ 0.0269, -0.0389,  0.0497,  ..., -0.0134,  0.0061, -0.0092],
        [-0.0175, -0.0090, -0.0035,  ...,  0.0170,  0.0184, -0.0447]],
       dtype=torch.float16), 'model.layers.14.self_attn.k_proj.weight': tensor([[-0.0143, -0.0049,  0.0068,  ..., -0.0091,  0.0271,  0.0431],
        [ 0.0191,  0.0324, -0.0204,  ..., -0.0030, -0.0276, -0.0050],
        [-0.0183,  0.0034,  0.0196,  ...,  0.0239,  0.0110,  0.0012],
        ...,
        [-0.0387, -0.0029,  0.0264,  ..., -0.0049,  0.0017, -0.0254],
        [-0.0293,  0.0005,  0.0153,  ..., -0.0359, -0.0144,  0.0012],
        [-0.0202,  0.0292,  0.0236,  ...,  0.0703,  0.0087, -0.0386]],
       dtype=torch.float16), 'model.layers.14.self_attn.v_proj.weight': tensor([[ 7.4310e-03,  7.7629e-03, -3.8025e-02,  ..., -3.4210e-02,
         -5.2032e-03,  1.2451e-02],
        [-1.0204e-03, -2.5452e-02, -3.0117e-03,  ...,  1.0887e-02,
         -5.2512e-05, -3.2425e-03],
        [ 2.6276e-02, -1.5022e-02,  2.2659e-03,  ..., -5.5466e-03,
          2.3460e-03,  8.2321e-03],
        ...,
        [ 1.5747e-02, -1.1642e-02,  1.5343e-02,  ...,  1.5533e-02,
         -1.1597e-02,  2.6016e-03],
        [-1.1391e-02,  2.2583e-02, -3.5553e-02,  ..., -7.8058e-04,
         -8.8654e-03, -2.5574e-02],
        [ 3.5992e-03,  2.3102e-02, -2.2568e-02,  ..., -5.2261e-03,
         -3.3932e-03,  1.8295e-02]], dtype=torch.float16), 'model.layers.14.self_attn.o_proj.weight': tensor([[-0.0108,  0.0044, -0.0227,  ..., -0.0021,  0.0010, -0.0110],
        [ 0.0080,  0.0304,  0.0077,  ...,  0.0221, -0.0049,  0.0021],
        [ 0.0060,  0.0082,  0.0024,  ...,  0.0075,  0.0206,  0.0054],
        ...,
        [ 0.0245, -0.0073,  0.0008,  ..., -0.0073, -0.0022,  0.0139],
        [-0.0025,  0.0010, -0.0195,  ..., -0.0021,  0.0362,  0.0155],
        [-0.0085, -0.0104, -0.0139,  ..., -0.0070,  0.0146,  0.0060]],
       dtype=torch.float16), 'model.layers.14.mlp.gate_proj.weight': tensor([[-0.0084,  0.0011, -0.0090,  ...,  0.0102, -0.0185, -0.0064],
        [ 0.0296,  0.0080, -0.0390,  ...,  0.0377,  0.0119, -0.0075],
        [ 0.0095,  0.0148, -0.0004,  ..., -0.0081,  0.0108, -0.0179],
        ...,
        [ 0.0065,  0.0105, -0.0190,  ...,  0.0003, -0.0047,  0.0004],
        [ 0.0033,  0.0159,  0.0201,  ..., -0.0192,  0.0087,  0.0073],
        [ 0.0200,  0.0017,  0.0183,  ..., -0.0106, -0.0248,  0.0258]],
       dtype=torch.float16), 'model.layers.14.mlp.up_proj.weight': tensor([[ 0.0052,  0.0099,  0.0201,  ..., -0.0153,  0.0073,  0.0048],
        [ 0.0269,  0.0089, -0.0300,  ...,  0.0064,  0.0262,  0.0104],
        [ 0.0012, -0.0055,  0.0300,  ..., -0.0013,  0.0177, -0.0023],
        ...,
        [-0.0164, -0.0013, -0.0479,  ..., -0.0145, -0.0116, -0.0048],
        [-0.0415,  0.0074, -0.0075,  ..., -0.0081,  0.0239, -0.0144],
        [ 0.0029,  0.0235,  0.0122,  ...,  0.0086, -0.0140,  0.0131]],
       dtype=torch.float16), 'model.layers.14.mlp.down_proj.weight': tensor([[ 0.0100,  0.0243,  0.0113,  ..., -0.0290, -0.0019, -0.0056],
        [ 0.0121,  0.0222, -0.0091,  ...,  0.0131, -0.0032,  0.0189],
        [ 0.0080, -0.0420,  0.0119,  ...,  0.0042, -0.0302,  0.0124],
        ...,
        [ 0.0005,  0.0152, -0.0169,  ..., -0.0046, -0.0100, -0.0109],
        [ 0.0242,  0.0335,  0.0364,  ..., -0.0051, -0.0155,  0.0210],
        [-0.0245,  0.0057, -0.0101,  ..., -0.0300,  0.0070,  0.0187]],
       dtype=torch.float16), 'model.layers.14.input_layernorm.weight': tensor([0.4219, 0.4297, 0.3789,  ..., 0.4141, 0.4062, 0.3984],
       dtype=torch.float16), 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2734, 0.2656,  ..., 0.2871, 0.2832, 0.2793],
       dtype=torch.float16), 'model.layers.15.self_attn.q_proj.weight': tensor([[-0.0194, -0.0154, -0.0142,  ...,  0.0138, -0.0084,  0.0010],
        [ 0.0363, -0.0190,  0.0038,  ..., -0.0058,  0.0144,  0.0015],
        [ 0.0084, -0.0132,  0.0030,  ...,  0.0098, -0.0134, -0.0160],
        ...,
        [-0.0477, -0.0267,  0.0071,  ..., -0.0063, -0.0128,  0.0200],
        [-0.0155, -0.0536,  0.0174,  ...,  0.0155, -0.0015,  0.0025],
        [ 0.0236,  0.0251,  0.0278,  ..., -0.0140, -0.0227, -0.0165]],
       dtype=torch.float16), 'model.layers.15.self_attn.k_proj.weight': tensor([[ 0.0209, -0.0054, -0.0045,  ..., -0.0027,  0.0014,  0.0044],
        [ 0.0111, -0.0042, -0.0052,  ..., -0.0015,  0.0046, -0.0135],
        [-0.0021,  0.0020, -0.0083,  ..., -0.0007,  0.0133, -0.0119],
        ...,
        [-0.0540, -0.0380,  0.0168,  ...,  0.0214,  0.0069, -0.0060],
        [ 0.0092,  0.0011,  0.0159,  ...,  0.0275, -0.0217,  0.0132],
        [-0.0067, -0.0060,  0.0341,  ..., -0.0027, -0.0171,  0.0033]],
       dtype=torch.float16), 'model.layers.15.self_attn.v_proj.weight': tensor([[ 0.0088,  0.0023,  0.0053,  ...,  0.0037,  0.0141,  0.0177],
        [-0.0096, -0.0142,  0.0151,  ...,  0.0168,  0.0018,  0.0224],
        [ 0.0075, -0.0377, -0.0064,  ..., -0.0365,  0.0073,  0.0073],
        ...,
        [-0.0038, -0.0107,  0.0116,  ...,  0.0066,  0.0181, -0.0141],
        [ 0.0056, -0.0006, -0.0311,  ...,  0.0116,  0.0151, -0.0054],
        [ 0.0169,  0.0104,  0.0152,  ..., -0.0160,  0.0075,  0.0077]],
       dtype=torch.float16), 'model.layers.15.self_attn.o_proj.weight': tensor([[ 0.0012,  0.0029, -0.0154,  ...,  0.0104, -0.0127,  0.0282],
        [-0.0046, -0.0112, -0.0177,  ...,  0.0099, -0.0261,  0.0198],
        [ 0.0020, -0.0083,  0.0008,  ...,  0.0102, -0.0070,  0.0095],
        ...,
        [-0.0089, -0.0197,  0.0142,  ..., -0.0044, -0.0201, -0.0100],
        [ 0.0005, -0.0017, -0.0072,  ...,  0.0113,  0.0051,  0.0044],
        [-0.0241,  0.0053,  0.0263,  ..., -0.0118, -0.0254, -0.0296]],
       dtype=torch.float16), 'model.layers.15.mlp.gate_proj.weight': tensor([[-0.0145,  0.0259, -0.0075,  ...,  0.0116, -0.0298,  0.0140],
        [ 0.0069, -0.0101,  0.0278,  ..., -0.0192,  0.0056,  0.0099],
        [ 0.0088, -0.0179, -0.0112,  ...,  0.0231, -0.0539, -0.0260],
        ...,
        [-0.0106, -0.0046,  0.0301,  ..., -0.0094,  0.0175,  0.0069],
        [-0.0124, -0.0172,  0.0103,  ..., -0.0082, -0.0106, -0.0440],
        [ 0.0040, -0.0142, -0.0008,  ...,  0.0002,  0.0071, -0.0001]],
       dtype=torch.float16), 'model.layers.15.mlp.up_proj.weight': tensor([[-1.2886e-02, -9.5215e-03,  2.7924e-02,  ...,  1.2367e-02,
          1.1269e-02, -4.3579e-02],
        [-1.5732e-02,  4.2908e-02,  2.9343e-02,  ...,  1.0506e-02,
          7.6866e-03,  3.9864e-03],
        [-4.2419e-02, -7.7896e-03, -4.7994e-04,  ..., -1.5518e-02,
          1.5602e-02, -1.0269e-02],
        ...,
        [-6.7863e-03, -2.3376e-02, -7.8659e-03,  ...,  8.5068e-03,
         -4.8757e-05, -4.9782e-03],
        [ 2.7618e-02, -5.3329e-03,  7.8354e-03,  ..., -1.0330e-02,
          1.5747e-02,  5.7030e-04],
        [-7.5302e-03, -2.7130e-02, -9.7809e-03,  ...,  4.5633e-04,
         -1.2245e-02,  1.1940e-03]], dtype=torch.float16), 'model.layers.15.mlp.down_proj.weight': tensor([[-1.2512e-02, -6.8245e-03, -1.6098e-02,  ...,  2.5909e-02,
          9.1171e-03, -1.0674e-02],
        [ 1.0666e-02, -1.1749e-02, -2.6199e-02,  ..., -1.1993e-02,
         -2.3163e-02,  1.6129e-02],
        [ 3.8452e-02,  4.4830e-02, -1.5747e-02,  ..., -1.1589e-02,
          3.4302e-02,  1.8906e-02],
        ...,
        [-4.5853e-03, -3.9978e-02,  6.3210e-03,  ...,  9.4833e-03,
          5.5046e-03,  7.1466e-05],
        [-4.1779e-02, -1.7502e-02, -1.1826e-03,  ..., -2.9480e-02,
         -1.5137e-02,  7.0038e-03],
        [ 1.5354e-03,  2.3773e-02, -6.3553e-03,  ..., -1.7715e-02,
         -3.2593e-02, -2.0401e-02]], dtype=torch.float16), 'model.layers.15.input_layernorm.weight': tensor([0.4160, 0.4102, 0.3809,  ..., 0.3867, 0.3945, 0.3945],
       dtype=torch.float16), 'model.layers.15.post_attention_layernorm.weight': tensor([0.2930, 0.2793, 0.2793,  ..., 0.2969, 0.2910, 0.2891],
       dtype=torch.float16), 'model.layers.16.self_attn.q_proj.weight': tensor([[ 0.0090,  0.0135, -0.0253,  ...,  0.0048,  0.0263, -0.0078],
        [ 0.0172, -0.0415,  0.0228,  ...,  0.0170,  0.0186, -0.0237],
        [-0.0128, -0.0067,  0.0088,  ..., -0.0257,  0.0021, -0.0261],
        ...,
        [ 0.0328, -0.0378, -0.0080,  ..., -0.0196,  0.0181, -0.0271],
        [-0.0166, -0.0170,  0.0283,  ...,  0.0018, -0.0181,  0.0157],
        [ 0.0046,  0.0219,  0.0146,  ..., -0.0030, -0.0327, -0.0095]],
       dtype=torch.float16), 'model.layers.16.self_attn.k_proj.weight': tensor([[-0.0072,  0.0235,  0.0023,  ...,  0.0131,  0.0227,  0.0217],
        [ 0.0223, -0.0315,  0.0097,  ..., -0.0058, -0.0194, -0.0077],
        [ 0.0272, -0.0056, -0.0197,  ..., -0.0234,  0.0092, -0.0277],
        ...,
        [ 0.0239,  0.0135, -0.0127,  ..., -0.0233, -0.0399, -0.0581],
        [ 0.0161,  0.0086,  0.0133,  ...,  0.0302,  0.0043,  0.0115],
        [-0.0444,  0.0565,  0.0591,  ...,  0.0017, -0.0147,  0.0274]],
       dtype=torch.float16), 'model.layers.16.self_attn.v_proj.weight': tensor([[-0.0166,  0.0066, -0.0049,  ...,  0.0065, -0.0008, -0.0020],
        [-0.0576, -0.0069,  0.0042,  ...,  0.0035,  0.0128, -0.0267],
        [-0.0069, -0.0133, -0.0021,  ..., -0.0211,  0.0416,  0.0151],
        ...,
        [ 0.0040, -0.0079,  0.0167,  ..., -0.0125, -0.0001,  0.0166],
        [-0.0169,  0.0023,  0.0052,  ...,  0.0389, -0.0043,  0.0089],
        [ 0.0118,  0.0102,  0.0083,  ..., -0.0158, -0.0042, -0.0301]],
       dtype=torch.float16), 'model.layers.16.self_attn.o_proj.weight': tensor([[ 0.0388, -0.0079, -0.0170,  ...,  0.0112, -0.0126,  0.0047],
        [-0.0246,  0.0107, -0.0208,  ...,  0.0039, -0.0083,  0.0016],
        [-0.0285, -0.0177, -0.0134,  ..., -0.0021,  0.0259,  0.0170],
        ...,
        [-0.0030, -0.0207,  0.0029,  ...,  0.0046, -0.0266,  0.0010],
        [-0.0073,  0.0199,  0.0344,  ..., -0.0005,  0.0009, -0.0051],
        [-0.0192,  0.0035,  0.0066,  ...,  0.0018,  0.0024,  0.0109]],
       dtype=torch.float16), 'model.layers.16.mlp.gate_proj.weight': tensor([[-0.0275, -0.0157, -0.0233,  ...,  0.0007, -0.0003,  0.0085],
        [ 0.0313,  0.0157, -0.0098,  ...,  0.0153,  0.0087,  0.0166],
        [ 0.0027,  0.0056,  0.0041,  ..., -0.0008, -0.0035, -0.0189],
        ...,
        [-0.0086,  0.0085,  0.0053,  ...,  0.0223,  0.0300,  0.0286],
        [-0.0033, -0.0147,  0.0094,  ...,  0.0099,  0.0210,  0.0115],
        [ 0.0256,  0.0212,  0.0310,  ..., -0.0399,  0.0148, -0.0203]],
       dtype=torch.float16), 'model.layers.16.mlp.up_proj.weight': tensor([[-0.0403,  0.0147,  0.0066,  ...,  0.0294, -0.0128,  0.0091],
        [ 0.0156, -0.0131,  0.0048,  ...,  0.0215, -0.0303, -0.0077],
        [-0.0078, -0.0256, -0.0064,  ..., -0.0124, -0.0047,  0.0258],
        ...,
        [-0.0096,  0.0263, -0.0066,  ...,  0.0095, -0.0235, -0.0248],
        [-0.0098,  0.0216, -0.0177,  ...,  0.0097, -0.0052,  0.0185],
        [ 0.0099,  0.0079, -0.0118,  ...,  0.0013, -0.0239, -0.0209]],
       dtype=torch.float16), 'model.layers.16.mlp.down_proj.weight': tensor([[-0.0236,  0.0045,  0.0134,  ...,  0.0206, -0.0091, -0.0008],
        [-0.0233, -0.0041, -0.0123,  ...,  0.0286,  0.0018, -0.0002],
        [-0.0142,  0.0049, -0.0120,  ...,  0.0201, -0.0042, -0.0009],
        ...,
        [ 0.0143, -0.0248, -0.0242,  ...,  0.0203,  0.0178, -0.0020],
        [ 0.0227,  0.0019, -0.0097,  ..., -0.0214, -0.0128, -0.0098],
        [ 0.0107, -0.0168, -0.0371,  ...,  0.0256, -0.0010, -0.0141]],
       dtype=torch.float16), 'model.layers.16.input_layernorm.weight': tensor([0.4180, 0.4219, 0.3906,  ..., 0.3984, 0.4160, 0.4082],
       dtype=torch.float16), 'model.layers.16.post_attention_layernorm.weight': tensor([0.3164, 0.2949, 0.2988,  ..., 0.3105, 0.3086, 0.3047],
       dtype=torch.float16), 'model.layers.17.self_attn.q_proj.weight': tensor([[-0.0125, -0.0138,  0.0065,  ...,  0.0073, -0.0072, -0.0107],
        [ 0.0094, -0.0095,  0.0169,  ...,  0.0019, -0.0260,  0.0081],
        [-0.0130, -0.0020, -0.0129,  ...,  0.0152, -0.0114,  0.0020],
        ...,
        [ 0.0362, -0.0261,  0.0562,  ..., -0.0142, -0.0178,  0.0079],
        [ 0.0282, -0.0184,  0.0462,  ...,  0.0094, -0.0215, -0.0601],
        [ 0.0126, -0.0017,  0.0116,  ...,  0.0320,  0.0013,  0.0742]],
       dtype=torch.float16), 'model.layers.17.self_attn.k_proj.weight': tensor([[-0.0127, -0.0063,  0.0040,  ..., -0.0014,  0.0197,  0.0079],
        [ 0.0078,  0.0072,  0.0041,  ...,  0.0103,  0.0002, -0.0138],
        [ 0.0077, -0.0085,  0.0012,  ...,  0.0154, -0.0231, -0.0079],
        ...,
        [ 0.0041, -0.0500, -0.0091,  ..., -0.0221,  0.0599, -0.0676],
        [ 0.0275,  0.0191,  0.0122,  ..., -0.0132, -0.0267, -0.0225],
        [-0.0380, -0.0470, -0.0048,  ...,  0.0278,  0.0259, -0.0048]],
       dtype=torch.float16), 'model.layers.17.self_attn.v_proj.weight': tensor([[-0.0122,  0.0105,  0.0024,  ...,  0.0239, -0.0088, -0.0096],
        [-0.0039, -0.0155, -0.0111,  ...,  0.0116, -0.0257, -0.0144],
        [ 0.0174,  0.0158, -0.0024,  ...,  0.0018, -0.0111, -0.0288],
        ...,
        [ 0.0010, -0.0043,  0.0143,  ...,  0.0121,  0.0051, -0.0155],
        [ 0.0189, -0.0031, -0.0388,  ..., -0.0152, -0.0034, -0.0341],
        [-0.0093, -0.0103, -0.0053,  ...,  0.0055,  0.0081,  0.0092]],
       dtype=torch.float16), 'model.layers.17.self_attn.o_proj.weight': tensor([[-0.0049, -0.0105,  0.0036,  ..., -0.0197,  0.0008, -0.0131],
        [-0.0116, -0.0207,  0.0218,  ...,  0.0219, -0.0174,  0.0221],
        [ 0.0098, -0.0111, -0.0045,  ..., -0.0186, -0.0138, -0.0218],
        ...,
        [-0.0109,  0.0140, -0.0118,  ..., -0.0310, -0.0329, -0.0185],
        [-0.0070,  0.0101, -0.0009,  ..., -0.0287,  0.0044,  0.0065],
        [-0.0155, -0.0129,  0.0072,  ...,  0.0329, -0.0223,  0.0173]],
       dtype=torch.float16), 'model.layers.17.mlp.gate_proj.weight': tensor([[-0.0341,  0.0291,  0.0243,  ...,  0.0059,  0.0021,  0.0031],
        [-0.0008,  0.0264,  0.0270,  ...,  0.0185,  0.0077,  0.0121],
        [ 0.0100,  0.0120, -0.0222,  ...,  0.0171,  0.0307, -0.0055],
        ...,
        [-0.0114, -0.0160, -0.0122,  ..., -0.0103, -0.0229, -0.0157],
        [ 0.0041,  0.0033,  0.0092,  ...,  0.0065,  0.0431, -0.0114],
        [-0.0032,  0.0208,  0.0144,  ..., -0.0138, -0.0018, -0.0032]],
       dtype=torch.float16), 'model.layers.17.mlp.up_proj.weight': tensor([[-0.0169, -0.0280, -0.0067,  ...,  0.0061,  0.0168, -0.0130],
        [-0.0231,  0.0152,  0.0278,  ...,  0.0003,  0.0016,  0.0020],
        [-0.0010, -0.0031,  0.0035,  ...,  0.0089, -0.0150,  0.0119],
        ...,
        [ 0.0138,  0.0168,  0.0068,  ...,  0.0064, -0.0204, -0.0130],
        [-0.0162, -0.0182, -0.0103,  ..., -0.0115, -0.0220,  0.0159],
        [-0.0032,  0.0038, -0.0083,  ...,  0.0034, -0.0360, -0.0131]],
       dtype=torch.float16), 'model.layers.17.mlp.down_proj.weight': tensor([[ 0.0260, -0.0225,  0.0134,  ...,  0.0120, -0.0079, -0.0022],
        [ 0.0285,  0.0301,  0.0086,  ...,  0.0063, -0.0083,  0.0336],
        [-0.0263, -0.0165, -0.0178,  ...,  0.0121, -0.0150, -0.0046],
        ...,
        [ 0.0067, -0.0222, -0.0068,  ..., -0.0141, -0.0051, -0.0367],
        [ 0.0015,  0.0053, -0.0114,  ..., -0.0275, -0.0274,  0.0174],
        [-0.0009, -0.0200,  0.0189,  ..., -0.0368, -0.0108,  0.0045]],
       dtype=torch.float16), 'model.layers.17.input_layernorm.weight': tensor([0.4316, 0.4336, 0.4043,  ..., 0.4238, 0.4277, 0.4062],
       dtype=torch.float16), 'model.layers.17.post_attention_layernorm.weight': tensor([0.3320, 0.3164, 0.3145,  ..., 0.3320, 0.3301, 0.3223],
       dtype=torch.float16), 'model.layers.18.self_attn.q_proj.weight': tensor([[ 0.0067,  0.0054,  0.0022,  ..., -0.0046, -0.0363,  0.0100],
        [ 0.0022, -0.0133,  0.0213,  ...,  0.0001,  0.0255,  0.0434],
        [ 0.0111, -0.0257, -0.0097,  ...,  0.0015, -0.0081,  0.0164],
        ...,
        [-0.0324,  0.0133,  0.0033,  ...,  0.0230,  0.0055,  0.0155],
        [ 0.0622, -0.0166, -0.0270,  ...,  0.0574,  0.0266,  0.0184],
        [ 0.0301,  0.0155,  0.0043,  ...,  0.0281,  0.0549, -0.0513]],
       dtype=torch.float16), 'model.layers.18.self_attn.k_proj.weight': tensor([[-0.0115,  0.0326, -0.0141,  ...,  0.0089, -0.0094, -0.0243],
        [ 0.0082, -0.0191,  0.0162,  ...,  0.0176,  0.0292,  0.0015],
        [ 0.0123, -0.0097, -0.0019,  ...,  0.0210, -0.0017,  0.0248],
        ...,
        [-0.1082, -0.0282, -0.0618,  ...,  0.0203, -0.0044, -0.0386],
        [ 0.0520,  0.0363, -0.0182,  ...,  0.0459,  0.0646, -0.0261],
        [-0.0487, -0.0503, -0.0435,  ...,  0.0343, -0.0235, -0.0319]],
       dtype=torch.float16), 'model.layers.18.self_attn.v_proj.weight': tensor([[-0.0296,  0.0286, -0.0176,  ...,  0.0053,  0.0276,  0.0051],
        [ 0.0173,  0.0070, -0.0124,  ..., -0.0175,  0.0382, -0.0023],
        [ 0.0001,  0.0193,  0.0009,  ...,  0.0046, -0.0021, -0.0077],
        ...,
        [ 0.0137,  0.0160, -0.0047,  ..., -0.0077, -0.0233,  0.0025],
        [ 0.0073, -0.0028,  0.0031,  ...,  0.0136,  0.0159,  0.0355],
        [-0.0068,  0.0012,  0.0111,  ..., -0.0062, -0.0200,  0.0024]],
       dtype=torch.float16), 'model.layers.18.self_attn.o_proj.weight': tensor([[-0.0180,  0.0188, -0.0144,  ...,  0.0118,  0.0222,  0.0198],
        [-0.0003, -0.0400,  0.0047,  ..., -0.0010, -0.0070, -0.0164],
        [ 0.0022, -0.0141,  0.0099,  ...,  0.0279,  0.0158,  0.0373],
        ...,
        [-0.0351, -0.0236, -0.0248,  ...,  0.0230,  0.0176, -0.0098],
        [ 0.0128,  0.0511,  0.0149,  ...,  0.0131, -0.0084, -0.0367],
        [-0.0119, -0.0472, -0.0218,  ..., -0.0158,  0.0139, -0.0140]],
       dtype=torch.float16), 'model.layers.18.mlp.gate_proj.weight': tensor([[ 0.0147, -0.0038,  0.0166,  ..., -0.0080,  0.0101, -0.0105],
        [-0.0428,  0.0071, -0.0162,  ..., -0.0086, -0.0150, -0.0096],
        [-0.0190,  0.0073,  0.0444,  ..., -0.0250,  0.0031,  0.0038],
        ...,
        [-0.0438, -0.0219, -0.0285,  ..., -0.0296, -0.0218, -0.0233],
        [ 0.0015,  0.0197,  0.0297,  ..., -0.0164, -0.0011,  0.0164],
        [ 0.0040, -0.0041,  0.0039,  ...,  0.0107, -0.0188, -0.0050]],
       dtype=torch.float16), 'model.layers.18.mlp.up_proj.weight': tensor([[ 0.0165,  0.0081,  0.0298,  ..., -0.0004,  0.0271, -0.0095],
        [-0.0201,  0.0243, -0.0282,  ..., -0.0057, -0.0087, -0.0003],
        [-0.0311, -0.0098,  0.0076,  ...,  0.0074,  0.0209,  0.0261],
        ...,
        [-0.0012,  0.0045,  0.0046,  ...,  0.0238, -0.0075,  0.0040],
        [-0.0094, -0.0048, -0.0210,  ...,  0.0134,  0.0343,  0.0362],
        [ 0.0087,  0.0248,  0.0111,  ..., -0.0163,  0.0135,  0.0152]],
       dtype=torch.float16), 'model.layers.18.mlp.down_proj.weight': tensor([[ 0.0152,  0.0034, -0.0323,  ...,  0.0311,  0.0165,  0.0073],
        [ 0.0117, -0.0078,  0.0196,  ...,  0.0007, -0.0016, -0.0021],
        [ 0.0172, -0.0250, -0.0335,  ...,  0.0177,  0.0036,  0.0148],
        ...,
        [-0.0127,  0.0210,  0.0102,  ...,  0.0230, -0.0081, -0.0087],
        [-0.0160,  0.0116,  0.0182,  ...,  0.0120,  0.0356,  0.0087],
        [-0.0091,  0.0257,  0.0244,  ..., -0.0073,  0.0167,  0.0157]],
       dtype=torch.float16), 'model.layers.18.input_layernorm.weight': tensor([0.4570, 0.4551, 0.4316,  ..., 0.4375, 0.4512, 0.4355],
       dtype=torch.float16), 'model.layers.18.post_attention_layernorm.weight': tensor([0.3477, 0.3340, 0.3320,  ..., 0.3477, 0.3496, 0.3457],
       dtype=torch.float16), 'model.layers.19.self_attn.q_proj.weight': tensor([[ 5.5275e-03,  7.6294e-03, -9.7961e-03,  ..., -1.0323e-02,
         -3.1209e-04,  8.8806e-03],
        [ 2.6894e-03, -2.5539e-03,  3.1719e-03,  ..., -4.7493e-03,
          2.9022e-02,  1.7868e-02],
        [ 5.2185e-03,  2.1896e-02,  4.5896e-05,  ...,  8.6498e-04,
          1.5182e-02,  3.0727e-03],
        ...,
        [-1.4160e-02, -1.4923e-02,  1.0290e-03,  ..., -4.4189e-02,
         -3.1805e-04,  2.4979e-02],
        [ 4.7226e-03,  4.8279e-02,  2.3041e-02,  ...,  5.4077e-02,
          2.9755e-02, -2.9358e-02],
        [-1.5991e-02,  4.9011e-02,  5.8014e-02,  ..., -6.6414e-03,
         -4.1382e-02, -1.4290e-02]], dtype=torch.float16), 'model.layers.19.self_attn.k_proj.weight': tensor([[ 0.0216,  0.0117,  0.0022,  ..., -0.0116, -0.0213, -0.0106],
        [-0.0142,  0.0180, -0.0159,  ...,  0.0100,  0.0034,  0.0251],
        [-0.0157,  0.0043, -0.0122,  ...,  0.0044,  0.0137,  0.0252],
        ...,
        [ 0.0005,  0.0502, -0.0095,  ..., -0.0208,  0.0299, -0.0225],
        [-0.0653, -0.0269, -0.0101,  ...,  0.0084,  0.0184, -0.0099],
        [-0.0202,  0.0115, -0.0150,  ..., -0.0266,  0.0129,  0.0399]],
       dtype=torch.float16), 'model.layers.19.self_attn.v_proj.weight': tensor([[-0.0011, -0.0055, -0.0055,  ..., -0.0020,  0.0005,  0.0070],
        [-0.0020,  0.0188, -0.0031,  ...,  0.0351, -0.0211,  0.0162],
        [-0.0448, -0.0359, -0.0080,  ..., -0.0085, -0.0002,  0.0056],
        ...,
        [ 0.0013, -0.0373, -0.0014,  ...,  0.0010, -0.0002, -0.0166],
        [ 0.0145, -0.0095, -0.0219,  ..., -0.0066, -0.0073, -0.0058],
        [-0.0033,  0.0275,  0.0008,  ..., -0.0254, -0.0120,  0.0062]],
       dtype=torch.float16), 'model.layers.19.self_attn.o_proj.weight': tensor([[ 0.0296, -0.0517,  0.0258,  ...,  0.0012,  0.0066, -0.0257],
        [ 0.0307, -0.0164, -0.0036,  ..., -0.0145, -0.0012, -0.0030],
        [-0.0033, -0.0176, -0.0195,  ...,  0.0010,  0.0150,  0.0012],
        ...,
        [ 0.0123, -0.0018,  0.0002,  ...,  0.0056, -0.0152,  0.0122],
        [ 0.0089, -0.0057, -0.0186,  ..., -0.0244, -0.0204,  0.0051],
        [ 0.0127,  0.0175,  0.0140,  ..., -0.0233, -0.0083,  0.0153]],
       dtype=torch.float16), 'model.layers.19.mlp.gate_proj.weight': tensor([[-0.0082,  0.0010,  0.0049,  ..., -0.0039,  0.0037, -0.0065],
        [ 0.0145,  0.0183,  0.0011,  ..., -0.0036,  0.0125, -0.0351],
        [-0.0169, -0.0121, -0.0127,  ..., -0.0433,  0.0002,  0.0285],
        ...,
        [-0.0016,  0.0101, -0.0004,  ..., -0.0291, -0.0092, -0.0010],
        [-0.0475, -0.0082,  0.0029,  ..., -0.0074, -0.0217,  0.0107],
        [-0.0205, -0.0197,  0.0153,  ...,  0.0069,  0.0052, -0.0020]],
       dtype=torch.float16), 'model.layers.19.mlp.up_proj.weight': tensor([[ 0.0020, -0.0107,  0.0096,  ...,  0.0065,  0.0100,  0.0032],
        [-0.0134, -0.0063, -0.0158,  ...,  0.0269, -0.0230, -0.0070],
        [ 0.0094,  0.0039,  0.0094,  ..., -0.0246, -0.0129,  0.0532],
        ...,
        [ 0.0142,  0.0140,  0.0074,  ...,  0.0136, -0.0170,  0.0311],
        [ 0.0013,  0.0262,  0.0249,  ..., -0.0094,  0.0361, -0.0004],
        [-0.0002, -0.0181, -0.0124,  ..., -0.0027,  0.0045,  0.0140]],
       dtype=torch.float16), 'model.layers.19.mlp.down_proj.weight': tensor([[-0.0026, -0.0278,  0.0015,  ...,  0.0057, -0.0235,  0.0278],
        [-0.0050, -0.0306, -0.0208,  ...,  0.0139,  0.0175, -0.0169],
        [-0.0209, -0.0261,  0.0290,  ...,  0.0159, -0.0008,  0.0071],
        ...,
        [-0.0104, -0.0050,  0.0274,  ...,  0.0129,  0.0162,  0.0012],
        [ 0.0065, -0.0093, -0.0501,  ...,  0.0219, -0.0086, -0.0152],
        [ 0.0041, -0.0093, -0.0342,  ...,  0.0006,  0.0090,  0.0042]],
       dtype=torch.float16), 'model.layers.19.input_layernorm.weight': tensor([0.4570, 0.4629, 0.4395,  ..., 0.4316, 0.4395, 0.4414],
       dtype=torch.float16), 'model.layers.19.post_attention_layernorm.weight': tensor([0.3613, 0.3477, 0.3457,  ..., 0.3574, 0.3555, 0.3594],
       dtype=torch.float16), 'model.layers.20.self_attn.q_proj.weight': tensor([[-3.3512e-03,  2.7599e-03,  2.2141e-02,  ...,  3.8643e-03,
          3.5381e-03, -2.3499e-02],
        [ 1.8127e-02, -2.1729e-02, -4.8876e-06,  ..., -6.9809e-03,
         -1.2131e-02,  1.7120e-02],
        [ 7.9117e-03, -6.8665e-03, -1.8326e-02,  ...,  1.7166e-02,
          7.0038e-03,  8.3780e-04],
        ...,
        [-3.1219e-02, -5.3162e-02,  1.0094e-02,  ..., -1.0918e-02,
          3.9520e-02,  1.1047e-02],
        [-8.0872e-02, -1.9455e-02,  1.1688e-02,  ...,  8.7585e-03,
          2.6505e-02,  8.3389e-03],
        [ 2.6978e-02,  2.4643e-03, -5.2071e-03,  ..., -1.9089e-02,
         -5.4512e-03, -1.3123e-03]], dtype=torch.float16), 'model.layers.20.self_attn.k_proj.weight': tensor([[-5.6038e-03,  7.3128e-03,  3.8834e-03,  ..., -1.6464e-02,
         -3.4750e-05,  3.6964e-03],
        [-3.7003e-04,  8.7585e-03,  4.4060e-03,  ..., -2.0161e-03,
          4.6120e-03,  1.1047e-02],
        [ 1.4694e-02,  2.8610e-03, -1.1185e-02,  ..., -1.5091e-02,
          1.4725e-03,  1.9836e-02],
        ...,
        [ 2.0256e-03,  4.9706e-03, -1.7044e-02,  ..., -2.3407e-02,
          2.5925e-02,  3.5919e-02],
        [-2.4094e-02,  2.4918e-02,  2.4490e-03,  ...,  2.1759e-02,
          3.0762e-02,  5.1605e-02],
        [-1.5228e-02, -3.0060e-02, -1.5793e-02,  ...,  2.0111e-02,
         -2.3468e-02,  5.2704e-02]], dtype=torch.float16), 'model.layers.20.self_attn.v_proj.weight': tensor([[-7.1526e-03, -1.8005e-02,  1.3290e-02,  ..., -2.7752e-03,
          1.9043e-02,  1.1086e-02],
        [-1.5945e-02, -3.7201e-02,  5.2223e-03,  ..., -1.2299e-02,
          3.4332e-04,  9.0942e-03],
        [-3.0174e-03, -1.3779e-02,  3.5763e-03,  ..., -2.5085e-02,
          9.9301e-05,  6.9046e-04],
        ...,
        [ 9.6893e-03, -1.2962e-02, -2.5940e-03,  ...,  2.4796e-02,
         -7.9269e-03,  9.0103e-03],
        [ 1.8799e-02,  1.4400e-03, -9.5062e-03,  ...,  8.0681e-04,
          1.1032e-02, -1.3542e-02],
        [ 2.3708e-03, -3.8452e-03,  2.4155e-02,  ..., -5.8403e-03,
         -1.1604e-02, -4.0283e-02]], dtype=torch.float16), 'model.layers.20.self_attn.o_proj.weight': tensor([[-0.0066,  0.0037,  0.0200,  ..., -0.0024,  0.0155, -0.0167],
        [ 0.0103, -0.0098, -0.0066,  ..., -0.0050, -0.0065,  0.0191],
        [ 0.0099, -0.0022, -0.0135,  ..., -0.0240,  0.0092,  0.0103],
        ...,
        [-0.0074, -0.0039,  0.0135,  ...,  0.0168, -0.0150,  0.0116],
        [-0.0101,  0.0031, -0.0113,  ...,  0.0121, -0.0273,  0.0036],
        [ 0.0107, -0.0183, -0.0039,  ...,  0.0065, -0.0230,  0.0195]],
       dtype=torch.float16), 'model.layers.20.mlp.gate_proj.weight': tensor([[ 0.0012, -0.0088, -0.0118,  ...,  0.0177, -0.0055,  0.0139],
        [-0.0275,  0.0091, -0.0060,  ..., -0.0098, -0.0143,  0.0149],
        [-0.0167, -0.0078,  0.0665,  ..., -0.0155,  0.0111, -0.0063],
        ...,
        [-0.0048, -0.0114,  0.0241,  ..., -0.0145,  0.0109, -0.0033],
        [ 0.0093,  0.0071,  0.0046,  ...,  0.0154,  0.0030,  0.0123],
        [-0.0032, -0.0308, -0.0070,  ...,  0.0059, -0.0142, -0.0134]],
       dtype=torch.float16), 'model.layers.20.mlp.up_proj.weight': tensor([[-0.0601, -0.0002, -0.0019,  ...,  0.0153, -0.0108, -0.0119],
        [-0.0098,  0.0006, -0.0098,  ..., -0.0502, -0.0143,  0.0372],
        [ 0.0060,  0.0302,  0.0182,  ...,  0.0070, -0.0175,  0.0047],
        ...,
        [-0.0139,  0.0211, -0.0016,  ..., -0.0180, -0.0043, -0.0030],
        [ 0.0155, -0.0318, -0.0148,  ...,  0.0031, -0.0208, -0.0377],
        [ 0.0145, -0.0241,  0.0311,  ..., -0.0039, -0.0222,  0.0036]],
       dtype=torch.float16), 'model.layers.20.mlp.down_proj.weight': tensor([[-0.0016,  0.0202, -0.0034,  ...,  0.0053, -0.0169, -0.0248],
        [ 0.0021,  0.0127, -0.0073,  ...,  0.0044, -0.0178,  0.0143],
        [-0.0127,  0.0180, -0.0242,  ..., -0.0042,  0.0238, -0.0053],
        ...,
        [-0.0375,  0.0276,  0.0056,  ...,  0.0026, -0.0002, -0.0114],
        [-0.0156,  0.0062, -0.0158,  ...,  0.0057,  0.0178, -0.0025],
        [ 0.0120, -0.0131,  0.0019,  ..., -0.0029, -0.0063, -0.0147]],
       dtype=torch.float16), 'model.layers.20.input_layernorm.weight': tensor([0.4590, 0.4688, 0.4395,  ..., 0.4414, 0.4375, 0.4590],
       dtype=torch.float16), 'model.layers.20.post_attention_layernorm.weight': tensor([0.3711, 0.3633, 0.3535,  ..., 0.3672, 0.3672, 0.3691],
       dtype=torch.float16), 'model.layers.21.self_attn.q_proj.weight': tensor([[-0.0138, -0.0057,  0.0144,  ..., -0.0153, -0.0030,  0.0070],
        [ 0.0252,  0.0060, -0.0012,  ...,  0.0031,  0.0002,  0.0141],
        [-0.0117, -0.0101,  0.0026,  ...,  0.0280,  0.0023,  0.0066],
        ...,
        [-0.0025, -0.0157,  0.0354,  ..., -0.0107, -0.0593,  0.0191],
        [-0.0115,  0.0166,  0.0210,  ...,  0.0295,  0.0328,  0.0014],
        [-0.0795, -0.0016, -0.0130,  ..., -0.0056,  0.0264, -0.0380]],
       dtype=torch.float16), 'model.layers.21.self_attn.k_proj.weight': tensor([[-1.3864e-04,  4.9858e-03, -3.4065e-03,  ...,  7.4348e-03,
          3.9625e-04,  1.0353e-02],
        [-8.3685e-05,  7.3128e-03,  1.9882e-02,  ...,  6.2561e-03,
          9.4681e-03,  8.8806e-03],
        [ 1.8494e-02,  2.9202e-03,  2.8900e-02,  ...,  1.5823e-02,
          1.2871e-02,  1.4816e-02],
        ...,
        [-1.8295e-02,  2.6428e-02,  1.5945e-03,  ...,  2.5818e-02,
         -1.9394e-02,  4.6265e-02],
        [ 2.0866e-03, -3.1281e-03, -1.4458e-02,  ..., -2.2232e-02,
          3.1250e-02,  1.6203e-03],
        [-1.8906e-02, -8.1329e-03, -3.1433e-02,  ...,  7.8888e-03,
         -7.5493e-03,  5.9235e-02]], dtype=torch.float16), 'model.layers.21.self_attn.v_proj.weight': tensor([[ 0.0032,  0.0054, -0.0003,  ...,  0.0005,  0.0223, -0.0286],
        [-0.0232,  0.0240, -0.0079,  ...,  0.0211, -0.0195,  0.0266],
        [ 0.0280, -0.0030,  0.0003,  ..., -0.0232,  0.0258, -0.0058],
        ...,
        [-0.0056, -0.0269,  0.0320,  ..., -0.0065,  0.0038, -0.0102],
        [-0.0154, -0.0090,  0.0156,  ...,  0.0048, -0.0052,  0.0086],
        [-0.0069,  0.0157, -0.0162,  ...,  0.0070, -0.0155, -0.0029]],
       dtype=torch.float16), 'model.layers.21.self_attn.o_proj.weight': tensor([[-0.0118, -0.0017,  0.0116,  ..., -0.0132,  0.0231,  0.0102],
        [-0.0058,  0.0267, -0.0098,  ..., -0.0189,  0.0061, -0.0112],
        [-0.0298, -0.0130,  0.0119,  ...,  0.0249,  0.0273,  0.0079],
        ...,
        [ 0.0198, -0.0042, -0.0136,  ...,  0.0248, -0.0006,  0.0144],
        [ 0.0152, -0.0136,  0.0135,  ..., -0.0006,  0.0018, -0.0185],
        [-0.0264,  0.0155, -0.0134,  ...,  0.0298, -0.0163,  0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.gate_proj.weight': tensor([[-0.0058, -0.0234,  0.0144,  ..., -0.0285,  0.0456,  0.0089],
        [ 0.0061,  0.0061,  0.0039,  ..., -0.0275,  0.0574,  0.0085],
        [ 0.0084,  0.0064,  0.0049,  ..., -0.0498,  0.0041, -0.0245],
        ...,
        [ 0.0102, -0.0292, -0.0215,  ...,  0.0331, -0.0270,  0.0024],
        [-0.0010,  0.0293,  0.0065,  ...,  0.0160, -0.0249,  0.0030],
        [ 0.0093, -0.0124, -0.0017,  ..., -0.0182,  0.0064, -0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.up_proj.weight': tensor([[ 0.0276, -0.0258, -0.0142,  ...,  0.0225,  0.0422, -0.0112],
        [-0.0261, -0.0107,  0.0040,  ...,  0.0379,  0.0453, -0.0010],
        [ 0.0133, -0.0011, -0.0018,  ...,  0.0067, -0.0079, -0.0061],
        ...,
        [-0.0461, -0.0002,  0.0137,  ...,  0.0162, -0.0095, -0.0118],
        [-0.0100, -0.0107,  0.0042,  ..., -0.0188, -0.0023,  0.0027],
        [-0.0051, -0.0337, -0.0248,  ..., -0.0035, -0.0055, -0.0260]],
       dtype=torch.float16), 'model.layers.21.mlp.down_proj.weight': tensor([[ 0.0117,  0.0132,  0.0028,  ...,  0.0198,  0.0068,  0.0062],
        [ 0.0095, -0.0029, -0.0151,  ...,  0.0037, -0.0319, -0.0163],
        [-0.0061,  0.0059,  0.0132,  ..., -0.0084,  0.0412,  0.0299],
        ...,
        [-0.0106,  0.0375,  0.0182,  ..., -0.0093, -0.0024,  0.0179],
        [ 0.0125,  0.0007, -0.0043,  ..., -0.0493, -0.0052,  0.0049],
        [ 0.0089,  0.0014,  0.0242,  ..., -0.0152,  0.0267, -0.0278]],
       dtype=torch.float16), 'model.layers.21.input_layernorm.weight': tensor([0.4805, 0.4883, 0.4688,  ..., 0.4609, 0.4805, 0.4824],
       dtype=torch.float16), 'model.layers.21.post_attention_layernorm.weight': tensor([0.3770, 0.3730, 0.3652,  ..., 0.3848, 0.3789, 0.3828],
       dtype=torch.float16), 'model.layers.22.self_attn.q_proj.weight': tensor([[-0.0249, -0.0096, -0.0046,  ...,  0.0535, -0.0391,  0.0201],
        [-0.0361, -0.0200, -0.0063,  ..., -0.0361,  0.0211, -0.0515],
        [-0.0322,  0.0232, -0.0146,  ...,  0.0286,  0.0173, -0.0100],
        ...,
        [ 0.0094,  0.0199,  0.0122,  ...,  0.0116,  0.0576, -0.0013],
        [-0.0323,  0.0064, -0.0220,  ...,  0.0465,  0.0088, -0.0131],
        [ 0.0380, -0.0125,  0.0065,  ..., -0.0505,  0.0111,  0.0195]],
       dtype=torch.float16), 'model.layers.22.self_attn.k_proj.weight': tensor([[-0.0130, -0.0065,  0.0037,  ...,  0.0139, -0.0164, -0.0157],
        [ 0.0106, -0.0099,  0.0312,  ..., -0.0320,  0.0375, -0.0140],
        [-0.0207,  0.0286, -0.0425,  ...,  0.0614,  0.0035, -0.0076],
        ...,
        [ 0.0210,  0.0074, -0.0286,  ..., -0.0204, -0.0135,  0.0172],
        [-0.0150, -0.0424,  0.0025,  ..., -0.0002, -0.0132, -0.0070],
        [ 0.0240, -0.0025,  0.0283,  ...,  0.0377, -0.0425,  0.0131]],
       dtype=torch.float16), 'model.layers.22.self_attn.v_proj.weight': tensor([[-0.0201,  0.0126, -0.0017,  ..., -0.0395, -0.0264,  0.0152],
        [-0.0346, -0.0108,  0.0072,  ..., -0.0269, -0.0413, -0.0159],
        [ 0.0243, -0.0267, -0.0040,  ...,  0.0528, -0.0026, -0.0139],
        ...,
        [-0.0104, -0.0462, -0.0226,  ...,  0.0124, -0.0114,  0.0218],
        [-0.0375, -0.0086,  0.0181,  ..., -0.0198,  0.0020, -0.0155],
        [ 0.0007,  0.0152, -0.0433,  ...,  0.0020, -0.0053,  0.0264]],
       dtype=torch.float16), 'model.layers.22.self_attn.o_proj.weight': tensor([[ 0.0263,  0.0156, -0.0218,  ..., -0.0026, -0.0353,  0.0123],
        [ 0.0242,  0.0126,  0.0108,  ...,  0.0045, -0.0100, -0.0247],
        [ 0.0046,  0.0026, -0.0081,  ..., -0.0232,  0.0110,  0.0107],
        ...,
        [-0.0008, -0.0238, -0.0129,  ..., -0.0138, -0.0166,  0.0042],
        [ 0.0259, -0.0104, -0.0196,  ..., -0.0260, -0.0027,  0.0137],
        [ 0.0039, -0.0258,  0.0213,  ...,  0.0115,  0.0122,  0.0111]],
       dtype=torch.float16), 'model.layers.22.mlp.gate_proj.weight': tensor([[-0.0284, -0.0156,  0.0184,  ...,  0.0108,  0.0197, -0.0452],
        [ 0.0226, -0.0165,  0.0014,  ...,  0.0043,  0.0029,  0.0221],
        [ 0.0005, -0.0069,  0.0054,  ...,  0.0142,  0.0002, -0.0003],
        ...,
        [-0.0043, -0.0079,  0.0014,  ..., -0.0152,  0.0073,  0.0022],
        [ 0.0095,  0.0165, -0.0293,  ..., -0.0035,  0.0127, -0.0289],
        [-0.0101,  0.0012,  0.0053,  ..., -0.0148,  0.0278,  0.0245]],
       dtype=torch.float16), 'model.layers.22.mlp.up_proj.weight': tensor([[ 0.0293,  0.0162, -0.0013,  ...,  0.0170,  0.0276,  0.0071],
        [ 0.0198,  0.0076,  0.0164,  ..., -0.0117, -0.0078,  0.0030],
        [ 0.0086, -0.0282, -0.0375,  ...,  0.0255,  0.0104,  0.0061],
        ...,
        [-0.0032, -0.0006, -0.0185,  ..., -0.0040,  0.0057,  0.0067],
        [ 0.0126, -0.0111, -0.0286,  ..., -0.0226,  0.0108, -0.0270],
        [-0.0014,  0.0023, -0.0036,  ..., -0.0440, -0.0598,  0.0154]],
       dtype=torch.float16), 'model.layers.22.mlp.down_proj.weight': tensor([[ 1.3527e-02, -5.1918e-03,  1.2299e-02,  ..., -1.8967e-02,
         -4.1428e-03, -3.6041e-02],
        [ 5.5885e-03,  2.6581e-02, -4.9362e-03,  ..., -1.1017e-02,
          1.4084e-02, -2.6627e-02],
        [-9.6512e-03,  3.9363e-04,  4.1962e-03,  ...,  1.2886e-02,
          4.5013e-03,  1.7517e-02],
        ...,
        [ 1.8250e-02, -8.5297e-03, -4.5288e-02,  ..., -2.8934e-03,
         -1.2947e-02, -1.7014e-02],
        [-1.1414e-02, -4.8767e-02,  1.1642e-02,  ...,  1.9028e-02,
         -2.7069e-02,  3.1433e-02],
        [ 1.4130e-02,  3.7551e-06, -3.1067e-02,  ..., -3.3903e-04,
         -1.8875e-02,  2.1286e-03]], dtype=torch.float16), 'model.layers.22.input_layernorm.weight': tensor([0.4883, 0.4922, 0.4805,  ..., 0.4688, 0.5000, 0.4902],
       dtype=torch.float16), 'model.layers.22.post_attention_layernorm.weight': tensor([0.3867, 0.3848, 0.3848,  ..., 0.3965, 0.3945, 0.3965],
       dtype=torch.float16), 'model.layers.23.self_attn.q_proj.weight': tensor([[-0.0039, -0.0179,  0.0076,  ..., -0.0155, -0.0002,  0.0023],
        [ 0.0042,  0.0015,  0.0140,  ..., -0.0166, -0.0002,  0.0083],
        [-0.0038,  0.0028,  0.0219,  ...,  0.0002, -0.0167,  0.0066],
        ...,
        [-0.0211,  0.0670,  0.0119,  ..., -0.0314, -0.0684, -0.0263],
        [-0.0411, -0.0311,  0.0199,  ..., -0.0232,  0.0020,  0.0060],
        [ 0.0047, -0.0559, -0.0093,  ...,  0.0072,  0.0403, -0.0026]],
       dtype=torch.float16), 'model.layers.23.self_attn.k_proj.weight': tensor([[-0.0030,  0.0121,  0.0090,  ...,  0.0010, -0.0083,  0.0059],
        [-0.0224,  0.0057, -0.0117,  ...,  0.0093,  0.0254,  0.0036],
        [ 0.0182,  0.0078, -0.0185,  ...,  0.0181,  0.0016, -0.0107],
        ...,
        [ 0.0067,  0.0374,  0.0580,  ..., -0.0332, -0.0120, -0.0131],
        [ 0.0034, -0.0352, -0.0113,  ..., -0.0232, -0.0226,  0.0194],
        [-0.0173, -0.0081, -0.0259,  ...,  0.0043,  0.0060, -0.0084]],
       dtype=torch.float16), 'model.layers.23.self_attn.v_proj.weight': tensor([[-0.0028,  0.0343, -0.0120,  ..., -0.0097, -0.0016, -0.0112],
        [-0.0093, -0.0038, -0.0190,  ..., -0.0033, -0.0097,  0.0105],
        [ 0.0111, -0.0211, -0.0208,  ...,  0.0130, -0.0508, -0.0305],
        ...,
        [ 0.0070,  0.0084,  0.0091,  ..., -0.0020,  0.0338,  0.0089],
        [ 0.0261,  0.0316, -0.0011,  ...,  0.0070,  0.0022, -0.0127],
        [-0.0201, -0.0131, -0.0540,  ...,  0.0057,  0.0076, -0.0381]],
       dtype=torch.float16), 'model.layers.23.self_attn.o_proj.weight': tensor([[-0.0019,  0.0019, -0.0202,  ..., -0.0179,  0.0104, -0.0070],
        [-0.0127, -0.0213, -0.0022,  ..., -0.0004,  0.0100, -0.0021],
        [ 0.0130,  0.0094,  0.0306,  ..., -0.0228, -0.0026, -0.0276],
        ...,
        [ 0.0290, -0.0114,  0.0348,  ..., -0.0162,  0.0113, -0.0013],
        [-0.0044,  0.0202, -0.0200,  ...,  0.0056, -0.0164,  0.0007],
        [ 0.0013, -0.0023, -0.0177,  ..., -0.0060,  0.0059, -0.0296]],
       dtype=torch.float16), 'model.layers.23.mlp.gate_proj.weight': tensor([[-1.1848e-02,  3.4424e-02, -1.0048e-02,  ..., -7.0152e-03,
          3.2776e-02,  9.2316e-03],
        [-1.4702e-02,  4.7729e-02, -1.7593e-02,  ...,  7.1678e-03,
         -1.8631e-02,  2.5070e-02],
        [-3.2349e-02,  1.4786e-02,  2.6913e-03,  ...,  1.5274e-02,
         -6.7444e-02,  1.2131e-02],
        ...,
        [-3.1548e-03,  1.9089e-02,  3.1509e-03,  ..., -8.1863e-03,
          7.2556e-03, -2.4643e-03],
        [-2.0828e-02,  3.8971e-02,  2.9430e-03,  ...,  3.3021e-05,
          7.8201e-03, -2.8381e-02],
        [ 8.8692e-04,  8.5144e-03,  1.6830e-02,  ..., -7.6561e-03,
          1.5450e-02, -1.6495e-02]], dtype=torch.float16), 'model.layers.23.mlp.up_proj.weight': tensor([[ 0.0283,  0.0066,  0.0351,  ...,  0.0134, -0.0322, -0.0074],
        [-0.0003,  0.0065, -0.0196,  ..., -0.0043, -0.0111,  0.0061],
        [-0.0177,  0.0038, -0.0218,  ...,  0.0182,  0.0106, -0.0052],
        ...,
        [-0.0084, -0.0166,  0.0116,  ...,  0.0093,  0.0408,  0.0053],
        [ 0.0036,  0.0078, -0.0382,  ...,  0.0106,  0.0070,  0.0220],
        [ 0.0014,  0.0079, -0.0071,  ...,  0.0070, -0.0126,  0.0127]],
       dtype=torch.float16), 'model.layers.23.mlp.down_proj.weight': tensor([[-0.0008,  0.0069, -0.0182,  ..., -0.0434, -0.0227,  0.0330],
        [-0.0012,  0.0231, -0.0064,  ...,  0.0257,  0.0306,  0.0021],
        [-0.0066, -0.0139, -0.0233,  ...,  0.0102,  0.0330, -0.0052],
        ...,
        [ 0.0001, -0.0050,  0.0135,  ...,  0.0180,  0.0037, -0.0187],
        [ 0.0296, -0.0114, -0.0007,  ..., -0.0026,  0.0101,  0.0058],
        [ 0.0031, -0.0307, -0.0152,  ..., -0.0104,  0.0204, -0.0025]],
       dtype=torch.float16), 'model.layers.23.input_layernorm.weight': tensor([0.5156, 0.5312, 0.5117,  ..., 0.5039, 0.5352, 0.5273],
       dtype=torch.float16), 'model.layers.23.post_attention_layernorm.weight': tensor([0.4043, 0.4023, 0.3965,  ..., 0.4043, 0.4121, 0.4062],
       dtype=torch.float16), 'model.layers.24.self_attn.q_proj.weight': tensor([[ 0.0204, -0.0176,  0.0145,  ...,  0.0364, -0.0300,  0.0106],
        [ 0.0215,  0.0088,  0.0012,  ..., -0.0026,  0.0186, -0.0139],
        [-0.0056, -0.0111, -0.0277,  ...,  0.0088, -0.0132,  0.0202],
        ...,
        [-0.0147,  0.0136, -0.0193,  ...,  0.0181, -0.0004, -0.0123],
        [-0.0288,  0.0078,  0.0070,  ...,  0.0100, -0.0323, -0.0062],
        [-0.0231, -0.0385, -0.0181,  ..., -0.0132,  0.0128,  0.0677]],
       dtype=torch.float16), 'model.layers.24.self_attn.k_proj.weight': tensor([[ 0.0235, -0.0035, -0.0125,  ...,  0.0110, -0.0008,  0.0021],
        [ 0.0118, -0.0169,  0.0035,  ..., -0.0216,  0.0245,  0.0066],
        [ 0.0097,  0.0045, -0.0445,  ...,  0.0204,  0.0171, -0.0175],
        ...,
        [ 0.0344,  0.0036,  0.0493,  ...,  0.0161,  0.0179, -0.0516],
        [-0.0119,  0.0177,  0.0127,  ...,  0.0320, -0.0181,  0.0027],
        [-0.0318, -0.0295, -0.0190,  ...,  0.0139, -0.0048,  0.0518]],
       dtype=torch.float16), 'model.layers.24.self_attn.v_proj.weight': tensor([[ 0.0212, -0.0251, -0.0028,  ..., -0.0041, -0.0040,  0.0113],
        [ 0.0288, -0.0173, -0.0054,  ..., -0.0646, -0.0470, -0.0240],
        [-0.0579, -0.0169, -0.0134,  ..., -0.0156, -0.0121, -0.0027],
        ...,
        [ 0.0011, -0.0192,  0.0171,  ...,  0.0272,  0.0067,  0.0217],
        [-0.0034, -0.0157, -0.0141,  ...,  0.0332, -0.0036,  0.0038],
        [ 0.0172,  0.0228,  0.0187,  ...,  0.0274, -0.0135, -0.0108]],
       dtype=torch.float16), 'model.layers.24.self_attn.o_proj.weight': tensor([[-0.0016,  0.0144,  0.0280,  ...,  0.0066, -0.0051, -0.0141],
        [-0.0118,  0.0308,  0.0156,  ...,  0.0195,  0.0282, -0.0186],
        [-0.0057, -0.0029,  0.0094,  ..., -0.0232,  0.0084, -0.0049],
        ...,
        [ 0.0045,  0.0179,  0.0119,  ..., -0.0027, -0.0031, -0.0005],
        [ 0.0508,  0.0096, -0.0061,  ...,  0.0075, -0.0257, -0.0106],
        [ 0.0026,  0.0155,  0.0109,  ...,  0.0046, -0.0261,  0.0131]],
       dtype=torch.float16), 'model.layers.24.mlp.gate_proj.weight': tensor([[-0.0267, -0.0104,  0.0093,  ..., -0.0031, -0.0058,  0.0011],
        [ 0.0075, -0.0302, -0.0231,  ...,  0.0075,  0.0110, -0.0131],
        [ 0.0014, -0.0466,  0.0257,  ...,  0.0015, -0.0532, -0.0207],
        ...,
        [ 0.0042, -0.0358, -0.0088,  ...,  0.0080,  0.0152, -0.0062],
        [ 0.0094,  0.0158,  0.0041,  ...,  0.0043,  0.0011,  0.0048],
        [-0.0410,  0.0326,  0.0009,  ...,  0.0294, -0.0074, -0.0473]],
       dtype=torch.float16), 'model.layers.24.mlp.up_proj.weight': tensor([[ 0.0016, -0.0057,  0.0201,  ...,  0.0262,  0.0025,  0.0263],
        [-0.0026,  0.0136, -0.0327,  ..., -0.0081, -0.0044, -0.0171],
        [ 0.0114, -0.0520,  0.0097,  ...,  0.0402,  0.0179, -0.0341],
        ...,
        [ 0.0115, -0.0207, -0.0147,  ..., -0.0067,  0.0112,  0.0111],
        [ 0.0412, -0.0033,  0.0132,  ...,  0.0025,  0.0054, -0.0100],
        [-0.0056, -0.0197,  0.0203,  ...,  0.0303,  0.0333,  0.0164]],
       dtype=torch.float16), 'model.layers.24.mlp.down_proj.weight': tensor([[-0.0052, -0.0114, -0.0357,  ...,  0.0015,  0.0022, -0.0194],
        [ 0.0278, -0.0030,  0.0175,  ..., -0.0015,  0.0048, -0.0508],
        [ 0.0195,  0.0135, -0.0284,  ...,  0.0095,  0.0215,  0.0078],
        ...,
        [-0.0092,  0.0149, -0.0204,  ..., -0.0330, -0.0109, -0.0146],
        [ 0.0112,  0.0248,  0.0120,  ...,  0.0257, -0.0255,  0.0133],
        [-0.0171, -0.0086,  0.0033,  ...,  0.0172, -0.0154, -0.0324]],
       dtype=torch.float16), 'model.layers.24.input_layernorm.weight': tensor([0.4980, 0.5273, 0.5195,  ..., 0.4863, 0.5234, 0.5156],
       dtype=torch.float16), 'model.layers.24.post_attention_layernorm.weight': tensor([0.4219, 0.4180, 0.4180,  ..., 0.4199, 0.4258, 0.4219],
       dtype=torch.float16), 'model.layers.25.self_attn.q_proj.weight': tensor([[ 1.7204e-03, -1.9974e-02, -2.5269e-02,  ...,  1.2192e-02,
         -9.5139e-03,  4.5357e-03],
        [-1.3947e-02,  3.5877e-03,  2.3804e-02,  ..., -1.4412e-02,
         -3.4485e-03,  2.4557e-05],
        [ 9.1629e-03,  8.6136e-03,  3.9368e-03,  ..., -1.1436e-02,
         -2.0157e-02, -1.5068e-02],
        ...,
        [ 5.5756e-02,  4.5746e-02,  2.2964e-03,  ...,  4.9858e-03,
          1.5762e-02, -2.6688e-02],
        [-6.3721e-02, -5.0293e-02, -1.2497e-02,  ..., -1.0338e-02,
         -2.1088e-02,  4.0932e-03],
        [ 3.9978e-02, -4.3365e-02, -2.2217e-02,  ...,  3.9279e-05,
          1.0757e-02, -2.6917e-02]], dtype=torch.float16), 'model.layers.25.self_attn.k_proj.weight': tensor([[-5.6648e-03, -1.3237e-02, -1.2611e-02,  ...,  1.5726e-03,
          1.6232e-03,  1.4572e-03],
        [-1.4183e-02, -1.4297e-02,  2.7120e-05,  ..., -3.4618e-03,
         -2.1515e-02,  7.6561e-03],
        [-8.5354e-04,  1.9426e-03,  4.9133e-03,  ...,  6.0310e-03,
         -6.0654e-03,  7.2212e-03],
        ...,
        [ 1.3847e-02,  4.8248e-02, -9.6283e-03,  ..., -5.4504e-02,
         -5.6427e-02,  3.7598e-02],
        [ 3.4454e-02, -3.4393e-02,  4.3602e-03,  ..., -8.3771e-03,
          2.8229e-03,  1.0277e-02],
        [-7.9346e-03, -2.7908e-02,  3.2768e-03,  ...,  3.6316e-02,
          8.8501e-03, -2.9388e-02]], dtype=torch.float16), 'model.layers.25.self_attn.v_proj.weight': tensor([[ 0.0173,  0.0201,  0.0084,  ...,  0.0248, -0.0133, -0.0128],
        [-0.0143, -0.0107,  0.0099,  ...,  0.0090, -0.0273, -0.0127],
        [-0.0150,  0.0164, -0.0202,  ..., -0.0099,  0.0054, -0.0090],
        ...,
        [-0.0186, -0.0324, -0.0026,  ...,  0.0150,  0.0097,  0.0189],
        [-0.0152,  0.0089,  0.0258,  ..., -0.0068,  0.0044, -0.0216],
        [-0.0386, -0.0105, -0.0145,  ...,  0.0065,  0.0192,  0.0297]],
       dtype=torch.float16), 'model.layers.25.self_attn.o_proj.weight': tensor([[ 1.9470e-02,  1.0475e-02,  1.3229e-02,  ...,  1.4595e-02,
          2.8362e-03,  3.7861e-03],
        [-2.6352e-02, -9.8953e-03, -1.6998e-02,  ...,  2.6093e-02,
         -7.1945e-03, -1.3523e-03],
        [-8.1863e-03, -1.5879e-03,  2.5925e-02,  ..., -1.9821e-02,
         -1.3336e-02, -1.3371e-03],
        ...,
        [-1.3893e-02,  2.3819e-02, -2.7676e-03,  ...,  1.0544e-02,
          1.3359e-02,  2.7084e-02],
        [-4.1842e-05, -2.7664e-02, -3.7750e-02,  ..., -2.3926e-02,
         -1.6037e-02,  2.2125e-03],
        [-2.4704e-02, -8.4839e-03, -1.3412e-02,  ..., -3.7964e-02,
         -2.0554e-02, -1.3344e-02]], dtype=torch.float16), 'model.layers.25.mlp.gate_proj.weight': tensor([[ 0.0037, -0.0402,  0.0397,  ..., -0.0020, -0.0228,  0.0070],
        [-0.0239, -0.0074, -0.0153,  ...,  0.0345,  0.0486,  0.0262],
        [-0.0017,  0.0171, -0.0012,  ...,  0.0176,  0.0161,  0.0310],
        ...,
        [-0.0347,  0.0086,  0.0019,  ..., -0.0027, -0.0130,  0.0004],
        [ 0.0218,  0.0088,  0.0610,  ...,  0.0170,  0.0224,  0.0062],
        [-0.0047, -0.0022, -0.0174,  ...,  0.0450,  0.0030, -0.0100]],
       dtype=torch.float16), 'model.layers.25.mlp.up_proj.weight': tensor([[-0.0265, -0.0114,  0.0169,  ...,  0.0016,  0.0052, -0.0100],
        [-0.0138, -0.0033,  0.0076,  ..., -0.0056,  0.0163,  0.0114],
        [ 0.0298,  0.0056,  0.0224,  ..., -0.0136, -0.0282, -0.0026],
        ...,
        [ 0.0102,  0.0049,  0.0475,  ...,  0.0056, -0.0394, -0.0210],
        [-0.0387, -0.0015, -0.0307,  ..., -0.0457, -0.0228, -0.0002],
        [-0.0147, -0.0097,  0.0229,  ...,  0.0258, -0.0055,  0.0242]],
       dtype=torch.float16), 'model.layers.25.mlp.down_proj.weight': tensor([[ 0.0289, -0.0159,  0.0110,  ...,  0.0204, -0.0067,  0.0310],
        [-0.0150, -0.0020,  0.0045,  ...,  0.0100, -0.0012,  0.0230],
        [ 0.0123,  0.0103, -0.0082,  ..., -0.0229,  0.0118, -0.0181],
        ...,
        [ 0.0188, -0.0142, -0.0232,  ..., -0.0466, -0.0010,  0.0237],
        [ 0.0065, -0.0114,  0.0031,  ...,  0.0045,  0.0039,  0.0058],
        [-0.0111, -0.0243,  0.0161,  ..., -0.0298, -0.0061, -0.0051]],
       dtype=torch.float16), 'model.layers.25.input_layernorm.weight': tensor([0.5547, 0.5703, 0.5547,  ..., 0.5547, 0.5742, 0.5625],
       dtype=torch.float16), 'model.layers.25.post_attention_layernorm.weight': tensor([0.4316, 0.4316, 0.4297,  ..., 0.4355, 0.4336, 0.4395],
       dtype=torch.float16), 'model.layers.26.self_attn.q_proj.weight': tensor([[ 0.0299, -0.0067, -0.0090,  ..., -0.0101,  0.0408,  0.0010],
        [-0.0050, -0.0182,  0.0142,  ...,  0.0062, -0.0230,  0.0177],
        [-0.0064,  0.0024,  0.0114,  ...,  0.0050, -0.0381, -0.0195],
        ...,
        [ 0.0009, -0.0125, -0.0078,  ...,  0.0158,  0.0216,  0.0021],
        [ 0.0070, -0.0182, -0.0230,  ...,  0.0060, -0.0005, -0.0075],
        [-0.0146,  0.0520,  0.0271,  ..., -0.0072, -0.0645, -0.0416]],
       dtype=torch.float16), 'model.layers.26.self_attn.k_proj.weight': tensor([[ 0.0220,  0.0199, -0.0121,  ..., -0.0308,  0.0384,  0.0029],
        [-0.0267,  0.0055,  0.0148,  ...,  0.0016,  0.0168,  0.0291],
        [ 0.0129,  0.0286,  0.0004,  ..., -0.0190, -0.0591, -0.0098],
        ...,
        [ 0.0247,  0.0246,  0.0012,  ..., -0.0466, -0.0545,  0.0259],
        [-0.0216, -0.0389, -0.0074,  ...,  0.0483,  0.0228, -0.0051],
        [-0.0171,  0.0094, -0.0132,  ...,  0.0006, -0.0198, -0.0154]],
       dtype=torch.float16), 'model.layers.26.self_attn.v_proj.weight': tensor([[ 0.0506, -0.0262, -0.0245,  ..., -0.0152,  0.0105, -0.0191],
        [-0.0491, -0.0213,  0.0254,  ...,  0.0101, -0.0062,  0.0016],
        [ 0.0013, -0.0020, -0.0238,  ..., -0.0061,  0.0042, -0.0306],
        ...,
        [-0.0236, -0.0176, -0.0008,  ...,  0.0428, -0.0050,  0.0086],
        [ 0.0039, -0.0365, -0.0094,  ..., -0.0166, -0.0242, -0.0042],
        [ 0.0092,  0.0188, -0.0045,  ...,  0.0071,  0.0064,  0.0172]],
       dtype=torch.float16), 'model.layers.26.self_attn.o_proj.weight': tensor([[ 0.0108, -0.0005, -0.0306,  ...,  0.0052,  0.0149,  0.0272],
        [ 0.0067,  0.0455,  0.0062,  ..., -0.0016,  0.0462, -0.0053],
        [ 0.0013,  0.0102, -0.0247,  ..., -0.0226,  0.0037, -0.0018],
        ...,
        [ 0.0307,  0.0040,  0.0108,  ..., -0.0002,  0.0182,  0.0043],
        [-0.0128,  0.0049, -0.0096,  ...,  0.0135, -0.0017, -0.0425],
        [ 0.0257,  0.0072,  0.0050,  ..., -0.0276,  0.0283, -0.0160]],
       dtype=torch.float16), 'model.layers.26.mlp.gate_proj.weight': tensor([[ 0.0187,  0.0045,  0.0131,  ...,  0.0258,  0.0262, -0.0261],
        [-0.0062,  0.0102, -0.0258,  ..., -0.0255, -0.0266,  0.0190],
        [ 0.0022, -0.0109,  0.0007,  ...,  0.0060,  0.0038, -0.0172],
        ...,
        [-0.0065,  0.0356, -0.0078,  ..., -0.0015, -0.0380, -0.0219],
        [-0.0150,  0.0138,  0.0250,  ...,  0.0159,  0.0240,  0.0123],
        [ 0.0182, -0.0038, -0.0058,  ..., -0.0301, -0.0062, -0.0043]],
       dtype=torch.float16), 'model.layers.26.mlp.up_proj.weight': tensor([[-0.0168,  0.0401,  0.0018,  ...,  0.0049, -0.0029, -0.0195],
        [-0.0410, -0.0193,  0.0116,  ...,  0.0265, -0.0069,  0.0175],
        [ 0.0082, -0.0065, -0.0241,  ...,  0.0146, -0.0218, -0.0152],
        ...,
        [ 0.0058, -0.0324,  0.0059,  ...,  0.0126,  0.0300, -0.0139],
        [-0.0445,  0.0100,  0.0505,  ...,  0.0299, -0.0133,  0.0091],
        [ 0.0003, -0.0191,  0.0266,  ..., -0.0121,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.layers.26.mlp.down_proj.weight': tensor([[-0.0157, -0.0151, -0.0184,  ...,  0.0317,  0.0165,  0.0026],
        [ 0.0194,  0.0122,  0.0013,  ...,  0.0555,  0.0187, -0.0188],
        [-0.0182,  0.0041, -0.0274,  ..., -0.0111,  0.0171,  0.0083],
        ...,
        [-0.0175, -0.0124, -0.0203,  ...,  0.0105,  0.0436, -0.0020],
        [-0.0128, -0.0142, -0.0195,  ...,  0.0095,  0.0033,  0.0230],
        [ 0.0049, -0.0129, -0.0006,  ...,  0.0101,  0.0221,  0.0164]],
       dtype=torch.float16), 'model.layers.26.input_layernorm.weight': tensor([0.5312, 0.5469, 0.5469,  ..., 0.5234, 0.5508, 0.5547],
       dtype=torch.float16), 'model.layers.26.post_attention_layernorm.weight': tensor([0.4492, 0.4492, 0.4375,  ..., 0.4512, 0.4590, 0.4590],
       dtype=torch.float16), 'model.layers.27.self_attn.q_proj.weight': tensor([[-0.0292,  0.0145,  0.0077,  ..., -0.0038,  0.0122,  0.0435],
        [-0.0134,  0.0433,  0.0299,  ..., -0.0242,  0.0111,  0.0059],
        [-0.0217, -0.0236,  0.0096,  ...,  0.0025, -0.0223,  0.0289],
        ...,
        [-0.0505,  0.0273, -0.0095,  ...,  0.0185, -0.0201, -0.0225],
        [-0.0039,  0.0271,  0.0072,  ...,  0.0084,  0.0002,  0.0258],
        [-0.0235, -0.0104,  0.0114,  ...,  0.0226,  0.0154, -0.0077]],
       dtype=torch.float16), 'model.layers.27.self_attn.k_proj.weight': tensor([[-0.0173, -0.0195,  0.0098,  ..., -0.0015, -0.0104,  0.0059],
        [-0.0029,  0.0090,  0.0194,  ...,  0.0424, -0.0081, -0.0110],
        [ 0.0017, -0.0138,  0.0081,  ..., -0.0129,  0.0021, -0.0088],
        ...,
        [-0.0041, -0.0153,  0.0362,  ...,  0.0069, -0.0344, -0.0087],
        [ 0.0248, -0.0192, -0.0473,  ...,  0.0660, -0.0128,  0.0439],
        [ 0.0315,  0.0143, -0.0021,  ..., -0.0374, -0.0376,  0.0114]],
       dtype=torch.float16), 'model.layers.27.self_attn.v_proj.weight': tensor([[ 0.0174, -0.0144, -0.0334,  ...,  0.0311,  0.0319, -0.0054],
        [ 0.0185,  0.0108,  0.0118,  ...,  0.0023, -0.0246,  0.0214],
        [-0.0263, -0.0055,  0.0169,  ..., -0.0106,  0.0546, -0.0242],
        ...,
        [ 0.0146, -0.0203, -0.0192,  ...,  0.0176, -0.0095, -0.0034],
        [ 0.0059, -0.0240, -0.0200,  ..., -0.0100, -0.0106, -0.0184],
        [ 0.0211, -0.0241, -0.0149,  ..., -0.0229, -0.0193,  0.0111]],
       dtype=torch.float16), 'model.layers.27.self_attn.o_proj.weight': tensor([[ 0.0038, -0.0119,  0.0095,  ...,  0.0242,  0.0067, -0.0269],
        [ 0.0054,  0.0286, -0.0241,  ..., -0.0172, -0.0162,  0.0058],
        [-0.0047, -0.0113, -0.0132,  ...,  0.0162,  0.0009, -0.0092],
        ...,
        [ 0.0251, -0.0114, -0.0128,  ...,  0.0111,  0.0484, -0.0008],
        [ 0.0368, -0.0221, -0.0091,  ..., -0.0011, -0.0006,  0.0184],
        [ 0.0446,  0.0125,  0.0281,  ..., -0.0113, -0.0002, -0.0220]],
       dtype=torch.float16), 'model.layers.27.mlp.gate_proj.weight': tensor([[ 0.0450,  0.0128, -0.0067,  ...,  0.0097,  0.0032, -0.0147],
        [-0.0158,  0.0018, -0.0322,  ...,  0.0303,  0.0333,  0.0226],
        [ 0.0075,  0.0203, -0.0080,  ..., -0.0125, -0.0238,  0.0320],
        ...,
        [ 0.0358,  0.0211,  0.0024,  ..., -0.0008,  0.0165, -0.0047],
        [-0.0144,  0.0255, -0.0209,  ..., -0.0090, -0.0178,  0.0073],
        [ 0.0026, -0.0184, -0.0149,  ..., -0.0166, -0.0047, -0.0048]],
       dtype=torch.float16), 'model.layers.27.mlp.up_proj.weight': tensor([[-0.0049,  0.0078,  0.0265,  ..., -0.0012,  0.0131, -0.0389],
        [-0.0102,  0.0028, -0.0278,  ...,  0.0119, -0.0223, -0.0237],
        [ 0.0258,  0.0162,  0.0435,  ...,  0.0278,  0.0015, -0.0196],
        ...,
        [-0.0044,  0.0250,  0.0330,  ..., -0.0218,  0.0206, -0.0381],
        [ 0.0097,  0.0212,  0.0149,  ...,  0.0130, -0.0131, -0.0248],
        [-0.0111,  0.0048, -0.0053,  ..., -0.0063, -0.0244, -0.0093]],
       dtype=torch.float16), 'model.layers.27.mlp.down_proj.weight': tensor([[ 2.4376e-03, -2.2705e-02,  3.4363e-02,  ..., -1.9394e-02,
          1.9669e-02, -1.1414e-02],
        [ 8.0466e-05,  1.3931e-02, -9.4910e-03,  ..., -1.9272e-02,
         -3.1616e-02,  1.2093e-02],
        [ 4.6478e-02,  1.3847e-02,  5.7602e-03,  ..., -3.2166e-02,
          4.1733e-03,  2.9587e-02],
        ...,
        [-7.6523e-03,  1.0971e-02,  1.5335e-02,  ...,  7.5302e-03,
         -4.5685e-02,  2.5742e-02],
        [-2.2018e-02, -3.3932e-03, -1.7227e-02,  ...,  2.2934e-02,
         -9.0866e-03,  2.0813e-02],
        [ 4.7493e-03,  1.7471e-02, -9.1858e-03,  ...,  1.9531e-02,
         -2.3441e-03, -4.7493e-03]], dtype=torch.float16), 'model.layers.27.input_layernorm.weight': tensor([0.5625, 0.5625, 0.5586,  ..., 0.5547, 0.5625, 0.5703],
       dtype=torch.float16), 'model.layers.27.post_attention_layernorm.weight': tensor([0.4688, 0.4629, 0.4531,  ..., 0.4668, 0.4707, 0.4688],
       dtype=torch.float16), 'model.layers.28.self_attn.q_proj.weight': tensor([[-3.2127e-05, -1.9119e-02, -7.1669e-04,  ..., -1.4694e-02,
         -9.0561e-03, -1.0872e-02],
        [ 1.1421e-02, -1.8387e-02, -2.4986e-03,  ...,  1.3634e-02,
          5.4283e-03, -3.9635e-03],
        [ 1.4305e-02,  6.4993e-04, -1.0948e-02,  ..., -3.7956e-03,
         -2.4414e-02,  2.4261e-02],
        ...,
        [-1.1253e-02,  2.4719e-02, -5.3101e-02,  ...,  1.6006e-02,
         -7.5684e-03, -3.9825e-02],
        [ 1.6541e-02, -2.6855e-02, -1.2665e-02,  ...,  2.0569e-02,
          3.2928e-02, -6.5002e-02],
        [ 1.9409e-02,  1.4633e-02, -4.5654e-02,  ...,  4.5868e-02,
          1.4122e-02, -3.6987e-02]], dtype=torch.float16), 'model.layers.28.self_attn.k_proj.weight': tensor([[-0.0036, -0.0034,  0.0078,  ..., -0.0043,  0.0148, -0.0134],
        [-0.0133, -0.0068, -0.0168,  ..., -0.0066,  0.0050,  0.0043],
        [ 0.0061,  0.0063, -0.0146,  ..., -0.0197, -0.0112,  0.0050],
        ...,
        [-0.0251, -0.0133, -0.0040,  ..., -0.0014, -0.0604, -0.0040],
        [ 0.0462, -0.0221,  0.0039,  ...,  0.0161,  0.0397,  0.0285],
        [ 0.0180, -0.0042,  0.0045,  ..., -0.0038, -0.0185, -0.0136]],
       dtype=torch.float16), 'model.layers.28.self_attn.v_proj.weight': tensor([[-0.0240,  0.0090,  0.0227,  ..., -0.0210, -0.0288,  0.0260],
        [ 0.0231, -0.0178, -0.0135,  ..., -0.0447,  0.0313, -0.0163],
        [-0.0102,  0.0174, -0.0021,  ...,  0.0075, -0.0479,  0.0167],
        ...,
        [ 0.0193,  0.0043, -0.0005,  ...,  0.0143, -0.0064, -0.0217],
        [ 0.0511,  0.0041,  0.0421,  ...,  0.0019,  0.0046, -0.0031],
        [ 0.0181,  0.0192, -0.0485,  ...,  0.0328, -0.0048,  0.0090]],
       dtype=torch.float16), 'model.layers.28.self_attn.o_proj.weight': tensor([[ 1.1208e-02,  2.4567e-02, -4.1473e-02,  ..., -3.4485e-02,
          1.7929e-02, -9.8646e-05],
        [-1.2238e-02, -2.0905e-02, -2.8381e-03,  ..., -1.7075e-02,
          2.7145e-02,  3.2501e-02],
        [ 2.7863e-02,  1.7838e-02, -5.3741e-02,  ...,  2.2293e-02,
          1.5701e-02, -1.6464e-02],
        ...,
        [ 2.5444e-03, -4.4098e-03,  3.4332e-02,  ..., -9.8801e-03,
         -3.9917e-02, -6.6757e-03],
        [-7.5188e-03, -5.8655e-02, -1.8112e-02,  ...,  2.0889e-02,
         -2.8183e-02, -2.7084e-02],
        [-4.3823e-02, -4.1618e-03, -1.0742e-02,  ..., -1.9196e-02,
         -8.0719e-03,  4.2839e-03]], dtype=torch.float16), 'model.layers.28.mlp.gate_proj.weight': tensor([[-0.0007,  0.0031, -0.0068,  ...,  0.0274, -0.0111,  0.0312],
        [-0.0257,  0.0139, -0.0106,  ...,  0.0121,  0.0034,  0.0177],
        [ 0.0099,  0.0288,  0.0274,  ...,  0.0168,  0.0038,  0.0067],
        ...,
        [-0.0053,  0.0228,  0.0102,  ...,  0.0135,  0.0128, -0.0202],
        [ 0.0124, -0.0344, -0.0104,  ..., -0.0197, -0.0044, -0.0032],
        [-0.0318,  0.0149,  0.0106,  ..., -0.0078, -0.0112,  0.0179]],
       dtype=torch.float16), 'model.layers.28.mlp.up_proj.weight': tensor([[ 0.0224,  0.0047,  0.0220,  ...,  0.0277,  0.0156,  0.0114],
        [-0.0177, -0.0260, -0.0041,  ..., -0.0033, -0.0355, -0.0220],
        [ 0.0064,  0.0259, -0.0073,  ...,  0.0068,  0.0073, -0.0160],
        ...,
        [-0.0055, -0.0151,  0.0324,  ..., -0.0026,  0.0111, -0.0013],
        [-0.0215,  0.0078, -0.0074,  ...,  0.0127, -0.0099, -0.0497],
        [-0.0093, -0.0252, -0.0048,  ..., -0.0067,  0.0076,  0.0080]],
       dtype=torch.float16), 'model.layers.28.mlp.down_proj.weight': tensor([[ 0.0077,  0.0342, -0.0055,  ...,  0.0029, -0.0016, -0.0298],
        [-0.0009, -0.0338,  0.0198,  ..., -0.0268, -0.0070, -0.0280],
        [-0.0241,  0.0253, -0.0140,  ...,  0.0032,  0.0074, -0.0012],
        ...,
        [ 0.0106, -0.0143, -0.0053,  ..., -0.0309, -0.0309,  0.0070],
        [-0.0170, -0.0194,  0.0628,  ..., -0.0242, -0.0061,  0.0128],
        [-0.0234,  0.0108, -0.0081,  ...,  0.0294,  0.0295, -0.0142]],
       dtype=torch.float16), 'model.layers.28.input_layernorm.weight': tensor([0.5781, 0.5859, 0.5664,  ..., 0.5547, 0.5742, 0.5742],
       dtype=torch.float16), 'model.layers.28.post_attention_layernorm.weight': tensor([0.4805, 0.4785, 0.4648,  ..., 0.4785, 0.4727, 0.4727],
       dtype=torch.float16), 'model.layers.29.self_attn.q_proj.weight': tensor([[ 0.0060,  0.0026, -0.0075,  ...,  0.0002, -0.0110,  0.0094],
        [-0.0288, -0.0180, -0.0257,  ..., -0.0128, -0.0063, -0.0059],
        [-0.0291,  0.0377, -0.0024,  ..., -0.0022, -0.0156,  0.0146],
        ...,
        [ 0.0005,  0.0704, -0.0331,  ...,  0.0133, -0.0080, -0.0352],
        [-0.0236, -0.0242,  0.0169,  ..., -0.0142, -0.0230,  0.0260],
        [ 0.0005, -0.0416, -0.0127,  ...,  0.0132,  0.0065, -0.0391]],
       dtype=torch.float16), 'model.layers.29.self_attn.k_proj.weight': tensor([[ 0.0357, -0.0135, -0.0162,  ...,  0.0005,  0.0101, -0.0023],
        [-0.0177,  0.0316, -0.0048,  ..., -0.0086,  0.0006, -0.0218],
        [ 0.0214,  0.0079,  0.0186,  ...,  0.0193,  0.0339, -0.0014],
        ...,
        [-0.0317,  0.0448,  0.0010,  ..., -0.0091,  0.0024, -0.0117],
        [ 0.0014, -0.0123, -0.0701,  ..., -0.0106, -0.0095, -0.0427],
        [ 0.0107, -0.0124, -0.0583,  ..., -0.0584, -0.0144,  0.0027]],
       dtype=torch.float16), 'model.layers.29.self_attn.v_proj.weight': tensor([[ 0.0110,  0.0064,  0.0324,  ...,  0.0194,  0.0085,  0.0135],
        [-0.0017,  0.0247,  0.0385,  ..., -0.0199,  0.0092, -0.0022],
        [-0.0130,  0.0104, -0.0103,  ...,  0.0083,  0.0268,  0.0188],
        ...,
        [ 0.0067,  0.0294,  0.0116,  ..., -0.0203, -0.0125, -0.0172],
        [ 0.0001,  0.0276, -0.0236,  ...,  0.0186,  0.0294, -0.0053],
        [-0.0033, -0.0211,  0.0092,  ..., -0.0019, -0.0083,  0.0262]],
       dtype=torch.float16), 'model.layers.29.self_attn.o_proj.weight': tensor([[-6.3057e-03,  3.2288e-02,  3.3630e-02,  ...,  5.8222e-04,
         -1.7517e-02, -6.4850e-03],
        [-2.0340e-02, -2.5772e-02, -1.2833e-02,  ...,  1.2199e-02,
         -2.8244e-02,  1.2634e-02],
        [ 2.6093e-02,  2.8381e-02, -8.5678e-03,  ..., -3.7781e-02,
          1.7441e-02, -2.1240e-02],
        ...,
        [-2.8381e-02, -1.6617e-02,  2.8061e-02,  ..., -7.0839e-03,
         -7.8201e-03, -1.4076e-02],
        [-1.3969e-02, -1.0399e-02,  3.3966e-02,  ..., -4.7803e-05,
         -2.0554e-02,  4.7226e-03],
        [ 1.5411e-02,  3.9749e-03, -3.4275e-03,  ...,  4.1122e-03,
          1.9104e-02, -2.8473e-02]], dtype=torch.float16), 'model.layers.29.mlp.gate_proj.weight': tensor([[ 0.0161,  0.0169, -0.0145,  ..., -0.0036, -0.0243,  0.0359],
        [ 0.0034,  0.0243, -0.0081,  ..., -0.0228,  0.0151,  0.0046],
        [ 0.0371, -0.0013, -0.0085,  ..., -0.0063,  0.0206,  0.0335],
        ...,
        [-0.0048,  0.0104, -0.0152,  ...,  0.0026,  0.0065,  0.0039],
        [ 0.0079,  0.0031, -0.0292,  ..., -0.0222, -0.0051,  0.0174],
        [-0.0031,  0.0190, -0.0012,  ...,  0.0228, -0.0130, -0.0158]],
       dtype=torch.float16), 'model.layers.29.mlp.up_proj.weight': tensor([[-0.0069,  0.0021,  0.0118,  ...,  0.0150,  0.0049,  0.0057],
        [ 0.0012,  0.0072,  0.0320,  ...,  0.0089, -0.0199,  0.0363],
        [-0.0076, -0.0212, -0.0125,  ..., -0.0495,  0.0085, -0.0360],
        ...,
        [ 0.0260,  0.0129,  0.0126,  ...,  0.0124,  0.0245,  0.0357],
        [-0.0250, -0.0191, -0.0051,  ...,  0.0142,  0.0133,  0.0017],
        [ 0.0065, -0.0030,  0.0111,  ..., -0.0080,  0.0094,  0.0100]],
       dtype=torch.float16), 'model.layers.29.mlp.down_proj.weight': tensor([[ 0.0411,  0.0098, -0.0018,  ...,  0.0168, -0.0244, -0.0152],
        [ 0.0184,  0.0098,  0.0223,  ...,  0.0344,  0.0027,  0.0017],
        [ 0.0008, -0.0209, -0.0160,  ..., -0.0007,  0.0110, -0.0271],
        ...,
        [ 0.0088, -0.0090,  0.0057,  ..., -0.0189, -0.0051, -0.0197],
        [ 0.0228,  0.0159,  0.0265,  ...,  0.0094, -0.0411,  0.0024],
        [ 0.0148, -0.0185, -0.0088,  ..., -0.0158, -0.0135,  0.0045]],
       dtype=torch.float16), 'model.layers.29.input_layernorm.weight': tensor([0.5430, 0.5586, 0.5391,  ..., 0.5312, 0.5586, 0.5625],
       dtype=torch.float16), 'model.layers.29.post_attention_layernorm.weight': tensor([0.4902, 0.4922, 0.4785,  ..., 0.4785, 0.4922, 0.4805],
       dtype=torch.float16), 'model.layers.30.self_attn.q_proj.weight': tensor([[-0.0041, -0.0047,  0.0075,  ..., -0.0091, -0.0045,  0.0028],
        [ 0.0163,  0.0142,  0.0050,  ..., -0.0033, -0.0027, -0.0191],
        [-0.0086, -0.0204,  0.0428,  ...,  0.0224,  0.0053, -0.0305],
        ...,
        [-0.0093, -0.0009, -0.0012,  ...,  0.0209, -0.0119,  0.0017],
        [-0.0005, -0.0218, -0.0206,  ...,  0.0153,  0.0086, -0.0354],
        [-0.0708, -0.0093,  0.0420,  ..., -0.0094, -0.0046, -0.0015]],
       dtype=torch.float16), 'model.layers.30.self_attn.k_proj.weight': tensor([[ 0.0262, -0.0208,  0.0015,  ..., -0.0112,  0.0095,  0.0076],
        [ 0.0337,  0.0127,  0.0035,  ..., -0.0041, -0.0045,  0.0022],
        [-0.0044, -0.0148,  0.0216,  ...,  0.0055, -0.0088, -0.0004],
        ...,
        [ 0.0057,  0.0255,  0.0007,  ...,  0.0564, -0.0037, -0.0002],
        [ 0.0107, -0.0630,  0.0325,  ...,  0.0062, -0.0082, -0.0273],
        [-0.0373, -0.0082,  0.0209,  ...,  0.0079,  0.0169, -0.0247]],
       dtype=torch.float16), 'model.layers.30.self_attn.v_proj.weight': tensor([[-0.0035, -0.0291,  0.0310,  ..., -0.0268, -0.0363,  0.0307],
        [ 0.0073,  0.0172,  0.0300,  ..., -0.0118,  0.0262,  0.0019],
        [-0.0203,  0.0174, -0.0189,  ...,  0.0050, -0.0255, -0.0103],
        ...,
        [ 0.0184, -0.0039, -0.0030,  ..., -0.0245,  0.0030,  0.0241],
        [-0.0072, -0.0434,  0.0219,  ...,  0.0296, -0.0089,  0.0216],
        [-0.0088,  0.0059,  0.0193,  ..., -0.0144, -0.0613, -0.0227]],
       dtype=torch.float16), 'model.layers.30.self_attn.o_proj.weight': tensor([[-0.0074,  0.0176, -0.0070,  ...,  0.0119, -0.0119, -0.0202],
        [-0.0116, -0.0252, -0.0082,  ...,  0.0136, -0.0305, -0.0236],
        [-0.0294, -0.0029,  0.0179,  ..., -0.0482, -0.0128, -0.0113],
        ...,
        [ 0.0068,  0.0052,  0.0028,  ..., -0.0247,  0.0106,  0.0177],
        [ 0.0227, -0.0089,  0.0036,  ...,  0.0353, -0.0069,  0.0047],
        [-0.0028,  0.0133, -0.0032,  ..., -0.0048,  0.0101, -0.0147]],
       dtype=torch.float16), 'model.layers.30.mlp.gate_proj.weight': tensor([[-0.0422, -0.0289, -0.0057,  ...,  0.0138, -0.0067, -0.0003],
        [-0.0175,  0.0047,  0.0389,  ..., -0.0063, -0.0058,  0.0305],
        [-0.0219, -0.0067, -0.0307,  ...,  0.0154, -0.0004, -0.0035],
        ...,
        [-0.0204, -0.0261,  0.0121,  ..., -0.0081, -0.0219, -0.0244],
        [ 0.0268,  0.0282, -0.0097,  ...,  0.0118, -0.0396, -0.0025],
        [-0.0012, -0.0307, -0.0203,  ..., -0.0023,  0.0182, -0.0061]],
       dtype=torch.float16), 'model.layers.30.mlp.up_proj.weight': tensor([[ 0.0034,  0.0162,  0.0123,  ...,  0.0126,  0.0213, -0.0029],
        [-0.0196, -0.0118,  0.0388,  ...,  0.0008, -0.0193, -0.0033],
        [-0.0327, -0.0235, -0.0368,  ..., -0.0176,  0.0011,  0.0209],
        ...,
        [-0.0163, -0.0128,  0.0153,  ...,  0.0128, -0.0097, -0.0216],
        [-0.0081,  0.0077, -0.0097,  ...,  0.0053, -0.0229,  0.0164],
        [-0.0030, -0.0283,  0.0003,  ..., -0.0168,  0.0070,  0.0171]],
       dtype=torch.float16), 'model.layers.30.mlp.down_proj.weight': tensor([[ 2.2812e-02, -1.3634e-02, -3.0258e-02,  ...,  3.1342e-02,
         -7.2098e-03, -8.8263e-04],
        [ 2.5818e-02,  4.8409e-03,  4.3427e-02,  ...,  1.2611e-02,
          1.6594e-03, -7.8888e-03],
        [ 3.6883e-04, -3.0899e-03, -2.1591e-02,  ...,  3.1242e-03,
          1.0376e-02,  2.0767e-02],
        ...,
        [-3.1921e-02,  6.3400e-03, -2.4643e-02,  ...,  1.8341e-02,
         -2.4780e-02, -9.6664e-03],
        [-4.3750e-05, -1.9287e-02,  2.8934e-03,  ...,  1.9730e-02,
          2.3232e-03,  1.2312e-03],
        [-8.7738e-03, -1.4030e-02, -2.5955e-02,  ...,  1.0109e-02,
          3.0589e-04, -1.9150e-02]], dtype=torch.float16), 'model.layers.30.input_layernorm.weight': tensor([0.5859, 0.6016, 0.5664,  ..., 0.5586, 0.5781, 0.6016],
       dtype=torch.float16), 'model.layers.30.post_attention_layernorm.weight': tensor([0.4824, 0.5039, 0.4824,  ..., 0.4883, 0.4980, 0.4863],
       dtype=torch.float16), 'model.layers.31.self_attn.q_proj.weight': tensor([[-0.0350,  0.0179,  0.0228,  ...,  0.0133, -0.0005, -0.0199],
        [-0.0200, -0.0252, -0.0369,  ...,  0.0008, -0.0122, -0.0238],
        [-0.0219,  0.0272,  0.0192,  ..., -0.0004,  0.0037,  0.0022],
        ...,
        [ 0.0171, -0.0177, -0.0151,  ..., -0.0145,  0.0273, -0.0253],
        [-0.0265,  0.0056, -0.0053,  ..., -0.0029,  0.0124,  0.0107],
        [-0.0533, -0.0123,  0.0282,  ...,  0.0389, -0.0044,  0.0329]],
       dtype=torch.float16), 'model.layers.31.self_attn.k_proj.weight': tensor([[-0.0058, -0.0082,  0.0132,  ..., -0.0011, -0.0107, -0.0206],
        [ 0.0245, -0.0202,  0.0109,  ..., -0.0002,  0.0066, -0.0021],
        [ 0.0027,  0.0117, -0.0064,  ...,  0.0055, -0.0005, -0.0275],
        ...,
        [ 0.0315, -0.0261, -0.0244,  ..., -0.0081, -0.0101, -0.0515],
        [ 0.0134,  0.0200,  0.0124,  ..., -0.0259, -0.0236,  0.0204],
        [-0.0787, -0.0352,  0.0162,  ..., -0.0131,  0.0023, -0.0065]],
       dtype=torch.float16), 'model.layers.31.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0230, -0.0018,  ...,  0.0031,  0.0012,  0.0155],
        [ 0.0281,  0.0153,  0.0112,  ...,  0.0094,  0.0336,  0.0164],
        [ 0.0143, -0.0011, -0.0159,  ...,  0.0129,  0.0024,  0.0344],
        ...,
        [-0.0017, -0.0013, -0.0144,  ..., -0.0160, -0.0032,  0.0248],
        [ 0.0126, -0.0183,  0.0156,  ..., -0.0102, -0.0292,  0.0144],
        [-0.0103, -0.0228,  0.0264,  ...,  0.0243, -0.0042,  0.0403]],
       dtype=torch.float16), 'model.layers.31.self_attn.o_proj.weight': tensor([[ 0.0089,  0.0304, -0.0052,  ..., -0.0004, -0.0148, -0.0504],
        [-0.0065,  0.0034, -0.0314,  ...,  0.0269, -0.0200, -0.0146],
        [ 0.0102,  0.0023,  0.0032,  ..., -0.0174,  0.0214,  0.0120],
        ...,
        [ 0.0077, -0.0209,  0.0315,  ..., -0.0161, -0.0128, -0.0216],
        [ 0.0010,  0.0138, -0.0207,  ..., -0.0174, -0.0141, -0.0177],
        [ 0.0062,  0.0165, -0.0088,  ...,  0.0295, -0.0164,  0.0075]],
       dtype=torch.float16), 'model.layers.31.mlp.gate_proj.weight': tensor([[ 0.0088, -0.0101,  0.0378,  ...,  0.0157,  0.0179,  0.0108],
        [-0.0751, -0.0179,  0.0038,  ...,  0.0049, -0.0193,  0.0181],
        [ 0.0142,  0.0066, -0.0107,  ..., -0.0041, -0.0197, -0.0075],
        ...,
        [-0.0168, -0.0297,  0.0126,  ..., -0.0009,  0.0242,  0.0329],
        [ 0.0417,  0.0298, -0.0222,  ...,  0.0354, -0.0096, -0.0061],
        [ 0.0174, -0.0382, -0.0287,  ..., -0.0177,  0.0085,  0.0057]],
       dtype=torch.float16), 'model.layers.31.mlp.up_proj.weight': tensor([[-0.0397, -0.0182,  0.0206,  ...,  0.0010, -0.0187,  0.0024],
        [ 0.0275,  0.0354,  0.0046,  ..., -0.0228,  0.0012, -0.0013],
        [-0.0043,  0.0044, -0.0210,  ...,  0.0143,  0.0034, -0.0117],
        ...,
        [ 0.0134, -0.0182,  0.0072,  ...,  0.0026,  0.0326, -0.0186],
        [ 0.0055,  0.0044, -0.0258,  ...,  0.0280,  0.0101, -0.0022],
        [ 0.0409, -0.0411, -0.0085,  ..., -0.0104,  0.0099,  0.0237]],
       dtype=torch.float16), 'model.layers.31.mlp.down_proj.weight': tensor([[-1.2767e-04, -2.5101e-02, -9.8572e-03,  ..., -3.8147e-02,
         -1.4954e-02,  2.7756e-02],
        [ 3.8208e-02,  3.5248e-03, -3.6736e-03,  ..., -5.2691e-04,
         -1.6205e-02,  1.3901e-02],
        [-1.2566e-02, -1.2192e-02,  2.5131e-02,  ...,  3.0304e-02,
         -1.5383e-03,  2.3193e-02],
        ...,
        [ 4.7088e-05,  2.8351e-02, -2.0237e-03,  ...,  1.1597e-02,
          5.3177e-03,  1.7136e-02],
        [-9.8515e-04,  4.7424e-02, -5.3787e-03,  ..., -7.3509e-03,
          2.3331e-02,  1.7090e-02],
        [ 2.6001e-02, -3.8910e-02,  1.8829e-02,  ...,  4.1313e-03,
          1.2999e-03,  2.6016e-02]], dtype=torch.float16), 'model.layers.31.input_layernorm.weight': tensor([0.4961, 0.4980, 0.4453,  ..., 0.4375, 0.4727, 0.4922],
       dtype=torch.float16), 'model.layers.31.post_attention_layernorm.weight': tensor([0.4414, 0.4434, 0.4531,  ..., 0.4336, 0.4219, 0.4375],
       dtype=torch.float16), 'model.norm.weight': tensor([2.0000, 2.0469, 1.9453,  ..., 1.8594, 1.9453, 1.7656],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding': tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight': tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,
            2.1957e-02,  5.0011e-03],
          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,
            7.5417e-03, -1.2230e-02],
          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,
            5.3940e-03, -1.2283e-02],
          ...,
          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,
           -2.3239e-02, -2.4017e-02],
          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,
            1.5745e-03, -4.1771e-03],
          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,
            4.0169e-03, -6.7177e-03]],

         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,
            2.4185e-02,  5.8136e-03],
          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,
            5.4970e-03, -1.4351e-02],
          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,
            5.5618e-03, -1.2390e-02],
          ...,
          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,
            3.9816e-04, -5.1346e-03],
          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,
            2.2552e-02,  1.2917e-02],
          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,
            1.8158e-02,  9.2745e-04]],

         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,
            1.1757e-02,  5.7259e-03],
          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,
           -4.2191e-03, -7.1831e-03],
          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,
            1.3041e-04, -7.3051e-03],
          ...,
          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,
           -9.8267e-03, -6.7825e-03],
          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,
            6.3400e-03,  5.3177e-03],
          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,
            6.5193e-03,  2.9850e-04]]],


        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,
           -8.4381e-03,  2.0447e-02],
          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,
            3.5906e-04,  1.5945e-02],
          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,
           -2.7924e-02, -3.2177e-03],
          ...,
          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,
           -5.4741e-03, -5.9624e-03],
          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,
           -2.7969e-02, -1.8875e-02],
          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,
            7.1335e-03,  4.6478e-02]],

         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,
           -1.1604e-02,  1.7593e-02],
          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,
            3.4976e-04,  1.4732e-02],
          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,
           -3.2684e-02, -7.0076e-03],
          ...,
          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,
           -1.1253e-02, -9.8648e-03],
          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,
           -3.7231e-02, -2.6505e-02],
          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,
           -4.2000e-03,  3.9368e-02]],

         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,
           -1.2558e-02,  1.7303e-02],
          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,
            4.3440e-04,  1.5656e-02],
          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,
           -2.9968e-02, -6.5422e-03],
          ...,
          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,
           -8.7967e-03, -8.7662e-03],
          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,
           -3.0518e-02, -2.4918e-02],
          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,
           -7.3242e-04,  3.8818e-02]]],


        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,
            1.4229e-02,  1.8768e-02],
          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,
            5.4283e-03,  6.6032e-03],
          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,
            2.5959e-03,  6.8703e-03],
          ...,
          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,
            1.4397e-02,  1.2421e-02],
          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,
            2.2766e-02,  2.2659e-02],
          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,
            2.2263e-02,  2.5238e-02]],

         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,
            1.9653e-02,  2.8290e-02],
          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,
            6.0501e-03,  1.2810e-02],
          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,
           -5.9271e-04,  8.8959e-03],
          ...,
          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,
            2.4902e-02,  2.6871e-02],
          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,
            3.3569e-02,  3.9612e-02],
          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,
            3.9276e-02,  4.6051e-02]],

         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,
            2.1042e-02,  2.9053e-02],
          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,
            7.7019e-03,  1.2169e-02],
          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,
            3.3913e-03,  9.0408e-03],
          ...,
          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,
            8.0795e-03,  1.4221e-02],
          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,
            1.1887e-02,  1.8204e-02],
          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,
            1.5701e-02,  2.2247e-02]]],


        ...,


        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,
            3.1686e-04, -3.0446e-04],
          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,
           -2.2995e-04, -1.6510e-04],
          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,
           -5.0831e-04,  5.9748e-04],
          ...,
          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,
           -9.3746e-04, -6.7472e-04],
          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,
           -1.4048e-03, -1.3056e-03],
          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,
            3.2640e-04,  1.7679e-04]],

         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,
            1.0500e-03, -5.0831e-04],
          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,
            1.0071e-03, -4.9925e-04],
          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,
            8.0919e-04,  9.7132e-04],
          ...,
          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,
            6.2895e-04,  4.0889e-04],
          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,
           -2.8610e-04,  1.9038e-04],
          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,
            1.4138e-04,  4.2319e-04]],

         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,
           -4.3130e-04, -5.6791e-04],
          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,
            1.9002e-04,  1.8311e-04],
          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,
            2.3186e-05, -5.7578e-05],
          ...,
          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,
            1.3471e-04,  6.5708e-04],
          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,
            1.0538e-04, -4.9019e-04],
          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,
           -4.1580e-04,  5.5599e-04]]],


        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,
            6.1874e-03,  2.6535e-02],
          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,
           -1.7639e-02, -3.2768e-03],
          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,
           -2.7237e-02, -5.5046e-03],
          ...,
          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,
            2.8503e-02,  3.6499e-02],
          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,
           -2.3010e-02,  5.0926e-03],
          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,
           -3.9276e-02,  1.3908e-02]],

         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,
            2.8896e-03,  2.2415e-02],
          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,
           -1.8616e-02, -6.5308e-03],
          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,
           -3.0472e-02, -9.3613e-03],
          ...,
          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,
            2.6001e-02,  3.4241e-02],
          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,
           -3.0487e-02, -9.5701e-04],
          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,
           -5.1422e-02,  4.2267e-03]],

         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,
           -2.1572e-03,  1.6891e-02],
          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,
           -2.1347e-02, -9.2316e-03],
          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,
           -2.9694e-02, -1.2733e-02],
          ...,
          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,
            1.9257e-02,  2.4582e-02],
          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,
           -3.1281e-02, -9.1248e-03],
          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,
           -5.2246e-02, -2.8057e-03]]],


        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,
            8.1863e-03, -4.8248e-02],
          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,
            9.3689e-03, -3.8544e-02],
          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,
            2.3956e-02, -1.1154e-02],
          ...,
          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,
           -1.8654e-03, -1.9440e-02],
          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,
            8.4381e-03,  1.4282e-02],
          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,
            1.6689e-03,  1.6891e-02]],

         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,
            1.5839e-02, -4.3243e-02],
          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,
            1.8433e-02, -3.1799e-02],
          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,
            2.9694e-02, -5.4817e-03],
          ...,
          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,
           -1.5268e-03, -1.4626e-02],
          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,
            8.5602e-03,  2.0035e-02],
          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,
           -2.3785e-03,  1.9150e-02]],

         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,
            2.1317e-02, -3.0197e-02],
          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,
            2.4658e-02, -1.7670e-02],
          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,
            3.4302e-02,  4.5395e-03],
          ...,
          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,
            4.1656e-03, -5.9814e-03],
          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,
            1.6068e-02,  2.5879e-02],
          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,
            2.2964e-03,  2.2339e-02]]]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight': tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],
        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],
        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],
        ...,
        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],
        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],
        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight': tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias': tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight': tensor([[-1.1724e-04,  8.3399e-04, -1.5700e-04,  ..., -4.8332e-03,
          1.3428e-02,  3.2604e-05],
        [-4.4703e-05, -9.5272e-04,  1.2279e-04,  ...,  1.9855e-03,
         -1.3626e-02, -4.1783e-05],
        [ 6.6280e-04,  1.0419e-04,  9.0420e-05,  ..., -2.1820e-02,
          4.1199e-03,  3.2187e-06],
        ...,
        [-5.2512e-05, -2.9278e-04, -3.6895e-05,  ...,  8.8196e-03,
         -4.2796e-04, -3.0100e-05],
        [ 7.5936e-05, -6.5148e-05, -9.0182e-05,  ...,  8.1682e-04,
         -6.0844e-03,  1.9014e-05],
        [-6.3896e-05,  9.8705e-05,  4.9829e-05,  ..., -1.2579e-03,
         -7.1793e-03,  2.3961e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias': tensor([ 0.0577, -0.0588, -0.0266,  ..., -0.0147, -0.0175,  0.0096],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight': tensor([[ 2.4986e-04, -1.5283e-04, -5.8556e-04,  ...,  3.3607e-03,
         -9.5901e-03,  5.5373e-05],
        [-3.4356e-04, -1.5092e-04,  5.2691e-05,  ...,  2.5725e-04,
          1.0010e-02, -6.2883e-05],
        [ 6.7472e-04, -9.6798e-05,  2.5392e-04,  ..., -1.0386e-03,
         -1.9531e-02, -1.2141e-04],
        ...,
        [ 2.9850e-04,  4.0436e-04, -9.7811e-05,  ...,  4.6654e-03,
         -2.2392e-03, -6.6221e-05],
        [ 3.2973e-04, -3.2961e-05, -2.1207e-04,  ...,  1.1917e-02,
          3.4637e-03,  6.9439e-05],
        [ 2.1458e-06,  4.7874e-04,  4.8459e-05,  ..., -1.1612e-02,
          2.6779e-03, -8.3089e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias': tensor([-0.0277,  0.0222, -0.0355,  ...,  0.0123,  0.0105, -0.0041],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight': tensor([[-2.6703e-05, -1.3638e-04, -8.3923e-05,  ...,  4.2152e-03,
         -2.7649e-02, -7.5042e-05],
        [-1.6391e-04,  9.0241e-05,  5.4836e-05,  ..., -1.5821e-03,
          2.9831e-02,  7.0333e-05],
        [ 4.7588e-04,  7.6008e-04, -1.0198e-04,  ..., -1.7090e-02,
          4.1809e-02,  1.5020e-04],
        ...,
        [ 6.9141e-05,  7.0274e-05,  8.6784e-05,  ..., -4.3411e-03,
          1.1421e-02, -3.8803e-05],
        [-1.8144e-04,  1.4305e-06, -2.5940e-04,  ...,  1.5802e-03,
         -1.8799e-04,  1.6689e-05],
        [-1.2624e-04,  9.4473e-05,  5.3406e-05,  ..., -1.4961e-02,
         -5.8937e-04,  4.2021e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias': tensor([ 1.5693, -1.6172, -0.8213,  ..., -1.2852, -0.0976,  0.7852],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight': tensor([[-0.0073,  0.0083, -0.0076,  ..., -0.0090, -0.0080,  0.0038],
        [ 0.0107,  0.0062,  0.0133,  ..., -0.0036,  0.0022,  0.0034],
        [-0.0065,  0.0033,  0.0139,  ...,  0.0069,  0.0004, -0.0009],
        ...,
        [-0.0002, -0.0035, -0.0027,  ..., -0.0046, -0.0187,  0.0087],
        [-0.0093,  0.0047, -0.0083,  ...,  0.0006, -0.0013, -0.0006],
        [ 0.0092,  0.0003,  0.0016,  ...,  0.0016, -0.0045,  0.0045]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias': tensor([-0.0263, -0.0654,  0.0031,  ...,  0.1759, -0.0438,  0.0020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight': tensor([8.3113e-04, 2.9087e-03, 1.1456e-04,  ..., 6.9092e-01, 3.5498e-01,
        2.4021e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias': tensor([ 6.9141e-06,  7.7629e-04, -8.8811e-05,  ..., -3.6816e-01,
         1.7981e-01, -1.0854e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight': tensor([[ 4.2367e-04, -2.1219e-05,  5.9605e-08,  ..., -5.6458e-03,
         -1.2026e-03, -6.4087e-04],
        [ 6.1340e-03,  1.3588e-02, -3.5858e-04,  ..., -3.5954e-03,
         -7.6485e-04,  6.7101e-03],
        [ 1.3552e-03,  1.2817e-03, -2.0266e-06,  ..., -2.8351e-02,
         -1.2054e-03,  1.4830e-03],
        ...,
        [-2.4002e-02, -1.0193e-02,  2.1684e-04,  ..., -2.5864e-03,
         -1.1841e-02,  5.9166e-03],
        [ 4.1008e-04,  4.2856e-05, -1.1921e-07,  ..., -5.0697e-03,
         -7.7248e-04, -6.3896e-04],
        [-6.3753e-04, -2.3392e-02, -2.6226e-04,  ..., -4.2801e-03,
          2.7962e-03, -8.1863e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias': tensor([-0.6826, -0.3130, -0.8076,  ..., -0.2166, -0.6538, -0.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight': tensor([[-0.0037, -0.0032,  0.0043,  ...,  0.0117, -0.0042, -0.0073],
        [ 0.0017,  0.0183, -0.0100,  ..., -0.0255,  0.0024,  0.0209],
        [ 0.0033,  0.0024, -0.0029,  ...,  0.0037,  0.0032, -0.0154],
        ...,
        [ 0.0015, -0.0007, -0.0035,  ...,  0.0049,  0.0009,  0.0082],
        [-0.0060,  0.0064,  0.0067,  ..., -0.0009, -0.0061,  0.0016],
        [ 0.0007, -0.0034, -0.0020,  ..., -0.0091,  0.0009,  0.0035]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias': tensor([-0.0185, -0.1009,  0.0397,  ..., -0.0955, -0.1080, -0.0239],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight': tensor([2.8296e-01, 5.9082e-01, 1.0455e-04,  ..., 2.0195e+00, 7.7490e-01,
        2.9736e-01], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias': tensor([2.1988e-02, 2.1716e-01, 9.2089e-05,  ..., 2.6318e-01, 4.5020e-01,
        5.0903e-02], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight': tensor([[-3.9864e-03,  1.4374e-02, -2.8610e-03,  ...,  1.0399e-02,
         -2.8076e-02,  5.1155e-03],
        [ 8.1024e-03,  2.2583e-03,  1.1635e-02,  ..., -7.1716e-03,
         -7.5607e-03,  2.5375e-02],
        [ 9.5596e-03,  1.1284e-02, -3.6469e-03,  ..., -6.6757e-03,
         -1.2465e-03, -1.1475e-02],
        ...,
        [ 7.7188e-05, -1.6190e-02,  3.6583e-03,  ...,  2.1240e-02,
          4.3907e-03, -1.0063e-02],
        [ 1.5762e-02,  1.7273e-02, -3.3447e-02,  ..., -2.2507e-03,
         -1.2947e-02,  1.1726e-02],
        [-2.2697e-04,  1.2230e-02, -4.3411e-03,  ...,  3.3436e-03,
         -4.9973e-03,  5.5504e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias': tensor([-0.0012,  0.0081,  0.0097,  ...,  0.0535,  0.0071,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight': tensor([[ 0.0077,  0.0006,  0.0053,  ..., -0.0067,  0.0008,  0.0013],
        [ 0.0230, -0.0166, -0.0004,  ...,  0.0092, -0.0118, -0.0134],
        [-0.0103,  0.0013,  0.0111,  ..., -0.0549, -0.0047,  0.0056],
        ...,
        [ 0.0119,  0.0002, -0.0045,  ...,  0.0001,  0.0034, -0.0075],
        [-0.0129, -0.0114,  0.0075,  ..., -0.0030,  0.0044,  0.0061],
        [-0.0006, -0.0018,  0.0009,  ..., -0.0068, -0.0205, -0.0002]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias': tensor([ 0.0038, -0.0079, -0.1469,  ..., -0.0014, -0.0041,  0.0007],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight': tensor([[-2.4929e-03,  4.6706e-04, -1.8919e-04,  ...,  6.1684e-03,
         -2.4582e-02,  8.7051e-03],
        [ 6.5422e-03,  4.3602e-03,  1.5930e-02,  ..., -6.5994e-03,
          8.2169e-03,  6.1111e-03],
        [ 1.0727e-02, -9.2239e-03, -7.5698e-06,  ...,  3.7136e-03,
          1.6861e-02,  3.5305e-03],
        ...,
        [-2.3708e-03,  6.6452e-03,  5.9052e-03,  ..., -1.0399e-02,
          2.9945e-04, -9.6989e-04],
        [ 3.0609e-02,  1.3458e-02, -3.3386e-02,  ..., -1.3857e-03,
          3.5801e-03,  1.3245e-02],
        [-3.2291e-03,  4.7607e-03, -1.8759e-03,  ...,  6.1035e-04,
          4.9515e-03, -5.3520e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias': tensor([-0.1035,  0.8804,  1.4414,  ..., -2.2109, -0.1892,  0.0048],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight': tensor([[-0.0013, -0.0215,  0.0011,  ..., -0.0115,  0.0102, -0.0012],
        [-0.0010,  0.0065, -0.0018,  ..., -0.0036,  0.0112, -0.0025],
        [ 0.0015, -0.0069, -0.0120,  ..., -0.0047, -0.0009, -0.0056],
        ...,
        [ 0.0053, -0.0177,  0.0780,  ..., -0.0228, -0.0122,  0.0151],
        [-0.0086, -0.0019,  0.0054,  ...,  0.0081, -0.0049,  0.0067],
        [-0.0037,  0.0063, -0.0005,  ...,  0.0054,  0.0045, -0.0036]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias': tensor([-0.0204, -0.0210,  0.0255,  ..., -0.0381, -0.0211, -0.0043],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight': tensor([0.3650, 0.7476, 0.0972,  ..., 0.8521, 0.4248, 0.2639],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias': tensor([-0.0482, -0.1315,  0.0198,  ..., -0.1031, -0.0545,  0.0076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight': tensor([[ 0.0026,  0.0065,  0.0155,  ..., -0.0063,  0.0479, -0.0807],
        [ 0.0002, -0.0075,  0.0009,  ..., -0.0009, -0.0030,  0.0036],
        [ 0.0070, -0.0211,  0.0002,  ..., -0.0094,  0.0178, -0.0043],
        ...,
        [ 0.0026, -0.0113,  0.0019,  ..., -0.0057, -0.0008,  0.0038],
        [-0.0059,  0.0099,  0.0010,  ...,  0.0037, -0.0142, -0.0178],
        [ 0.0160,  0.0002,  0.0312,  ..., -0.0003, -0.0056, -0.0220]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias': tensor([-0.1216, -0.6841, -0.5278,  ..., -0.7573, -0.0995, -0.3076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight': tensor([[ 0.0008, -0.0008, -0.0176,  ..., -0.0029, -0.0098, -0.0047],
        [-0.0157,  0.0059,  0.0156,  ...,  0.0064, -0.0005, -0.0058],
        [ 0.0051, -0.0005,  0.0091,  ..., -0.0056, -0.0015,  0.0059],
        ...,
        [ 0.0030, -0.0024,  0.0040,  ...,  0.0014,  0.0002,  0.0047],
        [ 0.0007, -0.0015,  0.0031,  ..., -0.0015,  0.0046, -0.0055],
        [ 0.0299,  0.0036,  0.0020,  ...,  0.0047,  0.0134,  0.0043]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias': tensor([ 0.0244, -0.0645,  0.0788,  ..., -0.0807, -0.1028, -0.0836],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight': tensor([0.4128, 0.9854, 0.1910,  ..., 0.7715, 0.5596, 0.5142],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias': tensor([-0.0198, -0.1075, -0.0195,  ...,  0.0887,  0.1349,  0.0288],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight': tensor([[-0.0085,  0.0006, -0.0289,  ...,  0.0041,  0.0569, -0.0674],
        [-0.0052,  0.0245, -0.0213,  ..., -0.0084,  0.0220, -0.0248],
        [-0.0135, -0.0092,  0.0144,  ...,  0.0162,  0.0298, -0.0357],
        ...,
        [-0.0062,  0.0068,  0.0082,  ...,  0.0119,  0.0132, -0.0033],
        [-0.0083,  0.0247, -0.0094,  ..., -0.0040, -0.0122,  0.0142],
        [-0.0048, -0.0044, -0.0164,  ...,  0.0119, -0.0213, -0.0117]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias': tensor([ 0.0234,  0.0084, -0.0015,  ...,  0.0951,  0.0065,  0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight': tensor([[ 0.0164,  0.0053, -0.0065,  ..., -0.0008,  0.0037, -0.0120],
        [-0.0057, -0.0036, -0.0029,  ..., -0.0013,  0.0026, -0.0108],
        [-0.0081,  0.0057,  0.0067,  ...,  0.0028, -0.0068, -0.0023],
        ...,
        [-0.0249,  0.0121,  0.0107,  ...,  0.0037,  0.0007,  0.0044],
        [ 0.0115,  0.0107,  0.0118,  ...,  0.0015, -0.0038, -0.0073],
        [-0.0073,  0.0032, -0.0060,  ...,  0.0023, -0.0074,  0.0047]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias': tensor([-0.0014, -0.0060,  0.0129,  ...,  0.1081,  0.0069,  0.0455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight': tensor([[-0.0067, -0.0208, -0.0222,  ...,  0.0014,  0.0279, -0.0558],
        [-0.0030,  0.0016, -0.0191,  ...,  0.0001, -0.0169, -0.0034],
        [-0.0079, -0.0049,  0.0074,  ..., -0.0163, -0.0186, -0.0105],
        ...,
        [ 0.0002, -0.0036,  0.0084,  ..., -0.0038,  0.0105, -0.0002],
        [-0.0035, -0.0039, -0.0118,  ..., -0.0067, -0.0292,  0.0361],
        [-0.0044, -0.0008, -0.0187,  ...,  0.0014, -0.0064, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias': tensor([ 0.1927, -0.0745, -0.0890,  ...,  0.6807,  0.7334, -0.5073],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight': tensor([[-2.4796e-02,  3.3035e-03, -5.1379e-05,  ...,  2.5177e-02,
         -2.3010e-02,  1.2245e-02],
        [-2.7504e-03,  1.5330e-04, -1.1650e-02,  ..., -8.4229e-03,
         -4.1389e-03, -6.9275e-03],
        [-1.2238e-02, -7.1983e-03, -1.0323e-02,  ..., -1.6312e-02,
         -5.9547e-03, -1.4572e-03],
        ...,
        [-1.8501e-03,  5.0354e-04, -6.7101e-03,  ..., -7.3471e-03,
         -2.3518e-03, -1.8501e-03],
        [ 5.4131e-03, -4.4937e-03,  1.2329e-02,  ..., -7.1716e-04,
          9.8038e-04,  7.2708e-03],
        [ 1.0040e-02,  6.5422e-03,  9.2163e-03,  ..., -4.5815e-03,
         -1.1330e-03, -2.6169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias': tensor([ 0.0182, -0.0970,  0.0244,  ..., -0.0159, -0.0449, -0.0308],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight': tensor([0.5078, 0.3108, 0.4004,  ..., 1.4219, 0.5015, 0.3591],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias': tensor([-0.0750, -0.0109,  0.0618,  ..., -0.0417,  0.0176, -0.0477],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight': tensor([[-0.0066, -0.0264,  0.0131,  ..., -0.0004,  0.0194, -0.0154],
        [ 0.0097,  0.0090, -0.0017,  ...,  0.0023, -0.0030,  0.0246],
        [-0.0057,  0.0093,  0.0011,  ..., -0.0040,  0.0003,  0.0128],
        ...,
        [ 0.0005, -0.0012, -0.0009,  ...,  0.0011, -0.0034, -0.0059],
        [ 0.0002,  0.0115,  0.0158,  ...,  0.0040,  0.0015,  0.0208],
        [-0.0148,  0.0111, -0.0085,  ...,  0.0049, -0.0076, -0.0022]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias': tensor([-0.2452, -0.3076, -0.4565,  ..., -0.1678, -0.2119, -0.5581],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight': tensor([[ 1.3428e-03, -3.5172e-03,  9.3317e-04,  ..., -5.0354e-03,
          4.3907e-03,  2.0161e-03],
        [ 1.2999e-03, -1.6678e-02, -4.5662e-03,  ..., -4.4584e-04,
          1.3359e-02, -3.9558e-03],
        [-1.8829e-02,  5.2261e-03,  4.7760e-03,  ...,  8.3113e-04,
         -1.8860e-02,  1.0452e-03],
        ...,
        [-7.8201e-03,  8.4305e-04, -2.1601e-04,  ..., -5.6207e-05,
          4.8339e-05,  1.7557e-03],
        [-4.5300e-05, -7.9498e-03, -9.6178e-04,  ...,  3.4180e-03,
         -1.0208e-02,  2.4460e-02],
        [ 6.0883e-03,  3.3398e-03, -3.7789e-04,  ...,  1.5259e-02,
          6.6223e-03,  6.8169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias': tensor([ 0.0453, -0.0798, -0.0027,  ..., -0.0154, -0.1379, -0.0307],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight': tensor([0.6362, 0.5508, 0.3787,  ..., 1.3506, 0.4011, 0.4910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias': tensor([-0.0338, -0.0840, -0.0964,  ..., -0.0491,  0.0855, -0.2158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight': tensor([[ 0.0149, -0.0155, -0.0083,  ...,  0.0066,  0.0086, -0.0173],
        [ 0.0067,  0.0134,  0.0050,  ..., -0.0056, -0.0293, -0.0028],
        [ 0.0041, -0.0027, -0.0011,  ...,  0.0060,  0.0020, -0.0035],
        ...,
        [ 0.0110, -0.0188,  0.0174,  ..., -0.0223,  0.0017, -0.0122],
        [ 0.0165, -0.0201, -0.0204,  ..., -0.0262, -0.0232, -0.0039],
        [ 0.0062, -0.0148,  0.0194,  ...,  0.0090, -0.0007, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias': tensor([-0.0385, -0.0122,  0.0262,  ...,  0.1536,  0.0992, -0.0590],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight': tensor([[ 0.0275, -0.0126, -0.0067,  ...,  0.0002,  0.0201,  0.0163],
        [-0.0074,  0.0475,  0.0058,  ..., -0.0040,  0.0014,  0.0004],
        [-0.0100, -0.0039, -0.0155,  ...,  0.0009, -0.0079,  0.0033],
        ...,
        [ 0.0009,  0.0007,  0.0107,  ...,  0.0007,  0.0007, -0.0059],
        [-0.0008,  0.0147,  0.0066,  ...,  0.0022, -0.0062, -0.0033],
        [-0.0195, -0.0065,  0.0118,  ..., -0.0030,  0.0058,  0.0028]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias': tensor([ 0.0095, -0.0516,  0.0111,  ..., -0.0145,  0.0041,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight': tensor([[ 2.7618e-02,  1.0513e-02,  4.2725e-03,  ...,  6.3095e-03,
         -8.5907e-03, -1.3008e-02],
        [ 2.4605e-03,  1.8875e-02, -3.9787e-03,  ..., -5.7335e-03,
         -2.1698e-02,  5.3406e-03],
        [-5.1880e-04, -1.0147e-02, -1.0471e-03,  ...,  1.0002e-02,
          1.0025e-02, -1.6159e-02],
        ...,
        [ 1.4210e-03, -1.6434e-02,  5.2299e-03,  ..., -1.5053e-02,
          1.1284e-02,  1.2054e-03],
        [ 1.5579e-02,  1.5251e-02, -3.5915e-03,  ..., -2.6520e-02,
         -1.4130e-02, -7.7133e-03],
        [ 1.0399e-02, -2.2491e-02,  3.2783e-06,  ...,  8.3542e-03,
         -6.7215e-03,  1.6525e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias': tensor([-0.1852, -0.5479, -0.1450,  ..., -0.9072, -0.3499, -0.3457],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight': tensor([[-2.1683e-02,  2.3556e-03, -1.9245e-03,  ..., -9.4910e-03,
          1.6251e-02,  1.2527e-02],
        [ 6.4430e-03, -3.8055e-02, -3.1567e-03,  ..., -2.6455e-03,
         -2.1515e-02,  1.1864e-02],
        [ 5.2147e-03, -8.5602e-03,  1.5732e-02,  ..., -1.2611e-02,
          7.3395e-03, -1.2505e-02],
        ...,
        [-1.1325e-04,  3.4676e-03, -1.1169e-02,  ..., -1.0071e-02,
         -5.4538e-05, -1.7357e-03],
        [-6.8245e-03, -1.0139e-02,  1.4579e-04,  ...,  2.0309e-02,
          1.3527e-02, -3.0098e-03],
        [-1.7868e-02,  6.0368e-04, -6.7101e-03,  ...,  6.6853e-04,
         -3.0327e-03,  3.0651e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias': tensor([-0.0147, -0.0586,  0.0197,  ...,  0.0204, -0.1210,  0.0171],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight': tensor([0.7456, 0.3557, 0.6133,  ..., 2.2637, 0.5059, 0.3938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias': tensor([-0.0006,  0.0249,  0.0189,  ..., -0.1539, -0.0345,  0.0151],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight': tensor([[ 0.0034,  0.0025,  0.0007,  ..., -0.0021, -0.0065,  0.0058],
        [ 0.0011, -0.0024, -0.0028,  ..., -0.0094, -0.0078, -0.0065],
        [-0.0051, -0.0246, -0.0075,  ..., -0.0073,  0.0121,  0.0036],
        ...,
        [ 0.0077,  0.0038, -0.0011,  ..., -0.0060, -0.0017,  0.0005],
        [-0.0208, -0.0176, -0.0064,  ..., -0.0076, -0.0137, -0.0056],
        [-0.0240,  0.0082, -0.0047,  ..., -0.0105, -0.0069, -0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias': tensor([-0.0952, -0.1888, -0.1597,  ..., -0.2030, -0.3225, -0.3745],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight': tensor([[ 0.0074, -0.0074,  0.0041,  ...,  0.0181,  0.0235,  0.0145],
        [ 0.0106,  0.0015, -0.0078,  ..., -0.0323, -0.0017,  0.0073],
        [-0.0059, -0.0090, -0.0087,  ...,  0.0023,  0.0091,  0.0240],
        ...,
        [ 0.0054,  0.0013, -0.0012,  ..., -0.0047, -0.0021, -0.0053],
        [-0.0028,  0.0165,  0.0051,  ...,  0.0006, -0.0043, -0.0041],
        [-0.0045,  0.0066,  0.0154,  ..., -0.0027,  0.0146, -0.0076]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias': tensor([ 0.0139, -0.0796,  0.0050,  ...,  0.0715, -0.1787,  0.0414],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight': tensor([0.9761, 0.5317, 0.6523,  ..., 0.0116, 0.5054, 0.5391],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias': tensor([ 0.0585,  0.0282,  0.0207,  ...,  0.3896, -0.0784, -0.1201],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight': tensor([[ 2.0187e-02,  9.6970e-03,  1.7242e-02,  ..., -2.5925e-02,
         -1.5945e-02,  6.4671e-05],
        [ 1.0201e-02, -7.3357e-03,  3.3722e-02,  ...,  8.9111e-03,
         -3.2410e-02,  5.5122e-03],
        [ 9.6817e-03, -2.4231e-02,  5.7907e-03,  ...,  4.0955e-02,
          2.2415e-02, -1.8143e-02],
        ...,
        [-2.4857e-02, -2.5803e-02, -3.2673e-03,  ..., -1.3596e-02,
          3.6240e-03, -5.7650e-04],
        [-6.4754e-04,  2.4719e-02, -3.0411e-02,  ..., -1.3008e-02,
          5.0879e-04, -1.9455e-02],
        [ 1.7380e-02, -2.3804e-02,  1.2428e-02,  ..., -4.4670e-03,
         -4.2297e-02,  9.2545e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias': tensor([-0.0362, -0.0177,  0.0258,  ...,  0.0230,  0.0147,  0.0451],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight': tensor([[-0.0050,  0.0089,  0.0017,  ..., -0.0001, -0.0173, -0.0087],
        [ 0.0064, -0.0170,  0.0071,  ..., -0.0039,  0.0387, -0.0100],
        [-0.0151,  0.0005, -0.0012,  ..., -0.0011, -0.0048,  0.0012],
        ...,
        [ 0.0129, -0.0303, -0.0177,  ...,  0.0005,  0.0013,  0.0006],
        [ 0.0157,  0.0140, -0.0101,  ...,  0.0011,  0.0336, -0.0216],
        [ 0.0171, -0.0183, -0.0061,  ...,  0.0016, -0.0197, -0.0110]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias': tensor([ 0.0241, -0.0481, -0.0028,  ...,  0.0268,  0.0064, -0.0023],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight': tensor([[ 0.0075,  0.0013, -0.0144,  ..., -0.0114, -0.0454, -0.0086],
        [-0.0035, -0.0501,  0.0037,  ..., -0.0065, -0.0287,  0.0070],
        [ 0.0061, -0.0005,  0.0146,  ...,  0.0271,  0.0069, -0.0366],
        ...,
        [-0.0107,  0.0089, -0.0109,  ..., -0.0074, -0.0206, -0.0009],
        [-0.0004, -0.0072, -0.0339,  ..., -0.0124, -0.0053, -0.0094],
        [ 0.0051, -0.0136, -0.0062,  ..., -0.0015, -0.0242, -0.0031]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias': tensor([-0.4634, -0.0086,  0.2761,  ..., -0.2158, -0.2346, -0.2240],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight': tensor([[-2.6817e-03, -4.3983e-03,  1.3580e-03,  ..., -2.4681e-03,
         -1.6296e-02, -1.9119e-02],
        [-6.3057e-03,  1.3931e-02,  2.0657e-03,  ...,  2.4063e-02,
         -2.3544e-02,  2.3361e-02],
        [ 4.4098e-03,  2.9049e-03,  3.0816e-05,  ...,  1.9028e-02,
          1.2093e-02,  9.4528e-03],
        ...,
        [-6.3095e-03,  7.6141e-03, -4.4861e-03,  ..., -6.6261e-03,
         -6.6795e-03, -3.0851e-04],
        [ 1.7075e-02, -3.9612e-02,  9.1248e-03,  ...,  1.1742e-02,
         -3.6469e-02,  2.8046e-02],
        [ 8.2626e-03,  1.3752e-03, -1.0185e-02,  ...,  6.5994e-04,
          1.5320e-02,  1.1871e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias': tensor([ 0.0089, -0.0782,  0.0222,  ..., -0.0115, -0.1763,  0.0233],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight': tensor([0.7534, 0.5015, 0.7891,  ..., 1.1660, 0.6074, 0.5796],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias': tensor([ 0.0149, -0.0122,  0.0052,  ..., -0.1028,  0.0337, -0.0357],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight': tensor([[ 0.0072, -0.0114, -0.0013,  ..., -0.0066,  0.0127,  0.0151],
        [-0.0095,  0.0185,  0.0141,  ..., -0.0075,  0.0141,  0.0101],
        [-0.0018,  0.0118,  0.0032,  ..., -0.0046,  0.0148,  0.0008],
        ...,
        [ 0.0204,  0.0075,  0.0235,  ..., -0.0079,  0.0030, -0.0164],
        [ 0.0157, -0.0033, -0.0008,  ..., -0.0085,  0.0043, -0.0139],
        [-0.0009, -0.0003,  0.0257,  ..., -0.0072, -0.0059, -0.0217]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias': tensor([-0.2440, -0.3796, -0.5205,  ..., -0.2163, -0.4248, -0.2197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight': tensor([[-1.6296e-02,  6.4087e-03, -1.4839e-03,  ..., -2.2827e-02,
          1.9302e-02,  1.6346e-03],
        [ 5.0888e-03, -1.3763e-02,  5.1537e-03,  ..., -1.9989e-02,
         -2.7637e-03, -1.0567e-02],
        [ 2.8763e-03, -5.1460e-03, -5.6326e-05,  ..., -7.1030e-03,
         -9.8724e-03, -2.3098e-03],
        ...,
        [-5.3024e-03, -2.0905e-03,  2.9635e-04,  ..., -5.4092e-03,
          2.0993e-04,  2.4395e-03],
        [-9.9411e-03, -1.4748e-02, -2.4283e-04,  ...,  1.8127e-02,
          3.3779e-03,  2.1927e-02],
        [-5.7182e-03,  1.5316e-03,  1.1997e-03,  ...,  2.5387e-03,
         -5.6725e-03,  4.6387e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias': tensor([-0.0155, -0.0524, -0.0402,  ...,  0.1025, -0.1437, -0.0174],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight': tensor([1.1230, 0.5190, 1.0762,  ..., 0.0112, 0.6738, 0.7544],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias': tensor([ 0.0829, -0.0929, -0.0049,  ...,  0.1129, -0.0392, -0.0677],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight': tensor([[ 0.0035, -0.0081,  0.0270,  ..., -0.0032,  0.0041,  0.0172],
        [-0.0174,  0.0256,  0.0060,  ..., -0.0001,  0.0052, -0.0038],
        [ 0.0038,  0.0144, -0.0161,  ..., -0.0028,  0.0033,  0.0003],
        ...,
        [-0.0023, -0.0123, -0.0080,  ...,  0.0256,  0.0213, -0.0097],
        [-0.0147,  0.0030,  0.0045,  ...,  0.0211,  0.0161, -0.0218],
        [-0.0035,  0.0147,  0.0030,  ..., -0.0244, -0.0005, -0.0255]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias': tensor([-0.0187, -0.0076,  0.0053,  ...,  0.0369,  0.0955,  0.0978],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight': tensor([[-0.0090,  0.0047, -0.0008,  ..., -0.0064, -0.0025, -0.0247],
        [-0.0128, -0.0091,  0.0087,  ...,  0.0024, -0.0012,  0.0007],
        [ 0.0101, -0.0021, -0.0005,  ...,  0.0017,  0.0007, -0.0170],
        ...,
        [-0.0120,  0.0108,  0.0011,  ..., -0.0008, -0.0032,  0.0003],
        [-0.0157, -0.0033,  0.0135,  ..., -0.0007, -0.0310, -0.0129],
        [ 0.0124, -0.0001,  0.0213,  ..., -0.0014, -0.0043, -0.0239]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias': tensor([-0.0186, -0.0071, -0.0258,  ..., -0.0043, -0.0113, -0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight': tensor([[-1.7075e-02,  3.0457e-02,  8.3542e-03,  ..., -8.0032e-03,
          1.6724e-02, -1.0490e-02],
        [-1.2169e-02,  8.2474e-03, -4.2725e-03,  ..., -9.4366e-04,
         -4.9591e-03, -1.0300e-02],
        [ 1.0185e-03, -1.2466e-02, -3.0880e-03,  ..., -3.4428e-03,
         -1.3107e-02,  6.5384e-03],
        ...,
        [ 1.5793e-02,  2.0809e-03,  1.9424e-02,  ...,  2.6367e-02,
          1.0529e-02, -2.1439e-02],
        [-5.6992e-03,  4.1580e-04,  3.8116e-02,  ...,  1.6739e-02,
         -9.0103e-03, -1.6327e-02],
        [ 2.8789e-05, -9.8114e-03,  1.0004e-03,  ..., -2.2293e-02,
         -3.0365e-02,  6.1569e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias': tensor([-0.0072, -1.4619,  0.3447,  ..., -0.6147, -0.3474, -0.6455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight': tensor([[ 5.2567e-03,  1.1238e-02, -6.8092e-03,  ..., -8.0013e-04,
          1.5930e-02, -1.4336e-02],
        [-6.6223e-03,  1.9255e-03, -1.6006e-02,  ..., -2.0706e-02,
         -1.1848e-02, -1.1147e-02],
        [ 2.3087e-02,  1.1986e-02, -1.7288e-02,  ...,  5.7144e-03,
          1.4824e-02, -1.6876e-02],
        ...,
        [ 1.6647e-02,  5.3596e-03, -1.5154e-03,  ..., -2.9736e-03,
          1.8129e-03,  1.0559e-02],
        [ 4.1847e-03,  8.3694e-03,  1.2535e-02,  ..., -1.0323e-02,
          1.6327e-02, -3.2544e-05],
        [ 1.0185e-03, -2.1400e-03, -4.4098e-03,  ..., -4.6120e-03,
          6.0921e-03,  1.5152e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias': tensor([-0.0087, -0.0482, -0.0096,  ..., -0.0479, -0.1366,  0.0062],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight': tensor([0.8506, 0.6484, 0.8960,  ..., 1.2539, 0.7212, 0.8564],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias': tensor([-0.0077,  0.0670, -0.0532,  ..., -0.1699, -0.0490,  0.0434],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight': tensor([[ 0.0058,  0.0115,  0.0089,  ..., -0.0020, -0.0053,  0.0026],
        [-0.0017, -0.0024,  0.0162,  ...,  0.0009, -0.0208, -0.0094],
        [-0.0388, -0.0012, -0.0004,  ...,  0.0032, -0.0029, -0.0226],
        ...,
        [ 0.0085,  0.0130,  0.0209,  ..., -0.0057, -0.0040, -0.0012],
        [ 0.0260,  0.0055,  0.0095,  ..., -0.0008,  0.0056, -0.0098],
        [ 0.0116,  0.0073, -0.0117,  ...,  0.0011, -0.0095, -0.0163]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias': tensor([-0.4192, -0.2394, -0.3069,  ..., -0.3667, -0.2563, -0.1315],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight': tensor([[ 0.0154, -0.0020, -0.0083,  ...,  0.0161, -0.0060,  0.0146],
        [ 0.0042,  0.0226,  0.0055,  ...,  0.0110,  0.0033,  0.0034],
        [ 0.0140, -0.0083,  0.0006,  ...,  0.0085,  0.0010,  0.0007],
        ...,
        [-0.0025, -0.0010, -0.0020,  ...,  0.0007, -0.0030, -0.0018],
        [-0.0141, -0.0032, -0.0003,  ...,  0.0106, -0.0021, -0.0400],
        [ 0.0069,  0.0051, -0.0135,  ..., -0.0115,  0.0067, -0.0104]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias': tensor([-0.0416,  0.0127, -0.0229,  ...,  0.0723, -0.0145, -0.0363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight': tensor([1.1514, 0.7275, 1.1299,  ..., 1.0918, 0.8794, 1.1055],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias': tensor([ 0.0418, -0.1718, -0.0305,  ...,  0.0424, -0.2144, -0.0068],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight': tensor([[ 0.0195, -0.0016, -0.0010,  ...,  0.1302, -0.0123, -0.0063],
        [-0.0176,  0.0024, -0.0196,  ..., -0.1481, -0.0101, -0.0231],
        [-0.0042, -0.0077,  0.0033,  ...,  0.0850, -0.0172,  0.0256],
        ...,
        [ 0.0024, -0.0123,  0.0282,  ..., -0.0123,  0.0272,  0.0247],
        [ 0.0084, -0.0235,  0.0189,  ...,  0.0040, -0.0171,  0.0120],
        [ 0.0308, -0.0003,  0.0095,  ..., -0.0054, -0.0117, -0.0379]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias': tensor([-0.0049,  0.0073,  0.0145,  ...,  0.0185, -0.0033,  0.0204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight': tensor([[ 0.0096,  0.0166, -0.0025,  ..., -0.0005,  0.0005,  0.0034],
        [ 0.0066,  0.0109, -0.0074,  ...,  0.0010,  0.0079, -0.0095],
        [-0.0074, -0.0047,  0.0016,  ...,  0.0002,  0.0039,  0.0040],
        ...,
        [-0.0159,  0.0166, -0.0176,  ...,  0.0020, -0.0064,  0.0302],
        [ 0.0316, -0.0076, -0.0238,  ..., -0.0002, -0.0032, -0.0157],
        [-0.0096, -0.0192,  0.0207,  ..., -0.0009, -0.0289, -0.0082]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias': tensor([ 0.0264, -0.0288,  0.0074,  ...,  0.0075, -0.0047,  0.0190],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight': tensor([[ 0.0136, -0.0235, -0.0059,  ...,  0.0935,  0.0115, -0.0124],
        [-0.0146, -0.0224,  0.0003,  ..., -0.1112, -0.0056, -0.0134],
        [-0.0018,  0.0100,  0.0052,  ...,  0.0525,  0.0120,  0.0163],
        ...,
        [ 0.0338,  0.0004,  0.0047,  ..., -0.0146,  0.0189, -0.0173],
        [ 0.0022, -0.0096, -0.0040,  ...,  0.0011, -0.0013,  0.0135],
        [ 0.0178,  0.0135,  0.0019,  ..., -0.0075,  0.0044, -0.0363]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias': tensor([ 0.2430,  0.3418, -0.1379,  ...,  0.0247,  1.4775,  0.2130],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight': tensor([[-0.0026,  0.0052,  0.0064,  ...,  0.0172, -0.0226,  0.0066],
        [-0.0029,  0.0043, -0.0091,  ..., -0.0054, -0.0009,  0.0137],
        [-0.0161,  0.0021,  0.0049,  ...,  0.0088,  0.0251, -0.0076],
        ...,
        [ 0.0092,  0.0003, -0.0009,  ..., -0.0040,  0.0036,  0.0044],
        [ 0.0016, -0.0087,  0.0108,  ..., -0.0028, -0.0046,  0.0207],
        [ 0.0181, -0.0077, -0.0030,  ..., -0.0368, -0.0015,  0.0158]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias': tensor([-0.0217,  0.0017,  0.0176,  ...,  0.0564, -0.0415, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight': tensor([0.8926, 0.8076, 1.0293,  ..., 2.0488, 0.9590, 0.9756],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias': tensor([-0.1279, -0.0777, -0.0509,  ..., -0.2275, -0.0558,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight': tensor([[ 0.0265,  0.0048,  0.0027,  ..., -0.0071,  0.0051,  0.0187],
        [ 0.0004,  0.0177,  0.0098,  ..., -0.0020, -0.0084,  0.0181],
        [-0.0045,  0.0070, -0.0007,  ..., -0.0080, -0.0070, -0.0316],
        ...,
        [-0.0285,  0.0282,  0.0047,  ...,  0.0006, -0.0079,  0.0194],
        [-0.0049, -0.0312, -0.0060,  ..., -0.0043,  0.0310, -0.0003],
        [ 0.0185,  0.0199,  0.0079,  ..., -0.0067, -0.0297, -0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias': tensor([-0.1132, -0.1494, -0.4023,  ..., -0.2355, -0.3335, -0.2045],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight': tensor([[-0.0180,  0.0037,  0.0069,  ..., -0.0019, -0.0086, -0.0024],
        [-0.0006, -0.0030, -0.0042,  ..., -0.0177,  0.0375, -0.0014],
        [-0.0129, -0.0050, -0.0065,  ...,  0.0015, -0.0005, -0.0149],
        ...,
        [ 0.0031,  0.0014, -0.0087,  ..., -0.0003,  0.0073,  0.0014],
        [ 0.0105,  0.0060,  0.0064,  ..., -0.0005, -0.0007,  0.0372],
        [-0.0087, -0.0052,  0.0026,  ..., -0.0113, -0.0085,  0.0098]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias': tensor([-0.0068,  0.0179, -0.0552,  ...,  0.1210, -0.0750, -0.1090],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight': tensor([1.1914, 0.9712, 1.2656,  ..., 0.1719, 0.9092, 1.1973],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias': tensor([-0.0956, -0.1851, -0.0547,  ...,  0.2583, -0.0542,  0.0387],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight': tensor([[ 0.0076, -0.0117, -0.0114,  ...,  0.0770, -0.0048, -0.0017],
        [-0.0195, -0.0001, -0.0053,  ...,  0.0370, -0.0298,  0.0023],
        [-0.0094, -0.0034,  0.0132,  ...,  0.0014,  0.0088, -0.0013],
        ...,
        [ 0.0047, -0.0200, -0.0213,  ..., -0.0028, -0.0125, -0.0193],
        [-0.0028,  0.0018, -0.0313,  ..., -0.0143, -0.0024,  0.0085],
        [-0.0081, -0.0074,  0.0052,  ..., -0.0006, -0.0049, -0.0085]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias': tensor([ 0.0311, -0.0070, -0.0134,  ...,  0.0024, -0.0121, -0.0230],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight': tensor([[ 0.0104, -0.0064, -0.0062,  ...,  0.0015,  0.0052, -0.0058],
        [ 0.0179, -0.0065, -0.0221,  ..., -0.0002, -0.0032, -0.0219],
        [-0.0078,  0.0084, -0.0027,  ..., -0.0003,  0.0120,  0.0011],
        ...,
        [-0.0272, -0.0105,  0.0010,  ..., -0.0082,  0.0024,  0.0062],
        [ 0.0284, -0.0029, -0.0178,  ..., -0.0007, -0.0008, -0.0054],
        [-0.0113,  0.0083,  0.0034,  ..., -0.0102,  0.0250,  0.0115]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias': tensor([ 0.0282,  0.0175, -0.0284,  ...,  0.0397, -0.0209, -0.1344],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight': tensor([[ 0.0094, -0.0159, -0.0203,  ...,  0.0367, -0.0055, -0.0276],
        [ 0.0029, -0.0178, -0.0045,  ..., -0.0709, -0.0047, -0.0184],
        [-0.0128,  0.0083,  0.0116,  ..., -0.0014,  0.0039,  0.0124],
        ...,
        [-0.0292,  0.0131, -0.0025,  ...,  0.0003, -0.0127, -0.0156],
        [-0.0237,  0.0121, -0.0025,  ..., -0.0010,  0.0081, -0.0145],
        [ 0.0137,  0.0139,  0.0163,  ...,  0.0071,  0.0116, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias': tensor([-1.8535,  0.1802,  2.3398,  ..., -0.0595, -0.0338,  0.0305],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight': tensor([[ 0.0028, -0.0249,  0.0077,  ...,  0.0163, -0.0069, -0.0036],
        [ 0.0140, -0.0086,  0.0026,  ...,  0.0077,  0.0073, -0.0239],
        [ 0.0044,  0.0041, -0.0237,  ..., -0.0202, -0.0074,  0.0211],
        ...,
        [-0.0025,  0.0102, -0.0030,  ...,  0.0096,  0.0018,  0.0186],
        [ 0.0052, -0.0034,  0.0046,  ..., -0.0001,  0.0089, -0.0238],
        [-0.0090,  0.0134,  0.0052,  ..., -0.0156, -0.0131,  0.0157]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias': tensor([ 0.0039,  0.0259, -0.0086,  ..., -0.0503, -0.0064, -0.0460],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight': tensor([1.1934, 1.1006, 1.2510,  ..., 1.4092, 1.1592, 1.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias': tensor([ 0.0223, -0.0916,  0.0971,  ..., -0.2983, -0.0408,  0.0070],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight': tensor([[-0.0150,  0.0078,  0.0025,  ..., -0.0011, -0.0016,  0.0092],
        [-0.0219,  0.0313,  0.0128,  ...,  0.0032,  0.0150,  0.0033],
        [-0.0176, -0.0190,  0.0216,  ...,  0.0038, -0.0361,  0.0145],
        ...,
        [ 0.0060, -0.0061, -0.0066,  ...,  0.0027, -0.0050, -0.0172],
        [-0.0283, -0.0057,  0.0115,  ..., -0.0054, -0.0136, -0.0057],
        [-0.0160,  0.0153, -0.0277,  ..., -0.0289, -0.0194,  0.0007]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias': tensor([-0.1221, -0.2144, -0.4114,  ..., -0.1118, -0.1782, -0.3628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight': tensor([[-0.0016,  0.0125, -0.0344,  ..., -0.0221,  0.0044, -0.0154],
        [-0.0039, -0.0351,  0.0205,  ...,  0.0108, -0.0206, -0.0023],
        [ 0.0063, -0.0273, -0.0012,  ...,  0.0131,  0.0057, -0.0150],
        ...,
        [-0.0002, -0.0069,  0.0022,  ..., -0.0065,  0.0032,  0.0088],
        [ 0.0108, -0.0061, -0.0134,  ..., -0.0061,  0.0058, -0.0083],
        [ 0.0133,  0.0173,  0.0049,  ...,  0.0188, -0.0199, -0.0074]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias': tensor([-0.0200,  0.0232, -0.0657,  ...,  0.1028, -0.0782, -0.1134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight': tensor([1.2578, 1.1084, 1.2061,  ..., 0.5884, 1.0264, 1.2910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias': tensor([-0.0061, -0.0651,  0.0878,  ...,  0.1716,  0.1021, -0.0355],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight': tensor([[-0.0184, -0.0017,  0.0284,  ..., -0.0922, -0.0121,  0.0085],
        [ 0.0216,  0.0109,  0.0091,  ..., -0.0531,  0.0165, -0.0052],
        [-0.0036,  0.0282,  0.0128,  ...,  0.0421, -0.0305, -0.0203],
        ...,
        [-0.0003, -0.0044, -0.0082,  ..., -0.0171,  0.0052,  0.0071],
        [ 0.0136, -0.0294, -0.0073,  ..., -0.0191, -0.0179,  0.0170],
        [-0.0079,  0.0298, -0.0092,  ...,  0.0071,  0.0015,  0.0033]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias': tensor([-0.0044, -0.0038, -0.0472,  ...,  0.0818,  0.0363, -0.0465],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight': tensor([[ 1.9028e-02,  3.3264e-03, -1.4641e-02,  ..., -4.6754e-04,
         -1.4366e-02,  1.6556e-02],
        [ 2.1267e-04, -1.5457e-02, -3.2166e-02,  ..., -2.4629e-04,
          5.9090e-03, -9.8267e-03],
        [-1.2535e-02, -1.2222e-02,  9.6970e-03,  ...,  1.7128e-03,
         -2.1992e-03,  3.7842e-03],
        ...,
        [ 1.0918e-02,  1.8097e-02,  1.2695e-02,  ...,  4.8494e-04,
          5.1918e-03, -1.9058e-02],
        [ 9.9792e-03, -1.2085e-02,  6.0320e-04,  ...,  3.4790e-03,
          1.0284e-02,  2.8300e-04],
        [ 2.2034e-02, -1.5373e-03, -2.1362e-02,  ...,  4.9706e-03,
         -4.9174e-05, -6.5117e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias': tensor([ 0.0094,  0.0439, -0.0031,  ..., -0.0485, -0.1193,  0.0170],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight': tensor([[-1.2352e-02,  2.3239e-02,  5.5618e-03,  ..., -5.1178e-02,
         -2.8687e-02,  2.2531e-05],
        [-1.0605e-02, -2.5497e-02,  1.1894e-02,  ..., -2.0462e-02,
         -8.5449e-04,  4.6265e-02],
        [ 8.6212e-03, -9.3765e-03,  5.9357e-03,  ...,  2.0432e-02,
         -2.2537e-02,  4.4495e-02],
        ...,
        [ 1.3062e-02, -5.5428e-03,  1.0025e-02,  ..., -4.5746e-02,
          6.3477e-03,  2.0248e-02],
        [ 9.6588e-03, -1.4442e-02, -2.0096e-02,  ...,  6.9542e-03,
          5.9013e-03, -3.3588e-03],
        [-5.3177e-03,  2.2705e-02, -2.1713e-02,  ...,  2.4307e-02,
          1.5465e-02, -8.3237e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias': tensor([ 0.0542, -0.0733,  0.2440,  ..., -0.3313, -0.1129,  0.1049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight': tensor([[-0.0227,  0.0130, -0.0113,  ..., -0.0045,  0.0108, -0.0190],
        [-0.0057, -0.0069,  0.0119,  ..., -0.0068,  0.0143,  0.0030],
        [ 0.0062,  0.0204,  0.0161,  ..., -0.0079, -0.0057,  0.0308],
        ...,
        [ 0.0001,  0.0003,  0.0048,  ...,  0.0089, -0.0032,  0.0210],
        [-0.0079,  0.0007,  0.0030,  ...,  0.0093, -0.0068, -0.0121],
        [-0.0154,  0.0158, -0.0231,  ..., -0.0158,  0.0141, -0.0072]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias': tensor([-0.0179,  0.0685, -0.0152,  ..., -0.0815,  0.0257,  0.0175],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight': tensor([1.1738, 1.1582, 1.1592,  ..., 1.5869, 1.1748, 1.2314],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias': tensor([-0.0068,  0.0917, -0.0354,  ..., -0.3271, -0.1141, -0.0543],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight': tensor([[-0.0195, -0.0128, -0.0054,  ..., -0.0029, -0.0047,  0.0116],
        [-0.0031, -0.0199,  0.0011,  ..., -0.0044,  0.0127,  0.0019],
        [ 0.0130, -0.0056,  0.0037,  ..., -0.0005,  0.0237,  0.0081],
        ...,
        [ 0.0115,  0.0130, -0.0272,  ...,  0.0021,  0.0227,  0.0057],
        [-0.0035,  0.0108, -0.0211,  ..., -0.0011,  0.0154, -0.0001],
        [-0.0336,  0.0183,  0.0121,  ..., -0.0012, -0.0093,  0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias': tensor([-0.3628, -0.2211, -0.1648,  ..., -0.2524, -0.2686, -0.2517],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight': tensor([[-4.5166e-03,  7.6828e-03,  1.3664e-02,  ..., -2.5959e-03,
         -2.0126e-02, -7.1602e-03],
        [-1.4015e-02,  2.0084e-03,  6.2370e-03,  ...,  1.9714e-02,
         -4.8294e-03, -2.3682e-02],
        [-4.3793e-03,  6.3400e-03,  5.3253e-03,  ...,  9.2888e-04,
          7.6599e-03, -1.8555e-02],
        ...,
        [-4.1809e-03, -1.8768e-03,  4.0741e-03,  ..., -1.5802e-03,
         -3.6144e-03,  8.3983e-05],
        [-2.7523e-03, -2.6489e-02, -1.3283e-02,  ...,  3.4904e-03,
         -1.4786e-02,  6.2981e-03],
        [-3.0880e-03, -2.1713e-02, -1.7853e-02,  ...,  1.1139e-02,
          7.2784e-03, -1.2558e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias': tensor([-0.0283,  0.0284, -0.0329,  ...,  0.0671, -0.0050, -0.0488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight': tensor([1.2725, 1.2539, 1.2041,  ..., 0.7529, 1.0645, 1.2422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias': tensor([ 0.0019, -0.0140,  0.0246,  ...,  0.2150, -0.1251, -0.2118],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0117,  0.0046,  ..., -0.0265, -0.0033,  0.0070],
        [ 0.0061,  0.0207, -0.0110,  ...,  0.0132,  0.0091,  0.0226],
        [-0.0012,  0.0130,  0.0031,  ...,  0.0025,  0.0157,  0.0028],
        ...,
        [ 0.0178,  0.0099,  0.0200,  ...,  0.0006, -0.0303, -0.0324],
        [-0.0035,  0.0138,  0.0245,  ..., -0.0032, -0.0065,  0.0055],
        [-0.0023,  0.0024, -0.0018,  ...,  0.0053,  0.0023, -0.0070]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias': tensor([ 0.1105, -0.0046,  0.0618,  ...,  0.0103, -0.0147,  0.0179],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight': tensor([[ 0.0128, -0.0147,  0.0370,  ..., -0.0059,  0.0019, -0.0157],
        [-0.0200,  0.0040, -0.0021,  ..., -0.0084, -0.0056, -0.0079],
        [-0.0030, -0.0037, -0.0301,  ..., -0.0076,  0.0190,  0.0188],
        ...,
        [ 0.0036,  0.0197, -0.0007,  ..., -0.0078,  0.0181, -0.0004],
        [-0.0112,  0.0034, -0.0117,  ...,  0.0041, -0.0017, -0.0116],
        [-0.0199,  0.0032, -0.0224,  ..., -0.0046,  0.0289,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias': tensor([-0.0085, -0.0267, -0.0139,  ..., -0.0130,  0.0113,  0.0014],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight': tensor([[-5.2223e-03, -1.1261e-02,  2.0859e-02,  ..., -3.4424e-02,
          5.4245e-03,  3.5515e-03],
        [ 2.7637e-03,  4.4861e-03,  5.6877e-03,  ...,  6.7830e-05,
         -1.3123e-02,  1.6266e-02],
        [-7.9575e-03,  6.3133e-03,  1.7059e-02,  ...,  2.5711e-03,
         -5.4283e-03, -1.0437e-02],
        ...,
        [-1.2264e-03,  2.9633e-02, -8.0185e-03,  ...,  1.4366e-02,
          2.8824e-02, -1.8001e-05],
        [ 5.7316e-04,  8.2397e-03,  1.8951e-02,  ...,  1.4248e-03,
          1.8433e-02, -1.7624e-02],
        [ 6.5842e-03,  2.7451e-02, -1.9012e-02,  ...,  1.1887e-02,
         -7.3357e-03,  1.1284e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias': tensor([-0.8462,  0.0103, -1.0879,  ..., -0.1941,  0.1663, -1.2803],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight': tensor([[-0.0020,  0.0252,  0.0039,  ...,  0.0061, -0.0123,  0.0283],
        [ 0.0043,  0.0004, -0.0082,  ..., -0.0251,  0.0068,  0.0017],
        [-0.0231,  0.0006,  0.0164,  ...,  0.0248,  0.0101,  0.0125],
        ...,
        [ 0.0080,  0.0312,  0.0238,  ...,  0.0045,  0.0003,  0.0054],
        [ 0.0077,  0.0073, -0.0009,  ..., -0.0016,  0.0038, -0.0133],
        [ 0.0194, -0.0053, -0.0238,  ...,  0.0249, -0.0041,  0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias': tensor([-0.0205,  0.0181, -0.0017,  ..., -0.0779,  0.0408, -0.0200],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight': tensor([1.1533, 1.2090, 1.1787,  ..., 1.6367, 1.1729, 1.2188],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias': tensor([-0.0550,  0.0990, -0.0018,  ..., -0.1779, -0.0518, -0.0147],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight': tensor([[-0.0073, -0.0223,  0.0130,  ..., -0.0079, -0.0028,  0.0022],
        [-0.0071,  0.0068,  0.0017,  ..., -0.0123, -0.0179, -0.0108],
        [ 0.0072,  0.0217,  0.0110,  ...,  0.0060,  0.0005,  0.0016],
        ...,
        [ 0.0225, -0.0085,  0.0064,  ...,  0.0007,  0.0014, -0.0003],
        [-0.0191,  0.0245,  0.0085,  ..., -0.0102, -0.0108, -0.0063],
        [ 0.0290, -0.0322, -0.0287,  ..., -0.0045,  0.0156, -0.0153]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias': tensor([-0.4795, -0.1469, -0.1043,  ..., -0.2998, -0.2252, -0.3262],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight': tensor([[-0.0205,  0.0170, -0.0019,  ...,  0.0084,  0.0040,  0.0268],
        [ 0.0060,  0.0025, -0.0069,  ...,  0.0071, -0.0261,  0.0028],
        [ 0.0291, -0.0064, -0.0019,  ..., -0.0131,  0.0078, -0.0294],
        ...,
        [-0.0110,  0.0011, -0.0081,  ..., -0.0030,  0.0036, -0.0003],
        [-0.0195,  0.0083,  0.0063,  ...,  0.0095, -0.0105,  0.0214],
        [-0.0028,  0.0316,  0.0016,  ..., -0.0094, -0.0051,  0.0145]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias': tensor([ 0.0411, -0.0040, -0.0517,  ...,  0.1116,  0.0086, -0.0608],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight': tensor([1.3838, 1.2871, 1.2334,  ..., 0.6108, 1.1768, 1.2568],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias': tensor([-0.2367,  0.0573,  0.1235,  ...,  0.2408,  0.0240, -0.0257],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight': tensor([[-0.0176,  0.0033,  0.0183,  ..., -0.0038,  0.0074,  0.0088],
        [-0.0091,  0.0276, -0.0216,  ...,  0.0220,  0.0110,  0.0020],
        [-0.0428, -0.0160,  0.0246,  ...,  0.0130, -0.0163, -0.0116],
        ...,
        [ 0.0326,  0.0183, -0.0093,  ...,  0.0212, -0.0169,  0.0020],
        [ 0.0131,  0.0204,  0.0034,  ...,  0.0138,  0.0030,  0.0125],
        [ 0.0216,  0.0034,  0.0112,  ..., -0.0203,  0.0063, -0.0135]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias': tensor([-0.0005,  0.0142, -0.0017,  ...,  0.0816, -0.0667,  0.0688],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight': tensor([[-0.0305, -0.0173,  0.0406,  ...,  0.0054,  0.0093, -0.0001],
        [ 0.0040,  0.0132, -0.0068,  ..., -0.0034, -0.0217, -0.0175],
        [-0.0051,  0.0121, -0.0121,  ..., -0.0104, -0.0141, -0.0050],
        ...,
        [ 0.0016,  0.0205, -0.0056,  ..., -0.0040, -0.0046,  0.0020],
        [ 0.0378,  0.0040, -0.0073,  ...,  0.0001, -0.0014,  0.0133],
        [ 0.0088, -0.0021, -0.0040,  ..., -0.0019,  0.0257, -0.0056]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias': tensor([-0.0842, -0.0092,  0.0031,  ...,  0.0677, -0.0071,  0.0129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight': tensor([[ 0.0169, -0.0117, -0.0191,  ...,  0.0101, -0.0038,  0.0100],
        [-0.0080,  0.0092,  0.0094,  ...,  0.0197, -0.0175, -0.0183],
        [-0.0264, -0.0041,  0.0021,  ...,  0.0114,  0.0084, -0.0139],
        ...,
        [-0.0015,  0.0094,  0.0175,  ...,  0.0220, -0.0158,  0.0012],
        [-0.0012,  0.0214, -0.0034,  ...,  0.0166, -0.0191,  0.0039],
        [ 0.0204, -0.0130,  0.0074,  ..., -0.0208,  0.0063, -0.0040]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias': tensor([ 0.0173,  0.2045, -0.1959,  ..., -0.0136, -0.0571, -0.2710],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight': tensor([[ 1.1879e-02, -8.7357e-03, -2.2980e-02,  ..., -5.5885e-03,
         -2.6260e-02,  1.4985e-04],
        [ 2.3117e-02, -1.8127e-02,  2.0111e-02,  ..., -5.3711e-03,
         -3.0880e-03, -2.6855e-03],
        [-7.4577e-03,  5.7449e-03, -2.7313e-02,  ...,  2.7695e-03,
          7.9803e-03,  1.0475e-02],
        ...,
        [-1.1810e-02,  1.0620e-02,  1.4153e-02,  ...,  7.8049e-03,
          7.3671e-04,  2.8267e-03],
        [ 6.1150e-03,  1.5244e-02,  2.3621e-02,  ...,  9.0599e-05,
          2.7008e-03, -3.2196e-02],
        [ 3.8743e-04, -6.6109e-03, -1.4534e-02,  ...,  1.1330e-03,
         -1.8280e-02, -3.4065e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias': tensor([-0.0230,  0.0388, -0.0072,  ..., -0.0651,  0.0296, -0.0002],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight': tensor([1.2031, 1.2344, 1.1543,  ..., 1.5986, 1.2275, 1.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias': tensor([-0.0587,  0.0094, -0.0588,  ..., -0.2544, -0.1669, -0.0670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight': tensor([[-0.0105, -0.0159, -0.0260,  ..., -0.0012,  0.0033,  0.0001],
        [ 0.0232, -0.0237,  0.0074,  ..., -0.0032,  0.0108,  0.0003],
        [ 0.0088,  0.0072,  0.0034,  ...,  0.0001, -0.0065,  0.0012],
        ...,
        [ 0.0007, -0.0093,  0.0181,  ..., -0.0021, -0.0059,  0.0082],
        [ 0.0024,  0.0102, -0.0177,  ..., -0.0005, -0.0069, -0.0302],
        [ 0.0112,  0.0245,  0.0004,  ...,  0.0030, -0.0044,  0.0190]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias': tensor([-0.1327, -0.2241, -0.0568,  ..., -0.2708, -0.3245, -0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight': tensor([[ 1.0185e-02, -1.1162e-02, -2.3911e-02,  ...,  2.9709e-02,
         -1.3023e-02, -1.1803e-02],
        [ 8.2092e-03, -4.3631e-04, -3.1257e-04,  ..., -1.3252e-02,
          5.4598e-05, -1.8997e-02],
        [ 5.5885e-03,  1.8112e-02,  9.0179e-03,  ..., -3.1700e-03,
          8.4686e-03, -3.6144e-03],
        ...,
        [ 4.7798e-03,  3.0174e-03, -3.5143e-04,  ...,  5.4665e-03,
         -3.4122e-03, -4.2953e-03],
        [ 3.2082e-03, -1.4816e-02, -9.4986e-04,  ..., -1.9455e-02,
         -9.8825e-05,  9.9869e-03],
        [-7.2784e-03, -5.8289e-03, -3.9062e-03,  ...,  5.5122e-03,
         -2.4323e-02, -2.7542e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias': tensor([ 0.0389,  0.0069, -0.0129,  ...,  0.0417,  0.0218,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight': tensor([1.4287, 1.3613, 1.2949,  ..., 1.0137, 1.1826, 1.3213],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias': tensor([-0.1137,  0.0275,  0.0679,  ...,  0.1796,  0.0205, -0.2534],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight': tensor([[ 0.0030,  0.0209, -0.0001,  ..., -0.0044,  0.0148,  0.0093],
        [-0.0027, -0.0116,  0.0012,  ...,  0.0060, -0.0152, -0.0084],
        [-0.0064,  0.0066, -0.0148,  ..., -0.0031, -0.0160,  0.0061],
        ...,
        [ 0.0134, -0.0141, -0.0170,  ...,  0.0031, -0.0175,  0.0096],
        [ 0.0032, -0.0072,  0.0027,  ...,  0.0026,  0.0248,  0.0016],
        [ 0.0372, -0.0190,  0.0259,  ..., -0.0076,  0.0134,  0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias': tensor([ 0.0132, -0.0158,  0.0312,  ...,  0.1599,  0.0190, -0.0702],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight': tensor([[-0.0019,  0.0161, -0.0136,  ...,  0.0041,  0.0124, -0.0042],
        [ 0.0003, -0.0210,  0.0050,  ...,  0.0030, -0.0272,  0.0083],
        [-0.0101, -0.0327, -0.0195,  ..., -0.0035,  0.0067, -0.0172],
        ...,
        [ 0.0214, -0.0060, -0.0126,  ..., -0.0054, -0.0032,  0.0097],
        [-0.0153, -0.0010, -0.0009,  ...,  0.0023, -0.0131,  0.0013],
        [ 0.0080,  0.0060,  0.0053,  ..., -0.0054, -0.0073,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias': tensor([-0.0223, -0.0200, -0.0063,  ..., -0.0170, -0.0150,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight': tensor([[-0.0132,  0.0006,  0.0249,  ..., -0.0071,  0.0142, -0.0221],
        [-0.0046,  0.0369, -0.0272,  ...,  0.0017,  0.0163,  0.0032],
        [-0.0089, -0.0084,  0.0370,  ..., -0.0099,  0.0085,  0.0120],
        ...,
        [ 0.0223, -0.0226, -0.0282,  ...,  0.0133, -0.0224, -0.0005],
        [ 0.0005, -0.0127, -0.0058,  ..., -0.0071,  0.0076, -0.0049],
        [-0.0067,  0.0026,  0.0143,  ...,  0.0054, -0.0011,  0.0246]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias': tensor([-0.0499, -0.0381,  0.5078,  ..., -0.0939, -1.3535,  0.2761],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight': tensor([[ 0.0038,  0.0181,  0.0089,  ..., -0.0054,  0.0091,  0.0008],
        [-0.0116,  0.0084,  0.0211,  ...,  0.0138,  0.0282, -0.0086],
        [ 0.0388,  0.0029,  0.0070,  ..., -0.0161,  0.0043, -0.0173],
        ...,
        [ 0.0053, -0.0073, -0.0049,  ...,  0.0171, -0.0165,  0.0032],
        [ 0.0020, -0.0032,  0.0069,  ...,  0.0089,  0.0018,  0.0021],
        [ 0.0025, -0.0044,  0.0106,  ..., -0.0193,  0.0141, -0.0083]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias': tensor([ 0.0060,  0.0680,  0.0354,  ..., -0.0553,  0.0136,  0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight': tensor([1.2344, 1.2090, 1.1689,  ..., 1.8428, 1.1562, 1.2676],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias': tensor([-0.0174, -0.0716, -0.1256,  ..., -0.2900, -0.1460,  0.1504],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight': tensor([[-0.0042, -0.0027,  0.0133,  ..., -0.0005,  0.0226, -0.0110],
        [ 0.0404,  0.0308,  0.0195,  ...,  0.0055, -0.0234,  0.0145],
        [-0.0008, -0.0259, -0.0103,  ...,  0.0008,  0.0100,  0.0084],
        ...,
        [ 0.0190, -0.0154,  0.0061,  ..., -0.0111, -0.0397,  0.0165],
        [ 0.0025, -0.0002,  0.0089,  ..., -0.0010, -0.0172, -0.0077],
        [ 0.0183, -0.0069, -0.0037,  ...,  0.0029, -0.0036,  0.0130]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias': tensor([-0.2314, -0.3215, -0.0735,  ..., -0.3020, -0.1613, -0.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight': tensor([[ 1.0155e-02,  3.2532e-02,  8.2626e-03,  ..., -6.4468e-03,
         -4.7760e-03,  5.5432e-06],
        [-1.1612e-02,  1.7509e-03,  2.4841e-02,  ...,  8.9645e-03,
         -2.5436e-02, -8.4152e-03],
        [ 1.5182e-02,  7.3395e-03,  6.1264e-03,  ..., -1.5427e-02,
         -1.8677e-02,  1.9806e-02],
        ...,
        [-5.6686e-03,  6.3848e-04,  4.5128e-03,  ..., -9.9792e-03,
          1.1284e-02,  6.5231e-04],
        [-3.6335e-03,  3.6285e-02, -9.9277e-04,  ...,  4.8828e-03,
          9.6283e-03,  1.3008e-02],
        [ 9.3918e-03, -2.1927e-02, -1.4038e-02,  ...,  1.3329e-02,
          5.4359e-03,  3.3169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias': tensor([0.0373, 0.0198, 0.0018,  ..., 0.0559, 0.0675, 0.0106],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight': tensor([1.4990, 1.4297, 1.3555,  ..., 0.9502, 1.1816, 1.4072],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias': tensor([-0.1736, -0.0029,  0.0179,  ...,  0.2495,  0.0637, -0.1158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight': tensor([[ 0.0138, -0.0022,  0.0212,  ...,  0.0048,  0.0084,  0.0082],
        [-0.0165, -0.0025,  0.0060,  ...,  0.0063,  0.0062, -0.0098],
        [ 0.0116,  0.0009,  0.0094,  ...,  0.0054,  0.0176,  0.0027],
        ...,
        [ 0.0160, -0.0161,  0.0148,  ..., -0.0268,  0.0052,  0.0090],
        [-0.0136,  0.0253, -0.0004,  ...,  0.0156,  0.0059,  0.0038],
        [-0.0080,  0.0130, -0.0251,  ...,  0.0136, -0.0164,  0.0184]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias': tensor([ 0.1146,  1.0303,  0.1827,  ...,  0.0439,  0.0025, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0085, -0.0074,  ...,  0.0006, -0.0214, -0.0142],
        [ 0.0022,  0.0155, -0.0111,  ..., -0.0004, -0.0232, -0.0101],
        [-0.0139,  0.0073, -0.0043,  ..., -0.0005, -0.0110, -0.0235],
        ...,
        [ 0.0153,  0.0130, -0.0090,  ...,  0.0045,  0.0109,  0.0025],
        [ 0.0072,  0.0052, -0.0024,  ..., -0.0120,  0.0016, -0.0072],
        [ 0.0013, -0.0272, -0.0105,  ..., -0.0043,  0.0004, -0.0020]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias': tensor([ 0.0573, -0.0360, -0.0042,  ...,  0.0485, -0.0465,  0.0206],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight': tensor([[ 0.0094,  0.0003,  0.0279,  ...,  0.0015, -0.0191,  0.0090],
        [ 0.0041, -0.0014,  0.0020,  ...,  0.0017, -0.0018,  0.0040],
        [-0.0280,  0.0335,  0.0134,  ...,  0.0017,  0.0047, -0.0206],
        ...,
        [-0.0081, -0.0019,  0.0095,  ..., -0.0111, -0.0239,  0.0087],
        [-0.0195, -0.0019,  0.0218,  ...,  0.0267,  0.0121, -0.0089],
        [-0.0340, -0.0066,  0.0098,  ...,  0.0160,  0.0019, -0.0100]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias': tensor([ 0.2460,  1.7949,  0.0708,  ..., -0.2112,  0.1188,  0.6323],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight': tensor([[ 0.0051,  0.0107, -0.0119,  ..., -0.0148,  0.0005, -0.0302],
        [-0.0066, -0.0071, -0.0048,  ..., -0.0226, -0.0094,  0.0276],
        [ 0.0101,  0.0083,  0.0168,  ..., -0.0064,  0.0009, -0.0152],
        ...,
        [ 0.0094, -0.0071,  0.0016,  ..., -0.0147,  0.0114,  0.0020],
        [ 0.0223,  0.0076,  0.0287,  ..., -0.0214,  0.0006,  0.0041],
        [ 0.0177,  0.0222,  0.0063,  ...,  0.0065,  0.0120, -0.0114]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias': tensor([ 0.0267, -0.0057, -0.0027,  ..., -0.0531, -0.0267,  0.0482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight': tensor([1.2383, 1.2549, 1.2197,  ..., 1.8193, 1.1484, 1.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias': tensor([ 0.1250, -0.0352,  0.1172,  ..., -0.1227, -0.0328,  0.1005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight': tensor([[-0.0007, -0.0112,  0.0090,  ..., -0.0016,  0.0087,  0.0027],
        [ 0.0122, -0.0152,  0.0042,  ..., -0.0079, -0.0033, -0.0148],
        [ 0.0095, -0.0118, -0.0270,  ...,  0.0040,  0.0046, -0.0246],
        ...,
        [-0.0209, -0.0194, -0.0025,  ..., -0.0006, -0.0144,  0.0085],
        [ 0.0016,  0.0133,  0.0006,  ..., -0.0033, -0.0143,  0.0128],
        [-0.0106,  0.0115,  0.0019,  ..., -0.0046, -0.0505,  0.0052]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias': tensor([-0.3506, -0.3098, -0.0692,  ..., -0.3076, -0.2494, -0.4229],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight': tensor([[-0.0116,  0.0186, -0.0109,  ...,  0.0093, -0.0051, -0.0192],
        [ 0.0115,  0.0091,  0.0046,  ...,  0.0060, -0.0104, -0.0086],
        [-0.0004,  0.0162,  0.0221,  ...,  0.0048,  0.0374,  0.0092],
        ...,
        [-0.0029,  0.0068, -0.0073,  ...,  0.0019, -0.0060,  0.0068],
        [ 0.0121, -0.0012, -0.0035,  ..., -0.0168, -0.0036, -0.0015],
        [ 0.0085, -0.0005,  0.0138,  ..., -0.0026,  0.0074, -0.0113]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias': tensor([ 0.0374, -0.0088, -0.0430,  ...,  0.0654, -0.0126, -0.0253],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight': tensor([1.5195, 1.3818, 1.3984,  ..., 0.8403, 1.2627, 1.5020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias': tensor([-0.1865,  0.1162,  0.4048,  ...,  0.2292,  0.4202, -0.0959],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight': tensor([[ 0.0295,  0.0205, -0.0174,  ...,  0.0181,  0.0055,  0.0153],
        [ 0.0159, -0.0236, -0.0138,  ...,  0.0058,  0.0019,  0.0084],
        [-0.0116, -0.0219,  0.0080,  ...,  0.0020, -0.0022,  0.0255],
        ...,
        [-0.0140,  0.0030, -0.0549,  ...,  0.0038, -0.0079,  0.0469],
        [-0.0193,  0.0216, -0.0092,  ...,  0.0083,  0.0186,  0.0123],
        [ 0.0039,  0.0084,  0.0082,  ..., -0.0016, -0.0041, -0.0187]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias': tensor([-0.0278, -0.0587, -0.0110,  ..., -0.0826, -0.0213, -0.0725],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight': tensor([[-0.0007,  0.0020,  0.0042,  ..., -0.0033, -0.0094, -0.0123],
        [ 0.0162,  0.0139,  0.0239,  ..., -0.0017, -0.0188,  0.0138],
        [-0.0234,  0.0133, -0.0101,  ..., -0.0029, -0.0003,  0.0196],
        ...,
        [ 0.0244,  0.0202,  0.0058,  ..., -0.0130,  0.0092, -0.0032],
        [ 0.0215,  0.0236, -0.0171,  ..., -0.0159, -0.0069,  0.0134],
        [-0.0087,  0.0025,  0.0248,  ..., -0.0004,  0.0047, -0.0208]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias': tensor([-0.0305,  0.0005, -0.0124,  ..., -0.0511, -0.0883,  0.0079],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight': tensor([[-0.0156,  0.0022, -0.0072,  ...,  0.0036,  0.0290,  0.0180],
        [-0.0003,  0.0088, -0.0014,  ..., -0.0144, -0.0101,  0.0001],
        [-0.0141, -0.0287,  0.0098,  ..., -0.0024,  0.0292,  0.0254],
        ...,
        [-0.0255,  0.0364, -0.0171,  ...,  0.0032,  0.0116, -0.0182],
        [-0.0159,  0.0349, -0.0009,  ..., -0.0083, -0.0006, -0.0242],
        [-0.0239,  0.0287,  0.0045,  ...,  0.0057, -0.0037, -0.0132]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias': tensor([-0.2856, -0.3130, -0.2024,  ...,  0.1942, -0.0307, -0.0692],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight': tensor([[ 0.0021, -0.0248,  0.0393,  ..., -0.0213, -0.0080,  0.0129],
        [-0.0123, -0.0083,  0.0236,  ..., -0.0091, -0.0172, -0.0205],
        [-0.0194, -0.0024,  0.0146,  ..., -0.0071,  0.0185, -0.0175],
        ...,
        [-0.0277,  0.0011, -0.0187,  ...,  0.0559,  0.0597, -0.0009],
        [ 0.0156,  0.0051, -0.0020,  ..., -0.0031,  0.0066,  0.0040],
        [-0.0057, -0.0281, -0.0138,  ...,  0.0075, -0.0093,  0.0108]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias': tensor([ 0.0077,  0.0031,  0.0012,  ..., -0.0701,  0.0300,  0.0083],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight': tensor([1.2822, 1.2529, 1.2988,  ..., 2.2090, 1.1758, 1.3721],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias': tensor([ 0.1495, -0.0801, -0.0723,  ..., -0.1654, -0.0899,  0.0350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight': tensor([[ 0.0063,  0.0413,  0.0369,  ...,  0.0064,  0.0150,  0.0227],
        [ 0.0141,  0.0154,  0.0189,  ...,  0.0018,  0.0107,  0.0041],
        [-0.0081, -0.0167,  0.0103,  ..., -0.0018, -0.0027,  0.0110],
        ...,
        [ 0.0142,  0.0290,  0.0162,  ..., -0.0030,  0.0042,  0.0023],
        [ 0.0167,  0.0140,  0.0168,  ..., -0.0036, -0.0046,  0.0118],
        [-0.0082,  0.0164,  0.0227,  ...,  0.0009, -0.0199, -0.0222]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias': tensor([-0.2788, -0.1959, -0.3855,  ..., -0.3228, -0.2610, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight': tensor([[-6.8474e-03, -1.1681e-02, -1.7517e-02,  ...,  1.0986e-02,
         -1.8341e-02,  2.0432e-02],
        [ 1.1215e-02, -7.8430e-03, -6.9542e-03,  ...,  1.2108e-02,
         -9.6741e-03, -1.2093e-02],
        [ 1.2321e-02, -2.7924e-02, -2.8896e-03,  ...,  4.8676e-03,
         -2.0275e-03, -1.2695e-02],
        ...,
        [-2.5902e-03,  1.4412e-02, -3.3092e-03,  ..., -2.8193e-05,
          6.4087e-04, -7.4434e-04],
        [-1.8280e-02, -8.6746e-03,  9.6130e-03,  ...,  4.2915e-03,
         -1.1269e-02,  2.3453e-02],
        [-6.6452e-03, -2.1088e-02, -1.2444e-02,  ..., -3.5534e-03,
         -7.8659e-03,  2.5589e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias': tensor([ 0.0329,  0.0112, -0.0181,  ...,  0.0332,  0.0061, -0.0410],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight': tensor([1.6201, 1.4990, 1.4219,  ..., 0.7642, 1.2715, 1.4961],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias': tensor([-0.1376, -0.0238, -0.0118,  ...,  0.3352,  0.1462, -0.0976],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight': tensor([[ 0.0070,  0.0068,  0.0031,  ...,  0.0113, -0.0308, -0.0060],
        [ 0.0026, -0.0039,  0.0043,  ..., -0.0343, -0.0066,  0.0307],
        [-0.0036,  0.0332, -0.0028,  ...,  0.0011, -0.0337,  0.0031],
        ...,
        [-0.0229, -0.0187, -0.0097,  ..., -0.0007,  0.0183, -0.0038],
        [ 0.0047,  0.0152, -0.0175,  ...,  0.0070,  0.0130, -0.0114],
        [-0.0206,  0.0068, -0.0252,  ...,  0.0070, -0.0134, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias': tensor([ 0.1860, -0.2378,  0.0005,  ...,  0.0031,  0.1797, -0.0522],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight': tensor([[-0.0298, -0.0140,  0.0248,  ...,  0.0035, -0.0014, -0.0059],
        [-0.0006, -0.0080,  0.0046,  ...,  0.0036,  0.0106, -0.0112],
        [ 0.0055,  0.0188,  0.0175,  ...,  0.0029, -0.0033, -0.0018],
        ...,
        [ 0.0039, -0.0129,  0.0162,  ...,  0.0032, -0.0222, -0.0056],
        [-0.0039, -0.0104,  0.0050,  ..., -0.0019,  0.0213, -0.0076],
        [ 0.0024,  0.0067, -0.0013,  ..., -0.0021,  0.0013,  0.0046]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias': tensor([ 0.0186, -0.0095,  0.0066,  ...,  0.0210,  0.0131,  0.0208],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight': tensor([[ 0.0029, -0.0233, -0.0027,  ...,  0.0144, -0.0352, -0.0105],
        [-0.0247, -0.0116,  0.0012,  ..., -0.0372,  0.0113, -0.0128],
        [ 0.0080, -0.0012, -0.0150,  ...,  0.0013, -0.0024,  0.0199],
        ...,
        [-0.0113, -0.0235, -0.0017,  ...,  0.0006, -0.0010, -0.0029],
        [ 0.0197, -0.0205, -0.0153,  ...,  0.0061,  0.0182,  0.0045],
        [-0.0173, -0.0083,  0.0412,  ...,  0.0141, -0.0057,  0.0143]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias': tensor([ 0.2690, -0.1337,  0.1326,  ...,  0.5728, -0.2661, -0.0468],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight': tensor([[ 0.0029,  0.0160,  0.0056,  ...,  0.0018,  0.0077, -0.0090],
        [ 0.0110, -0.0064,  0.0049,  ...,  0.0272,  0.0262,  0.0051],
        [-0.0114, -0.0032,  0.0054,  ...,  0.0236, -0.0132, -0.0082],
        ...,
        [-0.0007,  0.0021, -0.0044,  ..., -0.0028, -0.0311, -0.0200],
        [-0.0074, -0.0073, -0.0035,  ..., -0.0198, -0.0346, -0.0070],
        [-0.0123, -0.0216,  0.0046,  ...,  0.0036,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias': tensor([-0.0063, -0.0193, -0.0133,  ...,  0.0398,  0.0332,  0.0196],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight': tensor([1.3359, 1.2266, 1.2646,  ..., 1.9346, 1.1377, 1.3818],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias': tensor([ 0.1417,  0.0006,  0.0168,  ...,  0.0170, -0.0730,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight': tensor([[ 0.0115,  0.0003, -0.0145,  ..., -0.0144, -0.0194, -0.0104],
        [-0.0015,  0.0058,  0.0179,  ..., -0.0030,  0.0044, -0.0100],
        [-0.0029,  0.0045,  0.0084,  ..., -0.0206,  0.0133,  0.0283],
        ...,
        [ 0.0059, -0.0118, -0.0161,  ..., -0.0221, -0.0054,  0.0157],
        [ 0.0215, -0.0010,  0.0022,  ...,  0.0130,  0.0179,  0.0099],
        [ 0.0113,  0.0054, -0.0108,  ...,  0.0036,  0.0090, -0.0237]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias': tensor([-0.2153, -0.2783, -0.3320,  ..., -0.1221, -0.1306, -0.2898],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight': tensor([[-0.0038, -0.0308,  0.0166,  ..., -0.0028, -0.0180,  0.0016],
        [ 0.0179,  0.0086,  0.0044,  ...,  0.0105,  0.0129, -0.0061],
        [-0.0078, -0.0048,  0.0276,  ...,  0.0158, -0.0102,  0.0017],
        ...,
        [-0.0093,  0.0032, -0.0129,  ...,  0.0116, -0.0041, -0.0039],
        [-0.0126,  0.0043,  0.0086,  ...,  0.0042, -0.0106,  0.0038],
        [-0.0054, -0.0066, -0.0067,  ..., -0.0130, -0.0257,  0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias': tensor([ 0.0253, -0.0025, -0.0242,  ...,  0.0955,  0.0208, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight': tensor([1.6533, 1.5479, 1.5508,  ..., 0.4094, 1.3984, 1.6689],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias': tensor([-0.2152,  0.1279,  0.3982,  ...,  0.3850,  0.3862, -0.2152],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight': tensor([[ 0.0007,  0.0003,  0.0054,  ...,  0.0126,  0.0008,  0.0107],
        [-0.0359,  0.0132, -0.0041,  ..., -0.0473,  0.0050, -0.0005],
        [ 0.0122, -0.0012, -0.0178,  ..., -0.0031,  0.0207, -0.0100],
        ...,
        [ 0.0512, -0.0152, -0.0452,  ...,  0.0250, -0.0268,  0.0074],
        [ 0.0115,  0.0260, -0.0071,  ...,  0.0085,  0.0057,  0.0017],
        [ 0.0223, -0.0031, -0.0004,  ...,  0.0035, -0.0175,  0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias': tensor([-0.8135, -0.1840,  0.0576,  ..., -0.0189,  0.0277,  0.0699],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight': tensor([[ 2.6184e-02,  6.5842e-03, -6.6528e-03,  ...,  2.3901e-05,
          1.5297e-02, -1.9302e-02],
        [ 4.0741e-03,  3.0079e-03,  3.1090e-03,  ..., -9.0485e-03,
          1.0986e-02,  4.2953e-03],
        [ 4.1504e-03,  1.6336e-03, -1.1185e-02,  ...,  5.6496e-03,
          2.0889e-02, -1.3113e-04],
        ...,
        [-3.6945e-03,  1.4648e-02, -8.8348e-03,  ...,  8.1711e-03,
         -2.6073e-03,  1.3008e-02],
        [ 1.9562e-02, -1.5762e-02,  7.0877e-03,  ...,  6.5517e-04,
         -2.1744e-02, -2.0233e-02],
        [ 1.8417e-02, -1.2039e-02, -9.2239e-03,  ..., -4.6659e-04,
         -1.3191e-02, -7.4272e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias': tensor([ 0.0088,  0.0188,  0.0441,  ..., -0.0099, -0.0044,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight': tensor([[-0.0029,  0.0020, -0.0026,  ...,  0.0042, -0.0110, -0.0049],
        [-0.0278,  0.0302,  0.0003,  ..., -0.0331,  0.0236,  0.0125],
        [ 0.0239,  0.0206,  0.0083,  ..., -0.0029,  0.0212, -0.0040],
        ...,
        [ 0.0231,  0.0166, -0.0169,  ...,  0.0415, -0.0144,  0.0037],
        [ 0.0159,  0.0033, -0.0034,  ...,  0.0044, -0.0091,  0.0034],
        [ 0.0106, -0.0117, -0.0165,  ...,  0.0030, -0.0196,  0.0211]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias': tensor([-2.5234,  0.2341, -0.3838,  ..., -0.0643,  0.1272,  0.1238],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight': tensor([[-0.0296, -0.0036,  0.0027,  ...,  0.0065,  0.0073, -0.0128],
        [-0.0154, -0.0153,  0.0213,  ...,  0.0241,  0.0144,  0.0159],
        [-0.0073, -0.0148,  0.0064,  ...,  0.0165,  0.0177,  0.0191],
        ...,
        [-0.0013,  0.0025, -0.0111,  ..., -0.0081,  0.0079,  0.0101],
        [-0.0041, -0.0076, -0.0202,  ..., -0.0055,  0.0170,  0.0018],
        [ 0.0106, -0.0025,  0.0060,  ...,  0.0055, -0.0079,  0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias': tensor([ 0.0107, -0.0549,  0.0179,  ...,  0.0266,  0.0321, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight': tensor([1.3027, 1.2529, 1.3281,  ..., 1.4834, 1.1562, 1.3789],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias': tensor([ 0.1531,  0.0493, -0.0565,  ..., -0.0096, -0.0239, -0.0371],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight': tensor([[ 0.0043,  0.0120,  0.0113,  ..., -0.0241, -0.0064, -0.0090],
        [ 0.0006, -0.0211, -0.0018,  ..., -0.0029, -0.0108,  0.0110],
        [ 0.0030,  0.0094, -0.0028,  ..., -0.0025, -0.0057,  0.0185],
        ...,
        [-0.0027, -0.0314, -0.0122,  ..., -0.0098, -0.0206, -0.0127],
        [-0.0042,  0.0269, -0.0155,  ..., -0.0024, -0.0119, -0.0034],
        [-0.0102,  0.0069, -0.0109,  ..., -0.0012,  0.0015, -0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias': tensor([-0.2781, -0.2573, -0.3364,  ..., -0.3469, -0.2040, -0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight': tensor([[ 0.0010, -0.0122,  0.0169,  ...,  0.0076, -0.0051,  0.0080],
        [ 0.0136, -0.0151, -0.0033,  ..., -0.0080,  0.0146, -0.0023],
        [ 0.0173, -0.0216,  0.0123,  ...,  0.0066, -0.0024, -0.0003],
        ...,
        [-0.0117,  0.0076, -0.0053,  ...,  0.0010,  0.0026,  0.0003],
        [-0.0175,  0.0074, -0.0194,  ..., -0.0246, -0.0096, -0.0045],
        [ 0.0076,  0.0037,  0.0206,  ...,  0.0206, -0.0109,  0.0051]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias': tensor([ 0.0366, -0.0981, -0.0667,  ...,  0.0356,  0.0194, -0.0255],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight': tensor([1.7695, 1.6426, 1.7236,  ..., 0.6680, 1.5166, 1.7900],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias': tensor([-0.1890,  0.3459,  0.1487,  ...,  0.4136,  0.4312, -0.1221],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight': tensor([[ 0.0141,  0.0079,  0.0303,  ..., -0.0145,  0.0041,  0.0001],
        [-0.0112,  0.0048,  0.0240,  ..., -0.0055, -0.0139,  0.0003],
        [ 0.0167,  0.0107,  0.0269,  ..., -0.0065,  0.0130, -0.0072],
        ...,
        [-0.0014,  0.0062,  0.0020,  ..., -0.0017,  0.0170, -0.0246],
        [-0.0123, -0.0318, -0.0099,  ..., -0.0016, -0.0070, -0.0297],
        [ 0.0025,  0.0103,  0.0089,  ...,  0.0022,  0.0038,  0.0318]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias': tensor([-0.0931,  0.0089, -0.0538,  ...,  0.1041,  0.1436,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight': tensor([[-0.0085,  0.0049, -0.0003,  ...,  0.0036, -0.0302,  0.0040],
        [ 0.0075, -0.0265, -0.0065,  ..., -0.0031,  0.0134, -0.0018],
        [-0.0087, -0.0006, -0.0056,  ...,  0.0055,  0.0154,  0.0372],
        ...,
        [-0.0022, -0.0078,  0.0144,  ...,  0.0019, -0.0084,  0.0115],
        [ 0.0047, -0.0127, -0.0223,  ..., -0.0021, -0.0109,  0.0101],
        [-0.0105, -0.0005, -0.0008,  ..., -0.0030, -0.0079, -0.0039]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias': tensor([-0.0321,  0.0378,  0.0632,  ...,  0.0502, -0.0048, -0.0005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight': tensor([[-0.0095, -0.0095,  0.0312,  ...,  0.0022, -0.0092,  0.0262],
        [-0.0264, -0.0028, -0.0018,  ..., -0.0075, -0.0155, -0.0109],
        [-0.0025, -0.0001,  0.0389,  ..., -0.0119,  0.0128, -0.0002],
        ...,
        [ 0.0271, -0.0069,  0.0122,  ...,  0.0018,  0.0167, -0.0080],
        [ 0.0080, -0.0216,  0.0023,  ...,  0.0015, -0.0140,  0.0002],
        [-0.0039,  0.0055,  0.0021,  ...,  0.0071, -0.0103,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias': tensor([-0.2311,  0.2390, -0.0950,  ...,  0.0876,  0.1581,  0.0798],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight': tensor([[-0.0281, -0.0058,  0.0026,  ..., -0.0079,  0.0053, -0.0023],
        [ 0.0130, -0.0057, -0.0072,  ..., -0.0006, -0.0015, -0.0051],
        [-0.0112,  0.0132,  0.0089,  ..., -0.0184,  0.0022, -0.0036],
        ...,
        [ 0.0086,  0.0047, -0.0106,  ..., -0.0117, -0.0147, -0.0069],
        [ 0.0147, -0.0031, -0.0165,  ...,  0.0125, -0.0091,  0.0107],
        [ 0.0214,  0.0008, -0.0262,  ..., -0.0205, -0.0144,  0.0057]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias': tensor([-0.0645, -0.0639,  0.0044,  ..., -0.0346, -0.0156, -0.0320],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight': tensor([1.3975, 1.3584, 1.4883,  ..., 1.8799, 1.3203, 1.4980],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias': tensor([ 0.0757, -0.1133, -0.0580,  ..., -0.0255, -0.0899, -0.1061],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight': tensor([[-7.1793e-03,  4.6234e-03,  1.7502e-02,  ..., -1.0124e-02,
          1.3245e-02, -6.4430e-03],
        [-1.6571e-02,  1.1040e-02, -5.1537e-03,  ..., -6.7616e-04,
         -2.2491e-02, -9.1019e-03],
        [-7.6675e-04,  2.2156e-02,  1.0216e-02,  ..., -4.4708e-03,
         -1.6510e-02, -2.4704e-02],
        ...,
        [-2.9205e-02, -7.1602e-03,  8.7559e-05,  ..., -9.7656e-03,
          1.6312e-02,  2.7145e-02],
        [-1.2413e-02,  6.9084e-03,  2.4399e-02,  ..., -7.0381e-03,
         -7.9803e-03,  9.6130e-03],
        [ 6.4039e-04, -4.3259e-03,  4.3121e-02,  ..., -3.9101e-03,
         -1.3245e-02,  1.4565e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias': tensor([-0.3418, -0.2771, -0.3467,  ..., -0.3992, -0.2385, -0.2927],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight': tensor([[-9.4452e-03,  1.2772e-02,  1.8539e-02,  ..., -2.6276e-02,
          4.2343e-04, -1.3672e-02],
        [ 3.2593e-02,  8.7070e-04, -2.8477e-03,  ..., -8.7814e-03,
          1.1383e-02, -3.0182e-02],
        [-4.3488e-03, -2.7359e-02,  1.8482e-03,  ..., -6.5002e-03,
          2.6016e-02,  3.3539e-02],
        ...,
        [-4.1504e-03,  1.6251e-02,  7.8354e-03,  ...,  1.4816e-02,
         -1.9627e-03, -6.3002e-05],
        [ 6.4125e-03, -1.6647e-02,  4.3945e-03,  ...,  1.2833e-02,
         -1.5268e-03, -1.7975e-02],
        [-1.8167e-03, -1.1734e-02, -1.4511e-02,  ...,  3.0396e-02,
          1.1108e-02, -9.7580e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias': tensor([-0.0361, -0.0392,  0.0150,  ..., -0.0163,  0.0041, -0.0078],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight': tensor([2.1113, 2.0137, 2.0352,  ..., 0.7090, 1.8164, 2.2012],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias': tensor([-0.1631, -0.1508,  0.1484,  ...,  0.4434,  0.6812, -0.3279],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight': tensor([[-9.9716e-03, -2.5208e-02,  8.4457e-03,  ...,  1.3168e-02,
         -5.3942e-05, -2.8748e-02],
        [-3.1233e-05,  1.3992e-02, -2.2476e-02,  ...,  6.3232e-02,
         -1.4221e-02, -1.4404e-02],
        [-5.1785e-04, -3.1403e-02,  6.5517e-04,  ..., -1.0399e-02,
          1.1505e-02, -2.8076e-03],
        ...,
        [-6.2132e-04, -1.0201e-02,  1.3947e-02,  ..., -5.4810e-02,
         -8.1787e-03, -2.0981e-02],
        [ 9.8572e-03, -1.7899e-02,  1.1734e-02,  ..., -4.1885e-03,
          1.4870e-02,  1.1244e-03],
        [ 1.5884e-02,  2.2827e-02,  4.2000e-03,  ..., -4.3091e-02,
         -2.2690e-02, -1.3191e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias': tensor([ 0.2656, -0.2185,  0.0432,  ..., -0.1787, -0.2061,  0.0742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight': tensor([[ 0.0261,  0.0077, -0.0120,  ..., -0.0027, -0.0164, -0.0107],
        [-0.0080,  0.0102,  0.0077,  ...,  0.0039,  0.0010, -0.0050],
        [ 0.0017, -0.0101, -0.0256,  ...,  0.0058, -0.0145, -0.0055],
        ...,
        [-0.0161,  0.0100, -0.0047,  ..., -0.0049, -0.0208,  0.0245],
        [ 0.0115, -0.0098,  0.0141,  ...,  0.0035, -0.0129, -0.0005],
        [-0.0111, -0.0270,  0.0220,  ..., -0.0022, -0.0052, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias': tensor([-0.0182,  0.0114,  0.1055,  ..., -0.0048, -0.0138,  0.0093],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight': tensor([[-0.0116, -0.0250, -0.0204,  ...,  0.0060, -0.0022, -0.0020],
        [ 0.0243,  0.0011, -0.0106,  ...,  0.0480, -0.0213,  0.0138],
        [ 0.0116, -0.0210, -0.0045,  ..., -0.0067, -0.0268, -0.0189],
        ...,
        [ 0.0013,  0.0050,  0.0468,  ..., -0.0500,  0.0203,  0.0043],
        [ 0.0273, -0.0117,  0.0099,  ..., -0.0033, -0.0067,  0.0015],
        [-0.0062,  0.0012,  0.0167,  ..., -0.0361, -0.0010,  0.0275]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias': tensor([ 0.2439, -0.1146,  0.0887,  ...,  0.2213,  0.1515, -0.0186],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight': tensor([[-3.0136e-02,  1.2367e-02, -9.5749e-03,  ...,  1.8692e-02,
          9.2697e-03, -4.0054e-03],
        [-3.6682e-02, -9.7504e-03,  7.6950e-05,  ..., -1.0941e-02,
          8.2474e-03, -8.6546e-04],
        [ 1.9424e-02, -2.1729e-02,  5.8022e-03,  ...,  6.4888e-03,
         -4.6577e-03, -6.9504e-03],
        ...,
        [-7.0953e-03, -1.1024e-02,  1.4248e-03,  ...,  3.1490e-03,
         -7.8735e-03, -1.8097e-02],
        [ 1.8778e-03, -1.1490e-02, -8.2855e-03,  ..., -1.9104e-02,
          7.3166e-03, -8.8959e-03],
        [-8.1558e-03,  1.7426e-02,  1.1551e-02,  ..., -4.8790e-03,
          5.9700e-03,  9.9030e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias': tensor([-0.0732,  0.0212,  0.0239,  ...,  0.0091, -0.0001, -0.0141],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight': tensor([1.3848, 1.3320, 1.4814,  ..., 1.5195, 1.3164, 1.4180],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias': tensor([ 0.0473, -0.0936, -0.0594,  ...,  0.0325,  0.0149, -0.0659],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight': tensor([[ 1.5793e-02, -8.3160e-03,  2.2156e-02,  ...,  1.8814e-02,
         -5.4436e-03, -1.1604e-02],
        [ 1.5007e-02, -9.5978e-03, -2.5284e-02,  ..., -1.6510e-02,
         -3.3539e-02, -2.3102e-02],
        [-2.1622e-02,  2.0309e-02,  2.1801e-03,  ...,  7.5798e-03,
          1.4145e-02, -7.3433e-03],
        ...,
        [-4.5624e-03, -2.5757e-02,  6.9199e-03,  ...,  3.5572e-03,
          1.4694e-02, -2.2339e-02],
        [-9.1791e-06,  7.1487e-03, -1.3298e-02,  ...,  5.6610e-03,
          4.4975e-03,  1.1978e-02],
        [-5.8289e-03,  5.1689e-03, -1.4862e-02,  ...,  1.8585e-02,
          9.6655e-04,  1.1856e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias': tensor([-0.2683, -0.3921, -0.3279,  ..., -0.3718, -0.2028, -0.3127],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight': tensor([[-0.0059, -0.0140,  0.0130,  ...,  0.0043,  0.0292, -0.0014],
        [ 0.0265, -0.0073, -0.0116,  ..., -0.0211,  0.0206,  0.0263],
        [ 0.0022, -0.0233,  0.0002,  ...,  0.0067, -0.0096, -0.0120],
        ...,
        [ 0.0080, -0.0016,  0.0073,  ..., -0.0021, -0.0057, -0.0010],
        [ 0.0048, -0.0163, -0.0040,  ...,  0.0130, -0.0188,  0.0429],
        [-0.0011, -0.0383, -0.0151,  ..., -0.0132,  0.0248,  0.0216]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias': tensor([ 0.0359,  0.0342,  0.0545,  ...,  0.0745, -0.0070,  0.0030],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight': tensor([2.5176, 2.3496, 2.4785,  ..., 0.5151, 2.0352, 2.4492],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias': tensor([-0.2339, -0.0297,  0.1533,  ...,  0.4067,  0.7363, -0.2054],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0246, -0.0315,  ...,  0.0246, -0.0050,  0.0121],
        [ 0.0096,  0.0193,  0.0106,  ..., -0.0207, -0.0075,  0.0043],
        [ 0.0199,  0.0022, -0.0148,  ..., -0.0771, -0.0211,  0.0064],
        ...,
        [ 0.0369,  0.0040, -0.0087,  ..., -0.0215,  0.0106,  0.0167],
        [-0.0061, -0.0050, -0.0032,  ..., -0.0078,  0.0147,  0.0186],
        [ 0.0009,  0.0079, -0.0195,  ..., -0.0096, -0.0309,  0.0012]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias': tensor([ 0.0911, -0.1252, -0.4846,  ...,  0.0673, -0.0733,  0.0197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight': tensor([[ 0.0141,  0.0237,  0.0094,  ..., -0.0007, -0.0127, -0.0134],
        [ 0.0092, -0.0071,  0.0201,  ...,  0.0027, -0.0176, -0.0013],
        [ 0.0039, -0.0016, -0.0055,  ...,  0.0065, -0.0001, -0.0049],
        ...,
        [ 0.0073, -0.0355, -0.0101,  ...,  0.0047, -0.0010, -0.0099],
        [-0.0019,  0.0097, -0.0335,  ..., -0.0019,  0.0006, -0.0019],
        [ 0.0030, -0.0076,  0.0026,  ..., -0.0004,  0.0043, -0.0152]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias': tensor([ 0.0290,  0.0252,  0.0343,  ...,  0.0027, -0.0045, -0.0545],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight': tensor([[ 0.0060, -0.0019, -0.0088,  ...,  0.0198, -0.0025, -0.0177],
        [ 0.0059,  0.0067,  0.0215,  ..., -0.0244, -0.0294,  0.0024],
        [ 0.0271,  0.0004, -0.0182,  ..., -0.0876,  0.0076, -0.0006],
        ...,
        [-0.0081,  0.0160, -0.0380,  ..., -0.0249, -0.0083,  0.0045],
        [ 0.0112, -0.0182, -0.0261,  ..., -0.0056, -0.0009, -0.0319],
        [ 0.0435,  0.0031,  0.0118,  ..., -0.0163,  0.0102, -0.0193]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias': tensor([ 0.0622,  0.0999, -0.5308,  ..., -0.1455,  0.0368, -0.1086],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight': tensor([[ 4.6425e-03, -2.0313e-03,  2.7237e-02,  ...,  1.0216e-02,
         -2.0187e-02,  1.1955e-02],
        [-5.8823e-03,  2.6627e-02,  7.8506e-03,  ...,  3.9864e-03,
         -1.8646e-02,  2.6762e-05],
        [-5.6601e-04,  5.0240e-03,  2.1591e-02,  ...,  1.1375e-02,
          6.1035e-03,  7.7581e-04],
        ...,
        [ 9.0256e-03, -4.1656e-03, -1.2932e-02,  ...,  9.0778e-05,
          1.9577e-02, -6.6452e-03],
        [ 1.5488e-02,  5.1928e-04,  1.3100e-02,  ..., -2.1057e-02,
         -4.6921e-03,  1.0338e-02],
        [ 3.2501e-03, -2.0432e-02, -2.8076e-02,  ..., -8.2169e-03,
         -2.1858e-03,  3.8376e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias': tensor([ 0.0169,  0.0075, -0.0464,  ...,  0.0064, -0.0125, -0.0271],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight': tensor([1.4844, 1.5352, 1.5859,  ..., 1.5234, 1.4395, 1.5938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias': tensor([ 0.1630, -0.0892, -0.0373,  ..., -0.0082, -0.0609, -0.1628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight': tensor([[-0.0057, -0.0090,  0.0211,  ...,  0.0072, -0.0180, -0.0063],
        [ 0.0278,  0.0188,  0.0136,  ..., -0.0074,  0.0133, -0.0087],
        [-0.0168,  0.0028, -0.0226,  ..., -0.0184, -0.0072, -0.0020],
        ...,
        [ 0.0011, -0.0155, -0.0045,  ..., -0.0092, -0.0268,  0.0125],
        [ 0.0054, -0.0030,  0.0160,  ...,  0.0257, -0.0181, -0.0068],
        [ 0.0045,  0.0018,  0.0164,  ..., -0.0108, -0.0191, -0.0004]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias': tensor([-0.2793, -0.3452, -0.2959,  ..., -0.1838, -0.1981, -0.2494],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight': tensor([[-0.0017, -0.0146,  0.0010,  ...,  0.0037, -0.0001,  0.0201],
        [ 0.0174, -0.0161, -0.0016,  ..., -0.0007, -0.0096, -0.0005],
        [ 0.0072,  0.0077, -0.0210,  ...,  0.0165, -0.0019, -0.0208],
        ...,
        [ 0.0195, -0.0092,  0.0151,  ..., -0.0062, -0.0071, -0.0216],
        [ 0.0159,  0.0006,  0.0077,  ..., -0.0073,  0.0030,  0.0091],
        [ 0.0062,  0.0206,  0.0089,  ...,  0.0090, -0.0033, -0.0063]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias': tensor([0.0065, 0.0102, 0.0046,  ..., 0.0065, 0.0796, 0.0695],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight': tensor([2.6719, 2.5625, 2.7695,  ..., 0.6802, 2.2539, 2.7422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias': tensor([-0.0354,  0.2776,  0.4175,  ...,  0.5674,  0.5327, -0.4670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight': tensor([[-0.0087,  0.0027,  0.0113,  ..., -0.0616,  0.0051, -0.0137],
        [-0.0173,  0.0047,  0.0124,  ...,  0.0239, -0.0160,  0.0129],
        [ 0.0097, -0.0005, -0.0050,  ...,  0.0011,  0.0099, -0.0130],
        ...,
        [-0.0052,  0.0120,  0.0098,  ..., -0.0244,  0.0038,  0.0010],
        [ 0.0119, -0.0235, -0.0134,  ..., -0.0140, -0.0140,  0.0065],
        [ 0.0291,  0.0226, -0.0254,  ..., -0.0035, -0.0137,  0.0350]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias': tensor([ 0.2783, -0.2036, -0.0648,  ...,  0.1705,  0.1809,  0.1080],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight': tensor([[-0.0184,  0.0137,  0.0067,  ..., -0.0029,  0.0099,  0.0297],
        [-0.0110,  0.0184,  0.0020,  ...,  0.0024, -0.0151,  0.0009],
        [ 0.0191, -0.0126,  0.0212,  ...,  0.0024, -0.0348,  0.0026],
        ...,
        [ 0.0005,  0.0007, -0.0011,  ...,  0.0046, -0.0222, -0.0393],
        [ 0.0117,  0.0042,  0.0002,  ..., -0.0006,  0.0005, -0.0083],
        [-0.0062,  0.0128,  0.0124,  ..., -0.0037, -0.0134,  0.0008]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias': tensor([-0.0114,  0.0300,  0.0252,  ..., -0.0060,  0.0197,  0.0400],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight': tensor([[ 1.4931e-02, -1.2466e-02,  2.4918e-02,  ..., -5.9814e-02,
         -4.3068e-03,  1.2131e-02],
        [-1.6464e-02, -9.9030e-03, -1.1108e-02,  ...,  2.3956e-02,
         -3.6163e-02,  1.1703e-02],
        [ 1.0757e-02,  2.5730e-03, -7.3338e-04,  ...,  2.4662e-03,
          6.1493e-03,  6.6528e-03],
        ...,
        [ 5.1003e-03, -7.8678e-06,  5.1041e-03,  ..., -4.5410e-02,
         -3.1738e-02,  1.8631e-02],
        [ 1.7502e-02, -4.1084e-03,  3.9978e-03,  ..., -1.8753e-02,
         -2.2335e-03,  2.1057e-03],
        [ 1.7303e-02,  6.7902e-03,  1.1360e-02,  ...,  8.0719e-03,
         -5.0278e-03,  2.1713e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias': tensor([-0.2339,  0.0393, -0.0323,  ..., -0.1953,  0.0200,  0.0049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight': tensor([[ 0.0254,  0.0050,  0.0049,  ...,  0.0120, -0.0121,  0.0091],
        [ 0.0248, -0.0193, -0.0093,  ..., -0.0044, -0.0032,  0.0151],
        [ 0.0053,  0.0182, -0.0142,  ..., -0.0130, -0.0033, -0.0087],
        ...,
        [ 0.0006, -0.0051, -0.0173,  ...,  0.0031, -0.0128,  0.0099],
        [ 0.0081, -0.0134,  0.0246,  ...,  0.0185, -0.0136,  0.0109],
        [-0.0261, -0.0152, -0.0080,  ...,  0.0230, -0.0056,  0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias': tensor([-0.0083,  0.0091, -0.0955,  ..., -0.0067,  0.0003, -0.0047],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight': tensor([1.5762, 1.4580, 1.5850,  ..., 1.7383, 1.4209, 1.5967],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias': tensor([ 0.1272, -0.2208, -0.0098,  ..., -0.0831, -0.0858, -0.1576],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight': tensor([[-0.0051,  0.0014, -0.0012,  ...,  0.0091, -0.0065, -0.0086],
        [-0.0191,  0.0118,  0.0002,  ..., -0.0095, -0.0148,  0.0134],
        [-0.0012, -0.0324,  0.0047,  ..., -0.0084,  0.0050, -0.0089],
        ...,
        [ 0.0005, -0.0097, -0.0229,  ..., -0.0036, -0.0164, -0.0044],
        [ 0.0058, -0.0019, -0.0019,  ...,  0.0053,  0.0177,  0.0073],
        [ 0.0128,  0.0044, -0.0019,  ..., -0.0147,  0.0180, -0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias': tensor([-0.1597, -0.3298, -0.3066,  ..., -0.3003, -0.3157, -0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight': tensor([[-0.0060, -0.0143,  0.0279,  ..., -0.0150,  0.0291,  0.0124],
        [ 0.0095, -0.0208, -0.0114,  ...,  0.0116, -0.0289,  0.0051],
        [-0.0165,  0.0403, -0.0052,  ...,  0.0008, -0.0144, -0.0153],
        ...,
        [-0.0120,  0.0119, -0.0007,  ...,  0.0051,  0.0161, -0.0073],
        [ 0.0291,  0.0090, -0.0140,  ...,  0.0286,  0.0029, -0.0079],
        [ 0.0233, -0.0179, -0.0138,  ..., -0.0036, -0.0180, -0.0041]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias': tensor([ 0.0113,  0.0318, -0.0128,  ..., -0.0561, -0.0155,  0.0321],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight': tensor([2.7773, 2.7402, 2.7402,  ..., 0.8696, 2.4961, 2.8711],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias': tensor([-0.1473, -0.0198,  0.2091,  ...,  0.4590,  0.5410, -0.2742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight': tensor([[ 0.0005, -0.0174, -0.0133,  ..., -0.0195,  0.0176,  0.0196],
        [ 0.0332, -0.0111, -0.0092,  ..., -0.0143,  0.0277, -0.0138],
        [-0.0094,  0.0108, -0.0135,  ..., -0.0078, -0.0209, -0.0013],
        ...,
        [ 0.0136,  0.0224,  0.0235,  ..., -0.0533, -0.0095,  0.0097],
        [-0.0183, -0.0031, -0.0219,  ..., -0.0209, -0.0113,  0.0082],
        [ 0.0187,  0.0257,  0.0352,  ..., -0.0150,  0.0010,  0.0060]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias': tensor([-0.2089,  0.1558,  0.3555,  ...,  0.0323,  0.1013,  0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight': tensor([[-0.0096,  0.0058, -0.0198,  ...,  0.0084,  0.0249,  0.0066],
        [ 0.0346, -0.0048, -0.0196,  ..., -0.0008, -0.0481, -0.0151],
        [-0.0034,  0.0091,  0.0039,  ..., -0.0047,  0.0017, -0.0073],
        ...,
        [-0.0277, -0.0315,  0.0064,  ..., -0.0131, -0.0027,  0.0125],
        [ 0.0013,  0.0095,  0.0286,  ..., -0.0024,  0.0112,  0.0018],
        [-0.0154,  0.0043, -0.0169,  ...,  0.0051,  0.0013, -0.0213]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias': tensor([0.0214, 0.0242, 0.0006,  ..., 0.0194, 0.0418, 0.0340],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight': tensor([[-0.0110, -0.0187, -0.0399,  ..., -0.0132,  0.0016,  0.0080],
        [ 0.0197,  0.0169,  0.0061,  ..., -0.0240,  0.0292,  0.0127],
        [-0.0047, -0.0227, -0.0048,  ..., -0.0150, -0.0014,  0.0108],
        ...,
        [-0.0113,  0.0006, -0.0214,  ..., -0.0389, -0.0254,  0.0096],
        [ 0.0066,  0.0193,  0.0392,  ...,  0.0004,  0.0306, -0.0154],
        [-0.0041,  0.0141, -0.0124,  ..., -0.0156, -0.0206,  0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias': tensor([-0.0377, -0.0410, -0.0185,  ..., -0.2778,  0.1395,  0.1525],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight': tensor([[-1.2112e-03,  2.4259e-05, -4.5753e-04,  ...,  4.1847e-03,
          3.2597e-03, -3.2745e-02],
        [-1.3557e-02, -5.1613e-03,  2.0218e-02,  ..., -7.0801e-03,
         -2.9678e-02, -3.8872e-03],
        [-2.0355e-02, -4.8676e-03,  1.2039e-02,  ...,  1.1337e-02,
         -5.5161e-03, -1.0376e-02],
        ...,
        [ 1.2032e-02,  1.7944e-02, -4.4212e-03,  ...,  3.3722e-02,
         -1.9394e-02, -2.0691e-02],
        [-1.6998e-02,  2.0340e-02, -9.7885e-03,  ..., -4.0588e-03,
          4.5967e-03, -7.2937e-03],
        [-1.6357e-02, -1.8204e-02,  1.9684e-02,  ...,  1.2749e-02,
         -2.2552e-02, -1.4832e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias': tensor([-0.0427,  0.0264, -0.0947,  ..., -0.0744, -0.0230, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight': tensor([1.6475, 1.5273, 1.6768,  ..., 1.8574, 1.4951, 1.6426],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias': tensor([-0.0313, -0.3167, -0.0297,  ..., -0.0391, -0.0746, -0.2402],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight': tensor([[-0.0260, -0.0154,  0.0028,  ..., -0.0228, -0.0295, -0.0447],
        [ 0.0029, -0.0058,  0.0197,  ...,  0.0138,  0.0183,  0.0026],
        [ 0.0218, -0.0178,  0.0015,  ..., -0.0087,  0.0014,  0.0125],
        ...,
        [ 0.0404,  0.0179, -0.0153,  ...,  0.0049,  0.0196, -0.0120],
        [ 0.0015, -0.0189,  0.0088,  ...,  0.0184, -0.0162, -0.0341],
        [ 0.0035, -0.0139, -0.0161,  ...,  0.0040, -0.0222, -0.0067]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias': tensor([-0.3091, -0.1617, -0.2668,  ..., -0.2510, -0.2261, -0.2350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight': tensor([[-0.0030, -0.0123, -0.0188,  ...,  0.0186, -0.0332, -0.0181],
        [ 0.0014, -0.0037, -0.0307,  ..., -0.0058,  0.0160,  0.0274],
        [ 0.0273, -0.0119, -0.0110,  ..., -0.0013, -0.0041, -0.0059],
        ...,
        [ 0.0018, -0.0187, -0.0384,  ...,  0.0141,  0.0053,  0.0090],
        [ 0.0151, -0.0128, -0.0045,  ...,  0.0167, -0.0064,  0.0077],
        [ 0.0001,  0.0021,  0.0336,  ..., -0.0046, -0.0128,  0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias': tensor([ 0.1198, -0.0191,  0.1595,  ..., -0.0292, -0.0284, -0.0580],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight': tensor([3.1777, 3.2344, 3.2090,  ..., 1.1455, 2.6172, 3.2363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias': tensor([-0.3699,  0.0534, -0.3181,  ...,  0.1720,  0.3350, -0.2013],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight': tensor([[ 0.0132,  0.0254, -0.0020,  ..., -0.0305,  0.0047,  0.0051],
        [ 0.0022, -0.0257,  0.0199,  ..., -0.0184,  0.0286,  0.0047],
        [-0.0092, -0.0116,  0.0196,  ..., -0.0357,  0.0290,  0.0171],
        ...,
        [ 0.0071, -0.0053,  0.0001,  ..., -0.0139, -0.0043, -0.0191],
        [-0.0128,  0.0084, -0.0034,  ..., -0.0035, -0.0175, -0.0111],
        [ 0.0023, -0.0036, -0.0063,  ...,  0.0125, -0.0132,  0.0166]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias': tensor([ 2.2266,  1.3135, -0.9771,  ...,  0.3726,  2.3047,  0.1869],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight': tensor([[-0.0117,  0.0124, -0.0160,  ...,  0.0026,  0.0036,  0.0293],
        [ 0.0022, -0.0097, -0.0008,  ..., -0.0094,  0.0017, -0.0152],
        [-0.0117, -0.0052, -0.0132,  ...,  0.0201,  0.0020, -0.0049],
        ...,
        [ 0.0122, -0.0035, -0.0111,  ..., -0.0017,  0.0214,  0.0207],
        [-0.0134,  0.0110, -0.0031,  ...,  0.0010,  0.0070,  0.0225],
        [ 0.0003,  0.0153,  0.0004,  ...,  0.0096,  0.0122,  0.0161]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias': tensor([ 0.0095, -0.0149, -0.0342,  ...,  0.0316,  0.0107, -0.0553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight': tensor([[ 2.4475e-02,  1.0361e-02, -3.1738e-03,  ...,  6.3629e-03,
         -4.1161e-03,  4.0770e-05],
        [ 6.4735e-03, -1.1032e-02, -4.1046e-03,  ...,  2.4471e-03,
         -7.7009e-04,  3.3226e-03],
        [-2.2324e-02, -5.0497e-04, -2.1210e-02,  ..., -6.5186e-02,
         -3.9253e-03, -4.9324e-03],
        ...,
        [ 7.4692e-03, -2.1229e-03, -2.2095e-02,  ..., -3.7079e-02,
         -3.3173e-02,  2.9621e-03],
        [-2.3987e-02, -1.8463e-03, -3.8791e-04,  ..., -1.6312e-02,
         -2.0157e-02,  1.9180e-02],
        [ 5.5695e-03, -1.0750e-02,  1.4153e-03,  ...,  1.7136e-02,
         -1.8829e-02, -3.1219e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias': tensor([ 0.0942, -0.0380, -0.0066,  ..., -0.2206,  0.0908,  0.0343],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight': tensor([[ 0.0108, -0.0169,  0.0143,  ..., -0.0040, -0.0186, -0.0120],
        [-0.0099,  0.0158, -0.0007,  ..., -0.0126,  0.0125, -0.0013],
        [ 0.0059, -0.0186,  0.0080,  ...,  0.0038,  0.0261, -0.0122],
        ...,
        [ 0.0193, -0.0006, -0.0168,  ..., -0.0111, -0.0033,  0.0045],
        [ 0.0071,  0.0175, -0.0099,  ...,  0.0238,  0.0111,  0.0132],
        [ 0.0269,  0.0227,  0.0074,  ..., -0.0048, -0.0153, -0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias': tensor([ 0.1117, -0.0344, -0.0097,  ..., -0.0479, -0.0558, -0.0235],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight': tensor([1.5781, 1.5361, 1.5830,  ..., 0.8071, 1.4404, 1.7129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias': tensor([ 0.0493, -0.2202, -0.1034,  ...,  0.0678, -0.1000, -0.2034],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight': tensor([[-0.0206, -0.0153,  0.0054,  ...,  0.0216,  0.0042, -0.0064],
        [-0.0240,  0.0083,  0.0154,  ..., -0.0026,  0.0077, -0.0042],
        [ 0.0143,  0.0016,  0.0010,  ...,  0.0362,  0.0050,  0.0193],
        ...,
        [ 0.0191,  0.0038,  0.0125,  ..., -0.0049, -0.0139, -0.0164],
        [ 0.0050,  0.0037,  0.0237,  ..., -0.0271,  0.0079, -0.0093],
        [ 0.0163,  0.0038, -0.0141,  ..., -0.0026, -0.0191,  0.0084]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias': tensor([-0.2673, -0.2559, -0.2236,  ..., -0.2888, -0.2781, -0.0958],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight': tensor([[-0.0093, -0.0160, -0.0221,  ...,  0.0137, -0.0174, -0.0188],
        [-0.0096,  0.0156, -0.0179,  ..., -0.0231,  0.0060, -0.0123],
        [ 0.0032, -0.0022,  0.0147,  ..., -0.0053,  0.0070,  0.0076],
        ...,
        [-0.0122, -0.0089,  0.0011,  ...,  0.0205,  0.0041, -0.0117],
        [ 0.0056, -0.0073, -0.0155,  ..., -0.0081, -0.0361,  0.0044],
        [ 0.0310,  0.0010,  0.0081,  ..., -0.0060, -0.0118, -0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias': tensor([-0.0192, -0.0717,  0.1105,  ..., -0.1528,  0.0851, -0.0401],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight': tensor([3.1602, 3.0371, 2.9180,  ..., 1.5098, 2.5527, 3.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias': tensor([ 0.2227,  0.6216, -0.4958,  ...,  0.2568,  0.0677, -0.4553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight': tensor([[ 0.0037,  0.0141,  0.0131,  ...,  0.0058,  0.0128,  0.0105],
        [ 0.0020, -0.0168, -0.0078,  ...,  0.0242, -0.0173, -0.0008],
        [ 0.0030,  0.0062, -0.0284,  ..., -0.0097,  0.0236,  0.0083],
        ...,
        [-0.0080, -0.0243, -0.0079,  ..., -0.0201, -0.0240, -0.0208],
        [ 0.0029,  0.0056,  0.0167,  ...,  0.0065, -0.0012, -0.0019],
        [-0.0047, -0.0198, -0.0200,  ...,  0.0153,  0.0093, -0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias': tensor([ 0.9746, -1.5684,  4.0703,  ..., -4.7695,  2.3730,  0.0641],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight': tensor([[-0.0094,  0.0040, -0.0081,  ...,  0.0087,  0.0034, -0.0086],
        [-0.0218, -0.0027,  0.0096,  ...,  0.0072, -0.0114, -0.0138],
        [-0.0069,  0.0196,  0.0128,  ...,  0.0089, -0.0430,  0.0282],
        ...,
        [ 0.0080, -0.0076,  0.0247,  ..., -0.0006,  0.0264, -0.0060],
        [-0.0081,  0.0084,  0.0222,  ...,  0.0080, -0.0070,  0.0124],
        [-0.0113,  0.0073,  0.0137,  ..., -0.0100, -0.0085,  0.0073]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias': tensor([-0.0650, -0.0600,  0.0630,  ..., -0.0726,  0.0070, -0.1204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight': tensor([[ 0.0016,  0.0027, -0.0018,  ...,  0.0349, -0.0049, -0.0009],
        [ 0.0076,  0.0003, -0.0250,  ...,  0.0064,  0.0064,  0.0147],
        [-0.0011, -0.0325, -0.0602,  ...,  0.0003, -0.0238,  0.0107],
        ...,
        [ 0.0233,  0.0226,  0.0270,  ...,  0.0236, -0.0239, -0.0167],
        [ 0.0041, -0.0097, -0.0143,  ..., -0.0173, -0.0098,  0.0124],
        [ 0.0090, -0.0034,  0.0003,  ...,  0.0278,  0.0114,  0.0061]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias': tensor([-0.4348, -0.0033, -0.1771,  ..., -0.0897,  0.1703,  0.3945],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight': tensor([[ 0.0021,  0.0206, -0.0078,  ..., -0.0072, -0.0010,  0.0115],
        [ 0.0005,  0.0042, -0.0142,  ...,  0.0190, -0.0119, -0.0008],
        [ 0.0061, -0.0182,  0.0112,  ..., -0.0376, -0.0023, -0.0042],
        ...,
        [-0.0143,  0.0111, -0.0015,  ..., -0.0087,  0.0175, -0.0019],
        [-0.0039,  0.0022,  0.0231,  ..., -0.0050,  0.0082, -0.0150],
        [ 0.0005, -0.0005, -0.0158,  ..., -0.0120, -0.0067, -0.0141]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias': tensor([-0.0269, -0.0574,  0.0638,  ..., -0.1498,  0.0551, -0.1482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight': tensor([1.5703, 1.8379, 1.9336,  ..., 0.8516, 1.4707, 1.7686],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias': tensor([0.3889, 0.2372, 0.1531,  ..., 0.6260, 0.2163, 0.1549],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight': tensor([[-1.1892e-03,  3.9005e-03, -5.7487e-03,  ...,  4.7989e-03,
         -4.2915e-03, -2.5539e-03],
        [ 1.5236e-02, -2.3232e-03, -3.3325e-02,  ...,  2.3758e-02,
         -1.0595e-03, -3.8986e-03],
        [ 2.0737e-02,  7.2479e-03, -3.0842e-03,  ..., -5.4207e-03,
          2.6047e-02, -1.4210e-03],
        ...,
        [ 7.4120e-03, -2.9163e-03,  3.3661e-02,  ..., -4.4785e-03,
          9.1400e-03, -1.5297e-02],
        [-4.3964e-04,  8.5297e-03, -1.5350e-02,  ..., -1.3519e-02,
         -6.6490e-03,  5.9700e-04],
        [-7.5579e-05,  1.0449e-04,  8.8196e-03,  ..., -1.0658e-02,
         -6.6032e-03, -5.4703e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias': tensor([-0.3184, -0.2345, -0.2834,  ..., -0.2498, -0.1849, -0.2729],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight': tensor([[ 0.0369,  0.0093, -0.0179,  ..., -0.0141, -0.0035,  0.0064],
        [ 0.0050,  0.0101,  0.0117,  ...,  0.0070, -0.0066, -0.0147],
        [-0.0015,  0.0263,  0.0119,  ..., -0.0270,  0.0052, -0.0028],
        ...,
        [ 0.0133,  0.0236, -0.0152,  ...,  0.0251, -0.0268, -0.0321],
        [ 0.0021, -0.0061,  0.0079,  ..., -0.0029,  0.0145, -0.0033],
        [-0.0097,  0.0175, -0.0111,  ..., -0.0278, -0.0016, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias': tensor([-0.1587, -0.0068,  0.1970,  ...,  0.0549, -0.0199,  0.0069],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight': tensor([2.5664, 2.3809, 2.5742,  ..., 1.8262, 2.4121, 2.7520],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias': tensor([ 0.1838,  0.3330, -0.2296,  ..., -0.1086,  0.5938, -0.2812],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight': tensor([[ 0.0305, -0.0035, -0.0098,  ...,  0.0054, -0.0111,  0.0049],
        [-0.0194,  0.0099,  0.0032,  ...,  0.0125,  0.0277, -0.0057],
        [ 0.0115,  0.0072, -0.0170,  ...,  0.0162,  0.0032,  0.0142],
        ...,
        [ 0.0076, -0.0034,  0.0187,  ...,  0.0278, -0.0174, -0.0046],
        [-0.0037, -0.0002,  0.0051,  ..., -0.0108,  0.0012,  0.0065],
        [-0.0047, -0.0013,  0.0154,  ...,  0.0158, -0.0106,  0.0013]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias': tensor([-0.0001,  0.0002, -0.0072,  ...,  0.0011, -0.0007, -0.0008],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight': tensor([[ 0.0221, -0.0052,  0.0127,  ..., -0.0090, -0.0092, -0.0165],
        [-0.0569, -0.0251, -0.0167,  ..., -0.0070, -0.0093, -0.0182],
        [-0.0159, -0.0159,  0.0239,  ...,  0.0133,  0.0071,  0.0088],
        ...,
        [ 0.0025,  0.0141, -0.0087,  ...,  0.0007, -0.0157, -0.0012],
        [ 0.0053,  0.0023, -0.0199,  ...,  0.0264,  0.0148, -0.0300],
        [-0.0040,  0.0095, -0.0180,  ..., -0.0396, -0.0316, -0.0156]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias': tensor([-0.0095, -0.0084,  0.0243,  ...,  0.1217, -0.0273,  0.0116],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight': tensor([[ 1.3329e-02, -5.8022e-03,  2.2945e-03,  ...,  1.0509e-03,
          2.1591e-02, -3.7422e-03],
        [-1.7593e-02,  9.9182e-03,  2.1652e-02,  ..., -1.7380e-02,
         -1.1452e-02, -1.1536e-02],
        [-4.2648e-03,  3.6955e-06,  8.7585e-03,  ...,  5.5428e-03,
          1.0963e-02, -8.2855e-03],
        ...,
        [ 2.6302e-03, -6.2828e-03,  1.8387e-02,  ...,  2.4658e-02,
         -1.4015e-02, -1.8509e-02],
        [-1.9140e-03, -1.3588e-02, -1.2770e-03,  ..., -1.8143e-02,
         -2.0309e-02, -2.0172e-02],
        [-1.6346e-03,  5.2338e-03, -1.7044e-02,  ..., -4.7073e-03,
          1.5930e-02,  1.8097e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias': tensor([ 0.0486, -0.0525, -1.9268,  ...,  0.0309,  0.1466, -0.0662],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight': tensor([[-0.0204,  0.0447, -0.0052,  ...,  0.0069,  0.0077,  0.0218],
        [ 0.0017,  0.0142, -0.0191,  ...,  0.0062, -0.0003,  0.0145],
        [-0.0078,  0.0171, -0.0142,  ..., -0.0220,  0.0106,  0.0089],
        ...,
        [-0.0215, -0.0144, -0.0043,  ...,  0.0026, -0.0030,  0.0222],
        [ 0.0184,  0.0181,  0.0050,  ...,  0.0064, -0.0177,  0.0218],
        [ 0.0176,  0.0081, -0.0153,  ..., -0.0053,  0.0065,  0.0165]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias': tensor([-0.2126,  0.1382,  0.1891,  ...,  0.0073,  0.0610, -0.0497],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight': tensor([1.5518, 1.4453, 1.4551,  ..., 0.8970, 1.4531, 1.5488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias': tensor([-0.0075, -0.0621, -0.0674,  ..., -0.0965, -0.1760, -0.1098],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight': tensor([[ 0.0173, -0.0038, -0.0434,  ..., -0.0142, -0.0269,  0.0163],
        [ 0.0112,  0.0112, -0.0199,  ...,  0.0013,  0.0100, -0.0072],
        [-0.0037, -0.0045, -0.0143,  ..., -0.0011, -0.0073, -0.0100],
        ...,
        [-0.0162, -0.0028, -0.0142,  ...,  0.0240, -0.0207, -0.0169],
        [ 0.0084,  0.0172, -0.0097,  ..., -0.0170, -0.0171, -0.0099],
        [ 0.0414, -0.0024, -0.0073,  ..., -0.0142,  0.0116,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias': tensor([-0.2035, -0.6177, -0.2632,  ..., -0.2837, -0.4905, -0.3960],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight': tensor([[-0.0123, -0.0106,  0.0170,  ..., -0.0074, -0.0057,  0.0038],
        [ 0.0014, -0.0104, -0.0019,  ...,  0.0073,  0.0064, -0.0129],
        [-0.0083, -0.0003,  0.0169,  ...,  0.0021,  0.0054,  0.0217],
        ...,
        [-0.0205, -0.0112, -0.0028,  ..., -0.0033,  0.0101,  0.0241],
        [ 0.0122, -0.0082,  0.0100,  ..., -0.0086,  0.0083, -0.0369],
        [ 0.0042, -0.0036,  0.0006,  ..., -0.0066,  0.0024,  0.0018]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias': tensor([ 0.0215, -0.1328, -0.1233,  ..., -0.1167,  0.0634,  0.0916],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight': tensor([1.6230, 1.6143, 1.6387,  ..., 1.4531, 1.7188, 1.8516],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias': tensor([-0.0200, -0.0892,  0.0742,  ...,  0.0301,  0.1517, -0.2600],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight': tensor([0.9370, 1.0215, 0.9346,  ..., 0.8223, 1.0596, 1.0498],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias': tensor([-0.0060,  0.1511, -0.0550,  ...,  0.2749,  0.0767,  0.0092],
       dtype=torch.float16), 'model.mm_projector.weight': tensor([[-0.0226,  0.0154, -0.0191,  ...,  0.0185,  0.0186, -0.0280],
        [ 0.0254, -0.0120, -0.0296,  ...,  0.0291, -0.0103,  0.0277],
        [ 0.0119,  0.0010,  0.0103,  ..., -0.0016,  0.0062,  0.0068],
        ...,
        [-0.0011, -0.0270, -0.0277,  ...,  0.0039, -0.0264,  0.0197],
        [ 0.0292, -0.0221, -0.0292,  ..., -0.0171,  0.0040,  0.0152],
        [ 0.0030,  0.0098, -0.0163,  ...,  0.0201, -0.0038, -0.0202]]), 'model.mm_projector.bias': tensor([ 0.0242, -0.0164,  0.0043,  ..., -0.0311,  0.0091, -0.0224]), 'model.perceiver.latents': tensor([[-9.6134e-02, -9.8558e-01, -1.4001e+00,  ..., -1.7456e+00,
          1.5848e+00,  1.8189e-01],
        [ 1.7626e+00,  1.0492e+00, -8.1532e-01,  ..., -1.8006e-01,
         -2.5432e-01,  5.6430e-01],
        [ 8.0852e-01, -7.9023e-01, -1.5254e+00,  ...,  3.1523e-01,
         -3.1729e+00, -1.0900e+00],
        ...,
        [ 5.9788e-01, -1.4592e+00, -1.5042e-01,  ..., -1.8199e+00,
         -3.1138e+00,  4.8139e-01],
        [ 3.0208e-01, -3.4718e-01, -5.9780e-01,  ...,  1.9781e+00,
         -1.6512e-01, -1.5223e+00],
        [-5.6219e-01, -1.0361e+00,  2.5611e+00,  ..., -3.0432e-04,
          1.1358e+00,  8.7693e-01]]), 'model.perceiver.frame_embs': tensor([[ 2.1244, -1.7784,  1.2783,  ...,  1.2683, -0.4469,  0.4178],
        [ 0.2014, -0.4432, -0.3559,  ..., -0.2089,  1.3429, -1.2028],
        [-0.3412,  1.4497, -0.2595,  ..., -0.1889, -0.8071, -1.6996],
        ...,
        [-0.2329, -1.1179,  0.0448,  ...,  0.8850, -0.6434, -0.0325],
        [ 1.3619, -1.8971,  0.9639,  ..., -0.1346,  0.1863, -1.3246],
        [-1.0572, -0.8511,  0.2865,  ..., -0.3322,  1.4016,  1.2969]]), 'model.perceiver.media_time_embs': tensor([[[ 0.4842,  1.0550, -1.5953,  ...,  2.9238, -0.4467, -0.6728]],

        [[-0.1110, -0.3199,  0.3027,  ..., -0.1099, -1.0560,  0.4390]],

        [[ 1.2614, -1.0508,  0.5700,  ...,  0.0837, -0.1641, -1.9703]],

        [[-0.0528,  1.0952, -1.0782,  ...,  0.4843,  1.2082,  0.5736]]]), 'model.perceiver.layers.0.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.to_q.weight': tensor([[ 9.9467e-05,  1.2232e-02,  1.1464e-02,  ..., -9.9076e-03,
          5.8128e-03, -1.8482e-04],
        [-2.5149e-03, -4.8036e-03,  3.9576e-03,  ..., -2.0224e-03,
         -8.8850e-03, -1.1058e-02],
        [ 1.1403e-03, -1.5516e-02,  9.5756e-03,  ..., -7.9009e-03,
          2.6818e-03,  2.9320e-03],
        ...,
        [ 6.2121e-03, -3.7357e-03,  1.4711e-02,  ...,  9.2359e-03,
         -7.3014e-03, -1.1338e-03],
        [ 2.2874e-03,  7.6571e-03, -8.7765e-03,  ...,  8.0181e-03,
          5.3932e-03,  6.7866e-03],
        [-5.7309e-03, -3.7322e-03, -9.7078e-03,  ..., -1.0937e-02,
          2.7534e-03, -5.5313e-03]]), 'model.perceiver.layers.0.0.to_kv.weight': tensor([[-6.8147e-03, -7.7607e-03, -8.2590e-03,  ...,  1.2791e-02,
         -5.6540e-03,  1.2262e-02],
        [-3.9220e-03,  8.2318e-03,  1.1303e-02,  ...,  7.1530e-03,
         -4.6096e-03,  9.3891e-03],
        [ 1.5334e-02,  4.7931e-03,  1.4842e-02,  ..., -1.0320e-02,
          1.4123e-02, -1.1573e-03],
        ...,
        [ 1.5827e-03,  1.3305e-02,  1.9624e-03,  ...,  6.7533e-03,
         -1.3825e-02,  7.0831e-03],
        [ 2.5565e-03,  1.4449e-02,  6.7824e-03,  ...,  9.8554e-05,
         -7.2292e-03, -8.1013e-03],
        [-1.3489e-03, -1.4517e-02,  1.0389e-03,  ..., -6.0490e-04,
         -3.2923e-03,  1.2188e-02]]), 'model.perceiver.layers.0.0.to_out.weight': tensor([[ 0.0392,  0.0057, -0.0269,  ...,  0.0395,  0.0212,  0.0417],
        [-0.0373, -0.0362,  0.0026,  ...,  0.0293,  0.0203,  0.0118],
        [ 0.0017,  0.0307,  0.0206,  ...,  0.0148,  0.0384, -0.0326],
        ...,
        [ 0.0095,  0.0094, -0.0083,  ...,  0.0076, -0.0035,  0.0205],
        [ 0.0210, -0.0161, -0.0343,  ...,  0.0018, -0.0041, -0.0188],
        [-0.0020, -0.0397,  0.0314,  ..., -0.0253, -0.0232, -0.0086]]), 'model.perceiver.layers.0.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.1.1.weight': tensor([[ 0.0049,  0.0006,  0.0020,  ...,  0.0115,  0.0134,  0.0051],
        [-0.0047,  0.0045,  0.0048,  ..., -0.0030,  0.0032, -0.0085],
        [-0.0035,  0.0093, -0.0140,  ..., -0.0013,  0.0110,  0.0020],
        ...,
        [-0.0126, -0.0146, -0.0039,  ...,  0.0043,  0.0104,  0.0156],
        [-0.0150, -0.0085, -0.0101,  ...,  0.0018,  0.0156,  0.0057],
        [ 0.0052,  0.0076, -0.0027,  ..., -0.0135,  0.0155, -0.0144]]), 'model.perceiver.layers.0.1.3.weight': tensor([[-0.0061, -0.0048, -0.0029,  ..., -0.0023,  0.0075,  0.0016],
        [-0.0009,  0.0067,  0.0058,  ..., -0.0029,  0.0068,  0.0015],
        [ 0.0019,  0.0011,  0.0009,  ...,  0.0014, -0.0047,  0.0074],
        ...,
        [ 0.0061,  0.0044, -0.0073,  ..., -0.0063, -0.0075,  0.0044],
        [ 0.0042,  0.0023, -0.0007,  ...,  0.0025, -0.0032, -0.0040],
        [-0.0016,  0.0050,  0.0057,  ..., -0.0007,  0.0036,  0.0027]]), 'model.perceiver.layers.1.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.to_q.weight': tensor([[ 0.0023,  0.0044, -0.0112,  ..., -0.0102,  0.0049,  0.0128],
        [ 0.0142,  0.0013, -0.0005,  ..., -0.0097, -0.0014, -0.0149],
        [-0.0052, -0.0109, -0.0029,  ..., -0.0018,  0.0138,  0.0060],
        ...,
        [ 0.0042,  0.0020,  0.0137,  ...,  0.0074, -0.0011,  0.0047],
        [-0.0049,  0.0016, -0.0088,  ...,  0.0041, -0.0066,  0.0008],
        [ 0.0062,  0.0032,  0.0154,  ..., -0.0016,  0.0083,  0.0035]]), 'model.perceiver.layers.1.0.to_kv.weight': tensor([[-0.0018, -0.0047,  0.0002,  ..., -0.0062,  0.0118, -0.0065],
        [-0.0138,  0.0075, -0.0084,  ..., -0.0111, -0.0073, -0.0108],
        [ 0.0012,  0.0091,  0.0137,  ..., -0.0058, -0.0142,  0.0106],
        ...,
        [ 0.0150,  0.0007, -0.0115,  ...,  0.0051,  0.0104, -0.0124],
        [-0.0047,  0.0090, -0.0126,  ..., -0.0025,  0.0029, -0.0055],
        [-0.0049,  0.0101, -0.0073,  ..., -0.0108, -0.0002, -0.0003]]), 'model.perceiver.layers.1.0.to_out.weight': tensor([[-0.0098,  0.0398,  0.0038,  ...,  0.0304, -0.0360,  0.0222],
        [ 0.0097, -0.0205,  0.0349,  ...,  0.0094,  0.0095, -0.0371],
        [ 0.0334, -0.0368, -0.0086,  ...,  0.0216, -0.0193, -0.0201],
        ...,
        [-0.0424,  0.0305,  0.0355,  ...,  0.0094, -0.0184,  0.0276],
        [-0.0180,  0.0173,  0.0096,  ...,  0.0320, -0.0438, -0.0371],
        [-0.0385, -0.0326,  0.0347,  ...,  0.0039,  0.0046,  0.0014]]), 'model.perceiver.layers.1.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.1.1.weight': tensor([[-0.0061, -0.0044, -0.0125,  ..., -0.0090, -0.0058,  0.0098],
        [ 0.0097, -0.0148, -0.0002,  ..., -0.0040, -0.0017, -0.0073],
        [ 0.0018,  0.0156, -0.0151,  ...,  0.0110,  0.0133, -0.0064],
        ...,
        [ 0.0136,  0.0117,  0.0052,  ...,  0.0025,  0.0109, -0.0028],
        [-0.0111, -0.0035, -0.0046,  ...,  0.0137,  0.0114, -0.0084],
        [ 0.0130, -0.0136, -0.0071,  ..., -0.0041, -0.0135, -0.0055]]), 'model.perceiver.layers.1.1.3.weight': tensor([[-0.0042, -0.0073,  0.0025,  ...,  0.0033,  0.0050,  0.0075],
        [ 0.0077,  0.0068,  0.0061,  ..., -0.0058, -0.0068,  0.0005],
        [ 0.0023, -0.0018, -0.0002,  ...,  0.0067,  0.0012,  0.0014],
        ...,
        [-0.0053,  0.0002,  0.0005,  ..., -0.0001,  0.0063, -0.0036],
        [ 0.0059,  0.0049,  0.0005,  ..., -0.0058, -0.0004,  0.0076],
        [-0.0027, -0.0060, -0.0025,  ...,  0.0031, -0.0075,  0.0040]]), 'model.perceiver.layers.2.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.to_q.weight': tensor([[ 3.1237e-03,  2.6824e-03,  1.4634e-02,  ..., -9.0934e-04,
          1.1593e-02,  8.1033e-03],
        [-9.7144e-03,  8.6245e-03, -7.5599e-03,  ...,  1.0612e-02,
          1.1662e-02, -1.0840e-02],
        [ 1.1036e-03, -8.9472e-03,  7.5406e-03,  ...,  1.2134e-02,
         -1.1954e-02,  1.4820e-02],
        ...,
        [ 7.2566e-03,  8.4716e-03,  1.2266e-02,  ...,  1.1714e-02,
         -1.0039e-02,  6.7795e-03],
        [-5.5864e-03,  4.7563e-03,  6.4620e-03,  ...,  4.4685e-05,
         -7.4468e-03,  8.3243e-03],
        [ 5.7497e-03,  1.4933e-02,  1.1493e-02,  ..., -6.2805e-03,
         -4.3006e-03, -1.5183e-02]]), 'model.perceiver.layers.2.0.to_kv.weight': tensor([[-1.3232e-02, -3.0709e-03,  1.2479e-02,  ..., -1.1573e-02,
          1.3568e-02, -1.1108e-02],
        [-1.2957e-02,  1.3868e-02,  7.3241e-03,  ...,  5.2917e-03,
         -7.8221e-03,  1.6100e-03],
        [ 8.2100e-04,  1.1513e-02,  7.1723e-03,  ...,  1.4707e-02,
         -2.9655e-03,  1.3276e-02],
        ...,
        [ 2.5911e-03,  4.1458e-03,  7.6574e-03,  ..., -1.1220e-02,
          3.6918e-03, -3.7819e-03],
        [ 5.2764e-03,  1.0383e-02,  7.3626e-03,  ..., -5.1578e-03,
         -6.2793e-03, -1.3847e-02],
        [-3.0469e-04, -1.1631e-03, -1.0317e-02,  ...,  2.4144e-05,
          1.1450e-02,  7.1981e-03]]), 'model.perceiver.layers.2.0.to_out.weight': tensor([[-0.0154,  0.0204,  0.0366,  ...,  0.0200, -0.0185,  0.0426],
        [-0.0305, -0.0413,  0.0394,  ..., -0.0204,  0.0133, -0.0268],
        [ 0.0021,  0.0202,  0.0294,  ..., -0.0235, -0.0149, -0.0220],
        ...,
        [-0.0193, -0.0198, -0.0201,  ..., -0.0400, -0.0205, -0.0137],
        [ 0.0229,  0.0197,  0.0396,  ...,  0.0161, -0.0294, -0.0250],
        [-0.0125, -0.0132,  0.0325,  ...,  0.0360,  0.0363, -0.0152]]), 'model.perceiver.layers.2.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.1.1.weight': tensor([[ 0.0040, -0.0073, -0.0104,  ...,  0.0029, -0.0079, -0.0142],
        [-0.0117,  0.0018, -0.0080,  ..., -0.0092,  0.0109, -0.0091],
        [-0.0076, -0.0103, -0.0121,  ...,  0.0072,  0.0149, -0.0151],
        ...,
        [ 0.0072,  0.0069, -0.0136,  ..., -0.0052, -0.0044,  0.0029],
        [-0.0127,  0.0082,  0.0092,  ...,  0.0112,  0.0061, -0.0090],
        [ 0.0073, -0.0053,  0.0122,  ..., -0.0007, -0.0017, -0.0014]]), 'model.perceiver.layers.2.1.3.weight': tensor([[-0.0061, -0.0030, -0.0067,  ...,  0.0074, -0.0067,  0.0011],
        [ 0.0007,  0.0037, -0.0034,  ..., -0.0043, -0.0017, -0.0067],
        [-0.0065, -0.0012, -0.0044,  ..., -0.0037, -0.0044,  0.0052],
        ...,
        [-0.0020, -0.0035,  0.0078,  ..., -0.0030, -0.0070, -0.0037],
        [ 0.0076,  0.0006,  0.0009,  ..., -0.0074,  0.0040, -0.0064],
        [ 0.0043, -0.0015,  0.0074,  ..., -0.0017,  0.0028,  0.0009]]), 'model.perceiver.layers.3.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.to_q.weight': tensor([[-0.0046,  0.0144, -0.0096,  ...,  0.0009,  0.0077,  0.0073],
        [-0.0008,  0.0058,  0.0133,  ...,  0.0152,  0.0106, -0.0068],
        [-0.0094, -0.0056,  0.0124,  ...,  0.0117,  0.0135, -0.0035],
        ...,
        [ 0.0066, -0.0052, -0.0075,  ...,  0.0025, -0.0096,  0.0063],
        [ 0.0143, -0.0145, -0.0112,  ..., -0.0056, -0.0068, -0.0020],
        [ 0.0098,  0.0118, -0.0065,  ..., -0.0128,  0.0088, -0.0099]]), 'model.perceiver.layers.3.0.to_kv.weight': tensor([[ 1.3328e-02, -1.2511e-02,  1.2682e-02,  ...,  3.8474e-03,
          4.4602e-03, -7.7178e-03],
        [-1.4688e-02,  1.3074e-05, -8.3515e-03,  ...,  1.4422e-02,
         -4.8666e-03,  1.4222e-03],
        [-1.2511e-02, -1.4780e-02,  4.3994e-03,  ..., -2.3500e-03,
         -1.3359e-02, -5.2784e-03],
        ...,
        [-5.2164e-03,  3.3093e-03,  1.2887e-02,  ...,  5.7970e-03,
         -7.0198e-03, -9.2681e-03],
        [-1.1036e-02, -8.2030e-03,  8.3007e-03,  ..., -1.5348e-02,
         -1.1721e-03, -1.1033e-02],
        [ 8.0563e-03, -6.5417e-04,  1.1954e-02,  ..., -1.4704e-02,
         -7.9901e-03, -1.4578e-02]]), 'model.perceiver.layers.3.0.to_out.weight': tensor([[-0.0178,  0.0279,  0.0284,  ...,  0.0113, -0.0380,  0.0112],
        [ 0.0417, -0.0070,  0.0232,  ...,  0.0314,  0.0325,  0.0369],
        [ 0.0323,  0.0366,  0.0340,  ...,  0.0206, -0.0135,  0.0145],
        ...,
        [-0.0432,  0.0234, -0.0150,  ..., -0.0273, -0.0408,  0.0421],
        [-0.0040,  0.0132, -0.0004,  ..., -0.0104, -0.0346, -0.0278],
        [-0.0315, -0.0275, -0.0273,  ...,  0.0329, -0.0094,  0.0187]]), 'model.perceiver.layers.3.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.1.1.weight': tensor([[-0.0052, -0.0015, -0.0154,  ...,  0.0059, -0.0093, -0.0018],
        [-0.0074,  0.0002, -0.0078,  ..., -0.0127, -0.0034, -0.0135],
        [-0.0090,  0.0112,  0.0089,  ..., -0.0111,  0.0060, -0.0139],
        ...,
        [ 0.0006,  0.0079, -0.0084,  ..., -0.0154, -0.0022, -0.0060],
        [ 0.0002,  0.0100, -0.0021,  ...,  0.0083,  0.0132, -0.0001],
        [ 0.0017,  0.0095,  0.0122,  ...,  0.0062,  0.0153,  0.0132]]), 'model.perceiver.layers.3.1.3.weight': tensor([[ 0.0064, -0.0055, -0.0015,  ...,  0.0038,  0.0051,  0.0020],
        [ 0.0023,  0.0007, -0.0040,  ...,  0.0048,  0.0056, -0.0069],
        [ 0.0068,  0.0033, -0.0056,  ...,  0.0022, -0.0054, -0.0008],
        ...,
        [-0.0005,  0.0045,  0.0031,  ..., -0.0015,  0.0041,  0.0031],
        [ 0.0027, -0.0004, -0.0012,  ..., -0.0025,  0.0056, -0.0013],
        [ 0.0063, -0.0066,  0.0035,  ..., -0.0008,  0.0061, -0.0064]]), 'model.perceiver.layers.4.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.to_q.weight': tensor([[-0.0078, -0.0118,  0.0113,  ..., -0.0061, -0.0136, -0.0113],
        [ 0.0093, -0.0029,  0.0147,  ...,  0.0129,  0.0156,  0.0078],
        [ 0.0063,  0.0028,  0.0137,  ...,  0.0112, -0.0013, -0.0082],
        ...,
        [-0.0066,  0.0147, -0.0049,  ...,  0.0141,  0.0099,  0.0074],
        [-0.0125,  0.0016, -0.0035,  ...,  0.0103, -0.0127, -0.0057],
        [ 0.0015, -0.0033,  0.0154,  ..., -0.0052,  0.0014,  0.0137]]), 'model.perceiver.layers.4.0.to_kv.weight': tensor([[-0.0061, -0.0100, -0.0152,  ...,  0.0153, -0.0090, -0.0154],
        [-0.0044, -0.0056,  0.0062,  ...,  0.0079, -0.0011,  0.0041],
        [-0.0089, -0.0016, -0.0018,  ...,  0.0045,  0.0094, -0.0080],
        ...,
        [-0.0020, -0.0123,  0.0039,  ..., -0.0138, -0.0103,  0.0130],
        [-0.0149, -0.0045,  0.0031,  ..., -0.0022,  0.0002,  0.0078],
        [-0.0145,  0.0035,  0.0123,  ..., -0.0075, -0.0087, -0.0145]]), 'model.perceiver.layers.4.0.to_out.weight': tensor([[-0.0389,  0.0207,  0.0384,  ...,  0.0165,  0.0346, -0.0003],
        [ 0.0361, -0.0257, -0.0209,  ..., -0.0138,  0.0404,  0.0343],
        [ 0.0169, -0.0411,  0.0399,  ...,  0.0236, -0.0279, -0.0304],
        ...,
        [ 0.0084,  0.0318,  0.0316,  ..., -0.0233,  0.0050, -0.0083],
        [ 0.0054, -0.0235,  0.0268,  ..., -0.0092, -0.0213, -0.0018],
        [ 0.0189, -0.0266, -0.0248,  ..., -0.0390,  0.0167, -0.0127]]), 'model.perceiver.layers.4.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.1.1.weight': tensor([[-0.0141, -0.0121,  0.0128,  ...,  0.0068,  0.0050, -0.0099],
        [ 0.0145, -0.0039, -0.0060,  ..., -0.0074,  0.0110,  0.0034],
        [-0.0116,  0.0142,  0.0060,  ..., -0.0055, -0.0027, -0.0005],
        ...,
        [-0.0038,  0.0055, -0.0124,  ..., -0.0079, -0.0019, -0.0019],
        [-0.0035,  0.0086, -0.0041,  ...,  0.0059, -0.0032, -0.0121],
        [-0.0152, -0.0010,  0.0085,  ..., -0.0011,  0.0152,  0.0156]]), 'model.perceiver.layers.4.1.3.weight': tensor([[-0.0036, -0.0006,  0.0053,  ..., -0.0046, -0.0004,  0.0038],
        [-0.0001,  0.0053, -0.0064,  ..., -0.0029,  0.0029, -0.0034],
        [-0.0003, -0.0020, -0.0054,  ..., -0.0018, -0.0057, -0.0028],
        ...,
        [ 0.0030, -0.0069,  0.0020,  ...,  0.0069, -0.0018, -0.0065],
        [ 0.0065,  0.0059,  0.0070,  ...,  0.0066, -0.0019, -0.0061],
        [-0.0038, -0.0032, -0.0055,  ...,  0.0075,  0.0002, -0.0034]]), 'model.perceiver.layers.5.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.to_q.weight': tensor([[-0.0055, -0.0120,  0.0021,  ..., -0.0096, -0.0116,  0.0042],
        [ 0.0058, -0.0015,  0.0064,  ..., -0.0043,  0.0152,  0.0116],
        [ 0.0075, -0.0031, -0.0140,  ...,  0.0051, -0.0042, -0.0141],
        ...,
        [ 0.0078,  0.0029, -0.0063,  ...,  0.0052, -0.0147, -0.0139],
        [-0.0047, -0.0050,  0.0059,  ..., -0.0064, -0.0138, -0.0022],
        [ 0.0062,  0.0026,  0.0061,  ..., -0.0051,  0.0033,  0.0060]]), 'model.perceiver.layers.5.0.to_kv.weight': tensor([[-0.0024, -0.0038, -0.0080,  ..., -0.0019, -0.0061, -0.0039],
        [-0.0108,  0.0097,  0.0146,  ...,  0.0145,  0.0058,  0.0083],
        [ 0.0020, -0.0052, -0.0101,  ..., -0.0023,  0.0133,  0.0096],
        ...,
        [ 0.0011, -0.0039, -0.0008,  ...,  0.0150,  0.0064,  0.0008],
        [-0.0027,  0.0083, -0.0079,  ...,  0.0093,  0.0135, -0.0041],
        [-0.0094,  0.0045, -0.0047,  ..., -0.0096, -0.0108, -0.0103]]), 'model.perceiver.layers.5.0.to_out.weight': tensor([[-1.2052e-02, -2.3363e-02, -3.7300e-02,  ..., -3.7578e-03,
          1.6700e-02, -9.6923e-03],
        [-3.3774e-02,  2.1326e-02,  3.3339e-02,  ..., -6.8984e-05,
         -2.3711e-02,  3.2635e-02],
        [-4.2027e-02, -1.8181e-02, -2.7480e-02,  ...,  2.7427e-02,
         -2.0209e-02,  4.7901e-03],
        ...,
        [-2.9604e-02,  3.1551e-02, -4.6002e-03,  ...,  2.3912e-02,
          1.0342e-02, -1.8536e-02],
        [-4.3343e-02,  2.7038e-02,  2.0541e-02,  ...,  4.2764e-02,
          1.4506e-02,  2.9083e-02],
        [ 3.2243e-02, -4.3172e-02, -3.8493e-02,  ...,  2.5028e-02,
         -1.1940e-02,  1.1492e-03]]), 'model.perceiver.layers.5.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.1.1.weight': tensor([[ 3.4591e-05,  1.3231e-02, -2.9893e-03,  ...,  1.2798e-02,
          7.6490e-03, -8.4097e-03],
        [-4.7645e-03,  4.4146e-03,  1.3545e-02,  ...,  1.1882e-02,
          6.6045e-03,  9.8625e-03],
        [-2.0682e-03,  1.2150e-02,  2.5624e-03,  ...,  6.1473e-03,
          3.2561e-03, -1.5138e-02],
        ...,
        [ 1.3620e-02, -1.5310e-02, -1.4945e-03,  ...,  7.8995e-04,
         -1.0022e-02,  1.0835e-03],
        [-1.3829e-02,  8.6296e-03, -6.4565e-03,  ...,  2.5012e-03,
          6.2400e-03,  7.5920e-04],
        [ 1.4574e-02, -7.4768e-03, -1.5069e-03,  ..., -2.2139e-03,
         -1.3597e-02, -4.4300e-03]]), 'model.perceiver.layers.5.1.3.weight': tensor([[ 0.0047, -0.0045,  0.0007,  ..., -0.0004,  0.0050,  0.0054],
        [-0.0040,  0.0008,  0.0070,  ..., -0.0022, -0.0003,  0.0037],
        [-0.0018,  0.0009, -0.0033,  ...,  0.0009,  0.0021,  0.0060],
        ...,
        [-0.0025,  0.0014,  0.0012,  ..., -0.0068,  0.0018, -0.0054],
        [-0.0059,  0.0023, -0.0032,  ..., -0.0076,  0.0044, -0.0072],
        [-0.0068,  0.0060, -0.0035,  ...,  0.0015,  0.0060, -0.0070]]), 'model.perceiver.norm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.norm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'lm_head.weight': tensor([[-0.0058, -0.0009, -0.0071,  ...,  0.0035, -0.0099,  0.0190],
        [-0.0278,  0.0547, -0.0115,  ..., -0.0232,  0.0147,  0.0332],
        [-0.0140, -0.0099,  0.0201,  ..., -0.0344,  0.0142, -0.0150],
        ...,
        [-0.0243,  0.0031,  0.0008,  ..., -0.0046,  0.0029, -0.0072],
        [ 0.0070,  0.0007,  0.0051,  ..., -0.0131, -0.0103, -0.0041],
        [-0.0041, -0.0077, -0.0308,  ...,  0.0179,  0.0084,  0.0356]],
       dtype=torch.float16)}
[INFO] Medical save done, finish
[INFO] medical_state_dict: {'model.embed_tokens.weight': tensor([[-0.0013,  0.0004, -0.0018,  ...,  0.0004, -0.0038, -0.0033],
        [ 0.0011, -0.0046, -0.0005,  ..., -0.0079, -0.0010,  0.0003],
        [ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
        ...,
        [-0.0052,  0.0041, -0.0056,  ..., -0.0011,  0.0072,  0.0068],
        [ 0.0075, -0.0039,  0.0058,  ...,  0.0447,  0.0135, -0.0091],
        [-0.0026,  0.0215, -0.0237,  ..., -0.0354,  0.0114,  0.0210]],
       dtype=torch.float16), 'model.layers.0.self_attn.q_proj.weight': tensor([[-9.6512e-03, -1.4015e-02, -1.5736e-03,  ...,  2.1338e-05,
          1.3115e-02, -3.8280e-03],
        [ 2.9144e-02,  4.8027e-03,  5.9013e-03,  ..., -1.3435e-02,
         -8.2550e-03,  1.8204e-02],
        [-1.3481e-02,  1.8463e-02, -3.4637e-03,  ...,  6.7596e-03,
          2.8107e-02, -7.3576e-04],
        ...,
        [ 1.1032e-02,  1.4496e-02, -1.0233e-03,  ..., -2.4509e-03,
         -9.9945e-03,  1.9012e-02],
        [ 2.2018e-02,  9.6817e-03,  3.0251e-03,  ..., -2.1957e-02,
         -2.9984e-02, -1.5228e-02],
        [-4.3945e-03, -3.2215e-03,  2.4204e-03,  ...,  1.5717e-02,
          2.7542e-02, -3.5992e-03]], dtype=torch.float16), 'model.layers.0.self_attn.k_proj.weight': tensor([[-1.8356e-02,  4.0359e-03, -1.2512e-03,  ...,  1.7609e-02,
         -8.6746e-03, -1.4610e-02],
        [ 1.5823e-02,  6.5346e-03,  2.6360e-03,  ..., -1.8021e-02,
          1.6815e-02,  2.4765e-02],
        [ 2.4891e-04, -2.5513e-02,  9.2087e-03,  ...,  1.0544e-02,
         -2.4979e-02, -1.9958e-02],
        ...,
        [ 1.5572e-02,  6.2644e-05,  2.2449e-03,  ..., -7.4625e-04,
          1.9274e-03,  5.2757e-03],
        [-1.0864e-02,  2.2339e-02, -8.3771e-03,  ...,  2.7027e-03,
          1.7319e-02, -7.6866e-03],
        [ 5.8746e-03,  5.1308e-04,  6.3248e-03,  ...,  7.2708e-03,
         -1.2901e-02,  6.5727e-03]], dtype=torch.float16), 'model.layers.0.self_attn.v_proj.weight': tensor([[ 0.0007,  0.0044,  0.0010,  ...,  0.0090,  0.0010,  0.0093],
        [-0.0099, -0.0005, -0.0035,  ..., -0.0119,  0.0113,  0.0107],
        [ 0.0048,  0.0068, -0.0029,  ...,  0.0021, -0.0156, -0.0190],
        ...,
        [-0.0073, -0.0050,  0.0162,  ...,  0.0033,  0.0020, -0.0007],
        [-0.0006,  0.0075, -0.0048,  ...,  0.0051,  0.0155,  0.0017],
        [-0.0032,  0.0046,  0.0082,  ..., -0.0016, -0.0035,  0.0023]],
       dtype=torch.float16), 'model.layers.0.self_attn.o_proj.weight': tensor([[ 1.3628e-03, -3.9444e-03,  3.8643e-03,  ...,  2.2564e-03,
          2.7990e-04, -8.9340e-03],
        [-2.4300e-03,  5.6076e-03,  1.1387e-03,  ..., -1.7481e-03,
          2.0924e-03,  5.7678e-03],
        [-3.3474e-03, -7.6914e-04,  2.4796e-03,  ..., -2.0561e-03,
         -6.5956e-03, -8.0681e-04],
        ...,
        [ 4.8943e-03, -1.4791e-03,  7.6332e-03,  ...,  2.2650e-06,
          4.2534e-03,  3.3951e-03],
        [-2.9583e-03, -1.8663e-03, -1.1358e-03,  ...,  5.2490e-03,
         -5.8899e-03, -2.8267e-03],
        [ 4.0221e-04, -1.2932e-03,  3.3665e-03,  ...,  6.5804e-03,
         -4.6806e-03, -5.0964e-03]], dtype=torch.float16), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0081,  0.0134,  0.0292,  ..., -0.0172,  0.0053,  0.0193],
        [-0.0028, -0.0027,  0.0029,  ...,  0.0147, -0.0076,  0.0114],
        [-0.0002, -0.0256,  0.0180,  ..., -0.0189,  0.0257,  0.0206],
        ...,
        [ 0.0058, -0.0258,  0.0025,  ..., -0.0036, -0.0106,  0.0365],
        [ 0.0223,  0.0168, -0.0171,  ..., -0.0017, -0.0030, -0.0196],
        [-0.0070, -0.0135, -0.0268,  ..., -0.0042,  0.0025, -0.0229]],
       dtype=torch.float16), 'model.layers.0.mlp.up_proj.weight': tensor([[-0.0072, -0.0297,  0.0135,  ..., -0.0198, -0.0236,  0.0091],
        [-0.0119, -0.0311,  0.0110,  ...,  0.0178,  0.0034,  0.0087],
        [-0.0066,  0.0157, -0.0102,  ..., -0.0231,  0.0132,  0.0038],
        ...,
        [-0.0121, -0.0005, -0.0019,  ...,  0.0259, -0.0082,  0.0114],
        [-0.0198,  0.0047,  0.0170,  ..., -0.0023, -0.0186,  0.0037],
        [ 0.0142,  0.0268, -0.0009,  ...,  0.0088, -0.0174, -0.0420]],
       dtype=torch.float16), 'model.layers.0.mlp.down_proj.weight': tensor([[ 0.0044, -0.0123,  0.0141,  ..., -0.0181, -0.0041, -0.0016],
        [-0.0006, -0.0026,  0.0135,  ...,  0.0106, -0.0167,  0.0315],
        [ 0.0044,  0.0371,  0.0019,  ..., -0.0117,  0.0212,  0.0207],
        ...,
        [-0.0078, -0.0106,  0.0062,  ...,  0.0204, -0.0163,  0.0254],
        [-0.0202,  0.0401,  0.0176,  ..., -0.0138, -0.0104, -0.0290],
        [ 0.0179, -0.0031, -0.0126,  ...,  0.0003, -0.0050, -0.0296]],
       dtype=torch.float16), 'model.layers.0.input_layernorm.weight': tensor([ 0.0193,  0.0087, -0.0008,  ...,  0.0058,  0.0089,  0.0019],
       dtype=torch.float16), 'model.layers.0.post_attention_layernorm.weight': tensor([0.0530, 0.0537, 0.0498,  ..., 0.0540, 0.0569, 0.0491],
       dtype=torch.float16), 'model.layers.1.self_attn.q_proj.weight': tensor([[-0.0228, -0.0012, -0.0327,  ..., -0.0147, -0.0572,  0.0403],
        [-0.0012, -0.0125,  0.0112,  ..., -0.0081, -0.0516,  0.0322],
        [ 0.0274,  0.0308,  0.0248,  ..., -0.0133, -0.0764,  0.0221],
        ...,
        [-0.0004,  0.0029,  0.0050,  ..., -0.0099, -0.0020, -0.0116],
        [-0.0018, -0.0048, -0.0055,  ...,  0.0103,  0.0032,  0.0117],
        [ 0.0002,  0.0064,  0.0077,  ..., -0.0088,  0.0019, -0.0165]],
       dtype=torch.float16), 'model.layers.1.self_attn.k_proj.weight': tensor([[-0.0254,  0.0089,  0.0425,  ...,  0.0178,  0.0165, -0.0135],
        [-0.0323,  0.0092, -0.0083,  ..., -0.0091,  0.0150, -0.0595],
        [-0.0262,  0.0288, -0.0696,  ...,  0.0352,  0.0172, -0.0609],
        ...,
        [-0.0149,  0.0229,  0.0028,  ...,  0.0081, -0.0048,  0.0070],
        [ 0.0114, -0.0230, -0.0001,  ..., -0.0092,  0.0033, -0.0068],
        [-0.0111,  0.0184,  0.0055,  ...,  0.0007, -0.0071,  0.0058]],
       dtype=torch.float16), 'model.layers.1.self_attn.v_proj.weight': tensor([[ 6.8245e-03, -4.9133e-03,  1.0071e-03,  ..., -4.8561e-03,
         -2.9144e-02, -2.2125e-02],
        [-5.1346e-03,  4.9515e-03, -3.3360e-03,  ...,  2.7618e-03,
          1.1398e-02,  3.1982e-02],
        [ 3.6736e-03, -1.1612e-02,  8.0032e-03,  ..., -2.2590e-05,
         -1.4648e-03, -3.3340e-03],
        ...,
        [-3.6926e-03,  5.3062e-03,  7.3509e-03,  ..., -2.7981e-03,
         -1.4305e-03,  2.2399e-04],
        [-7.8735e-03, -3.1986e-03,  7.9422e-03,  ..., -6.5727e-03,
          8.4534e-03, -5.7817e-06],
        [ 1.0643e-03,  6.4468e-03,  8.0719e-03,  ..., -6.3095e-03,
         -2.6455e-03,  1.0246e-02]], dtype=torch.float16), 'model.layers.1.self_attn.o_proj.weight': tensor([[ 0.0024, -0.0163,  0.0091,  ..., -0.0058, -0.0015, -0.0006],
        [-0.0016, -0.0059, -0.0052,  ...,  0.0035, -0.0019,  0.0037],
        [ 0.0247,  0.0128, -0.0125,  ...,  0.0022, -0.0027,  0.0011],
        ...,
        [ 0.0058,  0.0022,  0.0012,  ..., -0.0011, -0.0004, -0.0001],
        [ 0.0036, -0.0075,  0.0050,  ..., -0.0054,  0.0002,  0.0056],
        [-0.0017, -0.0238,  0.0015,  ..., -0.0021, -0.0055,  0.0007]],
       dtype=torch.float16), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0305, -0.0128,  0.0422,  ..., -0.0312, -0.0152, -0.0100],
        [-0.0312, -0.0045, -0.0312,  ...,  0.0140, -0.0307, -0.0427],
        [-0.0055, -0.0319,  0.0095,  ..., -0.0064, -0.0123, -0.0204],
        ...,
        [-0.0385,  0.0105, -0.0028,  ..., -0.0023,  0.0122,  0.0004],
        [-0.0149, -0.0031, -0.0339,  ...,  0.0217,  0.0198, -0.0084],
        [-0.0266,  0.0121,  0.0041,  ...,  0.0391,  0.0065, -0.0430]],
       dtype=torch.float16), 'model.layers.1.mlp.up_proj.weight': tensor([[-0.0034,  0.0414, -0.0204,  ...,  0.0118,  0.0263, -0.0124],
        [ 0.0071, -0.0067, -0.0129,  ..., -0.0086,  0.0069,  0.0108],
        [ 0.0309, -0.0436,  0.0134,  ...,  0.0177, -0.0427,  0.0297],
        ...,
        [-0.0148, -0.0275,  0.0184,  ...,  0.0293,  0.0069, -0.0238],
        [ 0.0356,  0.0030, -0.0164,  ...,  0.0032, -0.0060, -0.0045],
        [-0.0108, -0.0150, -0.0105,  ..., -0.0249, -0.0061,  0.0173]],
       dtype=torch.float16), 'model.layers.1.mlp.down_proj.weight': tensor([[ 0.0107,  0.0179,  0.0578,  ..., -0.0177,  0.0072, -0.0210],
        [ 0.0088,  0.0063, -0.0363,  ...,  0.0069, -0.0142,  0.0028],
        [-0.0113, -0.0138, -0.0245,  ...,  0.0014, -0.0134,  0.0023],
        ...,
        [-0.0099, -0.0073, -0.0143,  ...,  0.0442, -0.0065,  0.0090],
        [-0.0116,  0.0203,  0.0101,  ..., -0.0278, -0.0228,  0.0261],
        [ 0.0262, -0.0061, -0.0175,  ..., -0.0080, -0.0135,  0.0338]],
       dtype=torch.float16), 'model.layers.1.input_layernorm.weight': tensor([0.1050, 0.0967, 0.0884,  ..., 0.0518, 0.0781, 0.0608],
       dtype=torch.float16), 'model.layers.1.post_attention_layernorm.weight': tensor([0.0986, 0.0991, 0.0957,  ..., 0.1060, 0.1006, 0.1001],
       dtype=torch.float16), 'model.layers.2.self_attn.q_proj.weight': tensor([[-0.0236, -0.0038,  0.0098,  ..., -0.0133, -0.0098, -0.0003],
        [-0.0190,  0.0037, -0.0345,  ..., -0.0344, -0.0162,  0.0232],
        [-0.0165,  0.0366, -0.0252,  ..., -0.0018, -0.0211,  0.0159],
        ...,
        [-0.0526,  0.0145, -0.0261,  ..., -0.0085, -0.0328, -0.0351],
        [ 0.0019, -0.0063,  0.0003,  ..., -0.0023, -0.0186,  0.0160],
        [-0.0048, -0.0168,  0.0231,  ...,  0.0604, -0.0444,  0.0058]],
       dtype=torch.float16), 'model.layers.2.self_attn.k_proj.weight': tensor([[ 0.0004,  0.0156, -0.0085,  ..., -0.0106, -0.0010,  0.0175],
        [ 0.0163, -0.0154, -0.0090,  ...,  0.0110, -0.0093, -0.0075],
        [ 0.0128,  0.0151,  0.0360,  ..., -0.0084,  0.0124,  0.0131],
        ...,
        [ 0.0299,  0.0465, -0.0237,  ...,  0.0386, -0.0369,  0.0006],
        [-0.0072, -0.0126, -0.0009,  ...,  0.0045,  0.0003, -0.0041],
        [ 0.0020, -0.0215, -0.0021,  ..., -0.0809, -0.0249,  0.0965]],
       dtype=torch.float16), 'model.layers.2.self_attn.v_proj.weight': tensor([[-7.3767e-04,  6.2332e-03,  1.5961e-02,  ...,  3.8208e-02,
         -3.6240e-03, -6.9313e-03],
        [ 5.0621e-03,  1.1269e-02, -2.1118e-02,  ..., -7.7972e-03,
          7.8506e-03, -1.4595e-02],
        [-6.8617e-04,  1.8463e-02,  3.3112e-03,  ..., -2.0950e-02,
         -3.0457e-02, -2.9480e-02],
        ...,
        [-5.3465e-05, -2.5360e-02, -2.0248e-02,  ..., -1.0956e-02,
         -9.5272e-04,  3.3970e-03],
        [-3.7140e-02, -7.9775e-04,  1.4175e-02,  ..., -1.0040e-02,
         -6.6071e-03, -1.5135e-03],
        [-1.1009e-02,  1.4809e-02,  4.5662e-03,  ..., -5.1880e-03,
          1.8234e-02, -7.3395e-03]], dtype=torch.float16), 'model.layers.2.self_attn.o_proj.weight': tensor([[ 0.0041,  0.0149,  0.0103,  ...,  0.0196,  0.0020, -0.0260],
        [ 0.0006, -0.0130,  0.0079,  ...,  0.0049, -0.0125, -0.0198],
        [-0.0215,  0.0032, -0.0169,  ..., -0.0224, -0.0103,  0.0078],
        ...,
        [-0.0046, -0.0235,  0.0281,  ..., -0.0049, -0.0220,  0.0198],
        [ 0.0184, -0.0113,  0.0301,  ...,  0.0192, -0.0004, -0.0239],
        [-0.0107,  0.0023,  0.0075,  ..., -0.0129,  0.0050, -0.0142]],
       dtype=torch.float16), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0072,  0.0239, -0.0107,  ..., -0.0090,  0.0302, -0.0034],
        [ 0.0013,  0.0012, -0.0015,  ...,  0.0126, -0.0138, -0.0115],
        [-0.0069, -0.0083,  0.0255,  ..., -0.0112,  0.0158,  0.0069],
        ...,
        [ 0.0342, -0.0119, -0.0193,  ..., -0.0285, -0.0400, -0.0150],
        [-0.0113, -0.0116, -0.0017,  ...,  0.0174, -0.0425,  0.0180],
        [-0.0015,  0.0111,  0.0085,  ..., -0.0133, -0.0261,  0.0048]],
       dtype=torch.float16), 'model.layers.2.mlp.up_proj.weight': tensor([[-0.0008, -0.0006,  0.0139,  ..., -0.0152,  0.0090, -0.0034],
        [ 0.0053, -0.0186, -0.0090,  ...,  0.0056,  0.0114,  0.0062],
        [ 0.0306,  0.0189,  0.0293,  ..., -0.0141, -0.0088,  0.0175],
        ...,
        [-0.0071, -0.0148,  0.0009,  ..., -0.0116, -0.0025,  0.0209],
        [ 0.0155, -0.0129,  0.0144,  ...,  0.0003,  0.0049, -0.0228],
        [-0.0146, -0.0302, -0.0243,  ..., -0.0050,  0.0011, -0.0050]],
       dtype=torch.float16), 'model.layers.2.mlp.down_proj.weight': tensor([[ 0.0146,  0.0174,  0.0375,  ..., -0.0273, -0.0011, -0.0335],
        [ 0.0209, -0.0227, -0.0188,  ...,  0.0180,  0.0023, -0.0226],
        [ 0.0438, -0.0178,  0.0010,  ..., -0.0302,  0.0004, -0.0330],
        ...,
        [-0.0133,  0.0283, -0.0105,  ..., -0.0015, -0.0013, -0.0135],
        [-0.0211,  0.0298,  0.0079,  ...,  0.0158, -0.0182, -0.0113],
        [ 0.0315,  0.0117, -0.0220,  ...,  0.0192, -0.0449, -0.0119]],
       dtype=torch.float16), 'model.layers.2.input_layernorm.weight': tensor([0.1729, 0.1787, 0.1709,  ..., 0.1768, 0.1680, 0.1748],
       dtype=torch.float16), 'model.layers.2.post_attention_layernorm.weight': tensor([0.1338, 0.1377, 0.1367,  ..., 0.1367, 0.1387, 0.1367],
       dtype=torch.float16), 'model.layers.3.self_attn.q_proj.weight': tensor([[ 0.0001,  0.0111,  0.0058,  ...,  0.0241,  0.0127,  0.0220],
        [-0.0121,  0.0172, -0.0149,  ..., -0.0432,  0.0006, -0.0074],
        [ 0.0129,  0.0027, -0.0203,  ...,  0.0116, -0.0187, -0.0406],
        ...,
        [ 0.0717, -0.0696,  0.0428,  ..., -0.0779, -0.0139,  0.0070],
        [-0.0797,  0.0404, -0.0023,  ...,  0.0363,  0.0769,  0.0251],
        [-0.0153, -0.0497,  0.0779,  ..., -0.0225, -0.0032, -0.0130]],
       dtype=torch.float16), 'model.layers.3.self_attn.k_proj.weight': tensor([[ 0.0074, -0.0077, -0.0088,  ..., -0.0140,  0.0067,  0.0404],
        [-0.0116,  0.0102, -0.0252,  ...,  0.0031, -0.0150, -0.0390],
        [ 0.0029, -0.0079,  0.0005,  ...,  0.0074, -0.0090, -0.0374],
        ...,
        [ 0.0884, -0.0848,  0.0065,  ..., -0.0621,  0.0024,  0.0343],
        [-0.0830,  0.0328,  0.0418,  ...,  0.0079,  0.0463, -0.0032],
        [ 0.0020, -0.0524,  0.0955,  ..., -0.0163,  0.0029, -0.0172]],
       dtype=torch.float16), 'model.layers.3.self_attn.v_proj.weight': tensor([[-0.0039,  0.0125, -0.0059,  ..., -0.0148,  0.0063, -0.0150],
        [-0.0113,  0.0269, -0.0179,  ..., -0.0122, -0.0101, -0.0094],
        [ 0.0024, -0.0062,  0.0057,  ..., -0.0406, -0.0087, -0.0281],
        ...,
        [-0.0131, -0.0097, -0.0019,  ...,  0.0023, -0.0041, -0.0064],
        [ 0.0055, -0.0019,  0.0020,  ...,  0.0007, -0.0084,  0.0018],
        [-0.0120, -0.0069,  0.0093,  ..., -0.0012, -0.0018,  0.0084]],
       dtype=torch.float16), 'model.layers.3.self_attn.o_proj.weight': tensor([[-2.7054e-02,  5.7945e-03, -1.2451e-02,  ...,  2.7256e-03,
         -1.1616e-03, -2.2335e-03],
        [ 2.4536e-02, -2.4429e-02, -1.0193e-02,  ...,  6.5651e-03,
         -2.5272e-03, -2.3193e-03],
        [-3.7498e-03, -1.3260e-02,  1.9197e-03,  ...,  2.6493e-03,
          3.3932e-03,  8.3084e-03],
        ...,
        [ 1.1963e-02,  1.3344e-02,  1.3680e-02,  ...,  1.3313e-03,
          7.1793e-03,  9.9335e-03],
        [ 1.7960e-02,  2.6199e-02,  2.9206e-06,  ...,  3.6945e-03,
         -1.1940e-03, -2.8419e-03],
        [ 8.5297e-03, -9.2773e-03,  1.0519e-03,  ..., -6.4993e-04,
          5.8823e-03,  1.0956e-02]], dtype=torch.float16), 'model.layers.3.mlp.gate_proj.weight': tensor([[ 0.0009, -0.0099, -0.0182,  ..., -0.0315,  0.0460,  0.0153],
        [ 0.0189,  0.0017, -0.0123,  ..., -0.0025, -0.0261, -0.0161],
        [-0.0253,  0.0021, -0.0174,  ...,  0.0050, -0.0040, -0.0361],
        ...,
        [-0.0003,  0.0394,  0.0065,  ...,  0.0199, -0.0123, -0.0001],
        [-0.0057,  0.0087, -0.0060,  ...,  0.0003, -0.0041, -0.0112],
        [-0.0025, -0.0155,  0.0031,  ...,  0.0264, -0.0254,  0.0148]],
       dtype=torch.float16), 'model.layers.3.mlp.up_proj.weight': tensor([[-0.0160,  0.0154,  0.0104,  ...,  0.0014,  0.0186, -0.0085],
        [-0.0123, -0.0174,  0.0343,  ...,  0.0175,  0.0141, -0.0052],
        [-0.0005, -0.0031, -0.0144,  ..., -0.0012,  0.0091, -0.0125],
        ...,
        [-0.0042, -0.0016, -0.0006,  ...,  0.0215,  0.0084, -0.0228],
        [ 0.0052, -0.0099, -0.0050,  ...,  0.0113, -0.0249, -0.0080],
        [ 0.0486, -0.0004, -0.0031,  ...,  0.0433,  0.0057,  0.0085]],
       dtype=torch.float16), 'model.layers.3.mlp.down_proj.weight': tensor([[ 0.0014, -0.0079, -0.0008,  ..., -0.0033,  0.0087,  0.0142],
        [ 0.0225,  0.0028,  0.0088,  ..., -0.0140, -0.0148, -0.0148],
        [ 0.0144,  0.0119, -0.0174,  ..., -0.0200, -0.0066,  0.0060],
        ...,
        [ 0.0280, -0.0107, -0.0166,  ...,  0.0040,  0.0193,  0.0221],
        [-0.0217,  0.0099, -0.0106,  ..., -0.0006, -0.0170,  0.0130],
        [ 0.0110, -0.0169, -0.0266,  ...,  0.0033,  0.0121,  0.0063]],
       dtype=torch.float16), 'model.layers.3.input_layernorm.weight': tensor([0.2852, 0.2852, 0.2832,  ..., 0.2812, 0.2910, 0.2969],
       dtype=torch.float16), 'model.layers.3.post_attention_layernorm.weight': tensor([0.1738, 0.1748, 0.1689,  ..., 0.1719, 0.1719, 0.1758],
       dtype=torch.float16), 'model.layers.4.self_attn.q_proj.weight': tensor([[-0.0206, -0.0058,  0.0019,  ..., -0.0113, -0.0038,  0.0106],
        [ 0.0190, -0.0170, -0.0051,  ...,  0.0039, -0.0259, -0.0004],
        [-0.0124, -0.0312,  0.0122,  ..., -0.0027, -0.0195, -0.0239],
        ...,
        [ 0.0246,  0.0004, -0.0039,  ...,  0.0032,  0.0244, -0.0600],
        [-0.0293,  0.0085,  0.0295,  ..., -0.0561,  0.0037,  0.0337],
        [-0.0074, -0.0351,  0.0680,  ...,  0.0638,  0.0376, -0.0406]],
       dtype=torch.float16), 'model.layers.4.self_attn.k_proj.weight': tensor([[-0.0037,  0.0210, -0.0139,  ..., -0.0044,  0.0025, -0.0019],
        [-0.0307, -0.0041, -0.0032,  ..., -0.0014,  0.0142, -0.0028],
        [ 0.0089, -0.0021, -0.0143,  ...,  0.0076,  0.0189,  0.0352],
        ...,
        [-0.0089,  0.1188,  0.0593,  ...,  0.0388, -0.0216, -0.0060],
        [ 0.0320,  0.0533, -0.0162,  ...,  0.0641, -0.0399,  0.0720],
        [ 0.0100,  0.0640,  0.0195,  ..., -0.0011,  0.0424, -0.0209]],
       dtype=torch.float16), 'model.layers.4.self_attn.v_proj.weight': tensor([[-3.6507e-03, -8.4000e-03,  1.2493e-03,  ..., -6.4735e-03,
         -3.6030e-03, -6.0320e-05],
        [-1.4557e-02,  3.6133e-02,  5.1346e-03,  ...,  3.2978e-03,
          1.1721e-03,  2.7237e-03],
        [ 1.0719e-02, -6.2370e-03, -3.4729e-02,  ...,  5.4436e-03,
         -1.3771e-03, -1.8631e-02],
        ...,
        [-3.3283e-03, -8.3771e-03, -2.2263e-02,  ..., -9.6893e-03,
         -1.1740e-03,  3.3360e-03],
        [-2.0599e-03, -1.0277e-02, -1.9855e-03,  ...,  7.9956e-03,
         -1.5678e-03,  4.0550e-03],
        [-2.6131e-04, -1.7914e-02, -3.6087e-03,  ..., -5.3263e-04,
         -5.2681e-03,  1.1940e-02]], dtype=torch.float16), 'model.layers.4.self_attn.o_proj.weight': tensor([[ 0.0270,  0.0083, -0.0050,  ..., -0.0021, -0.0267, -0.0015],
        [ 0.0075, -0.0009, -0.0082,  ...,  0.0017, -0.0215,  0.0036],
        [-0.0045,  0.0041, -0.0073,  ..., -0.0134,  0.0101, -0.0084],
        ...,
        [-0.0148,  0.0272, -0.0037,  ..., -0.0209,  0.0081, -0.0208],
        [ 0.0033, -0.0025, -0.0150,  ..., -0.0094, -0.0004, -0.0059],
        [ 0.0100,  0.0215, -0.0056,  ..., -0.0007,  0.0051,  0.0010]],
       dtype=torch.float16), 'model.layers.4.mlp.gate_proj.weight': tensor([[-0.0053,  0.0065, -0.0110,  ..., -0.0182, -0.0035, -0.0159],
        [-0.0267,  0.0111,  0.0142,  ...,  0.0066,  0.0154, -0.0106],
        [-0.0136, -0.0220, -0.0006,  ...,  0.0055, -0.0028,  0.0260],
        ...,
        [ 0.0008, -0.0025,  0.0095,  ..., -0.0211,  0.0097, -0.0120],
        [-0.0265,  0.0148, -0.0281,  ...,  0.0098,  0.0180, -0.0102],
        [ 0.0017, -0.0143, -0.0135,  ..., -0.0124,  0.0221,  0.0190]],
       dtype=torch.float16), 'model.layers.4.mlp.up_proj.weight': tensor([[-1.6373e-02, -5.6725e-03, -4.0833e-02,  ...,  8.6670e-03,
         -8.2254e-04, -5.4932e-03],
        [-2.2400e-02, -4.0680e-02,  5.3253e-03,  ..., -8.6517e-03,
          9.8953e-03, -2.4872e-02],
        [-1.2989e-03,  2.9587e-02,  7.5042e-05,  ..., -2.8885e-02,
         -1.1322e-02,  8.4839e-03],
        ...,
        [-8.8882e-03, -3.1769e-02, -7.3433e-03,  ...,  1.2138e-02,
         -6.8016e-03,  5.5023e-02],
        [ 1.2787e-02, -1.0330e-02, -1.5060e-02,  ..., -4.2175e-02,
         -1.6281e-02,  9.5596e-03],
        [ 3.7937e-03,  1.3062e-02,  8.8272e-03,  ...,  3.7594e-03,
         -3.4237e-03, -2.4376e-03]], dtype=torch.float16), 'model.layers.4.mlp.down_proj.weight': tensor([[ 2.3834e-02, -4.2458e-03,  2.3529e-02,  ..., -1.9836e-02,
         -8.3983e-05,  2.9861e-02],
        [-5.7335e-03, -4.8859e-02,  4.5746e-02,  ..., -2.4323e-02,
         -2.1210e-02, -7.2365e-03],
        [-2.9135e-04, -2.7969e-02,  1.6556e-02,  ...,  1.1406e-02,
         -2.8000e-03,  2.2263e-02],
        ...,
        [-3.4393e-02, -1.9779e-03, -9.8801e-03,  ...,  2.4658e-02,
          2.1534e-03,  1.5030e-02],
        [-7.8430e-03,  1.8177e-03, -2.0020e-02,  ...,  1.2718e-02,
         -4.1931e-02, -1.1818e-02],
        [ 1.6479e-02, -3.2135e-02, -1.5076e-02,  ..., -3.5000e-03,
         -4.4739e-02, -2.3956e-02]], dtype=torch.float16), 'model.layers.4.input_layernorm.weight': tensor([0.2617, 0.2676, 0.2617,  ..., 0.2578, 0.2656, 0.2734],
       dtype=torch.float16), 'model.layers.4.post_attention_layernorm.weight': tensor([0.1914, 0.1895, 0.1855,  ..., 0.1904, 0.1885, 0.1895],
       dtype=torch.float16), 'model.layers.5.self_attn.q_proj.weight': tensor([[-0.0089, -0.0005, -0.0254,  ..., -0.0074, -0.0164,  0.0120],
        [-0.0202,  0.0197,  0.0401,  ..., -0.0054, -0.0094, -0.0347],
        [ 0.0045,  0.0043, -0.0135,  ...,  0.0205, -0.0172,  0.0105],
        ...,
        [-0.0121,  0.0095, -0.0033,  ...,  0.0542,  0.0104,  0.0356],
        [ 0.0433,  0.0046,  0.0262,  ..., -0.0415, -0.0351, -0.0303],
        [ 0.0103,  0.0194,  0.0370,  ..., -0.0282, -0.0147, -0.0007]],
       dtype=torch.float16), 'model.layers.5.self_attn.k_proj.weight': tensor([[-0.0049,  0.0373,  0.0067,  ...,  0.0198, -0.0056, -0.0016],
        [ 0.0006,  0.0027, -0.0324,  ...,  0.0231, -0.0123,  0.0318],
        [-0.0116, -0.0233,  0.0013,  ...,  0.0026, -0.0059,  0.0032],
        ...,
        [ 0.0031, -0.0016, -0.0228,  ...,  0.0397,  0.0098, -0.0320],
        [ 0.0524,  0.0166, -0.0242,  ..., -0.0012, -0.0159, -0.0361],
        [-0.0242, -0.0217,  0.0421,  ..., -0.0155, -0.0347,  0.0102]],
       dtype=torch.float16), 'model.layers.5.self_attn.v_proj.weight': tensor([[-3.0975e-02,  6.6643e-03,  9.8114e-03,  ...,  2.2919e-02,
          7.3671e-05,  2.3392e-02],
        [ 3.9635e-03,  1.0124e-02, -1.8448e-02,  ..., -1.1353e-02,
          3.7670e-03, -1.3893e-02],
        [ 2.2354e-02,  2.4128e-03, -2.9063e-04,  ..., -2.4063e-02,
          2.8976e-02,  1.1208e-02],
        ...,
        [ 2.0477e-02,  1.1581e-02,  1.0353e-02,  ...,  3.7048e-02,
         -5.7449e-03,  1.1454e-03],
        [-5.3596e-03,  3.0289e-03, -4.7684e-03,  ...,  9.9945e-04,
         -9.2010e-03,  8.7404e-04],
        [-1.2375e-02, -6.2561e-03,  2.1561e-02,  ..., -9.5673e-03,
         -9.2545e-03, -1.5900e-02]], dtype=torch.float16), 'model.layers.5.self_attn.o_proj.weight': tensor([[-0.0155, -0.0091,  0.0050,  ..., -0.0181, -0.0074,  0.0271],
        [ 0.0017,  0.0016, -0.0094,  ..., -0.0182,  0.0043,  0.0034],
        [-0.0014, -0.0026,  0.0131,  ...,  0.0181,  0.0119,  0.0234],
        ...,
        [ 0.0181,  0.0066, -0.0060,  ...,  0.0162,  0.0306, -0.0247],
        [-0.0016,  0.0017, -0.0038,  ..., -0.0184, -0.0139, -0.0013],
        [ 0.0051,  0.0035, -0.0148,  ..., -0.0011, -0.0060, -0.0158]],
       dtype=torch.float16), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0002, -0.0082, -0.0302,  ...,  0.0003, -0.0062, -0.0114],
        [ 0.0216, -0.0073, -0.0212,  ...,  0.0374, -0.0015,  0.0022],
        [ 0.0123,  0.0039, -0.0196,  ...,  0.0148,  0.0164, -0.0348],
        ...,
        [ 0.0065,  0.0096,  0.0416,  ..., -0.0671,  0.0157, -0.0199],
        [-0.0280,  0.0043,  0.0038,  ...,  0.0014,  0.0170, -0.0017],
        [ 0.0282, -0.0299, -0.0141,  ..., -0.0040, -0.0043, -0.0409]],
       dtype=torch.float16), 'model.layers.5.mlp.up_proj.weight': tensor([[-0.0063, -0.0135, -0.0069,  ..., -0.0147,  0.0037, -0.0168],
        [-0.0320, -0.0062,  0.0009,  ...,  0.0124,  0.0182,  0.0228],
        [-0.0019,  0.0090,  0.0094,  ...,  0.0040,  0.0080,  0.0185],
        ...,
        [ 0.0077,  0.0239, -0.0076,  ..., -0.0109,  0.0145,  0.0252],
        [ 0.0447, -0.0130, -0.0292,  ..., -0.0080, -0.0179,  0.0240],
        [ 0.0085,  0.0172,  0.0130,  ..., -0.0103, -0.0041, -0.0160]],
       dtype=torch.float16), 'model.layers.5.mlp.down_proj.weight': tensor([[-0.0074, -0.0270, -0.0031,  ...,  0.0008,  0.0067,  0.0141],
        [-0.0113,  0.0156,  0.0281,  ...,  0.0215,  0.0064, -0.0341],
        [ 0.0131,  0.0207,  0.0143,  ..., -0.0241, -0.0463,  0.0110],
        ...,
        [ 0.0110, -0.0240, -0.0051,  ...,  0.0063, -0.0257, -0.0186],
        [-0.0034, -0.0391,  0.0152,  ...,  0.0161,  0.0156, -0.0515],
        [ 0.0212,  0.0142, -0.0118,  ...,  0.0309,  0.0092, -0.0177]],
       dtype=torch.float16), 'model.layers.5.input_layernorm.weight': tensor([0.2617, 0.2695, 0.2637,  ..., 0.2500, 0.2695, 0.2676],
       dtype=torch.float16), 'model.layers.5.post_attention_layernorm.weight': tensor([0.2090, 0.1953, 0.1934,  ..., 0.2051, 0.2021, 0.2051],
       dtype=torch.float16), 'model.layers.6.self_attn.q_proj.weight': tensor([[-9.7351e-03, -1.1505e-02,  6.6071e-03,  ..., -3.3630e-02,
         -6.4468e-03, -4.9515e-03],
        [ 4.4250e-03, -6.5613e-03,  5.6343e-03,  ...,  1.4587e-02,
          3.5286e-03, -3.1464e-02],
        [-1.7654e-02,  2.4216e-02, -3.8513e-02,  ...,  3.0502e-02,
         -4.8431e-02, -3.2272e-03],
        ...,
        [ 1.2878e-02,  9.0103e-03, -3.7628e-02,  ...,  2.3987e-02,
          2.7657e-03,  1.5497e-03],
        [ 3.5614e-02,  3.2532e-02,  5.3329e-03,  ..., -9.7885e-03,
         -9.6497e-02, -2.0844e-02],
        [-6.3538e-02, -5.3558e-02, -4.8697e-05,  ...,  1.7288e-02,
          5.1155e-03,  8.5220e-03]], dtype=torch.float16), 'model.layers.6.self_attn.k_proj.weight': tensor([[ 0.0139, -0.0106,  0.0204,  ..., -0.0071,  0.0222,  0.0589],
        [-0.0198, -0.0036,  0.0422,  ...,  0.0071, -0.0126,  0.0158],
        [-0.0102, -0.0131, -0.0068,  ..., -0.0006, -0.0307, -0.0107],
        ...,
        [ 0.0214, -0.0376, -0.0183,  ...,  0.0607, -0.0023, -0.0482],
        [-0.0199,  0.0045, -0.0262,  ..., -0.0461, -0.0408,  0.0156],
        [-0.0544, -0.0241, -0.0399,  ...,  0.0161, -0.0420, -0.0188]],
       dtype=torch.float16), 'model.layers.6.self_attn.v_proj.weight': tensor([[ 0.0140,  0.0336,  0.0101,  ...,  0.0127, -0.0017,  0.0078],
        [ 0.0381, -0.0063, -0.0095,  ...,  0.0046, -0.0005,  0.0038],
        [-0.0079, -0.0024,  0.0124,  ...,  0.0101,  0.0240,  0.0046],
        ...,
        [-0.0221, -0.0061,  0.0052,  ...,  0.0010, -0.0165,  0.0085],
        [-0.0243, -0.0088, -0.0003,  ..., -0.0012, -0.0083,  0.0198],
        [ 0.0311,  0.0049,  0.0161,  ..., -0.0222,  0.0005, -0.0030]],
       dtype=torch.float16), 'model.layers.6.self_attn.o_proj.weight': tensor([[ 0.0112, -0.0127, -0.0365,  ..., -0.0135,  0.0086,  0.0113],
        [-0.0260,  0.0067, -0.0001,  ..., -0.0224,  0.0014, -0.0022],
        [ 0.0019, -0.0115, -0.0042,  ...,  0.0106,  0.0079,  0.0094],
        ...,
        [-0.0053, -0.0143, -0.0063,  ...,  0.0074, -0.0062,  0.0256],
        [-0.0204,  0.0092, -0.0014,  ..., -0.0024,  0.0081, -0.0214],
        [-0.0201, -0.0129,  0.0079,  ..., -0.0237,  0.0066,  0.0064]],
       dtype=torch.float16), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0222,  0.0260, -0.0189,  ..., -0.0039, -0.0074, -0.0042],
        [ 0.0321,  0.0016, -0.0231,  ...,  0.0066,  0.0205,  0.0123],
        [-0.0146,  0.0217, -0.0156,  ..., -0.0187,  0.0011,  0.0088],
        ...,
        [ 0.0056, -0.0261,  0.0048,  ...,  0.0091, -0.0184, -0.0066],
        [ 0.0083,  0.0047, -0.0169,  ..., -0.0235, -0.0025, -0.0016],
        [-0.0396, -0.0513,  0.0267,  ..., -0.0413, -0.0027,  0.0164]],
       dtype=torch.float16), 'model.layers.6.mlp.up_proj.weight': tensor([[-0.0147, -0.0145, -0.0228,  ...,  0.0067, -0.0053, -0.0105],
        [ 0.0071, -0.0485,  0.0392,  ...,  0.0123,  0.0003, -0.0055],
        [-0.0220, -0.0162, -0.0241,  ...,  0.0055,  0.0135,  0.0216],
        ...,
        [-0.0267,  0.0002,  0.0167,  ...,  0.0149, -0.0019,  0.0385],
        [ 0.0244,  0.0173, -0.0063,  ..., -0.0283,  0.0101,  0.0017],
        [-0.0249,  0.0287, -0.0220,  ...,  0.0081, -0.0178, -0.0498]],
       dtype=torch.float16), 'model.layers.6.mlp.down_proj.weight': tensor([[-0.0122,  0.0100, -0.0043,  ...,  0.0013,  0.0143,  0.0160],
        [-0.0081, -0.0157,  0.0045,  ..., -0.0036, -0.0266, -0.0125],
        [ 0.0030,  0.0159, -0.0086,  ...,  0.0244,  0.0240,  0.0227],
        ...,
        [ 0.0110, -0.0024,  0.0207,  ...,  0.0316, -0.0336, -0.0099],
        [ 0.0216, -0.0065,  0.0070,  ...,  0.0098, -0.0135, -0.0126],
        [ 0.0152, -0.0165, -0.0085,  ...,  0.0319, -0.0050,  0.0079]],
       dtype=torch.float16), 'model.layers.6.input_layernorm.weight': tensor([0.3223, 0.3613, 0.3242,  ..., 0.3145, 0.3359, 0.3223],
       dtype=torch.float16), 'model.layers.6.post_attention_layernorm.weight': tensor([0.2217, 0.2129, 0.2090,  ..., 0.2227, 0.2168, 0.2178],
       dtype=torch.float16), 'model.layers.7.self_attn.q_proj.weight': tensor([[-6.2637e-03, -1.0843e-03, -8.1658e-06,  ..., -3.4428e-03,
         -2.0752e-02, -6.3477e-03],
        [-1.0460e-02,  1.4365e-04, -1.0338e-03,  ...,  1.2947e-02,
         -3.6564e-03, -1.6739e-02],
        [ 5.0201e-03,  6.6719e-03, -3.1158e-02,  ..., -2.0416e-02,
         -7.5684e-03,  9.1553e-03],
        ...,
        [-1.5259e-03, -3.3752e-02, -2.5040e-02,  ..., -1.2718e-02,
          3.4180e-02,  3.5553e-02],
        [ 1.3344e-02,  5.2917e-02, -4.0039e-02,  ..., -1.1269e-02,
         -6.7383e-02, -5.6915e-02],
        [ 7.9102e-02, -2.4200e-02, -1.8158e-02,  ...,  8.2947e-02,
          3.1113e-02, -4.3716e-03]], dtype=torch.float16), 'model.layers.7.self_attn.k_proj.weight': tensor([[ 0.0032, -0.0077, -0.0123,  ...,  0.0064,  0.0024, -0.0099],
        [-0.0070, -0.0178,  0.0048,  ..., -0.0072,  0.0043,  0.0185],
        [-0.0024, -0.0103,  0.0107,  ..., -0.0082, -0.0065, -0.0179],
        ...,
        [ 0.0429,  0.0077,  0.0243,  ...,  0.0351,  0.0396,  0.0282],
        [ 0.0400,  0.0500, -0.0002,  ..., -0.0307, -0.0344, -0.0016],
        [ 0.0403,  0.0058,  0.0104,  ..., -0.0012,  0.0019, -0.0272]],
       dtype=torch.float16), 'model.layers.7.self_attn.v_proj.weight': tensor([[-1.4038e-02,  5.2605e-03,  1.2993e-02,  ...,  2.8549e-02,
          4.2191e-03, -1.3847e-02],
        [ 2.6672e-02, -2.6993e-02,  4.3640e-03,  ...,  2.0035e-02,
         -1.8890e-02, -1.5915e-02],
        [-6.8970e-03, -1.0094e-02, -3.4523e-03,  ..., -1.8097e-02,
          1.1665e-02, -7.9453e-05],
        ...,
        [-1.3485e-03, -3.8300e-02,  2.7924e-03,  ...,  5.7297e-03,
         -6.9427e-03, -4.0016e-03],
        [-3.7872e-02,  1.9394e-02, -2.7618e-02,  ..., -1.8707e-02,
          1.0628e-02, -1.9252e-04],
        [-7.4272e-03,  2.6951e-03, -8.4991e-03,  ...,  2.0401e-02,
          7.3357e-03,  1.1787e-02]], dtype=torch.float16), 'model.layers.7.self_attn.o_proj.weight': tensor([[ 0.0116, -0.0154,  0.0014,  ...,  0.0091, -0.0194,  0.0053],
        [-0.0066,  0.0281,  0.0115,  ..., -0.0417, -0.0176, -0.0100],
        [ 0.0047, -0.0011, -0.0201,  ..., -0.0096, -0.0059, -0.0107],
        ...,
        [-0.0163, -0.0252, -0.0036,  ...,  0.0259, -0.0186,  0.0010],
        [-0.0226,  0.0085,  0.0167,  ...,  0.0080, -0.0130,  0.0153],
        [ 0.0028, -0.0002,  0.0005,  ...,  0.0060, -0.0161,  0.0039]],
       dtype=torch.float16), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 7.7896e-03,  4.7340e-03, -5.0850e-03,  ..., -4.3983e-03,
         -3.3386e-02, -7.2746e-03],
        [-3.1647e-02,  1.0490e-02, -8.5449e-03,  ..., -4.9400e-03,
         -3.8891e-03,  2.0676e-03],
        [ 1.7075e-02, -3.0640e-02, -8.4043e-06,  ...,  2.5543e-02,
         -2.7069e-02,  3.4237e-03],
        ...,
        [ 1.6441e-03,  2.0504e-03, -1.4145e-02,  ..., -2.0462e-02,
          4.6463e-03, -2.1713e-02],
        [ 2.6989e-03,  1.8036e-02,  1.2131e-02,  ..., -4.7798e-03,
          6.1493e-03, -3.0258e-02],
        [ 1.9714e-02, -1.6556e-02, -1.0773e-02,  ...,  1.7761e-02,
          1.8799e-02, -6.9962e-03]], dtype=torch.float16), 'model.layers.7.mlp.up_proj.weight': tensor([[ 0.0250,  0.0014, -0.0038,  ...,  0.0224, -0.0396,  0.0026],
        [-0.0110, -0.0190,  0.0299,  ...,  0.0095, -0.0108,  0.0154],
        [ 0.0259, -0.0214,  0.0107,  ..., -0.0126,  0.0181, -0.0352],
        ...,
        [-0.0019, -0.0023, -0.0150,  ..., -0.0095, -0.0177,  0.0024],
        [ 0.0003,  0.0084,  0.0167,  ..., -0.0071,  0.0215, -0.0067],
        [-0.0245, -0.0151,  0.0063,  ...,  0.0170,  0.0119,  0.0050]],
       dtype=torch.float16), 'model.layers.7.mlp.down_proj.weight': tensor([[-0.0079, -0.0069,  0.0050,  ..., -0.0115, -0.0060, -0.0211],
        [-0.0095, -0.0072,  0.0217,  ..., -0.0125,  0.0093,  0.0047],
        [ 0.0106,  0.0077,  0.0231,  ..., -0.0157, -0.0048, -0.0210],
        ...,
        [-0.0100,  0.0002, -0.0191,  ...,  0.0123,  0.0022, -0.0257],
        [ 0.0428, -0.0037,  0.0073,  ..., -0.0168,  0.0043, -0.0133],
        [ 0.0117,  0.0195, -0.0333,  ...,  0.0041, -0.0196, -0.0012]],
       dtype=torch.float16), 'model.layers.7.input_layernorm.weight': tensor([0.3242, 0.3652, 0.3340,  ..., 0.3203, 0.3574, 0.3320],
       dtype=torch.float16), 'model.layers.7.post_attention_layernorm.weight': tensor([0.2383, 0.2197, 0.2236,  ..., 0.2314, 0.2324, 0.2314],
       dtype=torch.float16), 'model.layers.8.self_attn.q_proj.weight': tensor([[-0.0004, -0.0152, -0.0297,  ..., -0.0065,  0.0065, -0.0091],
        [-0.0125, -0.0141, -0.0328,  ...,  0.0038, -0.0112,  0.0025],
        [-0.0400, -0.0028, -0.0129,  ..., -0.0023,  0.0260, -0.0321],
        ...,
        [-0.0062,  0.0861,  0.0443,  ..., -0.0247, -0.0285, -0.0468],
        [ 0.0012, -0.0596, -0.0192,  ...,  0.0352,  0.0269, -0.0008],
        [-0.0648, -0.0531, -0.0116,  ..., -0.0541,  0.0303, -0.0170]],
       dtype=torch.float16), 'model.layers.8.self_attn.k_proj.weight': tensor([[-0.0032, -0.0058, -0.0180,  ..., -0.0109,  0.0052,  0.0049],
        [-0.0125,  0.0011, -0.0050,  ...,  0.0228, -0.0019,  0.0143],
        [-0.0167,  0.0023,  0.0027,  ...,  0.0063, -0.0082, -0.0249],
        ...,
        [ 0.0031, -0.0395, -0.0067,  ..., -0.0295, -0.0149,  0.0230],
        [ 0.0078,  0.0294,  0.0184,  ..., -0.0301,  0.0431, -0.0562],
        [ 0.0190, -0.0026, -0.0326,  ...,  0.0140,  0.0077, -0.0147]],
       dtype=torch.float16), 'model.layers.8.self_attn.v_proj.weight': tensor([[-0.0287, -0.0166,  0.0045,  ..., -0.0193, -0.0085, -0.0096],
        [-0.0234, -0.0132,  0.0059,  ...,  0.0352,  0.0096,  0.0248],
        [-0.0082,  0.0140,  0.0135,  ..., -0.0079,  0.0031, -0.0204],
        ...,
        [ 0.0319, -0.0149,  0.0065,  ...,  0.0218, -0.0201,  0.0271],
        [ 0.0327, -0.0165,  0.0041,  ...,  0.0074, -0.0036,  0.0023],
        [ 0.0126, -0.0004, -0.0005,  ..., -0.0017,  0.0009, -0.0126]],
       dtype=torch.float16), 'model.layers.8.self_attn.o_proj.weight': tensor([[ 0.0177,  0.0157, -0.0148,  ..., -0.0109,  0.0026,  0.0176],
        [ 0.0054,  0.0004, -0.0322,  ..., -0.0121, -0.0108, -0.0186],
        [ 0.0025,  0.0138, -0.0094,  ..., -0.0011,  0.0121,  0.0166],
        ...,
        [-0.0150,  0.0233, -0.0010,  ...,  0.0010, -0.0001, -0.0027],
        [ 0.0086,  0.0015, -0.0089,  ...,  0.0043,  0.0054, -0.0251],
        [-0.0232, -0.0003, -0.0096,  ...,  0.0193, -0.0100,  0.0087]],
       dtype=torch.float16), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0158, -0.0021, -0.0490,  ...,  0.0059, -0.0245, -0.0163],
        [-0.0002, -0.0475,  0.0061,  ..., -0.0033, -0.0370,  0.0276],
        [ 0.0212,  0.0191,  0.0176,  ...,  0.0272,  0.0241, -0.0056],
        ...,
        [-0.0111,  0.0015,  0.0134,  ...,  0.0221,  0.0168,  0.0057],
        [-0.0146,  0.0039,  0.0056,  ..., -0.0016, -0.0165,  0.0145],
        [-0.0243,  0.0096, -0.0066,  ..., -0.0134,  0.0060,  0.0033]],
       dtype=torch.float16), 'model.layers.8.mlp.up_proj.weight': tensor([[-0.0055,  0.0251, -0.0157,  ...,  0.0298,  0.0039, -0.0158],
        [-0.0517,  0.0134, -0.0384,  ...,  0.0145, -0.0113, -0.0159],
        [ 0.0176, -0.0004,  0.0102,  ..., -0.0102, -0.0179,  0.0334],
        ...,
        [-0.0138,  0.0403, -0.0309,  ...,  0.0130,  0.0027,  0.0163],
        [ 0.0054, -0.0047, -0.0058,  ..., -0.0160,  0.0193, -0.0173],
        [-0.0224,  0.0174, -0.0155,  ..., -0.0185, -0.0012, -0.0002]],
       dtype=torch.float16), 'model.layers.8.mlp.down_proj.weight': tensor([[-0.0099, -0.0094,  0.0129,  ...,  0.0072,  0.0198, -0.0290],
        [ 0.0178,  0.0132, -0.0227,  ..., -0.0072,  0.0143, -0.0171],
        [ 0.0061, -0.0186, -0.0251,  ..., -0.0091, -0.0019,  0.0038],
        ...,
        [ 0.0090, -0.0205, -0.0343,  ...,  0.0038,  0.0098, -0.0160],
        [ 0.0096,  0.0107, -0.0036,  ..., -0.0060, -0.0068, -0.0226],
        [-0.0031,  0.0103,  0.0024,  ...,  0.0047,  0.0011,  0.0048]],
       dtype=torch.float16), 'model.layers.8.input_layernorm.weight': tensor([0.3301, 0.3477, 0.3320,  ..., 0.3203, 0.3398, 0.3242],
       dtype=torch.float16), 'model.layers.8.post_attention_layernorm.weight': tensor([0.2422, 0.2314, 0.2236,  ..., 0.2363, 0.2324, 0.2305],
       dtype=torch.float16), 'model.layers.9.self_attn.q_proj.weight': tensor([[-0.0147,  0.0026,  0.0210,  ..., -0.0103, -0.0100, -0.0244],
        [-0.0023, -0.0385,  0.0208,  ..., -0.0013, -0.0039,  0.0068],
        [ 0.0012, -0.0021, -0.0153,  ..., -0.0283, -0.0279, -0.0179],
        ...,
        [-0.0006, -0.0509,  0.0130,  ...,  0.0190,  0.0121, -0.0163],
        [ 0.0161, -0.0186,  0.0037,  ...,  0.0068,  0.0028,  0.0125],
        [-0.0003,  0.0516,  0.0195,  ..., -0.0563,  0.0534, -0.0034]],
       dtype=torch.float16), 'model.layers.9.self_attn.k_proj.weight': tensor([[-0.0307,  0.0100, -0.0252,  ..., -0.0017, -0.0205, -0.0061],
        [-0.0069,  0.0352,  0.0098,  ..., -0.0149,  0.0085,  0.0003],
        [-0.0164, -0.0064,  0.0345,  ...,  0.0036, -0.0246, -0.0038],
        ...,
        [ 0.0229, -0.0136, -0.0035,  ..., -0.0085,  0.0241,  0.0240],
        [ 0.0319,  0.0002,  0.0217,  ...,  0.0495, -0.0169,  0.0517],
        [ 0.0084, -0.0259,  0.0257,  ...,  0.0061,  0.0235, -0.0248]],
       dtype=torch.float16), 'model.layers.9.self_attn.v_proj.weight': tensor([[-0.0064,  0.0087,  0.0034,  ...,  0.0043, -0.0216, -0.0148],
        [-0.0142, -0.0147, -0.0031,  ...,  0.0340, -0.0037, -0.0044],
        [ 0.0071, -0.0220,  0.0211,  ..., -0.0274,  0.0032, -0.0137],
        ...,
        [-0.0094, -0.0083,  0.0037,  ...,  0.0052, -0.0218, -0.0055],
        [-0.0172, -0.0003, -0.0087,  ..., -0.0159,  0.0021, -0.0135],
        [ 0.0245,  0.0242, -0.0037,  ..., -0.0092, -0.0047, -0.0060]],
       dtype=torch.float16), 'model.layers.9.self_attn.o_proj.weight': tensor([[ 0.0102,  0.0094,  0.0113,  ..., -0.0143,  0.0007, -0.0113],
        [-0.0017, -0.0193, -0.0068,  ..., -0.0033,  0.0041,  0.0140],
        [-0.0407, -0.0316,  0.0091,  ...,  0.0292,  0.0020,  0.0106],
        ...,
        [ 0.0148, -0.0133,  0.0091,  ...,  0.0057,  0.0059, -0.0098],
        [ 0.0072,  0.0159,  0.0002,  ...,  0.0084,  0.0001,  0.0006],
        [ 0.0189,  0.0456, -0.0234,  ..., -0.0009,  0.0104,  0.0045]],
       dtype=torch.float16), 'model.layers.9.mlp.gate_proj.weight': tensor([[-0.0097,  0.0258,  0.0002,  ..., -0.0271, -0.0084,  0.0018],
        [-0.0202,  0.0319,  0.0322,  ...,  0.0281,  0.0377,  0.0024],
        [ 0.0390,  0.0285, -0.0269,  ..., -0.0217,  0.0120,  0.0011],
        ...,
        [-0.0204, -0.0079, -0.0243,  ...,  0.0019, -0.0409,  0.0066],
        [-0.0061, -0.0243,  0.0275,  ..., -0.0112,  0.0039,  0.0113],
        [ 0.0146, -0.0229, -0.0039,  ...,  0.0122, -0.0083,  0.0163]],
       dtype=torch.float16), 'model.layers.9.mlp.up_proj.weight': tensor([[-0.0143,  0.0186,  0.0150,  ..., -0.0016, -0.0087,  0.0038],
        [ 0.0086, -0.0010,  0.0079,  ...,  0.0153,  0.0204, -0.0192],
        [-0.0182, -0.0051, -0.0223,  ..., -0.0026, -0.0114,  0.0033],
        ...,
        [ 0.0029,  0.0126, -0.0075,  ..., -0.0150, -0.0307, -0.0130],
        [ 0.0031,  0.0218, -0.0348,  ..., -0.0351, -0.0096, -0.0163],
        [ 0.0102, -0.0337, -0.0058,  ..., -0.0190,  0.0217, -0.0074]],
       dtype=torch.float16), 'model.layers.9.mlp.down_proj.weight': tensor([[-0.0030,  0.0313, -0.0411,  ...,  0.0004, -0.0109,  0.0136],
        [ 0.0216, -0.0283, -0.0173,  ..., -0.0057, -0.0223, -0.0278],
        [-0.0026, -0.0015,  0.0022,  ..., -0.0155,  0.0007, -0.0026],
        ...,
        [-0.0101,  0.0194,  0.0052,  ..., -0.0095, -0.0285,  0.0141],
        [-0.0309,  0.0034,  0.0155,  ..., -0.0204, -0.0034, -0.0333],
        [ 0.0165,  0.0171,  0.0078,  ...,  0.0404,  0.0161,  0.0167]],
       dtype=torch.float16), 'model.layers.9.input_layernorm.weight': tensor([0.3535, 0.3633, 0.3281,  ..., 0.3477, 0.3477, 0.3438],
       dtype=torch.float16), 'model.layers.9.post_attention_layernorm.weight': tensor([0.2490, 0.2334, 0.2285,  ..., 0.2451, 0.2422, 0.2383],
       dtype=torch.float16), 'model.layers.10.self_attn.q_proj.weight': tensor([[-3.6449e-03,  3.8357e-03,  2.0087e-05,  ..., -2.7161e-03,
         -6.6376e-03, -1.4206e-02],
        [-9.7427e-03, -4.9667e-03,  2.0599e-02,  ..., -1.9287e-02,
          6.4575e-02, -3.7270e-03],
        [-1.3718e-02, -1.5106e-02,  2.1040e-04,  ...,  3.4210e-02,
         -9.4452e-03, -1.4389e-02],
        ...,
        [ 3.2104e-02,  6.3049e-02, -1.7929e-02,  ...,  3.7445e-02,
          3.3508e-02, -9.3842e-03],
        [-6.6040e-02,  5.6519e-02, -2.7695e-03,  ..., -6.0577e-02,
         -5.7068e-03, -3.6221e-03],
        [-4.9713e-02, -2.1591e-02, -7.7477e-03,  ..., -1.2627e-02,
         -3.6346e-02, -9.3536e-03]], dtype=torch.float16), 'model.layers.10.self_attn.k_proj.weight': tensor([[-0.0320,  0.0131, -0.0093,  ..., -0.0153,  0.0091, -0.0001],
        [-0.0056,  0.0082, -0.0056,  ..., -0.0057, -0.0101,  0.0133],
        [-0.0008, -0.0022,  0.0067,  ..., -0.0274,  0.0042,  0.0012],
        ...,
        [-0.0464, -0.0599,  0.0127,  ...,  0.0291, -0.0853,  0.0117],
        [-0.0345, -0.0131,  0.0234,  ..., -0.0141, -0.0415, -0.0148],
        [-0.0192,  0.0225, -0.0224,  ...,  0.0083,  0.0425, -0.0002]],
       dtype=torch.float16), 'model.layers.10.self_attn.v_proj.weight': tensor([[-0.0387,  0.0081, -0.0087,  ...,  0.0097,  0.0140,  0.0083],
        [-0.0083,  0.0136,  0.0120,  ..., -0.0067, -0.0419,  0.0195],
        [ 0.0170, -0.0150,  0.0130,  ...,  0.0145,  0.0079, -0.0095],
        ...,
        [ 0.0214,  0.0277,  0.0017,  ...,  0.0253,  0.0023, -0.0228],
        [-0.0040,  0.0057, -0.0005,  ...,  0.0020,  0.0113, -0.0018],
        [ 0.0172,  0.0061, -0.0238,  ..., -0.0072, -0.0071,  0.0242]],
       dtype=torch.float16), 'model.layers.10.self_attn.o_proj.weight': tensor([[-0.0057,  0.0007, -0.0348,  ...,  0.0022,  0.0056,  0.0074],
        [ 0.0006, -0.0118,  0.0126,  ...,  0.0058,  0.0132,  0.0075],
        [ 0.0153, -0.0353, -0.0162,  ...,  0.0007, -0.0036, -0.0031],
        ...,
        [-0.0021,  0.0080, -0.0197,  ..., -0.0031, -0.0003,  0.0199],
        [ 0.0090, -0.0164, -0.0207,  ...,  0.0118,  0.0087,  0.0109],
        [ 0.0075, -0.0081, -0.0278,  ...,  0.0101, -0.0039,  0.0009]],
       dtype=torch.float16), 'model.layers.10.mlp.gate_proj.weight': tensor([[-0.0255, -0.0464, -0.0296,  ...,  0.0059, -0.0014, -0.0041],
        [-0.0152, -0.0224, -0.0173,  ...,  0.0032,  0.0152,  0.0143],
        [-0.0210, -0.0214,  0.0097,  ...,  0.0347, -0.0098,  0.0017],
        ...,
        [-0.0465, -0.0077,  0.0100,  ...,  0.0039, -0.0303,  0.0208],
        [ 0.0046,  0.0114,  0.0203,  ...,  0.0042, -0.0112, -0.0007],
        [-0.0159, -0.0042, -0.0147,  ..., -0.0145,  0.0072, -0.0121]],
       dtype=torch.float16), 'model.layers.10.mlp.up_proj.weight': tensor([[-0.0320, -0.0040, -0.0427,  ...,  0.0109, -0.0067, -0.0190],
        [-0.0074,  0.0061,  0.0065,  ...,  0.0190,  0.0319, -0.0167],
        [-0.0080, -0.0042,  0.0192,  ...,  0.0319, -0.0360,  0.0033],
        ...,
        [ 0.0242,  0.0213, -0.0094,  ..., -0.0432, -0.0039,  0.0027],
        [-0.0012, -0.0116, -0.0232,  ...,  0.0270, -0.0056,  0.0214],
        [-0.0042,  0.0167, -0.0049,  ..., -0.0009,  0.0034,  0.0205]],
       dtype=torch.float16), 'model.layers.10.mlp.down_proj.weight': tensor([[-0.0152, -0.0201, -0.0101,  ...,  0.0302, -0.0133,  0.0010],
        [-0.0054,  0.0221, -0.0139,  ..., -0.0116,  0.0119, -0.0105],
        [-0.0275, -0.0021,  0.0208,  ..., -0.0218, -0.0254,  0.0118],
        ...,
        [ 0.0098, -0.0068, -0.0057,  ...,  0.0063,  0.0142,  0.0074],
        [-0.0106,  0.0519, -0.0189,  ...,  0.0284,  0.0307, -0.0305],
        [-0.0471,  0.0020, -0.0252,  ..., -0.0184, -0.0151,  0.0109]],
       dtype=torch.float16), 'model.layers.10.input_layernorm.weight': tensor([0.3652, 0.3594, 0.3223,  ..., 0.3398, 0.3496, 0.3379],
       dtype=torch.float16), 'model.layers.10.post_attention_layernorm.weight': tensor([0.2500, 0.2383, 0.2285,  ..., 0.2432, 0.2432, 0.2432],
       dtype=torch.float16), 'model.layers.11.self_attn.q_proj.weight': tensor([[ 0.0161, -0.0006, -0.0169,  ...,  0.0251, -0.0088,  0.0062],
        [-0.0113,  0.0006,  0.0061,  ...,  0.0169,  0.0102,  0.0040],
        [ 0.0104,  0.0213, -0.0237,  ..., -0.0047, -0.0055,  0.0015],
        ...,
        [ 0.0066,  0.0024,  0.0322,  ...,  0.0338,  0.0438, -0.0291],
        [ 0.0504,  0.0148, -0.0166,  ..., -0.0151,  0.0161, -0.0268],
        [ 0.0818, -0.0201, -0.0214,  ..., -0.0201,  0.0410,  0.0539]],
       dtype=torch.float16), 'model.layers.11.self_attn.k_proj.weight': tensor([[-0.0052,  0.0221,  0.0030,  ..., -0.0179,  0.0177, -0.0154],
        [ 0.0012,  0.0016, -0.0310,  ..., -0.0106,  0.0045,  0.0256],
        [ 0.0298, -0.0297,  0.0027,  ...,  0.0140,  0.0046,  0.0079],
        ...,
        [-0.0032,  0.0288,  0.0043,  ..., -0.0189, -0.0055,  0.0403],
        [ 0.0598, -0.0065, -0.0142,  ..., -0.0078,  0.0050, -0.0079],
        [ 0.0110,  0.0065,  0.0253,  ..., -0.0007,  0.0569,  0.0267]],
       dtype=torch.float16), 'model.layers.11.self_attn.v_proj.weight': tensor([[ 9.6436e-03,  1.0605e-03, -4.5738e-03,  ..., -2.2232e-02,
         -1.0233e-03,  7.4806e-03],
        [ 2.6855e-03, -6.0806e-03, -1.6937e-02,  ..., -5.5611e-05,
          3.7360e-04, -2.7130e-02],
        [ 2.9392e-03,  9.2468e-03, -7.0686e-03,  ...,  1.6724e-02,
          1.0735e-02, -2.5055e-02],
        ...,
        [-2.0782e-02,  7.5455e-03, -1.4633e-02,  ...,  8.2016e-03,
         -1.7349e-02, -2.2812e-03],
        [-9.9487e-03,  1.0506e-02, -1.1917e-02,  ..., -1.3245e-02,
         -1.7868e-02,  3.2711e-03],
        [ 1.7990e-02, -2.1179e-02, -1.4639e-03,  ..., -4.0344e-02,
          1.8826e-03, -1.2375e-02]], dtype=torch.float16), 'model.layers.11.self_attn.o_proj.weight': tensor([[-0.0191, -0.0035,  0.0060,  ...,  0.0097,  0.0109,  0.0016],
        [-0.0016, -0.0260,  0.0116,  ..., -0.0118, -0.0028, -0.0255],
        [-0.0051, -0.0058,  0.0210,  ...,  0.0021, -0.0066,  0.0139],
        ...,
        [ 0.0016, -0.0042,  0.0228,  ...,  0.0024, -0.0016, -0.0029],
        [ 0.0077,  0.0177,  0.0082,  ...,  0.0172,  0.0129, -0.0298],
        [-0.0027, -0.0047,  0.0054,  ..., -0.0081, -0.0022, -0.0107]],
       dtype=torch.float16), 'model.layers.11.mlp.gate_proj.weight': tensor([[-0.0440, -0.0086,  0.0052,  ...,  0.0062, -0.0116,  0.0425],
        [ 0.0074, -0.0107,  0.0206,  ...,  0.0087, -0.0197, -0.0413],
        [-0.0010, -0.0459, -0.0289,  ..., -0.0025, -0.0084, -0.0026],
        ...,
        [-0.0202, -0.0397, -0.0216,  ..., -0.0041, -0.0321,  0.0039],
        [ 0.0090, -0.0044, -0.0364,  ..., -0.0127,  0.0069,  0.0010],
        [ 0.0023,  0.0186,  0.0080,  ...,  0.0468, -0.0007, -0.0140]],
       dtype=torch.float16), 'model.layers.11.mlp.up_proj.weight': tensor([[-0.0093,  0.0016, -0.0275,  ...,  0.0240,  0.0097,  0.0313],
        [ 0.0179, -0.0028, -0.0222,  ...,  0.0172, -0.0467,  0.0077],
        [-0.0064, -0.0369,  0.0014,  ..., -0.0048, -0.0177,  0.0154],
        ...,
        [ 0.0408,  0.0105, -0.0095,  ...,  0.0014, -0.0005,  0.0161],
        [-0.0116,  0.0200,  0.0059,  ...,  0.0163,  0.0094,  0.0065],
        [-0.0041,  0.0019, -0.0054,  ..., -0.0172, -0.0005,  0.0250]],
       dtype=torch.float16), 'model.layers.11.mlp.down_proj.weight': tensor([[-0.0162,  0.0454,  0.0091,  ...,  0.0194,  0.0163, -0.0040],
        [-0.0136, -0.0092, -0.0251,  ..., -0.0202, -0.0090,  0.0154],
        [-0.0237, -0.0169,  0.0102,  ...,  0.0052, -0.0217, -0.0031],
        ...,
        [ 0.0215,  0.0262, -0.0104,  ..., -0.0017, -0.0003,  0.0087],
        [-0.0111, -0.0290, -0.0306,  ..., -0.0254, -0.0089,  0.0139],
        [ 0.0362,  0.0240,  0.0214,  ..., -0.0028, -0.0135,  0.0383]],
       dtype=torch.float16), 'model.layers.11.input_layernorm.weight': tensor([0.3965, 0.3965, 0.3652,  ..., 0.3848, 0.3828, 0.3711],
       dtype=torch.float16), 'model.layers.11.post_attention_layernorm.weight': tensor([0.2598, 0.2471, 0.2383,  ..., 0.2578, 0.2559, 0.2559],
       dtype=torch.float16), 'model.layers.12.self_attn.q_proj.weight': tensor([[-0.0093, -0.0171,  0.0036,  ...,  0.0262, -0.0099,  0.0055],
        [ 0.0065, -0.0070, -0.0075,  ..., -0.0127,  0.0223,  0.0202],
        [ 0.0106,  0.0411, -0.0328,  ...,  0.0061,  0.0025, -0.0291],
        ...,
        [ 0.0094,  0.0321, -0.0197,  ..., -0.0311, -0.0004, -0.0008],
        [ 0.0424, -0.0059,  0.0097,  ...,  0.0322,  0.0067, -0.0247],
        [ 0.0332,  0.0143, -0.0364,  ..., -0.0210,  0.0215,  0.0238]],
       dtype=torch.float16), 'model.layers.12.self_attn.k_proj.weight': tensor([[ 0.0099, -0.0011, -0.0045,  ...,  0.0193, -0.0024, -0.0102],
        [ 0.0073,  0.0208, -0.0157,  ..., -0.0014, -0.0157, -0.0293],
        [-0.0113, -0.0283,  0.0173,  ...,  0.0087,  0.0026,  0.0026],
        ...,
        [ 0.0132,  0.0322, -0.0148,  ..., -0.0355, -0.0164, -0.0242],
        [-0.0381,  0.0037,  0.0226,  ..., -0.0282,  0.0146, -0.0006],
        [-0.0007,  0.0322,  0.0109,  ...,  0.0129, -0.0465, -0.0404]],
       dtype=torch.float16), 'model.layers.12.self_attn.v_proj.weight': tensor([[ 0.0064,  0.0072,  0.0069,  ..., -0.0077,  0.0109, -0.0189],
        [-0.0275,  0.0104, -0.0036,  ..., -0.0175, -0.0006,  0.0191],
        [-0.0148, -0.0132,  0.0088,  ..., -0.0069,  0.0475, -0.0107],
        ...,
        [ 0.0081, -0.0017, -0.0150,  ..., -0.0068, -0.0115, -0.0013],
        [-0.0010, -0.0147, -0.0047,  ...,  0.0034,  0.0109,  0.0122],
        [ 0.0225,  0.0017,  0.0007,  ...,  0.0178,  0.0139, -0.0070]],
       dtype=torch.float16), 'model.layers.12.self_attn.o_proj.weight': tensor([[ 0.0277,  0.0071, -0.0019,  ..., -0.0012,  0.0083, -0.0061],
        [-0.0092, -0.0141, -0.0014,  ..., -0.0108,  0.0061, -0.0138],
        [ 0.0068, -0.0023, -0.0018,  ...,  0.0037, -0.0232,  0.0125],
        ...,
        [ 0.0032, -0.0023,  0.0126,  ..., -0.0084, -0.0009,  0.0019],
        [-0.0108, -0.0346, -0.0278,  ..., -0.0121,  0.0109,  0.0143],
        [ 0.0210,  0.0093,  0.0084,  ...,  0.0209, -0.0084, -0.0171]],
       dtype=torch.float16), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0057, -0.0110,  0.0123,  ..., -0.0042,  0.0268, -0.0024],
        [-0.0266, -0.0214,  0.0172,  ...,  0.0121,  0.0153,  0.0057],
        [-0.0005,  0.0258, -0.0114,  ..., -0.0099, -0.0289, -0.0045],
        ...,
        [-0.0024,  0.0108,  0.0106,  ..., -0.0328,  0.0070,  0.0276],
        [-0.0325, -0.0083,  0.0082,  ...,  0.0103,  0.0123, -0.0085],
        [ 0.0045, -0.0267, -0.0056,  ..., -0.0053, -0.0018, -0.0202]],
       dtype=torch.float16), 'model.layers.12.mlp.up_proj.weight': tensor([[ 2.9488e-03,  1.7151e-02,  3.6030e-03,  ..., -9.1076e-05,
          1.3832e-02,  1.5427e-02],
        [-3.6373e-03, -1.4801e-02, -1.3435e-02,  ...,  6.5842e-03,
         -7.0915e-03,  2.4414e-02],
        [ 1.4610e-02, -1.2291e-02,  7.4959e-03,  ..., -4.1534e-02,
          4.9171e-03,  1.6441e-03],
        ...,
        [-2.6154e-02, -3.3844e-02, -7.3738e-03,  ...,  1.6922e-02,
         -1.5038e-02,  3.0403e-03],
        [-1.5144e-03, -4.3915e-02, -8.0156e-04,  ...,  1.3924e-02,
          3.0556e-03, -1.5656e-02],
        [ 2.2144e-03, -2.8961e-02,  3.7813e-04,  ...,  3.2440e-02,
         -3.6602e-03, -3.8300e-02]], dtype=torch.float16), 'model.layers.12.mlp.down_proj.weight': tensor([[ 0.0081, -0.0018, -0.0294,  ..., -0.0123,  0.0035,  0.0029],
        [ 0.0170, -0.0288,  0.0046,  ..., -0.0004, -0.0089, -0.0230],
        [ 0.0200,  0.0030,  0.0241,  ...,  0.0043, -0.0012, -0.0281],
        ...,
        [ 0.0183, -0.0085, -0.0380,  ...,  0.0313, -0.0193, -0.0176],
        [-0.0259,  0.0179,  0.0106,  ..., -0.0092,  0.0359, -0.0229],
        [ 0.0075,  0.0262,  0.0221,  ..., -0.0381,  0.0273, -0.0022]],
       dtype=torch.float16), 'model.layers.12.input_layernorm.weight': tensor([0.4062, 0.4023, 0.3691,  ..., 0.3848, 0.3867, 0.3887],
       dtype=torch.float16), 'model.layers.12.post_attention_layernorm.weight': tensor([0.2656, 0.2520, 0.2432,  ..., 0.2656, 0.2617, 0.2598],
       dtype=torch.float16), 'model.layers.13.self_attn.q_proj.weight': tensor([[-0.0002, -0.0013, -0.0132,  ...,  0.0055, -0.0150, -0.0128],
        [-0.0118, -0.0142,  0.0031,  ..., -0.0004,  0.0004, -0.0026],
        [-0.0175,  0.0138,  0.0197,  ..., -0.0115, -0.0075, -0.0069],
        ...,
        [ 0.0483,  0.0084,  0.0043,  ...,  0.0573,  0.0140, -0.0512],
        [ 0.0078,  0.0083, -0.0259,  ...,  0.0091,  0.0111, -0.0104],
        [-0.0040, -0.0248, -0.0212,  ..., -0.0068,  0.0285, -0.0065]],
       dtype=torch.float16), 'model.layers.13.self_attn.k_proj.weight': tensor([[ 0.0134,  0.0048, -0.0030,  ..., -0.0130,  0.0337,  0.0125],
        [ 0.0155,  0.0307, -0.0005,  ..., -0.0055,  0.0136,  0.0046],
        [-0.0007, -0.0130,  0.0334,  ..., -0.0083,  0.0110, -0.0375],
        ...,
        [ 0.0375,  0.0356,  0.0033,  ...,  0.0048, -0.0061, -0.0118],
        [-0.0010,  0.0045,  0.0287,  ..., -0.0342, -0.0217,  0.0352],
        [-0.0229, -0.0535, -0.0142,  ..., -0.0378, -0.0310,  0.0118]],
       dtype=torch.float16), 'model.layers.13.self_attn.v_proj.weight': tensor([[ 0.0149,  0.0064, -0.0058,  ..., -0.0005,  0.0173,  0.0124],
        [-0.0029,  0.0087,  0.0005,  ...,  0.0233, -0.0065, -0.0029],
        [ 0.0146, -0.0016, -0.0023,  ..., -0.0212,  0.0366, -0.0090],
        ...,
        [-0.0011,  0.0251, -0.0052,  ..., -0.0111,  0.0272, -0.0211],
        [-0.0103,  0.0104,  0.0128,  ...,  0.0017,  0.0274,  0.0058],
        [-0.0045, -0.0064,  0.0239,  ...,  0.0154, -0.0026,  0.0374]],
       dtype=torch.float16), 'model.layers.13.self_attn.o_proj.weight': tensor([[-0.0035,  0.0010, -0.0044,  ..., -0.0015, -0.0045, -0.0012],
        [ 0.0222,  0.0148,  0.0101,  ..., -0.0146, -0.0108,  0.0024],
        [ 0.0118,  0.0055,  0.0036,  ...,  0.0065, -0.0233, -0.0088],
        ...,
        [-0.0102,  0.0102,  0.0194,  ..., -0.0114, -0.0154, -0.0165],
        [ 0.0083, -0.0005,  0.0301,  ..., -0.0037, -0.0268, -0.0238],
        [ 0.0100,  0.0019,  0.0086,  ...,  0.0171, -0.0083, -0.0238]],
       dtype=torch.float16), 'model.layers.13.mlp.gate_proj.weight': tensor([[ 0.0249, -0.0034, -0.0082,  ...,  0.0114,  0.0034, -0.0122],
        [-0.0141,  0.0452,  0.0071,  ...,  0.0416, -0.0012, -0.0260],
        [ 0.0035, -0.0199, -0.0103,  ...,  0.0047, -0.0093, -0.0152],
        ...,
        [ 0.0153, -0.0196,  0.0202,  ..., -0.0065,  0.0133,  0.0111],
        [ 0.0154, -0.0125,  0.0203,  ...,  0.0181,  0.0106, -0.0270],
        [ 0.0028,  0.0392,  0.0161,  ..., -0.0045,  0.0059,  0.0285]],
       dtype=torch.float16), 'model.layers.13.mlp.up_proj.weight': tensor([[-0.0423,  0.0199, -0.0013,  ...,  0.0037,  0.0091,  0.0011],
        [ 0.0138, -0.0066,  0.0247,  ...,  0.0468,  0.0286,  0.0224],
        [ 0.0281, -0.0344,  0.0093,  ...,  0.0069,  0.0009, -0.0082],
        ...,
        [-0.0130, -0.0038,  0.0297,  ...,  0.0190, -0.0247,  0.0139],
        [-0.0103, -0.0171,  0.0079,  ...,  0.0177,  0.0563,  0.0096],
        [ 0.0117, -0.0212,  0.0179,  ..., -0.0185, -0.0004,  0.0269]],
       dtype=torch.float16), 'model.layers.13.mlp.down_proj.weight': tensor([[-0.0062, -0.0036, -0.0027,  ...,  0.0226, -0.0265, -0.0220],
        [-0.0117,  0.0470, -0.0413,  ..., -0.0018,  0.0133, -0.0090],
        [ 0.0081,  0.0038,  0.0183,  ...,  0.0015, -0.0249, -0.0031],
        ...,
        [ 0.0058,  0.0077,  0.0354,  ..., -0.0014, -0.0209,  0.0290],
        [ 0.0167, -0.0015,  0.0188,  ..., -0.0109,  0.0164, -0.0045],
        [ 0.0029, -0.0229,  0.0393,  ...,  0.0041,  0.0022,  0.0325]],
       dtype=torch.float16), 'model.layers.13.input_layernorm.weight': tensor([0.4199, 0.4121, 0.3770,  ..., 0.3926, 0.3848, 0.3965],
       dtype=torch.float16), 'model.layers.13.post_attention_layernorm.weight': tensor([0.2715, 0.2598, 0.2539,  ..., 0.2715, 0.2734, 0.2656],
       dtype=torch.float16), 'model.layers.14.self_attn.q_proj.weight': tensor([[-0.0088, -0.0028,  0.0195,  ..., -0.0054,  0.0162,  0.0367],
        [ 0.0097,  0.0160, -0.0124,  ..., -0.0348, -0.0203, -0.0406],
        [-0.0202, -0.0112,  0.0171,  ...,  0.0106,  0.0140, -0.0339],
        ...,
        [-0.0201,  0.0005, -0.0295,  ...,  0.0018,  0.0130, -0.0074],
        [ 0.0269, -0.0389,  0.0497,  ..., -0.0134,  0.0061, -0.0092],
        [-0.0175, -0.0090, -0.0035,  ...,  0.0170,  0.0184, -0.0447]],
       dtype=torch.float16), 'model.layers.14.self_attn.k_proj.weight': tensor([[-0.0143, -0.0049,  0.0068,  ..., -0.0091,  0.0271,  0.0431],
        [ 0.0191,  0.0324, -0.0204,  ..., -0.0030, -0.0276, -0.0050],
        [-0.0183,  0.0034,  0.0196,  ...,  0.0239,  0.0110,  0.0012],
        ...,
        [-0.0387, -0.0029,  0.0264,  ..., -0.0049,  0.0017, -0.0254],
        [-0.0293,  0.0005,  0.0153,  ..., -0.0359, -0.0144,  0.0012],
        [-0.0202,  0.0292,  0.0236,  ...,  0.0703,  0.0087, -0.0386]],
       dtype=torch.float16), 'model.layers.14.self_attn.v_proj.weight': tensor([[ 7.4310e-03,  7.7629e-03, -3.8025e-02,  ..., -3.4210e-02,
         -5.2032e-03,  1.2451e-02],
        [-1.0204e-03, -2.5452e-02, -3.0117e-03,  ...,  1.0887e-02,
         -5.2512e-05, -3.2425e-03],
        [ 2.6276e-02, -1.5022e-02,  2.2659e-03,  ..., -5.5466e-03,
          2.3460e-03,  8.2321e-03],
        ...,
        [ 1.5747e-02, -1.1642e-02,  1.5343e-02,  ...,  1.5533e-02,
         -1.1597e-02,  2.6016e-03],
        [-1.1391e-02,  2.2583e-02, -3.5553e-02,  ..., -7.8058e-04,
         -8.8654e-03, -2.5574e-02],
        [ 3.5992e-03,  2.3102e-02, -2.2568e-02,  ..., -5.2261e-03,
         -3.3932e-03,  1.8295e-02]], dtype=torch.float16), 'model.layers.14.self_attn.o_proj.weight': tensor([[-0.0108,  0.0044, -0.0227,  ..., -0.0021,  0.0010, -0.0110],
        [ 0.0080,  0.0304,  0.0077,  ...,  0.0221, -0.0049,  0.0021],
        [ 0.0060,  0.0082,  0.0024,  ...,  0.0075,  0.0206,  0.0054],
        ...,
        [ 0.0245, -0.0073,  0.0008,  ..., -0.0073, -0.0022,  0.0139],
        [-0.0025,  0.0010, -0.0195,  ..., -0.0021,  0.0362,  0.0155],
        [-0.0085, -0.0104, -0.0139,  ..., -0.0070,  0.0146,  0.0060]],
       dtype=torch.float16), 'model.layers.14.mlp.gate_proj.weight': tensor([[-0.0084,  0.0011, -0.0090,  ...,  0.0102, -0.0185, -0.0064],
        [ 0.0296,  0.0080, -0.0390,  ...,  0.0377,  0.0119, -0.0075],
        [ 0.0095,  0.0148, -0.0004,  ..., -0.0081,  0.0108, -0.0179],
        ...,
        [ 0.0065,  0.0105, -0.0190,  ...,  0.0003, -0.0047,  0.0004],
        [ 0.0033,  0.0159,  0.0201,  ..., -0.0192,  0.0087,  0.0073],
        [ 0.0200,  0.0017,  0.0183,  ..., -0.0106, -0.0248,  0.0258]],
       dtype=torch.float16), 'model.layers.14.mlp.up_proj.weight': tensor([[ 0.0052,  0.0099,  0.0201,  ..., -0.0153,  0.0073,  0.0048],
        [ 0.0269,  0.0089, -0.0300,  ...,  0.0064,  0.0262,  0.0104],
        [ 0.0012, -0.0055,  0.0300,  ..., -0.0013,  0.0177, -0.0023],
        ...,
        [-0.0164, -0.0013, -0.0479,  ..., -0.0145, -0.0116, -0.0048],
        [-0.0415,  0.0074, -0.0075,  ..., -0.0081,  0.0239, -0.0144],
        [ 0.0029,  0.0235,  0.0122,  ...,  0.0086, -0.0140,  0.0131]],
       dtype=torch.float16), 'model.layers.14.mlp.down_proj.weight': tensor([[ 0.0100,  0.0243,  0.0113,  ..., -0.0290, -0.0019, -0.0056],
        [ 0.0121,  0.0222, -0.0091,  ...,  0.0131, -0.0032,  0.0189],
        [ 0.0080, -0.0420,  0.0119,  ...,  0.0042, -0.0302,  0.0124],
        ...,
        [ 0.0005,  0.0152, -0.0169,  ..., -0.0046, -0.0100, -0.0109],
        [ 0.0242,  0.0335,  0.0364,  ..., -0.0051, -0.0155,  0.0210],
        [-0.0245,  0.0057, -0.0101,  ..., -0.0300,  0.0070,  0.0187]],
       dtype=torch.float16), 'model.layers.14.input_layernorm.weight': tensor([0.4219, 0.4297, 0.3789,  ..., 0.4141, 0.4062, 0.3984],
       dtype=torch.float16), 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2734, 0.2656,  ..., 0.2871, 0.2832, 0.2793],
       dtype=torch.float16), 'model.layers.15.self_attn.q_proj.weight': tensor([[-0.0194, -0.0154, -0.0142,  ...,  0.0138, -0.0084,  0.0010],
        [ 0.0363, -0.0190,  0.0038,  ..., -0.0058,  0.0144,  0.0015],
        [ 0.0084, -0.0132,  0.0030,  ...,  0.0098, -0.0134, -0.0160],
        ...,
        [-0.0477, -0.0267,  0.0071,  ..., -0.0063, -0.0128,  0.0200],
        [-0.0155, -0.0536,  0.0174,  ...,  0.0155, -0.0015,  0.0025],
        [ 0.0236,  0.0251,  0.0278,  ..., -0.0140, -0.0227, -0.0165]],
       dtype=torch.float16), 'model.layers.15.self_attn.k_proj.weight': tensor([[ 0.0209, -0.0054, -0.0045,  ..., -0.0027,  0.0014,  0.0044],
        [ 0.0111, -0.0042, -0.0052,  ..., -0.0015,  0.0046, -0.0135],
        [-0.0021,  0.0020, -0.0083,  ..., -0.0007,  0.0133, -0.0119],
        ...,
        [-0.0540, -0.0380,  0.0168,  ...,  0.0214,  0.0069, -0.0060],
        [ 0.0092,  0.0011,  0.0159,  ...,  0.0275, -0.0217,  0.0132],
        [-0.0067, -0.0060,  0.0341,  ..., -0.0027, -0.0171,  0.0033]],
       dtype=torch.float16), 'model.layers.15.self_attn.v_proj.weight': tensor([[ 0.0088,  0.0023,  0.0053,  ...,  0.0037,  0.0141,  0.0177],
        [-0.0096, -0.0142,  0.0151,  ...,  0.0168,  0.0018,  0.0224],
        [ 0.0075, -0.0377, -0.0064,  ..., -0.0365,  0.0073,  0.0073],
        ...,
        [-0.0038, -0.0107,  0.0116,  ...,  0.0066,  0.0181, -0.0141],
        [ 0.0056, -0.0006, -0.0311,  ...,  0.0116,  0.0151, -0.0054],
        [ 0.0169,  0.0104,  0.0152,  ..., -0.0160,  0.0075,  0.0077]],
       dtype=torch.float16), 'model.layers.15.self_attn.o_proj.weight': tensor([[ 0.0012,  0.0029, -0.0154,  ...,  0.0104, -0.0127,  0.0282],
        [-0.0046, -0.0112, -0.0177,  ...,  0.0099, -0.0261,  0.0198],
        [ 0.0020, -0.0083,  0.0008,  ...,  0.0102, -0.0070,  0.0095],
        ...,
        [-0.0089, -0.0197,  0.0142,  ..., -0.0044, -0.0201, -0.0100],
        [ 0.0005, -0.0017, -0.0072,  ...,  0.0113,  0.0051,  0.0044],
        [-0.0241,  0.0053,  0.0263,  ..., -0.0118, -0.0254, -0.0296]],
       dtype=torch.float16), 'model.layers.15.mlp.gate_proj.weight': tensor([[-0.0145,  0.0259, -0.0075,  ...,  0.0116, -0.0298,  0.0140],
        [ 0.0069, -0.0101,  0.0278,  ..., -0.0192,  0.0056,  0.0099],
        [ 0.0088, -0.0179, -0.0112,  ...,  0.0231, -0.0539, -0.0260],
        ...,
        [-0.0106, -0.0046,  0.0301,  ..., -0.0094,  0.0175,  0.0069],
        [-0.0124, -0.0172,  0.0103,  ..., -0.0082, -0.0106, -0.0440],
        [ 0.0040, -0.0142, -0.0008,  ...,  0.0002,  0.0071, -0.0001]],
       dtype=torch.float16), 'model.layers.15.mlp.up_proj.weight': tensor([[-1.2886e-02, -9.5215e-03,  2.7924e-02,  ...,  1.2367e-02,
          1.1269e-02, -4.3579e-02],
        [-1.5732e-02,  4.2908e-02,  2.9343e-02,  ...,  1.0506e-02,
          7.6866e-03,  3.9864e-03],
        [-4.2419e-02, -7.7896e-03, -4.7994e-04,  ..., -1.5518e-02,
          1.5602e-02, -1.0269e-02],
        ...,
        [-6.7863e-03, -2.3376e-02, -7.8659e-03,  ...,  8.5068e-03,
         -4.8757e-05, -4.9782e-03],
        [ 2.7618e-02, -5.3329e-03,  7.8354e-03,  ..., -1.0330e-02,
          1.5747e-02,  5.7030e-04],
        [-7.5302e-03, -2.7130e-02, -9.7809e-03,  ...,  4.5633e-04,
         -1.2245e-02,  1.1940e-03]], dtype=torch.float16), 'model.layers.15.mlp.down_proj.weight': tensor([[-1.2512e-02, -6.8245e-03, -1.6098e-02,  ...,  2.5909e-02,
          9.1171e-03, -1.0674e-02],
        [ 1.0666e-02, -1.1749e-02, -2.6199e-02,  ..., -1.1993e-02,
         -2.3163e-02,  1.6129e-02],
        [ 3.8452e-02,  4.4830e-02, -1.5747e-02,  ..., -1.1589e-02,
          3.4302e-02,  1.8906e-02],
        ...,
        [-4.5853e-03, -3.9978e-02,  6.3210e-03,  ...,  9.4833e-03,
          5.5046e-03,  7.1466e-05],
        [-4.1779e-02, -1.7502e-02, -1.1826e-03,  ..., -2.9480e-02,
         -1.5137e-02,  7.0038e-03],
        [ 1.5354e-03,  2.3773e-02, -6.3553e-03,  ..., -1.7715e-02,
         -3.2593e-02, -2.0401e-02]], dtype=torch.float16), 'model.layers.15.input_layernorm.weight': tensor([0.4160, 0.4102, 0.3809,  ..., 0.3867, 0.3945, 0.3945],
       dtype=torch.float16), 'model.layers.15.post_attention_layernorm.weight': tensor([0.2930, 0.2793, 0.2793,  ..., 0.2969, 0.2910, 0.2891],
       dtype=torch.float16), 'model.layers.16.self_attn.q_proj.weight': tensor([[ 0.0090,  0.0135, -0.0253,  ...,  0.0048,  0.0263, -0.0078],
        [ 0.0172, -0.0415,  0.0228,  ...,  0.0170,  0.0186, -0.0237],
        [-0.0128, -0.0067,  0.0088,  ..., -0.0257,  0.0021, -0.0261],
        ...,
        [ 0.0328, -0.0378, -0.0080,  ..., -0.0196,  0.0181, -0.0271],
        [-0.0166, -0.0170,  0.0283,  ...,  0.0018, -0.0181,  0.0157],
        [ 0.0046,  0.0219,  0.0146,  ..., -0.0030, -0.0327, -0.0095]],
       dtype=torch.float16), 'model.layers.16.self_attn.k_proj.weight': tensor([[-0.0072,  0.0235,  0.0023,  ...,  0.0131,  0.0227,  0.0217],
        [ 0.0223, -0.0315,  0.0097,  ..., -0.0058, -0.0194, -0.0077],
        [ 0.0272, -0.0056, -0.0197,  ..., -0.0234,  0.0092, -0.0277],
        ...,
        [ 0.0239,  0.0135, -0.0127,  ..., -0.0233, -0.0399, -0.0581],
        [ 0.0161,  0.0086,  0.0133,  ...,  0.0302,  0.0043,  0.0115],
        [-0.0444,  0.0565,  0.0591,  ...,  0.0017, -0.0147,  0.0274]],
       dtype=torch.float16), 'model.layers.16.self_attn.v_proj.weight': tensor([[-0.0166,  0.0066, -0.0049,  ...,  0.0065, -0.0008, -0.0020],
        [-0.0576, -0.0069,  0.0042,  ...,  0.0035,  0.0128, -0.0267],
        [-0.0069, -0.0133, -0.0021,  ..., -0.0211,  0.0416,  0.0151],
        ...,
        [ 0.0040, -0.0079,  0.0167,  ..., -0.0125, -0.0001,  0.0166],
        [-0.0169,  0.0023,  0.0052,  ...,  0.0389, -0.0043,  0.0089],
        [ 0.0118,  0.0102,  0.0083,  ..., -0.0158, -0.0042, -0.0301]],
       dtype=torch.float16), 'model.layers.16.self_attn.o_proj.weight': tensor([[ 0.0388, -0.0079, -0.0170,  ...,  0.0112, -0.0126,  0.0047],
        [-0.0246,  0.0107, -0.0208,  ...,  0.0039, -0.0083,  0.0016],
        [-0.0285, -0.0177, -0.0134,  ..., -0.0021,  0.0259,  0.0170],
        ...,
        [-0.0030, -0.0207,  0.0029,  ...,  0.0046, -0.0266,  0.0010],
        [-0.0073,  0.0199,  0.0344,  ..., -0.0005,  0.0009, -0.0051],
        [-0.0192,  0.0035,  0.0066,  ...,  0.0018,  0.0024,  0.0109]],
       dtype=torch.float16), 'model.layers.16.mlp.gate_proj.weight': tensor([[-0.0275, -0.0157, -0.0233,  ...,  0.0007, -0.0003,  0.0085],
        [ 0.0313,  0.0157, -0.0098,  ...,  0.0153,  0.0087,  0.0166],
        [ 0.0027,  0.0056,  0.0041,  ..., -0.0008, -0.0035, -0.0189],
        ...,
        [-0.0086,  0.0085,  0.0053,  ...,  0.0223,  0.0300,  0.0286],
        [-0.0033, -0.0147,  0.0094,  ...,  0.0099,  0.0210,  0.0115],
        [ 0.0256,  0.0212,  0.0310,  ..., -0.0399,  0.0148, -0.0203]],
       dtype=torch.float16), 'model.layers.16.mlp.up_proj.weight': tensor([[-0.0403,  0.0147,  0.0066,  ...,  0.0294, -0.0128,  0.0091],
        [ 0.0156, -0.0131,  0.0048,  ...,  0.0215, -0.0303, -0.0077],
        [-0.0078, -0.0256, -0.0064,  ..., -0.0124, -0.0047,  0.0258],
        ...,
        [-0.0096,  0.0263, -0.0066,  ...,  0.0095, -0.0235, -0.0248],
        [-0.0098,  0.0216, -0.0177,  ...,  0.0097, -0.0052,  0.0185],
        [ 0.0099,  0.0079, -0.0118,  ...,  0.0013, -0.0239, -0.0209]],
       dtype=torch.float16), 'model.layers.16.mlp.down_proj.weight': tensor([[-0.0236,  0.0045,  0.0134,  ...,  0.0206, -0.0091, -0.0008],
        [-0.0233, -0.0041, -0.0123,  ...,  0.0286,  0.0018, -0.0002],
        [-0.0142,  0.0049, -0.0120,  ...,  0.0201, -0.0042, -0.0009],
        ...,
        [ 0.0143, -0.0248, -0.0242,  ...,  0.0203,  0.0178, -0.0020],
        [ 0.0227,  0.0019, -0.0097,  ..., -0.0214, -0.0128, -0.0098],
        [ 0.0107, -0.0168, -0.0371,  ...,  0.0256, -0.0010, -0.0141]],
       dtype=torch.float16), 'model.layers.16.input_layernorm.weight': tensor([0.4180, 0.4219, 0.3906,  ..., 0.3984, 0.4160, 0.4082],
       dtype=torch.float16), 'model.layers.16.post_attention_layernorm.weight': tensor([0.3164, 0.2949, 0.2988,  ..., 0.3105, 0.3086, 0.3047],
       dtype=torch.float16), 'model.layers.17.self_attn.q_proj.weight': tensor([[-0.0125, -0.0138,  0.0065,  ...,  0.0073, -0.0072, -0.0107],
        [ 0.0094, -0.0095,  0.0169,  ...,  0.0019, -0.0260,  0.0081],
        [-0.0130, -0.0020, -0.0129,  ...,  0.0152, -0.0114,  0.0020],
        ...,
        [ 0.0362, -0.0261,  0.0562,  ..., -0.0142, -0.0178,  0.0079],
        [ 0.0282, -0.0184,  0.0462,  ...,  0.0094, -0.0215, -0.0601],
        [ 0.0126, -0.0017,  0.0116,  ...,  0.0320,  0.0013,  0.0742]],
       dtype=torch.float16), 'model.layers.17.self_attn.k_proj.weight': tensor([[-0.0127, -0.0063,  0.0040,  ..., -0.0014,  0.0197,  0.0079],
        [ 0.0078,  0.0072,  0.0041,  ...,  0.0103,  0.0002, -0.0138],
        [ 0.0077, -0.0085,  0.0012,  ...,  0.0154, -0.0231, -0.0079],
        ...,
        [ 0.0041, -0.0500, -0.0091,  ..., -0.0221,  0.0599, -0.0676],
        [ 0.0275,  0.0191,  0.0122,  ..., -0.0132, -0.0267, -0.0225],
        [-0.0380, -0.0470, -0.0048,  ...,  0.0278,  0.0259, -0.0048]],
       dtype=torch.float16), 'model.layers.17.self_attn.v_proj.weight': tensor([[-0.0122,  0.0105,  0.0024,  ...,  0.0239, -0.0088, -0.0096],
        [-0.0039, -0.0155, -0.0111,  ...,  0.0116, -0.0257, -0.0144],
        [ 0.0174,  0.0158, -0.0024,  ...,  0.0018, -0.0111, -0.0288],
        ...,
        [ 0.0010, -0.0043,  0.0143,  ...,  0.0121,  0.0051, -0.0155],
        [ 0.0189, -0.0031, -0.0388,  ..., -0.0152, -0.0034, -0.0341],
        [-0.0093, -0.0103, -0.0053,  ...,  0.0055,  0.0081,  0.0092]],
       dtype=torch.float16), 'model.layers.17.self_attn.o_proj.weight': tensor([[-0.0049, -0.0105,  0.0036,  ..., -0.0197,  0.0008, -0.0131],
        [-0.0116, -0.0207,  0.0218,  ...,  0.0219, -0.0174,  0.0221],
        [ 0.0098, -0.0111, -0.0045,  ..., -0.0186, -0.0138, -0.0218],
        ...,
        [-0.0109,  0.0140, -0.0118,  ..., -0.0310, -0.0329, -0.0185],
        [-0.0070,  0.0101, -0.0009,  ..., -0.0287,  0.0044,  0.0065],
        [-0.0155, -0.0129,  0.0072,  ...,  0.0329, -0.0223,  0.0173]],
       dtype=torch.float16), 'model.layers.17.mlp.gate_proj.weight': tensor([[-0.0341,  0.0291,  0.0243,  ...,  0.0059,  0.0021,  0.0031],
        [-0.0008,  0.0264,  0.0270,  ...,  0.0185,  0.0077,  0.0121],
        [ 0.0100,  0.0120, -0.0222,  ...,  0.0171,  0.0307, -0.0055],
        ...,
        [-0.0114, -0.0160, -0.0122,  ..., -0.0103, -0.0229, -0.0157],
        [ 0.0041,  0.0033,  0.0092,  ...,  0.0065,  0.0431, -0.0114],
        [-0.0032,  0.0208,  0.0144,  ..., -0.0138, -0.0018, -0.0032]],
       dtype=torch.float16), 'model.layers.17.mlp.up_proj.weight': tensor([[-0.0169, -0.0280, -0.0067,  ...,  0.0061,  0.0168, -0.0130],
        [-0.0231,  0.0152,  0.0278,  ...,  0.0003,  0.0016,  0.0020],
        [-0.0010, -0.0031,  0.0035,  ...,  0.0089, -0.0150,  0.0119],
        ...,
        [ 0.0138,  0.0168,  0.0068,  ...,  0.0064, -0.0204, -0.0130],
        [-0.0162, -0.0182, -0.0103,  ..., -0.0115, -0.0220,  0.0159],
        [-0.0032,  0.0038, -0.0083,  ...,  0.0034, -0.0360, -0.0131]],
       dtype=torch.float16), 'model.layers.17.mlp.down_proj.weight': tensor([[ 0.0260, -0.0225,  0.0134,  ...,  0.0120, -0.0079, -0.0022],
        [ 0.0285,  0.0301,  0.0086,  ...,  0.0063, -0.0083,  0.0336],
        [-0.0263, -0.0165, -0.0178,  ...,  0.0121, -0.0150, -0.0046],
        ...,
        [ 0.0067, -0.0222, -0.0068,  ..., -0.0141, -0.0051, -0.0367],
        [ 0.0015,  0.0053, -0.0114,  ..., -0.0275, -0.0274,  0.0174],
        [-0.0009, -0.0200,  0.0189,  ..., -0.0368, -0.0108,  0.0045]],
       dtype=torch.float16), 'model.layers.17.input_layernorm.weight': tensor([0.4316, 0.4336, 0.4043,  ..., 0.4238, 0.4277, 0.4062],
       dtype=torch.float16), 'model.layers.17.post_attention_layernorm.weight': tensor([0.3320, 0.3164, 0.3145,  ..., 0.3320, 0.3301, 0.3223],
       dtype=torch.float16), 'model.layers.18.self_attn.q_proj.weight': tensor([[ 0.0067,  0.0054,  0.0022,  ..., -0.0046, -0.0363,  0.0100],
        [ 0.0022, -0.0133,  0.0213,  ...,  0.0001,  0.0255,  0.0434],
        [ 0.0111, -0.0257, -0.0097,  ...,  0.0015, -0.0081,  0.0164],
        ...,
        [-0.0324,  0.0133,  0.0033,  ...,  0.0230,  0.0055,  0.0155],
        [ 0.0622, -0.0166, -0.0270,  ...,  0.0574,  0.0266,  0.0184],
        [ 0.0301,  0.0155,  0.0043,  ...,  0.0281,  0.0549, -0.0513]],
       dtype=torch.float16), 'model.layers.18.self_attn.k_proj.weight': tensor([[-0.0115,  0.0326, -0.0141,  ...,  0.0089, -0.0094, -0.0243],
        [ 0.0082, -0.0191,  0.0162,  ...,  0.0176,  0.0292,  0.0015],
        [ 0.0123, -0.0097, -0.0019,  ...,  0.0210, -0.0017,  0.0248],
        ...,
        [-0.1082, -0.0282, -0.0618,  ...,  0.0203, -0.0044, -0.0386],
        [ 0.0520,  0.0363, -0.0182,  ...,  0.0459,  0.0646, -0.0261],
        [-0.0487, -0.0503, -0.0435,  ...,  0.0343, -0.0235, -0.0319]],
       dtype=torch.float16), 'model.layers.18.self_attn.v_proj.weight': tensor([[-0.0296,  0.0286, -0.0176,  ...,  0.0053,  0.0276,  0.0051],
        [ 0.0173,  0.0070, -0.0124,  ..., -0.0175,  0.0382, -0.0023],
        [ 0.0001,  0.0193,  0.0009,  ...,  0.0046, -0.0021, -0.0077],
        ...,
        [ 0.0137,  0.0160, -0.0047,  ..., -0.0077, -0.0233,  0.0025],
        [ 0.0073, -0.0028,  0.0031,  ...,  0.0136,  0.0159,  0.0355],
        [-0.0068,  0.0012,  0.0111,  ..., -0.0062, -0.0200,  0.0024]],
       dtype=torch.float16), 'model.layers.18.self_attn.o_proj.weight': tensor([[-0.0180,  0.0188, -0.0144,  ...,  0.0118,  0.0222,  0.0198],
        [-0.0003, -0.0400,  0.0047,  ..., -0.0010, -0.0070, -0.0164],
        [ 0.0022, -0.0141,  0.0099,  ...,  0.0279,  0.0158,  0.0373],
        ...,
        [-0.0351, -0.0236, -0.0248,  ...,  0.0230,  0.0176, -0.0098],
        [ 0.0128,  0.0511,  0.0149,  ...,  0.0131, -0.0084, -0.0367],
        [-0.0119, -0.0472, -0.0218,  ..., -0.0158,  0.0139, -0.0140]],
       dtype=torch.float16), 'model.layers.18.mlp.gate_proj.weight': tensor([[ 0.0147, -0.0038,  0.0166,  ..., -0.0080,  0.0101, -0.0105],
        [-0.0428,  0.0071, -0.0162,  ..., -0.0086, -0.0150, -0.0096],
        [-0.0190,  0.0073,  0.0444,  ..., -0.0250,  0.0031,  0.0038],
        ...,
        [-0.0438, -0.0219, -0.0285,  ..., -0.0296, -0.0218, -0.0233],
        [ 0.0015,  0.0197,  0.0297,  ..., -0.0164, -0.0011,  0.0164],
        [ 0.0040, -0.0041,  0.0039,  ...,  0.0107, -0.0188, -0.0050]],
       dtype=torch.float16), 'model.layers.18.mlp.up_proj.weight': tensor([[ 0.0165,  0.0081,  0.0298,  ..., -0.0004,  0.0271, -0.0095],
        [-0.0201,  0.0243, -0.0282,  ..., -0.0057, -0.0087, -0.0003],
        [-0.0311, -0.0098,  0.0076,  ...,  0.0074,  0.0209,  0.0261],
        ...,
        [-0.0012,  0.0045,  0.0046,  ...,  0.0238, -0.0075,  0.0040],
        [-0.0094, -0.0048, -0.0210,  ...,  0.0134,  0.0343,  0.0362],
        [ 0.0087,  0.0248,  0.0111,  ..., -0.0163,  0.0135,  0.0152]],
       dtype=torch.float16), 'model.layers.18.mlp.down_proj.weight': tensor([[ 0.0152,  0.0034, -0.0323,  ...,  0.0311,  0.0165,  0.0073],
        [ 0.0117, -0.0078,  0.0196,  ...,  0.0007, -0.0016, -0.0021],
        [ 0.0172, -0.0250, -0.0335,  ...,  0.0177,  0.0036,  0.0148],
        ...,
        [-0.0127,  0.0210,  0.0102,  ...,  0.0230, -0.0081, -0.0087],
        [-0.0160,  0.0116,  0.0182,  ...,  0.0120,  0.0356,  0.0087],
        [-0.0091,  0.0257,  0.0244,  ..., -0.0073,  0.0167,  0.0157]],
       dtype=torch.float16), 'model.layers.18.input_layernorm.weight': tensor([0.4570, 0.4551, 0.4316,  ..., 0.4375, 0.4512, 0.4355],
       dtype=torch.float16), 'model.layers.18.post_attention_layernorm.weight': tensor([0.3477, 0.3340, 0.3320,  ..., 0.3477, 0.3496, 0.3457],
       dtype=torch.float16), 'model.layers.19.self_attn.q_proj.weight': tensor([[ 5.5275e-03,  7.6294e-03, -9.7961e-03,  ..., -1.0323e-02,
         -3.1209e-04,  8.8806e-03],
        [ 2.6894e-03, -2.5539e-03,  3.1719e-03,  ..., -4.7493e-03,
          2.9022e-02,  1.7868e-02],
        [ 5.2185e-03,  2.1896e-02,  4.5896e-05,  ...,  8.6498e-04,
          1.5182e-02,  3.0727e-03],
        ...,
        [-1.4160e-02, -1.4923e-02,  1.0290e-03,  ..., -4.4189e-02,
         -3.1805e-04,  2.4979e-02],
        [ 4.7226e-03,  4.8279e-02,  2.3041e-02,  ...,  5.4077e-02,
          2.9755e-02, -2.9358e-02],
        [-1.5991e-02,  4.9011e-02,  5.8014e-02,  ..., -6.6414e-03,
         -4.1382e-02, -1.4290e-02]], dtype=torch.float16), 'model.layers.19.self_attn.k_proj.weight': tensor([[ 0.0216,  0.0117,  0.0022,  ..., -0.0116, -0.0213, -0.0106],
        [-0.0142,  0.0180, -0.0159,  ...,  0.0100,  0.0034,  0.0251],
        [-0.0157,  0.0043, -0.0122,  ...,  0.0044,  0.0137,  0.0252],
        ...,
        [ 0.0005,  0.0502, -0.0095,  ..., -0.0208,  0.0299, -0.0225],
        [-0.0653, -0.0269, -0.0101,  ...,  0.0084,  0.0184, -0.0099],
        [-0.0202,  0.0115, -0.0150,  ..., -0.0266,  0.0129,  0.0399]],
       dtype=torch.float16), 'model.layers.19.self_attn.v_proj.weight': tensor([[-0.0011, -0.0055, -0.0055,  ..., -0.0020,  0.0005,  0.0070],
        [-0.0020,  0.0188, -0.0031,  ...,  0.0351, -0.0211,  0.0162],
        [-0.0448, -0.0359, -0.0080,  ..., -0.0085, -0.0002,  0.0056],
        ...,
        [ 0.0013, -0.0373, -0.0014,  ...,  0.0010, -0.0002, -0.0166],
        [ 0.0145, -0.0095, -0.0219,  ..., -0.0066, -0.0073, -0.0058],
        [-0.0033,  0.0275,  0.0008,  ..., -0.0254, -0.0120,  0.0062]],
       dtype=torch.float16), 'model.layers.19.self_attn.o_proj.weight': tensor([[ 0.0296, -0.0517,  0.0258,  ...,  0.0012,  0.0066, -0.0257],
        [ 0.0307, -0.0164, -0.0036,  ..., -0.0145, -0.0012, -0.0030],
        [-0.0033, -0.0176, -0.0195,  ...,  0.0010,  0.0150,  0.0012],
        ...,
        [ 0.0123, -0.0018,  0.0002,  ...,  0.0056, -0.0152,  0.0122],
        [ 0.0089, -0.0057, -0.0186,  ..., -0.0244, -0.0204,  0.0051],
        [ 0.0127,  0.0175,  0.0140,  ..., -0.0233, -0.0083,  0.0153]],
       dtype=torch.float16), 'model.layers.19.mlp.gate_proj.weight': tensor([[-0.0082,  0.0010,  0.0049,  ..., -0.0039,  0.0037, -0.0065],
        [ 0.0145,  0.0183,  0.0011,  ..., -0.0036,  0.0125, -0.0351],
        [-0.0169, -0.0121, -0.0127,  ..., -0.0433,  0.0002,  0.0285],
        ...,
        [-0.0016,  0.0101, -0.0004,  ..., -0.0291, -0.0092, -0.0010],
        [-0.0475, -0.0082,  0.0029,  ..., -0.0074, -0.0217,  0.0107],
        [-0.0205, -0.0197,  0.0153,  ...,  0.0069,  0.0052, -0.0020]],
       dtype=torch.float16), 'model.layers.19.mlp.up_proj.weight': tensor([[ 0.0020, -0.0107,  0.0096,  ...,  0.0065,  0.0100,  0.0032],
        [-0.0134, -0.0063, -0.0158,  ...,  0.0269, -0.0230, -0.0070],
        [ 0.0094,  0.0039,  0.0094,  ..., -0.0246, -0.0129,  0.0532],
        ...,
        [ 0.0142,  0.0140,  0.0074,  ...,  0.0136, -0.0170,  0.0311],
        [ 0.0013,  0.0262,  0.0249,  ..., -0.0094,  0.0361, -0.0004],
        [-0.0002, -0.0181, -0.0124,  ..., -0.0027,  0.0045,  0.0140]],
       dtype=torch.float16), 'model.layers.19.mlp.down_proj.weight': tensor([[-0.0026, -0.0278,  0.0015,  ...,  0.0057, -0.0235,  0.0278],
        [-0.0050, -0.0306, -0.0208,  ...,  0.0139,  0.0175, -0.0169],
        [-0.0209, -0.0261,  0.0290,  ...,  0.0159, -0.0008,  0.0071],
        ...,
        [-0.0104, -0.0050,  0.0274,  ...,  0.0129,  0.0162,  0.0012],
        [ 0.0065, -0.0093, -0.0501,  ...,  0.0219, -0.0086, -0.0152],
        [ 0.0041, -0.0093, -0.0342,  ...,  0.0006,  0.0090,  0.0042]],
       dtype=torch.float16), 'model.layers.19.input_layernorm.weight': tensor([0.4570, 0.4629, 0.4395,  ..., 0.4316, 0.4395, 0.4414],
       dtype=torch.float16), 'model.layers.19.post_attention_layernorm.weight': tensor([0.3613, 0.3477, 0.3457,  ..., 0.3574, 0.3555, 0.3594],
       dtype=torch.float16), 'model.layers.20.self_attn.q_proj.weight': tensor([[-3.3512e-03,  2.7599e-03,  2.2141e-02,  ...,  3.8643e-03,
          3.5381e-03, -2.3499e-02],
        [ 1.8127e-02, -2.1729e-02, -4.8876e-06,  ..., -6.9809e-03,
         -1.2131e-02,  1.7120e-02],
        [ 7.9117e-03, -6.8665e-03, -1.8326e-02,  ...,  1.7166e-02,
          7.0038e-03,  8.3780e-04],
        ...,
        [-3.1219e-02, -5.3162e-02,  1.0094e-02,  ..., -1.0918e-02,
          3.9520e-02,  1.1047e-02],
        [-8.0872e-02, -1.9455e-02,  1.1688e-02,  ...,  8.7585e-03,
          2.6505e-02,  8.3389e-03],
        [ 2.6978e-02,  2.4643e-03, -5.2071e-03,  ..., -1.9089e-02,
         -5.4512e-03, -1.3123e-03]], dtype=torch.float16), 'model.layers.20.self_attn.k_proj.weight': tensor([[-5.6038e-03,  7.3128e-03,  3.8834e-03,  ..., -1.6464e-02,
         -3.4750e-05,  3.6964e-03],
        [-3.7003e-04,  8.7585e-03,  4.4060e-03,  ..., -2.0161e-03,
          4.6120e-03,  1.1047e-02],
        [ 1.4694e-02,  2.8610e-03, -1.1185e-02,  ..., -1.5091e-02,
          1.4725e-03,  1.9836e-02],
        ...,
        [ 2.0256e-03,  4.9706e-03, -1.7044e-02,  ..., -2.3407e-02,
          2.5925e-02,  3.5919e-02],
        [-2.4094e-02,  2.4918e-02,  2.4490e-03,  ...,  2.1759e-02,
          3.0762e-02,  5.1605e-02],
        [-1.5228e-02, -3.0060e-02, -1.5793e-02,  ...,  2.0111e-02,
         -2.3468e-02,  5.2704e-02]], dtype=torch.float16), 'model.layers.20.self_attn.v_proj.weight': tensor([[-7.1526e-03, -1.8005e-02,  1.3290e-02,  ..., -2.7752e-03,
          1.9043e-02,  1.1086e-02],
        [-1.5945e-02, -3.7201e-02,  5.2223e-03,  ..., -1.2299e-02,
          3.4332e-04,  9.0942e-03],
        [-3.0174e-03, -1.3779e-02,  3.5763e-03,  ..., -2.5085e-02,
          9.9301e-05,  6.9046e-04],
        ...,
        [ 9.6893e-03, -1.2962e-02, -2.5940e-03,  ...,  2.4796e-02,
         -7.9269e-03,  9.0103e-03],
        [ 1.8799e-02,  1.4400e-03, -9.5062e-03,  ...,  8.0681e-04,
          1.1032e-02, -1.3542e-02],
        [ 2.3708e-03, -3.8452e-03,  2.4155e-02,  ..., -5.8403e-03,
         -1.1604e-02, -4.0283e-02]], dtype=torch.float16), 'model.layers.20.self_attn.o_proj.weight': tensor([[-0.0066,  0.0037,  0.0200,  ..., -0.0024,  0.0155, -0.0167],
        [ 0.0103, -0.0098, -0.0066,  ..., -0.0050, -0.0065,  0.0191],
        [ 0.0099, -0.0022, -0.0135,  ..., -0.0240,  0.0092,  0.0103],
        ...,
        [-0.0074, -0.0039,  0.0135,  ...,  0.0168, -0.0150,  0.0116],
        [-0.0101,  0.0031, -0.0113,  ...,  0.0121, -0.0273,  0.0036],
        [ 0.0107, -0.0183, -0.0039,  ...,  0.0065, -0.0230,  0.0195]],
       dtype=torch.float16), 'model.layers.20.mlp.gate_proj.weight': tensor([[ 0.0012, -0.0088, -0.0118,  ...,  0.0177, -0.0055,  0.0139],
        [-0.0275,  0.0091, -0.0060,  ..., -0.0098, -0.0143,  0.0149],
        [-0.0167, -0.0078,  0.0665,  ..., -0.0155,  0.0111, -0.0063],
        ...,
        [-0.0048, -0.0114,  0.0241,  ..., -0.0145,  0.0109, -0.0033],
        [ 0.0093,  0.0071,  0.0046,  ...,  0.0154,  0.0030,  0.0123],
        [-0.0032, -0.0308, -0.0070,  ...,  0.0059, -0.0142, -0.0134]],
       dtype=torch.float16), 'model.layers.20.mlp.up_proj.weight': tensor([[-0.0601, -0.0002, -0.0019,  ...,  0.0153, -0.0108, -0.0119],
        [-0.0098,  0.0006, -0.0098,  ..., -0.0502, -0.0143,  0.0372],
        [ 0.0060,  0.0302,  0.0182,  ...,  0.0070, -0.0175,  0.0047],
        ...,
        [-0.0139,  0.0211, -0.0016,  ..., -0.0180, -0.0043, -0.0030],
        [ 0.0155, -0.0318, -0.0148,  ...,  0.0031, -0.0208, -0.0377],
        [ 0.0145, -0.0241,  0.0311,  ..., -0.0039, -0.0222,  0.0036]],
       dtype=torch.float16), 'model.layers.20.mlp.down_proj.weight': tensor([[-0.0016,  0.0202, -0.0034,  ...,  0.0053, -0.0169, -0.0248],
        [ 0.0021,  0.0127, -0.0073,  ...,  0.0044, -0.0178,  0.0143],
        [-0.0127,  0.0180, -0.0242,  ..., -0.0042,  0.0238, -0.0053],
        ...,
        [-0.0375,  0.0276,  0.0056,  ...,  0.0026, -0.0002, -0.0114],
        [-0.0156,  0.0062, -0.0158,  ...,  0.0057,  0.0178, -0.0025],
        [ 0.0120, -0.0131,  0.0019,  ..., -0.0029, -0.0063, -0.0147]],
       dtype=torch.float16), 'model.layers.20.input_layernorm.weight': tensor([0.4590, 0.4688, 0.4395,  ..., 0.4414, 0.4375, 0.4590],
       dtype=torch.float16), 'model.layers.20.post_attention_layernorm.weight': tensor([0.3711, 0.3633, 0.3535,  ..., 0.3672, 0.3672, 0.3691],
       dtype=torch.float16), 'model.layers.21.self_attn.q_proj.weight': tensor([[-0.0138, -0.0057,  0.0144,  ..., -0.0153, -0.0030,  0.0070],
        [ 0.0252,  0.0060, -0.0012,  ...,  0.0031,  0.0002,  0.0141],
        [-0.0117, -0.0101,  0.0026,  ...,  0.0280,  0.0023,  0.0066],
        ...,
        [-0.0025, -0.0157,  0.0354,  ..., -0.0107, -0.0593,  0.0191],
        [-0.0115,  0.0166,  0.0210,  ...,  0.0295,  0.0328,  0.0014],
        [-0.0795, -0.0016, -0.0130,  ..., -0.0056,  0.0264, -0.0380]],
       dtype=torch.float16), 'model.layers.21.self_attn.k_proj.weight': tensor([[-1.3864e-04,  4.9858e-03, -3.4065e-03,  ...,  7.4348e-03,
          3.9625e-04,  1.0353e-02],
        [-8.3685e-05,  7.3128e-03,  1.9882e-02,  ...,  6.2561e-03,
          9.4681e-03,  8.8806e-03],
        [ 1.8494e-02,  2.9202e-03,  2.8900e-02,  ...,  1.5823e-02,
          1.2871e-02,  1.4816e-02],
        ...,
        [-1.8295e-02,  2.6428e-02,  1.5945e-03,  ...,  2.5818e-02,
         -1.9394e-02,  4.6265e-02],
        [ 2.0866e-03, -3.1281e-03, -1.4458e-02,  ..., -2.2232e-02,
          3.1250e-02,  1.6203e-03],
        [-1.8906e-02, -8.1329e-03, -3.1433e-02,  ...,  7.8888e-03,
         -7.5493e-03,  5.9235e-02]], dtype=torch.float16), 'model.layers.21.self_attn.v_proj.weight': tensor([[ 0.0032,  0.0054, -0.0003,  ...,  0.0005,  0.0223, -0.0286],
        [-0.0232,  0.0240, -0.0079,  ...,  0.0211, -0.0195,  0.0266],
        [ 0.0280, -0.0030,  0.0003,  ..., -0.0232,  0.0258, -0.0058],
        ...,
        [-0.0056, -0.0269,  0.0320,  ..., -0.0065,  0.0038, -0.0102],
        [-0.0154, -0.0090,  0.0156,  ...,  0.0048, -0.0052,  0.0086],
        [-0.0069,  0.0157, -0.0162,  ...,  0.0070, -0.0155, -0.0029]],
       dtype=torch.float16), 'model.layers.21.self_attn.o_proj.weight': tensor([[-0.0118, -0.0017,  0.0116,  ..., -0.0132,  0.0231,  0.0102],
        [-0.0058,  0.0267, -0.0098,  ..., -0.0189,  0.0061, -0.0112],
        [-0.0298, -0.0130,  0.0119,  ...,  0.0249,  0.0273,  0.0079],
        ...,
        [ 0.0198, -0.0042, -0.0136,  ...,  0.0248, -0.0006,  0.0144],
        [ 0.0152, -0.0136,  0.0135,  ..., -0.0006,  0.0018, -0.0185],
        [-0.0264,  0.0155, -0.0134,  ...,  0.0298, -0.0163,  0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.gate_proj.weight': tensor([[-0.0058, -0.0234,  0.0144,  ..., -0.0285,  0.0456,  0.0089],
        [ 0.0061,  0.0061,  0.0039,  ..., -0.0275,  0.0574,  0.0085],
        [ 0.0084,  0.0064,  0.0049,  ..., -0.0498,  0.0041, -0.0245],
        ...,
        [ 0.0102, -0.0292, -0.0215,  ...,  0.0331, -0.0270,  0.0024],
        [-0.0010,  0.0293,  0.0065,  ...,  0.0160, -0.0249,  0.0030],
        [ 0.0093, -0.0124, -0.0017,  ..., -0.0182,  0.0064, -0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.up_proj.weight': tensor([[ 0.0276, -0.0258, -0.0142,  ...,  0.0225,  0.0422, -0.0112],
        [-0.0261, -0.0107,  0.0040,  ...,  0.0379,  0.0453, -0.0010],
        [ 0.0133, -0.0011, -0.0018,  ...,  0.0067, -0.0079, -0.0061],
        ...,
        [-0.0461, -0.0002,  0.0137,  ...,  0.0162, -0.0095, -0.0118],
        [-0.0100, -0.0107,  0.0042,  ..., -0.0188, -0.0023,  0.0027],
        [-0.0051, -0.0337, -0.0248,  ..., -0.0035, -0.0055, -0.0260]],
       dtype=torch.float16), 'model.layers.21.mlp.down_proj.weight': tensor([[ 0.0117,  0.0132,  0.0028,  ...,  0.0198,  0.0068,  0.0062],
        [ 0.0095, -0.0029, -0.0151,  ...,  0.0037, -0.0319, -0.0163],
        [-0.0061,  0.0059,  0.0132,  ..., -0.0084,  0.0412,  0.0299],
        ...,
        [-0.0106,  0.0375,  0.0182,  ..., -0.0093, -0.0024,  0.0179],
        [ 0.0125,  0.0007, -0.0043,  ..., -0.0493, -0.0052,  0.0049],
        [ 0.0089,  0.0014,  0.0242,  ..., -0.0152,  0.0267, -0.0278]],
       dtype=torch.float16), 'model.layers.21.input_layernorm.weight': tensor([0.4805, 0.4883, 0.4688,  ..., 0.4609, 0.4805, 0.4824],
       dtype=torch.float16), 'model.layers.21.post_attention_layernorm.weight': tensor([0.3770, 0.3730, 0.3652,  ..., 0.3848, 0.3789, 0.3828],
       dtype=torch.float16), 'model.layers.22.self_attn.q_proj.weight': tensor([[-0.0249, -0.0096, -0.0046,  ...,  0.0535, -0.0391,  0.0201],
        [-0.0361, -0.0200, -0.0063,  ..., -0.0361,  0.0211, -0.0515],
        [-0.0322,  0.0232, -0.0146,  ...,  0.0286,  0.0173, -0.0100],
        ...,
        [ 0.0094,  0.0199,  0.0122,  ...,  0.0116,  0.0576, -0.0013],
        [-0.0323,  0.0064, -0.0220,  ...,  0.0465,  0.0088, -0.0131],
        [ 0.0380, -0.0125,  0.0065,  ..., -0.0505,  0.0111,  0.0195]],
       dtype=torch.float16), 'model.layers.22.self_attn.k_proj.weight': tensor([[-0.0130, -0.0065,  0.0037,  ...,  0.0139, -0.0164, -0.0157],
        [ 0.0106, -0.0099,  0.0312,  ..., -0.0320,  0.0375, -0.0140],
        [-0.0207,  0.0286, -0.0425,  ...,  0.0614,  0.0035, -0.0076],
        ...,
        [ 0.0210,  0.0074, -0.0286,  ..., -0.0204, -0.0135,  0.0172],
        [-0.0150, -0.0424,  0.0025,  ..., -0.0002, -0.0132, -0.0070],
        [ 0.0240, -0.0025,  0.0283,  ...,  0.0377, -0.0425,  0.0131]],
       dtype=torch.float16), 'model.layers.22.self_attn.v_proj.weight': tensor([[-0.0201,  0.0126, -0.0017,  ..., -0.0395, -0.0264,  0.0152],
        [-0.0346, -0.0108,  0.0072,  ..., -0.0269, -0.0413, -0.0159],
        [ 0.0243, -0.0267, -0.0040,  ...,  0.0528, -0.0026, -0.0139],
        ...,
        [-0.0104, -0.0462, -0.0226,  ...,  0.0124, -0.0114,  0.0218],
        [-0.0375, -0.0086,  0.0181,  ..., -0.0198,  0.0020, -0.0155],
        [ 0.0007,  0.0152, -0.0433,  ...,  0.0020, -0.0053,  0.0264]],
       dtype=torch.float16), 'model.layers.22.self_attn.o_proj.weight': tensor([[ 0.0263,  0.0156, -0.0218,  ..., -0.0026, -0.0353,  0.0123],
        [ 0.0242,  0.0126,  0.0108,  ...,  0.0045, -0.0100, -0.0247],
        [ 0.0046,  0.0026, -0.0081,  ..., -0.0232,  0.0110,  0.0107],
        ...,
        [-0.0008, -0.0238, -0.0129,  ..., -0.0138, -0.0166,  0.0042],
        [ 0.0259, -0.0104, -0.0196,  ..., -0.0260, -0.0027,  0.0137],
        [ 0.0039, -0.0258,  0.0213,  ...,  0.0115,  0.0122,  0.0111]],
       dtype=torch.float16), 'model.layers.22.mlp.gate_proj.weight': tensor([[-0.0284, -0.0156,  0.0184,  ...,  0.0108,  0.0197, -0.0452],
        [ 0.0226, -0.0165,  0.0014,  ...,  0.0043,  0.0029,  0.0221],
        [ 0.0005, -0.0069,  0.0054,  ...,  0.0142,  0.0002, -0.0003],
        ...,
        [-0.0043, -0.0079,  0.0014,  ..., -0.0152,  0.0073,  0.0022],
        [ 0.0095,  0.0165, -0.0293,  ..., -0.0035,  0.0127, -0.0289],
        [-0.0101,  0.0012,  0.0053,  ..., -0.0148,  0.0278,  0.0245]],
       dtype=torch.float16), 'model.layers.22.mlp.up_proj.weight': tensor([[ 0.0293,  0.0162, -0.0013,  ...,  0.0170,  0.0276,  0.0071],
        [ 0.0198,  0.0076,  0.0164,  ..., -0.0117, -0.0078,  0.0030],
        [ 0.0086, -0.0282, -0.0375,  ...,  0.0255,  0.0104,  0.0061],
        ...,
        [-0.0032, -0.0006, -0.0185,  ..., -0.0040,  0.0057,  0.0067],
        [ 0.0126, -0.0111, -0.0286,  ..., -0.0226,  0.0108, -0.0270],
        [-0.0014,  0.0023, -0.0036,  ..., -0.0440, -0.0598,  0.0154]],
       dtype=torch.float16), 'model.layers.22.mlp.down_proj.weight': tensor([[ 1.3527e-02, -5.1918e-03,  1.2299e-02,  ..., -1.8967e-02,
         -4.1428e-03, -3.6041e-02],
        [ 5.5885e-03,  2.6581e-02, -4.9362e-03,  ..., -1.1017e-02,
          1.4084e-02, -2.6627e-02],
        [-9.6512e-03,  3.9363e-04,  4.1962e-03,  ...,  1.2886e-02,
          4.5013e-03,  1.7517e-02],
        ...,
        [ 1.8250e-02, -8.5297e-03, -4.5288e-02,  ..., -2.8934e-03,
         -1.2947e-02, -1.7014e-02],
        [-1.1414e-02, -4.8767e-02,  1.1642e-02,  ...,  1.9028e-02,
         -2.7069e-02,  3.1433e-02],
        [ 1.4130e-02,  3.7551e-06, -3.1067e-02,  ..., -3.3903e-04,
         -1.8875e-02,  2.1286e-03]], dtype=torch.float16), 'model.layers.22.input_layernorm.weight': tensor([0.4883, 0.4922, 0.4805,  ..., 0.4688, 0.5000, 0.4902],
       dtype=torch.float16), 'model.layers.22.post_attention_layernorm.weight': tensor([0.3867, 0.3848, 0.3848,  ..., 0.3965, 0.3945, 0.3965],
       dtype=torch.float16), 'model.layers.23.self_attn.q_proj.weight': tensor([[-0.0039, -0.0179,  0.0076,  ..., -0.0155, -0.0002,  0.0023],
        [ 0.0042,  0.0015,  0.0140,  ..., -0.0166, -0.0002,  0.0083],
        [-0.0038,  0.0028,  0.0219,  ...,  0.0002, -0.0167,  0.0066],
        ...,
        [-0.0211,  0.0670,  0.0119,  ..., -0.0314, -0.0684, -0.0263],
        [-0.0411, -0.0311,  0.0199,  ..., -0.0232,  0.0020,  0.0060],
        [ 0.0047, -0.0559, -0.0093,  ...,  0.0072,  0.0403, -0.0026]],
       dtype=torch.float16), 'model.layers.23.self_attn.k_proj.weight': tensor([[-0.0030,  0.0121,  0.0090,  ...,  0.0010, -0.0083,  0.0059],
        [-0.0224,  0.0057, -0.0117,  ...,  0.0093,  0.0254,  0.0036],
        [ 0.0182,  0.0078, -0.0185,  ...,  0.0181,  0.0016, -0.0107],
        ...,
        [ 0.0067,  0.0374,  0.0580,  ..., -0.0332, -0.0120, -0.0131],
        [ 0.0034, -0.0352, -0.0113,  ..., -0.0232, -0.0226,  0.0194],
        [-0.0173, -0.0081, -0.0259,  ...,  0.0043,  0.0060, -0.0084]],
       dtype=torch.float16), 'model.layers.23.self_attn.v_proj.weight': tensor([[-0.0028,  0.0343, -0.0120,  ..., -0.0097, -0.0016, -0.0112],
        [-0.0093, -0.0038, -0.0190,  ..., -0.0033, -0.0097,  0.0105],
        [ 0.0111, -0.0211, -0.0208,  ...,  0.0130, -0.0508, -0.0305],
        ...,
        [ 0.0070,  0.0084,  0.0091,  ..., -0.0020,  0.0338,  0.0089],
        [ 0.0261,  0.0316, -0.0011,  ...,  0.0070,  0.0022, -0.0127],
        [-0.0201, -0.0131, -0.0540,  ...,  0.0057,  0.0076, -0.0381]],
       dtype=torch.float16), 'model.layers.23.self_attn.o_proj.weight': tensor([[-0.0019,  0.0019, -0.0202,  ..., -0.0179,  0.0104, -0.0070],
        [-0.0127, -0.0213, -0.0022,  ..., -0.0004,  0.0100, -0.0021],
        [ 0.0130,  0.0094,  0.0306,  ..., -0.0228, -0.0026, -0.0276],
        ...,
        [ 0.0290, -0.0114,  0.0348,  ..., -0.0162,  0.0113, -0.0013],
        [-0.0044,  0.0202, -0.0200,  ...,  0.0056, -0.0164,  0.0007],
        [ 0.0013, -0.0023, -0.0177,  ..., -0.0060,  0.0059, -0.0296]],
       dtype=torch.float16), 'model.layers.23.mlp.gate_proj.weight': tensor([[-1.1848e-02,  3.4424e-02, -1.0048e-02,  ..., -7.0152e-03,
          3.2776e-02,  9.2316e-03],
        [-1.4702e-02,  4.7729e-02, -1.7593e-02,  ...,  7.1678e-03,
         -1.8631e-02,  2.5070e-02],
        [-3.2349e-02,  1.4786e-02,  2.6913e-03,  ...,  1.5274e-02,
         -6.7444e-02,  1.2131e-02],
        ...,
        [-3.1548e-03,  1.9089e-02,  3.1509e-03,  ..., -8.1863e-03,
          7.2556e-03, -2.4643e-03],
        [-2.0828e-02,  3.8971e-02,  2.9430e-03,  ...,  3.3021e-05,
          7.8201e-03, -2.8381e-02],
        [ 8.8692e-04,  8.5144e-03,  1.6830e-02,  ..., -7.6561e-03,
          1.5450e-02, -1.6495e-02]], dtype=torch.float16), 'model.layers.23.mlp.up_proj.weight': tensor([[ 0.0283,  0.0066,  0.0351,  ...,  0.0134, -0.0322, -0.0074],
        [-0.0003,  0.0065, -0.0196,  ..., -0.0043, -0.0111,  0.0061],
        [-0.0177,  0.0038, -0.0218,  ...,  0.0182,  0.0106, -0.0052],
        ...,
        [-0.0084, -0.0166,  0.0116,  ...,  0.0093,  0.0408,  0.0053],
        [ 0.0036,  0.0078, -0.0382,  ...,  0.0106,  0.0070,  0.0220],
        [ 0.0014,  0.0079, -0.0071,  ...,  0.0070, -0.0126,  0.0127]],
       dtype=torch.float16), 'model.layers.23.mlp.down_proj.weight': tensor([[-0.0008,  0.0069, -0.0182,  ..., -0.0434, -0.0227,  0.0330],
        [-0.0012,  0.0231, -0.0064,  ...,  0.0257,  0.0306,  0.0021],
        [-0.0066, -0.0139, -0.0233,  ...,  0.0102,  0.0330, -0.0052],
        ...,
        [ 0.0001, -0.0050,  0.0135,  ...,  0.0180,  0.0037, -0.0187],
        [ 0.0296, -0.0114, -0.0007,  ..., -0.0026,  0.0101,  0.0058],
        [ 0.0031, -0.0307, -0.0152,  ..., -0.0104,  0.0204, -0.0025]],
       dtype=torch.float16), 'model.layers.23.input_layernorm.weight': tensor([0.5156, 0.5312, 0.5117,  ..., 0.5039, 0.5352, 0.5273],
       dtype=torch.float16), 'model.layers.23.post_attention_layernorm.weight': tensor([0.4043, 0.4023, 0.3965,  ..., 0.4043, 0.4121, 0.4062],
       dtype=torch.float16), 'model.layers.24.self_attn.q_proj.weight': tensor([[ 0.0204, -0.0176,  0.0145,  ...,  0.0364, -0.0300,  0.0106],
        [ 0.0215,  0.0088,  0.0012,  ..., -0.0026,  0.0186, -0.0139],
        [-0.0056, -0.0111, -0.0277,  ...,  0.0088, -0.0132,  0.0202],
        ...,
        [-0.0147,  0.0136, -0.0193,  ...,  0.0181, -0.0004, -0.0123],
        [-0.0288,  0.0078,  0.0070,  ...,  0.0100, -0.0323, -0.0062],
        [-0.0231, -0.0385, -0.0181,  ..., -0.0132,  0.0128,  0.0677]],
       dtype=torch.float16), 'model.layers.24.self_attn.k_proj.weight': tensor([[ 0.0235, -0.0035, -0.0125,  ...,  0.0110, -0.0008,  0.0021],
        [ 0.0118, -0.0169,  0.0035,  ..., -0.0216,  0.0245,  0.0066],
        [ 0.0097,  0.0045, -0.0445,  ...,  0.0204,  0.0171, -0.0175],
        ...,
        [ 0.0344,  0.0036,  0.0493,  ...,  0.0161,  0.0179, -0.0516],
        [-0.0119,  0.0177,  0.0127,  ...,  0.0320, -0.0181,  0.0027],
        [-0.0318, -0.0295, -0.0190,  ...,  0.0139, -0.0048,  0.0518]],
       dtype=torch.float16), 'model.layers.24.self_attn.v_proj.weight': tensor([[ 0.0212, -0.0251, -0.0028,  ..., -0.0041, -0.0040,  0.0113],
        [ 0.0288, -0.0173, -0.0054,  ..., -0.0646, -0.0470, -0.0240],
        [-0.0579, -0.0169, -0.0134,  ..., -0.0156, -0.0121, -0.0027],
        ...,
        [ 0.0011, -0.0192,  0.0171,  ...,  0.0272,  0.0067,  0.0217],
        [-0.0034, -0.0157, -0.0141,  ...,  0.0332, -0.0036,  0.0038],
        [ 0.0172,  0.0228,  0.0187,  ...,  0.0274, -0.0135, -0.0108]],
       dtype=torch.float16), 'model.layers.24.self_attn.o_proj.weight': tensor([[-0.0016,  0.0144,  0.0280,  ...,  0.0066, -0.0051, -0.0141],
        [-0.0118,  0.0308,  0.0156,  ...,  0.0195,  0.0282, -0.0186],
        [-0.0057, -0.0029,  0.0094,  ..., -0.0232,  0.0084, -0.0049],
        ...,
        [ 0.0045,  0.0179,  0.0119,  ..., -0.0027, -0.0031, -0.0005],
        [ 0.0508,  0.0096, -0.0061,  ...,  0.0075, -0.0257, -0.0106],
        [ 0.0026,  0.0155,  0.0109,  ...,  0.0046, -0.0261,  0.0131]],
       dtype=torch.float16), 'model.layers.24.mlp.gate_proj.weight': tensor([[-0.0267, -0.0104,  0.0093,  ..., -0.0031, -0.0058,  0.0011],
        [ 0.0075, -0.0302, -0.0231,  ...,  0.0075,  0.0110, -0.0131],
        [ 0.0014, -0.0466,  0.0257,  ...,  0.0015, -0.0532, -0.0207],
        ...,
        [ 0.0042, -0.0358, -0.0088,  ...,  0.0080,  0.0152, -0.0062],
        [ 0.0094,  0.0158,  0.0041,  ...,  0.0043,  0.0011,  0.0048],
        [-0.0410,  0.0326,  0.0009,  ...,  0.0294, -0.0074, -0.0473]],
       dtype=torch.float16), 'model.layers.24.mlp.up_proj.weight': tensor([[ 0.0016, -0.0057,  0.0201,  ...,  0.0262,  0.0025,  0.0263],
        [-0.0026,  0.0136, -0.0327,  ..., -0.0081, -0.0044, -0.0171],
        [ 0.0114, -0.0520,  0.0097,  ...,  0.0402,  0.0179, -0.0341],
        ...,
        [ 0.0115, -0.0207, -0.0147,  ..., -0.0067,  0.0112,  0.0111],
        [ 0.0412, -0.0033,  0.0132,  ...,  0.0025,  0.0054, -0.0100],
        [-0.0056, -0.0197,  0.0203,  ...,  0.0303,  0.0333,  0.0164]],
       dtype=torch.float16), 'model.layers.24.mlp.down_proj.weight': tensor([[-0.0052, -0.0114, -0.0357,  ...,  0.0015,  0.0022, -0.0194],
        [ 0.0278, -0.0030,  0.0175,  ..., -0.0015,  0.0048, -0.0508],
        [ 0.0195,  0.0135, -0.0284,  ...,  0.0095,  0.0215,  0.0078],
        ...,
        [-0.0092,  0.0149, -0.0204,  ..., -0.0330, -0.0109, -0.0146],
        [ 0.0112,  0.0248,  0.0120,  ...,  0.0257, -0.0255,  0.0133],
        [-0.0171, -0.0086,  0.0033,  ...,  0.0172, -0.0154, -0.0324]],
       dtype=torch.float16), 'model.layers.24.input_layernorm.weight': tensor([0.4980, 0.5273, 0.5195,  ..., 0.4863, 0.5234, 0.5156],
       dtype=torch.float16), 'model.layers.24.post_attention_layernorm.weight': tensor([0.4219, 0.4180, 0.4180,  ..., 0.4199, 0.4258, 0.4219],
       dtype=torch.float16), 'model.layers.25.self_attn.q_proj.weight': tensor([[ 1.7204e-03, -1.9974e-02, -2.5269e-02,  ...,  1.2192e-02,
         -9.5139e-03,  4.5357e-03],
        [-1.3947e-02,  3.5877e-03,  2.3804e-02,  ..., -1.4412e-02,
         -3.4485e-03,  2.4557e-05],
        [ 9.1629e-03,  8.6136e-03,  3.9368e-03,  ..., -1.1436e-02,
         -2.0157e-02, -1.5068e-02],
        ...,
        [ 5.5756e-02,  4.5746e-02,  2.2964e-03,  ...,  4.9858e-03,
          1.5762e-02, -2.6688e-02],
        [-6.3721e-02, -5.0293e-02, -1.2497e-02,  ..., -1.0338e-02,
         -2.1088e-02,  4.0932e-03],
        [ 3.9978e-02, -4.3365e-02, -2.2217e-02,  ...,  3.9279e-05,
          1.0757e-02, -2.6917e-02]], dtype=torch.float16), 'model.layers.25.self_attn.k_proj.weight': tensor([[-5.6648e-03, -1.3237e-02, -1.2611e-02,  ...,  1.5726e-03,
          1.6232e-03,  1.4572e-03],
        [-1.4183e-02, -1.4297e-02,  2.7120e-05,  ..., -3.4618e-03,
         -2.1515e-02,  7.6561e-03],
        [-8.5354e-04,  1.9426e-03,  4.9133e-03,  ...,  6.0310e-03,
         -6.0654e-03,  7.2212e-03],
        ...,
        [ 1.3847e-02,  4.8248e-02, -9.6283e-03,  ..., -5.4504e-02,
         -5.6427e-02,  3.7598e-02],
        [ 3.4454e-02, -3.4393e-02,  4.3602e-03,  ..., -8.3771e-03,
          2.8229e-03,  1.0277e-02],
        [-7.9346e-03, -2.7908e-02,  3.2768e-03,  ...,  3.6316e-02,
          8.8501e-03, -2.9388e-02]], dtype=torch.float16), 'model.layers.25.self_attn.v_proj.weight': tensor([[ 0.0173,  0.0201,  0.0084,  ...,  0.0248, -0.0133, -0.0128],
        [-0.0143, -0.0107,  0.0099,  ...,  0.0090, -0.0273, -0.0127],
        [-0.0150,  0.0164, -0.0202,  ..., -0.0099,  0.0054, -0.0090],
        ...,
        [-0.0186, -0.0324, -0.0026,  ...,  0.0150,  0.0097,  0.0189],
        [-0.0152,  0.0089,  0.0258,  ..., -0.0068,  0.0044, -0.0216],
        [-0.0386, -0.0105, -0.0145,  ...,  0.0065,  0.0192,  0.0297]],
       dtype=torch.float16), 'model.layers.25.self_attn.o_proj.weight': tensor([[ 1.9470e-02,  1.0475e-02,  1.3229e-02,  ...,  1.4595e-02,
          2.8362e-03,  3.7861e-03],
        [-2.6352e-02, -9.8953e-03, -1.6998e-02,  ...,  2.6093e-02,
         -7.1945e-03, -1.3523e-03],
        [-8.1863e-03, -1.5879e-03,  2.5925e-02,  ..., -1.9821e-02,
         -1.3336e-02, -1.3371e-03],
        ...,
        [-1.3893e-02,  2.3819e-02, -2.7676e-03,  ...,  1.0544e-02,
          1.3359e-02,  2.7084e-02],
        [-4.1842e-05, -2.7664e-02, -3.7750e-02,  ..., -2.3926e-02,
         -1.6037e-02,  2.2125e-03],
        [-2.4704e-02, -8.4839e-03, -1.3412e-02,  ..., -3.7964e-02,
         -2.0554e-02, -1.3344e-02]], dtype=torch.float16), 'model.layers.25.mlp.gate_proj.weight': tensor([[ 0.0037, -0.0402,  0.0397,  ..., -0.0020, -0.0228,  0.0070],
        [-0.0239, -0.0074, -0.0153,  ...,  0.0345,  0.0486,  0.0262],
        [-0.0017,  0.0171, -0.0012,  ...,  0.0176,  0.0161,  0.0310],
        ...,
        [-0.0347,  0.0086,  0.0019,  ..., -0.0027, -0.0130,  0.0004],
        [ 0.0218,  0.0088,  0.0610,  ...,  0.0170,  0.0224,  0.0062],
        [-0.0047, -0.0022, -0.0174,  ...,  0.0450,  0.0030, -0.0100]],
       dtype=torch.float16), 'model.layers.25.mlp.up_proj.weight': tensor([[-0.0265, -0.0114,  0.0169,  ...,  0.0016,  0.0052, -0.0100],
        [-0.0138, -0.0033,  0.0076,  ..., -0.0056,  0.0163,  0.0114],
        [ 0.0298,  0.0056,  0.0224,  ..., -0.0136, -0.0282, -0.0026],
        ...,
        [ 0.0102,  0.0049,  0.0475,  ...,  0.0056, -0.0394, -0.0210],
        [-0.0387, -0.0015, -0.0307,  ..., -0.0457, -0.0228, -0.0002],
        [-0.0147, -0.0097,  0.0229,  ...,  0.0258, -0.0055,  0.0242]],
       dtype=torch.float16), 'model.layers.25.mlp.down_proj.weight': tensor([[ 0.0289, -0.0159,  0.0110,  ...,  0.0204, -0.0067,  0.0310],
        [-0.0150, -0.0020,  0.0045,  ...,  0.0100, -0.0012,  0.0230],
        [ 0.0123,  0.0103, -0.0082,  ..., -0.0229,  0.0118, -0.0181],
        ...,
        [ 0.0188, -0.0142, -0.0232,  ..., -0.0466, -0.0010,  0.0237],
        [ 0.0065, -0.0114,  0.0031,  ...,  0.0045,  0.0039,  0.0058],
        [-0.0111, -0.0243,  0.0161,  ..., -0.0298, -0.0061, -0.0051]],
       dtype=torch.float16), 'model.layers.25.input_layernorm.weight': tensor([0.5547, 0.5703, 0.5547,  ..., 0.5547, 0.5742, 0.5625],
       dtype=torch.float16), 'model.layers.25.post_attention_layernorm.weight': tensor([0.4316, 0.4316, 0.4297,  ..., 0.4355, 0.4336, 0.4395],
       dtype=torch.float16), 'model.layers.26.self_attn.q_proj.weight': tensor([[ 0.0299, -0.0067, -0.0090,  ..., -0.0101,  0.0408,  0.0010],
        [-0.0050, -0.0182,  0.0142,  ...,  0.0062, -0.0230,  0.0177],
        [-0.0064,  0.0024,  0.0114,  ...,  0.0050, -0.0381, -0.0195],
        ...,
        [ 0.0009, -0.0125, -0.0078,  ...,  0.0158,  0.0216,  0.0021],
        [ 0.0070, -0.0182, -0.0230,  ...,  0.0060, -0.0005, -0.0075],
        [-0.0146,  0.0520,  0.0271,  ..., -0.0072, -0.0645, -0.0416]],
       dtype=torch.float16), 'model.layers.26.self_attn.k_proj.weight': tensor([[ 0.0220,  0.0199, -0.0121,  ..., -0.0308,  0.0384,  0.0029],
        [-0.0267,  0.0055,  0.0148,  ...,  0.0016,  0.0168,  0.0291],
        [ 0.0129,  0.0286,  0.0004,  ..., -0.0190, -0.0591, -0.0098],
        ...,
        [ 0.0247,  0.0246,  0.0012,  ..., -0.0466, -0.0545,  0.0259],
        [-0.0216, -0.0389, -0.0074,  ...,  0.0483,  0.0228, -0.0051],
        [-0.0171,  0.0094, -0.0132,  ...,  0.0006, -0.0198, -0.0154]],
       dtype=torch.float16), 'model.layers.26.self_attn.v_proj.weight': tensor([[ 0.0506, -0.0262, -0.0245,  ..., -0.0152,  0.0105, -0.0191],
        [-0.0491, -0.0213,  0.0254,  ...,  0.0101, -0.0062,  0.0016],
        [ 0.0013, -0.0020, -0.0238,  ..., -0.0061,  0.0042, -0.0306],
        ...,
        [-0.0236, -0.0176, -0.0008,  ...,  0.0428, -0.0050,  0.0086],
        [ 0.0039, -0.0365, -0.0094,  ..., -0.0166, -0.0242, -0.0042],
        [ 0.0092,  0.0188, -0.0045,  ...,  0.0071,  0.0064,  0.0172]],
       dtype=torch.float16), 'model.layers.26.self_attn.o_proj.weight': tensor([[ 0.0108, -0.0005, -0.0306,  ...,  0.0052,  0.0149,  0.0272],
        [ 0.0067,  0.0455,  0.0062,  ..., -0.0016,  0.0462, -0.0053],
        [ 0.0013,  0.0102, -0.0247,  ..., -0.0226,  0.0037, -0.0018],
        ...,
        [ 0.0307,  0.0040,  0.0108,  ..., -0.0002,  0.0182,  0.0043],
        [-0.0128,  0.0049, -0.0096,  ...,  0.0135, -0.0017, -0.0425],
        [ 0.0257,  0.0072,  0.0050,  ..., -0.0276,  0.0283, -0.0160]],
       dtype=torch.float16), 'model.layers.26.mlp.gate_proj.weight': tensor([[ 0.0187,  0.0045,  0.0131,  ...,  0.0258,  0.0262, -0.0261],
        [-0.0062,  0.0102, -0.0258,  ..., -0.0255, -0.0266,  0.0190],
        [ 0.0022, -0.0109,  0.0007,  ...,  0.0060,  0.0038, -0.0172],
        ...,
        [-0.0065,  0.0356, -0.0078,  ..., -0.0015, -0.0380, -0.0219],
        [-0.0150,  0.0138,  0.0250,  ...,  0.0159,  0.0240,  0.0123],
        [ 0.0182, -0.0038, -0.0058,  ..., -0.0301, -0.0062, -0.0043]],
       dtype=torch.float16), 'model.layers.26.mlp.up_proj.weight': tensor([[-0.0168,  0.0401,  0.0018,  ...,  0.0049, -0.0029, -0.0195],
        [-0.0410, -0.0193,  0.0116,  ...,  0.0265, -0.0069,  0.0175],
        [ 0.0082, -0.0065, -0.0241,  ...,  0.0146, -0.0218, -0.0152],
        ...,
        [ 0.0058, -0.0324,  0.0059,  ...,  0.0126,  0.0300, -0.0139],
        [-0.0445,  0.0100,  0.0505,  ...,  0.0299, -0.0133,  0.0091],
        [ 0.0003, -0.0191,  0.0266,  ..., -0.0121,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.layers.26.mlp.down_proj.weight': tensor([[-0.0157, -0.0151, -0.0184,  ...,  0.0317,  0.0165,  0.0026],
        [ 0.0194,  0.0122,  0.0013,  ...,  0.0555,  0.0187, -0.0188],
        [-0.0182,  0.0041, -0.0274,  ..., -0.0111,  0.0171,  0.0083],
        ...,
        [-0.0175, -0.0124, -0.0203,  ...,  0.0105,  0.0436, -0.0020],
        [-0.0128, -0.0142, -0.0195,  ...,  0.0095,  0.0033,  0.0230],
        [ 0.0049, -0.0129, -0.0006,  ...,  0.0101,  0.0221,  0.0164]],
       dtype=torch.float16), 'model.layers.26.input_layernorm.weight': tensor([0.5312, 0.5469, 0.5469,  ..., 0.5234, 0.5508, 0.5547],
       dtype=torch.float16), 'model.layers.26.post_attention_layernorm.weight': tensor([0.4492, 0.4492, 0.4375,  ..., 0.4512, 0.4590, 0.4590],
       dtype=torch.float16), 'model.layers.27.self_attn.q_proj.weight': tensor([[-0.0292,  0.0145,  0.0077,  ..., -0.0038,  0.0122,  0.0435],
        [-0.0134,  0.0433,  0.0299,  ..., -0.0242,  0.0111,  0.0059],
        [-0.0217, -0.0236,  0.0096,  ...,  0.0025, -0.0223,  0.0289],
        ...,
        [-0.0505,  0.0273, -0.0095,  ...,  0.0185, -0.0201, -0.0225],
        [-0.0039,  0.0271,  0.0072,  ...,  0.0084,  0.0002,  0.0258],
        [-0.0235, -0.0104,  0.0114,  ...,  0.0226,  0.0154, -0.0077]],
       dtype=torch.float16), 'model.layers.27.self_attn.k_proj.weight': tensor([[-0.0173, -0.0195,  0.0098,  ..., -0.0015, -0.0104,  0.0059],
        [-0.0029,  0.0090,  0.0194,  ...,  0.0424, -0.0081, -0.0110],
        [ 0.0017, -0.0138,  0.0081,  ..., -0.0129,  0.0021, -0.0088],
        ...,
        [-0.0041, -0.0153,  0.0362,  ...,  0.0069, -0.0344, -0.0087],
        [ 0.0248, -0.0192, -0.0473,  ...,  0.0660, -0.0128,  0.0439],
        [ 0.0315,  0.0143, -0.0021,  ..., -0.0374, -0.0376,  0.0114]],
       dtype=torch.float16), 'model.layers.27.self_attn.v_proj.weight': tensor([[ 0.0174, -0.0144, -0.0334,  ...,  0.0311,  0.0319, -0.0054],
        [ 0.0185,  0.0108,  0.0118,  ...,  0.0023, -0.0246,  0.0214],
        [-0.0263, -0.0055,  0.0169,  ..., -0.0106,  0.0546, -0.0242],
        ...,
        [ 0.0146, -0.0203, -0.0192,  ...,  0.0176, -0.0095, -0.0034],
        [ 0.0059, -0.0240, -0.0200,  ..., -0.0100, -0.0106, -0.0184],
        [ 0.0211, -0.0241, -0.0149,  ..., -0.0229, -0.0193,  0.0111]],
       dtype=torch.float16), 'model.layers.27.self_attn.o_proj.weight': tensor([[ 0.0038, -0.0119,  0.0095,  ...,  0.0242,  0.0067, -0.0269],
        [ 0.0054,  0.0286, -0.0241,  ..., -0.0172, -0.0162,  0.0058],
        [-0.0047, -0.0113, -0.0132,  ...,  0.0162,  0.0009, -0.0092],
        ...,
        [ 0.0251, -0.0114, -0.0128,  ...,  0.0111,  0.0484, -0.0008],
        [ 0.0368, -0.0221, -0.0091,  ..., -0.0011, -0.0006,  0.0184],
        [ 0.0446,  0.0125,  0.0281,  ..., -0.0113, -0.0002, -0.0220]],
       dtype=torch.float16), 'model.layers.27.mlp.gate_proj.weight': tensor([[ 0.0450,  0.0128, -0.0067,  ...,  0.0097,  0.0032, -0.0147],
        [-0.0158,  0.0018, -0.0322,  ...,  0.0303,  0.0333,  0.0226],
        [ 0.0075,  0.0203, -0.0080,  ..., -0.0125, -0.0238,  0.0320],
        ...,
        [ 0.0358,  0.0211,  0.0024,  ..., -0.0008,  0.0165, -0.0047],
        [-0.0144,  0.0255, -0.0209,  ..., -0.0090, -0.0178,  0.0073],
        [ 0.0026, -0.0184, -0.0149,  ..., -0.0166, -0.0047, -0.0048]],
       dtype=torch.float16), 'model.layers.27.mlp.up_proj.weight': tensor([[-0.0049,  0.0078,  0.0265,  ..., -0.0012,  0.0131, -0.0389],
        [-0.0102,  0.0028, -0.0278,  ...,  0.0119, -0.0223, -0.0237],
        [ 0.0258,  0.0162,  0.0435,  ...,  0.0278,  0.0015, -0.0196],
        ...,
        [-0.0044,  0.0250,  0.0330,  ..., -0.0218,  0.0206, -0.0381],
        [ 0.0097,  0.0212,  0.0149,  ...,  0.0130, -0.0131, -0.0248],
        [-0.0111,  0.0048, -0.0053,  ..., -0.0063, -0.0244, -0.0093]],
       dtype=torch.float16), 'model.layers.27.mlp.down_proj.weight': tensor([[ 2.4376e-03, -2.2705e-02,  3.4363e-02,  ..., -1.9394e-02,
          1.9669e-02, -1.1414e-02],
        [ 8.0466e-05,  1.3931e-02, -9.4910e-03,  ..., -1.9272e-02,
         -3.1616e-02,  1.2093e-02],
        [ 4.6478e-02,  1.3847e-02,  5.7602e-03,  ..., -3.2166e-02,
          4.1733e-03,  2.9587e-02],
        ...,
        [-7.6523e-03,  1.0971e-02,  1.5335e-02,  ...,  7.5302e-03,
         -4.5685e-02,  2.5742e-02],
        [-2.2018e-02, -3.3932e-03, -1.7227e-02,  ...,  2.2934e-02,
         -9.0866e-03,  2.0813e-02],
        [ 4.7493e-03,  1.7471e-02, -9.1858e-03,  ...,  1.9531e-02,
         -2.3441e-03, -4.7493e-03]], dtype=torch.float16), 'model.layers.27.input_layernorm.weight': tensor([0.5625, 0.5625, 0.5586,  ..., 0.5547, 0.5625, 0.5703],
       dtype=torch.float16), 'model.layers.27.post_attention_layernorm.weight': tensor([0.4688, 0.4629, 0.4531,  ..., 0.4668, 0.4707, 0.4688],
       dtype=torch.float16), 'model.layers.28.self_attn.q_proj.weight': tensor([[-3.2127e-05, -1.9119e-02, -7.1669e-04,  ..., -1.4694e-02,
         -9.0561e-03, -1.0872e-02],
        [ 1.1421e-02, -1.8387e-02, -2.4986e-03,  ...,  1.3634e-02,
          5.4283e-03, -3.9635e-03],
        [ 1.4305e-02,  6.4993e-04, -1.0948e-02,  ..., -3.7956e-03,
         -2.4414e-02,  2.4261e-02],
        ...,
        [-1.1253e-02,  2.4719e-02, -5.3101e-02,  ...,  1.6006e-02,
         -7.5684e-03, -3.9825e-02],
        [ 1.6541e-02, -2.6855e-02, -1.2665e-02,  ...,  2.0569e-02,
          3.2928e-02, -6.5002e-02],
        [ 1.9409e-02,  1.4633e-02, -4.5654e-02,  ...,  4.5868e-02,
          1.4122e-02, -3.6987e-02]], dtype=torch.float16), 'model.layers.28.self_attn.k_proj.weight': tensor([[-0.0036, -0.0034,  0.0078,  ..., -0.0043,  0.0148, -0.0134],
        [-0.0133, -0.0068, -0.0168,  ..., -0.0066,  0.0050,  0.0043],
        [ 0.0061,  0.0063, -0.0146,  ..., -0.0197, -0.0112,  0.0050],
        ...,
        [-0.0251, -0.0133, -0.0040,  ..., -0.0014, -0.0604, -0.0040],
        [ 0.0462, -0.0221,  0.0039,  ...,  0.0161,  0.0397,  0.0285],
        [ 0.0180, -0.0042,  0.0045,  ..., -0.0038, -0.0185, -0.0136]],
       dtype=torch.float16), 'model.layers.28.self_attn.v_proj.weight': tensor([[-0.0240,  0.0090,  0.0227,  ..., -0.0210, -0.0288,  0.0260],
        [ 0.0231, -0.0178, -0.0135,  ..., -0.0447,  0.0313, -0.0163],
        [-0.0102,  0.0174, -0.0021,  ...,  0.0075, -0.0479,  0.0167],
        ...,
        [ 0.0193,  0.0043, -0.0005,  ...,  0.0143, -0.0064, -0.0217],
        [ 0.0511,  0.0041,  0.0421,  ...,  0.0019,  0.0046, -0.0031],
        [ 0.0181,  0.0192, -0.0485,  ...,  0.0328, -0.0048,  0.0090]],
       dtype=torch.float16), 'model.layers.28.self_attn.o_proj.weight': tensor([[ 1.1208e-02,  2.4567e-02, -4.1473e-02,  ..., -3.4485e-02,
          1.7929e-02, -9.8646e-05],
        [-1.2238e-02, -2.0905e-02, -2.8381e-03,  ..., -1.7075e-02,
          2.7145e-02,  3.2501e-02],
        [ 2.7863e-02,  1.7838e-02, -5.3741e-02,  ...,  2.2293e-02,
          1.5701e-02, -1.6464e-02],
        ...,
        [ 2.5444e-03, -4.4098e-03,  3.4332e-02,  ..., -9.8801e-03,
         -3.9917e-02, -6.6757e-03],
        [-7.5188e-03, -5.8655e-02, -1.8112e-02,  ...,  2.0889e-02,
         -2.8183e-02, -2.7084e-02],
        [-4.3823e-02, -4.1618e-03, -1.0742e-02,  ..., -1.9196e-02,
         -8.0719e-03,  4.2839e-03]], dtype=torch.float16), 'model.layers.28.mlp.gate_proj.weight': tensor([[-0.0007,  0.0031, -0.0068,  ...,  0.0274, -0.0111,  0.0312],
        [-0.0257,  0.0139, -0.0106,  ...,  0.0121,  0.0034,  0.0177],
        [ 0.0099,  0.0288,  0.0274,  ...,  0.0168,  0.0038,  0.0067],
        ...,
        [-0.0053,  0.0228,  0.0102,  ...,  0.0135,  0.0128, -0.0202],
        [ 0.0124, -0.0344, -0.0104,  ..., -0.0197, -0.0044, -0.0032],
        [-0.0318,  0.0149,  0.0106,  ..., -0.0078, -0.0112,  0.0179]],
       dtype=torch.float16), 'model.layers.28.mlp.up_proj.weight': tensor([[ 0.0224,  0.0047,  0.0220,  ...,  0.0277,  0.0156,  0.0114],
        [-0.0177, -0.0260, -0.0041,  ..., -0.0033, -0.0355, -0.0220],
        [ 0.0064,  0.0259, -0.0073,  ...,  0.0068,  0.0073, -0.0160],
        ...,
        [-0.0055, -0.0151,  0.0324,  ..., -0.0026,  0.0111, -0.0013],
        [-0.0215,  0.0078, -0.0074,  ...,  0.0127, -0.0099, -0.0497],
        [-0.0093, -0.0252, -0.0048,  ..., -0.0067,  0.0076,  0.0080]],
       dtype=torch.float16), 'model.layers.28.mlp.down_proj.weight': tensor([[ 0.0077,  0.0342, -0.0055,  ...,  0.0029, -0.0016, -0.0298],
        [-0.0009, -0.0338,  0.0198,  ..., -0.0268, -0.0070, -0.0280],
        [-0.0241,  0.0253, -0.0140,  ...,  0.0032,  0.0074, -0.0012],
        ...,
        [ 0.0106, -0.0143, -0.0053,  ..., -0.0309, -0.0309,  0.0070],
        [-0.0170, -0.0194,  0.0628,  ..., -0.0242, -0.0061,  0.0128],
        [-0.0234,  0.0108, -0.0081,  ...,  0.0294,  0.0295, -0.0142]],
       dtype=torch.float16), 'model.layers.28.input_layernorm.weight': tensor([0.5781, 0.5859, 0.5664,  ..., 0.5547, 0.5742, 0.5742],
       dtype=torch.float16), 'model.layers.28.post_attention_layernorm.weight': tensor([0.4805, 0.4785, 0.4648,  ..., 0.4785, 0.4727, 0.4727],
       dtype=torch.float16), 'model.layers.29.self_attn.q_proj.weight': tensor([[ 0.0060,  0.0026, -0.0075,  ...,  0.0002, -0.0110,  0.0094],
        [-0.0288, -0.0180, -0.0257,  ..., -0.0128, -0.0063, -0.0059],
        [-0.0291,  0.0377, -0.0024,  ..., -0.0022, -0.0156,  0.0146],
        ...,
        [ 0.0005,  0.0704, -0.0331,  ...,  0.0133, -0.0080, -0.0352],
        [-0.0236, -0.0242,  0.0169,  ..., -0.0142, -0.0230,  0.0260],
        [ 0.0005, -0.0416, -0.0127,  ...,  0.0132,  0.0065, -0.0391]],
       dtype=torch.float16), 'model.layers.29.self_attn.k_proj.weight': tensor([[ 0.0357, -0.0135, -0.0162,  ...,  0.0005,  0.0101, -0.0023],
        [-0.0177,  0.0316, -0.0048,  ..., -0.0086,  0.0006, -0.0218],
        [ 0.0214,  0.0079,  0.0186,  ...,  0.0193,  0.0339, -0.0014],
        ...,
        [-0.0317,  0.0448,  0.0010,  ..., -0.0091,  0.0024, -0.0117],
        [ 0.0014, -0.0123, -0.0701,  ..., -0.0106, -0.0095, -0.0427],
        [ 0.0107, -0.0124, -0.0583,  ..., -0.0584, -0.0144,  0.0027]],
       dtype=torch.float16), 'model.layers.29.self_attn.v_proj.weight': tensor([[ 0.0110,  0.0064,  0.0324,  ...,  0.0194,  0.0085,  0.0135],
        [-0.0017,  0.0247,  0.0385,  ..., -0.0199,  0.0092, -0.0022],
        [-0.0130,  0.0104, -0.0103,  ...,  0.0083,  0.0268,  0.0188],
        ...,
        [ 0.0067,  0.0294,  0.0116,  ..., -0.0203, -0.0125, -0.0172],
        [ 0.0001,  0.0276, -0.0236,  ...,  0.0186,  0.0294, -0.0053],
        [-0.0033, -0.0211,  0.0092,  ..., -0.0019, -0.0083,  0.0262]],
       dtype=torch.float16), 'model.layers.29.self_attn.o_proj.weight': tensor([[-6.3057e-03,  3.2288e-02,  3.3630e-02,  ...,  5.8222e-04,
         -1.7517e-02, -6.4850e-03],
        [-2.0340e-02, -2.5772e-02, -1.2833e-02,  ...,  1.2199e-02,
         -2.8244e-02,  1.2634e-02],
        [ 2.6093e-02,  2.8381e-02, -8.5678e-03,  ..., -3.7781e-02,
          1.7441e-02, -2.1240e-02],
        ...,
        [-2.8381e-02, -1.6617e-02,  2.8061e-02,  ..., -7.0839e-03,
         -7.8201e-03, -1.4076e-02],
        [-1.3969e-02, -1.0399e-02,  3.3966e-02,  ..., -4.7803e-05,
         -2.0554e-02,  4.7226e-03],
        [ 1.5411e-02,  3.9749e-03, -3.4275e-03,  ...,  4.1122e-03,
          1.9104e-02, -2.8473e-02]], dtype=torch.float16), 'model.layers.29.mlp.gate_proj.weight': tensor([[ 0.0161,  0.0169, -0.0145,  ..., -0.0036, -0.0243,  0.0359],
        [ 0.0034,  0.0243, -0.0081,  ..., -0.0228,  0.0151,  0.0046],
        [ 0.0371, -0.0013, -0.0085,  ..., -0.0063,  0.0206,  0.0335],
        ...,
        [-0.0048,  0.0104, -0.0152,  ...,  0.0026,  0.0065,  0.0039],
        [ 0.0079,  0.0031, -0.0292,  ..., -0.0222, -0.0051,  0.0174],
        [-0.0031,  0.0190, -0.0012,  ...,  0.0228, -0.0130, -0.0158]],
       dtype=torch.float16), 'model.layers.29.mlp.up_proj.weight': tensor([[-0.0069,  0.0021,  0.0118,  ...,  0.0150,  0.0049,  0.0057],
        [ 0.0012,  0.0072,  0.0320,  ...,  0.0089, -0.0199,  0.0363],
        [-0.0076, -0.0212, -0.0125,  ..., -0.0495,  0.0085, -0.0360],
        ...,
        [ 0.0260,  0.0129,  0.0126,  ...,  0.0124,  0.0245,  0.0357],
        [-0.0250, -0.0191, -0.0051,  ...,  0.0142,  0.0133,  0.0017],
        [ 0.0065, -0.0030,  0.0111,  ..., -0.0080,  0.0094,  0.0100]],
       dtype=torch.float16), 'model.layers.29.mlp.down_proj.weight': tensor([[ 0.0411,  0.0098, -0.0018,  ...,  0.0168, -0.0244, -0.0152],
        [ 0.0184,  0.0098,  0.0223,  ...,  0.0344,  0.0027,  0.0017],
        [ 0.0008, -0.0209, -0.0160,  ..., -0.0007,  0.0110, -0.0271],
        ...,
        [ 0.0088, -0.0090,  0.0057,  ..., -0.0189, -0.0051, -0.0197],
        [ 0.0228,  0.0159,  0.0265,  ...,  0.0094, -0.0411,  0.0024],
        [ 0.0148, -0.0185, -0.0088,  ..., -0.0158, -0.0135,  0.0045]],
       dtype=torch.float16), 'model.layers.29.input_layernorm.weight': tensor([0.5430, 0.5586, 0.5391,  ..., 0.5312, 0.5586, 0.5625],
       dtype=torch.float16), 'model.layers.29.post_attention_layernorm.weight': tensor([0.4902, 0.4922, 0.4785,  ..., 0.4785, 0.4922, 0.4805],
       dtype=torch.float16), 'model.layers.30.self_attn.q_proj.weight': tensor([[-0.0041, -0.0047,  0.0075,  ..., -0.0091, -0.0045,  0.0028],
        [ 0.0163,  0.0142,  0.0050,  ..., -0.0033, -0.0027, -0.0191],
        [-0.0086, -0.0204,  0.0428,  ...,  0.0224,  0.0053, -0.0305],
        ...,
        [-0.0093, -0.0009, -0.0012,  ...,  0.0209, -0.0119,  0.0017],
        [-0.0005, -0.0218, -0.0206,  ...,  0.0153,  0.0086, -0.0354],
        [-0.0708, -0.0093,  0.0420,  ..., -0.0094, -0.0046, -0.0015]],
       dtype=torch.float16), 'model.layers.30.self_attn.k_proj.weight': tensor([[ 0.0262, -0.0208,  0.0015,  ..., -0.0112,  0.0095,  0.0076],
        [ 0.0337,  0.0127,  0.0035,  ..., -0.0041, -0.0045,  0.0022],
        [-0.0044, -0.0148,  0.0216,  ...,  0.0055, -0.0088, -0.0004],
        ...,
        [ 0.0057,  0.0255,  0.0007,  ...,  0.0564, -0.0037, -0.0002],
        [ 0.0107, -0.0630,  0.0325,  ...,  0.0062, -0.0082, -0.0273],
        [-0.0373, -0.0082,  0.0209,  ...,  0.0079,  0.0169, -0.0247]],
       dtype=torch.float16), 'model.layers.30.self_attn.v_proj.weight': tensor([[-0.0035, -0.0291,  0.0310,  ..., -0.0268, -0.0363,  0.0307],
        [ 0.0073,  0.0172,  0.0300,  ..., -0.0118,  0.0262,  0.0019],
        [-0.0203,  0.0174, -0.0189,  ...,  0.0050, -0.0255, -0.0103],
        ...,
        [ 0.0184, -0.0039, -0.0030,  ..., -0.0245,  0.0030,  0.0241],
        [-0.0072, -0.0434,  0.0219,  ...,  0.0296, -0.0089,  0.0216],
        [-0.0088,  0.0059,  0.0193,  ..., -0.0144, -0.0613, -0.0227]],
       dtype=torch.float16), 'model.layers.30.self_attn.o_proj.weight': tensor([[-0.0074,  0.0176, -0.0070,  ...,  0.0119, -0.0119, -0.0202],
        [-0.0116, -0.0252, -0.0082,  ...,  0.0136, -0.0305, -0.0236],
        [-0.0294, -0.0029,  0.0179,  ..., -0.0482, -0.0128, -0.0113],
        ...,
        [ 0.0068,  0.0052,  0.0028,  ..., -0.0247,  0.0106,  0.0177],
        [ 0.0227, -0.0089,  0.0036,  ...,  0.0353, -0.0069,  0.0047],
        [-0.0028,  0.0133, -0.0032,  ..., -0.0048,  0.0101, -0.0147]],
       dtype=torch.float16), 'model.layers.30.mlp.gate_proj.weight': tensor([[-0.0422, -0.0289, -0.0057,  ...,  0.0138, -0.0067, -0.0003],
        [-0.0175,  0.0047,  0.0389,  ..., -0.0063, -0.0058,  0.0305],
        [-0.0219, -0.0067, -0.0307,  ...,  0.0154, -0.0004, -0.0035],
        ...,
        [-0.0204, -0.0261,  0.0121,  ..., -0.0081, -0.0219, -0.0244],
        [ 0.0268,  0.0282, -0.0097,  ...,  0.0118, -0.0396, -0.0025],
        [-0.0012, -0.0307, -0.0203,  ..., -0.0023,  0.0182, -0.0061]],
       dtype=torch.float16), 'model.layers.30.mlp.up_proj.weight': tensor([[ 0.0034,  0.0162,  0.0123,  ...,  0.0126,  0.0213, -0.0029],
        [-0.0196, -0.0118,  0.0388,  ...,  0.0008, -0.0193, -0.0033],
        [-0.0327, -0.0235, -0.0368,  ..., -0.0176,  0.0011,  0.0209],
        ...,
        [-0.0163, -0.0128,  0.0153,  ...,  0.0128, -0.0097, -0.0216],
        [-0.0081,  0.0077, -0.0097,  ...,  0.0053, -0.0229,  0.0164],
        [-0.0030, -0.0283,  0.0003,  ..., -0.0168,  0.0070,  0.0171]],
       dtype=torch.float16), 'model.layers.30.mlp.down_proj.weight': tensor([[ 2.2812e-02, -1.3634e-02, -3.0258e-02,  ...,  3.1342e-02,
         -7.2098e-03, -8.8263e-04],
        [ 2.5818e-02,  4.8409e-03,  4.3427e-02,  ...,  1.2611e-02,
          1.6594e-03, -7.8888e-03],
        [ 3.6883e-04, -3.0899e-03, -2.1591e-02,  ...,  3.1242e-03,
          1.0376e-02,  2.0767e-02],
        ...,
        [-3.1921e-02,  6.3400e-03, -2.4643e-02,  ...,  1.8341e-02,
         -2.4780e-02, -9.6664e-03],
        [-4.3750e-05, -1.9287e-02,  2.8934e-03,  ...,  1.9730e-02,
          2.3232e-03,  1.2312e-03],
        [-8.7738e-03, -1.4030e-02, -2.5955e-02,  ...,  1.0109e-02,
          3.0589e-04, -1.9150e-02]], dtype=torch.float16), 'model.layers.30.input_layernorm.weight': tensor([0.5859, 0.6016, 0.5664,  ..., 0.5586, 0.5781, 0.6016],
       dtype=torch.float16), 'model.layers.30.post_attention_layernorm.weight': tensor([0.4824, 0.5039, 0.4824,  ..., 0.4883, 0.4980, 0.4863],
       dtype=torch.float16), 'model.layers.31.self_attn.q_proj.weight': tensor([[-0.0350,  0.0179,  0.0228,  ...,  0.0133, -0.0005, -0.0199],
        [-0.0200, -0.0252, -0.0369,  ...,  0.0008, -0.0122, -0.0238],
        [-0.0219,  0.0272,  0.0192,  ..., -0.0004,  0.0037,  0.0022],
        ...,
        [ 0.0171, -0.0177, -0.0151,  ..., -0.0145,  0.0273, -0.0253],
        [-0.0265,  0.0056, -0.0053,  ..., -0.0029,  0.0124,  0.0107],
        [-0.0533, -0.0123,  0.0282,  ...,  0.0389, -0.0044,  0.0329]],
       dtype=torch.float16), 'model.layers.31.self_attn.k_proj.weight': tensor([[-0.0058, -0.0082,  0.0132,  ..., -0.0011, -0.0107, -0.0206],
        [ 0.0245, -0.0202,  0.0109,  ..., -0.0002,  0.0066, -0.0021],
        [ 0.0027,  0.0117, -0.0064,  ...,  0.0055, -0.0005, -0.0275],
        ...,
        [ 0.0315, -0.0261, -0.0244,  ..., -0.0081, -0.0101, -0.0515],
        [ 0.0134,  0.0200,  0.0124,  ..., -0.0259, -0.0236,  0.0204],
        [-0.0787, -0.0352,  0.0162,  ..., -0.0131,  0.0023, -0.0065]],
       dtype=torch.float16), 'model.layers.31.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0230, -0.0018,  ...,  0.0031,  0.0012,  0.0155],
        [ 0.0281,  0.0153,  0.0112,  ...,  0.0094,  0.0336,  0.0164],
        [ 0.0143, -0.0011, -0.0159,  ...,  0.0129,  0.0024,  0.0344],
        ...,
        [-0.0017, -0.0013, -0.0144,  ..., -0.0160, -0.0032,  0.0248],
        [ 0.0126, -0.0183,  0.0156,  ..., -0.0102, -0.0292,  0.0144],
        [-0.0103, -0.0228,  0.0264,  ...,  0.0243, -0.0042,  0.0403]],
       dtype=torch.float16), 'model.layers.31.self_attn.o_proj.weight': tensor([[ 0.0089,  0.0304, -0.0052,  ..., -0.0004, -0.0148, -0.0504],
        [-0.0065,  0.0034, -0.0314,  ...,  0.0269, -0.0200, -0.0146],
        [ 0.0102,  0.0023,  0.0032,  ..., -0.0174,  0.0214,  0.0120],
        ...,
        [ 0.0077, -0.0209,  0.0315,  ..., -0.0161, -0.0128, -0.0216],
        [ 0.0010,  0.0138, -0.0207,  ..., -0.0174, -0.0141, -0.0177],
        [ 0.0062,  0.0165, -0.0088,  ...,  0.0295, -0.0164,  0.0075]],
       dtype=torch.float16), 'model.layers.31.mlp.gate_proj.weight': tensor([[ 0.0088, -0.0101,  0.0378,  ...,  0.0157,  0.0179,  0.0108],
        [-0.0751, -0.0179,  0.0038,  ...,  0.0049, -0.0193,  0.0181],
        [ 0.0142,  0.0066, -0.0107,  ..., -0.0041, -0.0197, -0.0075],
        ...,
        [-0.0168, -0.0297,  0.0126,  ..., -0.0009,  0.0242,  0.0329],
        [ 0.0417,  0.0298, -0.0222,  ...,  0.0354, -0.0096, -0.0061],
        [ 0.0174, -0.0382, -0.0287,  ..., -0.0177,  0.0085,  0.0057]],
       dtype=torch.float16), 'model.layers.31.mlp.up_proj.weight': tensor([[-0.0397, -0.0182,  0.0206,  ...,  0.0010, -0.0187,  0.0024],
        [ 0.0275,  0.0354,  0.0046,  ..., -0.0228,  0.0012, -0.0013],
        [-0.0043,  0.0044, -0.0210,  ...,  0.0143,  0.0034, -0.0117],
        ...,
        [ 0.0134, -0.0182,  0.0072,  ...,  0.0026,  0.0326, -0.0186],
        [ 0.0055,  0.0044, -0.0258,  ...,  0.0280,  0.0101, -0.0022],
        [ 0.0409, -0.0411, -0.0085,  ..., -0.0104,  0.0099,  0.0237]],
       dtype=torch.float16), 'model.layers.31.mlp.down_proj.weight': tensor([[-1.2767e-04, -2.5101e-02, -9.8572e-03,  ..., -3.8147e-02,
         -1.4954e-02,  2.7756e-02],
        [ 3.8208e-02,  3.5248e-03, -3.6736e-03,  ..., -5.2691e-04,
         -1.6205e-02,  1.3901e-02],
        [-1.2566e-02, -1.2192e-02,  2.5131e-02,  ...,  3.0304e-02,
         -1.5383e-03,  2.3193e-02],
        ...,
        [ 4.7088e-05,  2.8351e-02, -2.0237e-03,  ...,  1.1597e-02,
          5.3177e-03,  1.7136e-02],
        [-9.8515e-04,  4.7424e-02, -5.3787e-03,  ..., -7.3509e-03,
          2.3331e-02,  1.7090e-02],
        [ 2.6001e-02, -3.8910e-02,  1.8829e-02,  ...,  4.1313e-03,
          1.2999e-03,  2.6016e-02]], dtype=torch.float16), 'model.layers.31.input_layernorm.weight': tensor([0.4961, 0.4980, 0.4453,  ..., 0.4375, 0.4727, 0.4922],
       dtype=torch.float16), 'model.layers.31.post_attention_layernorm.weight': tensor([0.4414, 0.4434, 0.4531,  ..., 0.4336, 0.4219, 0.4375],
       dtype=torch.float16), 'model.norm.weight': tensor([2.0000, 2.0469, 1.9453,  ..., 1.8594, 1.9453, 1.7656],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding': tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight': tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,
            2.1957e-02,  5.0011e-03],
          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,
            7.5417e-03, -1.2230e-02],
          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,
            5.3940e-03, -1.2283e-02],
          ...,
          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,
           -2.3239e-02, -2.4017e-02],
          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,
            1.5745e-03, -4.1771e-03],
          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,
            4.0169e-03, -6.7177e-03]],

         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,
            2.4185e-02,  5.8136e-03],
          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,
            5.4970e-03, -1.4351e-02],
          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,
            5.5618e-03, -1.2390e-02],
          ...,
          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,
            3.9816e-04, -5.1346e-03],
          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,
            2.2552e-02,  1.2917e-02],
          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,
            1.8158e-02,  9.2745e-04]],

         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,
            1.1757e-02,  5.7259e-03],
          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,
           -4.2191e-03, -7.1831e-03],
          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,
            1.3041e-04, -7.3051e-03],
          ...,
          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,
           -9.8267e-03, -6.7825e-03],
          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,
            6.3400e-03,  5.3177e-03],
          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,
            6.5193e-03,  2.9850e-04]]],


        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,
           -8.4381e-03,  2.0447e-02],
          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,
            3.5906e-04,  1.5945e-02],
          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,
           -2.7924e-02, -3.2177e-03],
          ...,
          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,
           -5.4741e-03, -5.9624e-03],
          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,
           -2.7969e-02, -1.8875e-02],
          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,
            7.1335e-03,  4.6478e-02]],

         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,
           -1.1604e-02,  1.7593e-02],
          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,
            3.4976e-04,  1.4732e-02],
          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,
           -3.2684e-02, -7.0076e-03],
          ...,
          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,
           -1.1253e-02, -9.8648e-03],
          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,
           -3.7231e-02, -2.6505e-02],
          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,
           -4.2000e-03,  3.9368e-02]],

         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,
           -1.2558e-02,  1.7303e-02],
          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,
            4.3440e-04,  1.5656e-02],
          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,
           -2.9968e-02, -6.5422e-03],
          ...,
          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,
           -8.7967e-03, -8.7662e-03],
          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,
           -3.0518e-02, -2.4918e-02],
          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,
           -7.3242e-04,  3.8818e-02]]],


        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,
            1.4229e-02,  1.8768e-02],
          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,
            5.4283e-03,  6.6032e-03],
          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,
            2.5959e-03,  6.8703e-03],
          ...,
          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,
            1.4397e-02,  1.2421e-02],
          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,
            2.2766e-02,  2.2659e-02],
          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,
            2.2263e-02,  2.5238e-02]],

         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,
            1.9653e-02,  2.8290e-02],
          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,
            6.0501e-03,  1.2810e-02],
          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,
           -5.9271e-04,  8.8959e-03],
          ...,
          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,
            2.4902e-02,  2.6871e-02],
          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,
            3.3569e-02,  3.9612e-02],
          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,
            3.9276e-02,  4.6051e-02]],

         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,
            2.1042e-02,  2.9053e-02],
          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,
            7.7019e-03,  1.2169e-02],
          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,
            3.3913e-03,  9.0408e-03],
          ...,
          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,
            8.0795e-03,  1.4221e-02],
          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,
            1.1887e-02,  1.8204e-02],
          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,
            1.5701e-02,  2.2247e-02]]],


        ...,


        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,
            3.1686e-04, -3.0446e-04],
          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,
           -2.2995e-04, -1.6510e-04],
          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,
           -5.0831e-04,  5.9748e-04],
          ...,
          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,
           -9.3746e-04, -6.7472e-04],
          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,
           -1.4048e-03, -1.3056e-03],
          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,
            3.2640e-04,  1.7679e-04]],

         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,
            1.0500e-03, -5.0831e-04],
          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,
            1.0071e-03, -4.9925e-04],
          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,
            8.0919e-04,  9.7132e-04],
          ...,
          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,
            6.2895e-04,  4.0889e-04],
          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,
           -2.8610e-04,  1.9038e-04],
          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,
            1.4138e-04,  4.2319e-04]],

         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,
           -4.3130e-04, -5.6791e-04],
          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,
            1.9002e-04,  1.8311e-04],
          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,
            2.3186e-05, -5.7578e-05],
          ...,
          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,
            1.3471e-04,  6.5708e-04],
          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,
            1.0538e-04, -4.9019e-04],
          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,
           -4.1580e-04,  5.5599e-04]]],


        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,
            6.1874e-03,  2.6535e-02],
          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,
           -1.7639e-02, -3.2768e-03],
          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,
           -2.7237e-02, -5.5046e-03],
          ...,
          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,
            2.8503e-02,  3.6499e-02],
          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,
           -2.3010e-02,  5.0926e-03],
          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,
           -3.9276e-02,  1.3908e-02]],

         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,
            2.8896e-03,  2.2415e-02],
          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,
           -1.8616e-02, -6.5308e-03],
          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,
           -3.0472e-02, -9.3613e-03],
          ...,
          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,
            2.6001e-02,  3.4241e-02],
          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,
           -3.0487e-02, -9.5701e-04],
          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,
           -5.1422e-02,  4.2267e-03]],

         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,
           -2.1572e-03,  1.6891e-02],
          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,
           -2.1347e-02, -9.2316e-03],
          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,
           -2.9694e-02, -1.2733e-02],
          ...,
          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,
            1.9257e-02,  2.4582e-02],
          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,
           -3.1281e-02, -9.1248e-03],
          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,
           -5.2246e-02, -2.8057e-03]]],


        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,
            8.1863e-03, -4.8248e-02],
          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,
            9.3689e-03, -3.8544e-02],
          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,
            2.3956e-02, -1.1154e-02],
          ...,
          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,
           -1.8654e-03, -1.9440e-02],
          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,
            8.4381e-03,  1.4282e-02],
          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,
            1.6689e-03,  1.6891e-02]],

         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,
            1.5839e-02, -4.3243e-02],
          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,
            1.8433e-02, -3.1799e-02],
          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,
            2.9694e-02, -5.4817e-03],
          ...,
          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,
           -1.5268e-03, -1.4626e-02],
          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,
            8.5602e-03,  2.0035e-02],
          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,
           -2.3785e-03,  1.9150e-02]],

         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,
            2.1317e-02, -3.0197e-02],
          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,
            2.4658e-02, -1.7670e-02],
          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,
            3.4302e-02,  4.5395e-03],
          ...,
          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,
            4.1656e-03, -5.9814e-03],
          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,
            1.6068e-02,  2.5879e-02],
          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,
            2.2964e-03,  2.2339e-02]]]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight': tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],
        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],
        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],
        ...,
        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],
        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],
        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight': tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias': tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight': tensor([[-1.1724e-04,  8.3399e-04, -1.5700e-04,  ..., -4.8332e-03,
          1.3428e-02,  3.2604e-05],
        [-4.4703e-05, -9.5272e-04,  1.2279e-04,  ...,  1.9855e-03,
         -1.3626e-02, -4.1783e-05],
        [ 6.6280e-04,  1.0419e-04,  9.0420e-05,  ..., -2.1820e-02,
          4.1199e-03,  3.2187e-06],
        ...,
        [-5.2512e-05, -2.9278e-04, -3.6895e-05,  ...,  8.8196e-03,
         -4.2796e-04, -3.0100e-05],
        [ 7.5936e-05, -6.5148e-05, -9.0182e-05,  ...,  8.1682e-04,
         -6.0844e-03,  1.9014e-05],
        [-6.3896e-05,  9.8705e-05,  4.9829e-05,  ..., -1.2579e-03,
         -7.1793e-03,  2.3961e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias': tensor([ 0.0577, -0.0588, -0.0266,  ..., -0.0147, -0.0175,  0.0096],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight': tensor([[ 2.4986e-04, -1.5283e-04, -5.8556e-04,  ...,  3.3607e-03,
         -9.5901e-03,  5.5373e-05],
        [-3.4356e-04, -1.5092e-04,  5.2691e-05,  ...,  2.5725e-04,
          1.0010e-02, -6.2883e-05],
        [ 6.7472e-04, -9.6798e-05,  2.5392e-04,  ..., -1.0386e-03,
         -1.9531e-02, -1.2141e-04],
        ...,
        [ 2.9850e-04,  4.0436e-04, -9.7811e-05,  ...,  4.6654e-03,
         -2.2392e-03, -6.6221e-05],
        [ 3.2973e-04, -3.2961e-05, -2.1207e-04,  ...,  1.1917e-02,
          3.4637e-03,  6.9439e-05],
        [ 2.1458e-06,  4.7874e-04,  4.8459e-05,  ..., -1.1612e-02,
          2.6779e-03, -8.3089e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias': tensor([-0.0277,  0.0222, -0.0355,  ...,  0.0123,  0.0105, -0.0041],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight': tensor([[-2.6703e-05, -1.3638e-04, -8.3923e-05,  ...,  4.2152e-03,
         -2.7649e-02, -7.5042e-05],
        [-1.6391e-04,  9.0241e-05,  5.4836e-05,  ..., -1.5821e-03,
          2.9831e-02,  7.0333e-05],
        [ 4.7588e-04,  7.6008e-04, -1.0198e-04,  ..., -1.7090e-02,
          4.1809e-02,  1.5020e-04],
        ...,
        [ 6.9141e-05,  7.0274e-05,  8.6784e-05,  ..., -4.3411e-03,
          1.1421e-02, -3.8803e-05],
        [-1.8144e-04,  1.4305e-06, -2.5940e-04,  ...,  1.5802e-03,
         -1.8799e-04,  1.6689e-05],
        [-1.2624e-04,  9.4473e-05,  5.3406e-05,  ..., -1.4961e-02,
         -5.8937e-04,  4.2021e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias': tensor([ 1.5693, -1.6172, -0.8213,  ..., -1.2852, -0.0976,  0.7852],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight': tensor([[-0.0073,  0.0083, -0.0076,  ..., -0.0090, -0.0080,  0.0038],
        [ 0.0107,  0.0062,  0.0133,  ..., -0.0036,  0.0022,  0.0034],
        [-0.0065,  0.0033,  0.0139,  ...,  0.0069,  0.0004, -0.0009],
        ...,
        [-0.0002, -0.0035, -0.0027,  ..., -0.0046, -0.0187,  0.0087],
        [-0.0093,  0.0047, -0.0083,  ...,  0.0006, -0.0013, -0.0006],
        [ 0.0092,  0.0003,  0.0016,  ...,  0.0016, -0.0045,  0.0045]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias': tensor([-0.0263, -0.0654,  0.0031,  ...,  0.1759, -0.0438,  0.0020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight': tensor([8.3113e-04, 2.9087e-03, 1.1456e-04,  ..., 6.9092e-01, 3.5498e-01,
        2.4021e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias': tensor([ 6.9141e-06,  7.7629e-04, -8.8811e-05,  ..., -3.6816e-01,
         1.7981e-01, -1.0854e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight': tensor([[ 4.2367e-04, -2.1219e-05,  5.9605e-08,  ..., -5.6458e-03,
         -1.2026e-03, -6.4087e-04],
        [ 6.1340e-03,  1.3588e-02, -3.5858e-04,  ..., -3.5954e-03,
         -7.6485e-04,  6.7101e-03],
        [ 1.3552e-03,  1.2817e-03, -2.0266e-06,  ..., -2.8351e-02,
         -1.2054e-03,  1.4830e-03],
        ...,
        [-2.4002e-02, -1.0193e-02,  2.1684e-04,  ..., -2.5864e-03,
         -1.1841e-02,  5.9166e-03],
        [ 4.1008e-04,  4.2856e-05, -1.1921e-07,  ..., -5.0697e-03,
         -7.7248e-04, -6.3896e-04],
        [-6.3753e-04, -2.3392e-02, -2.6226e-04,  ..., -4.2801e-03,
          2.7962e-03, -8.1863e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias': tensor([-0.6826, -0.3130, -0.8076,  ..., -0.2166, -0.6538, -0.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight': tensor([[-0.0037, -0.0032,  0.0043,  ...,  0.0117, -0.0042, -0.0073],
        [ 0.0017,  0.0183, -0.0100,  ..., -0.0255,  0.0024,  0.0209],
        [ 0.0033,  0.0024, -0.0029,  ...,  0.0037,  0.0032, -0.0154],
        ...,
        [ 0.0015, -0.0007, -0.0035,  ...,  0.0049,  0.0009,  0.0082],
        [-0.0060,  0.0064,  0.0067,  ..., -0.0009, -0.0061,  0.0016],
        [ 0.0007, -0.0034, -0.0020,  ..., -0.0091,  0.0009,  0.0035]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias': tensor([-0.0185, -0.1009,  0.0397,  ..., -0.0955, -0.1080, -0.0239],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight': tensor([2.8296e-01, 5.9082e-01, 1.0455e-04,  ..., 2.0195e+00, 7.7490e-01,
        2.9736e-01], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias': tensor([2.1988e-02, 2.1716e-01, 9.2089e-05,  ..., 2.6318e-01, 4.5020e-01,
        5.0903e-02], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight': tensor([[-3.9864e-03,  1.4374e-02, -2.8610e-03,  ...,  1.0399e-02,
         -2.8076e-02,  5.1155e-03],
        [ 8.1024e-03,  2.2583e-03,  1.1635e-02,  ..., -7.1716e-03,
         -7.5607e-03,  2.5375e-02],
        [ 9.5596e-03,  1.1284e-02, -3.6469e-03,  ..., -6.6757e-03,
         -1.2465e-03, -1.1475e-02],
        ...,
        [ 7.7188e-05, -1.6190e-02,  3.6583e-03,  ...,  2.1240e-02,
          4.3907e-03, -1.0063e-02],
        [ 1.5762e-02,  1.7273e-02, -3.3447e-02,  ..., -2.2507e-03,
         -1.2947e-02,  1.1726e-02],
        [-2.2697e-04,  1.2230e-02, -4.3411e-03,  ...,  3.3436e-03,
         -4.9973e-03,  5.5504e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias': tensor([-0.0012,  0.0081,  0.0097,  ...,  0.0535,  0.0071,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight': tensor([[ 0.0077,  0.0006,  0.0053,  ..., -0.0067,  0.0008,  0.0013],
        [ 0.0230, -0.0166, -0.0004,  ...,  0.0092, -0.0118, -0.0134],
        [-0.0103,  0.0013,  0.0111,  ..., -0.0549, -0.0047,  0.0056],
        ...,
        [ 0.0119,  0.0002, -0.0045,  ...,  0.0001,  0.0034, -0.0075],
        [-0.0129, -0.0114,  0.0075,  ..., -0.0030,  0.0044,  0.0061],
        [-0.0006, -0.0018,  0.0009,  ..., -0.0068, -0.0205, -0.0002]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias': tensor([ 0.0038, -0.0079, -0.1469,  ..., -0.0014, -0.0041,  0.0007],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight': tensor([[-2.4929e-03,  4.6706e-04, -1.8919e-04,  ...,  6.1684e-03,
         -2.4582e-02,  8.7051e-03],
        [ 6.5422e-03,  4.3602e-03,  1.5930e-02,  ..., -6.5994e-03,
          8.2169e-03,  6.1111e-03],
        [ 1.0727e-02, -9.2239e-03, -7.5698e-06,  ...,  3.7136e-03,
          1.6861e-02,  3.5305e-03],
        ...,
        [-2.3708e-03,  6.6452e-03,  5.9052e-03,  ..., -1.0399e-02,
          2.9945e-04, -9.6989e-04],
        [ 3.0609e-02,  1.3458e-02, -3.3386e-02,  ..., -1.3857e-03,
          3.5801e-03,  1.3245e-02],
        [-3.2291e-03,  4.7607e-03, -1.8759e-03,  ...,  6.1035e-04,
          4.9515e-03, -5.3520e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias': tensor([-0.1035,  0.8804,  1.4414,  ..., -2.2109, -0.1892,  0.0048],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight': tensor([[-0.0013, -0.0215,  0.0011,  ..., -0.0115,  0.0102, -0.0012],
        [-0.0010,  0.0065, -0.0018,  ..., -0.0036,  0.0112, -0.0025],
        [ 0.0015, -0.0069, -0.0120,  ..., -0.0047, -0.0009, -0.0056],
        ...,
        [ 0.0053, -0.0177,  0.0780,  ..., -0.0228, -0.0122,  0.0151],
        [-0.0086, -0.0019,  0.0054,  ...,  0.0081, -0.0049,  0.0067],
        [-0.0037,  0.0063, -0.0005,  ...,  0.0054,  0.0045, -0.0036]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias': tensor([-0.0204, -0.0210,  0.0255,  ..., -0.0381, -0.0211, -0.0043],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight': tensor([0.3650, 0.7476, 0.0972,  ..., 0.8521, 0.4248, 0.2639],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias': tensor([-0.0482, -0.1315,  0.0198,  ..., -0.1031, -0.0545,  0.0076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight': tensor([[ 0.0026,  0.0065,  0.0155,  ..., -0.0063,  0.0479, -0.0807],
        [ 0.0002, -0.0075,  0.0009,  ..., -0.0009, -0.0030,  0.0036],
        [ 0.0070, -0.0211,  0.0002,  ..., -0.0094,  0.0178, -0.0043],
        ...,
        [ 0.0026, -0.0113,  0.0019,  ..., -0.0057, -0.0008,  0.0038],
        [-0.0059,  0.0099,  0.0010,  ...,  0.0037, -0.0142, -0.0178],
        [ 0.0160,  0.0002,  0.0312,  ..., -0.0003, -0.0056, -0.0220]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias': tensor([-0.1216, -0.6841, -0.5278,  ..., -0.7573, -0.0995, -0.3076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight': tensor([[ 0.0008, -0.0008, -0.0176,  ..., -0.0029, -0.0098, -0.0047],
        [-0.0157,  0.0059,  0.0156,  ...,  0.0064, -0.0005, -0.0058],
        [ 0.0051, -0.0005,  0.0091,  ..., -0.0056, -0.0015,  0.0059],
        ...,
        [ 0.0030, -0.0024,  0.0040,  ...,  0.0014,  0.0002,  0.0047],
        [ 0.0007, -0.0015,  0.0031,  ..., -0.0015,  0.0046, -0.0055],
        [ 0.0299,  0.0036,  0.0020,  ...,  0.0047,  0.0134,  0.0043]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias': tensor([ 0.0244, -0.0645,  0.0788,  ..., -0.0807, -0.1028, -0.0836],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight': tensor([0.4128, 0.9854, 0.1910,  ..., 0.7715, 0.5596, 0.5142],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias': tensor([-0.0198, -0.1075, -0.0195,  ...,  0.0887,  0.1349,  0.0288],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight': tensor([[-0.0085,  0.0006, -0.0289,  ...,  0.0041,  0.0569, -0.0674],
        [-0.0052,  0.0245, -0.0213,  ..., -0.0084,  0.0220, -0.0248],
        [-0.0135, -0.0092,  0.0144,  ...,  0.0162,  0.0298, -0.0357],
        ...,
        [-0.0062,  0.0068,  0.0082,  ...,  0.0119,  0.0132, -0.0033],
        [-0.0083,  0.0247, -0.0094,  ..., -0.0040, -0.0122,  0.0142],
        [-0.0048, -0.0044, -0.0164,  ...,  0.0119, -0.0213, -0.0117]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias': tensor([ 0.0234,  0.0084, -0.0015,  ...,  0.0951,  0.0065,  0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight': tensor([[ 0.0164,  0.0053, -0.0065,  ..., -0.0008,  0.0037, -0.0120],
        [-0.0057, -0.0036, -0.0029,  ..., -0.0013,  0.0026, -0.0108],
        [-0.0081,  0.0057,  0.0067,  ...,  0.0028, -0.0068, -0.0023],
        ...,
        [-0.0249,  0.0121,  0.0107,  ...,  0.0037,  0.0007,  0.0044],
        [ 0.0115,  0.0107,  0.0118,  ...,  0.0015, -0.0038, -0.0073],
        [-0.0073,  0.0032, -0.0060,  ...,  0.0023, -0.0074,  0.0047]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias': tensor([-0.0014, -0.0060,  0.0129,  ...,  0.1081,  0.0069,  0.0455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight': tensor([[-0.0067, -0.0208, -0.0222,  ...,  0.0014,  0.0279, -0.0558],
        [-0.0030,  0.0016, -0.0191,  ...,  0.0001, -0.0169, -0.0034],
        [-0.0079, -0.0049,  0.0074,  ..., -0.0163, -0.0186, -0.0105],
        ...,
        [ 0.0002, -0.0036,  0.0084,  ..., -0.0038,  0.0105, -0.0002],
        [-0.0035, -0.0039, -0.0118,  ..., -0.0067, -0.0292,  0.0361],
        [-0.0044, -0.0008, -0.0187,  ...,  0.0014, -0.0064, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias': tensor([ 0.1927, -0.0745, -0.0890,  ...,  0.6807,  0.7334, -0.5073],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight': tensor([[-2.4796e-02,  3.3035e-03, -5.1379e-05,  ...,  2.5177e-02,
         -2.3010e-02,  1.2245e-02],
        [-2.7504e-03,  1.5330e-04, -1.1650e-02,  ..., -8.4229e-03,
         -4.1389e-03, -6.9275e-03],
        [-1.2238e-02, -7.1983e-03, -1.0323e-02,  ..., -1.6312e-02,
         -5.9547e-03, -1.4572e-03],
        ...,
        [-1.8501e-03,  5.0354e-04, -6.7101e-03,  ..., -7.3471e-03,
         -2.3518e-03, -1.8501e-03],
        [ 5.4131e-03, -4.4937e-03,  1.2329e-02,  ..., -7.1716e-04,
          9.8038e-04,  7.2708e-03],
        [ 1.0040e-02,  6.5422e-03,  9.2163e-03,  ..., -4.5815e-03,
         -1.1330e-03, -2.6169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias': tensor([ 0.0182, -0.0970,  0.0244,  ..., -0.0159, -0.0449, -0.0308],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight': tensor([0.5078, 0.3108, 0.4004,  ..., 1.4219, 0.5015, 0.3591],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias': tensor([-0.0750, -0.0109,  0.0618,  ..., -0.0417,  0.0176, -0.0477],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight': tensor([[-0.0066, -0.0264,  0.0131,  ..., -0.0004,  0.0194, -0.0154],
        [ 0.0097,  0.0090, -0.0017,  ...,  0.0023, -0.0030,  0.0246],
        [-0.0057,  0.0093,  0.0011,  ..., -0.0040,  0.0003,  0.0128],
        ...,
        [ 0.0005, -0.0012, -0.0009,  ...,  0.0011, -0.0034, -0.0059],
        [ 0.0002,  0.0115,  0.0158,  ...,  0.0040,  0.0015,  0.0208],
        [-0.0148,  0.0111, -0.0085,  ...,  0.0049, -0.0076, -0.0022]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias': tensor([-0.2452, -0.3076, -0.4565,  ..., -0.1678, -0.2119, -0.5581],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight': tensor([[ 1.3428e-03, -3.5172e-03,  9.3317e-04,  ..., -5.0354e-03,
          4.3907e-03,  2.0161e-03],
        [ 1.2999e-03, -1.6678e-02, -4.5662e-03,  ..., -4.4584e-04,
          1.3359e-02, -3.9558e-03],
        [-1.8829e-02,  5.2261e-03,  4.7760e-03,  ...,  8.3113e-04,
         -1.8860e-02,  1.0452e-03],
        ...,
        [-7.8201e-03,  8.4305e-04, -2.1601e-04,  ..., -5.6207e-05,
          4.8339e-05,  1.7557e-03],
        [-4.5300e-05, -7.9498e-03, -9.6178e-04,  ...,  3.4180e-03,
         -1.0208e-02,  2.4460e-02],
        [ 6.0883e-03,  3.3398e-03, -3.7789e-04,  ...,  1.5259e-02,
          6.6223e-03,  6.8169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias': tensor([ 0.0453, -0.0798, -0.0027,  ..., -0.0154, -0.1379, -0.0307],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight': tensor([0.6362, 0.5508, 0.3787,  ..., 1.3506, 0.4011, 0.4910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias': tensor([-0.0338, -0.0840, -0.0964,  ..., -0.0491,  0.0855, -0.2158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight': tensor([[ 0.0149, -0.0155, -0.0083,  ...,  0.0066,  0.0086, -0.0173],
        [ 0.0067,  0.0134,  0.0050,  ..., -0.0056, -0.0293, -0.0028],
        [ 0.0041, -0.0027, -0.0011,  ...,  0.0060,  0.0020, -0.0035],
        ...,
        [ 0.0110, -0.0188,  0.0174,  ..., -0.0223,  0.0017, -0.0122],
        [ 0.0165, -0.0201, -0.0204,  ..., -0.0262, -0.0232, -0.0039],
        [ 0.0062, -0.0148,  0.0194,  ...,  0.0090, -0.0007, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias': tensor([-0.0385, -0.0122,  0.0262,  ...,  0.1536,  0.0992, -0.0590],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight': tensor([[ 0.0275, -0.0126, -0.0067,  ...,  0.0002,  0.0201,  0.0163],
        [-0.0074,  0.0475,  0.0058,  ..., -0.0040,  0.0014,  0.0004],
        [-0.0100, -0.0039, -0.0155,  ...,  0.0009, -0.0079,  0.0033],
        ...,
        [ 0.0009,  0.0007,  0.0107,  ...,  0.0007,  0.0007, -0.0059],
        [-0.0008,  0.0147,  0.0066,  ...,  0.0022, -0.0062, -0.0033],
        [-0.0195, -0.0065,  0.0118,  ..., -0.0030,  0.0058,  0.0028]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias': tensor([ 0.0095, -0.0516,  0.0111,  ..., -0.0145,  0.0041,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight': tensor([[ 2.7618e-02,  1.0513e-02,  4.2725e-03,  ...,  6.3095e-03,
         -8.5907e-03, -1.3008e-02],
        [ 2.4605e-03,  1.8875e-02, -3.9787e-03,  ..., -5.7335e-03,
         -2.1698e-02,  5.3406e-03],
        [-5.1880e-04, -1.0147e-02, -1.0471e-03,  ...,  1.0002e-02,
          1.0025e-02, -1.6159e-02],
        ...,
        [ 1.4210e-03, -1.6434e-02,  5.2299e-03,  ..., -1.5053e-02,
          1.1284e-02,  1.2054e-03],
        [ 1.5579e-02,  1.5251e-02, -3.5915e-03,  ..., -2.6520e-02,
         -1.4130e-02, -7.7133e-03],
        [ 1.0399e-02, -2.2491e-02,  3.2783e-06,  ...,  8.3542e-03,
         -6.7215e-03,  1.6525e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias': tensor([-0.1852, -0.5479, -0.1450,  ..., -0.9072, -0.3499, -0.3457],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight': tensor([[-2.1683e-02,  2.3556e-03, -1.9245e-03,  ..., -9.4910e-03,
          1.6251e-02,  1.2527e-02],
        [ 6.4430e-03, -3.8055e-02, -3.1567e-03,  ..., -2.6455e-03,
         -2.1515e-02,  1.1864e-02],
        [ 5.2147e-03, -8.5602e-03,  1.5732e-02,  ..., -1.2611e-02,
          7.3395e-03, -1.2505e-02],
        ...,
        [-1.1325e-04,  3.4676e-03, -1.1169e-02,  ..., -1.0071e-02,
         -5.4538e-05, -1.7357e-03],
        [-6.8245e-03, -1.0139e-02,  1.4579e-04,  ...,  2.0309e-02,
          1.3527e-02, -3.0098e-03],
        [-1.7868e-02,  6.0368e-04, -6.7101e-03,  ...,  6.6853e-04,
         -3.0327e-03,  3.0651e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias': tensor([-0.0147, -0.0586,  0.0197,  ...,  0.0204, -0.1210,  0.0171],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight': tensor([0.7456, 0.3557, 0.6133,  ..., 2.2637, 0.5059, 0.3938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias': tensor([-0.0006,  0.0249,  0.0189,  ..., -0.1539, -0.0345,  0.0151],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight': tensor([[ 0.0034,  0.0025,  0.0007,  ..., -0.0021, -0.0065,  0.0058],
        [ 0.0011, -0.0024, -0.0028,  ..., -0.0094, -0.0078, -0.0065],
        [-0.0051, -0.0246, -0.0075,  ..., -0.0073,  0.0121,  0.0036],
        ...,
        [ 0.0077,  0.0038, -0.0011,  ..., -0.0060, -0.0017,  0.0005],
        [-0.0208, -0.0176, -0.0064,  ..., -0.0076, -0.0137, -0.0056],
        [-0.0240,  0.0082, -0.0047,  ..., -0.0105, -0.0069, -0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias': tensor([-0.0952, -0.1888, -0.1597,  ..., -0.2030, -0.3225, -0.3745],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight': tensor([[ 0.0074, -0.0074,  0.0041,  ...,  0.0181,  0.0235,  0.0145],
        [ 0.0106,  0.0015, -0.0078,  ..., -0.0323, -0.0017,  0.0073],
        [-0.0059, -0.0090, -0.0087,  ...,  0.0023,  0.0091,  0.0240],
        ...,
        [ 0.0054,  0.0013, -0.0012,  ..., -0.0047, -0.0021, -0.0053],
        [-0.0028,  0.0165,  0.0051,  ...,  0.0006, -0.0043, -0.0041],
        [-0.0045,  0.0066,  0.0154,  ..., -0.0027,  0.0146, -0.0076]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias': tensor([ 0.0139, -0.0796,  0.0050,  ...,  0.0715, -0.1787,  0.0414],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight': tensor([0.9761, 0.5317, 0.6523,  ..., 0.0116, 0.5054, 0.5391],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias': tensor([ 0.0585,  0.0282,  0.0207,  ...,  0.3896, -0.0784, -0.1201],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight': tensor([[ 2.0187e-02,  9.6970e-03,  1.7242e-02,  ..., -2.5925e-02,
         -1.5945e-02,  6.4671e-05],
        [ 1.0201e-02, -7.3357e-03,  3.3722e-02,  ...,  8.9111e-03,
         -3.2410e-02,  5.5122e-03],
        [ 9.6817e-03, -2.4231e-02,  5.7907e-03,  ...,  4.0955e-02,
          2.2415e-02, -1.8143e-02],
        ...,
        [-2.4857e-02, -2.5803e-02, -3.2673e-03,  ..., -1.3596e-02,
          3.6240e-03, -5.7650e-04],
        [-6.4754e-04,  2.4719e-02, -3.0411e-02,  ..., -1.3008e-02,
          5.0879e-04, -1.9455e-02],
        [ 1.7380e-02, -2.3804e-02,  1.2428e-02,  ..., -4.4670e-03,
         -4.2297e-02,  9.2545e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias': tensor([-0.0362, -0.0177,  0.0258,  ...,  0.0230,  0.0147,  0.0451],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight': tensor([[-0.0050,  0.0089,  0.0017,  ..., -0.0001, -0.0173, -0.0087],
        [ 0.0064, -0.0170,  0.0071,  ..., -0.0039,  0.0387, -0.0100],
        [-0.0151,  0.0005, -0.0012,  ..., -0.0011, -0.0048,  0.0012],
        ...,
        [ 0.0129, -0.0303, -0.0177,  ...,  0.0005,  0.0013,  0.0006],
        [ 0.0157,  0.0140, -0.0101,  ...,  0.0011,  0.0336, -0.0216],
        [ 0.0171, -0.0183, -0.0061,  ...,  0.0016, -0.0197, -0.0110]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias': tensor([ 0.0241, -0.0481, -0.0028,  ...,  0.0268,  0.0064, -0.0023],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight': tensor([[ 0.0075,  0.0013, -0.0144,  ..., -0.0114, -0.0454, -0.0086],
        [-0.0035, -0.0501,  0.0037,  ..., -0.0065, -0.0287,  0.0070],
        [ 0.0061, -0.0005,  0.0146,  ...,  0.0271,  0.0069, -0.0366],
        ...,
        [-0.0107,  0.0089, -0.0109,  ..., -0.0074, -0.0206, -0.0009],
        [-0.0004, -0.0072, -0.0339,  ..., -0.0124, -0.0053, -0.0094],
        [ 0.0051, -0.0136, -0.0062,  ..., -0.0015, -0.0242, -0.0031]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias': tensor([-0.4634, -0.0086,  0.2761,  ..., -0.2158, -0.2346, -0.2240],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight': tensor([[-2.6817e-03, -4.3983e-03,  1.3580e-03,  ..., -2.4681e-03,
         -1.6296e-02, -1.9119e-02],
        [-6.3057e-03,  1.3931e-02,  2.0657e-03,  ...,  2.4063e-02,
         -2.3544e-02,  2.3361e-02],
        [ 4.4098e-03,  2.9049e-03,  3.0816e-05,  ...,  1.9028e-02,
          1.2093e-02,  9.4528e-03],
        ...,
        [-6.3095e-03,  7.6141e-03, -4.4861e-03,  ..., -6.6261e-03,
         -6.6795e-03, -3.0851e-04],
        [ 1.7075e-02, -3.9612e-02,  9.1248e-03,  ...,  1.1742e-02,
         -3.6469e-02,  2.8046e-02],
        [ 8.2626e-03,  1.3752e-03, -1.0185e-02,  ...,  6.5994e-04,
          1.5320e-02,  1.1871e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias': tensor([ 0.0089, -0.0782,  0.0222,  ..., -0.0115, -0.1763,  0.0233],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight': tensor([0.7534, 0.5015, 0.7891,  ..., 1.1660, 0.6074, 0.5796],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias': tensor([ 0.0149, -0.0122,  0.0052,  ..., -0.1028,  0.0337, -0.0357],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight': tensor([[ 0.0072, -0.0114, -0.0013,  ..., -0.0066,  0.0127,  0.0151],
        [-0.0095,  0.0185,  0.0141,  ..., -0.0075,  0.0141,  0.0101],
        [-0.0018,  0.0118,  0.0032,  ..., -0.0046,  0.0148,  0.0008],
        ...,
        [ 0.0204,  0.0075,  0.0235,  ..., -0.0079,  0.0030, -0.0164],
        [ 0.0157, -0.0033, -0.0008,  ..., -0.0085,  0.0043, -0.0139],
        [-0.0009, -0.0003,  0.0257,  ..., -0.0072, -0.0059, -0.0217]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias': tensor([-0.2440, -0.3796, -0.5205,  ..., -0.2163, -0.4248, -0.2197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight': tensor([[-1.6296e-02,  6.4087e-03, -1.4839e-03,  ..., -2.2827e-02,
          1.9302e-02,  1.6346e-03],
        [ 5.0888e-03, -1.3763e-02,  5.1537e-03,  ..., -1.9989e-02,
         -2.7637e-03, -1.0567e-02],
        [ 2.8763e-03, -5.1460e-03, -5.6326e-05,  ..., -7.1030e-03,
         -9.8724e-03, -2.3098e-03],
        ...,
        [-5.3024e-03, -2.0905e-03,  2.9635e-04,  ..., -5.4092e-03,
          2.0993e-04,  2.4395e-03],
        [-9.9411e-03, -1.4748e-02, -2.4283e-04,  ...,  1.8127e-02,
          3.3779e-03,  2.1927e-02],
        [-5.7182e-03,  1.5316e-03,  1.1997e-03,  ...,  2.5387e-03,
         -5.6725e-03,  4.6387e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias': tensor([-0.0155, -0.0524, -0.0402,  ...,  0.1025, -0.1437, -0.0174],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight': tensor([1.1230, 0.5190, 1.0762,  ..., 0.0112, 0.6738, 0.7544],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias': tensor([ 0.0829, -0.0929, -0.0049,  ...,  0.1129, -0.0392, -0.0677],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight': tensor([[ 0.0035, -0.0081,  0.0270,  ..., -0.0032,  0.0041,  0.0172],
        [-0.0174,  0.0256,  0.0060,  ..., -0.0001,  0.0052, -0.0038],
        [ 0.0038,  0.0144, -0.0161,  ..., -0.0028,  0.0033,  0.0003],
        ...,
        [-0.0023, -0.0123, -0.0080,  ...,  0.0256,  0.0213, -0.0097],
        [-0.0147,  0.0030,  0.0045,  ...,  0.0211,  0.0161, -0.0218],
        [-0.0035,  0.0147,  0.0030,  ..., -0.0244, -0.0005, -0.0255]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias': tensor([-0.0187, -0.0076,  0.0053,  ...,  0.0369,  0.0955,  0.0978],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight': tensor([[-0.0090,  0.0047, -0.0008,  ..., -0.0064, -0.0025, -0.0247],
        [-0.0128, -0.0091,  0.0087,  ...,  0.0024, -0.0012,  0.0007],
        [ 0.0101, -0.0021, -0.0005,  ...,  0.0017,  0.0007, -0.0170],
        ...,
        [-0.0120,  0.0108,  0.0011,  ..., -0.0008, -0.0032,  0.0003],
        [-0.0157, -0.0033,  0.0135,  ..., -0.0007, -0.0310, -0.0129],
        [ 0.0124, -0.0001,  0.0213,  ..., -0.0014, -0.0043, -0.0239]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias': tensor([-0.0186, -0.0071, -0.0258,  ..., -0.0043, -0.0113, -0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight': tensor([[-1.7075e-02,  3.0457e-02,  8.3542e-03,  ..., -8.0032e-03,
          1.6724e-02, -1.0490e-02],
        [-1.2169e-02,  8.2474e-03, -4.2725e-03,  ..., -9.4366e-04,
         -4.9591e-03, -1.0300e-02],
        [ 1.0185e-03, -1.2466e-02, -3.0880e-03,  ..., -3.4428e-03,
         -1.3107e-02,  6.5384e-03],
        ...,
        [ 1.5793e-02,  2.0809e-03,  1.9424e-02,  ...,  2.6367e-02,
          1.0529e-02, -2.1439e-02],
        [-5.6992e-03,  4.1580e-04,  3.8116e-02,  ...,  1.6739e-02,
         -9.0103e-03, -1.6327e-02],
        [ 2.8789e-05, -9.8114e-03,  1.0004e-03,  ..., -2.2293e-02,
         -3.0365e-02,  6.1569e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias': tensor([-0.0072, -1.4619,  0.3447,  ..., -0.6147, -0.3474, -0.6455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight': tensor([[ 5.2567e-03,  1.1238e-02, -6.8092e-03,  ..., -8.0013e-04,
          1.5930e-02, -1.4336e-02],
        [-6.6223e-03,  1.9255e-03, -1.6006e-02,  ..., -2.0706e-02,
         -1.1848e-02, -1.1147e-02],
        [ 2.3087e-02,  1.1986e-02, -1.7288e-02,  ...,  5.7144e-03,
          1.4824e-02, -1.6876e-02],
        ...,
        [ 1.6647e-02,  5.3596e-03, -1.5154e-03,  ..., -2.9736e-03,
          1.8129e-03,  1.0559e-02],
        [ 4.1847e-03,  8.3694e-03,  1.2535e-02,  ..., -1.0323e-02,
          1.6327e-02, -3.2544e-05],
        [ 1.0185e-03, -2.1400e-03, -4.4098e-03,  ..., -4.6120e-03,
          6.0921e-03,  1.5152e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias': tensor([-0.0087, -0.0482, -0.0096,  ..., -0.0479, -0.1366,  0.0062],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight': tensor([0.8506, 0.6484, 0.8960,  ..., 1.2539, 0.7212, 0.8564],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias': tensor([-0.0077,  0.0670, -0.0532,  ..., -0.1699, -0.0490,  0.0434],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight': tensor([[ 0.0058,  0.0115,  0.0089,  ..., -0.0020, -0.0053,  0.0026],
        [-0.0017, -0.0024,  0.0162,  ...,  0.0009, -0.0208, -0.0094],
        [-0.0388, -0.0012, -0.0004,  ...,  0.0032, -0.0029, -0.0226],
        ...,
        [ 0.0085,  0.0130,  0.0209,  ..., -0.0057, -0.0040, -0.0012],
        [ 0.0260,  0.0055,  0.0095,  ..., -0.0008,  0.0056, -0.0098],
        [ 0.0116,  0.0073, -0.0117,  ...,  0.0011, -0.0095, -0.0163]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias': tensor([-0.4192, -0.2394, -0.3069,  ..., -0.3667, -0.2563, -0.1315],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight': tensor([[ 0.0154, -0.0020, -0.0083,  ...,  0.0161, -0.0060,  0.0146],
        [ 0.0042,  0.0226,  0.0055,  ...,  0.0110,  0.0033,  0.0034],
        [ 0.0140, -0.0083,  0.0006,  ...,  0.0085,  0.0010,  0.0007],
        ...,
        [-0.0025, -0.0010, -0.0020,  ...,  0.0007, -0.0030, -0.0018],
        [-0.0141, -0.0032, -0.0003,  ...,  0.0106, -0.0021, -0.0400],
        [ 0.0069,  0.0051, -0.0135,  ..., -0.0115,  0.0067, -0.0104]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias': tensor([-0.0416,  0.0127, -0.0229,  ...,  0.0723, -0.0145, -0.0363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight': tensor([1.1514, 0.7275, 1.1299,  ..., 1.0918, 0.8794, 1.1055],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias': tensor([ 0.0418, -0.1718, -0.0305,  ...,  0.0424, -0.2144, -0.0068],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight': tensor([[ 0.0195, -0.0016, -0.0010,  ...,  0.1302, -0.0123, -0.0063],
        [-0.0176,  0.0024, -0.0196,  ..., -0.1481, -0.0101, -0.0231],
        [-0.0042, -0.0077,  0.0033,  ...,  0.0850, -0.0172,  0.0256],
        ...,
        [ 0.0024, -0.0123,  0.0282,  ..., -0.0123,  0.0272,  0.0247],
        [ 0.0084, -0.0235,  0.0189,  ...,  0.0040, -0.0171,  0.0120],
        [ 0.0308, -0.0003,  0.0095,  ..., -0.0054, -0.0117, -0.0379]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias': tensor([-0.0049,  0.0073,  0.0145,  ...,  0.0185, -0.0033,  0.0204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight': tensor([[ 0.0096,  0.0166, -0.0025,  ..., -0.0005,  0.0005,  0.0034],
        [ 0.0066,  0.0109, -0.0074,  ...,  0.0010,  0.0079, -0.0095],
        [-0.0074, -0.0047,  0.0016,  ...,  0.0002,  0.0039,  0.0040],
        ...,
        [-0.0159,  0.0166, -0.0176,  ...,  0.0020, -0.0064,  0.0302],
        [ 0.0316, -0.0076, -0.0238,  ..., -0.0002, -0.0032, -0.0157],
        [-0.0096, -0.0192,  0.0207,  ..., -0.0009, -0.0289, -0.0082]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias': tensor([ 0.0264, -0.0288,  0.0074,  ...,  0.0075, -0.0047,  0.0190],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight': tensor([[ 0.0136, -0.0235, -0.0059,  ...,  0.0935,  0.0115, -0.0124],
        [-0.0146, -0.0224,  0.0003,  ..., -0.1112, -0.0056, -0.0134],
        [-0.0018,  0.0100,  0.0052,  ...,  0.0525,  0.0120,  0.0163],
        ...,
        [ 0.0338,  0.0004,  0.0047,  ..., -0.0146,  0.0189, -0.0173],
        [ 0.0022, -0.0096, -0.0040,  ...,  0.0011, -0.0013,  0.0135],
        [ 0.0178,  0.0135,  0.0019,  ..., -0.0075,  0.0044, -0.0363]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias': tensor([ 0.2430,  0.3418, -0.1379,  ...,  0.0247,  1.4775,  0.2130],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight': tensor([[-0.0026,  0.0052,  0.0064,  ...,  0.0172, -0.0226,  0.0066],
        [-0.0029,  0.0043, -0.0091,  ..., -0.0054, -0.0009,  0.0137],
        [-0.0161,  0.0021,  0.0049,  ...,  0.0088,  0.0251, -0.0076],
        ...,
        [ 0.0092,  0.0003, -0.0009,  ..., -0.0040,  0.0036,  0.0044],
        [ 0.0016, -0.0087,  0.0108,  ..., -0.0028, -0.0046,  0.0207],
        [ 0.0181, -0.0077, -0.0030,  ..., -0.0368, -0.0015,  0.0158]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias': tensor([-0.0217,  0.0017,  0.0176,  ...,  0.0564, -0.0415, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight': tensor([0.8926, 0.8076, 1.0293,  ..., 2.0488, 0.9590, 0.9756],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias': tensor([-0.1279, -0.0777, -0.0509,  ..., -0.2275, -0.0558,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight': tensor([[ 0.0265,  0.0048,  0.0027,  ..., -0.0071,  0.0051,  0.0187],
        [ 0.0004,  0.0177,  0.0098,  ..., -0.0020, -0.0084,  0.0181],
        [-0.0045,  0.0070, -0.0007,  ..., -0.0080, -0.0070, -0.0316],
        ...,
        [-0.0285,  0.0282,  0.0047,  ...,  0.0006, -0.0079,  0.0194],
        [-0.0049, -0.0312, -0.0060,  ..., -0.0043,  0.0310, -0.0003],
        [ 0.0185,  0.0199,  0.0079,  ..., -0.0067, -0.0297, -0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias': tensor([-0.1132, -0.1494, -0.4023,  ..., -0.2355, -0.3335, -0.2045],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight': tensor([[-0.0180,  0.0037,  0.0069,  ..., -0.0019, -0.0086, -0.0024],
        [-0.0006, -0.0030, -0.0042,  ..., -0.0177,  0.0375, -0.0014],
        [-0.0129, -0.0050, -0.0065,  ...,  0.0015, -0.0005, -0.0149],
        ...,
        [ 0.0031,  0.0014, -0.0087,  ..., -0.0003,  0.0073,  0.0014],
        [ 0.0105,  0.0060,  0.0064,  ..., -0.0005, -0.0007,  0.0372],
        [-0.0087, -0.0052,  0.0026,  ..., -0.0113, -0.0085,  0.0098]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias': tensor([-0.0068,  0.0179, -0.0552,  ...,  0.1210, -0.0750, -0.1090],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight': tensor([1.1914, 0.9712, 1.2656,  ..., 0.1719, 0.9092, 1.1973],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias': tensor([-0.0956, -0.1851, -0.0547,  ...,  0.2583, -0.0542,  0.0387],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight': tensor([[ 0.0076, -0.0117, -0.0114,  ...,  0.0770, -0.0048, -0.0017],
        [-0.0195, -0.0001, -0.0053,  ...,  0.0370, -0.0298,  0.0023],
        [-0.0094, -0.0034,  0.0132,  ...,  0.0014,  0.0088, -0.0013],
        ...,
        [ 0.0047, -0.0200, -0.0213,  ..., -0.0028, -0.0125, -0.0193],
        [-0.0028,  0.0018, -0.0313,  ..., -0.0143, -0.0024,  0.0085],
        [-0.0081, -0.0074,  0.0052,  ..., -0.0006, -0.0049, -0.0085]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias': tensor([ 0.0311, -0.0070, -0.0134,  ...,  0.0024, -0.0121, -0.0230],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight': tensor([[ 0.0104, -0.0064, -0.0062,  ...,  0.0015,  0.0052, -0.0058],
        [ 0.0179, -0.0065, -0.0221,  ..., -0.0002, -0.0032, -0.0219],
        [-0.0078,  0.0084, -0.0027,  ..., -0.0003,  0.0120,  0.0011],
        ...,
        [-0.0272, -0.0105,  0.0010,  ..., -0.0082,  0.0024,  0.0062],
        [ 0.0284, -0.0029, -0.0178,  ..., -0.0007, -0.0008, -0.0054],
        [-0.0113,  0.0083,  0.0034,  ..., -0.0102,  0.0250,  0.0115]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias': tensor([ 0.0282,  0.0175, -0.0284,  ...,  0.0397, -0.0209, -0.1344],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight': tensor([[ 0.0094, -0.0159, -0.0203,  ...,  0.0367, -0.0055, -0.0276],
        [ 0.0029, -0.0178, -0.0045,  ..., -0.0709, -0.0047, -0.0184],
        [-0.0128,  0.0083,  0.0116,  ..., -0.0014,  0.0039,  0.0124],
        ...,
        [-0.0292,  0.0131, -0.0025,  ...,  0.0003, -0.0127, -0.0156],
        [-0.0237,  0.0121, -0.0025,  ..., -0.0010,  0.0081, -0.0145],
        [ 0.0137,  0.0139,  0.0163,  ...,  0.0071,  0.0116, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias': tensor([-1.8535,  0.1802,  2.3398,  ..., -0.0595, -0.0338,  0.0305],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight': tensor([[ 0.0028, -0.0249,  0.0077,  ...,  0.0163, -0.0069, -0.0036],
        [ 0.0140, -0.0086,  0.0026,  ...,  0.0077,  0.0073, -0.0239],
        [ 0.0044,  0.0041, -0.0237,  ..., -0.0202, -0.0074,  0.0211],
        ...,
        [-0.0025,  0.0102, -0.0030,  ...,  0.0096,  0.0018,  0.0186],
        [ 0.0052, -0.0034,  0.0046,  ..., -0.0001,  0.0089, -0.0238],
        [-0.0090,  0.0134,  0.0052,  ..., -0.0156, -0.0131,  0.0157]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias': tensor([ 0.0039,  0.0259, -0.0086,  ..., -0.0503, -0.0064, -0.0460],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight': tensor([1.1934, 1.1006, 1.2510,  ..., 1.4092, 1.1592, 1.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias': tensor([ 0.0223, -0.0916,  0.0971,  ..., -0.2983, -0.0408,  0.0070],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight': tensor([[-0.0150,  0.0078,  0.0025,  ..., -0.0011, -0.0016,  0.0092],
        [-0.0219,  0.0313,  0.0128,  ...,  0.0032,  0.0150,  0.0033],
        [-0.0176, -0.0190,  0.0216,  ...,  0.0038, -0.0361,  0.0145],
        ...,
        [ 0.0060, -0.0061, -0.0066,  ...,  0.0027, -0.0050, -0.0172],
        [-0.0283, -0.0057,  0.0115,  ..., -0.0054, -0.0136, -0.0057],
        [-0.0160,  0.0153, -0.0277,  ..., -0.0289, -0.0194,  0.0007]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias': tensor([-0.1221, -0.2144, -0.4114,  ..., -0.1118, -0.1782, -0.3628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight': tensor([[-0.0016,  0.0125, -0.0344,  ..., -0.0221,  0.0044, -0.0154],
        [-0.0039, -0.0351,  0.0205,  ...,  0.0108, -0.0206, -0.0023],
        [ 0.0063, -0.0273, -0.0012,  ...,  0.0131,  0.0057, -0.0150],
        ...,
        [-0.0002, -0.0069,  0.0022,  ..., -0.0065,  0.0032,  0.0088],
        [ 0.0108, -0.0061, -0.0134,  ..., -0.0061,  0.0058, -0.0083],
        [ 0.0133,  0.0173,  0.0049,  ...,  0.0188, -0.0199, -0.0074]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias': tensor([-0.0200,  0.0232, -0.0657,  ...,  0.1028, -0.0782, -0.1134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight': tensor([1.2578, 1.1084, 1.2061,  ..., 0.5884, 1.0264, 1.2910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias': tensor([-0.0061, -0.0651,  0.0878,  ...,  0.1716,  0.1021, -0.0355],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight': tensor([[-0.0184, -0.0017,  0.0284,  ..., -0.0922, -0.0121,  0.0085],
        [ 0.0216,  0.0109,  0.0091,  ..., -0.0531,  0.0165, -0.0052],
        [-0.0036,  0.0282,  0.0128,  ...,  0.0421, -0.0305, -0.0203],
        ...,
        [-0.0003, -0.0044, -0.0082,  ..., -0.0171,  0.0052,  0.0071],
        [ 0.0136, -0.0294, -0.0073,  ..., -0.0191, -0.0179,  0.0170],
        [-0.0079,  0.0298, -0.0092,  ...,  0.0071,  0.0015,  0.0033]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias': tensor([-0.0044, -0.0038, -0.0472,  ...,  0.0818,  0.0363, -0.0465],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight': tensor([[ 1.9028e-02,  3.3264e-03, -1.4641e-02,  ..., -4.6754e-04,
         -1.4366e-02,  1.6556e-02],
        [ 2.1267e-04, -1.5457e-02, -3.2166e-02,  ..., -2.4629e-04,
          5.9090e-03, -9.8267e-03],
        [-1.2535e-02, -1.2222e-02,  9.6970e-03,  ...,  1.7128e-03,
         -2.1992e-03,  3.7842e-03],
        ...,
        [ 1.0918e-02,  1.8097e-02,  1.2695e-02,  ...,  4.8494e-04,
          5.1918e-03, -1.9058e-02],
        [ 9.9792e-03, -1.2085e-02,  6.0320e-04,  ...,  3.4790e-03,
          1.0284e-02,  2.8300e-04],
        [ 2.2034e-02, -1.5373e-03, -2.1362e-02,  ...,  4.9706e-03,
         -4.9174e-05, -6.5117e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias': tensor([ 0.0094,  0.0439, -0.0031,  ..., -0.0485, -0.1193,  0.0170],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight': tensor([[-1.2352e-02,  2.3239e-02,  5.5618e-03,  ..., -5.1178e-02,
         -2.8687e-02,  2.2531e-05],
        [-1.0605e-02, -2.5497e-02,  1.1894e-02,  ..., -2.0462e-02,
         -8.5449e-04,  4.6265e-02],
        [ 8.6212e-03, -9.3765e-03,  5.9357e-03,  ...,  2.0432e-02,
         -2.2537e-02,  4.4495e-02],
        ...,
        [ 1.3062e-02, -5.5428e-03,  1.0025e-02,  ..., -4.5746e-02,
          6.3477e-03,  2.0248e-02],
        [ 9.6588e-03, -1.4442e-02, -2.0096e-02,  ...,  6.9542e-03,
          5.9013e-03, -3.3588e-03],
        [-5.3177e-03,  2.2705e-02, -2.1713e-02,  ...,  2.4307e-02,
          1.5465e-02, -8.3237e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias': tensor([ 0.0542, -0.0733,  0.2440,  ..., -0.3313, -0.1129,  0.1049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight': tensor([[-0.0227,  0.0130, -0.0113,  ..., -0.0045,  0.0108, -0.0190],
        [-0.0057, -0.0069,  0.0119,  ..., -0.0068,  0.0143,  0.0030],
        [ 0.0062,  0.0204,  0.0161,  ..., -0.0079, -0.0057,  0.0308],
        ...,
        [ 0.0001,  0.0003,  0.0048,  ...,  0.0089, -0.0032,  0.0210],
        [-0.0079,  0.0007,  0.0030,  ...,  0.0093, -0.0068, -0.0121],
        [-0.0154,  0.0158, -0.0231,  ..., -0.0158,  0.0141, -0.0072]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias': tensor([-0.0179,  0.0685, -0.0152,  ..., -0.0815,  0.0257,  0.0175],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight': tensor([1.1738, 1.1582, 1.1592,  ..., 1.5869, 1.1748, 1.2314],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias': tensor([-0.0068,  0.0917, -0.0354,  ..., -0.3271, -0.1141, -0.0543],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight': tensor([[-0.0195, -0.0128, -0.0054,  ..., -0.0029, -0.0047,  0.0116],
        [-0.0031, -0.0199,  0.0011,  ..., -0.0044,  0.0127,  0.0019],
        [ 0.0130, -0.0056,  0.0037,  ..., -0.0005,  0.0237,  0.0081],
        ...,
        [ 0.0115,  0.0130, -0.0272,  ...,  0.0021,  0.0227,  0.0057],
        [-0.0035,  0.0108, -0.0211,  ..., -0.0011,  0.0154, -0.0001],
        [-0.0336,  0.0183,  0.0121,  ..., -0.0012, -0.0093,  0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias': tensor([-0.3628, -0.2211, -0.1648,  ..., -0.2524, -0.2686, -0.2517],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight': tensor([[-4.5166e-03,  7.6828e-03,  1.3664e-02,  ..., -2.5959e-03,
         -2.0126e-02, -7.1602e-03],
        [-1.4015e-02,  2.0084e-03,  6.2370e-03,  ...,  1.9714e-02,
         -4.8294e-03, -2.3682e-02],
        [-4.3793e-03,  6.3400e-03,  5.3253e-03,  ...,  9.2888e-04,
          7.6599e-03, -1.8555e-02],
        ...,
        [-4.1809e-03, -1.8768e-03,  4.0741e-03,  ..., -1.5802e-03,
         -3.6144e-03,  8.3983e-05],
        [-2.7523e-03, -2.6489e-02, -1.3283e-02,  ...,  3.4904e-03,
         -1.4786e-02,  6.2981e-03],
        [-3.0880e-03, -2.1713e-02, -1.7853e-02,  ...,  1.1139e-02,
          7.2784e-03, -1.2558e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias': tensor([-0.0283,  0.0284, -0.0329,  ...,  0.0671, -0.0050, -0.0488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight': tensor([1.2725, 1.2539, 1.2041,  ..., 0.7529, 1.0645, 1.2422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias': tensor([ 0.0019, -0.0140,  0.0246,  ...,  0.2150, -0.1251, -0.2118],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0117,  0.0046,  ..., -0.0265, -0.0033,  0.0070],
        [ 0.0061,  0.0207, -0.0110,  ...,  0.0132,  0.0091,  0.0226],
        [-0.0012,  0.0130,  0.0031,  ...,  0.0025,  0.0157,  0.0028],
        ...,
        [ 0.0178,  0.0099,  0.0200,  ...,  0.0006, -0.0303, -0.0324],
        [-0.0035,  0.0138,  0.0245,  ..., -0.0032, -0.0065,  0.0055],
        [-0.0023,  0.0024, -0.0018,  ...,  0.0053,  0.0023, -0.0070]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias': tensor([ 0.1105, -0.0046,  0.0618,  ...,  0.0103, -0.0147,  0.0179],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight': tensor([[ 0.0128, -0.0147,  0.0370,  ..., -0.0059,  0.0019, -0.0157],
        [-0.0200,  0.0040, -0.0021,  ..., -0.0084, -0.0056, -0.0079],
        [-0.0030, -0.0037, -0.0301,  ..., -0.0076,  0.0190,  0.0188],
        ...,
        [ 0.0036,  0.0197, -0.0007,  ..., -0.0078,  0.0181, -0.0004],
        [-0.0112,  0.0034, -0.0117,  ...,  0.0041, -0.0017, -0.0116],
        [-0.0199,  0.0032, -0.0224,  ..., -0.0046,  0.0289,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias': tensor([-0.0085, -0.0267, -0.0139,  ..., -0.0130,  0.0113,  0.0014],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight': tensor([[-5.2223e-03, -1.1261e-02,  2.0859e-02,  ..., -3.4424e-02,
          5.4245e-03,  3.5515e-03],
        [ 2.7637e-03,  4.4861e-03,  5.6877e-03,  ...,  6.7830e-05,
         -1.3123e-02,  1.6266e-02],
        [-7.9575e-03,  6.3133e-03,  1.7059e-02,  ...,  2.5711e-03,
         -5.4283e-03, -1.0437e-02],
        ...,
        [-1.2264e-03,  2.9633e-02, -8.0185e-03,  ...,  1.4366e-02,
          2.8824e-02, -1.8001e-05],
        [ 5.7316e-04,  8.2397e-03,  1.8951e-02,  ...,  1.4248e-03,
          1.8433e-02, -1.7624e-02],
        [ 6.5842e-03,  2.7451e-02, -1.9012e-02,  ...,  1.1887e-02,
         -7.3357e-03,  1.1284e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias': tensor([-0.8462,  0.0103, -1.0879,  ..., -0.1941,  0.1663, -1.2803],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight': tensor([[-0.0020,  0.0252,  0.0039,  ...,  0.0061, -0.0123,  0.0283],
        [ 0.0043,  0.0004, -0.0082,  ..., -0.0251,  0.0068,  0.0017],
        [-0.0231,  0.0006,  0.0164,  ...,  0.0248,  0.0101,  0.0125],
        ...,
        [ 0.0080,  0.0312,  0.0238,  ...,  0.0045,  0.0003,  0.0054],
        [ 0.0077,  0.0073, -0.0009,  ..., -0.0016,  0.0038, -0.0133],
        [ 0.0194, -0.0053, -0.0238,  ...,  0.0249, -0.0041,  0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias': tensor([-0.0205,  0.0181, -0.0017,  ..., -0.0779,  0.0408, -0.0200],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight': tensor([1.1533, 1.2090, 1.1787,  ..., 1.6367, 1.1729, 1.2188],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias': tensor([-0.0550,  0.0990, -0.0018,  ..., -0.1779, -0.0518, -0.0147],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight': tensor([[-0.0073, -0.0223,  0.0130,  ..., -0.0079, -0.0028,  0.0022],
        [-0.0071,  0.0068,  0.0017,  ..., -0.0123, -0.0179, -0.0108],
        [ 0.0072,  0.0217,  0.0110,  ...,  0.0060,  0.0005,  0.0016],
        ...,
        [ 0.0225, -0.0085,  0.0064,  ...,  0.0007,  0.0014, -0.0003],
        [-0.0191,  0.0245,  0.0085,  ..., -0.0102, -0.0108, -0.0063],
        [ 0.0290, -0.0322, -0.0287,  ..., -0.0045,  0.0156, -0.0153]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias': tensor([-0.4795, -0.1469, -0.1043,  ..., -0.2998, -0.2252, -0.3262],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight': tensor([[-0.0205,  0.0170, -0.0019,  ...,  0.0084,  0.0040,  0.0268],
        [ 0.0060,  0.0025, -0.0069,  ...,  0.0071, -0.0261,  0.0028],
        [ 0.0291, -0.0064, -0.0019,  ..., -0.0131,  0.0078, -0.0294],
        ...,
        [-0.0110,  0.0011, -0.0081,  ..., -0.0030,  0.0036, -0.0003],
        [-0.0195,  0.0083,  0.0063,  ...,  0.0095, -0.0105,  0.0214],
        [-0.0028,  0.0316,  0.0016,  ..., -0.0094, -0.0051,  0.0145]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias': tensor([ 0.0411, -0.0040, -0.0517,  ...,  0.1116,  0.0086, -0.0608],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight': tensor([1.3838, 1.2871, 1.2334,  ..., 0.6108, 1.1768, 1.2568],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias': tensor([-0.2367,  0.0573,  0.1235,  ...,  0.2408,  0.0240, -0.0257],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight': tensor([[-0.0176,  0.0033,  0.0183,  ..., -0.0038,  0.0074,  0.0088],
        [-0.0091,  0.0276, -0.0216,  ...,  0.0220,  0.0110,  0.0020],
        [-0.0428, -0.0160,  0.0246,  ...,  0.0130, -0.0163, -0.0116],
        ...,
        [ 0.0326,  0.0183, -0.0093,  ...,  0.0212, -0.0169,  0.0020],
        [ 0.0131,  0.0204,  0.0034,  ...,  0.0138,  0.0030,  0.0125],
        [ 0.0216,  0.0034,  0.0112,  ..., -0.0203,  0.0063, -0.0135]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias': tensor([-0.0005,  0.0142, -0.0017,  ...,  0.0816, -0.0667,  0.0688],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight': tensor([[-0.0305, -0.0173,  0.0406,  ...,  0.0054,  0.0093, -0.0001],
        [ 0.0040,  0.0132, -0.0068,  ..., -0.0034, -0.0217, -0.0175],
        [-0.0051,  0.0121, -0.0121,  ..., -0.0104, -0.0141, -0.0050],
        ...,
        [ 0.0016,  0.0205, -0.0056,  ..., -0.0040, -0.0046,  0.0020],
        [ 0.0378,  0.0040, -0.0073,  ...,  0.0001, -0.0014,  0.0133],
        [ 0.0088, -0.0021, -0.0040,  ..., -0.0019,  0.0257, -0.0056]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias': tensor([-0.0842, -0.0092,  0.0031,  ...,  0.0677, -0.0071,  0.0129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight': tensor([[ 0.0169, -0.0117, -0.0191,  ...,  0.0101, -0.0038,  0.0100],
        [-0.0080,  0.0092,  0.0094,  ...,  0.0197, -0.0175, -0.0183],
        [-0.0264, -0.0041,  0.0021,  ...,  0.0114,  0.0084, -0.0139],
        ...,
        [-0.0015,  0.0094,  0.0175,  ...,  0.0220, -0.0158,  0.0012],
        [-0.0012,  0.0214, -0.0034,  ...,  0.0166, -0.0191,  0.0039],
        [ 0.0204, -0.0130,  0.0074,  ..., -0.0208,  0.0063, -0.0040]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias': tensor([ 0.0173,  0.2045, -0.1959,  ..., -0.0136, -0.0571, -0.2710],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight': tensor([[ 1.1879e-02, -8.7357e-03, -2.2980e-02,  ..., -5.5885e-03,
         -2.6260e-02,  1.4985e-04],
        [ 2.3117e-02, -1.8127e-02,  2.0111e-02,  ..., -5.3711e-03,
         -3.0880e-03, -2.6855e-03],
        [-7.4577e-03,  5.7449e-03, -2.7313e-02,  ...,  2.7695e-03,
          7.9803e-03,  1.0475e-02],
        ...,
        [-1.1810e-02,  1.0620e-02,  1.4153e-02,  ...,  7.8049e-03,
          7.3671e-04,  2.8267e-03],
        [ 6.1150e-03,  1.5244e-02,  2.3621e-02,  ...,  9.0599e-05,
          2.7008e-03, -3.2196e-02],
        [ 3.8743e-04, -6.6109e-03, -1.4534e-02,  ...,  1.1330e-03,
         -1.8280e-02, -3.4065e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias': tensor([-0.0230,  0.0388, -0.0072,  ..., -0.0651,  0.0296, -0.0002],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight': tensor([1.2031, 1.2344, 1.1543,  ..., 1.5986, 1.2275, 1.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias': tensor([-0.0587,  0.0094, -0.0588,  ..., -0.2544, -0.1669, -0.0670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight': tensor([[-0.0105, -0.0159, -0.0260,  ..., -0.0012,  0.0033,  0.0001],
        [ 0.0232, -0.0237,  0.0074,  ..., -0.0032,  0.0108,  0.0003],
        [ 0.0088,  0.0072,  0.0034,  ...,  0.0001, -0.0065,  0.0012],
        ...,
        [ 0.0007, -0.0093,  0.0181,  ..., -0.0021, -0.0059,  0.0082],
        [ 0.0024,  0.0102, -0.0177,  ..., -0.0005, -0.0069, -0.0302],
        [ 0.0112,  0.0245,  0.0004,  ...,  0.0030, -0.0044,  0.0190]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias': tensor([-0.1327, -0.2241, -0.0568,  ..., -0.2708, -0.3245, -0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight': tensor([[ 1.0185e-02, -1.1162e-02, -2.3911e-02,  ...,  2.9709e-02,
         -1.3023e-02, -1.1803e-02],
        [ 8.2092e-03, -4.3631e-04, -3.1257e-04,  ..., -1.3252e-02,
          5.4598e-05, -1.8997e-02],
        [ 5.5885e-03,  1.8112e-02,  9.0179e-03,  ..., -3.1700e-03,
          8.4686e-03, -3.6144e-03],
        ...,
        [ 4.7798e-03,  3.0174e-03, -3.5143e-04,  ...,  5.4665e-03,
         -3.4122e-03, -4.2953e-03],
        [ 3.2082e-03, -1.4816e-02, -9.4986e-04,  ..., -1.9455e-02,
         -9.8825e-05,  9.9869e-03],
        [-7.2784e-03, -5.8289e-03, -3.9062e-03,  ...,  5.5122e-03,
         -2.4323e-02, -2.7542e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias': tensor([ 0.0389,  0.0069, -0.0129,  ...,  0.0417,  0.0218,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight': tensor([1.4287, 1.3613, 1.2949,  ..., 1.0137, 1.1826, 1.3213],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias': tensor([-0.1137,  0.0275,  0.0679,  ...,  0.1796,  0.0205, -0.2534],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight': tensor([[ 0.0030,  0.0209, -0.0001,  ..., -0.0044,  0.0148,  0.0093],
        [-0.0027, -0.0116,  0.0012,  ...,  0.0060, -0.0152, -0.0084],
        [-0.0064,  0.0066, -0.0148,  ..., -0.0031, -0.0160,  0.0061],
        ...,
        [ 0.0134, -0.0141, -0.0170,  ...,  0.0031, -0.0175,  0.0096],
        [ 0.0032, -0.0072,  0.0027,  ...,  0.0026,  0.0248,  0.0016],
        [ 0.0372, -0.0190,  0.0259,  ..., -0.0076,  0.0134,  0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias': tensor([ 0.0132, -0.0158,  0.0312,  ...,  0.1599,  0.0190, -0.0702],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight': tensor([[-0.0019,  0.0161, -0.0136,  ...,  0.0041,  0.0124, -0.0042],
        [ 0.0003, -0.0210,  0.0050,  ...,  0.0030, -0.0272,  0.0083],
        [-0.0101, -0.0327, -0.0195,  ..., -0.0035,  0.0067, -0.0172],
        ...,
        [ 0.0214, -0.0060, -0.0126,  ..., -0.0054, -0.0032,  0.0097],
        [-0.0153, -0.0010, -0.0009,  ...,  0.0023, -0.0131,  0.0013],
        [ 0.0080,  0.0060,  0.0053,  ..., -0.0054, -0.0073,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias': tensor([-0.0223, -0.0200, -0.0063,  ..., -0.0170, -0.0150,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight': tensor([[-0.0132,  0.0006,  0.0249,  ..., -0.0071,  0.0142, -0.0221],
        [-0.0046,  0.0369, -0.0272,  ...,  0.0017,  0.0163,  0.0032],
        [-0.0089, -0.0084,  0.0370,  ..., -0.0099,  0.0085,  0.0120],
        ...,
        [ 0.0223, -0.0226, -0.0282,  ...,  0.0133, -0.0224, -0.0005],
        [ 0.0005, -0.0127, -0.0058,  ..., -0.0071,  0.0076, -0.0049],
        [-0.0067,  0.0026,  0.0143,  ...,  0.0054, -0.0011,  0.0246]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias': tensor([-0.0499, -0.0381,  0.5078,  ..., -0.0939, -1.3535,  0.2761],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight': tensor([[ 0.0038,  0.0181,  0.0089,  ..., -0.0054,  0.0091,  0.0008],
        [-0.0116,  0.0084,  0.0211,  ...,  0.0138,  0.0282, -0.0086],
        [ 0.0388,  0.0029,  0.0070,  ..., -0.0161,  0.0043, -0.0173],
        ...,
        [ 0.0053, -0.0073, -0.0049,  ...,  0.0171, -0.0165,  0.0032],
        [ 0.0020, -0.0032,  0.0069,  ...,  0.0089,  0.0018,  0.0021],
        [ 0.0025, -0.0044,  0.0106,  ..., -0.0193,  0.0141, -0.0083]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias': tensor([ 0.0060,  0.0680,  0.0354,  ..., -0.0553,  0.0136,  0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight': tensor([1.2344, 1.2090, 1.1689,  ..., 1.8428, 1.1562, 1.2676],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias': tensor([-0.0174, -0.0716, -0.1256,  ..., -0.2900, -0.1460,  0.1504],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight': tensor([[-0.0042, -0.0027,  0.0133,  ..., -0.0005,  0.0226, -0.0110],
        [ 0.0404,  0.0308,  0.0195,  ...,  0.0055, -0.0234,  0.0145],
        [-0.0008, -0.0259, -0.0103,  ...,  0.0008,  0.0100,  0.0084],
        ...,
        [ 0.0190, -0.0154,  0.0061,  ..., -0.0111, -0.0397,  0.0165],
        [ 0.0025, -0.0002,  0.0089,  ..., -0.0010, -0.0172, -0.0077],
        [ 0.0183, -0.0069, -0.0037,  ...,  0.0029, -0.0036,  0.0130]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias': tensor([-0.2314, -0.3215, -0.0735,  ..., -0.3020, -0.1613, -0.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight': tensor([[ 1.0155e-02,  3.2532e-02,  8.2626e-03,  ..., -6.4468e-03,
         -4.7760e-03,  5.5432e-06],
        [-1.1612e-02,  1.7509e-03,  2.4841e-02,  ...,  8.9645e-03,
         -2.5436e-02, -8.4152e-03],
        [ 1.5182e-02,  7.3395e-03,  6.1264e-03,  ..., -1.5427e-02,
         -1.8677e-02,  1.9806e-02],
        ...,
        [-5.6686e-03,  6.3848e-04,  4.5128e-03,  ..., -9.9792e-03,
          1.1284e-02,  6.5231e-04],
        [-3.6335e-03,  3.6285e-02, -9.9277e-04,  ...,  4.8828e-03,
          9.6283e-03,  1.3008e-02],
        [ 9.3918e-03, -2.1927e-02, -1.4038e-02,  ...,  1.3329e-02,
          5.4359e-03,  3.3169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias': tensor([0.0373, 0.0198, 0.0018,  ..., 0.0559, 0.0675, 0.0106],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight': tensor([1.4990, 1.4297, 1.3555,  ..., 0.9502, 1.1816, 1.4072],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias': tensor([-0.1736, -0.0029,  0.0179,  ...,  0.2495,  0.0637, -0.1158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight': tensor([[ 0.0138, -0.0022,  0.0212,  ...,  0.0048,  0.0084,  0.0082],
        [-0.0165, -0.0025,  0.0060,  ...,  0.0063,  0.0062, -0.0098],
        [ 0.0116,  0.0009,  0.0094,  ...,  0.0054,  0.0176,  0.0027],
        ...,
        [ 0.0160, -0.0161,  0.0148,  ..., -0.0268,  0.0052,  0.0090],
        [-0.0136,  0.0253, -0.0004,  ...,  0.0156,  0.0059,  0.0038],
        [-0.0080,  0.0130, -0.0251,  ...,  0.0136, -0.0164,  0.0184]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias': tensor([ 0.1146,  1.0303,  0.1827,  ...,  0.0439,  0.0025, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0085, -0.0074,  ...,  0.0006, -0.0214, -0.0142],
        [ 0.0022,  0.0155, -0.0111,  ..., -0.0004, -0.0232, -0.0101],
        [-0.0139,  0.0073, -0.0043,  ..., -0.0005, -0.0110, -0.0235],
        ...,
        [ 0.0153,  0.0130, -0.0090,  ...,  0.0045,  0.0109,  0.0025],
        [ 0.0072,  0.0052, -0.0024,  ..., -0.0120,  0.0016, -0.0072],
        [ 0.0013, -0.0272, -0.0105,  ..., -0.0043,  0.0004, -0.0020]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias': tensor([ 0.0573, -0.0360, -0.0042,  ...,  0.0485, -0.0465,  0.0206],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight': tensor([[ 0.0094,  0.0003,  0.0279,  ...,  0.0015, -0.0191,  0.0090],
        [ 0.0041, -0.0014,  0.0020,  ...,  0.0017, -0.0018,  0.0040],
        [-0.0280,  0.0335,  0.0134,  ...,  0.0017,  0.0047, -0.0206],
        ...,
        [-0.0081, -0.0019,  0.0095,  ..., -0.0111, -0.0239,  0.0087],
        [-0.0195, -0.0019,  0.0218,  ...,  0.0267,  0.0121, -0.0089],
        [-0.0340, -0.0066,  0.0098,  ...,  0.0160,  0.0019, -0.0100]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias': tensor([ 0.2460,  1.7949,  0.0708,  ..., -0.2112,  0.1188,  0.6323],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight': tensor([[ 0.0051,  0.0107, -0.0119,  ..., -0.0148,  0.0005, -0.0302],
        [-0.0066, -0.0071, -0.0048,  ..., -0.0226, -0.0094,  0.0276],
        [ 0.0101,  0.0083,  0.0168,  ..., -0.0064,  0.0009, -0.0152],
        ...,
        [ 0.0094, -0.0071,  0.0016,  ..., -0.0147,  0.0114,  0.0020],
        [ 0.0223,  0.0076,  0.0287,  ..., -0.0214,  0.0006,  0.0041],
        [ 0.0177,  0.0222,  0.0063,  ...,  0.0065,  0.0120, -0.0114]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias': tensor([ 0.0267, -0.0057, -0.0027,  ..., -0.0531, -0.0267,  0.0482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight': tensor([1.2383, 1.2549, 1.2197,  ..., 1.8193, 1.1484, 1.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias': tensor([ 0.1250, -0.0352,  0.1172,  ..., -0.1227, -0.0328,  0.1005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight': tensor([[-0.0007, -0.0112,  0.0090,  ..., -0.0016,  0.0087,  0.0027],
        [ 0.0122, -0.0152,  0.0042,  ..., -0.0079, -0.0033, -0.0148],
        [ 0.0095, -0.0118, -0.0270,  ...,  0.0040,  0.0046, -0.0246],
        ...,
        [-0.0209, -0.0194, -0.0025,  ..., -0.0006, -0.0144,  0.0085],
        [ 0.0016,  0.0133,  0.0006,  ..., -0.0033, -0.0143,  0.0128],
        [-0.0106,  0.0115,  0.0019,  ..., -0.0046, -0.0505,  0.0052]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias': tensor([-0.3506, -0.3098, -0.0692,  ..., -0.3076, -0.2494, -0.4229],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight': tensor([[-0.0116,  0.0186, -0.0109,  ...,  0.0093, -0.0051, -0.0192],
        [ 0.0115,  0.0091,  0.0046,  ...,  0.0060, -0.0104, -0.0086],
        [-0.0004,  0.0162,  0.0221,  ...,  0.0048,  0.0374,  0.0092],
        ...,
        [-0.0029,  0.0068, -0.0073,  ...,  0.0019, -0.0060,  0.0068],
        [ 0.0121, -0.0012, -0.0035,  ..., -0.0168, -0.0036, -0.0015],
        [ 0.0085, -0.0005,  0.0138,  ..., -0.0026,  0.0074, -0.0113]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias': tensor([ 0.0374, -0.0088, -0.0430,  ...,  0.0654, -0.0126, -0.0253],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight': tensor([1.5195, 1.3818, 1.3984,  ..., 0.8403, 1.2627, 1.5020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias': tensor([-0.1865,  0.1162,  0.4048,  ...,  0.2292,  0.4202, -0.0959],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight': tensor([[ 0.0295,  0.0205, -0.0174,  ...,  0.0181,  0.0055,  0.0153],
        [ 0.0159, -0.0236, -0.0138,  ...,  0.0058,  0.0019,  0.0084],
        [-0.0116, -0.0219,  0.0080,  ...,  0.0020, -0.0022,  0.0255],
        ...,
        [-0.0140,  0.0030, -0.0549,  ...,  0.0038, -0.0079,  0.0469],
        [-0.0193,  0.0216, -0.0092,  ...,  0.0083,  0.0186,  0.0123],
        [ 0.0039,  0.0084,  0.0082,  ..., -0.0016, -0.0041, -0.0187]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias': tensor([-0.0278, -0.0587, -0.0110,  ..., -0.0826, -0.0213, -0.0725],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight': tensor([[-0.0007,  0.0020,  0.0042,  ..., -0.0033, -0.0094, -0.0123],
        [ 0.0162,  0.0139,  0.0239,  ..., -0.0017, -0.0188,  0.0138],
        [-0.0234,  0.0133, -0.0101,  ..., -0.0029, -0.0003,  0.0196],
        ...,
        [ 0.0244,  0.0202,  0.0058,  ..., -0.0130,  0.0092, -0.0032],
        [ 0.0215,  0.0236, -0.0171,  ..., -0.0159, -0.0069,  0.0134],
        [-0.0087,  0.0025,  0.0248,  ..., -0.0004,  0.0047, -0.0208]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias': tensor([-0.0305,  0.0005, -0.0124,  ..., -0.0511, -0.0883,  0.0079],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight': tensor([[-0.0156,  0.0022, -0.0072,  ...,  0.0036,  0.0290,  0.0180],
        [-0.0003,  0.0088, -0.0014,  ..., -0.0144, -0.0101,  0.0001],
        [-0.0141, -0.0287,  0.0098,  ..., -0.0024,  0.0292,  0.0254],
        ...,
        [-0.0255,  0.0364, -0.0171,  ...,  0.0032,  0.0116, -0.0182],
        [-0.0159,  0.0349, -0.0009,  ..., -0.0083, -0.0006, -0.0242],
        [-0.0239,  0.0287,  0.0045,  ...,  0.0057, -0.0037, -0.0132]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias': tensor([-0.2856, -0.3130, -0.2024,  ...,  0.1942, -0.0307, -0.0692],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight': tensor([[ 0.0021, -0.0248,  0.0393,  ..., -0.0213, -0.0080,  0.0129],
        [-0.0123, -0.0083,  0.0236,  ..., -0.0091, -0.0172, -0.0205],
        [-0.0194, -0.0024,  0.0146,  ..., -0.0071,  0.0185, -0.0175],
        ...,
        [-0.0277,  0.0011, -0.0187,  ...,  0.0559,  0.0597, -0.0009],
        [ 0.0156,  0.0051, -0.0020,  ..., -0.0031,  0.0066,  0.0040],
        [-0.0057, -0.0281, -0.0138,  ...,  0.0075, -0.0093,  0.0108]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias': tensor([ 0.0077,  0.0031,  0.0012,  ..., -0.0701,  0.0300,  0.0083],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight': tensor([1.2822, 1.2529, 1.2988,  ..., 2.2090, 1.1758, 1.3721],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias': tensor([ 0.1495, -0.0801, -0.0723,  ..., -0.1654, -0.0899,  0.0350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight': tensor([[ 0.0063,  0.0413,  0.0369,  ...,  0.0064,  0.0150,  0.0227],
        [ 0.0141,  0.0154,  0.0189,  ...,  0.0018,  0.0107,  0.0041],
        [-0.0081, -0.0167,  0.0103,  ..., -0.0018, -0.0027,  0.0110],
        ...,
        [ 0.0142,  0.0290,  0.0162,  ..., -0.0030,  0.0042,  0.0023],
        [ 0.0167,  0.0140,  0.0168,  ..., -0.0036, -0.0046,  0.0118],
        [-0.0082,  0.0164,  0.0227,  ...,  0.0009, -0.0199, -0.0222]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias': tensor([-0.2788, -0.1959, -0.3855,  ..., -0.3228, -0.2610, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight': tensor([[-6.8474e-03, -1.1681e-02, -1.7517e-02,  ...,  1.0986e-02,
         -1.8341e-02,  2.0432e-02],
        [ 1.1215e-02, -7.8430e-03, -6.9542e-03,  ...,  1.2108e-02,
         -9.6741e-03, -1.2093e-02],
        [ 1.2321e-02, -2.7924e-02, -2.8896e-03,  ...,  4.8676e-03,
         -2.0275e-03, -1.2695e-02],
        ...,
        [-2.5902e-03,  1.4412e-02, -3.3092e-03,  ..., -2.8193e-05,
          6.4087e-04, -7.4434e-04],
        [-1.8280e-02, -8.6746e-03,  9.6130e-03,  ...,  4.2915e-03,
         -1.1269e-02,  2.3453e-02],
        [-6.6452e-03, -2.1088e-02, -1.2444e-02,  ..., -3.5534e-03,
         -7.8659e-03,  2.5589e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias': tensor([ 0.0329,  0.0112, -0.0181,  ...,  0.0332,  0.0061, -0.0410],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight': tensor([1.6201, 1.4990, 1.4219,  ..., 0.7642, 1.2715, 1.4961],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias': tensor([-0.1376, -0.0238, -0.0118,  ...,  0.3352,  0.1462, -0.0976],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight': tensor([[ 0.0070,  0.0068,  0.0031,  ...,  0.0113, -0.0308, -0.0060],
        [ 0.0026, -0.0039,  0.0043,  ..., -0.0343, -0.0066,  0.0307],
        [-0.0036,  0.0332, -0.0028,  ...,  0.0011, -0.0337,  0.0031],
        ...,
        [-0.0229, -0.0187, -0.0097,  ..., -0.0007,  0.0183, -0.0038],
        [ 0.0047,  0.0152, -0.0175,  ...,  0.0070,  0.0130, -0.0114],
        [-0.0206,  0.0068, -0.0252,  ...,  0.0070, -0.0134, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias': tensor([ 0.1860, -0.2378,  0.0005,  ...,  0.0031,  0.1797, -0.0522],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight': tensor([[-0.0298, -0.0140,  0.0248,  ...,  0.0035, -0.0014, -0.0059],
        [-0.0006, -0.0080,  0.0046,  ...,  0.0036,  0.0106, -0.0112],
        [ 0.0055,  0.0188,  0.0175,  ...,  0.0029, -0.0033, -0.0018],
        ...,
        [ 0.0039, -0.0129,  0.0162,  ...,  0.0032, -0.0222, -0.0056],
        [-0.0039, -0.0104,  0.0050,  ..., -0.0019,  0.0213, -0.0076],
        [ 0.0024,  0.0067, -0.0013,  ..., -0.0021,  0.0013,  0.0046]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias': tensor([ 0.0186, -0.0095,  0.0066,  ...,  0.0210,  0.0131,  0.0208],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight': tensor([[ 0.0029, -0.0233, -0.0027,  ...,  0.0144, -0.0352, -0.0105],
        [-0.0247, -0.0116,  0.0012,  ..., -0.0372,  0.0113, -0.0128],
        [ 0.0080, -0.0012, -0.0150,  ...,  0.0013, -0.0024,  0.0199],
        ...,
        [-0.0113, -0.0235, -0.0017,  ...,  0.0006, -0.0010, -0.0029],
        [ 0.0197, -0.0205, -0.0153,  ...,  0.0061,  0.0182,  0.0045],
        [-0.0173, -0.0083,  0.0412,  ...,  0.0141, -0.0057,  0.0143]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias': tensor([ 0.2690, -0.1337,  0.1326,  ...,  0.5728, -0.2661, -0.0468],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight': tensor([[ 0.0029,  0.0160,  0.0056,  ...,  0.0018,  0.0077, -0.0090],
        [ 0.0110, -0.0064,  0.0049,  ...,  0.0272,  0.0262,  0.0051],
        [-0.0114, -0.0032,  0.0054,  ...,  0.0236, -0.0132, -0.0082],
        ...,
        [-0.0007,  0.0021, -0.0044,  ..., -0.0028, -0.0311, -0.0200],
        [-0.0074, -0.0073, -0.0035,  ..., -0.0198, -0.0346, -0.0070],
        [-0.0123, -0.0216,  0.0046,  ...,  0.0036,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias': tensor([-0.0063, -0.0193, -0.0133,  ...,  0.0398,  0.0332,  0.0196],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight': tensor([1.3359, 1.2266, 1.2646,  ..., 1.9346, 1.1377, 1.3818],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias': tensor([ 0.1417,  0.0006,  0.0168,  ...,  0.0170, -0.0730,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight': tensor([[ 0.0115,  0.0003, -0.0145,  ..., -0.0144, -0.0194, -0.0104],
        [-0.0015,  0.0058,  0.0179,  ..., -0.0030,  0.0044, -0.0100],
        [-0.0029,  0.0045,  0.0084,  ..., -0.0206,  0.0133,  0.0283],
        ...,
        [ 0.0059, -0.0118, -0.0161,  ..., -0.0221, -0.0054,  0.0157],
        [ 0.0215, -0.0010,  0.0022,  ...,  0.0130,  0.0179,  0.0099],
        [ 0.0113,  0.0054, -0.0108,  ...,  0.0036,  0.0090, -0.0237]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias': tensor([-0.2153, -0.2783, -0.3320,  ..., -0.1221, -0.1306, -0.2898],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight': tensor([[-0.0038, -0.0308,  0.0166,  ..., -0.0028, -0.0180,  0.0016],
        [ 0.0179,  0.0086,  0.0044,  ...,  0.0105,  0.0129, -0.0061],
        [-0.0078, -0.0048,  0.0276,  ...,  0.0158, -0.0102,  0.0017],
        ...,
        [-0.0093,  0.0032, -0.0129,  ...,  0.0116, -0.0041, -0.0039],
        [-0.0126,  0.0043,  0.0086,  ...,  0.0042, -0.0106,  0.0038],
        [-0.0054, -0.0066, -0.0067,  ..., -0.0130, -0.0257,  0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias': tensor([ 0.0253, -0.0025, -0.0242,  ...,  0.0955,  0.0208, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight': tensor([1.6533, 1.5479, 1.5508,  ..., 0.4094, 1.3984, 1.6689],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias': tensor([-0.2152,  0.1279,  0.3982,  ...,  0.3850,  0.3862, -0.2152],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight': tensor([[ 0.0007,  0.0003,  0.0054,  ...,  0.0126,  0.0008,  0.0107],
        [-0.0359,  0.0132, -0.0041,  ..., -0.0473,  0.0050, -0.0005],
        [ 0.0122, -0.0012, -0.0178,  ..., -0.0031,  0.0207, -0.0100],
        ...,
        [ 0.0512, -0.0152, -0.0452,  ...,  0.0250, -0.0268,  0.0074],
        [ 0.0115,  0.0260, -0.0071,  ...,  0.0085,  0.0057,  0.0017],
        [ 0.0223, -0.0031, -0.0004,  ...,  0.0035, -0.0175,  0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias': tensor([-0.8135, -0.1840,  0.0576,  ..., -0.0189,  0.0277,  0.0699],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight': tensor([[ 2.6184e-02,  6.5842e-03, -6.6528e-03,  ...,  2.3901e-05,
          1.5297e-02, -1.9302e-02],
        [ 4.0741e-03,  3.0079e-03,  3.1090e-03,  ..., -9.0485e-03,
          1.0986e-02,  4.2953e-03],
        [ 4.1504e-03,  1.6336e-03, -1.1185e-02,  ...,  5.6496e-03,
          2.0889e-02, -1.3113e-04],
        ...,
        [-3.6945e-03,  1.4648e-02, -8.8348e-03,  ...,  8.1711e-03,
         -2.6073e-03,  1.3008e-02],
        [ 1.9562e-02, -1.5762e-02,  7.0877e-03,  ...,  6.5517e-04,
         -2.1744e-02, -2.0233e-02],
        [ 1.8417e-02, -1.2039e-02, -9.2239e-03,  ..., -4.6659e-04,
         -1.3191e-02, -7.4272e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias': tensor([ 0.0088,  0.0188,  0.0441,  ..., -0.0099, -0.0044,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight': tensor([[-0.0029,  0.0020, -0.0026,  ...,  0.0042, -0.0110, -0.0049],
        [-0.0278,  0.0302,  0.0003,  ..., -0.0331,  0.0236,  0.0125],
        [ 0.0239,  0.0206,  0.0083,  ..., -0.0029,  0.0212, -0.0040],
        ...,
        [ 0.0231,  0.0166, -0.0169,  ...,  0.0415, -0.0144,  0.0037],
        [ 0.0159,  0.0033, -0.0034,  ...,  0.0044, -0.0091,  0.0034],
        [ 0.0106, -0.0117, -0.0165,  ...,  0.0030, -0.0196,  0.0211]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias': tensor([-2.5234,  0.2341, -0.3838,  ..., -0.0643,  0.1272,  0.1238],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight': tensor([[-0.0296, -0.0036,  0.0027,  ...,  0.0065,  0.0073, -0.0128],
        [-0.0154, -0.0153,  0.0213,  ...,  0.0241,  0.0144,  0.0159],
        [-0.0073, -0.0148,  0.0064,  ...,  0.0165,  0.0177,  0.0191],
        ...,
        [-0.0013,  0.0025, -0.0111,  ..., -0.0081,  0.0079,  0.0101],
        [-0.0041, -0.0076, -0.0202,  ..., -0.0055,  0.0170,  0.0018],
        [ 0.0106, -0.0025,  0.0060,  ...,  0.0055, -0.0079,  0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias': tensor([ 0.0107, -0.0549,  0.0179,  ...,  0.0266,  0.0321, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight': tensor([1.3027, 1.2529, 1.3281,  ..., 1.4834, 1.1562, 1.3789],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias': tensor([ 0.1531,  0.0493, -0.0565,  ..., -0.0096, -0.0239, -0.0371],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight': tensor([[ 0.0043,  0.0120,  0.0113,  ..., -0.0241, -0.0064, -0.0090],
        [ 0.0006, -0.0211, -0.0018,  ..., -0.0029, -0.0108,  0.0110],
        [ 0.0030,  0.0094, -0.0028,  ..., -0.0025, -0.0057,  0.0185],
        ...,
        [-0.0027, -0.0314, -0.0122,  ..., -0.0098, -0.0206, -0.0127],
        [-0.0042,  0.0269, -0.0155,  ..., -0.0024, -0.0119, -0.0034],
        [-0.0102,  0.0069, -0.0109,  ..., -0.0012,  0.0015, -0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias': tensor([-0.2781, -0.2573, -0.3364,  ..., -0.3469, -0.2040, -0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight': tensor([[ 0.0010, -0.0122,  0.0169,  ...,  0.0076, -0.0051,  0.0080],
        [ 0.0136, -0.0151, -0.0033,  ..., -0.0080,  0.0146, -0.0023],
        [ 0.0173, -0.0216,  0.0123,  ...,  0.0066, -0.0024, -0.0003],
        ...,
        [-0.0117,  0.0076, -0.0053,  ...,  0.0010,  0.0026,  0.0003],
        [-0.0175,  0.0074, -0.0194,  ..., -0.0246, -0.0096, -0.0045],
        [ 0.0076,  0.0037,  0.0206,  ...,  0.0206, -0.0109,  0.0051]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias': tensor([ 0.0366, -0.0981, -0.0667,  ...,  0.0356,  0.0194, -0.0255],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight': tensor([1.7695, 1.6426, 1.7236,  ..., 0.6680, 1.5166, 1.7900],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias': tensor([-0.1890,  0.3459,  0.1487,  ...,  0.4136,  0.4312, -0.1221],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight': tensor([[ 0.0141,  0.0079,  0.0303,  ..., -0.0145,  0.0041,  0.0001],
        [-0.0112,  0.0048,  0.0240,  ..., -0.0055, -0.0139,  0.0003],
        [ 0.0167,  0.0107,  0.0269,  ..., -0.0065,  0.0130, -0.0072],
        ...,
        [-0.0014,  0.0062,  0.0020,  ..., -0.0017,  0.0170, -0.0246],
        [-0.0123, -0.0318, -0.0099,  ..., -0.0016, -0.0070, -0.0297],
        [ 0.0025,  0.0103,  0.0089,  ...,  0.0022,  0.0038,  0.0318]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias': tensor([-0.0931,  0.0089, -0.0538,  ...,  0.1041,  0.1436,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight': tensor([[-0.0085,  0.0049, -0.0003,  ...,  0.0036, -0.0302,  0.0040],
        [ 0.0075, -0.0265, -0.0065,  ..., -0.0031,  0.0134, -0.0018],
        [-0.0087, -0.0006, -0.0056,  ...,  0.0055,  0.0154,  0.0372],
        ...,
        [-0.0022, -0.0078,  0.0144,  ...,  0.0019, -0.0084,  0.0115],
        [ 0.0047, -0.0127, -0.0223,  ..., -0.0021, -0.0109,  0.0101],
        [-0.0105, -0.0005, -0.0008,  ..., -0.0030, -0.0079, -0.0039]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias': tensor([-0.0321,  0.0378,  0.0632,  ...,  0.0502, -0.0048, -0.0005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight': tensor([[-0.0095, -0.0095,  0.0312,  ...,  0.0022, -0.0092,  0.0262],
        [-0.0264, -0.0028, -0.0018,  ..., -0.0075, -0.0155, -0.0109],
        [-0.0025, -0.0001,  0.0389,  ..., -0.0119,  0.0128, -0.0002],
        ...,
        [ 0.0271, -0.0069,  0.0122,  ...,  0.0018,  0.0167, -0.0080],
        [ 0.0080, -0.0216,  0.0023,  ...,  0.0015, -0.0140,  0.0002],
        [-0.0039,  0.0055,  0.0021,  ...,  0.0071, -0.0103,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias': tensor([-0.2311,  0.2390, -0.0950,  ...,  0.0876,  0.1581,  0.0798],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight': tensor([[-0.0281, -0.0058,  0.0026,  ..., -0.0079,  0.0053, -0.0023],
        [ 0.0130, -0.0057, -0.0072,  ..., -0.0006, -0.0015, -0.0051],
        [-0.0112,  0.0132,  0.0089,  ..., -0.0184,  0.0022, -0.0036],
        ...,
        [ 0.0086,  0.0047, -0.0106,  ..., -0.0117, -0.0147, -0.0069],
        [ 0.0147, -0.0031, -0.0165,  ...,  0.0125, -0.0091,  0.0107],
        [ 0.0214,  0.0008, -0.0262,  ..., -0.0205, -0.0144,  0.0057]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias': tensor([-0.0645, -0.0639,  0.0044,  ..., -0.0346, -0.0156, -0.0320],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight': tensor([1.3975, 1.3584, 1.4883,  ..., 1.8799, 1.3203, 1.4980],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias': tensor([ 0.0757, -0.1133, -0.0580,  ..., -0.0255, -0.0899, -0.1061],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight': tensor([[-7.1793e-03,  4.6234e-03,  1.7502e-02,  ..., -1.0124e-02,
          1.3245e-02, -6.4430e-03],
        [-1.6571e-02,  1.1040e-02, -5.1537e-03,  ..., -6.7616e-04,
         -2.2491e-02, -9.1019e-03],
        [-7.6675e-04,  2.2156e-02,  1.0216e-02,  ..., -4.4708e-03,
         -1.6510e-02, -2.4704e-02],
        ...,
        [-2.9205e-02, -7.1602e-03,  8.7559e-05,  ..., -9.7656e-03,
          1.6312e-02,  2.7145e-02],
        [-1.2413e-02,  6.9084e-03,  2.4399e-02,  ..., -7.0381e-03,
         -7.9803e-03,  9.6130e-03],
        [ 6.4039e-04, -4.3259e-03,  4.3121e-02,  ..., -3.9101e-03,
         -1.3245e-02,  1.4565e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias': tensor([-0.3418, -0.2771, -0.3467,  ..., -0.3992, -0.2385, -0.2927],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight': tensor([[-9.4452e-03,  1.2772e-02,  1.8539e-02,  ..., -2.6276e-02,
          4.2343e-04, -1.3672e-02],
        [ 3.2593e-02,  8.7070e-04, -2.8477e-03,  ..., -8.7814e-03,
          1.1383e-02, -3.0182e-02],
        [-4.3488e-03, -2.7359e-02,  1.8482e-03,  ..., -6.5002e-03,
          2.6016e-02,  3.3539e-02],
        ...,
        [-4.1504e-03,  1.6251e-02,  7.8354e-03,  ...,  1.4816e-02,
         -1.9627e-03, -6.3002e-05],
        [ 6.4125e-03, -1.6647e-02,  4.3945e-03,  ...,  1.2833e-02,
         -1.5268e-03, -1.7975e-02],
        [-1.8167e-03, -1.1734e-02, -1.4511e-02,  ...,  3.0396e-02,
          1.1108e-02, -9.7580e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias': tensor([-0.0361, -0.0392,  0.0150,  ..., -0.0163,  0.0041, -0.0078],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight': tensor([2.1113, 2.0137, 2.0352,  ..., 0.7090, 1.8164, 2.2012],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias': tensor([-0.1631, -0.1508,  0.1484,  ...,  0.4434,  0.6812, -0.3279],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight': tensor([[-9.9716e-03, -2.5208e-02,  8.4457e-03,  ...,  1.3168e-02,
         -5.3942e-05, -2.8748e-02],
        [-3.1233e-05,  1.3992e-02, -2.2476e-02,  ...,  6.3232e-02,
         -1.4221e-02, -1.4404e-02],
        [-5.1785e-04, -3.1403e-02,  6.5517e-04,  ..., -1.0399e-02,
          1.1505e-02, -2.8076e-03],
        ...,
        [-6.2132e-04, -1.0201e-02,  1.3947e-02,  ..., -5.4810e-02,
         -8.1787e-03, -2.0981e-02],
        [ 9.8572e-03, -1.7899e-02,  1.1734e-02,  ..., -4.1885e-03,
          1.4870e-02,  1.1244e-03],
        [ 1.5884e-02,  2.2827e-02,  4.2000e-03,  ..., -4.3091e-02,
         -2.2690e-02, -1.3191e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias': tensor([ 0.2656, -0.2185,  0.0432,  ..., -0.1787, -0.2061,  0.0742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight': tensor([[ 0.0261,  0.0077, -0.0120,  ..., -0.0027, -0.0164, -0.0107],
        [-0.0080,  0.0102,  0.0077,  ...,  0.0039,  0.0010, -0.0050],
        [ 0.0017, -0.0101, -0.0256,  ...,  0.0058, -0.0145, -0.0055],
        ...,
        [-0.0161,  0.0100, -0.0047,  ..., -0.0049, -0.0208,  0.0245],
        [ 0.0115, -0.0098,  0.0141,  ...,  0.0035, -0.0129, -0.0005],
        [-0.0111, -0.0270,  0.0220,  ..., -0.0022, -0.0052, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias': tensor([-0.0182,  0.0114,  0.1055,  ..., -0.0048, -0.0138,  0.0093],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight': tensor([[-0.0116, -0.0250, -0.0204,  ...,  0.0060, -0.0022, -0.0020],
        [ 0.0243,  0.0011, -0.0106,  ...,  0.0480, -0.0213,  0.0138],
        [ 0.0116, -0.0210, -0.0045,  ..., -0.0067, -0.0268, -0.0189],
        ...,
        [ 0.0013,  0.0050,  0.0468,  ..., -0.0500,  0.0203,  0.0043],
        [ 0.0273, -0.0117,  0.0099,  ..., -0.0033, -0.0067,  0.0015],
        [-0.0062,  0.0012,  0.0167,  ..., -0.0361, -0.0010,  0.0275]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias': tensor([ 0.2439, -0.1146,  0.0887,  ...,  0.2213,  0.1515, -0.0186],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight': tensor([[-3.0136e-02,  1.2367e-02, -9.5749e-03,  ...,  1.8692e-02,
          9.2697e-03, -4.0054e-03],
        [-3.6682e-02, -9.7504e-03,  7.6950e-05,  ..., -1.0941e-02,
          8.2474e-03, -8.6546e-04],
        [ 1.9424e-02, -2.1729e-02,  5.8022e-03,  ...,  6.4888e-03,
         -4.6577e-03, -6.9504e-03],
        ...,
        [-7.0953e-03, -1.1024e-02,  1.4248e-03,  ...,  3.1490e-03,
         -7.8735e-03, -1.8097e-02],
        [ 1.8778e-03, -1.1490e-02, -8.2855e-03,  ..., -1.9104e-02,
          7.3166e-03, -8.8959e-03],
        [-8.1558e-03,  1.7426e-02,  1.1551e-02,  ..., -4.8790e-03,
          5.9700e-03,  9.9030e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias': tensor([-0.0732,  0.0212,  0.0239,  ...,  0.0091, -0.0001, -0.0141],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight': tensor([1.3848, 1.3320, 1.4814,  ..., 1.5195, 1.3164, 1.4180],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias': tensor([ 0.0473, -0.0936, -0.0594,  ...,  0.0325,  0.0149, -0.0659],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight': tensor([[ 1.5793e-02, -8.3160e-03,  2.2156e-02,  ...,  1.8814e-02,
         -5.4436e-03, -1.1604e-02],
        [ 1.5007e-02, -9.5978e-03, -2.5284e-02,  ..., -1.6510e-02,
         -3.3539e-02, -2.3102e-02],
        [-2.1622e-02,  2.0309e-02,  2.1801e-03,  ...,  7.5798e-03,
          1.4145e-02, -7.3433e-03],
        ...,
        [-4.5624e-03, -2.5757e-02,  6.9199e-03,  ...,  3.5572e-03,
          1.4694e-02, -2.2339e-02],
        [-9.1791e-06,  7.1487e-03, -1.3298e-02,  ...,  5.6610e-03,
          4.4975e-03,  1.1978e-02],
        [-5.8289e-03,  5.1689e-03, -1.4862e-02,  ...,  1.8585e-02,
          9.6655e-04,  1.1856e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias': tensor([-0.2683, -0.3921, -0.3279,  ..., -0.3718, -0.2028, -0.3127],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight': tensor([[-0.0059, -0.0140,  0.0130,  ...,  0.0043,  0.0292, -0.0014],
        [ 0.0265, -0.0073, -0.0116,  ..., -0.0211,  0.0206,  0.0263],
        [ 0.0022, -0.0233,  0.0002,  ...,  0.0067, -0.0096, -0.0120],
        ...,
        [ 0.0080, -0.0016,  0.0073,  ..., -0.0021, -0.0057, -0.0010],
        [ 0.0048, -0.0163, -0.0040,  ...,  0.0130, -0.0188,  0.0429],
        [-0.0011, -0.0383, -0.0151,  ..., -0.0132,  0.0248,  0.0216]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias': tensor([ 0.0359,  0.0342,  0.0545,  ...,  0.0745, -0.0070,  0.0030],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight': tensor([2.5176, 2.3496, 2.4785,  ..., 0.5151, 2.0352, 2.4492],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias': tensor([-0.2339, -0.0297,  0.1533,  ...,  0.4067,  0.7363, -0.2054],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0246, -0.0315,  ...,  0.0246, -0.0050,  0.0121],
        [ 0.0096,  0.0193,  0.0106,  ..., -0.0207, -0.0075,  0.0043],
        [ 0.0199,  0.0022, -0.0148,  ..., -0.0771, -0.0211,  0.0064],
        ...,
        [ 0.0369,  0.0040, -0.0087,  ..., -0.0215,  0.0106,  0.0167],
        [-0.0061, -0.0050, -0.0032,  ..., -0.0078,  0.0147,  0.0186],
        [ 0.0009,  0.0079, -0.0195,  ..., -0.0096, -0.0309,  0.0012]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias': tensor([ 0.0911, -0.1252, -0.4846,  ...,  0.0673, -0.0733,  0.0197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight': tensor([[ 0.0141,  0.0237,  0.0094,  ..., -0.0007, -0.0127, -0.0134],
        [ 0.0092, -0.0071,  0.0201,  ...,  0.0027, -0.0176, -0.0013],
        [ 0.0039, -0.0016, -0.0055,  ...,  0.0065, -0.0001, -0.0049],
        ...,
        [ 0.0073, -0.0355, -0.0101,  ...,  0.0047, -0.0010, -0.0099],
        [-0.0019,  0.0097, -0.0335,  ..., -0.0019,  0.0006, -0.0019],
        [ 0.0030, -0.0076,  0.0026,  ..., -0.0004,  0.0043, -0.0152]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias': tensor([ 0.0290,  0.0252,  0.0343,  ...,  0.0027, -0.0045, -0.0545],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight': tensor([[ 0.0060, -0.0019, -0.0088,  ...,  0.0198, -0.0025, -0.0177],
        [ 0.0059,  0.0067,  0.0215,  ..., -0.0244, -0.0294,  0.0024],
        [ 0.0271,  0.0004, -0.0182,  ..., -0.0876,  0.0076, -0.0006],
        ...,
        [-0.0081,  0.0160, -0.0380,  ..., -0.0249, -0.0083,  0.0045],
        [ 0.0112, -0.0182, -0.0261,  ..., -0.0056, -0.0009, -0.0319],
        [ 0.0435,  0.0031,  0.0118,  ..., -0.0163,  0.0102, -0.0193]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias': tensor([ 0.0622,  0.0999, -0.5308,  ..., -0.1455,  0.0368, -0.1086],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight': tensor([[ 4.6425e-03, -2.0313e-03,  2.7237e-02,  ...,  1.0216e-02,
         -2.0187e-02,  1.1955e-02],
        [-5.8823e-03,  2.6627e-02,  7.8506e-03,  ...,  3.9864e-03,
         -1.8646e-02,  2.6762e-05],
        [-5.6601e-04,  5.0240e-03,  2.1591e-02,  ...,  1.1375e-02,
          6.1035e-03,  7.7581e-04],
        ...,
        [ 9.0256e-03, -4.1656e-03, -1.2932e-02,  ...,  9.0778e-05,
          1.9577e-02, -6.6452e-03],
        [ 1.5488e-02,  5.1928e-04,  1.3100e-02,  ..., -2.1057e-02,
         -4.6921e-03,  1.0338e-02],
        [ 3.2501e-03, -2.0432e-02, -2.8076e-02,  ..., -8.2169e-03,
         -2.1858e-03,  3.8376e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias': tensor([ 0.0169,  0.0075, -0.0464,  ...,  0.0064, -0.0125, -0.0271],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight': tensor([1.4844, 1.5352, 1.5859,  ..., 1.5234, 1.4395, 1.5938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias': tensor([ 0.1630, -0.0892, -0.0373,  ..., -0.0082, -0.0609, -0.1628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight': tensor([[-0.0057, -0.0090,  0.0211,  ...,  0.0072, -0.0180, -0.0063],
        [ 0.0278,  0.0188,  0.0136,  ..., -0.0074,  0.0133, -0.0087],
        [-0.0168,  0.0028, -0.0226,  ..., -0.0184, -0.0072, -0.0020],
        ...,
        [ 0.0011, -0.0155, -0.0045,  ..., -0.0092, -0.0268,  0.0125],
        [ 0.0054, -0.0030,  0.0160,  ...,  0.0257, -0.0181, -0.0068],
        [ 0.0045,  0.0018,  0.0164,  ..., -0.0108, -0.0191, -0.0004]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias': tensor([-0.2793, -0.3452, -0.2959,  ..., -0.1838, -0.1981, -0.2494],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight': tensor([[-0.0017, -0.0146,  0.0010,  ...,  0.0037, -0.0001,  0.0201],
        [ 0.0174, -0.0161, -0.0016,  ..., -0.0007, -0.0096, -0.0005],
        [ 0.0072,  0.0077, -0.0210,  ...,  0.0165, -0.0019, -0.0208],
        ...,
        [ 0.0195, -0.0092,  0.0151,  ..., -0.0062, -0.0071, -0.0216],
        [ 0.0159,  0.0006,  0.0077,  ..., -0.0073,  0.0030,  0.0091],
        [ 0.0062,  0.0206,  0.0089,  ...,  0.0090, -0.0033, -0.0063]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias': tensor([0.0065, 0.0102, 0.0046,  ..., 0.0065, 0.0796, 0.0695],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight': tensor([2.6719, 2.5625, 2.7695,  ..., 0.6802, 2.2539, 2.7422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias': tensor([-0.0354,  0.2776,  0.4175,  ...,  0.5674,  0.5327, -0.4670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight': tensor([[-0.0087,  0.0027,  0.0113,  ..., -0.0616,  0.0051, -0.0137],
        [-0.0173,  0.0047,  0.0124,  ...,  0.0239, -0.0160,  0.0129],
        [ 0.0097, -0.0005, -0.0050,  ...,  0.0011,  0.0099, -0.0130],
        ...,
        [-0.0052,  0.0120,  0.0098,  ..., -0.0244,  0.0038,  0.0010],
        [ 0.0119, -0.0235, -0.0134,  ..., -0.0140, -0.0140,  0.0065],
        [ 0.0291,  0.0226, -0.0254,  ..., -0.0035, -0.0137,  0.0350]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias': tensor([ 0.2783, -0.2036, -0.0648,  ...,  0.1705,  0.1809,  0.1080],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight': tensor([[-0.0184,  0.0137,  0.0067,  ..., -0.0029,  0.0099,  0.0297],
        [-0.0110,  0.0184,  0.0020,  ...,  0.0024, -0.0151,  0.0009],
        [ 0.0191, -0.0126,  0.0212,  ...,  0.0024, -0.0348,  0.0026],
        ...,
        [ 0.0005,  0.0007, -0.0011,  ...,  0.0046, -0.0222, -0.0393],
        [ 0.0117,  0.0042,  0.0002,  ..., -0.0006,  0.0005, -0.0083],
        [-0.0062,  0.0128,  0.0124,  ..., -0.0037, -0.0134,  0.0008]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias': tensor([-0.0114,  0.0300,  0.0252,  ..., -0.0060,  0.0197,  0.0400],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight': tensor([[ 1.4931e-02, -1.2466e-02,  2.4918e-02,  ..., -5.9814e-02,
         -4.3068e-03,  1.2131e-02],
        [-1.6464e-02, -9.9030e-03, -1.1108e-02,  ...,  2.3956e-02,
         -3.6163e-02,  1.1703e-02],
        [ 1.0757e-02,  2.5730e-03, -7.3338e-04,  ...,  2.4662e-03,
          6.1493e-03,  6.6528e-03],
        ...,
        [ 5.1003e-03, -7.8678e-06,  5.1041e-03,  ..., -4.5410e-02,
         -3.1738e-02,  1.8631e-02],
        [ 1.7502e-02, -4.1084e-03,  3.9978e-03,  ..., -1.8753e-02,
         -2.2335e-03,  2.1057e-03],
        [ 1.7303e-02,  6.7902e-03,  1.1360e-02,  ...,  8.0719e-03,
         -5.0278e-03,  2.1713e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias': tensor([-0.2339,  0.0393, -0.0323,  ..., -0.1953,  0.0200,  0.0049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight': tensor([[ 0.0254,  0.0050,  0.0049,  ...,  0.0120, -0.0121,  0.0091],
        [ 0.0248, -0.0193, -0.0093,  ..., -0.0044, -0.0032,  0.0151],
        [ 0.0053,  0.0182, -0.0142,  ..., -0.0130, -0.0033, -0.0087],
        ...,
        [ 0.0006, -0.0051, -0.0173,  ...,  0.0031, -0.0128,  0.0099],
        [ 0.0081, -0.0134,  0.0246,  ...,  0.0185, -0.0136,  0.0109],
        [-0.0261, -0.0152, -0.0080,  ...,  0.0230, -0.0056,  0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias': tensor([-0.0083,  0.0091, -0.0955,  ..., -0.0067,  0.0003, -0.0047],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight': tensor([1.5762, 1.4580, 1.5850,  ..., 1.7383, 1.4209, 1.5967],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias': tensor([ 0.1272, -0.2208, -0.0098,  ..., -0.0831, -0.0858, -0.1576],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight': tensor([[-0.0051,  0.0014, -0.0012,  ...,  0.0091, -0.0065, -0.0086],
        [-0.0191,  0.0118,  0.0002,  ..., -0.0095, -0.0148,  0.0134],
        [-0.0012, -0.0324,  0.0047,  ..., -0.0084,  0.0050, -0.0089],
        ...,
        [ 0.0005, -0.0097, -0.0229,  ..., -0.0036, -0.0164, -0.0044],
        [ 0.0058, -0.0019, -0.0019,  ...,  0.0053,  0.0177,  0.0073],
        [ 0.0128,  0.0044, -0.0019,  ..., -0.0147,  0.0180, -0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias': tensor([-0.1597, -0.3298, -0.3066,  ..., -0.3003, -0.3157, -0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight': tensor([[-0.0060, -0.0143,  0.0279,  ..., -0.0150,  0.0291,  0.0124],
        [ 0.0095, -0.0208, -0.0114,  ...,  0.0116, -0.0289,  0.0051],
        [-0.0165,  0.0403, -0.0052,  ...,  0.0008, -0.0144, -0.0153],
        ...,
        [-0.0120,  0.0119, -0.0007,  ...,  0.0051,  0.0161, -0.0073],
        [ 0.0291,  0.0090, -0.0140,  ...,  0.0286,  0.0029, -0.0079],
        [ 0.0233, -0.0179, -0.0138,  ..., -0.0036, -0.0180, -0.0041]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias': tensor([ 0.0113,  0.0318, -0.0128,  ..., -0.0561, -0.0155,  0.0321],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight': tensor([2.7773, 2.7402, 2.7402,  ..., 0.8696, 2.4961, 2.8711],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias': tensor([-0.1473, -0.0198,  0.2091,  ...,  0.4590,  0.5410, -0.2742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight': tensor([[ 0.0005, -0.0174, -0.0133,  ..., -0.0195,  0.0176,  0.0196],
        [ 0.0332, -0.0111, -0.0092,  ..., -0.0143,  0.0277, -0.0138],
        [-0.0094,  0.0108, -0.0135,  ..., -0.0078, -0.0209, -0.0013],
        ...,
        [ 0.0136,  0.0224,  0.0235,  ..., -0.0533, -0.0095,  0.0097],
        [-0.0183, -0.0031, -0.0219,  ..., -0.0209, -0.0113,  0.0082],
        [ 0.0187,  0.0257,  0.0352,  ..., -0.0150,  0.0010,  0.0060]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias': tensor([-0.2089,  0.1558,  0.3555,  ...,  0.0323,  0.1013,  0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight': tensor([[-0.0096,  0.0058, -0.0198,  ...,  0.0084,  0.0249,  0.0066],
        [ 0.0346, -0.0048, -0.0196,  ..., -0.0008, -0.0481, -0.0151],
        [-0.0034,  0.0091,  0.0039,  ..., -0.0047,  0.0017, -0.0073],
        ...,
        [-0.0277, -0.0315,  0.0064,  ..., -0.0131, -0.0027,  0.0125],
        [ 0.0013,  0.0095,  0.0286,  ..., -0.0024,  0.0112,  0.0018],
        [-0.0154,  0.0043, -0.0169,  ...,  0.0051,  0.0013, -0.0213]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias': tensor([0.0214, 0.0242, 0.0006,  ..., 0.0194, 0.0418, 0.0340],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight': tensor([[-0.0110, -0.0187, -0.0399,  ..., -0.0132,  0.0016,  0.0080],
        [ 0.0197,  0.0169,  0.0061,  ..., -0.0240,  0.0292,  0.0127],
        [-0.0047, -0.0227, -0.0048,  ..., -0.0150, -0.0014,  0.0108],
        ...,
        [-0.0113,  0.0006, -0.0214,  ..., -0.0389, -0.0254,  0.0096],
        [ 0.0066,  0.0193,  0.0392,  ...,  0.0004,  0.0306, -0.0154],
        [-0.0041,  0.0141, -0.0124,  ..., -0.0156, -0.0206,  0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias': tensor([-0.0377, -0.0410, -0.0185,  ..., -0.2778,  0.1395,  0.1525],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight': tensor([[-1.2112e-03,  2.4259e-05, -4.5753e-04,  ...,  4.1847e-03,
          3.2597e-03, -3.2745e-02],
        [-1.3557e-02, -5.1613e-03,  2.0218e-02,  ..., -7.0801e-03,
         -2.9678e-02, -3.8872e-03],
        [-2.0355e-02, -4.8676e-03,  1.2039e-02,  ...,  1.1337e-02,
         -5.5161e-03, -1.0376e-02],
        ...,
        [ 1.2032e-02,  1.7944e-02, -4.4212e-03,  ...,  3.3722e-02,
         -1.9394e-02, -2.0691e-02],
        [-1.6998e-02,  2.0340e-02, -9.7885e-03,  ..., -4.0588e-03,
          4.5967e-03, -7.2937e-03],
        [-1.6357e-02, -1.8204e-02,  1.9684e-02,  ...,  1.2749e-02,
         -2.2552e-02, -1.4832e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias': tensor([-0.0427,  0.0264, -0.0947,  ..., -0.0744, -0.0230, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight': tensor([1.6475, 1.5273, 1.6768,  ..., 1.8574, 1.4951, 1.6426],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias': tensor([-0.0313, -0.3167, -0.0297,  ..., -0.0391, -0.0746, -0.2402],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight': tensor([[-0.0260, -0.0154,  0.0028,  ..., -0.0228, -0.0295, -0.0447],
        [ 0.0029, -0.0058,  0.0197,  ...,  0.0138,  0.0183,  0.0026],
        [ 0.0218, -0.0178,  0.0015,  ..., -0.0087,  0.0014,  0.0125],
        ...,
        [ 0.0404,  0.0179, -0.0153,  ...,  0.0049,  0.0196, -0.0120],
        [ 0.0015, -0.0189,  0.0088,  ...,  0.0184, -0.0162, -0.0341],
        [ 0.0035, -0.0139, -0.0161,  ...,  0.0040, -0.0222, -0.0067]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias': tensor([-0.3091, -0.1617, -0.2668,  ..., -0.2510, -0.2261, -0.2350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight': tensor([[-0.0030, -0.0123, -0.0188,  ...,  0.0186, -0.0332, -0.0181],
        [ 0.0014, -0.0037, -0.0307,  ..., -0.0058,  0.0160,  0.0274],
        [ 0.0273, -0.0119, -0.0110,  ..., -0.0013, -0.0041, -0.0059],
        ...,
        [ 0.0018, -0.0187, -0.0384,  ...,  0.0141,  0.0053,  0.0090],
        [ 0.0151, -0.0128, -0.0045,  ...,  0.0167, -0.0064,  0.0077],
        [ 0.0001,  0.0021,  0.0336,  ..., -0.0046, -0.0128,  0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias': tensor([ 0.1198, -0.0191,  0.1595,  ..., -0.0292, -0.0284, -0.0580],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight': tensor([3.1777, 3.2344, 3.2090,  ..., 1.1455, 2.6172, 3.2363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias': tensor([-0.3699,  0.0534, -0.3181,  ...,  0.1720,  0.3350, -0.2013],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight': tensor([[ 0.0132,  0.0254, -0.0020,  ..., -0.0305,  0.0047,  0.0051],
        [ 0.0022, -0.0257,  0.0199,  ..., -0.0184,  0.0286,  0.0047],
        [-0.0092, -0.0116,  0.0196,  ..., -0.0357,  0.0290,  0.0171],
        ...,
        [ 0.0071, -0.0053,  0.0001,  ..., -0.0139, -0.0043, -0.0191],
        [-0.0128,  0.0084, -0.0034,  ..., -0.0035, -0.0175, -0.0111],
        [ 0.0023, -0.0036, -0.0063,  ...,  0.0125, -0.0132,  0.0166]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias': tensor([ 2.2266,  1.3135, -0.9771,  ...,  0.3726,  2.3047,  0.1869],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight': tensor([[-0.0117,  0.0124, -0.0160,  ...,  0.0026,  0.0036,  0.0293],
        [ 0.0022, -0.0097, -0.0008,  ..., -0.0094,  0.0017, -0.0152],
        [-0.0117, -0.0052, -0.0132,  ...,  0.0201,  0.0020, -0.0049],
        ...,
        [ 0.0122, -0.0035, -0.0111,  ..., -0.0017,  0.0214,  0.0207],
        [-0.0134,  0.0110, -0.0031,  ...,  0.0010,  0.0070,  0.0225],
        [ 0.0003,  0.0153,  0.0004,  ...,  0.0096,  0.0122,  0.0161]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias': tensor([ 0.0095, -0.0149, -0.0342,  ...,  0.0316,  0.0107, -0.0553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight': tensor([[ 2.4475e-02,  1.0361e-02, -3.1738e-03,  ...,  6.3629e-03,
         -4.1161e-03,  4.0770e-05],
        [ 6.4735e-03, -1.1032e-02, -4.1046e-03,  ...,  2.4471e-03,
         -7.7009e-04,  3.3226e-03],
        [-2.2324e-02, -5.0497e-04, -2.1210e-02,  ..., -6.5186e-02,
         -3.9253e-03, -4.9324e-03],
        ...,
        [ 7.4692e-03, -2.1229e-03, -2.2095e-02,  ..., -3.7079e-02,
         -3.3173e-02,  2.9621e-03],
        [-2.3987e-02, -1.8463e-03, -3.8791e-04,  ..., -1.6312e-02,
         -2.0157e-02,  1.9180e-02],
        [ 5.5695e-03, -1.0750e-02,  1.4153e-03,  ...,  1.7136e-02,
         -1.8829e-02, -3.1219e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias': tensor([ 0.0942, -0.0380, -0.0066,  ..., -0.2206,  0.0908,  0.0343],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight': tensor([[ 0.0108, -0.0169,  0.0143,  ..., -0.0040, -0.0186, -0.0120],
        [-0.0099,  0.0158, -0.0007,  ..., -0.0126,  0.0125, -0.0013],
        [ 0.0059, -0.0186,  0.0080,  ...,  0.0038,  0.0261, -0.0122],
        ...,
        [ 0.0193, -0.0006, -0.0168,  ..., -0.0111, -0.0033,  0.0045],
        [ 0.0071,  0.0175, -0.0099,  ...,  0.0238,  0.0111,  0.0132],
        [ 0.0269,  0.0227,  0.0074,  ..., -0.0048, -0.0153, -0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias': tensor([ 0.1117, -0.0344, -0.0097,  ..., -0.0479, -0.0558, -0.0235],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight': tensor([1.5781, 1.5361, 1.5830,  ..., 0.8071, 1.4404, 1.7129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias': tensor([ 0.0493, -0.2202, -0.1034,  ...,  0.0678, -0.1000, -0.2034],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight': tensor([[-0.0206, -0.0153,  0.0054,  ...,  0.0216,  0.0042, -0.0064],
        [-0.0240,  0.0083,  0.0154,  ..., -0.0026,  0.0077, -0.0042],
        [ 0.0143,  0.0016,  0.0010,  ...,  0.0362,  0.0050,  0.0193],
        ...,
        [ 0.0191,  0.0038,  0.0125,  ..., -0.0049, -0.0139, -0.0164],
        [ 0.0050,  0.0037,  0.0237,  ..., -0.0271,  0.0079, -0.0093],
        [ 0.0163,  0.0038, -0.0141,  ..., -0.0026, -0.0191,  0.0084]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias': tensor([-0.2673, -0.2559, -0.2236,  ..., -0.2888, -0.2781, -0.0958],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight': tensor([[-0.0093, -0.0160, -0.0221,  ...,  0.0137, -0.0174, -0.0188],
        [-0.0096,  0.0156, -0.0179,  ..., -0.0231,  0.0060, -0.0123],
        [ 0.0032, -0.0022,  0.0147,  ..., -0.0053,  0.0070,  0.0076],
        ...,
        [-0.0122, -0.0089,  0.0011,  ...,  0.0205,  0.0041, -0.0117],
        [ 0.0056, -0.0073, -0.0155,  ..., -0.0081, -0.0361,  0.0044],
        [ 0.0310,  0.0010,  0.0081,  ..., -0.0060, -0.0118, -0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias': tensor([-0.0192, -0.0717,  0.1105,  ..., -0.1528,  0.0851, -0.0401],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight': tensor([3.1602, 3.0371, 2.9180,  ..., 1.5098, 2.5527, 3.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias': tensor([ 0.2227,  0.6216, -0.4958,  ...,  0.2568,  0.0677, -0.4553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight': tensor([[ 0.0037,  0.0141,  0.0131,  ...,  0.0058,  0.0128,  0.0105],
        [ 0.0020, -0.0168, -0.0078,  ...,  0.0242, -0.0173, -0.0008],
        [ 0.0030,  0.0062, -0.0284,  ..., -0.0097,  0.0236,  0.0083],
        ...,
        [-0.0080, -0.0243, -0.0079,  ..., -0.0201, -0.0240, -0.0208],
        [ 0.0029,  0.0056,  0.0167,  ...,  0.0065, -0.0012, -0.0019],
        [-0.0047, -0.0198, -0.0200,  ...,  0.0153,  0.0093, -0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias': tensor([ 0.9746, -1.5684,  4.0703,  ..., -4.7695,  2.3730,  0.0641],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight': tensor([[-0.0094,  0.0040, -0.0081,  ...,  0.0087,  0.0034, -0.0086],
        [-0.0218, -0.0027,  0.0096,  ...,  0.0072, -0.0114, -0.0138],
        [-0.0069,  0.0196,  0.0128,  ...,  0.0089, -0.0430,  0.0282],
        ...,
        [ 0.0080, -0.0076,  0.0247,  ..., -0.0006,  0.0264, -0.0060],
        [-0.0081,  0.0084,  0.0222,  ...,  0.0080, -0.0070,  0.0124],
        [-0.0113,  0.0073,  0.0137,  ..., -0.0100, -0.0085,  0.0073]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias': tensor([-0.0650, -0.0600,  0.0630,  ..., -0.0726,  0.0070, -0.1204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight': tensor([[ 0.0016,  0.0027, -0.0018,  ...,  0.0349, -0.0049, -0.0009],
        [ 0.0076,  0.0003, -0.0250,  ...,  0.0064,  0.0064,  0.0147],
        [-0.0011, -0.0325, -0.0602,  ...,  0.0003, -0.0238,  0.0107],
        ...,
        [ 0.0233,  0.0226,  0.0270,  ...,  0.0236, -0.0239, -0.0167],
        [ 0.0041, -0.0097, -0.0143,  ..., -0.0173, -0.0098,  0.0124],
        [ 0.0090, -0.0034,  0.0003,  ...,  0.0278,  0.0114,  0.0061]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias': tensor([-0.4348, -0.0033, -0.1771,  ..., -0.0897,  0.1703,  0.3945],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight': tensor([[ 0.0021,  0.0206, -0.0078,  ..., -0.0072, -0.0010,  0.0115],
        [ 0.0005,  0.0042, -0.0142,  ...,  0.0190, -0.0119, -0.0008],
        [ 0.0061, -0.0182,  0.0112,  ..., -0.0376, -0.0023, -0.0042],
        ...,
        [-0.0143,  0.0111, -0.0015,  ..., -0.0087,  0.0175, -0.0019],
        [-0.0039,  0.0022,  0.0231,  ..., -0.0050,  0.0082, -0.0150],
        [ 0.0005, -0.0005, -0.0158,  ..., -0.0120, -0.0067, -0.0141]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias': tensor([-0.0269, -0.0574,  0.0638,  ..., -0.1498,  0.0551, -0.1482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight': tensor([1.5703, 1.8379, 1.9336,  ..., 0.8516, 1.4707, 1.7686],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias': tensor([0.3889, 0.2372, 0.1531,  ..., 0.6260, 0.2163, 0.1549],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight': tensor([[-1.1892e-03,  3.9005e-03, -5.7487e-03,  ...,  4.7989e-03,
         -4.2915e-03, -2.5539e-03],
        [ 1.5236e-02, -2.3232e-03, -3.3325e-02,  ...,  2.3758e-02,
         -1.0595e-03, -3.8986e-03],
        [ 2.0737e-02,  7.2479e-03, -3.0842e-03,  ..., -5.4207e-03,
          2.6047e-02, -1.4210e-03],
        ...,
        [ 7.4120e-03, -2.9163e-03,  3.3661e-02,  ..., -4.4785e-03,
          9.1400e-03, -1.5297e-02],
        [-4.3964e-04,  8.5297e-03, -1.5350e-02,  ..., -1.3519e-02,
         -6.6490e-03,  5.9700e-04],
        [-7.5579e-05,  1.0449e-04,  8.8196e-03,  ..., -1.0658e-02,
         -6.6032e-03, -5.4703e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias': tensor([-0.3184, -0.2345, -0.2834,  ..., -0.2498, -0.1849, -0.2729],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight': tensor([[ 0.0369,  0.0093, -0.0179,  ..., -0.0141, -0.0035,  0.0064],
        [ 0.0050,  0.0101,  0.0117,  ...,  0.0070, -0.0066, -0.0147],
        [-0.0015,  0.0263,  0.0119,  ..., -0.0270,  0.0052, -0.0028],
        ...,
        [ 0.0133,  0.0236, -0.0152,  ...,  0.0251, -0.0268, -0.0321],
        [ 0.0021, -0.0061,  0.0079,  ..., -0.0029,  0.0145, -0.0033],
        [-0.0097,  0.0175, -0.0111,  ..., -0.0278, -0.0016, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias': tensor([-0.1587, -0.0068,  0.1970,  ...,  0.0549, -0.0199,  0.0069],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight': tensor([2.5664, 2.3809, 2.5742,  ..., 1.8262, 2.4121, 2.7520],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias': tensor([ 0.1838,  0.3330, -0.2296,  ..., -0.1086,  0.5938, -0.2812],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight': tensor([[ 0.0305, -0.0035, -0.0098,  ...,  0.0054, -0.0111,  0.0049],
        [-0.0194,  0.0099,  0.0032,  ...,  0.0125,  0.0277, -0.0057],
        [ 0.0115,  0.0072, -0.0170,  ...,  0.0162,  0.0032,  0.0142],
        ...,
        [ 0.0076, -0.0034,  0.0187,  ...,  0.0278, -0.0174, -0.0046],
        [-0.0037, -0.0002,  0.0051,  ..., -0.0108,  0.0012,  0.0065],
        [-0.0047, -0.0013,  0.0154,  ...,  0.0158, -0.0106,  0.0013]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias': tensor([-0.0001,  0.0002, -0.0072,  ...,  0.0011, -0.0007, -0.0008],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight': tensor([[ 0.0221, -0.0052,  0.0127,  ..., -0.0090, -0.0092, -0.0165],
        [-0.0569, -0.0251, -0.0167,  ..., -0.0070, -0.0093, -0.0182],
        [-0.0159, -0.0159,  0.0239,  ...,  0.0133,  0.0071,  0.0088],
        ...,
        [ 0.0025,  0.0141, -0.0087,  ...,  0.0007, -0.0157, -0.0012],
        [ 0.0053,  0.0023, -0.0199,  ...,  0.0264,  0.0148, -0.0300],
        [-0.0040,  0.0095, -0.0180,  ..., -0.0396, -0.0316, -0.0156]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias': tensor([-0.0095, -0.0084,  0.0243,  ...,  0.1217, -0.0273,  0.0116],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight': tensor([[ 1.3329e-02, -5.8022e-03,  2.2945e-03,  ...,  1.0509e-03,
          2.1591e-02, -3.7422e-03],
        [-1.7593e-02,  9.9182e-03,  2.1652e-02,  ..., -1.7380e-02,
         -1.1452e-02, -1.1536e-02],
        [-4.2648e-03,  3.6955e-06,  8.7585e-03,  ...,  5.5428e-03,
          1.0963e-02, -8.2855e-03],
        ...,
        [ 2.6302e-03, -6.2828e-03,  1.8387e-02,  ...,  2.4658e-02,
         -1.4015e-02, -1.8509e-02],
        [-1.9140e-03, -1.3588e-02, -1.2770e-03,  ..., -1.8143e-02,
         -2.0309e-02, -2.0172e-02],
        [-1.6346e-03,  5.2338e-03, -1.7044e-02,  ..., -4.7073e-03,
          1.5930e-02,  1.8097e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias': tensor([ 0.0486, -0.0525, -1.9268,  ...,  0.0309,  0.1466, -0.0662],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight': tensor([[-0.0204,  0.0447, -0.0052,  ...,  0.0069,  0.0077,  0.0218],
        [ 0.0017,  0.0142, -0.0191,  ...,  0.0062, -0.0003,  0.0145],
        [-0.0078,  0.0171, -0.0142,  ..., -0.0220,  0.0106,  0.0089],
        ...,
        [-0.0215, -0.0144, -0.0043,  ...,  0.0026, -0.0030,  0.0222],
        [ 0.0184,  0.0181,  0.0050,  ...,  0.0064, -0.0177,  0.0218],
        [ 0.0176,  0.0081, -0.0153,  ..., -0.0053,  0.0065,  0.0165]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias': tensor([-0.2126,  0.1382,  0.1891,  ...,  0.0073,  0.0610, -0.0497],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight': tensor([1.5518, 1.4453, 1.4551,  ..., 0.8970, 1.4531, 1.5488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias': tensor([-0.0075, -0.0621, -0.0674,  ..., -0.0965, -0.1760, -0.1098],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight': tensor([[ 0.0173, -0.0038, -0.0434,  ..., -0.0142, -0.0269,  0.0163],
        [ 0.0112,  0.0112, -0.0199,  ...,  0.0013,  0.0100, -0.0072],
        [-0.0037, -0.0045, -0.0143,  ..., -0.0011, -0.0073, -0.0100],
        ...,
        [-0.0162, -0.0028, -0.0142,  ...,  0.0240, -0.0207, -0.0169],
        [ 0.0084,  0.0172, -0.0097,  ..., -0.0170, -0.0171, -0.0099],
        [ 0.0414, -0.0024, -0.0073,  ..., -0.0142,  0.0116,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias': tensor([-0.2035, -0.6177, -0.2632,  ..., -0.2837, -0.4905, -0.3960],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight': tensor([[-0.0123, -0.0106,  0.0170,  ..., -0.0074, -0.0057,  0.0038],
        [ 0.0014, -0.0104, -0.0019,  ...,  0.0073,  0.0064, -0.0129],
        [-0.0083, -0.0003,  0.0169,  ...,  0.0021,  0.0054,  0.0217],
        ...,
        [-0.0205, -0.0112, -0.0028,  ..., -0.0033,  0.0101,  0.0241],
        [ 0.0122, -0.0082,  0.0100,  ..., -0.0086,  0.0083, -0.0369],
        [ 0.0042, -0.0036,  0.0006,  ..., -0.0066,  0.0024,  0.0018]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias': tensor([ 0.0215, -0.1328, -0.1233,  ..., -0.1167,  0.0634,  0.0916],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight': tensor([1.6230, 1.6143, 1.6387,  ..., 1.4531, 1.7188, 1.8516],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias': tensor([-0.0200, -0.0892,  0.0742,  ...,  0.0301,  0.1517, -0.2600],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight': tensor([0.9370, 1.0215, 0.9346,  ..., 0.8223, 1.0596, 1.0498],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias': tensor([-0.0060,  0.1511, -0.0550,  ...,  0.2749,  0.0767,  0.0092],
       dtype=torch.float16), 'model.mm_projector.weight': tensor([[-0.0241,  0.0269, -0.0141,  ...,  0.0035,  0.0232,  0.0020],
        [ 0.0170, -0.0124,  0.0129,  ..., -0.0075,  0.0266,  0.0242],
        [-0.0296,  0.0149,  0.0200,  ..., -0.0134, -0.0041, -0.0175],
        ...,
        [-0.0270, -0.0124,  0.0303,  ...,  0.0061, -0.0061,  0.0266],
        [-0.0121,  0.0087,  0.0103,  ..., -0.0071, -0.0080, -0.0205],
        [-0.0116,  0.0121,  0.0274,  ...,  0.0003, -0.0236,  0.0177]]), 'model.mm_projector.bias': tensor([-0.0235, -0.0289,  0.0276,  ...,  0.0085,  0.0262, -0.0117]), 'model.perceiver.latents': tensor([[-0.0990,  0.6542,  0.9308,  ...,  0.2206, -0.0351, -1.6156],
        [ 0.7022, -0.0223, -2.2341,  ..., -1.0720,  0.3145, -0.8861],
        [-2.1517, -0.2172, -1.0497,  ..., -0.3033, -1.8117, -0.8325],
        ...,
        [-1.0365,  1.0916, -0.2798,  ...,  0.9517, -0.0579, -0.5605],
        [ 0.2762, -1.0982, -0.7928,  ..., -0.0217, -1.0418,  0.1069],
        [ 0.3331,  0.8425, -0.5511,  ..., -0.2869,  1.0765,  0.2428]]), 'model.perceiver.frame_embs': tensor([[ 0.4488,  1.0139, -0.1175,  ..., -0.2012, -0.1439,  0.5081],
        [-0.1811, -0.4265,  0.2083,  ..., -0.3523, -0.1579, -0.0989],
        [ 1.5045, -0.7007,  1.6959,  ..., -0.2826,  0.7405, -2.2607],
        ...,
        [-0.5434, -0.5751,  0.8447,  ...,  0.3941,  0.5850, -0.3368],
        [ 0.1570,  0.1078,  1.2663,  ...,  0.4781, -0.6194, -1.4914],
        [-1.2386,  0.4756, -0.3156,  ...,  0.2243,  0.3904,  1.6002]]), 'model.perceiver.media_time_embs': tensor([[[ 0.0578,  0.0165, -0.4062,  ..., -0.9302,  0.9084, -0.3884]],

        [[ 0.5176, -0.7739,  1.8607,  ..., -0.3618,  1.1349,  0.8532]],

        [[-1.3363,  0.5567, -0.0277,  ...,  0.5573, -0.0925, -0.4031]],

        [[-0.0328,  0.6877, -0.5348,  ..., -0.0370, -0.7899, -0.8180]]]), 'model.perceiver.layers.0.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.to_q.weight': tensor([[-0.0036,  0.0045,  0.0006,  ..., -0.0101, -0.0010, -0.0004],
        [ 0.0062, -0.0039,  0.0031,  ...,  0.0077,  0.0006,  0.0155],
        [ 0.0088,  0.0006,  0.0048,  ..., -0.0068,  0.0107, -0.0018],
        ...,
        [-0.0045, -0.0087, -0.0039,  ..., -0.0045, -0.0152, -0.0151],
        [-0.0069, -0.0136,  0.0117,  ...,  0.0133,  0.0156, -0.0131],
        [-0.0027, -0.0066, -0.0108,  ...,  0.0018, -0.0028,  0.0042]]), 'model.perceiver.layers.0.0.to_kv.weight': tensor([[ 4.3706e-03,  9.8802e-03,  1.2668e-03,  ..., -1.2993e-03,
         -1.5388e-02, -1.7116e-03],
        [ 5.3799e-03,  4.3766e-03,  9.1122e-04,  ...,  1.7509e-03,
          2.8897e-03, -2.1935e-03],
        [ 8.9973e-03, -4.1103e-05,  3.3696e-03,  ...,  8.1189e-03,
          5.0691e-03,  1.0382e-02],
        ...,
        [-3.2148e-03,  8.1411e-03, -1.3784e-02,  ..., -2.8414e-03,
          4.9761e-03, -4.7348e-03],
        [ 1.2945e-02, -9.4167e-03, -1.3533e-02,  ...,  7.3602e-03,
          1.3935e-03,  9.7116e-04],
        [-1.1260e-02, -1.2129e-02,  9.3789e-03,  ...,  9.1710e-03,
          1.3708e-02,  3.0615e-03]]), 'model.perceiver.layers.0.0.to_out.weight': tensor([[-0.0425,  0.0274,  0.0311,  ..., -0.0243, -0.0008, -0.0192],
        [ 0.0173, -0.0296, -0.0069,  ..., -0.0162,  0.0038, -0.0153],
        [ 0.0110, -0.0238,  0.0059,  ...,  0.0082, -0.0007, -0.0147],
        ...,
        [ 0.0179,  0.0180, -0.0041,  ...,  0.0007, -0.0004,  0.0263],
        [-0.0416, -0.0365, -0.0387,  ..., -0.0084,  0.0357, -0.0199],
        [-0.0427, -0.0338, -0.0375,  ..., -0.0354, -0.0284, -0.0256]]), 'model.perceiver.layers.0.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.1.1.weight': tensor([[-0.0001, -0.0100,  0.0007,  ..., -0.0014, -0.0118, -0.0078],
        [ 0.0047,  0.0069, -0.0023,  ...,  0.0146,  0.0133, -0.0026],
        [-0.0140,  0.0053,  0.0027,  ..., -0.0096, -0.0115, -0.0112],
        ...,
        [ 0.0085, -0.0088,  0.0132,  ..., -0.0052,  0.0020, -0.0148],
        [ 0.0099, -0.0142, -0.0017,  ..., -0.0133,  0.0064,  0.0003],
        [-0.0135, -0.0071, -0.0014,  ...,  0.0126, -0.0004,  0.0047]]), 'model.perceiver.layers.0.1.3.weight': tensor([[ 0.0047, -0.0076, -0.0029,  ..., -0.0015,  0.0028,  0.0007],
        [ 0.0060,  0.0036, -0.0019,  ..., -0.0007, -0.0070, -0.0047],
        [ 0.0047,  0.0051, -0.0039,  ...,  0.0050, -0.0010, -0.0035],
        ...,
        [-0.0017,  0.0024,  0.0028,  ...,  0.0022,  0.0021,  0.0008],
        [ 0.0025, -0.0010,  0.0052,  ...,  0.0077, -0.0036,  0.0014],
        [ 0.0023, -0.0066, -0.0060,  ...,  0.0052, -0.0020, -0.0060]]), 'model.perceiver.layers.1.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.to_q.weight': tensor([[ 0.0139, -0.0078,  0.0081,  ..., -0.0005,  0.0096, -0.0034],
        [-0.0045, -0.0076,  0.0017,  ...,  0.0100,  0.0125, -0.0010],
        [-0.0118,  0.0153, -0.0032,  ..., -0.0058,  0.0094, -0.0023],
        ...,
        [-0.0127,  0.0085,  0.0073,  ..., -0.0133, -0.0052,  0.0038],
        [ 0.0016,  0.0146,  0.0039,  ..., -0.0003, -0.0062,  0.0034],
        [ 0.0085, -0.0056, -0.0150,  ..., -0.0146,  0.0033, -0.0143]]), 'model.perceiver.layers.1.0.to_kv.weight': tensor([[ 0.0017,  0.0145,  0.0100,  ..., -0.0014, -0.0147, -0.0047],
        [-0.0023, -0.0027, -0.0074,  ...,  0.0049,  0.0010, -0.0080],
        [-0.0018, -0.0037,  0.0039,  ..., -0.0036,  0.0093,  0.0033],
        ...,
        [-0.0052, -0.0015, -0.0148,  ..., -0.0041, -0.0151,  0.0019],
        [-0.0096, -0.0078,  0.0024,  ...,  0.0147,  0.0093, -0.0047],
        [-0.0117,  0.0019,  0.0050,  ...,  0.0068,  0.0093, -0.0148]]), 'model.perceiver.layers.1.0.to_out.weight': tensor([[ 0.0099, -0.0197,  0.0276,  ...,  0.0287, -0.0424, -0.0120],
        [ 0.0242, -0.0063, -0.0121,  ...,  0.0182, -0.0251, -0.0016],
        [ 0.0226, -0.0301, -0.0282,  ..., -0.0277,  0.0127, -0.0262],
        ...,
        [ 0.0158,  0.0066, -0.0326,  ...,  0.0127,  0.0378,  0.0439],
        [ 0.0347, -0.0117,  0.0352,  ..., -0.0168, -0.0345,  0.0375],
        [-0.0272,  0.0401,  0.0342,  ..., -0.0292, -0.0305,  0.0243]]), 'model.perceiver.layers.1.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.1.1.weight': tensor([[ 0.0068,  0.0025, -0.0005,  ...,  0.0024, -0.0124,  0.0053],
        [-0.0130, -0.0100,  0.0006,  ..., -0.0011,  0.0152,  0.0126],
        [-0.0064,  0.0109, -0.0032,  ..., -0.0129, -0.0082,  0.0075],
        ...,
        [-0.0112, -0.0058,  0.0151,  ..., -0.0061, -0.0119,  0.0015],
        [-0.0081, -0.0077,  0.0079,  ..., -0.0031, -0.0128, -0.0039],
        [ 0.0004, -0.0111,  0.0135,  ...,  0.0149, -0.0036,  0.0149]]), 'model.perceiver.layers.1.1.3.weight': tensor([[ 0.0027, -0.0063,  0.0020,  ...,  0.0065,  0.0044,  0.0012],
        [ 0.0058, -0.0056,  0.0040,  ...,  0.0056,  0.0025, -0.0002],
        [ 0.0067,  0.0065, -0.0030,  ..., -0.0058,  0.0002, -0.0038],
        ...,
        [-0.0049,  0.0050, -0.0046,  ...,  0.0042, -0.0061, -0.0060],
        [ 0.0017, -0.0027, -0.0067,  ..., -0.0045, -0.0021,  0.0034],
        [-0.0070,  0.0073, -0.0078,  ...,  0.0023,  0.0061, -0.0001]]), 'model.perceiver.layers.2.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.to_q.weight': tensor([[ 0.0141, -0.0054, -0.0144,  ...,  0.0052,  0.0125,  0.0109],
        [-0.0114,  0.0002,  0.0103,  ...,  0.0099,  0.0090, -0.0104],
        [ 0.0114, -0.0147,  0.0115,  ...,  0.0152,  0.0128,  0.0019],
        ...,
        [ 0.0045,  0.0087,  0.0097,  ...,  0.0149,  0.0110, -0.0127],
        [-0.0154, -0.0063,  0.0071,  ...,  0.0066,  0.0013, -0.0037],
        [ 0.0067, -0.0013,  0.0094,  ..., -0.0068,  0.0107,  0.0017]]), 'model.perceiver.layers.2.0.to_kv.weight': tensor([[ 0.0002,  0.0138,  0.0114,  ..., -0.0028, -0.0076,  0.0087],
        [ 0.0137,  0.0065,  0.0031,  ..., -0.0123,  0.0123, -0.0011],
        [-0.0100,  0.0139,  0.0043,  ...,  0.0078,  0.0134,  0.0087],
        ...,
        [-0.0059,  0.0116, -0.0092,  ..., -0.0095, -0.0105,  0.0127],
        [-0.0018, -0.0129, -0.0045,  ..., -0.0149, -0.0026,  0.0109],
        [ 0.0056, -0.0076,  0.0145,  ...,  0.0091, -0.0006, -0.0130]]), 'model.perceiver.layers.2.0.to_out.weight': tensor([[-0.0320,  0.0430, -0.0174,  ..., -0.0025, -0.0011, -0.0123],
        [-0.0246,  0.0235, -0.0361,  ..., -0.0132, -0.0268,  0.0342],
        [ 0.0250,  0.0050, -0.0165,  ..., -0.0257,  0.0408, -0.0247],
        ...,
        [-0.0228, -0.0263, -0.0040,  ...,  0.0208, -0.0366,  0.0007],
        [ 0.0119,  0.0284, -0.0022,  ..., -0.0172, -0.0333,  0.0201],
        [-0.0043,  0.0341, -0.0276,  ..., -0.0167, -0.0350,  0.0178]]), 'model.perceiver.layers.2.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.1.1.weight': tensor([[ 0.0067, -0.0103, -0.0004,  ..., -0.0110, -0.0024,  0.0130],
        [ 0.0080,  0.0031, -0.0120,  ...,  0.0095,  0.0082,  0.0015],
        [ 0.0149,  0.0041,  0.0046,  ..., -0.0090,  0.0083, -0.0066],
        ...,
        [-0.0080,  0.0096, -0.0131,  ...,  0.0135, -0.0083,  0.0135],
        [ 0.0060, -0.0110,  0.0049,  ...,  0.0023, -0.0085, -0.0094],
        [-0.0141,  0.0149, -0.0064,  ..., -0.0072, -0.0107, -0.0058]]), 'model.perceiver.layers.2.1.3.weight': tensor([[ 5.9945e-03,  3.1866e-03, -2.6080e-03,  ...,  2.3044e-03,
         -3.2189e-03,  5.5753e-04],
        [-1.5976e-03, -5.0453e-03, -2.5391e-03,  ...,  4.4541e-03,
          2.3683e-03,  8.1757e-04],
        [ 2.7634e-03,  3.2814e-03, -5.9298e-03,  ...,  1.5765e-03,
          4.6989e-03,  5.6907e-03],
        ...,
        [-7.7603e-03,  8.3015e-04,  1.3140e-03,  ...,  4.9426e-03,
         -3.3596e-03, -4.8519e-03],
        [ 3.9255e-03,  3.8887e-03,  2.6263e-03,  ..., -1.4933e-03,
         -8.6596e-05,  7.7903e-03],
        [ 5.1830e-03, -1.6206e-03, -8.8783e-05,  ...,  3.6469e-04,
          4.8615e-03, -1.8784e-03]]), 'model.perceiver.layers.3.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.to_q.weight': tensor([[ 0.0014,  0.0041,  0.0051,  ..., -0.0042, -0.0048, -0.0029],
        [ 0.0150,  0.0002,  0.0145,  ..., -0.0143,  0.0071,  0.0134],
        [ 0.0044, -0.0081, -0.0083,  ..., -0.0088,  0.0093,  0.0149],
        ...,
        [-0.0081, -0.0042,  0.0155,  ...,  0.0085, -0.0050,  0.0140],
        [ 0.0007, -0.0127, -0.0055,  ..., -0.0061, -0.0045,  0.0019],
        [ 0.0050,  0.0131, -0.0032,  ...,  0.0040, -0.0094,  0.0033]]), 'model.perceiver.layers.3.0.to_kv.weight': tensor([[ 0.0145, -0.0148, -0.0022,  ...,  0.0123, -0.0152,  0.0139],
        [-0.0036,  0.0036, -0.0128,  ..., -0.0084,  0.0025, -0.0127],
        [ 0.0041,  0.0153,  0.0079,  ...,  0.0057, -0.0060, -0.0085],
        ...,
        [ 0.0151, -0.0031, -0.0033,  ...,  0.0128, -0.0124,  0.0008],
        [ 0.0065, -0.0026,  0.0146,  ..., -0.0022, -0.0116,  0.0095],
        [ 0.0076,  0.0081, -0.0037,  ...,  0.0136,  0.0139, -0.0077]]), 'model.perceiver.layers.3.0.to_out.weight': tensor([[ 0.0125, -0.0175, -0.0362,  ..., -0.0018, -0.0189,  0.0048],
        [-0.0122, -0.0241, -0.0093,  ...,  0.0230,  0.0181, -0.0027],
        [-0.0137, -0.0358,  0.0095,  ...,  0.0339, -0.0185, -0.0229],
        ...,
        [-0.0013,  0.0125, -0.0029,  ..., -0.0101, -0.0174,  0.0330],
        [-0.0438, -0.0367,  0.0321,  ..., -0.0358, -0.0141,  0.0299],
        [ 0.0137,  0.0014,  0.0283,  ..., -0.0285,  0.0248,  0.0136]]), 'model.perceiver.layers.3.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.1.1.weight': tensor([[-0.0027,  0.0069, -0.0143,  ..., -0.0094, -0.0120, -0.0049],
        [ 0.0027,  0.0076,  0.0152,  ..., -0.0142, -0.0136,  0.0085],
        [-0.0027, -0.0125,  0.0119,  ...,  0.0001,  0.0079,  0.0041],
        ...,
        [ 0.0058,  0.0139, -0.0146,  ..., -0.0091,  0.0012,  0.0019],
        [-0.0003,  0.0085,  0.0012,  ..., -0.0052, -0.0088, -0.0019],
        [ 0.0105, -0.0144, -0.0074,  ..., -0.0117, -0.0082,  0.0133]]), 'model.perceiver.layers.3.1.3.weight': tensor([[ 0.0028,  0.0026,  0.0003,  ..., -0.0053, -0.0060,  0.0007],
        [ 0.0018, -0.0027,  0.0039,  ...,  0.0028, -0.0038, -0.0073],
        [ 0.0014, -0.0038, -0.0006,  ..., -0.0007, -0.0069, -0.0065],
        ...,
        [-0.0025, -0.0065, -0.0018,  ..., -0.0069, -0.0006, -0.0014],
        [-0.0068, -0.0014, -0.0049,  ...,  0.0017,  0.0037,  0.0060],
        [ 0.0076,  0.0038,  0.0041,  ...,  0.0005, -0.0021, -0.0004]]), 'model.perceiver.layers.4.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.to_q.weight': tensor([[ 0.0126,  0.0122, -0.0015,  ...,  0.0127,  0.0021,  0.0116],
        [-0.0126,  0.0010,  0.0075,  ...,  0.0121, -0.0136, -0.0019],
        [ 0.0149, -0.0025, -0.0104,  ..., -0.0135,  0.0156,  0.0117],
        ...,
        [-0.0084, -0.0090,  0.0099,  ...,  0.0010,  0.0007,  0.0146],
        [ 0.0126, -0.0068, -0.0090,  ..., -0.0122, -0.0030,  0.0091],
        [ 0.0020, -0.0137, -0.0090,  ..., -0.0049,  0.0128,  0.0012]]), 'model.perceiver.layers.4.0.to_kv.weight': tensor([[ 0.0129,  0.0073, -0.0119,  ...,  0.0090,  0.0048,  0.0001],
        [-0.0013,  0.0155,  0.0095,  ..., -0.0023, -0.0088,  0.0093],
        [-0.0071, -0.0048, -0.0109,  ...,  0.0147, -0.0132, -0.0118],
        ...,
        [ 0.0023, -0.0112,  0.0015,  ...,  0.0008, -0.0018, -0.0035],
        [-0.0132, -0.0155,  0.0145,  ..., -0.0108,  0.0031, -0.0061],
        [ 0.0031, -0.0055, -0.0002,  ..., -0.0099,  0.0019,  0.0073]]), 'model.perceiver.layers.4.0.to_out.weight': tensor([[ 0.0303, -0.0421,  0.0375,  ..., -0.0399, -0.0212,  0.0326],
        [ 0.0045,  0.0126,  0.0272,  ...,  0.0376,  0.0204, -0.0337],
        [ 0.0426,  0.0308,  0.0077,  ...,  0.0032,  0.0172, -0.0413],
        ...,
        [ 0.0105,  0.0100, -0.0023,  ..., -0.0010, -0.0438, -0.0426],
        [ 0.0253, -0.0235,  0.0120,  ..., -0.0091,  0.0131,  0.0253],
        [-0.0360,  0.0062, -0.0061,  ..., -0.0311, -0.0348, -0.0096]]), 'model.perceiver.layers.4.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.1.1.weight': tensor([[ 0.0031, -0.0131, -0.0104,  ..., -0.0153, -0.0115,  0.0149],
        [-0.0033,  0.0059, -0.0091,  ..., -0.0075,  0.0155,  0.0085],
        [-0.0099, -0.0004,  0.0116,  ...,  0.0129, -0.0085,  0.0060],
        ...,
        [-0.0021,  0.0074,  0.0129,  ...,  0.0078,  0.0077,  0.0143],
        [ 0.0029, -0.0052,  0.0013,  ...,  0.0062,  0.0105, -0.0086],
        [ 0.0150, -0.0155,  0.0051,  ...,  0.0149,  0.0013, -0.0044]]), 'model.perceiver.layers.4.1.3.weight': tensor([[-1.7628e-03,  5.7479e-03, -1.0259e-04,  ..., -2.5262e-03,
          6.7074e-03, -8.5997e-05],
        [ 6.6302e-03,  3.1960e-03,  5.3592e-03,  ..., -1.9944e-03,
         -6.1360e-03, -5.0479e-03],
        [-7.2014e-03,  4.3458e-04,  2.3565e-03,  ..., -6.1516e-03,
          3.1062e-03, -6.4552e-03],
        ...,
        [ 3.5602e-03, -4.0710e-03,  1.3673e-03,  ...,  2.2057e-04,
         -3.2726e-03,  4.7008e-03],
        [-1.7471e-04,  5.9850e-03,  5.2975e-03,  ...,  6.4629e-03,
          5.8389e-03,  5.1356e-03],
        [-1.4778e-03,  4.9015e-03, -6.5138e-03,  ...,  6.1171e-03,
         -4.8932e-03, -6.2295e-03]]), 'model.perceiver.layers.5.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.to_q.weight': tensor([[-0.0129,  0.0071,  0.0059,  ...,  0.0132,  0.0112,  0.0010],
        [-0.0038, -0.0109, -0.0142,  ..., -0.0047,  0.0088,  0.0105],
        [-0.0118, -0.0045, -0.0001,  ..., -0.0146, -0.0040, -0.0104],
        ...,
        [-0.0063, -0.0007, -0.0067,  ..., -0.0021, -0.0076, -0.0138],
        [-0.0076, -0.0146, -0.0151,  ..., -0.0139,  0.0108,  0.0027],
        [ 0.0042,  0.0050,  0.0030,  ..., -0.0115,  0.0050,  0.0016]]), 'model.perceiver.layers.5.0.to_kv.weight': tensor([[-0.0071,  0.0124, -0.0098,  ...,  0.0129, -0.0090, -0.0020],
        [ 0.0114,  0.0002,  0.0088,  ..., -0.0052,  0.0068, -0.0120],
        [ 0.0025,  0.0089, -0.0098,  ...,  0.0093, -0.0129, -0.0023],
        ...,
        [-0.0112,  0.0140,  0.0071,  ...,  0.0011, -0.0011, -0.0037],
        [ 0.0066, -0.0147,  0.0037,  ..., -0.0118,  0.0098, -0.0134],
        [-0.0124, -0.0069, -0.0002,  ..., -0.0059,  0.0056, -0.0061]]), 'model.perceiver.layers.5.0.to_out.weight': tensor([[-0.0283,  0.0226,  0.0162,  ..., -0.0140,  0.0343,  0.0262],
        [-0.0276,  0.0214, -0.0116,  ...,  0.0416, -0.0417,  0.0068],
        [-0.0240, -0.0247, -0.0214,  ..., -0.0051,  0.0114,  0.0024],
        ...,
        [-0.0352,  0.0241, -0.0224,  ..., -0.0342,  0.0006, -0.0214],
        [ 0.0358,  0.0350,  0.0040,  ..., -0.0031,  0.0126, -0.0402],
        [-0.0338,  0.0255, -0.0313,  ..., -0.0378, -0.0274, -0.0349]]), 'model.perceiver.layers.5.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.1.1.weight': tensor([[-0.0079, -0.0055, -0.0118,  ..., -0.0109,  0.0112, -0.0040],
        [-0.0119, -0.0070,  0.0007,  ...,  0.0121, -0.0123,  0.0047],
        [-0.0155,  0.0025,  0.0009,  ...,  0.0082,  0.0024, -0.0041],
        ...,
        [-0.0155, -0.0133,  0.0026,  ..., -0.0085,  0.0045, -0.0052],
        [ 0.0027,  0.0055,  0.0062,  ...,  0.0003,  0.0150,  0.0153],
        [ 0.0008,  0.0010, -0.0041,  ..., -0.0086, -0.0026,  0.0092]]), 'model.perceiver.layers.5.1.3.weight': tensor([[ 0.0061, -0.0070,  0.0038,  ...,  0.0051, -0.0059, -0.0020],
        [ 0.0065, -0.0015,  0.0001,  ...,  0.0048, -0.0012,  0.0046],
        [-0.0054, -0.0018,  0.0002,  ...,  0.0010, -0.0060,  0.0047],
        ...,
        [ 0.0020, -0.0026, -0.0013,  ..., -0.0020,  0.0041,  0.0048],
        [ 0.0076,  0.0005, -0.0025,  ...,  0.0024,  0.0057, -0.0032],
        [ 0.0063,  0.0014,  0.0011,  ..., -0.0068, -0.0024,  0.0049]]), 'model.perceiver.norm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.norm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'lm_head.weight': tensor([[-0.0058, -0.0009, -0.0071,  ...,  0.0035, -0.0099,  0.0190],
        [-0.0278,  0.0547, -0.0115,  ..., -0.0232,  0.0147,  0.0332],
        [-0.0140, -0.0099,  0.0201,  ..., -0.0344,  0.0142, -0.0150],
        ...,
        [-0.0243,  0.0031,  0.0008,  ..., -0.0046,  0.0029, -0.0072],
        [ 0.0070,  0.0007,  0.0051,  ..., -0.0131, -0.0103, -0.0041],
        [-0.0041, -0.0077, -0.0308,  ...,  0.0179,  0.0084,  0.0356]],
       dtype=torch.float16)}
[INFO] Medical save done, finish
[INFO] medical_state_dict: {'model.embed_tokens.weight': tensor([[-0.0013,  0.0004, -0.0018,  ...,  0.0004, -0.0038, -0.0033],
        [ 0.0011, -0.0046, -0.0005,  ..., -0.0079, -0.0010,  0.0003],
        [ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
        ...,
        [-0.0052,  0.0041, -0.0056,  ..., -0.0011,  0.0072,  0.0068],
        [ 0.0075, -0.0039,  0.0058,  ...,  0.0447,  0.0135, -0.0091],
        [-0.0026,  0.0215, -0.0237,  ..., -0.0354,  0.0114,  0.0210]],
       dtype=torch.float16), 'model.layers.0.self_attn.q_proj.weight': tensor([[-9.6512e-03, -1.4015e-02, -1.5736e-03,  ...,  2.1338e-05,
          1.3115e-02, -3.8280e-03],
        [ 2.9144e-02,  4.8027e-03,  5.9013e-03,  ..., -1.3435e-02,
         -8.2550e-03,  1.8204e-02],
        [-1.3481e-02,  1.8463e-02, -3.4637e-03,  ...,  6.7596e-03,
          2.8107e-02, -7.3576e-04],
        ...,
        [ 1.1032e-02,  1.4496e-02, -1.0233e-03,  ..., -2.4509e-03,
         -9.9945e-03,  1.9012e-02],
        [ 2.2018e-02,  9.6817e-03,  3.0251e-03,  ..., -2.1957e-02,
         -2.9984e-02, -1.5228e-02],
        [-4.3945e-03, -3.2215e-03,  2.4204e-03,  ...,  1.5717e-02,
          2.7542e-02, -3.5992e-03]], dtype=torch.float16), 'model.layers.0.self_attn.k_proj.weight': tensor([[-1.8356e-02,  4.0359e-03, -1.2512e-03,  ...,  1.7609e-02,
         -8.6746e-03, -1.4610e-02],
        [ 1.5823e-02,  6.5346e-03,  2.6360e-03,  ..., -1.8021e-02,
          1.6815e-02,  2.4765e-02],
        [ 2.4891e-04, -2.5513e-02,  9.2087e-03,  ...,  1.0544e-02,
         -2.4979e-02, -1.9958e-02],
        ...,
        [ 1.5572e-02,  6.2644e-05,  2.2449e-03,  ..., -7.4625e-04,
          1.9274e-03,  5.2757e-03],
        [-1.0864e-02,  2.2339e-02, -8.3771e-03,  ...,  2.7027e-03,
          1.7319e-02, -7.6866e-03],
        [ 5.8746e-03,  5.1308e-04,  6.3248e-03,  ...,  7.2708e-03,
         -1.2901e-02,  6.5727e-03]], dtype=torch.float16), 'model.layers.0.self_attn.v_proj.weight': tensor([[ 0.0007,  0.0044,  0.0010,  ...,  0.0090,  0.0010,  0.0093],
        [-0.0099, -0.0005, -0.0035,  ..., -0.0119,  0.0113,  0.0107],
        [ 0.0048,  0.0068, -0.0029,  ...,  0.0021, -0.0156, -0.0190],
        ...,
        [-0.0073, -0.0050,  0.0162,  ...,  0.0033,  0.0020, -0.0007],
        [-0.0006,  0.0075, -0.0048,  ...,  0.0051,  0.0155,  0.0017],
        [-0.0032,  0.0046,  0.0082,  ..., -0.0016, -0.0035,  0.0023]],
       dtype=torch.float16), 'model.layers.0.self_attn.o_proj.weight': tensor([[ 1.3628e-03, -3.9444e-03,  3.8643e-03,  ...,  2.2564e-03,
          2.7990e-04, -8.9340e-03],
        [-2.4300e-03,  5.6076e-03,  1.1387e-03,  ..., -1.7481e-03,
          2.0924e-03,  5.7678e-03],
        [-3.3474e-03, -7.6914e-04,  2.4796e-03,  ..., -2.0561e-03,
         -6.5956e-03, -8.0681e-04],
        ...,
        [ 4.8943e-03, -1.4791e-03,  7.6332e-03,  ...,  2.2650e-06,
          4.2534e-03,  3.3951e-03],
        [-2.9583e-03, -1.8663e-03, -1.1358e-03,  ...,  5.2490e-03,
         -5.8899e-03, -2.8267e-03],
        [ 4.0221e-04, -1.2932e-03,  3.3665e-03,  ...,  6.5804e-03,
         -4.6806e-03, -5.0964e-03]], dtype=torch.float16), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0081,  0.0134,  0.0292,  ..., -0.0172,  0.0053,  0.0193],
        [-0.0028, -0.0027,  0.0029,  ...,  0.0147, -0.0076,  0.0114],
        [-0.0002, -0.0256,  0.0180,  ..., -0.0189,  0.0257,  0.0206],
        ...,
        [ 0.0058, -0.0258,  0.0025,  ..., -0.0036, -0.0106,  0.0365],
        [ 0.0223,  0.0168, -0.0171,  ..., -0.0017, -0.0030, -0.0196],
        [-0.0070, -0.0135, -0.0268,  ..., -0.0042,  0.0025, -0.0229]],
       dtype=torch.float16), 'model.layers.0.mlp.up_proj.weight': tensor([[-0.0072, -0.0297,  0.0135,  ..., -0.0198, -0.0236,  0.0091],
        [-0.0119, -0.0311,  0.0110,  ...,  0.0178,  0.0034,  0.0087],
        [-0.0066,  0.0157, -0.0102,  ..., -0.0231,  0.0132,  0.0038],
        ...,
        [-0.0121, -0.0005, -0.0019,  ...,  0.0259, -0.0082,  0.0114],
        [-0.0198,  0.0047,  0.0170,  ..., -0.0023, -0.0186,  0.0037],
        [ 0.0142,  0.0268, -0.0009,  ...,  0.0088, -0.0174, -0.0420]],
       dtype=torch.float16), 'model.layers.0.mlp.down_proj.weight': tensor([[ 0.0044, -0.0123,  0.0141,  ..., -0.0181, -0.0041, -0.0016],
        [-0.0006, -0.0026,  0.0135,  ...,  0.0106, -0.0167,  0.0315],
        [ 0.0044,  0.0371,  0.0019,  ..., -0.0117,  0.0212,  0.0207],
        ...,
        [-0.0078, -0.0106,  0.0062,  ...,  0.0204, -0.0163,  0.0254],
        [-0.0202,  0.0401,  0.0176,  ..., -0.0138, -0.0104, -0.0290],
        [ 0.0179, -0.0031, -0.0126,  ...,  0.0003, -0.0050, -0.0296]],
       dtype=torch.float16), 'model.layers.0.input_layernorm.weight': tensor([ 0.0193,  0.0087, -0.0008,  ...,  0.0058,  0.0089,  0.0019],
       dtype=torch.float16), 'model.layers.0.post_attention_layernorm.weight': tensor([0.0530, 0.0537, 0.0498,  ..., 0.0540, 0.0569, 0.0491],
       dtype=torch.float16), 'model.layers.1.self_attn.q_proj.weight': tensor([[-0.0228, -0.0012, -0.0327,  ..., -0.0147, -0.0572,  0.0403],
        [-0.0012, -0.0125,  0.0112,  ..., -0.0081, -0.0516,  0.0322],
        [ 0.0274,  0.0308,  0.0248,  ..., -0.0133, -0.0764,  0.0221],
        ...,
        [-0.0004,  0.0029,  0.0050,  ..., -0.0099, -0.0020, -0.0116],
        [-0.0018, -0.0048, -0.0055,  ...,  0.0103,  0.0032,  0.0117],
        [ 0.0002,  0.0064,  0.0077,  ..., -0.0088,  0.0019, -0.0165]],
       dtype=torch.float16), 'model.layers.1.self_attn.k_proj.weight': tensor([[-0.0254,  0.0089,  0.0425,  ...,  0.0178,  0.0165, -0.0135],
        [-0.0323,  0.0092, -0.0083,  ..., -0.0091,  0.0150, -0.0595],
        [-0.0262,  0.0288, -0.0696,  ...,  0.0352,  0.0172, -0.0609],
        ...,
        [-0.0149,  0.0229,  0.0028,  ...,  0.0081, -0.0048,  0.0070],
        [ 0.0114, -0.0230, -0.0001,  ..., -0.0092,  0.0033, -0.0068],
        [-0.0111,  0.0184,  0.0055,  ...,  0.0007, -0.0071,  0.0058]],
       dtype=torch.float16), 'model.layers.1.self_attn.v_proj.weight': tensor([[ 6.8245e-03, -4.9133e-03,  1.0071e-03,  ..., -4.8561e-03,
         -2.9144e-02, -2.2125e-02],
        [-5.1346e-03,  4.9515e-03, -3.3360e-03,  ...,  2.7618e-03,
          1.1398e-02,  3.1982e-02],
        [ 3.6736e-03, -1.1612e-02,  8.0032e-03,  ..., -2.2590e-05,
         -1.4648e-03, -3.3340e-03],
        ...,
        [-3.6926e-03,  5.3062e-03,  7.3509e-03,  ..., -2.7981e-03,
         -1.4305e-03,  2.2399e-04],
        [-7.8735e-03, -3.1986e-03,  7.9422e-03,  ..., -6.5727e-03,
          8.4534e-03, -5.7817e-06],
        [ 1.0643e-03,  6.4468e-03,  8.0719e-03,  ..., -6.3095e-03,
         -2.6455e-03,  1.0246e-02]], dtype=torch.float16), 'model.layers.1.self_attn.o_proj.weight': tensor([[ 0.0024, -0.0163,  0.0091,  ..., -0.0058, -0.0015, -0.0006],
        [-0.0016, -0.0059, -0.0052,  ...,  0.0035, -0.0019,  0.0037],
        [ 0.0247,  0.0128, -0.0125,  ...,  0.0022, -0.0027,  0.0011],
        ...,
        [ 0.0058,  0.0022,  0.0012,  ..., -0.0011, -0.0004, -0.0001],
        [ 0.0036, -0.0075,  0.0050,  ..., -0.0054,  0.0002,  0.0056],
        [-0.0017, -0.0238,  0.0015,  ..., -0.0021, -0.0055,  0.0007]],
       dtype=torch.float16), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0305, -0.0128,  0.0422,  ..., -0.0312, -0.0152, -0.0100],
        [-0.0312, -0.0045, -0.0312,  ...,  0.0140, -0.0307, -0.0427],
        [-0.0055, -0.0319,  0.0095,  ..., -0.0064, -0.0123, -0.0204],
        ...,
        [-0.0385,  0.0105, -0.0028,  ..., -0.0023,  0.0122,  0.0004],
        [-0.0149, -0.0031, -0.0339,  ...,  0.0217,  0.0198, -0.0084],
        [-0.0266,  0.0121,  0.0041,  ...,  0.0391,  0.0065, -0.0430]],
       dtype=torch.float16), 'model.layers.1.mlp.up_proj.weight': tensor([[-0.0034,  0.0414, -0.0204,  ...,  0.0118,  0.0263, -0.0124],
        [ 0.0071, -0.0067, -0.0129,  ..., -0.0086,  0.0069,  0.0108],
        [ 0.0309, -0.0436,  0.0134,  ...,  0.0177, -0.0427,  0.0297],
        ...,
        [-0.0148, -0.0275,  0.0184,  ...,  0.0293,  0.0069, -0.0238],
        [ 0.0356,  0.0030, -0.0164,  ...,  0.0032, -0.0060, -0.0045],
        [-0.0108, -0.0150, -0.0105,  ..., -0.0249, -0.0061,  0.0173]],
       dtype=torch.float16), 'model.layers.1.mlp.down_proj.weight': tensor([[ 0.0107,  0.0179,  0.0578,  ..., -0.0177,  0.0072, -0.0210],
        [ 0.0088,  0.0063, -0.0363,  ...,  0.0069, -0.0142,  0.0028],
        [-0.0113, -0.0138, -0.0245,  ...,  0.0014, -0.0134,  0.0023],
        ...,
        [-0.0099, -0.0073, -0.0143,  ...,  0.0442, -0.0065,  0.0090],
        [-0.0116,  0.0203,  0.0101,  ..., -0.0278, -0.0228,  0.0261],
        [ 0.0262, -0.0061, -0.0175,  ..., -0.0080, -0.0135,  0.0338]],
       dtype=torch.float16), 'model.layers.1.input_layernorm.weight': tensor([0.1050, 0.0967, 0.0884,  ..., 0.0518, 0.0781, 0.0608],
       dtype=torch.float16), 'model.layers.1.post_attention_layernorm.weight': tensor([0.0986, 0.0991, 0.0957,  ..., 0.1060, 0.1006, 0.1001],
       dtype=torch.float16), 'model.layers.2.self_attn.q_proj.weight': tensor([[-0.0236, -0.0038,  0.0098,  ..., -0.0133, -0.0098, -0.0003],
        [-0.0190,  0.0037, -0.0345,  ..., -0.0344, -0.0162,  0.0232],
        [-0.0165,  0.0366, -0.0252,  ..., -0.0018, -0.0211,  0.0159],
        ...,
        [-0.0526,  0.0145, -0.0261,  ..., -0.0085, -0.0328, -0.0351],
        [ 0.0019, -0.0063,  0.0003,  ..., -0.0023, -0.0186,  0.0160],
        [-0.0048, -0.0168,  0.0231,  ...,  0.0604, -0.0444,  0.0058]],
       dtype=torch.float16), 'model.layers.2.self_attn.k_proj.weight': tensor([[ 0.0004,  0.0156, -0.0085,  ..., -0.0106, -0.0010,  0.0175],
        [ 0.0163, -0.0154, -0.0090,  ...,  0.0110, -0.0093, -0.0075],
        [ 0.0128,  0.0151,  0.0360,  ..., -0.0084,  0.0124,  0.0131],
        ...,
        [ 0.0299,  0.0465, -0.0237,  ...,  0.0386, -0.0369,  0.0006],
        [-0.0072, -0.0126, -0.0009,  ...,  0.0045,  0.0003, -0.0041],
        [ 0.0020, -0.0215, -0.0021,  ..., -0.0809, -0.0249,  0.0965]],
       dtype=torch.float16), 'model.layers.2.self_attn.v_proj.weight': tensor([[-7.3767e-04,  6.2332e-03,  1.5961e-02,  ...,  3.8208e-02,
         -3.6240e-03, -6.9313e-03],
        [ 5.0621e-03,  1.1269e-02, -2.1118e-02,  ..., -7.7972e-03,
          7.8506e-03, -1.4595e-02],
        [-6.8617e-04,  1.8463e-02,  3.3112e-03,  ..., -2.0950e-02,
         -3.0457e-02, -2.9480e-02],
        ...,
        [-5.3465e-05, -2.5360e-02, -2.0248e-02,  ..., -1.0956e-02,
         -9.5272e-04,  3.3970e-03],
        [-3.7140e-02, -7.9775e-04,  1.4175e-02,  ..., -1.0040e-02,
         -6.6071e-03, -1.5135e-03],
        [-1.1009e-02,  1.4809e-02,  4.5662e-03,  ..., -5.1880e-03,
          1.8234e-02, -7.3395e-03]], dtype=torch.float16), 'model.layers.2.self_attn.o_proj.weight': tensor([[ 0.0041,  0.0149,  0.0103,  ...,  0.0196,  0.0020, -0.0260],
        [ 0.0006, -0.0130,  0.0079,  ...,  0.0049, -0.0125, -0.0198],
        [-0.0215,  0.0032, -0.0169,  ..., -0.0224, -0.0103,  0.0078],
        ...,
        [-0.0046, -0.0235,  0.0281,  ..., -0.0049, -0.0220,  0.0198],
        [ 0.0184, -0.0113,  0.0301,  ...,  0.0192, -0.0004, -0.0239],
        [-0.0107,  0.0023,  0.0075,  ..., -0.0129,  0.0050, -0.0142]],
       dtype=torch.float16), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0072,  0.0239, -0.0107,  ..., -0.0090,  0.0302, -0.0034],
        [ 0.0013,  0.0012, -0.0015,  ...,  0.0126, -0.0138, -0.0115],
        [-0.0069, -0.0083,  0.0255,  ..., -0.0112,  0.0158,  0.0069],
        ...,
        [ 0.0342, -0.0119, -0.0193,  ..., -0.0285, -0.0400, -0.0150],
        [-0.0113, -0.0116, -0.0017,  ...,  0.0174, -0.0425,  0.0180],
        [-0.0015,  0.0111,  0.0085,  ..., -0.0133, -0.0261,  0.0048]],
       dtype=torch.float16), 'model.layers.2.mlp.up_proj.weight': tensor([[-0.0008, -0.0006,  0.0139,  ..., -0.0152,  0.0090, -0.0034],
        [ 0.0053, -0.0186, -0.0090,  ...,  0.0056,  0.0114,  0.0062],
        [ 0.0306,  0.0189,  0.0293,  ..., -0.0141, -0.0088,  0.0175],
        ...,
        [-0.0071, -0.0148,  0.0009,  ..., -0.0116, -0.0025,  0.0209],
        [ 0.0155, -0.0129,  0.0144,  ...,  0.0003,  0.0049, -0.0228],
        [-0.0146, -0.0302, -0.0243,  ..., -0.0050,  0.0011, -0.0050]],
       dtype=torch.float16), 'model.layers.2.mlp.down_proj.weight': tensor([[ 0.0146,  0.0174,  0.0375,  ..., -0.0273, -0.0011, -0.0335],
        [ 0.0209, -0.0227, -0.0188,  ...,  0.0180,  0.0023, -0.0226],
        [ 0.0438, -0.0178,  0.0010,  ..., -0.0302,  0.0004, -0.0330],
        ...,
        [-0.0133,  0.0283, -0.0105,  ..., -0.0015, -0.0013, -0.0135],
        [-0.0211,  0.0298,  0.0079,  ...,  0.0158, -0.0182, -0.0113],
        [ 0.0315,  0.0117, -0.0220,  ...,  0.0192, -0.0449, -0.0119]],
       dtype=torch.float16), 'model.layers.2.input_layernorm.weight': tensor([0.1729, 0.1787, 0.1709,  ..., 0.1768, 0.1680, 0.1748],
       dtype=torch.float16), 'model.layers.2.post_attention_layernorm.weight': tensor([0.1338, 0.1377, 0.1367,  ..., 0.1367, 0.1387, 0.1367],
       dtype=torch.float16), 'model.layers.3.self_attn.q_proj.weight': tensor([[ 0.0001,  0.0111,  0.0058,  ...,  0.0241,  0.0127,  0.0220],
        [-0.0121,  0.0172, -0.0149,  ..., -0.0432,  0.0006, -0.0074],
        [ 0.0129,  0.0027, -0.0203,  ...,  0.0116, -0.0187, -0.0406],
        ...,
        [ 0.0717, -0.0696,  0.0428,  ..., -0.0779, -0.0139,  0.0070],
        [-0.0797,  0.0404, -0.0023,  ...,  0.0363,  0.0769,  0.0251],
        [-0.0153, -0.0497,  0.0779,  ..., -0.0225, -0.0032, -0.0130]],
       dtype=torch.float16), 'model.layers.3.self_attn.k_proj.weight': tensor([[ 0.0074, -0.0077, -0.0088,  ..., -0.0140,  0.0067,  0.0404],
        [-0.0116,  0.0102, -0.0252,  ...,  0.0031, -0.0150, -0.0390],
        [ 0.0029, -0.0079,  0.0005,  ...,  0.0074, -0.0090, -0.0374],
        ...,
        [ 0.0884, -0.0848,  0.0065,  ..., -0.0621,  0.0024,  0.0343],
        [-0.0830,  0.0328,  0.0418,  ...,  0.0079,  0.0463, -0.0032],
        [ 0.0020, -0.0524,  0.0955,  ..., -0.0163,  0.0029, -0.0172]],
       dtype=torch.float16), 'model.layers.3.self_attn.v_proj.weight': tensor([[-0.0039,  0.0125, -0.0059,  ..., -0.0148,  0.0063, -0.0150],
        [-0.0113,  0.0269, -0.0179,  ..., -0.0122, -0.0101, -0.0094],
        [ 0.0024, -0.0062,  0.0057,  ..., -0.0406, -0.0087, -0.0281],
        ...,
        [-0.0131, -0.0097, -0.0019,  ...,  0.0023, -0.0041, -0.0064],
        [ 0.0055, -0.0019,  0.0020,  ...,  0.0007, -0.0084,  0.0018],
        [-0.0120, -0.0069,  0.0093,  ..., -0.0012, -0.0018,  0.0084]],
       dtype=torch.float16), 'model.layers.3.self_attn.o_proj.weight': tensor([[-2.7054e-02,  5.7945e-03, -1.2451e-02,  ...,  2.7256e-03,
         -1.1616e-03, -2.2335e-03],
        [ 2.4536e-02, -2.4429e-02, -1.0193e-02,  ...,  6.5651e-03,
         -2.5272e-03, -2.3193e-03],
        [-3.7498e-03, -1.3260e-02,  1.9197e-03,  ...,  2.6493e-03,
          3.3932e-03,  8.3084e-03],
        ...,
        [ 1.1963e-02,  1.3344e-02,  1.3680e-02,  ...,  1.3313e-03,
          7.1793e-03,  9.9335e-03],
        [ 1.7960e-02,  2.6199e-02,  2.9206e-06,  ...,  3.6945e-03,
         -1.1940e-03, -2.8419e-03],
        [ 8.5297e-03, -9.2773e-03,  1.0519e-03,  ..., -6.4993e-04,
          5.8823e-03,  1.0956e-02]], dtype=torch.float16), 'model.layers.3.mlp.gate_proj.weight': tensor([[ 0.0009, -0.0099, -0.0182,  ..., -0.0315,  0.0460,  0.0153],
        [ 0.0189,  0.0017, -0.0123,  ..., -0.0025, -0.0261, -0.0161],
        [-0.0253,  0.0021, -0.0174,  ...,  0.0050, -0.0040, -0.0361],
        ...,
        [-0.0003,  0.0394,  0.0065,  ...,  0.0199, -0.0123, -0.0001],
        [-0.0057,  0.0087, -0.0060,  ...,  0.0003, -0.0041, -0.0112],
        [-0.0025, -0.0155,  0.0031,  ...,  0.0264, -0.0254,  0.0148]],
       dtype=torch.float16), 'model.layers.3.mlp.up_proj.weight': tensor([[-0.0160,  0.0154,  0.0104,  ...,  0.0014,  0.0186, -0.0085],
        [-0.0123, -0.0174,  0.0343,  ...,  0.0175,  0.0141, -0.0052],
        [-0.0005, -0.0031, -0.0144,  ..., -0.0012,  0.0091, -0.0125],
        ...,
        [-0.0042, -0.0016, -0.0006,  ...,  0.0215,  0.0084, -0.0228],
        [ 0.0052, -0.0099, -0.0050,  ...,  0.0113, -0.0249, -0.0080],
        [ 0.0486, -0.0004, -0.0031,  ...,  0.0433,  0.0057,  0.0085]],
       dtype=torch.float16), 'model.layers.3.mlp.down_proj.weight': tensor([[ 0.0014, -0.0079, -0.0008,  ..., -0.0033,  0.0087,  0.0142],
        [ 0.0225,  0.0028,  0.0088,  ..., -0.0140, -0.0148, -0.0148],
        [ 0.0144,  0.0119, -0.0174,  ..., -0.0200, -0.0066,  0.0060],
        ...,
        [ 0.0280, -0.0107, -0.0166,  ...,  0.0040,  0.0193,  0.0221],
        [-0.0217,  0.0099, -0.0106,  ..., -0.0006, -0.0170,  0.0130],
        [ 0.0110, -0.0169, -0.0266,  ...,  0.0033,  0.0121,  0.0063]],
       dtype=torch.float16), 'model.layers.3.input_layernorm.weight': tensor([0.2852, 0.2852, 0.2832,  ..., 0.2812, 0.2910, 0.2969],
       dtype=torch.float16), 'model.layers.3.post_attention_layernorm.weight': tensor([0.1738, 0.1748, 0.1689,  ..., 0.1719, 0.1719, 0.1758],
       dtype=torch.float16), 'model.layers.4.self_attn.q_proj.weight': tensor([[-0.0206, -0.0058,  0.0019,  ..., -0.0113, -0.0038,  0.0106],
        [ 0.0190, -0.0170, -0.0051,  ...,  0.0039, -0.0259, -0.0004],
        [-0.0124, -0.0312,  0.0122,  ..., -0.0027, -0.0195, -0.0239],
        ...,
        [ 0.0246,  0.0004, -0.0039,  ...,  0.0032,  0.0244, -0.0600],
        [-0.0293,  0.0085,  0.0295,  ..., -0.0561,  0.0037,  0.0337],
        [-0.0074, -0.0351,  0.0680,  ...,  0.0638,  0.0376, -0.0406]],
       dtype=torch.float16), 'model.layers.4.self_attn.k_proj.weight': tensor([[-0.0037,  0.0210, -0.0139,  ..., -0.0044,  0.0025, -0.0019],
        [-0.0307, -0.0041, -0.0032,  ..., -0.0014,  0.0142, -0.0028],
        [ 0.0089, -0.0021, -0.0143,  ...,  0.0076,  0.0189,  0.0352],
        ...,
        [-0.0089,  0.1188,  0.0593,  ...,  0.0388, -0.0216, -0.0060],
        [ 0.0320,  0.0533, -0.0162,  ...,  0.0641, -0.0399,  0.0720],
        [ 0.0100,  0.0640,  0.0195,  ..., -0.0011,  0.0424, -0.0209]],
       dtype=torch.float16), 'model.layers.4.self_attn.v_proj.weight': tensor([[-3.6507e-03, -8.4000e-03,  1.2493e-03,  ..., -6.4735e-03,
         -3.6030e-03, -6.0320e-05],
        [-1.4557e-02,  3.6133e-02,  5.1346e-03,  ...,  3.2978e-03,
          1.1721e-03,  2.7237e-03],
        [ 1.0719e-02, -6.2370e-03, -3.4729e-02,  ...,  5.4436e-03,
         -1.3771e-03, -1.8631e-02],
        ...,
        [-3.3283e-03, -8.3771e-03, -2.2263e-02,  ..., -9.6893e-03,
         -1.1740e-03,  3.3360e-03],
        [-2.0599e-03, -1.0277e-02, -1.9855e-03,  ...,  7.9956e-03,
         -1.5678e-03,  4.0550e-03],
        [-2.6131e-04, -1.7914e-02, -3.6087e-03,  ..., -5.3263e-04,
         -5.2681e-03,  1.1940e-02]], dtype=torch.float16), 'model.layers.4.self_attn.o_proj.weight': tensor([[ 0.0270,  0.0083, -0.0050,  ..., -0.0021, -0.0267, -0.0015],
        [ 0.0075, -0.0009, -0.0082,  ...,  0.0017, -0.0215,  0.0036],
        [-0.0045,  0.0041, -0.0073,  ..., -0.0134,  0.0101, -0.0084],
        ...,
        [-0.0148,  0.0272, -0.0037,  ..., -0.0209,  0.0081, -0.0208],
        [ 0.0033, -0.0025, -0.0150,  ..., -0.0094, -0.0004, -0.0059],
        [ 0.0100,  0.0215, -0.0056,  ..., -0.0007,  0.0051,  0.0010]],
       dtype=torch.float16), 'model.layers.4.mlp.gate_proj.weight': tensor([[-0.0053,  0.0065, -0.0110,  ..., -0.0182, -0.0035, -0.0159],
        [-0.0267,  0.0111,  0.0142,  ...,  0.0066,  0.0154, -0.0106],
        [-0.0136, -0.0220, -0.0006,  ...,  0.0055, -0.0028,  0.0260],
        ...,
        [ 0.0008, -0.0025,  0.0095,  ..., -0.0211,  0.0097, -0.0120],
        [-0.0265,  0.0148, -0.0281,  ...,  0.0098,  0.0180, -0.0102],
        [ 0.0017, -0.0143, -0.0135,  ..., -0.0124,  0.0221,  0.0190]],
       dtype=torch.float16), 'model.layers.4.mlp.up_proj.weight': tensor([[-1.6373e-02, -5.6725e-03, -4.0833e-02,  ...,  8.6670e-03,
         -8.2254e-04, -5.4932e-03],
        [-2.2400e-02, -4.0680e-02,  5.3253e-03,  ..., -8.6517e-03,
          9.8953e-03, -2.4872e-02],
        [-1.2989e-03,  2.9587e-02,  7.5042e-05,  ..., -2.8885e-02,
         -1.1322e-02,  8.4839e-03],
        ...,
        [-8.8882e-03, -3.1769e-02, -7.3433e-03,  ...,  1.2138e-02,
         -6.8016e-03,  5.5023e-02],
        [ 1.2787e-02, -1.0330e-02, -1.5060e-02,  ..., -4.2175e-02,
         -1.6281e-02,  9.5596e-03],
        [ 3.7937e-03,  1.3062e-02,  8.8272e-03,  ...,  3.7594e-03,
         -3.4237e-03, -2.4376e-03]], dtype=torch.float16), 'model.layers.4.mlp.down_proj.weight': tensor([[ 2.3834e-02, -4.2458e-03,  2.3529e-02,  ..., -1.9836e-02,
         -8.3983e-05,  2.9861e-02],
        [-5.7335e-03, -4.8859e-02,  4.5746e-02,  ..., -2.4323e-02,
         -2.1210e-02, -7.2365e-03],
        [-2.9135e-04, -2.7969e-02,  1.6556e-02,  ...,  1.1406e-02,
         -2.8000e-03,  2.2263e-02],
        ...,
        [-3.4393e-02, -1.9779e-03, -9.8801e-03,  ...,  2.4658e-02,
          2.1534e-03,  1.5030e-02],
        [-7.8430e-03,  1.8177e-03, -2.0020e-02,  ...,  1.2718e-02,
         -4.1931e-02, -1.1818e-02],
        [ 1.6479e-02, -3.2135e-02, -1.5076e-02,  ..., -3.5000e-03,
         -4.4739e-02, -2.3956e-02]], dtype=torch.float16), 'model.layers.4.input_layernorm.weight': tensor([0.2617, 0.2676, 0.2617,  ..., 0.2578, 0.2656, 0.2734],
       dtype=torch.float16), 'model.layers.4.post_attention_layernorm.weight': tensor([0.1914, 0.1895, 0.1855,  ..., 0.1904, 0.1885, 0.1895],
       dtype=torch.float16), 'model.layers.5.self_attn.q_proj.weight': tensor([[-0.0089, -0.0005, -0.0254,  ..., -0.0074, -0.0164,  0.0120],
        [-0.0202,  0.0197,  0.0401,  ..., -0.0054, -0.0094, -0.0347],
        [ 0.0045,  0.0043, -0.0135,  ...,  0.0205, -0.0172,  0.0105],
        ...,
        [-0.0121,  0.0095, -0.0033,  ...,  0.0542,  0.0104,  0.0356],
        [ 0.0433,  0.0046,  0.0262,  ..., -0.0415, -0.0351, -0.0303],
        [ 0.0103,  0.0194,  0.0370,  ..., -0.0282, -0.0147, -0.0007]],
       dtype=torch.float16), 'model.layers.5.self_attn.k_proj.weight': tensor([[-0.0049,  0.0373,  0.0067,  ...,  0.0198, -0.0056, -0.0016],
        [ 0.0006,  0.0027, -0.0324,  ...,  0.0231, -0.0123,  0.0318],
        [-0.0116, -0.0233,  0.0013,  ...,  0.0026, -0.0059,  0.0032],
        ...,
        [ 0.0031, -0.0016, -0.0228,  ...,  0.0397,  0.0098, -0.0320],
        [ 0.0524,  0.0166, -0.0242,  ..., -0.0012, -0.0159, -0.0361],
        [-0.0242, -0.0217,  0.0421,  ..., -0.0155, -0.0347,  0.0102]],
       dtype=torch.float16), 'model.layers.5.self_attn.v_proj.weight': tensor([[-3.0975e-02,  6.6643e-03,  9.8114e-03,  ...,  2.2919e-02,
          7.3671e-05,  2.3392e-02],
        [ 3.9635e-03,  1.0124e-02, -1.8448e-02,  ..., -1.1353e-02,
          3.7670e-03, -1.3893e-02],
        [ 2.2354e-02,  2.4128e-03, -2.9063e-04,  ..., -2.4063e-02,
          2.8976e-02,  1.1208e-02],
        ...,
        [ 2.0477e-02,  1.1581e-02,  1.0353e-02,  ...,  3.7048e-02,
         -5.7449e-03,  1.1454e-03],
        [-5.3596e-03,  3.0289e-03, -4.7684e-03,  ...,  9.9945e-04,
         -9.2010e-03,  8.7404e-04],
        [-1.2375e-02, -6.2561e-03,  2.1561e-02,  ..., -9.5673e-03,
         -9.2545e-03, -1.5900e-02]], dtype=torch.float16), 'model.layers.5.self_attn.o_proj.weight': tensor([[-0.0155, -0.0091,  0.0050,  ..., -0.0181, -0.0074,  0.0271],
        [ 0.0017,  0.0016, -0.0094,  ..., -0.0182,  0.0043,  0.0034],
        [-0.0014, -0.0026,  0.0131,  ...,  0.0181,  0.0119,  0.0234],
        ...,
        [ 0.0181,  0.0066, -0.0060,  ...,  0.0162,  0.0306, -0.0247],
        [-0.0016,  0.0017, -0.0038,  ..., -0.0184, -0.0139, -0.0013],
        [ 0.0051,  0.0035, -0.0148,  ..., -0.0011, -0.0060, -0.0158]],
       dtype=torch.float16), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0002, -0.0082, -0.0302,  ...,  0.0003, -0.0062, -0.0114],
        [ 0.0216, -0.0073, -0.0212,  ...,  0.0374, -0.0015,  0.0022],
        [ 0.0123,  0.0039, -0.0196,  ...,  0.0148,  0.0164, -0.0348],
        ...,
        [ 0.0065,  0.0096,  0.0416,  ..., -0.0671,  0.0157, -0.0199],
        [-0.0280,  0.0043,  0.0038,  ...,  0.0014,  0.0170, -0.0017],
        [ 0.0282, -0.0299, -0.0141,  ..., -0.0040, -0.0043, -0.0409]],
       dtype=torch.float16), 'model.layers.5.mlp.up_proj.weight': tensor([[-0.0063, -0.0135, -0.0069,  ..., -0.0147,  0.0037, -0.0168],
        [-0.0320, -0.0062,  0.0009,  ...,  0.0124,  0.0182,  0.0228],
        [-0.0019,  0.0090,  0.0094,  ...,  0.0040,  0.0080,  0.0185],
        ...,
        [ 0.0077,  0.0239, -0.0076,  ..., -0.0109,  0.0145,  0.0252],
        [ 0.0447, -0.0130, -0.0292,  ..., -0.0080, -0.0179,  0.0240],
        [ 0.0085,  0.0172,  0.0130,  ..., -0.0103, -0.0041, -0.0160]],
       dtype=torch.float16), 'model.layers.5.mlp.down_proj.weight': tensor([[-0.0074, -0.0270, -0.0031,  ...,  0.0008,  0.0067,  0.0141],
        [-0.0113,  0.0156,  0.0281,  ...,  0.0215,  0.0064, -0.0341],
        [ 0.0131,  0.0207,  0.0143,  ..., -0.0241, -0.0463,  0.0110],
        ...,
        [ 0.0110, -0.0240, -0.0051,  ...,  0.0063, -0.0257, -0.0186],
        [-0.0034, -0.0391,  0.0152,  ...,  0.0161,  0.0156, -0.0515],
        [ 0.0212,  0.0142, -0.0118,  ...,  0.0309,  0.0092, -0.0177]],
       dtype=torch.float16), 'model.layers.5.input_layernorm.weight': tensor([0.2617, 0.2695, 0.2637,  ..., 0.2500, 0.2695, 0.2676],
       dtype=torch.float16), 'model.layers.5.post_attention_layernorm.weight': tensor([0.2090, 0.1953, 0.1934,  ..., 0.2051, 0.2021, 0.2051],
       dtype=torch.float16), 'model.layers.6.self_attn.q_proj.weight': tensor([[-9.7351e-03, -1.1505e-02,  6.6071e-03,  ..., -3.3630e-02,
         -6.4468e-03, -4.9515e-03],
        [ 4.4250e-03, -6.5613e-03,  5.6343e-03,  ...,  1.4587e-02,
          3.5286e-03, -3.1464e-02],
        [-1.7654e-02,  2.4216e-02, -3.8513e-02,  ...,  3.0502e-02,
         -4.8431e-02, -3.2272e-03],
        ...,
        [ 1.2878e-02,  9.0103e-03, -3.7628e-02,  ...,  2.3987e-02,
          2.7657e-03,  1.5497e-03],
        [ 3.5614e-02,  3.2532e-02,  5.3329e-03,  ..., -9.7885e-03,
         -9.6497e-02, -2.0844e-02],
        [-6.3538e-02, -5.3558e-02, -4.8697e-05,  ...,  1.7288e-02,
          5.1155e-03,  8.5220e-03]], dtype=torch.float16), 'model.layers.6.self_attn.k_proj.weight': tensor([[ 0.0139, -0.0106,  0.0204,  ..., -0.0071,  0.0222,  0.0589],
        [-0.0198, -0.0036,  0.0422,  ...,  0.0071, -0.0126,  0.0158],
        [-0.0102, -0.0131, -0.0068,  ..., -0.0006, -0.0307, -0.0107],
        ...,
        [ 0.0214, -0.0376, -0.0183,  ...,  0.0607, -0.0023, -0.0482],
        [-0.0199,  0.0045, -0.0262,  ..., -0.0461, -0.0408,  0.0156],
        [-0.0544, -0.0241, -0.0399,  ...,  0.0161, -0.0420, -0.0188]],
       dtype=torch.float16), 'model.layers.6.self_attn.v_proj.weight': tensor([[ 0.0140,  0.0336,  0.0101,  ...,  0.0127, -0.0017,  0.0078],
        [ 0.0381, -0.0063, -0.0095,  ...,  0.0046, -0.0005,  0.0038],
        [-0.0079, -0.0024,  0.0124,  ...,  0.0101,  0.0240,  0.0046],
        ...,
        [-0.0221, -0.0061,  0.0052,  ...,  0.0010, -0.0165,  0.0085],
        [-0.0243, -0.0088, -0.0003,  ..., -0.0012, -0.0083,  0.0198],
        [ 0.0311,  0.0049,  0.0161,  ..., -0.0222,  0.0005, -0.0030]],
       dtype=torch.float16), 'model.layers.6.self_attn.o_proj.weight': tensor([[ 0.0112, -0.0127, -0.0365,  ..., -0.0135,  0.0086,  0.0113],
        [-0.0260,  0.0067, -0.0001,  ..., -0.0224,  0.0014, -0.0022],
        [ 0.0019, -0.0115, -0.0042,  ...,  0.0106,  0.0079,  0.0094],
        ...,
        [-0.0053, -0.0143, -0.0063,  ...,  0.0074, -0.0062,  0.0256],
        [-0.0204,  0.0092, -0.0014,  ..., -0.0024,  0.0081, -0.0214],
        [-0.0201, -0.0129,  0.0079,  ..., -0.0237,  0.0066,  0.0064]],
       dtype=torch.float16), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0222,  0.0260, -0.0189,  ..., -0.0039, -0.0074, -0.0042],
        [ 0.0321,  0.0016, -0.0231,  ...,  0.0066,  0.0205,  0.0123],
        [-0.0146,  0.0217, -0.0156,  ..., -0.0187,  0.0011,  0.0088],
        ...,
        [ 0.0056, -0.0261,  0.0048,  ...,  0.0091, -0.0184, -0.0066],
        [ 0.0083,  0.0047, -0.0169,  ..., -0.0235, -0.0025, -0.0016],
        [-0.0396, -0.0513,  0.0267,  ..., -0.0413, -0.0027,  0.0164]],
       dtype=torch.float16), 'model.layers.6.mlp.up_proj.weight': tensor([[-0.0147, -0.0145, -0.0228,  ...,  0.0067, -0.0053, -0.0105],
        [ 0.0071, -0.0485,  0.0392,  ...,  0.0123,  0.0003, -0.0055],
        [-0.0220, -0.0162, -0.0241,  ...,  0.0055,  0.0135,  0.0216],
        ...,
        [-0.0267,  0.0002,  0.0167,  ...,  0.0149, -0.0019,  0.0385],
        [ 0.0244,  0.0173, -0.0063,  ..., -0.0283,  0.0101,  0.0017],
        [-0.0249,  0.0287, -0.0220,  ...,  0.0081, -0.0178, -0.0498]],
       dtype=torch.float16), 'model.layers.6.mlp.down_proj.weight': tensor([[-0.0122,  0.0100, -0.0043,  ...,  0.0013,  0.0143,  0.0160],
        [-0.0081, -0.0157,  0.0045,  ..., -0.0036, -0.0266, -0.0125],
        [ 0.0030,  0.0159, -0.0086,  ...,  0.0244,  0.0240,  0.0227],
        ...,
        [ 0.0110, -0.0024,  0.0207,  ...,  0.0316, -0.0336, -0.0099],
        [ 0.0216, -0.0065,  0.0070,  ...,  0.0098, -0.0135, -0.0126],
        [ 0.0152, -0.0165, -0.0085,  ...,  0.0319, -0.0050,  0.0079]],
       dtype=torch.float16), 'model.layers.6.input_layernorm.weight': tensor([0.3223, 0.3613, 0.3242,  ..., 0.3145, 0.3359, 0.3223],
       dtype=torch.float16), 'model.layers.6.post_attention_layernorm.weight': tensor([0.2217, 0.2129, 0.2090,  ..., 0.2227, 0.2168, 0.2178],
       dtype=torch.float16), 'model.layers.7.self_attn.q_proj.weight': tensor([[-6.2637e-03, -1.0843e-03, -8.1658e-06,  ..., -3.4428e-03,
         -2.0752e-02, -6.3477e-03],
        [-1.0460e-02,  1.4365e-04, -1.0338e-03,  ...,  1.2947e-02,
         -3.6564e-03, -1.6739e-02],
        [ 5.0201e-03,  6.6719e-03, -3.1158e-02,  ..., -2.0416e-02,
         -7.5684e-03,  9.1553e-03],
        ...,
        [-1.5259e-03, -3.3752e-02, -2.5040e-02,  ..., -1.2718e-02,
          3.4180e-02,  3.5553e-02],
        [ 1.3344e-02,  5.2917e-02, -4.0039e-02,  ..., -1.1269e-02,
         -6.7383e-02, -5.6915e-02],
        [ 7.9102e-02, -2.4200e-02, -1.8158e-02,  ...,  8.2947e-02,
          3.1113e-02, -4.3716e-03]], dtype=torch.float16), 'model.layers.7.self_attn.k_proj.weight': tensor([[ 0.0032, -0.0077, -0.0123,  ...,  0.0064,  0.0024, -0.0099],
        [-0.0070, -0.0178,  0.0048,  ..., -0.0072,  0.0043,  0.0185],
        [-0.0024, -0.0103,  0.0107,  ..., -0.0082, -0.0065, -0.0179],
        ...,
        [ 0.0429,  0.0077,  0.0243,  ...,  0.0351,  0.0396,  0.0282],
        [ 0.0400,  0.0500, -0.0002,  ..., -0.0307, -0.0344, -0.0016],
        [ 0.0403,  0.0058,  0.0104,  ..., -0.0012,  0.0019, -0.0272]],
       dtype=torch.float16), 'model.layers.7.self_attn.v_proj.weight': tensor([[-1.4038e-02,  5.2605e-03,  1.2993e-02,  ...,  2.8549e-02,
          4.2191e-03, -1.3847e-02],
        [ 2.6672e-02, -2.6993e-02,  4.3640e-03,  ...,  2.0035e-02,
         -1.8890e-02, -1.5915e-02],
        [-6.8970e-03, -1.0094e-02, -3.4523e-03,  ..., -1.8097e-02,
          1.1665e-02, -7.9453e-05],
        ...,
        [-1.3485e-03, -3.8300e-02,  2.7924e-03,  ...,  5.7297e-03,
         -6.9427e-03, -4.0016e-03],
        [-3.7872e-02,  1.9394e-02, -2.7618e-02,  ..., -1.8707e-02,
          1.0628e-02, -1.9252e-04],
        [-7.4272e-03,  2.6951e-03, -8.4991e-03,  ...,  2.0401e-02,
          7.3357e-03,  1.1787e-02]], dtype=torch.float16), 'model.layers.7.self_attn.o_proj.weight': tensor([[ 0.0116, -0.0154,  0.0014,  ...,  0.0091, -0.0194,  0.0053],
        [-0.0066,  0.0281,  0.0115,  ..., -0.0417, -0.0176, -0.0100],
        [ 0.0047, -0.0011, -0.0201,  ..., -0.0096, -0.0059, -0.0107],
        ...,
        [-0.0163, -0.0252, -0.0036,  ...,  0.0259, -0.0186,  0.0010],
        [-0.0226,  0.0085,  0.0167,  ...,  0.0080, -0.0130,  0.0153],
        [ 0.0028, -0.0002,  0.0005,  ...,  0.0060, -0.0161,  0.0039]],
       dtype=torch.float16), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 7.7896e-03,  4.7340e-03, -5.0850e-03,  ..., -4.3983e-03,
         -3.3386e-02, -7.2746e-03],
        [-3.1647e-02,  1.0490e-02, -8.5449e-03,  ..., -4.9400e-03,
         -3.8891e-03,  2.0676e-03],
        [ 1.7075e-02, -3.0640e-02, -8.4043e-06,  ...,  2.5543e-02,
         -2.7069e-02,  3.4237e-03],
        ...,
        [ 1.6441e-03,  2.0504e-03, -1.4145e-02,  ..., -2.0462e-02,
          4.6463e-03, -2.1713e-02],
        [ 2.6989e-03,  1.8036e-02,  1.2131e-02,  ..., -4.7798e-03,
          6.1493e-03, -3.0258e-02],
        [ 1.9714e-02, -1.6556e-02, -1.0773e-02,  ...,  1.7761e-02,
          1.8799e-02, -6.9962e-03]], dtype=torch.float16), 'model.layers.7.mlp.up_proj.weight': tensor([[ 0.0250,  0.0014, -0.0038,  ...,  0.0224, -0.0396,  0.0026],
        [-0.0110, -0.0190,  0.0299,  ...,  0.0095, -0.0108,  0.0154],
        [ 0.0259, -0.0214,  0.0107,  ..., -0.0126,  0.0181, -0.0352],
        ...,
        [-0.0019, -0.0023, -0.0150,  ..., -0.0095, -0.0177,  0.0024],
        [ 0.0003,  0.0084,  0.0167,  ..., -0.0071,  0.0215, -0.0067],
        [-0.0245, -0.0151,  0.0063,  ...,  0.0170,  0.0119,  0.0050]],
       dtype=torch.float16), 'model.layers.7.mlp.down_proj.weight': tensor([[-0.0079, -0.0069,  0.0050,  ..., -0.0115, -0.0060, -0.0211],
        [-0.0095, -0.0072,  0.0217,  ..., -0.0125,  0.0093,  0.0047],
        [ 0.0106,  0.0077,  0.0231,  ..., -0.0157, -0.0048, -0.0210],
        ...,
        [-0.0100,  0.0002, -0.0191,  ...,  0.0123,  0.0022, -0.0257],
        [ 0.0428, -0.0037,  0.0073,  ..., -0.0168,  0.0043, -0.0133],
        [ 0.0117,  0.0195, -0.0333,  ...,  0.0041, -0.0196, -0.0012]],
       dtype=torch.float16), 'model.layers.7.input_layernorm.weight': tensor([0.3242, 0.3652, 0.3340,  ..., 0.3203, 0.3574, 0.3320],
       dtype=torch.float16), 'model.layers.7.post_attention_layernorm.weight': tensor([0.2383, 0.2197, 0.2236,  ..., 0.2314, 0.2324, 0.2314],
       dtype=torch.float16), 'model.layers.8.self_attn.q_proj.weight': tensor([[-0.0004, -0.0152, -0.0297,  ..., -0.0065,  0.0065, -0.0091],
        [-0.0125, -0.0141, -0.0328,  ...,  0.0038, -0.0112,  0.0025],
        [-0.0400, -0.0028, -0.0129,  ..., -0.0023,  0.0260, -0.0321],
        ...,
        [-0.0062,  0.0861,  0.0443,  ..., -0.0247, -0.0285, -0.0468],
        [ 0.0012, -0.0596, -0.0192,  ...,  0.0352,  0.0269, -0.0008],
        [-0.0648, -0.0531, -0.0116,  ..., -0.0541,  0.0303, -0.0170]],
       dtype=torch.float16), 'model.layers.8.self_attn.k_proj.weight': tensor([[-0.0032, -0.0058, -0.0180,  ..., -0.0109,  0.0052,  0.0049],
        [-0.0125,  0.0011, -0.0050,  ...,  0.0228, -0.0019,  0.0143],
        [-0.0167,  0.0023,  0.0027,  ...,  0.0063, -0.0082, -0.0249],
        ...,
        [ 0.0031, -0.0395, -0.0067,  ..., -0.0295, -0.0149,  0.0230],
        [ 0.0078,  0.0294,  0.0184,  ..., -0.0301,  0.0431, -0.0562],
        [ 0.0190, -0.0026, -0.0326,  ...,  0.0140,  0.0077, -0.0147]],
       dtype=torch.float16), 'model.layers.8.self_attn.v_proj.weight': tensor([[-0.0287, -0.0166,  0.0045,  ..., -0.0193, -0.0085, -0.0096],
        [-0.0234, -0.0132,  0.0059,  ...,  0.0352,  0.0096,  0.0248],
        [-0.0082,  0.0140,  0.0135,  ..., -0.0079,  0.0031, -0.0204],
        ...,
        [ 0.0319, -0.0149,  0.0065,  ...,  0.0218, -0.0201,  0.0271],
        [ 0.0327, -0.0165,  0.0041,  ...,  0.0074, -0.0036,  0.0023],
        [ 0.0126, -0.0004, -0.0005,  ..., -0.0017,  0.0009, -0.0126]],
       dtype=torch.float16), 'model.layers.8.self_attn.o_proj.weight': tensor([[ 0.0177,  0.0157, -0.0148,  ..., -0.0109,  0.0026,  0.0176],
        [ 0.0054,  0.0004, -0.0322,  ..., -0.0121, -0.0108, -0.0186],
        [ 0.0025,  0.0138, -0.0094,  ..., -0.0011,  0.0121,  0.0166],
        ...,
        [-0.0150,  0.0233, -0.0010,  ...,  0.0010, -0.0001, -0.0027],
        [ 0.0086,  0.0015, -0.0089,  ...,  0.0043,  0.0054, -0.0251],
        [-0.0232, -0.0003, -0.0096,  ...,  0.0193, -0.0100,  0.0087]],
       dtype=torch.float16), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0158, -0.0021, -0.0490,  ...,  0.0059, -0.0245, -0.0163],
        [-0.0002, -0.0475,  0.0061,  ..., -0.0033, -0.0370,  0.0276],
        [ 0.0212,  0.0191,  0.0176,  ...,  0.0272,  0.0241, -0.0056],
        ...,
        [-0.0111,  0.0015,  0.0134,  ...,  0.0221,  0.0168,  0.0057],
        [-0.0146,  0.0039,  0.0056,  ..., -0.0016, -0.0165,  0.0145],
        [-0.0243,  0.0096, -0.0066,  ..., -0.0134,  0.0060,  0.0033]],
       dtype=torch.float16), 'model.layers.8.mlp.up_proj.weight': tensor([[-0.0055,  0.0251, -0.0157,  ...,  0.0298,  0.0039, -0.0158],
        [-0.0517,  0.0134, -0.0384,  ...,  0.0145, -0.0113, -0.0159],
        [ 0.0176, -0.0004,  0.0102,  ..., -0.0102, -0.0179,  0.0334],
        ...,
        [-0.0138,  0.0403, -0.0309,  ...,  0.0130,  0.0027,  0.0163],
        [ 0.0054, -0.0047, -0.0058,  ..., -0.0160,  0.0193, -0.0173],
        [-0.0224,  0.0174, -0.0155,  ..., -0.0185, -0.0012, -0.0002]],
       dtype=torch.float16), 'model.layers.8.mlp.down_proj.weight': tensor([[-0.0099, -0.0094,  0.0129,  ...,  0.0072,  0.0198, -0.0290],
        [ 0.0178,  0.0132, -0.0227,  ..., -0.0072,  0.0143, -0.0171],
        [ 0.0061, -0.0186, -0.0251,  ..., -0.0091, -0.0019,  0.0038],
        ...,
        [ 0.0090, -0.0205, -0.0343,  ...,  0.0038,  0.0098, -0.0160],
        [ 0.0096,  0.0107, -0.0036,  ..., -0.0060, -0.0068, -0.0226],
        [-0.0031,  0.0103,  0.0024,  ...,  0.0047,  0.0011,  0.0048]],
       dtype=torch.float16), 'model.layers.8.input_layernorm.weight': tensor([0.3301, 0.3477, 0.3320,  ..., 0.3203, 0.3398, 0.3242],
       dtype=torch.float16), 'model.layers.8.post_attention_layernorm.weight': tensor([0.2422, 0.2314, 0.2236,  ..., 0.2363, 0.2324, 0.2305],
       dtype=torch.float16), 'model.layers.9.self_attn.q_proj.weight': tensor([[-0.0147,  0.0026,  0.0210,  ..., -0.0103, -0.0100, -0.0244],
        [-0.0023, -0.0385,  0.0208,  ..., -0.0013, -0.0039,  0.0068],
        [ 0.0012, -0.0021, -0.0153,  ..., -0.0283, -0.0279, -0.0179],
        ...,
        [-0.0006, -0.0509,  0.0130,  ...,  0.0190,  0.0121, -0.0163],
        [ 0.0161, -0.0186,  0.0037,  ...,  0.0068,  0.0028,  0.0125],
        [-0.0003,  0.0516,  0.0195,  ..., -0.0563,  0.0534, -0.0034]],
       dtype=torch.float16), 'model.layers.9.self_attn.k_proj.weight': tensor([[-0.0307,  0.0100, -0.0252,  ..., -0.0017, -0.0205, -0.0061],
        [-0.0069,  0.0352,  0.0098,  ..., -0.0149,  0.0085,  0.0003],
        [-0.0164, -0.0064,  0.0345,  ...,  0.0036, -0.0246, -0.0038],
        ...,
        [ 0.0229, -0.0136, -0.0035,  ..., -0.0085,  0.0241,  0.0240],
        [ 0.0319,  0.0002,  0.0217,  ...,  0.0495, -0.0169,  0.0517],
        [ 0.0084, -0.0259,  0.0257,  ...,  0.0061,  0.0235, -0.0248]],
       dtype=torch.float16), 'model.layers.9.self_attn.v_proj.weight': tensor([[-0.0064,  0.0087,  0.0034,  ...,  0.0043, -0.0216, -0.0148],
        [-0.0142, -0.0147, -0.0031,  ...,  0.0340, -0.0037, -0.0044],
        [ 0.0071, -0.0220,  0.0211,  ..., -0.0274,  0.0032, -0.0137],
        ...,
        [-0.0094, -0.0083,  0.0037,  ...,  0.0052, -0.0218, -0.0055],
        [-0.0172, -0.0003, -0.0087,  ..., -0.0159,  0.0021, -0.0135],
        [ 0.0245,  0.0242, -0.0037,  ..., -0.0092, -0.0047, -0.0060]],
       dtype=torch.float16), 'model.layers.9.self_attn.o_proj.weight': tensor([[ 0.0102,  0.0094,  0.0113,  ..., -0.0143,  0.0007, -0.0113],
        [-0.0017, -0.0193, -0.0068,  ..., -0.0033,  0.0041,  0.0140],
        [-0.0407, -0.0316,  0.0091,  ...,  0.0292,  0.0020,  0.0106],
        ...,
        [ 0.0148, -0.0133,  0.0091,  ...,  0.0057,  0.0059, -0.0098],
        [ 0.0072,  0.0159,  0.0002,  ...,  0.0084,  0.0001,  0.0006],
        [ 0.0189,  0.0456, -0.0234,  ..., -0.0009,  0.0104,  0.0045]],
       dtype=torch.float16), 'model.layers.9.mlp.gate_proj.weight': tensor([[-0.0097,  0.0258,  0.0002,  ..., -0.0271, -0.0084,  0.0018],
        [-0.0202,  0.0319,  0.0322,  ...,  0.0281,  0.0377,  0.0024],
        [ 0.0390,  0.0285, -0.0269,  ..., -0.0217,  0.0120,  0.0011],
        ...,
        [-0.0204, -0.0079, -0.0243,  ...,  0.0019, -0.0409,  0.0066],
        [-0.0061, -0.0243,  0.0275,  ..., -0.0112,  0.0039,  0.0113],
        [ 0.0146, -0.0229, -0.0039,  ...,  0.0122, -0.0083,  0.0163]],
       dtype=torch.float16), 'model.layers.9.mlp.up_proj.weight': tensor([[-0.0143,  0.0186,  0.0150,  ..., -0.0016, -0.0087,  0.0038],
        [ 0.0086, -0.0010,  0.0079,  ...,  0.0153,  0.0204, -0.0192],
        [-0.0182, -0.0051, -0.0223,  ..., -0.0026, -0.0114,  0.0033],
        ...,
        [ 0.0029,  0.0126, -0.0075,  ..., -0.0150, -0.0307, -0.0130],
        [ 0.0031,  0.0218, -0.0348,  ..., -0.0351, -0.0096, -0.0163],
        [ 0.0102, -0.0337, -0.0058,  ..., -0.0190,  0.0217, -0.0074]],
       dtype=torch.float16), 'model.layers.9.mlp.down_proj.weight': tensor([[-0.0030,  0.0313, -0.0411,  ...,  0.0004, -0.0109,  0.0136],
        [ 0.0216, -0.0283, -0.0173,  ..., -0.0057, -0.0223, -0.0278],
        [-0.0026, -0.0015,  0.0022,  ..., -0.0155,  0.0007, -0.0026],
        ...,
        [-0.0101,  0.0194,  0.0052,  ..., -0.0095, -0.0285,  0.0141],
        [-0.0309,  0.0034,  0.0155,  ..., -0.0204, -0.0034, -0.0333],
        [ 0.0165,  0.0171,  0.0078,  ...,  0.0404,  0.0161,  0.0167]],
       dtype=torch.float16), 'model.layers.9.input_layernorm.weight': tensor([0.3535, 0.3633, 0.3281,  ..., 0.3477, 0.3477, 0.3438],
       dtype=torch.float16), 'model.layers.9.post_attention_layernorm.weight': tensor([0.2490, 0.2334, 0.2285,  ..., 0.2451, 0.2422, 0.2383],
       dtype=torch.float16), 'model.layers.10.self_attn.q_proj.weight': tensor([[-3.6449e-03,  3.8357e-03,  2.0087e-05,  ..., -2.7161e-03,
         -6.6376e-03, -1.4206e-02],
        [-9.7427e-03, -4.9667e-03,  2.0599e-02,  ..., -1.9287e-02,
          6.4575e-02, -3.7270e-03],
        [-1.3718e-02, -1.5106e-02,  2.1040e-04,  ...,  3.4210e-02,
         -9.4452e-03, -1.4389e-02],
        ...,
        [ 3.2104e-02,  6.3049e-02, -1.7929e-02,  ...,  3.7445e-02,
          3.3508e-02, -9.3842e-03],
        [-6.6040e-02,  5.6519e-02, -2.7695e-03,  ..., -6.0577e-02,
         -5.7068e-03, -3.6221e-03],
        [-4.9713e-02, -2.1591e-02, -7.7477e-03,  ..., -1.2627e-02,
         -3.6346e-02, -9.3536e-03]], dtype=torch.float16), 'model.layers.10.self_attn.k_proj.weight': tensor([[-0.0320,  0.0131, -0.0093,  ..., -0.0153,  0.0091, -0.0001],
        [-0.0056,  0.0082, -0.0056,  ..., -0.0057, -0.0101,  0.0133],
        [-0.0008, -0.0022,  0.0067,  ..., -0.0274,  0.0042,  0.0012],
        ...,
        [-0.0464, -0.0599,  0.0127,  ...,  0.0291, -0.0853,  0.0117],
        [-0.0345, -0.0131,  0.0234,  ..., -0.0141, -0.0415, -0.0148],
        [-0.0192,  0.0225, -0.0224,  ...,  0.0083,  0.0425, -0.0002]],
       dtype=torch.float16), 'model.layers.10.self_attn.v_proj.weight': tensor([[-0.0387,  0.0081, -0.0087,  ...,  0.0097,  0.0140,  0.0083],
        [-0.0083,  0.0136,  0.0120,  ..., -0.0067, -0.0419,  0.0195],
        [ 0.0170, -0.0150,  0.0130,  ...,  0.0145,  0.0079, -0.0095],
        ...,
        [ 0.0214,  0.0277,  0.0017,  ...,  0.0253,  0.0023, -0.0228],
        [-0.0040,  0.0057, -0.0005,  ...,  0.0020,  0.0113, -0.0018],
        [ 0.0172,  0.0061, -0.0238,  ..., -0.0072, -0.0071,  0.0242]],
       dtype=torch.float16), 'model.layers.10.self_attn.o_proj.weight': tensor([[-0.0057,  0.0007, -0.0348,  ...,  0.0022,  0.0056,  0.0074],
        [ 0.0006, -0.0118,  0.0126,  ...,  0.0058,  0.0132,  0.0075],
        [ 0.0153, -0.0353, -0.0162,  ...,  0.0007, -0.0036, -0.0031],
        ...,
        [-0.0021,  0.0080, -0.0197,  ..., -0.0031, -0.0003,  0.0199],
        [ 0.0090, -0.0164, -0.0207,  ...,  0.0118,  0.0087,  0.0109],
        [ 0.0075, -0.0081, -0.0278,  ...,  0.0101, -0.0039,  0.0009]],
       dtype=torch.float16), 'model.layers.10.mlp.gate_proj.weight': tensor([[-0.0255, -0.0464, -0.0296,  ...,  0.0059, -0.0014, -0.0041],
        [-0.0152, -0.0224, -0.0173,  ...,  0.0032,  0.0152,  0.0143],
        [-0.0210, -0.0214,  0.0097,  ...,  0.0347, -0.0098,  0.0017],
        ...,
        [-0.0465, -0.0077,  0.0100,  ...,  0.0039, -0.0303,  0.0208],
        [ 0.0046,  0.0114,  0.0203,  ...,  0.0042, -0.0112, -0.0007],
        [-0.0159, -0.0042, -0.0147,  ..., -0.0145,  0.0072, -0.0121]],
       dtype=torch.float16), 'model.layers.10.mlp.up_proj.weight': tensor([[-0.0320, -0.0040, -0.0427,  ...,  0.0109, -0.0067, -0.0190],
        [-0.0074,  0.0061,  0.0065,  ...,  0.0190,  0.0319, -0.0167],
        [-0.0080, -0.0042,  0.0192,  ...,  0.0319, -0.0360,  0.0033],
        ...,
        [ 0.0242,  0.0213, -0.0094,  ..., -0.0432, -0.0039,  0.0027],
        [-0.0012, -0.0116, -0.0232,  ...,  0.0270, -0.0056,  0.0214],
        [-0.0042,  0.0167, -0.0049,  ..., -0.0009,  0.0034,  0.0205]],
       dtype=torch.float16), 'model.layers.10.mlp.down_proj.weight': tensor([[-0.0152, -0.0201, -0.0101,  ...,  0.0302, -0.0133,  0.0010],
        [-0.0054,  0.0221, -0.0139,  ..., -0.0116,  0.0119, -0.0105],
        [-0.0275, -0.0021,  0.0208,  ..., -0.0218, -0.0254,  0.0118],
        ...,
        [ 0.0098, -0.0068, -0.0057,  ...,  0.0063,  0.0142,  0.0074],
        [-0.0106,  0.0519, -0.0189,  ...,  0.0284,  0.0307, -0.0305],
        [-0.0471,  0.0020, -0.0252,  ..., -0.0184, -0.0151,  0.0109]],
       dtype=torch.float16), 'model.layers.10.input_layernorm.weight': tensor([0.3652, 0.3594, 0.3223,  ..., 0.3398, 0.3496, 0.3379],
       dtype=torch.float16), 'model.layers.10.post_attention_layernorm.weight': tensor([0.2500, 0.2383, 0.2285,  ..., 0.2432, 0.2432, 0.2432],
       dtype=torch.float16), 'model.layers.11.self_attn.q_proj.weight': tensor([[ 0.0161, -0.0006, -0.0169,  ...,  0.0251, -0.0088,  0.0062],
        [-0.0113,  0.0006,  0.0061,  ...,  0.0169,  0.0102,  0.0040],
        [ 0.0104,  0.0213, -0.0237,  ..., -0.0047, -0.0055,  0.0015],
        ...,
        [ 0.0066,  0.0024,  0.0322,  ...,  0.0338,  0.0438, -0.0291],
        [ 0.0504,  0.0148, -0.0166,  ..., -0.0151,  0.0161, -0.0268],
        [ 0.0818, -0.0201, -0.0214,  ..., -0.0201,  0.0410,  0.0539]],
       dtype=torch.float16), 'model.layers.11.self_attn.k_proj.weight': tensor([[-0.0052,  0.0221,  0.0030,  ..., -0.0179,  0.0177, -0.0154],
        [ 0.0012,  0.0016, -0.0310,  ..., -0.0106,  0.0045,  0.0256],
        [ 0.0298, -0.0297,  0.0027,  ...,  0.0140,  0.0046,  0.0079],
        ...,
        [-0.0032,  0.0288,  0.0043,  ..., -0.0189, -0.0055,  0.0403],
        [ 0.0598, -0.0065, -0.0142,  ..., -0.0078,  0.0050, -0.0079],
        [ 0.0110,  0.0065,  0.0253,  ..., -0.0007,  0.0569,  0.0267]],
       dtype=torch.float16), 'model.layers.11.self_attn.v_proj.weight': tensor([[ 9.6436e-03,  1.0605e-03, -4.5738e-03,  ..., -2.2232e-02,
         -1.0233e-03,  7.4806e-03],
        [ 2.6855e-03, -6.0806e-03, -1.6937e-02,  ..., -5.5611e-05,
          3.7360e-04, -2.7130e-02],
        [ 2.9392e-03,  9.2468e-03, -7.0686e-03,  ...,  1.6724e-02,
          1.0735e-02, -2.5055e-02],
        ...,
        [-2.0782e-02,  7.5455e-03, -1.4633e-02,  ...,  8.2016e-03,
         -1.7349e-02, -2.2812e-03],
        [-9.9487e-03,  1.0506e-02, -1.1917e-02,  ..., -1.3245e-02,
         -1.7868e-02,  3.2711e-03],
        [ 1.7990e-02, -2.1179e-02, -1.4639e-03,  ..., -4.0344e-02,
          1.8826e-03, -1.2375e-02]], dtype=torch.float16), 'model.layers.11.self_attn.o_proj.weight': tensor([[-0.0191, -0.0035,  0.0060,  ...,  0.0097,  0.0109,  0.0016],
        [-0.0016, -0.0260,  0.0116,  ..., -0.0118, -0.0028, -0.0255],
        [-0.0051, -0.0058,  0.0210,  ...,  0.0021, -0.0066,  0.0139],
        ...,
        [ 0.0016, -0.0042,  0.0228,  ...,  0.0024, -0.0016, -0.0029],
        [ 0.0077,  0.0177,  0.0082,  ...,  0.0172,  0.0129, -0.0298],
        [-0.0027, -0.0047,  0.0054,  ..., -0.0081, -0.0022, -0.0107]],
       dtype=torch.float16), 'model.layers.11.mlp.gate_proj.weight': tensor([[-0.0440, -0.0086,  0.0052,  ...,  0.0062, -0.0116,  0.0425],
        [ 0.0074, -0.0107,  0.0206,  ...,  0.0087, -0.0197, -0.0413],
        [-0.0010, -0.0459, -0.0289,  ..., -0.0025, -0.0084, -0.0026],
        ...,
        [-0.0202, -0.0397, -0.0216,  ..., -0.0041, -0.0321,  0.0039],
        [ 0.0090, -0.0044, -0.0364,  ..., -0.0127,  0.0069,  0.0010],
        [ 0.0023,  0.0186,  0.0080,  ...,  0.0468, -0.0007, -0.0140]],
       dtype=torch.float16), 'model.layers.11.mlp.up_proj.weight': tensor([[-0.0093,  0.0016, -0.0275,  ...,  0.0240,  0.0097,  0.0313],
        [ 0.0179, -0.0028, -0.0222,  ...,  0.0172, -0.0467,  0.0077],
        [-0.0064, -0.0369,  0.0014,  ..., -0.0048, -0.0177,  0.0154],
        ...,
        [ 0.0408,  0.0105, -0.0095,  ...,  0.0014, -0.0005,  0.0161],
        [-0.0116,  0.0200,  0.0059,  ...,  0.0163,  0.0094,  0.0065],
        [-0.0041,  0.0019, -0.0054,  ..., -0.0172, -0.0005,  0.0250]],
       dtype=torch.float16), 'model.layers.11.mlp.down_proj.weight': tensor([[-0.0162,  0.0454,  0.0091,  ...,  0.0194,  0.0163, -0.0040],
        [-0.0136, -0.0092, -0.0251,  ..., -0.0202, -0.0090,  0.0154],
        [-0.0237, -0.0169,  0.0102,  ...,  0.0052, -0.0217, -0.0031],
        ...,
        [ 0.0215,  0.0262, -0.0104,  ..., -0.0017, -0.0003,  0.0087],
        [-0.0111, -0.0290, -0.0306,  ..., -0.0254, -0.0089,  0.0139],
        [ 0.0362,  0.0240,  0.0214,  ..., -0.0028, -0.0135,  0.0383]],
       dtype=torch.float16), 'model.layers.11.input_layernorm.weight': tensor([0.3965, 0.3965, 0.3652,  ..., 0.3848, 0.3828, 0.3711],
       dtype=torch.float16), 'model.layers.11.post_attention_layernorm.weight': tensor([0.2598, 0.2471, 0.2383,  ..., 0.2578, 0.2559, 0.2559],
       dtype=torch.float16), 'model.layers.12.self_attn.q_proj.weight': tensor([[-0.0093, -0.0171,  0.0036,  ...,  0.0262, -0.0099,  0.0055],
        [ 0.0065, -0.0070, -0.0075,  ..., -0.0127,  0.0223,  0.0202],
        [ 0.0106,  0.0411, -0.0328,  ...,  0.0061,  0.0025, -0.0291],
        ...,
        [ 0.0094,  0.0321, -0.0197,  ..., -0.0311, -0.0004, -0.0008],
        [ 0.0424, -0.0059,  0.0097,  ...,  0.0322,  0.0067, -0.0247],
        [ 0.0332,  0.0143, -0.0364,  ..., -0.0210,  0.0215,  0.0238]],
       dtype=torch.float16), 'model.layers.12.self_attn.k_proj.weight': tensor([[ 0.0099, -0.0011, -0.0045,  ...,  0.0193, -0.0024, -0.0102],
        [ 0.0073,  0.0208, -0.0157,  ..., -0.0014, -0.0157, -0.0293],
        [-0.0113, -0.0283,  0.0173,  ...,  0.0087,  0.0026,  0.0026],
        ...,
        [ 0.0132,  0.0322, -0.0148,  ..., -0.0355, -0.0164, -0.0242],
        [-0.0381,  0.0037,  0.0226,  ..., -0.0282,  0.0146, -0.0006],
        [-0.0007,  0.0322,  0.0109,  ...,  0.0129, -0.0465, -0.0404]],
       dtype=torch.float16), 'model.layers.12.self_attn.v_proj.weight': tensor([[ 0.0064,  0.0072,  0.0069,  ..., -0.0077,  0.0109, -0.0189],
        [-0.0275,  0.0104, -0.0036,  ..., -0.0175, -0.0006,  0.0191],
        [-0.0148, -0.0132,  0.0088,  ..., -0.0069,  0.0475, -0.0107],
        ...,
        [ 0.0081, -0.0017, -0.0150,  ..., -0.0068, -0.0115, -0.0013],
        [-0.0010, -0.0147, -0.0047,  ...,  0.0034,  0.0109,  0.0122],
        [ 0.0225,  0.0017,  0.0007,  ...,  0.0178,  0.0139, -0.0070]],
       dtype=torch.float16), 'model.layers.12.self_attn.o_proj.weight': tensor([[ 0.0277,  0.0071, -0.0019,  ..., -0.0012,  0.0083, -0.0061],
        [-0.0092, -0.0141, -0.0014,  ..., -0.0108,  0.0061, -0.0138],
        [ 0.0068, -0.0023, -0.0018,  ...,  0.0037, -0.0232,  0.0125],
        ...,
        [ 0.0032, -0.0023,  0.0126,  ..., -0.0084, -0.0009,  0.0019],
        [-0.0108, -0.0346, -0.0278,  ..., -0.0121,  0.0109,  0.0143],
        [ 0.0210,  0.0093,  0.0084,  ...,  0.0209, -0.0084, -0.0171]],
       dtype=torch.float16), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0057, -0.0110,  0.0123,  ..., -0.0042,  0.0268, -0.0024],
        [-0.0266, -0.0214,  0.0172,  ...,  0.0121,  0.0153,  0.0057],
        [-0.0005,  0.0258, -0.0114,  ..., -0.0099, -0.0289, -0.0045],
        ...,
        [-0.0024,  0.0108,  0.0106,  ..., -0.0328,  0.0070,  0.0276],
        [-0.0325, -0.0083,  0.0082,  ...,  0.0103,  0.0123, -0.0085],
        [ 0.0045, -0.0267, -0.0056,  ..., -0.0053, -0.0018, -0.0202]],
       dtype=torch.float16), 'model.layers.12.mlp.up_proj.weight': tensor([[ 2.9488e-03,  1.7151e-02,  3.6030e-03,  ..., -9.1076e-05,
          1.3832e-02,  1.5427e-02],
        [-3.6373e-03, -1.4801e-02, -1.3435e-02,  ...,  6.5842e-03,
         -7.0915e-03,  2.4414e-02],
        [ 1.4610e-02, -1.2291e-02,  7.4959e-03,  ..., -4.1534e-02,
          4.9171e-03,  1.6441e-03],
        ...,
        [-2.6154e-02, -3.3844e-02, -7.3738e-03,  ...,  1.6922e-02,
         -1.5038e-02,  3.0403e-03],
        [-1.5144e-03, -4.3915e-02, -8.0156e-04,  ...,  1.3924e-02,
          3.0556e-03, -1.5656e-02],
        [ 2.2144e-03, -2.8961e-02,  3.7813e-04,  ...,  3.2440e-02,
         -3.6602e-03, -3.8300e-02]], dtype=torch.float16), 'model.layers.12.mlp.down_proj.weight': tensor([[ 0.0081, -0.0018, -0.0294,  ..., -0.0123,  0.0035,  0.0029],
        [ 0.0170, -0.0288,  0.0046,  ..., -0.0004, -0.0089, -0.0230],
        [ 0.0200,  0.0030,  0.0241,  ...,  0.0043, -0.0012, -0.0281],
        ...,
        [ 0.0183, -0.0085, -0.0380,  ...,  0.0313, -0.0193, -0.0176],
        [-0.0259,  0.0179,  0.0106,  ..., -0.0092,  0.0359, -0.0229],
        [ 0.0075,  0.0262,  0.0221,  ..., -0.0381,  0.0273, -0.0022]],
       dtype=torch.float16), 'model.layers.12.input_layernorm.weight': tensor([0.4062, 0.4023, 0.3691,  ..., 0.3848, 0.3867, 0.3887],
       dtype=torch.float16), 'model.layers.12.post_attention_layernorm.weight': tensor([0.2656, 0.2520, 0.2432,  ..., 0.2656, 0.2617, 0.2598],
       dtype=torch.float16), 'model.layers.13.self_attn.q_proj.weight': tensor([[-0.0002, -0.0013, -0.0132,  ...,  0.0055, -0.0150, -0.0128],
        [-0.0118, -0.0142,  0.0031,  ..., -0.0004,  0.0004, -0.0026],
        [-0.0175,  0.0138,  0.0197,  ..., -0.0115, -0.0075, -0.0069],
        ...,
        [ 0.0483,  0.0084,  0.0043,  ...,  0.0573,  0.0140, -0.0512],
        [ 0.0078,  0.0083, -0.0259,  ...,  0.0091,  0.0111, -0.0104],
        [-0.0040, -0.0248, -0.0212,  ..., -0.0068,  0.0285, -0.0065]],
       dtype=torch.float16), 'model.layers.13.self_attn.k_proj.weight': tensor([[ 0.0134,  0.0048, -0.0030,  ..., -0.0130,  0.0337,  0.0125],
        [ 0.0155,  0.0307, -0.0005,  ..., -0.0055,  0.0136,  0.0046],
        [-0.0007, -0.0130,  0.0334,  ..., -0.0083,  0.0110, -0.0375],
        ...,
        [ 0.0375,  0.0356,  0.0033,  ...,  0.0048, -0.0061, -0.0118],
        [-0.0010,  0.0045,  0.0287,  ..., -0.0342, -0.0217,  0.0352],
        [-0.0229, -0.0535, -0.0142,  ..., -0.0378, -0.0310,  0.0118]],
       dtype=torch.float16), 'model.layers.13.self_attn.v_proj.weight': tensor([[ 0.0149,  0.0064, -0.0058,  ..., -0.0005,  0.0173,  0.0124],
        [-0.0029,  0.0087,  0.0005,  ...,  0.0233, -0.0065, -0.0029],
        [ 0.0146, -0.0016, -0.0023,  ..., -0.0212,  0.0366, -0.0090],
        ...,
        [-0.0011,  0.0251, -0.0052,  ..., -0.0111,  0.0272, -0.0211],
        [-0.0103,  0.0104,  0.0128,  ...,  0.0017,  0.0274,  0.0058],
        [-0.0045, -0.0064,  0.0239,  ...,  0.0154, -0.0026,  0.0374]],
       dtype=torch.float16), 'model.layers.13.self_attn.o_proj.weight': tensor([[-0.0035,  0.0010, -0.0044,  ..., -0.0015, -0.0045, -0.0012],
        [ 0.0222,  0.0148,  0.0101,  ..., -0.0146, -0.0108,  0.0024],
        [ 0.0118,  0.0055,  0.0036,  ...,  0.0065, -0.0233, -0.0088],
        ...,
        [-0.0102,  0.0102,  0.0194,  ..., -0.0114, -0.0154, -0.0165],
        [ 0.0083, -0.0005,  0.0301,  ..., -0.0037, -0.0268, -0.0238],
        [ 0.0100,  0.0019,  0.0086,  ...,  0.0171, -0.0083, -0.0238]],
       dtype=torch.float16), 'model.layers.13.mlp.gate_proj.weight': tensor([[ 0.0249, -0.0034, -0.0082,  ...,  0.0114,  0.0034, -0.0122],
        [-0.0141,  0.0452,  0.0071,  ...,  0.0416, -0.0012, -0.0260],
        [ 0.0035, -0.0199, -0.0103,  ...,  0.0047, -0.0093, -0.0152],
        ...,
        [ 0.0153, -0.0196,  0.0202,  ..., -0.0065,  0.0133,  0.0111],
        [ 0.0154, -0.0125,  0.0203,  ...,  0.0181,  0.0106, -0.0270],
        [ 0.0028,  0.0392,  0.0161,  ..., -0.0045,  0.0059,  0.0285]],
       dtype=torch.float16), 'model.layers.13.mlp.up_proj.weight': tensor([[-0.0423,  0.0199, -0.0013,  ...,  0.0037,  0.0091,  0.0011],
        [ 0.0138, -0.0066,  0.0247,  ...,  0.0468,  0.0286,  0.0224],
        [ 0.0281, -0.0344,  0.0093,  ...,  0.0069,  0.0009, -0.0082],
        ...,
        [-0.0130, -0.0038,  0.0297,  ...,  0.0190, -0.0247,  0.0139],
        [-0.0103, -0.0171,  0.0079,  ...,  0.0177,  0.0563,  0.0096],
        [ 0.0117, -0.0212,  0.0179,  ..., -0.0185, -0.0004,  0.0269]],
       dtype=torch.float16), 'model.layers.13.mlp.down_proj.weight': tensor([[-0.0062, -0.0036, -0.0027,  ...,  0.0226, -0.0265, -0.0220],
        [-0.0117,  0.0470, -0.0413,  ..., -0.0018,  0.0133, -0.0090],
        [ 0.0081,  0.0038,  0.0183,  ...,  0.0015, -0.0249, -0.0031],
        ...,
        [ 0.0058,  0.0077,  0.0354,  ..., -0.0014, -0.0209,  0.0290],
        [ 0.0167, -0.0015,  0.0188,  ..., -0.0109,  0.0164, -0.0045],
        [ 0.0029, -0.0229,  0.0393,  ...,  0.0041,  0.0022,  0.0325]],
       dtype=torch.float16), 'model.layers.13.input_layernorm.weight': tensor([0.4199, 0.4121, 0.3770,  ..., 0.3926, 0.3848, 0.3965],
       dtype=torch.float16), 'model.layers.13.post_attention_layernorm.weight': tensor([0.2715, 0.2598, 0.2539,  ..., 0.2715, 0.2734, 0.2656],
       dtype=torch.float16), 'model.layers.14.self_attn.q_proj.weight': tensor([[-0.0088, -0.0028,  0.0195,  ..., -0.0054,  0.0162,  0.0367],
        [ 0.0097,  0.0160, -0.0124,  ..., -0.0348, -0.0203, -0.0406],
        [-0.0202, -0.0112,  0.0171,  ...,  0.0106,  0.0140, -0.0339],
        ...,
        [-0.0201,  0.0005, -0.0295,  ...,  0.0018,  0.0130, -0.0074],
        [ 0.0269, -0.0389,  0.0497,  ..., -0.0134,  0.0061, -0.0092],
        [-0.0175, -0.0090, -0.0035,  ...,  0.0170,  0.0184, -0.0447]],
       dtype=torch.float16), 'model.layers.14.self_attn.k_proj.weight': tensor([[-0.0143, -0.0049,  0.0068,  ..., -0.0091,  0.0271,  0.0431],
        [ 0.0191,  0.0324, -0.0204,  ..., -0.0030, -0.0276, -0.0050],
        [-0.0183,  0.0034,  0.0196,  ...,  0.0239,  0.0110,  0.0012],
        ...,
        [-0.0387, -0.0029,  0.0264,  ..., -0.0049,  0.0017, -0.0254],
        [-0.0293,  0.0005,  0.0153,  ..., -0.0359, -0.0144,  0.0012],
        [-0.0202,  0.0292,  0.0236,  ...,  0.0703,  0.0087, -0.0386]],
       dtype=torch.float16), 'model.layers.14.self_attn.v_proj.weight': tensor([[ 7.4310e-03,  7.7629e-03, -3.8025e-02,  ..., -3.4210e-02,
         -5.2032e-03,  1.2451e-02],
        [-1.0204e-03, -2.5452e-02, -3.0117e-03,  ...,  1.0887e-02,
         -5.2512e-05, -3.2425e-03],
        [ 2.6276e-02, -1.5022e-02,  2.2659e-03,  ..., -5.5466e-03,
          2.3460e-03,  8.2321e-03],
        ...,
        [ 1.5747e-02, -1.1642e-02,  1.5343e-02,  ...,  1.5533e-02,
         -1.1597e-02,  2.6016e-03],
        [-1.1391e-02,  2.2583e-02, -3.5553e-02,  ..., -7.8058e-04,
         -8.8654e-03, -2.5574e-02],
        [ 3.5992e-03,  2.3102e-02, -2.2568e-02,  ..., -5.2261e-03,
         -3.3932e-03,  1.8295e-02]], dtype=torch.float16), 'model.layers.14.self_attn.o_proj.weight': tensor([[-0.0108,  0.0044, -0.0227,  ..., -0.0021,  0.0010, -0.0110],
        [ 0.0080,  0.0304,  0.0077,  ...,  0.0221, -0.0049,  0.0021],
        [ 0.0060,  0.0082,  0.0024,  ...,  0.0075,  0.0206,  0.0054],
        ...,
        [ 0.0245, -0.0073,  0.0008,  ..., -0.0073, -0.0022,  0.0139],
        [-0.0025,  0.0010, -0.0195,  ..., -0.0021,  0.0362,  0.0155],
        [-0.0085, -0.0104, -0.0139,  ..., -0.0070,  0.0146,  0.0060]],
       dtype=torch.float16), 'model.layers.14.mlp.gate_proj.weight': tensor([[-0.0084,  0.0011, -0.0090,  ...,  0.0102, -0.0185, -0.0064],
        [ 0.0296,  0.0080, -0.0390,  ...,  0.0377,  0.0119, -0.0075],
        [ 0.0095,  0.0148, -0.0004,  ..., -0.0081,  0.0108, -0.0179],
        ...,
        [ 0.0065,  0.0105, -0.0190,  ...,  0.0003, -0.0047,  0.0004],
        [ 0.0033,  0.0159,  0.0201,  ..., -0.0192,  0.0087,  0.0073],
        [ 0.0200,  0.0017,  0.0183,  ..., -0.0106, -0.0248,  0.0258]],
       dtype=torch.float16), 'model.layers.14.mlp.up_proj.weight': tensor([[ 0.0052,  0.0099,  0.0201,  ..., -0.0153,  0.0073,  0.0048],
        [ 0.0269,  0.0089, -0.0300,  ...,  0.0064,  0.0262,  0.0104],
        [ 0.0012, -0.0055,  0.0300,  ..., -0.0013,  0.0177, -0.0023],
        ...,
        [-0.0164, -0.0013, -0.0479,  ..., -0.0145, -0.0116, -0.0048],
        [-0.0415,  0.0074, -0.0075,  ..., -0.0081,  0.0239, -0.0144],
        [ 0.0029,  0.0235,  0.0122,  ...,  0.0086, -0.0140,  0.0131]],
       dtype=torch.float16), 'model.layers.14.mlp.down_proj.weight': tensor([[ 0.0100,  0.0243,  0.0113,  ..., -0.0290, -0.0019, -0.0056],
        [ 0.0121,  0.0222, -0.0091,  ...,  0.0131, -0.0032,  0.0189],
        [ 0.0080, -0.0420,  0.0119,  ...,  0.0042, -0.0302,  0.0124],
        ...,
        [ 0.0005,  0.0152, -0.0169,  ..., -0.0046, -0.0100, -0.0109],
        [ 0.0242,  0.0335,  0.0364,  ..., -0.0051, -0.0155,  0.0210],
        [-0.0245,  0.0057, -0.0101,  ..., -0.0300,  0.0070,  0.0187]],
       dtype=torch.float16), 'model.layers.14.input_layernorm.weight': tensor([0.4219, 0.4297, 0.3789,  ..., 0.4141, 0.4062, 0.3984],
       dtype=torch.float16), 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2734, 0.2656,  ..., 0.2871, 0.2832, 0.2793],
       dtype=torch.float16), 'model.layers.15.self_attn.q_proj.weight': tensor([[-0.0194, -0.0154, -0.0142,  ...,  0.0138, -0.0084,  0.0010],
        [ 0.0363, -0.0190,  0.0038,  ..., -0.0058,  0.0144,  0.0015],
        [ 0.0084, -0.0132,  0.0030,  ...,  0.0098, -0.0134, -0.0160],
        ...,
        [-0.0477, -0.0267,  0.0071,  ..., -0.0063, -0.0128,  0.0200],
        [-0.0155, -0.0536,  0.0174,  ...,  0.0155, -0.0015,  0.0025],
        [ 0.0236,  0.0251,  0.0278,  ..., -0.0140, -0.0227, -0.0165]],
       dtype=torch.float16), 'model.layers.15.self_attn.k_proj.weight': tensor([[ 0.0209, -0.0054, -0.0045,  ..., -0.0027,  0.0014,  0.0044],
        [ 0.0111, -0.0042, -0.0052,  ..., -0.0015,  0.0046, -0.0135],
        [-0.0021,  0.0020, -0.0083,  ..., -0.0007,  0.0133, -0.0119],
        ...,
        [-0.0540, -0.0380,  0.0168,  ...,  0.0214,  0.0069, -0.0060],
        [ 0.0092,  0.0011,  0.0159,  ...,  0.0275, -0.0217,  0.0132],
        [-0.0067, -0.0060,  0.0341,  ..., -0.0027, -0.0171,  0.0033]],
       dtype=torch.float16), 'model.layers.15.self_attn.v_proj.weight': tensor([[ 0.0088,  0.0023,  0.0053,  ...,  0.0037,  0.0141,  0.0177],
        [-0.0096, -0.0142,  0.0151,  ...,  0.0168,  0.0018,  0.0224],
        [ 0.0075, -0.0377, -0.0064,  ..., -0.0365,  0.0073,  0.0073],
        ...,
        [-0.0038, -0.0107,  0.0116,  ...,  0.0066,  0.0181, -0.0141],
        [ 0.0056, -0.0006, -0.0311,  ...,  0.0116,  0.0151, -0.0054],
        [ 0.0169,  0.0104,  0.0152,  ..., -0.0160,  0.0075,  0.0077]],
       dtype=torch.float16), 'model.layers.15.self_attn.o_proj.weight': tensor([[ 0.0012,  0.0029, -0.0154,  ...,  0.0104, -0.0127,  0.0282],
        [-0.0046, -0.0112, -0.0177,  ...,  0.0099, -0.0261,  0.0198],
        [ 0.0020, -0.0083,  0.0008,  ...,  0.0102, -0.0070,  0.0095],
        ...,
        [-0.0089, -0.0197,  0.0142,  ..., -0.0044, -0.0201, -0.0100],
        [ 0.0005, -0.0017, -0.0072,  ...,  0.0113,  0.0051,  0.0044],
        [-0.0241,  0.0053,  0.0263,  ..., -0.0118, -0.0254, -0.0296]],
       dtype=torch.float16), 'model.layers.15.mlp.gate_proj.weight': tensor([[-0.0145,  0.0259, -0.0075,  ...,  0.0116, -0.0298,  0.0140],
        [ 0.0069, -0.0101,  0.0278,  ..., -0.0192,  0.0056,  0.0099],
        [ 0.0088, -0.0179, -0.0112,  ...,  0.0231, -0.0539, -0.0260],
        ...,
        [-0.0106, -0.0046,  0.0301,  ..., -0.0094,  0.0175,  0.0069],
        [-0.0124, -0.0172,  0.0103,  ..., -0.0082, -0.0106, -0.0440],
        [ 0.0040, -0.0142, -0.0008,  ...,  0.0002,  0.0071, -0.0001]],
       dtype=torch.float16), 'model.layers.15.mlp.up_proj.weight': tensor([[-1.2886e-02, -9.5215e-03,  2.7924e-02,  ...,  1.2367e-02,
          1.1269e-02, -4.3579e-02],
        [-1.5732e-02,  4.2908e-02,  2.9343e-02,  ...,  1.0506e-02,
          7.6866e-03,  3.9864e-03],
        [-4.2419e-02, -7.7896e-03, -4.7994e-04,  ..., -1.5518e-02,
          1.5602e-02, -1.0269e-02],
        ...,
        [-6.7863e-03, -2.3376e-02, -7.8659e-03,  ...,  8.5068e-03,
         -4.8757e-05, -4.9782e-03],
        [ 2.7618e-02, -5.3329e-03,  7.8354e-03,  ..., -1.0330e-02,
          1.5747e-02,  5.7030e-04],
        [-7.5302e-03, -2.7130e-02, -9.7809e-03,  ...,  4.5633e-04,
         -1.2245e-02,  1.1940e-03]], dtype=torch.float16), 'model.layers.15.mlp.down_proj.weight': tensor([[-1.2512e-02, -6.8245e-03, -1.6098e-02,  ...,  2.5909e-02,
          9.1171e-03, -1.0674e-02],
        [ 1.0666e-02, -1.1749e-02, -2.6199e-02,  ..., -1.1993e-02,
         -2.3163e-02,  1.6129e-02],
        [ 3.8452e-02,  4.4830e-02, -1.5747e-02,  ..., -1.1589e-02,
          3.4302e-02,  1.8906e-02],
        ...,
        [-4.5853e-03, -3.9978e-02,  6.3210e-03,  ...,  9.4833e-03,
          5.5046e-03,  7.1466e-05],
        [-4.1779e-02, -1.7502e-02, -1.1826e-03,  ..., -2.9480e-02,
         -1.5137e-02,  7.0038e-03],
        [ 1.5354e-03,  2.3773e-02, -6.3553e-03,  ..., -1.7715e-02,
         -3.2593e-02, -2.0401e-02]], dtype=torch.float16), 'model.layers.15.input_layernorm.weight': tensor([0.4160, 0.4102, 0.3809,  ..., 0.3867, 0.3945, 0.3945],
       dtype=torch.float16), 'model.layers.15.post_attention_layernorm.weight': tensor([0.2930, 0.2793, 0.2793,  ..., 0.2969, 0.2910, 0.2891],
       dtype=torch.float16), 'model.layers.16.self_attn.q_proj.weight': tensor([[ 0.0090,  0.0135, -0.0253,  ...,  0.0048,  0.0263, -0.0078],
        [ 0.0172, -0.0415,  0.0228,  ...,  0.0170,  0.0186, -0.0237],
        [-0.0128, -0.0067,  0.0088,  ..., -0.0257,  0.0021, -0.0261],
        ...,
        [ 0.0328, -0.0378, -0.0080,  ..., -0.0196,  0.0181, -0.0271],
        [-0.0166, -0.0170,  0.0283,  ...,  0.0018, -0.0181,  0.0157],
        [ 0.0046,  0.0219,  0.0146,  ..., -0.0030, -0.0327, -0.0095]],
       dtype=torch.float16), 'model.layers.16.self_attn.k_proj.weight': tensor([[-0.0072,  0.0235,  0.0023,  ...,  0.0131,  0.0227,  0.0217],
        [ 0.0223, -0.0315,  0.0097,  ..., -0.0058, -0.0194, -0.0077],
        [ 0.0272, -0.0056, -0.0197,  ..., -0.0234,  0.0092, -0.0277],
        ...,
        [ 0.0239,  0.0135, -0.0127,  ..., -0.0233, -0.0399, -0.0581],
        [ 0.0161,  0.0086,  0.0133,  ...,  0.0302,  0.0043,  0.0115],
        [-0.0444,  0.0565,  0.0591,  ...,  0.0017, -0.0147,  0.0274]],
       dtype=torch.float16), 'model.layers.16.self_attn.v_proj.weight': tensor([[-0.0166,  0.0066, -0.0049,  ...,  0.0065, -0.0008, -0.0020],
        [-0.0576, -0.0069,  0.0042,  ...,  0.0035,  0.0128, -0.0267],
        [-0.0069, -0.0133, -0.0021,  ..., -0.0211,  0.0416,  0.0151],
        ...,
        [ 0.0040, -0.0079,  0.0167,  ..., -0.0125, -0.0001,  0.0166],
        [-0.0169,  0.0023,  0.0052,  ...,  0.0389, -0.0043,  0.0089],
        [ 0.0118,  0.0102,  0.0083,  ..., -0.0158, -0.0042, -0.0301]],
       dtype=torch.float16), 'model.layers.16.self_attn.o_proj.weight': tensor([[ 0.0388, -0.0079, -0.0170,  ...,  0.0112, -0.0126,  0.0047],
        [-0.0246,  0.0107, -0.0208,  ...,  0.0039, -0.0083,  0.0016],
        [-0.0285, -0.0177, -0.0134,  ..., -0.0021,  0.0259,  0.0170],
        ...,
        [-0.0030, -0.0207,  0.0029,  ...,  0.0046, -0.0266,  0.0010],
        [-0.0073,  0.0199,  0.0344,  ..., -0.0005,  0.0009, -0.0051],
        [-0.0192,  0.0035,  0.0066,  ...,  0.0018,  0.0024,  0.0109]],
       dtype=torch.float16), 'model.layers.16.mlp.gate_proj.weight': tensor([[-0.0275, -0.0157, -0.0233,  ...,  0.0007, -0.0003,  0.0085],
        [ 0.0313,  0.0157, -0.0098,  ...,  0.0153,  0.0087,  0.0166],
        [ 0.0027,  0.0056,  0.0041,  ..., -0.0008, -0.0035, -0.0189],
        ...,
        [-0.0086,  0.0085,  0.0053,  ...,  0.0223,  0.0300,  0.0286],
        [-0.0033, -0.0147,  0.0094,  ...,  0.0099,  0.0210,  0.0115],
        [ 0.0256,  0.0212,  0.0310,  ..., -0.0399,  0.0148, -0.0203]],
       dtype=torch.float16), 'model.layers.16.mlp.up_proj.weight': tensor([[-0.0403,  0.0147,  0.0066,  ...,  0.0294, -0.0128,  0.0091],
        [ 0.0156, -0.0131,  0.0048,  ...,  0.0215, -0.0303, -0.0077],
        [-0.0078, -0.0256, -0.0064,  ..., -0.0124, -0.0047,  0.0258],
        ...,
        [-0.0096,  0.0263, -0.0066,  ...,  0.0095, -0.0235, -0.0248],
        [-0.0098,  0.0216, -0.0177,  ...,  0.0097, -0.0052,  0.0185],
        [ 0.0099,  0.0079, -0.0118,  ...,  0.0013, -0.0239, -0.0209]],
       dtype=torch.float16), 'model.layers.16.mlp.down_proj.weight': tensor([[-0.0236,  0.0045,  0.0134,  ...,  0.0206, -0.0091, -0.0008],
        [-0.0233, -0.0041, -0.0123,  ...,  0.0286,  0.0018, -0.0002],
        [-0.0142,  0.0049, -0.0120,  ...,  0.0201, -0.0042, -0.0009],
        ...,
        [ 0.0143, -0.0248, -0.0242,  ...,  0.0203,  0.0178, -0.0020],
        [ 0.0227,  0.0019, -0.0097,  ..., -0.0214, -0.0128, -0.0098],
        [ 0.0107, -0.0168, -0.0371,  ...,  0.0256, -0.0010, -0.0141]],
       dtype=torch.float16), 'model.layers.16.input_layernorm.weight': tensor([0.4180, 0.4219, 0.3906,  ..., 0.3984, 0.4160, 0.4082],
       dtype=torch.float16), 'model.layers.16.post_attention_layernorm.weight': tensor([0.3164, 0.2949, 0.2988,  ..., 0.3105, 0.3086, 0.3047],
       dtype=torch.float16), 'model.layers.17.self_attn.q_proj.weight': tensor([[-0.0125, -0.0138,  0.0065,  ...,  0.0073, -0.0072, -0.0107],
        [ 0.0094, -0.0095,  0.0169,  ...,  0.0019, -0.0260,  0.0081],
        [-0.0130, -0.0020, -0.0129,  ...,  0.0152, -0.0114,  0.0020],
        ...,
        [ 0.0362, -0.0261,  0.0562,  ..., -0.0142, -0.0178,  0.0079],
        [ 0.0282, -0.0184,  0.0462,  ...,  0.0094, -0.0215, -0.0601],
        [ 0.0126, -0.0017,  0.0116,  ...,  0.0320,  0.0013,  0.0742]],
       dtype=torch.float16), 'model.layers.17.self_attn.k_proj.weight': tensor([[-0.0127, -0.0063,  0.0040,  ..., -0.0014,  0.0197,  0.0079],
        [ 0.0078,  0.0072,  0.0041,  ...,  0.0103,  0.0002, -0.0138],
        [ 0.0077, -0.0085,  0.0012,  ...,  0.0154, -0.0231, -0.0079],
        ...,
        [ 0.0041, -0.0500, -0.0091,  ..., -0.0221,  0.0599, -0.0676],
        [ 0.0275,  0.0191,  0.0122,  ..., -0.0132, -0.0267, -0.0225],
        [-0.0380, -0.0470, -0.0048,  ...,  0.0278,  0.0259, -0.0048]],
       dtype=torch.float16), 'model.layers.17.self_attn.v_proj.weight': tensor([[-0.0122,  0.0105,  0.0024,  ...,  0.0239, -0.0088, -0.0096],
        [-0.0039, -0.0155, -0.0111,  ...,  0.0116, -0.0257, -0.0144],
        [ 0.0174,  0.0158, -0.0024,  ...,  0.0018, -0.0111, -0.0288],
        ...,
        [ 0.0010, -0.0043,  0.0143,  ...,  0.0121,  0.0051, -0.0155],
        [ 0.0189, -0.0031, -0.0388,  ..., -0.0152, -0.0034, -0.0341],
        [-0.0093, -0.0103, -0.0053,  ...,  0.0055,  0.0081,  0.0092]],
       dtype=torch.float16), 'model.layers.17.self_attn.o_proj.weight': tensor([[-0.0049, -0.0105,  0.0036,  ..., -0.0197,  0.0008, -0.0131],
        [-0.0116, -0.0207,  0.0218,  ...,  0.0219, -0.0174,  0.0221],
        [ 0.0098, -0.0111, -0.0045,  ..., -0.0186, -0.0138, -0.0218],
        ...,
        [-0.0109,  0.0140, -0.0118,  ..., -0.0310, -0.0329, -0.0185],
        [-0.0070,  0.0101, -0.0009,  ..., -0.0287,  0.0044,  0.0065],
        [-0.0155, -0.0129,  0.0072,  ...,  0.0329, -0.0223,  0.0173]],
       dtype=torch.float16), 'model.layers.17.mlp.gate_proj.weight': tensor([[-0.0341,  0.0291,  0.0243,  ...,  0.0059,  0.0021,  0.0031],
        [-0.0008,  0.0264,  0.0270,  ...,  0.0185,  0.0077,  0.0121],
        [ 0.0100,  0.0120, -0.0222,  ...,  0.0171,  0.0307, -0.0055],
        ...,
        [-0.0114, -0.0160, -0.0122,  ..., -0.0103, -0.0229, -0.0157],
        [ 0.0041,  0.0033,  0.0092,  ...,  0.0065,  0.0431, -0.0114],
        [-0.0032,  0.0208,  0.0144,  ..., -0.0138, -0.0018, -0.0032]],
       dtype=torch.float16), 'model.layers.17.mlp.up_proj.weight': tensor([[-0.0169, -0.0280, -0.0067,  ...,  0.0061,  0.0168, -0.0130],
        [-0.0231,  0.0152,  0.0278,  ...,  0.0003,  0.0016,  0.0020],
        [-0.0010, -0.0031,  0.0035,  ...,  0.0089, -0.0150,  0.0119],
        ...,
        [ 0.0138,  0.0168,  0.0068,  ...,  0.0064, -0.0204, -0.0130],
        [-0.0162, -0.0182, -0.0103,  ..., -0.0115, -0.0220,  0.0159],
        [-0.0032,  0.0038, -0.0083,  ...,  0.0034, -0.0360, -0.0131]],
       dtype=torch.float16), 'model.layers.17.mlp.down_proj.weight': tensor([[ 0.0260, -0.0225,  0.0134,  ...,  0.0120, -0.0079, -0.0022],
        [ 0.0285,  0.0301,  0.0086,  ...,  0.0063, -0.0083,  0.0336],
        [-0.0263, -0.0165, -0.0178,  ...,  0.0121, -0.0150, -0.0046],
        ...,
        [ 0.0067, -0.0222, -0.0068,  ..., -0.0141, -0.0051, -0.0367],
        [ 0.0015,  0.0053, -0.0114,  ..., -0.0275, -0.0274,  0.0174],
        [-0.0009, -0.0200,  0.0189,  ..., -0.0368, -0.0108,  0.0045]],
       dtype=torch.float16), 'model.layers.17.input_layernorm.weight': tensor([0.4316, 0.4336, 0.4043,  ..., 0.4238, 0.4277, 0.4062],
       dtype=torch.float16), 'model.layers.17.post_attention_layernorm.weight': tensor([0.3320, 0.3164, 0.3145,  ..., 0.3320, 0.3301, 0.3223],
       dtype=torch.float16), 'model.layers.18.self_attn.q_proj.weight': tensor([[ 0.0067,  0.0054,  0.0022,  ..., -0.0046, -0.0363,  0.0100],
        [ 0.0022, -0.0133,  0.0213,  ...,  0.0001,  0.0255,  0.0434],
        [ 0.0111, -0.0257, -0.0097,  ...,  0.0015, -0.0081,  0.0164],
        ...,
        [-0.0324,  0.0133,  0.0033,  ...,  0.0230,  0.0055,  0.0155],
        [ 0.0622, -0.0166, -0.0270,  ...,  0.0574,  0.0266,  0.0184],
        [ 0.0301,  0.0155,  0.0043,  ...,  0.0281,  0.0549, -0.0513]],
       dtype=torch.float16), 'model.layers.18.self_attn.k_proj.weight': tensor([[-0.0115,  0.0326, -0.0141,  ...,  0.0089, -0.0094, -0.0243],
        [ 0.0082, -0.0191,  0.0162,  ...,  0.0176,  0.0292,  0.0015],
        [ 0.0123, -0.0097, -0.0019,  ...,  0.0210, -0.0017,  0.0248],
        ...,
        [-0.1082, -0.0282, -0.0618,  ...,  0.0203, -0.0044, -0.0386],
        [ 0.0520,  0.0363, -0.0182,  ...,  0.0459,  0.0646, -0.0261],
        [-0.0487, -0.0503, -0.0435,  ...,  0.0343, -0.0235, -0.0319]],
       dtype=torch.float16), 'model.layers.18.self_attn.v_proj.weight': tensor([[-0.0296,  0.0286, -0.0176,  ...,  0.0053,  0.0276,  0.0051],
        [ 0.0173,  0.0070, -0.0124,  ..., -0.0175,  0.0382, -0.0023],
        [ 0.0001,  0.0193,  0.0009,  ...,  0.0046, -0.0021, -0.0077],
        ...,
        [ 0.0137,  0.0160, -0.0047,  ..., -0.0077, -0.0233,  0.0025],
        [ 0.0073, -0.0028,  0.0031,  ...,  0.0136,  0.0159,  0.0355],
        [-0.0068,  0.0012,  0.0111,  ..., -0.0062, -0.0200,  0.0024]],
       dtype=torch.float16), 'model.layers.18.self_attn.o_proj.weight': tensor([[-0.0180,  0.0188, -0.0144,  ...,  0.0118,  0.0222,  0.0198],
        [-0.0003, -0.0400,  0.0047,  ..., -0.0010, -0.0070, -0.0164],
        [ 0.0022, -0.0141,  0.0099,  ...,  0.0279,  0.0158,  0.0373],
        ...,
        [-0.0351, -0.0236, -0.0248,  ...,  0.0230,  0.0176, -0.0098],
        [ 0.0128,  0.0511,  0.0149,  ...,  0.0131, -0.0084, -0.0367],
        [-0.0119, -0.0472, -0.0218,  ..., -0.0158,  0.0139, -0.0140]],
       dtype=torch.float16), 'model.layers.18.mlp.gate_proj.weight': tensor([[ 0.0147, -0.0038,  0.0166,  ..., -0.0080,  0.0101, -0.0105],
        [-0.0428,  0.0071, -0.0162,  ..., -0.0086, -0.0150, -0.0096],
        [-0.0190,  0.0073,  0.0444,  ..., -0.0250,  0.0031,  0.0038],
        ...,
        [-0.0438, -0.0219, -0.0285,  ..., -0.0296, -0.0218, -0.0233],
        [ 0.0015,  0.0197,  0.0297,  ..., -0.0164, -0.0011,  0.0164],
        [ 0.0040, -0.0041,  0.0039,  ...,  0.0107, -0.0188, -0.0050]],
       dtype=torch.float16), 'model.layers.18.mlp.up_proj.weight': tensor([[ 0.0165,  0.0081,  0.0298,  ..., -0.0004,  0.0271, -0.0095],
        [-0.0201,  0.0243, -0.0282,  ..., -0.0057, -0.0087, -0.0003],
        [-0.0311, -0.0098,  0.0076,  ...,  0.0074,  0.0209,  0.0261],
        ...,
        [-0.0012,  0.0045,  0.0046,  ...,  0.0238, -0.0075,  0.0040],
        [-0.0094, -0.0048, -0.0210,  ...,  0.0134,  0.0343,  0.0362],
        [ 0.0087,  0.0248,  0.0111,  ..., -0.0163,  0.0135,  0.0152]],
       dtype=torch.float16), 'model.layers.18.mlp.down_proj.weight': tensor([[ 0.0152,  0.0034, -0.0323,  ...,  0.0311,  0.0165,  0.0073],
        [ 0.0117, -0.0078,  0.0196,  ...,  0.0007, -0.0016, -0.0021],
        [ 0.0172, -0.0250, -0.0335,  ...,  0.0177,  0.0036,  0.0148],
        ...,
        [-0.0127,  0.0210,  0.0102,  ...,  0.0230, -0.0081, -0.0087],
        [-0.0160,  0.0116,  0.0182,  ...,  0.0120,  0.0356,  0.0087],
        [-0.0091,  0.0257,  0.0244,  ..., -0.0073,  0.0167,  0.0157]],
       dtype=torch.float16), 'model.layers.18.input_layernorm.weight': tensor([0.4570, 0.4551, 0.4316,  ..., 0.4375, 0.4512, 0.4355],
       dtype=torch.float16), 'model.layers.18.post_attention_layernorm.weight': tensor([0.3477, 0.3340, 0.3320,  ..., 0.3477, 0.3496, 0.3457],
       dtype=torch.float16), 'model.layers.19.self_attn.q_proj.weight': tensor([[ 5.5275e-03,  7.6294e-03, -9.7961e-03,  ..., -1.0323e-02,
         -3.1209e-04,  8.8806e-03],
        [ 2.6894e-03, -2.5539e-03,  3.1719e-03,  ..., -4.7493e-03,
          2.9022e-02,  1.7868e-02],
        [ 5.2185e-03,  2.1896e-02,  4.5896e-05,  ...,  8.6498e-04,
          1.5182e-02,  3.0727e-03],
        ...,
        [-1.4160e-02, -1.4923e-02,  1.0290e-03,  ..., -4.4189e-02,
         -3.1805e-04,  2.4979e-02],
        [ 4.7226e-03,  4.8279e-02,  2.3041e-02,  ...,  5.4077e-02,
          2.9755e-02, -2.9358e-02],
        [-1.5991e-02,  4.9011e-02,  5.8014e-02,  ..., -6.6414e-03,
         -4.1382e-02, -1.4290e-02]], dtype=torch.float16), 'model.layers.19.self_attn.k_proj.weight': tensor([[ 0.0216,  0.0117,  0.0022,  ..., -0.0116, -0.0213, -0.0106],
        [-0.0142,  0.0180, -0.0159,  ...,  0.0100,  0.0034,  0.0251],
        [-0.0157,  0.0043, -0.0122,  ...,  0.0044,  0.0137,  0.0252],
        ...,
        [ 0.0005,  0.0502, -0.0095,  ..., -0.0208,  0.0299, -0.0225],
        [-0.0653, -0.0269, -0.0101,  ...,  0.0084,  0.0184, -0.0099],
        [-0.0202,  0.0115, -0.0150,  ..., -0.0266,  0.0129,  0.0399]],
       dtype=torch.float16), 'model.layers.19.self_attn.v_proj.weight': tensor([[-0.0011, -0.0055, -0.0055,  ..., -0.0020,  0.0005,  0.0070],
        [-0.0020,  0.0188, -0.0031,  ...,  0.0351, -0.0211,  0.0162],
        [-0.0448, -0.0359, -0.0080,  ..., -0.0085, -0.0002,  0.0056],
        ...,
        [ 0.0013, -0.0373, -0.0014,  ...,  0.0010, -0.0002, -0.0166],
        [ 0.0145, -0.0095, -0.0219,  ..., -0.0066, -0.0073, -0.0058],
        [-0.0033,  0.0275,  0.0008,  ..., -0.0254, -0.0120,  0.0062]],
       dtype=torch.float16), 'model.layers.19.self_attn.o_proj.weight': tensor([[ 0.0296, -0.0517,  0.0258,  ...,  0.0012,  0.0066, -0.0257],
        [ 0.0307, -0.0164, -0.0036,  ..., -0.0145, -0.0012, -0.0030],
        [-0.0033, -0.0176, -0.0195,  ...,  0.0010,  0.0150,  0.0012],
        ...,
        [ 0.0123, -0.0018,  0.0002,  ...,  0.0056, -0.0152,  0.0122],
        [ 0.0089, -0.0057, -0.0186,  ..., -0.0244, -0.0204,  0.0051],
        [ 0.0127,  0.0175,  0.0140,  ..., -0.0233, -0.0083,  0.0153]],
       dtype=torch.float16), 'model.layers.19.mlp.gate_proj.weight': tensor([[-0.0082,  0.0010,  0.0049,  ..., -0.0039,  0.0037, -0.0065],
        [ 0.0145,  0.0183,  0.0011,  ..., -0.0036,  0.0125, -0.0351],
        [-0.0169, -0.0121, -0.0127,  ..., -0.0433,  0.0002,  0.0285],
        ...,
        [-0.0016,  0.0101, -0.0004,  ..., -0.0291, -0.0092, -0.0010],
        [-0.0475, -0.0082,  0.0029,  ..., -0.0074, -0.0217,  0.0107],
        [-0.0205, -0.0197,  0.0153,  ...,  0.0069,  0.0052, -0.0020]],
       dtype=torch.float16), 'model.layers.19.mlp.up_proj.weight': tensor([[ 0.0020, -0.0107,  0.0096,  ...,  0.0065,  0.0100,  0.0032],
        [-0.0134, -0.0063, -0.0158,  ...,  0.0269, -0.0230, -0.0070],
        [ 0.0094,  0.0039,  0.0094,  ..., -0.0246, -0.0129,  0.0532],
        ...,
        [ 0.0142,  0.0140,  0.0074,  ...,  0.0136, -0.0170,  0.0311],
        [ 0.0013,  0.0262,  0.0249,  ..., -0.0094,  0.0361, -0.0004],
        [-0.0002, -0.0181, -0.0124,  ..., -0.0027,  0.0045,  0.0140]],
       dtype=torch.float16), 'model.layers.19.mlp.down_proj.weight': tensor([[-0.0026, -0.0278,  0.0015,  ...,  0.0057, -0.0235,  0.0278],
        [-0.0050, -0.0306, -0.0208,  ...,  0.0139,  0.0175, -0.0169],
        [-0.0209, -0.0261,  0.0290,  ...,  0.0159, -0.0008,  0.0071],
        ...,
        [-0.0104, -0.0050,  0.0274,  ...,  0.0129,  0.0162,  0.0012],
        [ 0.0065, -0.0093, -0.0501,  ...,  0.0219, -0.0086, -0.0152],
        [ 0.0041, -0.0093, -0.0342,  ...,  0.0006,  0.0090,  0.0042]],
       dtype=torch.float16), 'model.layers.19.input_layernorm.weight': tensor([0.4570, 0.4629, 0.4395,  ..., 0.4316, 0.4395, 0.4414],
       dtype=torch.float16), 'model.layers.19.post_attention_layernorm.weight': tensor([0.3613, 0.3477, 0.3457,  ..., 0.3574, 0.3555, 0.3594],
       dtype=torch.float16), 'model.layers.20.self_attn.q_proj.weight': tensor([[-3.3512e-03,  2.7599e-03,  2.2141e-02,  ...,  3.8643e-03,
          3.5381e-03, -2.3499e-02],
        [ 1.8127e-02, -2.1729e-02, -4.8876e-06,  ..., -6.9809e-03,
         -1.2131e-02,  1.7120e-02],
        [ 7.9117e-03, -6.8665e-03, -1.8326e-02,  ...,  1.7166e-02,
          7.0038e-03,  8.3780e-04],
        ...,
        [-3.1219e-02, -5.3162e-02,  1.0094e-02,  ..., -1.0918e-02,
          3.9520e-02,  1.1047e-02],
        [-8.0872e-02, -1.9455e-02,  1.1688e-02,  ...,  8.7585e-03,
          2.6505e-02,  8.3389e-03],
        [ 2.6978e-02,  2.4643e-03, -5.2071e-03,  ..., -1.9089e-02,
         -5.4512e-03, -1.3123e-03]], dtype=torch.float16), 'model.layers.20.self_attn.k_proj.weight': tensor([[-5.6038e-03,  7.3128e-03,  3.8834e-03,  ..., -1.6464e-02,
         -3.4750e-05,  3.6964e-03],
        [-3.7003e-04,  8.7585e-03,  4.4060e-03,  ..., -2.0161e-03,
          4.6120e-03,  1.1047e-02],
        [ 1.4694e-02,  2.8610e-03, -1.1185e-02,  ..., -1.5091e-02,
          1.4725e-03,  1.9836e-02],
        ...,
        [ 2.0256e-03,  4.9706e-03, -1.7044e-02,  ..., -2.3407e-02,
          2.5925e-02,  3.5919e-02],
        [-2.4094e-02,  2.4918e-02,  2.4490e-03,  ...,  2.1759e-02,
          3.0762e-02,  5.1605e-02],
        [-1.5228e-02, -3.0060e-02, -1.5793e-02,  ...,  2.0111e-02,
         -2.3468e-02,  5.2704e-02]], dtype=torch.float16), 'model.layers.20.self_attn.v_proj.weight': tensor([[-7.1526e-03, -1.8005e-02,  1.3290e-02,  ..., -2.7752e-03,
          1.9043e-02,  1.1086e-02],
        [-1.5945e-02, -3.7201e-02,  5.2223e-03,  ..., -1.2299e-02,
          3.4332e-04,  9.0942e-03],
        [-3.0174e-03, -1.3779e-02,  3.5763e-03,  ..., -2.5085e-02,
          9.9301e-05,  6.9046e-04],
        ...,
        [ 9.6893e-03, -1.2962e-02, -2.5940e-03,  ...,  2.4796e-02,
         -7.9269e-03,  9.0103e-03],
        [ 1.8799e-02,  1.4400e-03, -9.5062e-03,  ...,  8.0681e-04,
          1.1032e-02, -1.3542e-02],
        [ 2.3708e-03, -3.8452e-03,  2.4155e-02,  ..., -5.8403e-03,
         -1.1604e-02, -4.0283e-02]], dtype=torch.float16), 'model.layers.20.self_attn.o_proj.weight': tensor([[-0.0066,  0.0037,  0.0200,  ..., -0.0024,  0.0155, -0.0167],
        [ 0.0103, -0.0098, -0.0066,  ..., -0.0050, -0.0065,  0.0191],
        [ 0.0099, -0.0022, -0.0135,  ..., -0.0240,  0.0092,  0.0103],
        ...,
        [-0.0074, -0.0039,  0.0135,  ...,  0.0168, -0.0150,  0.0116],
        [-0.0101,  0.0031, -0.0113,  ...,  0.0121, -0.0273,  0.0036],
        [ 0.0107, -0.0183, -0.0039,  ...,  0.0065, -0.0230,  0.0195]],
       dtype=torch.float16), 'model.layers.20.mlp.gate_proj.weight': tensor([[ 0.0012, -0.0088, -0.0118,  ...,  0.0177, -0.0055,  0.0139],
        [-0.0275,  0.0091, -0.0060,  ..., -0.0098, -0.0143,  0.0149],
        [-0.0167, -0.0078,  0.0665,  ..., -0.0155,  0.0111, -0.0063],
        ...,
        [-0.0048, -0.0114,  0.0241,  ..., -0.0145,  0.0109, -0.0033],
        [ 0.0093,  0.0071,  0.0046,  ...,  0.0154,  0.0030,  0.0123],
        [-0.0032, -0.0308, -0.0070,  ...,  0.0059, -0.0142, -0.0134]],
       dtype=torch.float16), 'model.layers.20.mlp.up_proj.weight': tensor([[-0.0601, -0.0002, -0.0019,  ...,  0.0153, -0.0108, -0.0119],
        [-0.0098,  0.0006, -0.0098,  ..., -0.0502, -0.0143,  0.0372],
        [ 0.0060,  0.0302,  0.0182,  ...,  0.0070, -0.0175,  0.0047],
        ...,
        [-0.0139,  0.0211, -0.0016,  ..., -0.0180, -0.0043, -0.0030],
        [ 0.0155, -0.0318, -0.0148,  ...,  0.0031, -0.0208, -0.0377],
        [ 0.0145, -0.0241,  0.0311,  ..., -0.0039, -0.0222,  0.0036]],
       dtype=torch.float16), 'model.layers.20.mlp.down_proj.weight': tensor([[-0.0016,  0.0202, -0.0034,  ...,  0.0053, -0.0169, -0.0248],
        [ 0.0021,  0.0127, -0.0073,  ...,  0.0044, -0.0178,  0.0143],
        [-0.0127,  0.0180, -0.0242,  ..., -0.0042,  0.0238, -0.0053],
        ...,
        [-0.0375,  0.0276,  0.0056,  ...,  0.0026, -0.0002, -0.0114],
        [-0.0156,  0.0062, -0.0158,  ...,  0.0057,  0.0178, -0.0025],
        [ 0.0120, -0.0131,  0.0019,  ..., -0.0029, -0.0063, -0.0147]],
       dtype=torch.float16), 'model.layers.20.input_layernorm.weight': tensor([0.4590, 0.4688, 0.4395,  ..., 0.4414, 0.4375, 0.4590],
       dtype=torch.float16), 'model.layers.20.post_attention_layernorm.weight': tensor([0.3711, 0.3633, 0.3535,  ..., 0.3672, 0.3672, 0.3691],
       dtype=torch.float16), 'model.layers.21.self_attn.q_proj.weight': tensor([[-0.0138, -0.0057,  0.0144,  ..., -0.0153, -0.0030,  0.0070],
        [ 0.0252,  0.0060, -0.0012,  ...,  0.0031,  0.0002,  0.0141],
        [-0.0117, -0.0101,  0.0026,  ...,  0.0280,  0.0023,  0.0066],
        ...,
        [-0.0025, -0.0157,  0.0354,  ..., -0.0107, -0.0593,  0.0191],
        [-0.0115,  0.0166,  0.0210,  ...,  0.0295,  0.0328,  0.0014],
        [-0.0795, -0.0016, -0.0130,  ..., -0.0056,  0.0264, -0.0380]],
       dtype=torch.float16), 'model.layers.21.self_attn.k_proj.weight': tensor([[-1.3864e-04,  4.9858e-03, -3.4065e-03,  ...,  7.4348e-03,
          3.9625e-04,  1.0353e-02],
        [-8.3685e-05,  7.3128e-03,  1.9882e-02,  ...,  6.2561e-03,
          9.4681e-03,  8.8806e-03],
        [ 1.8494e-02,  2.9202e-03,  2.8900e-02,  ...,  1.5823e-02,
          1.2871e-02,  1.4816e-02],
        ...,
        [-1.8295e-02,  2.6428e-02,  1.5945e-03,  ...,  2.5818e-02,
         -1.9394e-02,  4.6265e-02],
        [ 2.0866e-03, -3.1281e-03, -1.4458e-02,  ..., -2.2232e-02,
          3.1250e-02,  1.6203e-03],
        [-1.8906e-02, -8.1329e-03, -3.1433e-02,  ...,  7.8888e-03,
         -7.5493e-03,  5.9235e-02]], dtype=torch.float16), 'model.layers.21.self_attn.v_proj.weight': tensor([[ 0.0032,  0.0054, -0.0003,  ...,  0.0005,  0.0223, -0.0286],
        [-0.0232,  0.0240, -0.0079,  ...,  0.0211, -0.0195,  0.0266],
        [ 0.0280, -0.0030,  0.0003,  ..., -0.0232,  0.0258, -0.0058],
        ...,
        [-0.0056, -0.0269,  0.0320,  ..., -0.0065,  0.0038, -0.0102],
        [-0.0154, -0.0090,  0.0156,  ...,  0.0048, -0.0052,  0.0086],
        [-0.0069,  0.0157, -0.0162,  ...,  0.0070, -0.0155, -0.0029]],
       dtype=torch.float16), 'model.layers.21.self_attn.o_proj.weight': tensor([[-0.0118, -0.0017,  0.0116,  ..., -0.0132,  0.0231,  0.0102],
        [-0.0058,  0.0267, -0.0098,  ..., -0.0189,  0.0061, -0.0112],
        [-0.0298, -0.0130,  0.0119,  ...,  0.0249,  0.0273,  0.0079],
        ...,
        [ 0.0198, -0.0042, -0.0136,  ...,  0.0248, -0.0006,  0.0144],
        [ 0.0152, -0.0136,  0.0135,  ..., -0.0006,  0.0018, -0.0185],
        [-0.0264,  0.0155, -0.0134,  ...,  0.0298, -0.0163,  0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.gate_proj.weight': tensor([[-0.0058, -0.0234,  0.0144,  ..., -0.0285,  0.0456,  0.0089],
        [ 0.0061,  0.0061,  0.0039,  ..., -0.0275,  0.0574,  0.0085],
        [ 0.0084,  0.0064,  0.0049,  ..., -0.0498,  0.0041, -0.0245],
        ...,
        [ 0.0102, -0.0292, -0.0215,  ...,  0.0331, -0.0270,  0.0024],
        [-0.0010,  0.0293,  0.0065,  ...,  0.0160, -0.0249,  0.0030],
        [ 0.0093, -0.0124, -0.0017,  ..., -0.0182,  0.0064, -0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.up_proj.weight': tensor([[ 0.0276, -0.0258, -0.0142,  ...,  0.0225,  0.0422, -0.0112],
        [-0.0261, -0.0107,  0.0040,  ...,  0.0379,  0.0453, -0.0010],
        [ 0.0133, -0.0011, -0.0018,  ...,  0.0067, -0.0079, -0.0061],
        ...,
        [-0.0461, -0.0002,  0.0137,  ...,  0.0162, -0.0095, -0.0118],
        [-0.0100, -0.0107,  0.0042,  ..., -0.0188, -0.0023,  0.0027],
        [-0.0051, -0.0337, -0.0248,  ..., -0.0035, -0.0055, -0.0260]],
       dtype=torch.float16), 'model.layers.21.mlp.down_proj.weight': tensor([[ 0.0117,  0.0132,  0.0028,  ...,  0.0198,  0.0068,  0.0062],
        [ 0.0095, -0.0029, -0.0151,  ...,  0.0037, -0.0319, -0.0163],
        [-0.0061,  0.0059,  0.0132,  ..., -0.0084,  0.0412,  0.0299],
        ...,
        [-0.0106,  0.0375,  0.0182,  ..., -0.0093, -0.0024,  0.0179],
        [ 0.0125,  0.0007, -0.0043,  ..., -0.0493, -0.0052,  0.0049],
        [ 0.0089,  0.0014,  0.0242,  ..., -0.0152,  0.0267, -0.0278]],
       dtype=torch.float16), 'model.layers.21.input_layernorm.weight': tensor([0.4805, 0.4883, 0.4688,  ..., 0.4609, 0.4805, 0.4824],
       dtype=torch.float16), 'model.layers.21.post_attention_layernorm.weight': tensor([0.3770, 0.3730, 0.3652,  ..., 0.3848, 0.3789, 0.3828],
       dtype=torch.float16), 'model.layers.22.self_attn.q_proj.weight': tensor([[-0.0249, -0.0096, -0.0046,  ...,  0.0535, -0.0391,  0.0201],
        [-0.0361, -0.0200, -0.0063,  ..., -0.0361,  0.0211, -0.0515],
        [-0.0322,  0.0232, -0.0146,  ...,  0.0286,  0.0173, -0.0100],
        ...,
        [ 0.0094,  0.0199,  0.0122,  ...,  0.0116,  0.0576, -0.0013],
        [-0.0323,  0.0064, -0.0220,  ...,  0.0465,  0.0088, -0.0131],
        [ 0.0380, -0.0125,  0.0065,  ..., -0.0505,  0.0111,  0.0195]],
       dtype=torch.float16), 'model.layers.22.self_attn.k_proj.weight': tensor([[-0.0130, -0.0065,  0.0037,  ...,  0.0139, -0.0164, -0.0157],
        [ 0.0106, -0.0099,  0.0312,  ..., -0.0320,  0.0375, -0.0140],
        [-0.0207,  0.0286, -0.0425,  ...,  0.0614,  0.0035, -0.0076],
        ...,
        [ 0.0210,  0.0074, -0.0286,  ..., -0.0204, -0.0135,  0.0172],
        [-0.0150, -0.0424,  0.0025,  ..., -0.0002, -0.0132, -0.0070],
        [ 0.0240, -0.0025,  0.0283,  ...,  0.0377, -0.0425,  0.0131]],
       dtype=torch.float16), 'model.layers.22.self_attn.v_proj.weight': tensor([[-0.0201,  0.0126, -0.0017,  ..., -0.0395, -0.0264,  0.0152],
        [-0.0346, -0.0108,  0.0072,  ..., -0.0269, -0.0413, -0.0159],
        [ 0.0243, -0.0267, -0.0040,  ...,  0.0528, -0.0026, -0.0139],
        ...,
        [-0.0104, -0.0462, -0.0226,  ...,  0.0124, -0.0114,  0.0218],
        [-0.0375, -0.0086,  0.0181,  ..., -0.0198,  0.0020, -0.0155],
        [ 0.0007,  0.0152, -0.0433,  ...,  0.0020, -0.0053,  0.0264]],
       dtype=torch.float16), 'model.layers.22.self_attn.o_proj.weight': tensor([[ 0.0263,  0.0156, -0.0218,  ..., -0.0026, -0.0353,  0.0123],
        [ 0.0242,  0.0126,  0.0108,  ...,  0.0045, -0.0100, -0.0247],
        [ 0.0046,  0.0026, -0.0081,  ..., -0.0232,  0.0110,  0.0107],
        ...,
        [-0.0008, -0.0238, -0.0129,  ..., -0.0138, -0.0166,  0.0042],
        [ 0.0259, -0.0104, -0.0196,  ..., -0.0260, -0.0027,  0.0137],
        [ 0.0039, -0.0258,  0.0213,  ...,  0.0115,  0.0122,  0.0111]],
       dtype=torch.float16), 'model.layers.22.mlp.gate_proj.weight': tensor([[-0.0284, -0.0156,  0.0184,  ...,  0.0108,  0.0197, -0.0452],
        [ 0.0226, -0.0165,  0.0014,  ...,  0.0043,  0.0029,  0.0221],
        [ 0.0005, -0.0069,  0.0054,  ...,  0.0142,  0.0002, -0.0003],
        ...,
        [-0.0043, -0.0079,  0.0014,  ..., -0.0152,  0.0073,  0.0022],
        [ 0.0095,  0.0165, -0.0293,  ..., -0.0035,  0.0127, -0.0289],
        [-0.0101,  0.0012,  0.0053,  ..., -0.0148,  0.0278,  0.0245]],
       dtype=torch.float16), 'model.layers.22.mlp.up_proj.weight': tensor([[ 0.0293,  0.0162, -0.0013,  ...,  0.0170,  0.0276,  0.0071],
        [ 0.0198,  0.0076,  0.0164,  ..., -0.0117, -0.0078,  0.0030],
        [ 0.0086, -0.0282, -0.0375,  ...,  0.0255,  0.0104,  0.0061],
        ...,
        [-0.0032, -0.0006, -0.0185,  ..., -0.0040,  0.0057,  0.0067],
        [ 0.0126, -0.0111, -0.0286,  ..., -0.0226,  0.0108, -0.0270],
        [-0.0014,  0.0023, -0.0036,  ..., -0.0440, -0.0598,  0.0154]],
       dtype=torch.float16), 'model.layers.22.mlp.down_proj.weight': tensor([[ 1.3527e-02, -5.1918e-03,  1.2299e-02,  ..., -1.8967e-02,
         -4.1428e-03, -3.6041e-02],
        [ 5.5885e-03,  2.6581e-02, -4.9362e-03,  ..., -1.1017e-02,
          1.4084e-02, -2.6627e-02],
        [-9.6512e-03,  3.9363e-04,  4.1962e-03,  ...,  1.2886e-02,
          4.5013e-03,  1.7517e-02],
        ...,
        [ 1.8250e-02, -8.5297e-03, -4.5288e-02,  ..., -2.8934e-03,
         -1.2947e-02, -1.7014e-02],
        [-1.1414e-02, -4.8767e-02,  1.1642e-02,  ...,  1.9028e-02,
         -2.7069e-02,  3.1433e-02],
        [ 1.4130e-02,  3.7551e-06, -3.1067e-02,  ..., -3.3903e-04,
         -1.8875e-02,  2.1286e-03]], dtype=torch.float16), 'model.layers.22.input_layernorm.weight': tensor([0.4883, 0.4922, 0.4805,  ..., 0.4688, 0.5000, 0.4902],
       dtype=torch.float16), 'model.layers.22.post_attention_layernorm.weight': tensor([0.3867, 0.3848, 0.3848,  ..., 0.3965, 0.3945, 0.3965],
       dtype=torch.float16), 'model.layers.23.self_attn.q_proj.weight': tensor([[-0.0039, -0.0179,  0.0076,  ..., -0.0155, -0.0002,  0.0023],
        [ 0.0042,  0.0015,  0.0140,  ..., -0.0166, -0.0002,  0.0083],
        [-0.0038,  0.0028,  0.0219,  ...,  0.0002, -0.0167,  0.0066],
        ...,
        [-0.0211,  0.0670,  0.0119,  ..., -0.0314, -0.0684, -0.0263],
        [-0.0411, -0.0311,  0.0199,  ..., -0.0232,  0.0020,  0.0060],
        [ 0.0047, -0.0559, -0.0093,  ...,  0.0072,  0.0403, -0.0026]],
       dtype=torch.float16), 'model.layers.23.self_attn.k_proj.weight': tensor([[-0.0030,  0.0121,  0.0090,  ...,  0.0010, -0.0083,  0.0059],
        [-0.0224,  0.0057, -0.0117,  ...,  0.0093,  0.0254,  0.0036],
        [ 0.0182,  0.0078, -0.0185,  ...,  0.0181,  0.0016, -0.0107],
        ...,
        [ 0.0067,  0.0374,  0.0580,  ..., -0.0332, -0.0120, -0.0131],
        [ 0.0034, -0.0352, -0.0113,  ..., -0.0232, -0.0226,  0.0194],
        [-0.0173, -0.0081, -0.0259,  ...,  0.0043,  0.0060, -0.0084]],
       dtype=torch.float16), 'model.layers.23.self_attn.v_proj.weight': tensor([[-0.0028,  0.0343, -0.0120,  ..., -0.0097, -0.0016, -0.0112],
        [-0.0093, -0.0038, -0.0190,  ..., -0.0033, -0.0097,  0.0105],
        [ 0.0111, -0.0211, -0.0208,  ...,  0.0130, -0.0508, -0.0305],
        ...,
        [ 0.0070,  0.0084,  0.0091,  ..., -0.0020,  0.0338,  0.0089],
        [ 0.0261,  0.0316, -0.0011,  ...,  0.0070,  0.0022, -0.0127],
        [-0.0201, -0.0131, -0.0540,  ...,  0.0057,  0.0076, -0.0381]],
       dtype=torch.float16), 'model.layers.23.self_attn.o_proj.weight': tensor([[-0.0019,  0.0019, -0.0202,  ..., -0.0179,  0.0104, -0.0070],
        [-0.0127, -0.0213, -0.0022,  ..., -0.0004,  0.0100, -0.0021],
        [ 0.0130,  0.0094,  0.0306,  ..., -0.0228, -0.0026, -0.0276],
        ...,
        [ 0.0290, -0.0114,  0.0348,  ..., -0.0162,  0.0113, -0.0013],
        [-0.0044,  0.0202, -0.0200,  ...,  0.0056, -0.0164,  0.0007],
        [ 0.0013, -0.0023, -0.0177,  ..., -0.0060,  0.0059, -0.0296]],
       dtype=torch.float16), 'model.layers.23.mlp.gate_proj.weight': tensor([[-1.1848e-02,  3.4424e-02, -1.0048e-02,  ..., -7.0152e-03,
          3.2776e-02,  9.2316e-03],
        [-1.4702e-02,  4.7729e-02, -1.7593e-02,  ...,  7.1678e-03,
         -1.8631e-02,  2.5070e-02],
        [-3.2349e-02,  1.4786e-02,  2.6913e-03,  ...,  1.5274e-02,
         -6.7444e-02,  1.2131e-02],
        ...,
        [-3.1548e-03,  1.9089e-02,  3.1509e-03,  ..., -8.1863e-03,
          7.2556e-03, -2.4643e-03],
        [-2.0828e-02,  3.8971e-02,  2.9430e-03,  ...,  3.3021e-05,
          7.8201e-03, -2.8381e-02],
        [ 8.8692e-04,  8.5144e-03,  1.6830e-02,  ..., -7.6561e-03,
          1.5450e-02, -1.6495e-02]], dtype=torch.float16), 'model.layers.23.mlp.up_proj.weight': tensor([[ 0.0283,  0.0066,  0.0351,  ...,  0.0134, -0.0322, -0.0074],
        [-0.0003,  0.0065, -0.0196,  ..., -0.0043, -0.0111,  0.0061],
        [-0.0177,  0.0038, -0.0218,  ...,  0.0182,  0.0106, -0.0052],
        ...,
        [-0.0084, -0.0166,  0.0116,  ...,  0.0093,  0.0408,  0.0053],
        [ 0.0036,  0.0078, -0.0382,  ...,  0.0106,  0.0070,  0.0220],
        [ 0.0014,  0.0079, -0.0071,  ...,  0.0070, -0.0126,  0.0127]],
       dtype=torch.float16), 'model.layers.23.mlp.down_proj.weight': tensor([[-0.0008,  0.0069, -0.0182,  ..., -0.0434, -0.0227,  0.0330],
        [-0.0012,  0.0231, -0.0064,  ...,  0.0257,  0.0306,  0.0021],
        [-0.0066, -0.0139, -0.0233,  ...,  0.0102,  0.0330, -0.0052],
        ...,
        [ 0.0001, -0.0050,  0.0135,  ...,  0.0180,  0.0037, -0.0187],
        [ 0.0296, -0.0114, -0.0007,  ..., -0.0026,  0.0101,  0.0058],
        [ 0.0031, -0.0307, -0.0152,  ..., -0.0104,  0.0204, -0.0025]],
       dtype=torch.float16), 'model.layers.23.input_layernorm.weight': tensor([0.5156, 0.5312, 0.5117,  ..., 0.5039, 0.5352, 0.5273],
       dtype=torch.float16), 'model.layers.23.post_attention_layernorm.weight': tensor([0.4043, 0.4023, 0.3965,  ..., 0.4043, 0.4121, 0.4062],
       dtype=torch.float16), 'model.layers.24.self_attn.q_proj.weight': tensor([[ 0.0204, -0.0176,  0.0145,  ...,  0.0364, -0.0300,  0.0106],
        [ 0.0215,  0.0088,  0.0012,  ..., -0.0026,  0.0186, -0.0139],
        [-0.0056, -0.0111, -0.0277,  ...,  0.0088, -0.0132,  0.0202],
        ...,
        [-0.0147,  0.0136, -0.0193,  ...,  0.0181, -0.0004, -0.0123],
        [-0.0288,  0.0078,  0.0070,  ...,  0.0100, -0.0323, -0.0062],
        [-0.0231, -0.0385, -0.0181,  ..., -0.0132,  0.0128,  0.0677]],
       dtype=torch.float16), 'model.layers.24.self_attn.k_proj.weight': tensor([[ 0.0235, -0.0035, -0.0125,  ...,  0.0110, -0.0008,  0.0021],
        [ 0.0118, -0.0169,  0.0035,  ..., -0.0216,  0.0245,  0.0066],
        [ 0.0097,  0.0045, -0.0445,  ...,  0.0204,  0.0171, -0.0175],
        ...,
        [ 0.0344,  0.0036,  0.0493,  ...,  0.0161,  0.0179, -0.0516],
        [-0.0119,  0.0177,  0.0127,  ...,  0.0320, -0.0181,  0.0027],
        [-0.0318, -0.0295, -0.0190,  ...,  0.0139, -0.0048,  0.0518]],
       dtype=torch.float16), 'model.layers.24.self_attn.v_proj.weight': tensor([[ 0.0212, -0.0251, -0.0028,  ..., -0.0041, -0.0040,  0.0113],
        [ 0.0288, -0.0173, -0.0054,  ..., -0.0646, -0.0470, -0.0240],
        [-0.0579, -0.0169, -0.0134,  ..., -0.0156, -0.0121, -0.0027],
        ...,
        [ 0.0011, -0.0192,  0.0171,  ...,  0.0272,  0.0067,  0.0217],
        [-0.0034, -0.0157, -0.0141,  ...,  0.0332, -0.0036,  0.0038],
        [ 0.0172,  0.0228,  0.0187,  ...,  0.0274, -0.0135, -0.0108]],
       dtype=torch.float16), 'model.layers.24.self_attn.o_proj.weight': tensor([[-0.0016,  0.0144,  0.0280,  ...,  0.0066, -0.0051, -0.0141],
        [-0.0118,  0.0308,  0.0156,  ...,  0.0195,  0.0282, -0.0186],
        [-0.0057, -0.0029,  0.0094,  ..., -0.0232,  0.0084, -0.0049],
        ...,
        [ 0.0045,  0.0179,  0.0119,  ..., -0.0027, -0.0031, -0.0005],
        [ 0.0508,  0.0096, -0.0061,  ...,  0.0075, -0.0257, -0.0106],
        [ 0.0026,  0.0155,  0.0109,  ...,  0.0046, -0.0261,  0.0131]],
       dtype=torch.float16), 'model.layers.24.mlp.gate_proj.weight': tensor([[-0.0267, -0.0104,  0.0093,  ..., -0.0031, -0.0058,  0.0011],
        [ 0.0075, -0.0302, -0.0231,  ...,  0.0075,  0.0110, -0.0131],
        [ 0.0014, -0.0466,  0.0257,  ...,  0.0015, -0.0532, -0.0207],
        ...,
        [ 0.0042, -0.0358, -0.0088,  ...,  0.0080,  0.0152, -0.0062],
        [ 0.0094,  0.0158,  0.0041,  ...,  0.0043,  0.0011,  0.0048],
        [-0.0410,  0.0326,  0.0009,  ...,  0.0294, -0.0074, -0.0473]],
       dtype=torch.float16), 'model.layers.24.mlp.up_proj.weight': tensor([[ 0.0016, -0.0057,  0.0201,  ...,  0.0262,  0.0025,  0.0263],
        [-0.0026,  0.0136, -0.0327,  ..., -0.0081, -0.0044, -0.0171],
        [ 0.0114, -0.0520,  0.0097,  ...,  0.0402,  0.0179, -0.0341],
        ...,
        [ 0.0115, -0.0207, -0.0147,  ..., -0.0067,  0.0112,  0.0111],
        [ 0.0412, -0.0033,  0.0132,  ...,  0.0025,  0.0054, -0.0100],
        [-0.0056, -0.0197,  0.0203,  ...,  0.0303,  0.0333,  0.0164]],
       dtype=torch.float16), 'model.layers.24.mlp.down_proj.weight': tensor([[-0.0052, -0.0114, -0.0357,  ...,  0.0015,  0.0022, -0.0194],
        [ 0.0278, -0.0030,  0.0175,  ..., -0.0015,  0.0048, -0.0508],
        [ 0.0195,  0.0135, -0.0284,  ...,  0.0095,  0.0215,  0.0078],
        ...,
        [-0.0092,  0.0149, -0.0204,  ..., -0.0330, -0.0109, -0.0146],
        [ 0.0112,  0.0248,  0.0120,  ...,  0.0257, -0.0255,  0.0133],
        [-0.0171, -0.0086,  0.0033,  ...,  0.0172, -0.0154, -0.0324]],
       dtype=torch.float16), 'model.layers.24.input_layernorm.weight': tensor([0.4980, 0.5273, 0.5195,  ..., 0.4863, 0.5234, 0.5156],
       dtype=torch.float16), 'model.layers.24.post_attention_layernorm.weight': tensor([0.4219, 0.4180, 0.4180,  ..., 0.4199, 0.4258, 0.4219],
       dtype=torch.float16), 'model.layers.25.self_attn.q_proj.weight': tensor([[ 1.7204e-03, -1.9974e-02, -2.5269e-02,  ...,  1.2192e-02,
         -9.5139e-03,  4.5357e-03],
        [-1.3947e-02,  3.5877e-03,  2.3804e-02,  ..., -1.4412e-02,
         -3.4485e-03,  2.4557e-05],
        [ 9.1629e-03,  8.6136e-03,  3.9368e-03,  ..., -1.1436e-02,
         -2.0157e-02, -1.5068e-02],
        ...,
        [ 5.5756e-02,  4.5746e-02,  2.2964e-03,  ...,  4.9858e-03,
          1.5762e-02, -2.6688e-02],
        [-6.3721e-02, -5.0293e-02, -1.2497e-02,  ..., -1.0338e-02,
         -2.1088e-02,  4.0932e-03],
        [ 3.9978e-02, -4.3365e-02, -2.2217e-02,  ...,  3.9279e-05,
          1.0757e-02, -2.6917e-02]], dtype=torch.float16), 'model.layers.25.self_attn.k_proj.weight': tensor([[-5.6648e-03, -1.3237e-02, -1.2611e-02,  ...,  1.5726e-03,
          1.6232e-03,  1.4572e-03],
        [-1.4183e-02, -1.4297e-02,  2.7120e-05,  ..., -3.4618e-03,
         -2.1515e-02,  7.6561e-03],
        [-8.5354e-04,  1.9426e-03,  4.9133e-03,  ...,  6.0310e-03,
         -6.0654e-03,  7.2212e-03],
        ...,
        [ 1.3847e-02,  4.8248e-02, -9.6283e-03,  ..., -5.4504e-02,
         -5.6427e-02,  3.7598e-02],
        [ 3.4454e-02, -3.4393e-02,  4.3602e-03,  ..., -8.3771e-03,
          2.8229e-03,  1.0277e-02],
        [-7.9346e-03, -2.7908e-02,  3.2768e-03,  ...,  3.6316e-02,
          8.8501e-03, -2.9388e-02]], dtype=torch.float16), 'model.layers.25.self_attn.v_proj.weight': tensor([[ 0.0173,  0.0201,  0.0084,  ...,  0.0248, -0.0133, -0.0128],
        [-0.0143, -0.0107,  0.0099,  ...,  0.0090, -0.0273, -0.0127],
        [-0.0150,  0.0164, -0.0202,  ..., -0.0099,  0.0054, -0.0090],
        ...,
        [-0.0186, -0.0324, -0.0026,  ...,  0.0150,  0.0097,  0.0189],
        [-0.0152,  0.0089,  0.0258,  ..., -0.0068,  0.0044, -0.0216],
        [-0.0386, -0.0105, -0.0145,  ...,  0.0065,  0.0192,  0.0297]],
       dtype=torch.float16), 'model.layers.25.self_attn.o_proj.weight': tensor([[ 1.9470e-02,  1.0475e-02,  1.3229e-02,  ...,  1.4595e-02,
          2.8362e-03,  3.7861e-03],
        [-2.6352e-02, -9.8953e-03, -1.6998e-02,  ...,  2.6093e-02,
         -7.1945e-03, -1.3523e-03],
        [-8.1863e-03, -1.5879e-03,  2.5925e-02,  ..., -1.9821e-02,
         -1.3336e-02, -1.3371e-03],
        ...,
        [-1.3893e-02,  2.3819e-02, -2.7676e-03,  ...,  1.0544e-02,
          1.3359e-02,  2.7084e-02],
        [-4.1842e-05, -2.7664e-02, -3.7750e-02,  ..., -2.3926e-02,
         -1.6037e-02,  2.2125e-03],
        [-2.4704e-02, -8.4839e-03, -1.3412e-02,  ..., -3.7964e-02,
         -2.0554e-02, -1.3344e-02]], dtype=torch.float16), 'model.layers.25.mlp.gate_proj.weight': tensor([[ 0.0037, -0.0402,  0.0397,  ..., -0.0020, -0.0228,  0.0070],
        [-0.0239, -0.0074, -0.0153,  ...,  0.0345,  0.0486,  0.0262],
        [-0.0017,  0.0171, -0.0012,  ...,  0.0176,  0.0161,  0.0310],
        ...,
        [-0.0347,  0.0086,  0.0019,  ..., -0.0027, -0.0130,  0.0004],
        [ 0.0218,  0.0088,  0.0610,  ...,  0.0170,  0.0224,  0.0062],
        [-0.0047, -0.0022, -0.0174,  ...,  0.0450,  0.0030, -0.0100]],
       dtype=torch.float16), 'model.layers.25.mlp.up_proj.weight': tensor([[-0.0265, -0.0114,  0.0169,  ...,  0.0016,  0.0052, -0.0100],
        [-0.0138, -0.0033,  0.0076,  ..., -0.0056,  0.0163,  0.0114],
        [ 0.0298,  0.0056,  0.0224,  ..., -0.0136, -0.0282, -0.0026],
        ...,
        [ 0.0102,  0.0049,  0.0475,  ...,  0.0056, -0.0394, -0.0210],
        [-0.0387, -0.0015, -0.0307,  ..., -0.0457, -0.0228, -0.0002],
        [-0.0147, -0.0097,  0.0229,  ...,  0.0258, -0.0055,  0.0242]],
       dtype=torch.float16), 'model.layers.25.mlp.down_proj.weight': tensor([[ 0.0289, -0.0159,  0.0110,  ...,  0.0204, -0.0067,  0.0310],
        [-0.0150, -0.0020,  0.0045,  ...,  0.0100, -0.0012,  0.0230],
        [ 0.0123,  0.0103, -0.0082,  ..., -0.0229,  0.0118, -0.0181],
        ...,
        [ 0.0188, -0.0142, -0.0232,  ..., -0.0466, -0.0010,  0.0237],
        [ 0.0065, -0.0114,  0.0031,  ...,  0.0045,  0.0039,  0.0058],
        [-0.0111, -0.0243,  0.0161,  ..., -0.0298, -0.0061, -0.0051]],
       dtype=torch.float16), 'model.layers.25.input_layernorm.weight': tensor([0.5547, 0.5703, 0.5547,  ..., 0.5547, 0.5742, 0.5625],
       dtype=torch.float16), 'model.layers.25.post_attention_layernorm.weight': tensor([0.4316, 0.4316, 0.4297,  ..., 0.4355, 0.4336, 0.4395],
       dtype=torch.float16), 'model.layers.26.self_attn.q_proj.weight': tensor([[ 0.0299, -0.0067, -0.0090,  ..., -0.0101,  0.0408,  0.0010],
        [-0.0050, -0.0182,  0.0142,  ...,  0.0062, -0.0230,  0.0177],
        [-0.0064,  0.0024,  0.0114,  ...,  0.0050, -0.0381, -0.0195],
        ...,
        [ 0.0009, -0.0125, -0.0078,  ...,  0.0158,  0.0216,  0.0021],
        [ 0.0070, -0.0182, -0.0230,  ...,  0.0060, -0.0005, -0.0075],
        [-0.0146,  0.0520,  0.0271,  ..., -0.0072, -0.0645, -0.0416]],
       dtype=torch.float16), 'model.layers.26.self_attn.k_proj.weight': tensor([[ 0.0220,  0.0199, -0.0121,  ..., -0.0308,  0.0384,  0.0029],
        [-0.0267,  0.0055,  0.0148,  ...,  0.0016,  0.0168,  0.0291],
        [ 0.0129,  0.0286,  0.0004,  ..., -0.0190, -0.0591, -0.0098],
        ...,
        [ 0.0247,  0.0246,  0.0012,  ..., -0.0466, -0.0545,  0.0259],
        [-0.0216, -0.0389, -0.0074,  ...,  0.0483,  0.0228, -0.0051],
        [-0.0171,  0.0094, -0.0132,  ...,  0.0006, -0.0198, -0.0154]],
       dtype=torch.float16), 'model.layers.26.self_attn.v_proj.weight': tensor([[ 0.0506, -0.0262, -0.0245,  ..., -0.0152,  0.0105, -0.0191],
        [-0.0491, -0.0213,  0.0254,  ...,  0.0101, -0.0062,  0.0016],
        [ 0.0013, -0.0020, -0.0238,  ..., -0.0061,  0.0042, -0.0306],
        ...,
        [-0.0236, -0.0176, -0.0008,  ...,  0.0428, -0.0050,  0.0086],
        [ 0.0039, -0.0365, -0.0094,  ..., -0.0166, -0.0242, -0.0042],
        [ 0.0092,  0.0188, -0.0045,  ...,  0.0071,  0.0064,  0.0172]],
       dtype=torch.float16), 'model.layers.26.self_attn.o_proj.weight': tensor([[ 0.0108, -0.0005, -0.0306,  ...,  0.0052,  0.0149,  0.0272],
        [ 0.0067,  0.0455,  0.0062,  ..., -0.0016,  0.0462, -0.0053],
        [ 0.0013,  0.0102, -0.0247,  ..., -0.0226,  0.0037, -0.0018],
        ...,
        [ 0.0307,  0.0040,  0.0108,  ..., -0.0002,  0.0182,  0.0043],
        [-0.0128,  0.0049, -0.0096,  ...,  0.0135, -0.0017, -0.0425],
        [ 0.0257,  0.0072,  0.0050,  ..., -0.0276,  0.0283, -0.0160]],
       dtype=torch.float16), 'model.layers.26.mlp.gate_proj.weight': tensor([[ 0.0187,  0.0045,  0.0131,  ...,  0.0258,  0.0262, -0.0261],
        [-0.0062,  0.0102, -0.0258,  ..., -0.0255, -0.0266,  0.0190],
        [ 0.0022, -0.0109,  0.0007,  ...,  0.0060,  0.0038, -0.0172],
        ...,
        [-0.0065,  0.0356, -0.0078,  ..., -0.0015, -0.0380, -0.0219],
        [-0.0150,  0.0138,  0.0250,  ...,  0.0159,  0.0240,  0.0123],
        [ 0.0182, -0.0038, -0.0058,  ..., -0.0301, -0.0062, -0.0043]],
       dtype=torch.float16), 'model.layers.26.mlp.up_proj.weight': tensor([[-0.0168,  0.0401,  0.0018,  ...,  0.0049, -0.0029, -0.0195],
        [-0.0410, -0.0193,  0.0116,  ...,  0.0265, -0.0069,  0.0175],
        [ 0.0082, -0.0065, -0.0241,  ...,  0.0146, -0.0218, -0.0152],
        ...,
        [ 0.0058, -0.0324,  0.0059,  ...,  0.0126,  0.0300, -0.0139],
        [-0.0445,  0.0100,  0.0505,  ...,  0.0299, -0.0133,  0.0091],
        [ 0.0003, -0.0191,  0.0266,  ..., -0.0121,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.layers.26.mlp.down_proj.weight': tensor([[-0.0157, -0.0151, -0.0184,  ...,  0.0317,  0.0165,  0.0026],
        [ 0.0194,  0.0122,  0.0013,  ...,  0.0555,  0.0187, -0.0188],
        [-0.0182,  0.0041, -0.0274,  ..., -0.0111,  0.0171,  0.0083],
        ...,
        [-0.0175, -0.0124, -0.0203,  ...,  0.0105,  0.0436, -0.0020],
        [-0.0128, -0.0142, -0.0195,  ...,  0.0095,  0.0033,  0.0230],
        [ 0.0049, -0.0129, -0.0006,  ...,  0.0101,  0.0221,  0.0164]],
       dtype=torch.float16), 'model.layers.26.input_layernorm.weight': tensor([0.5312, 0.5469, 0.5469,  ..., 0.5234, 0.5508, 0.5547],
       dtype=torch.float16), 'model.layers.26.post_attention_layernorm.weight': tensor([0.4492, 0.4492, 0.4375,  ..., 0.4512, 0.4590, 0.4590],
       dtype=torch.float16), 'model.layers.27.self_attn.q_proj.weight': tensor([[-0.0292,  0.0145,  0.0077,  ..., -0.0038,  0.0122,  0.0435],
        [-0.0134,  0.0433,  0.0299,  ..., -0.0242,  0.0111,  0.0059],
        [-0.0217, -0.0236,  0.0096,  ...,  0.0025, -0.0223,  0.0289],
        ...,
        [-0.0505,  0.0273, -0.0095,  ...,  0.0185, -0.0201, -0.0225],
        [-0.0039,  0.0271,  0.0072,  ...,  0.0084,  0.0002,  0.0258],
        [-0.0235, -0.0104,  0.0114,  ...,  0.0226,  0.0154, -0.0077]],
       dtype=torch.float16), 'model.layers.27.self_attn.k_proj.weight': tensor([[-0.0173, -0.0195,  0.0098,  ..., -0.0015, -0.0104,  0.0059],
        [-0.0029,  0.0090,  0.0194,  ...,  0.0424, -0.0081, -0.0110],
        [ 0.0017, -0.0138,  0.0081,  ..., -0.0129,  0.0021, -0.0088],
        ...,
        [-0.0041, -0.0153,  0.0362,  ...,  0.0069, -0.0344, -0.0087],
        [ 0.0248, -0.0192, -0.0473,  ...,  0.0660, -0.0128,  0.0439],
        [ 0.0315,  0.0143, -0.0021,  ..., -0.0374, -0.0376,  0.0114]],
       dtype=torch.float16), 'model.layers.27.self_attn.v_proj.weight': tensor([[ 0.0174, -0.0144, -0.0334,  ...,  0.0311,  0.0319, -0.0054],
        [ 0.0185,  0.0108,  0.0118,  ...,  0.0023, -0.0246,  0.0214],
        [-0.0263, -0.0055,  0.0169,  ..., -0.0106,  0.0546, -0.0242],
        ...,
        [ 0.0146, -0.0203, -0.0192,  ...,  0.0176, -0.0095, -0.0034],
        [ 0.0059, -0.0240, -0.0200,  ..., -0.0100, -0.0106, -0.0184],
        [ 0.0211, -0.0241, -0.0149,  ..., -0.0229, -0.0193,  0.0111]],
       dtype=torch.float16), 'model.layers.27.self_attn.o_proj.weight': tensor([[ 0.0038, -0.0119,  0.0095,  ...,  0.0242,  0.0067, -0.0269],
        [ 0.0054,  0.0286, -0.0241,  ..., -0.0172, -0.0162,  0.0058],
        [-0.0047, -0.0113, -0.0132,  ...,  0.0162,  0.0009, -0.0092],
        ...,
        [ 0.0251, -0.0114, -0.0128,  ...,  0.0111,  0.0484, -0.0008],
        [ 0.0368, -0.0221, -0.0091,  ..., -0.0011, -0.0006,  0.0184],
        [ 0.0446,  0.0125,  0.0281,  ..., -0.0113, -0.0002, -0.0220]],
       dtype=torch.float16), 'model.layers.27.mlp.gate_proj.weight': tensor([[ 0.0450,  0.0128, -0.0067,  ...,  0.0097,  0.0032, -0.0147],
        [-0.0158,  0.0018, -0.0322,  ...,  0.0303,  0.0333,  0.0226],
        [ 0.0075,  0.0203, -0.0080,  ..., -0.0125, -0.0238,  0.0320],
        ...,
        [ 0.0358,  0.0211,  0.0024,  ..., -0.0008,  0.0165, -0.0047],
        [-0.0144,  0.0255, -0.0209,  ..., -0.0090, -0.0178,  0.0073],
        [ 0.0026, -0.0184, -0.0149,  ..., -0.0166, -0.0047, -0.0048]],
       dtype=torch.float16), 'model.layers.27.mlp.up_proj.weight': tensor([[-0.0049,  0.0078,  0.0265,  ..., -0.0012,  0.0131, -0.0389],
        [-0.0102,  0.0028, -0.0278,  ...,  0.0119, -0.0223, -0.0237],
        [ 0.0258,  0.0162,  0.0435,  ...,  0.0278,  0.0015, -0.0196],
        ...,
        [-0.0044,  0.0250,  0.0330,  ..., -0.0218,  0.0206, -0.0381],
        [ 0.0097,  0.0212,  0.0149,  ...,  0.0130, -0.0131, -0.0248],
        [-0.0111,  0.0048, -0.0053,  ..., -0.0063, -0.0244, -0.0093]],
       dtype=torch.float16), 'model.layers.27.mlp.down_proj.weight': tensor([[ 2.4376e-03, -2.2705e-02,  3.4363e-02,  ..., -1.9394e-02,
          1.9669e-02, -1.1414e-02],
        [ 8.0466e-05,  1.3931e-02, -9.4910e-03,  ..., -1.9272e-02,
         -3.1616e-02,  1.2093e-02],
        [ 4.6478e-02,  1.3847e-02,  5.7602e-03,  ..., -3.2166e-02,
          4.1733e-03,  2.9587e-02],
        ...,
        [-7.6523e-03,  1.0971e-02,  1.5335e-02,  ...,  7.5302e-03,
         -4.5685e-02,  2.5742e-02],
        [-2.2018e-02, -3.3932e-03, -1.7227e-02,  ...,  2.2934e-02,
         -9.0866e-03,  2.0813e-02],
        [ 4.7493e-03,  1.7471e-02, -9.1858e-03,  ...,  1.9531e-02,
         -2.3441e-03, -4.7493e-03]], dtype=torch.float16), 'model.layers.27.input_layernorm.weight': tensor([0.5625, 0.5625, 0.5586,  ..., 0.5547, 0.5625, 0.5703],
       dtype=torch.float16), 'model.layers.27.post_attention_layernorm.weight': tensor([0.4688, 0.4629, 0.4531,  ..., 0.4668, 0.4707, 0.4688],
       dtype=torch.float16), 'model.layers.28.self_attn.q_proj.weight': tensor([[-3.2127e-05, -1.9119e-02, -7.1669e-04,  ..., -1.4694e-02,
         -9.0561e-03, -1.0872e-02],
        [ 1.1421e-02, -1.8387e-02, -2.4986e-03,  ...,  1.3634e-02,
          5.4283e-03, -3.9635e-03],
        [ 1.4305e-02,  6.4993e-04, -1.0948e-02,  ..., -3.7956e-03,
         -2.4414e-02,  2.4261e-02],
        ...,
        [-1.1253e-02,  2.4719e-02, -5.3101e-02,  ...,  1.6006e-02,
         -7.5684e-03, -3.9825e-02],
        [ 1.6541e-02, -2.6855e-02, -1.2665e-02,  ...,  2.0569e-02,
          3.2928e-02, -6.5002e-02],
        [ 1.9409e-02,  1.4633e-02, -4.5654e-02,  ...,  4.5868e-02,
          1.4122e-02, -3.6987e-02]], dtype=torch.float16), 'model.layers.28.self_attn.k_proj.weight': tensor([[-0.0036, -0.0034,  0.0078,  ..., -0.0043,  0.0148, -0.0134],
        [-0.0133, -0.0068, -0.0168,  ..., -0.0066,  0.0050,  0.0043],
        [ 0.0061,  0.0063, -0.0146,  ..., -0.0197, -0.0112,  0.0050],
        ...,
        [-0.0251, -0.0133, -0.0040,  ..., -0.0014, -0.0604, -0.0040],
        [ 0.0462, -0.0221,  0.0039,  ...,  0.0161,  0.0397,  0.0285],
        [ 0.0180, -0.0042,  0.0045,  ..., -0.0038, -0.0185, -0.0136]],
       dtype=torch.float16), 'model.layers.28.self_attn.v_proj.weight': tensor([[-0.0240,  0.0090,  0.0227,  ..., -0.0210, -0.0288,  0.0260],
        [ 0.0231, -0.0178, -0.0135,  ..., -0.0447,  0.0313, -0.0163],
        [-0.0102,  0.0174, -0.0021,  ...,  0.0075, -0.0479,  0.0167],
        ...,
        [ 0.0193,  0.0043, -0.0005,  ...,  0.0143, -0.0064, -0.0217],
        [ 0.0511,  0.0041,  0.0421,  ...,  0.0019,  0.0046, -0.0031],
        [ 0.0181,  0.0192, -0.0485,  ...,  0.0328, -0.0048,  0.0090]],
       dtype=torch.float16), 'model.layers.28.self_attn.o_proj.weight': tensor([[ 1.1208e-02,  2.4567e-02, -4.1473e-02,  ..., -3.4485e-02,
          1.7929e-02, -9.8646e-05],
        [-1.2238e-02, -2.0905e-02, -2.8381e-03,  ..., -1.7075e-02,
          2.7145e-02,  3.2501e-02],
        [ 2.7863e-02,  1.7838e-02, -5.3741e-02,  ...,  2.2293e-02,
          1.5701e-02, -1.6464e-02],
        ...,
        [ 2.5444e-03, -4.4098e-03,  3.4332e-02,  ..., -9.8801e-03,
         -3.9917e-02, -6.6757e-03],
        [-7.5188e-03, -5.8655e-02, -1.8112e-02,  ...,  2.0889e-02,
         -2.8183e-02, -2.7084e-02],
        [-4.3823e-02, -4.1618e-03, -1.0742e-02,  ..., -1.9196e-02,
         -8.0719e-03,  4.2839e-03]], dtype=torch.float16), 'model.layers.28.mlp.gate_proj.weight': tensor([[-0.0007,  0.0031, -0.0068,  ...,  0.0274, -0.0111,  0.0312],
        [-0.0257,  0.0139, -0.0106,  ...,  0.0121,  0.0034,  0.0177],
        [ 0.0099,  0.0288,  0.0274,  ...,  0.0168,  0.0038,  0.0067],
        ...,
        [-0.0053,  0.0228,  0.0102,  ...,  0.0135,  0.0128, -0.0202],
        [ 0.0124, -0.0344, -0.0104,  ..., -0.0197, -0.0044, -0.0032],
        [-0.0318,  0.0149,  0.0106,  ..., -0.0078, -0.0112,  0.0179]],
       dtype=torch.float16), 'model.layers.28.mlp.up_proj.weight': tensor([[ 0.0224,  0.0047,  0.0220,  ...,  0.0277,  0.0156,  0.0114],
        [-0.0177, -0.0260, -0.0041,  ..., -0.0033, -0.0355, -0.0220],
        [ 0.0064,  0.0259, -0.0073,  ...,  0.0068,  0.0073, -0.0160],
        ...,
        [-0.0055, -0.0151,  0.0324,  ..., -0.0026,  0.0111, -0.0013],
        [-0.0215,  0.0078, -0.0074,  ...,  0.0127, -0.0099, -0.0497],
        [-0.0093, -0.0252, -0.0048,  ..., -0.0067,  0.0076,  0.0080]],
       dtype=torch.float16), 'model.layers.28.mlp.down_proj.weight': tensor([[ 0.0077,  0.0342, -0.0055,  ...,  0.0029, -0.0016, -0.0298],
        [-0.0009, -0.0338,  0.0198,  ..., -0.0268, -0.0070, -0.0280],
        [-0.0241,  0.0253, -0.0140,  ...,  0.0032,  0.0074, -0.0012],
        ...,
        [ 0.0106, -0.0143, -0.0053,  ..., -0.0309, -0.0309,  0.0070],
        [-0.0170, -0.0194,  0.0628,  ..., -0.0242, -0.0061,  0.0128],
        [-0.0234,  0.0108, -0.0081,  ...,  0.0294,  0.0295, -0.0142]],
       dtype=torch.float16), 'model.layers.28.input_layernorm.weight': tensor([0.5781, 0.5859, 0.5664,  ..., 0.5547, 0.5742, 0.5742],
       dtype=torch.float16), 'model.layers.28.post_attention_layernorm.weight': tensor([0.4805, 0.4785, 0.4648,  ..., 0.4785, 0.4727, 0.4727],
       dtype=torch.float16), 'model.layers.29.self_attn.q_proj.weight': tensor([[ 0.0060,  0.0026, -0.0075,  ...,  0.0002, -0.0110,  0.0094],
        [-0.0288, -0.0180, -0.0257,  ..., -0.0128, -0.0063, -0.0059],
        [-0.0291,  0.0377, -0.0024,  ..., -0.0022, -0.0156,  0.0146],
        ...,
        [ 0.0005,  0.0704, -0.0331,  ...,  0.0133, -0.0080, -0.0352],
        [-0.0236, -0.0242,  0.0169,  ..., -0.0142, -0.0230,  0.0260],
        [ 0.0005, -0.0416, -0.0127,  ...,  0.0132,  0.0065, -0.0391]],
       dtype=torch.float16), 'model.layers.29.self_attn.k_proj.weight': tensor([[ 0.0357, -0.0135, -0.0162,  ...,  0.0005,  0.0101, -0.0023],
        [-0.0177,  0.0316, -0.0048,  ..., -0.0086,  0.0006, -0.0218],
        [ 0.0214,  0.0079,  0.0186,  ...,  0.0193,  0.0339, -0.0014],
        ...,
        [-0.0317,  0.0448,  0.0010,  ..., -0.0091,  0.0024, -0.0117],
        [ 0.0014, -0.0123, -0.0701,  ..., -0.0106, -0.0095, -0.0427],
        [ 0.0107, -0.0124, -0.0583,  ..., -0.0584, -0.0144,  0.0027]],
       dtype=torch.float16), 'model.layers.29.self_attn.v_proj.weight': tensor([[ 0.0110,  0.0064,  0.0324,  ...,  0.0194,  0.0085,  0.0135],
        [-0.0017,  0.0247,  0.0385,  ..., -0.0199,  0.0092, -0.0022],
        [-0.0130,  0.0104, -0.0103,  ...,  0.0083,  0.0268,  0.0188],
        ...,
        [ 0.0067,  0.0294,  0.0116,  ..., -0.0203, -0.0125, -0.0172],
        [ 0.0001,  0.0276, -0.0236,  ...,  0.0186,  0.0294, -0.0053],
        [-0.0033, -0.0211,  0.0092,  ..., -0.0019, -0.0083,  0.0262]],
       dtype=torch.float16), 'model.layers.29.self_attn.o_proj.weight': tensor([[-6.3057e-03,  3.2288e-02,  3.3630e-02,  ...,  5.8222e-04,
         -1.7517e-02, -6.4850e-03],
        [-2.0340e-02, -2.5772e-02, -1.2833e-02,  ...,  1.2199e-02,
         -2.8244e-02,  1.2634e-02],
        [ 2.6093e-02,  2.8381e-02, -8.5678e-03,  ..., -3.7781e-02,
          1.7441e-02, -2.1240e-02],
        ...,
        [-2.8381e-02, -1.6617e-02,  2.8061e-02,  ..., -7.0839e-03,
         -7.8201e-03, -1.4076e-02],
        [-1.3969e-02, -1.0399e-02,  3.3966e-02,  ..., -4.7803e-05,
         -2.0554e-02,  4.7226e-03],
        [ 1.5411e-02,  3.9749e-03, -3.4275e-03,  ...,  4.1122e-03,
          1.9104e-02, -2.8473e-02]], dtype=torch.float16), 'model.layers.29.mlp.gate_proj.weight': tensor([[ 0.0161,  0.0169, -0.0145,  ..., -0.0036, -0.0243,  0.0359],
        [ 0.0034,  0.0243, -0.0081,  ..., -0.0228,  0.0151,  0.0046],
        [ 0.0371, -0.0013, -0.0085,  ..., -0.0063,  0.0206,  0.0335],
        ...,
        [-0.0048,  0.0104, -0.0152,  ...,  0.0026,  0.0065,  0.0039],
        [ 0.0079,  0.0031, -0.0292,  ..., -0.0222, -0.0051,  0.0174],
        [-0.0031,  0.0190, -0.0012,  ...,  0.0228, -0.0130, -0.0158]],
       dtype=torch.float16), 'model.layers.29.mlp.up_proj.weight': tensor([[-0.0069,  0.0021,  0.0118,  ...,  0.0150,  0.0049,  0.0057],
        [ 0.0012,  0.0072,  0.0320,  ...,  0.0089, -0.0199,  0.0363],
        [-0.0076, -0.0212, -0.0125,  ..., -0.0495,  0.0085, -0.0360],
        ...,
        [ 0.0260,  0.0129,  0.0126,  ...,  0.0124,  0.0245,  0.0357],
        [-0.0250, -0.0191, -0.0051,  ...,  0.0142,  0.0133,  0.0017],
        [ 0.0065, -0.0030,  0.0111,  ..., -0.0080,  0.0094,  0.0100]],
       dtype=torch.float16), 'model.layers.29.mlp.down_proj.weight': tensor([[ 0.0411,  0.0098, -0.0018,  ...,  0.0168, -0.0244, -0.0152],
        [ 0.0184,  0.0098,  0.0223,  ...,  0.0344,  0.0027,  0.0017],
        [ 0.0008, -0.0209, -0.0160,  ..., -0.0007,  0.0110, -0.0271],
        ...,
        [ 0.0088, -0.0090,  0.0057,  ..., -0.0189, -0.0051, -0.0197],
        [ 0.0228,  0.0159,  0.0265,  ...,  0.0094, -0.0411,  0.0024],
        [ 0.0148, -0.0185, -0.0088,  ..., -0.0158, -0.0135,  0.0045]],
       dtype=torch.float16), 'model.layers.29.input_layernorm.weight': tensor([0.5430, 0.5586, 0.5391,  ..., 0.5312, 0.5586, 0.5625],
       dtype=torch.float16), 'model.layers.29.post_attention_layernorm.weight': tensor([0.4902, 0.4922, 0.4785,  ..., 0.4785, 0.4922, 0.4805],
       dtype=torch.float16), 'model.layers.30.self_attn.q_proj.weight': tensor([[-0.0041, -0.0047,  0.0075,  ..., -0.0091, -0.0045,  0.0028],
        [ 0.0163,  0.0142,  0.0050,  ..., -0.0033, -0.0027, -0.0191],
        [-0.0086, -0.0204,  0.0428,  ...,  0.0224,  0.0053, -0.0305],
        ...,
        [-0.0093, -0.0009, -0.0012,  ...,  0.0209, -0.0119,  0.0017],
        [-0.0005, -0.0218, -0.0206,  ...,  0.0153,  0.0086, -0.0354],
        [-0.0708, -0.0093,  0.0420,  ..., -0.0094, -0.0046, -0.0015]],
       dtype=torch.float16), 'model.layers.30.self_attn.k_proj.weight': tensor([[ 0.0262, -0.0208,  0.0015,  ..., -0.0112,  0.0095,  0.0076],
        [ 0.0337,  0.0127,  0.0035,  ..., -0.0041, -0.0045,  0.0022],
        [-0.0044, -0.0148,  0.0216,  ...,  0.0055, -0.0088, -0.0004],
        ...,
        [ 0.0057,  0.0255,  0.0007,  ...,  0.0564, -0.0037, -0.0002],
        [ 0.0107, -0.0630,  0.0325,  ...,  0.0062, -0.0082, -0.0273],
        [-0.0373, -0.0082,  0.0209,  ...,  0.0079,  0.0169, -0.0247]],
       dtype=torch.float16), 'model.layers.30.self_attn.v_proj.weight': tensor([[-0.0035, -0.0291,  0.0310,  ..., -0.0268, -0.0363,  0.0307],
        [ 0.0073,  0.0172,  0.0300,  ..., -0.0118,  0.0262,  0.0019],
        [-0.0203,  0.0174, -0.0189,  ...,  0.0050, -0.0255, -0.0103],
        ...,
        [ 0.0184, -0.0039, -0.0030,  ..., -0.0245,  0.0030,  0.0241],
        [-0.0072, -0.0434,  0.0219,  ...,  0.0296, -0.0089,  0.0216],
        [-0.0088,  0.0059,  0.0193,  ..., -0.0144, -0.0613, -0.0227]],
       dtype=torch.float16), 'model.layers.30.self_attn.o_proj.weight': tensor([[-0.0074,  0.0176, -0.0070,  ...,  0.0119, -0.0119, -0.0202],
        [-0.0116, -0.0252, -0.0082,  ...,  0.0136, -0.0305, -0.0236],
        [-0.0294, -0.0029,  0.0179,  ..., -0.0482, -0.0128, -0.0113],
        ...,
        [ 0.0068,  0.0052,  0.0028,  ..., -0.0247,  0.0106,  0.0177],
        [ 0.0227, -0.0089,  0.0036,  ...,  0.0353, -0.0069,  0.0047],
        [-0.0028,  0.0133, -0.0032,  ..., -0.0048,  0.0101, -0.0147]],
       dtype=torch.float16), 'model.layers.30.mlp.gate_proj.weight': tensor([[-0.0422, -0.0289, -0.0057,  ...,  0.0138, -0.0067, -0.0003],
        [-0.0175,  0.0047,  0.0389,  ..., -0.0063, -0.0058,  0.0305],
        [-0.0219, -0.0067, -0.0307,  ...,  0.0154, -0.0004, -0.0035],
        ...,
        [-0.0204, -0.0261,  0.0121,  ..., -0.0081, -0.0219, -0.0244],
        [ 0.0268,  0.0282, -0.0097,  ...,  0.0118, -0.0396, -0.0025],
        [-0.0012, -0.0307, -0.0203,  ..., -0.0023,  0.0182, -0.0061]],
       dtype=torch.float16), 'model.layers.30.mlp.up_proj.weight': tensor([[ 0.0034,  0.0162,  0.0123,  ...,  0.0126,  0.0213, -0.0029],
        [-0.0196, -0.0118,  0.0388,  ...,  0.0008, -0.0193, -0.0033],
        [-0.0327, -0.0235, -0.0368,  ..., -0.0176,  0.0011,  0.0209],
        ...,
        [-0.0163, -0.0128,  0.0153,  ...,  0.0128, -0.0097, -0.0216],
        [-0.0081,  0.0077, -0.0097,  ...,  0.0053, -0.0229,  0.0164],
        [-0.0030, -0.0283,  0.0003,  ..., -0.0168,  0.0070,  0.0171]],
       dtype=torch.float16), 'model.layers.30.mlp.down_proj.weight': tensor([[ 2.2812e-02, -1.3634e-02, -3.0258e-02,  ...,  3.1342e-02,
         -7.2098e-03, -8.8263e-04],
        [ 2.5818e-02,  4.8409e-03,  4.3427e-02,  ...,  1.2611e-02,
          1.6594e-03, -7.8888e-03],
        [ 3.6883e-04, -3.0899e-03, -2.1591e-02,  ...,  3.1242e-03,
          1.0376e-02,  2.0767e-02],
        ...,
        [-3.1921e-02,  6.3400e-03, -2.4643e-02,  ...,  1.8341e-02,
         -2.4780e-02, -9.6664e-03],
        [-4.3750e-05, -1.9287e-02,  2.8934e-03,  ...,  1.9730e-02,
          2.3232e-03,  1.2312e-03],
        [-8.7738e-03, -1.4030e-02, -2.5955e-02,  ...,  1.0109e-02,
          3.0589e-04, -1.9150e-02]], dtype=torch.float16), 'model.layers.30.input_layernorm.weight': tensor([0.5859, 0.6016, 0.5664,  ..., 0.5586, 0.5781, 0.6016],
       dtype=torch.float16), 'model.layers.30.post_attention_layernorm.weight': tensor([0.4824, 0.5039, 0.4824,  ..., 0.4883, 0.4980, 0.4863],
       dtype=torch.float16), 'model.layers.31.self_attn.q_proj.weight': tensor([[-0.0350,  0.0179,  0.0228,  ...,  0.0133, -0.0005, -0.0199],
        [-0.0200, -0.0252, -0.0369,  ...,  0.0008, -0.0122, -0.0238],
        [-0.0219,  0.0272,  0.0192,  ..., -0.0004,  0.0037,  0.0022],
        ...,
        [ 0.0171, -0.0177, -0.0151,  ..., -0.0145,  0.0273, -0.0253],
        [-0.0265,  0.0056, -0.0053,  ..., -0.0029,  0.0124,  0.0107],
        [-0.0533, -0.0123,  0.0282,  ...,  0.0389, -0.0044,  0.0329]],
       dtype=torch.float16), 'model.layers.31.self_attn.k_proj.weight': tensor([[-0.0058, -0.0082,  0.0132,  ..., -0.0011, -0.0107, -0.0206],
        [ 0.0245, -0.0202,  0.0109,  ..., -0.0002,  0.0066, -0.0021],
        [ 0.0027,  0.0117, -0.0064,  ...,  0.0055, -0.0005, -0.0275],
        ...,
        [ 0.0315, -0.0261, -0.0244,  ..., -0.0081, -0.0101, -0.0515],
        [ 0.0134,  0.0200,  0.0124,  ..., -0.0259, -0.0236,  0.0204],
        [-0.0787, -0.0352,  0.0162,  ..., -0.0131,  0.0023, -0.0065]],
       dtype=torch.float16), 'model.layers.31.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0230, -0.0018,  ...,  0.0031,  0.0012,  0.0155],
        [ 0.0281,  0.0153,  0.0112,  ...,  0.0094,  0.0336,  0.0164],
        [ 0.0143, -0.0011, -0.0159,  ...,  0.0129,  0.0024,  0.0344],
        ...,
        [-0.0017, -0.0013, -0.0144,  ..., -0.0160, -0.0032,  0.0248],
        [ 0.0126, -0.0183,  0.0156,  ..., -0.0102, -0.0292,  0.0144],
        [-0.0103, -0.0228,  0.0264,  ...,  0.0243, -0.0042,  0.0403]],
       dtype=torch.float16), 'model.layers.31.self_attn.o_proj.weight': tensor([[ 0.0089,  0.0304, -0.0052,  ..., -0.0004, -0.0148, -0.0504],
        [-0.0065,  0.0034, -0.0314,  ...,  0.0269, -0.0200, -0.0146],
        [ 0.0102,  0.0023,  0.0032,  ..., -0.0174,  0.0214,  0.0120],
        ...,
        [ 0.0077, -0.0209,  0.0315,  ..., -0.0161, -0.0128, -0.0216],
        [ 0.0010,  0.0138, -0.0207,  ..., -0.0174, -0.0141, -0.0177],
        [ 0.0062,  0.0165, -0.0088,  ...,  0.0295, -0.0164,  0.0075]],
       dtype=torch.float16), 'model.layers.31.mlp.gate_proj.weight': tensor([[ 0.0088, -0.0101,  0.0378,  ...,  0.0157,  0.0179,  0.0108],
        [-0.0751, -0.0179,  0.0038,  ...,  0.0049, -0.0193,  0.0181],
        [ 0.0142,  0.0066, -0.0107,  ..., -0.0041, -0.0197, -0.0075],
        ...,
        [-0.0168, -0.0297,  0.0126,  ..., -0.0009,  0.0242,  0.0329],
        [ 0.0417,  0.0298, -0.0222,  ...,  0.0354, -0.0096, -0.0061],
        [ 0.0174, -0.0382, -0.0287,  ..., -0.0177,  0.0085,  0.0057]],
       dtype=torch.float16), 'model.layers.31.mlp.up_proj.weight': tensor([[-0.0397, -0.0182,  0.0206,  ...,  0.0010, -0.0187,  0.0024],
        [ 0.0275,  0.0354,  0.0046,  ..., -0.0228,  0.0012, -0.0013],
        [-0.0043,  0.0044, -0.0210,  ...,  0.0143,  0.0034, -0.0117],
        ...,
        [ 0.0134, -0.0182,  0.0072,  ...,  0.0026,  0.0326, -0.0186],
        [ 0.0055,  0.0044, -0.0258,  ...,  0.0280,  0.0101, -0.0022],
        [ 0.0409, -0.0411, -0.0085,  ..., -0.0104,  0.0099,  0.0237]],
       dtype=torch.float16), 'model.layers.31.mlp.down_proj.weight': tensor([[-1.2767e-04, -2.5101e-02, -9.8572e-03,  ..., -3.8147e-02,
         -1.4954e-02,  2.7756e-02],
        [ 3.8208e-02,  3.5248e-03, -3.6736e-03,  ..., -5.2691e-04,
         -1.6205e-02,  1.3901e-02],
        [-1.2566e-02, -1.2192e-02,  2.5131e-02,  ...,  3.0304e-02,
         -1.5383e-03,  2.3193e-02],
        ...,
        [ 4.7088e-05,  2.8351e-02, -2.0237e-03,  ...,  1.1597e-02,
          5.3177e-03,  1.7136e-02],
        [-9.8515e-04,  4.7424e-02, -5.3787e-03,  ..., -7.3509e-03,
          2.3331e-02,  1.7090e-02],
        [ 2.6001e-02, -3.8910e-02,  1.8829e-02,  ...,  4.1313e-03,
          1.2999e-03,  2.6016e-02]], dtype=torch.float16), 'model.layers.31.input_layernorm.weight': tensor([0.4961, 0.4980, 0.4453,  ..., 0.4375, 0.4727, 0.4922],
       dtype=torch.float16), 'model.layers.31.post_attention_layernorm.weight': tensor([0.4414, 0.4434, 0.4531,  ..., 0.4336, 0.4219, 0.4375],
       dtype=torch.float16), 'model.norm.weight': tensor([2.0000, 2.0469, 1.9453,  ..., 1.8594, 1.9453, 1.7656],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding': tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight': tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,
            2.1957e-02,  5.0011e-03],
          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,
            7.5417e-03, -1.2230e-02],
          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,
            5.3940e-03, -1.2283e-02],
          ...,
          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,
           -2.3239e-02, -2.4017e-02],
          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,
            1.5745e-03, -4.1771e-03],
          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,
            4.0169e-03, -6.7177e-03]],

         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,
            2.4185e-02,  5.8136e-03],
          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,
            5.4970e-03, -1.4351e-02],
          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,
            5.5618e-03, -1.2390e-02],
          ...,
          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,
            3.9816e-04, -5.1346e-03],
          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,
            2.2552e-02,  1.2917e-02],
          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,
            1.8158e-02,  9.2745e-04]],

         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,
            1.1757e-02,  5.7259e-03],
          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,
           -4.2191e-03, -7.1831e-03],
          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,
            1.3041e-04, -7.3051e-03],
          ...,
          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,
           -9.8267e-03, -6.7825e-03],
          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,
            6.3400e-03,  5.3177e-03],
          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,
            6.5193e-03,  2.9850e-04]]],


        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,
           -8.4381e-03,  2.0447e-02],
          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,
            3.5906e-04,  1.5945e-02],
          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,
           -2.7924e-02, -3.2177e-03],
          ...,
          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,
           -5.4741e-03, -5.9624e-03],
          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,
           -2.7969e-02, -1.8875e-02],
          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,
            7.1335e-03,  4.6478e-02]],

         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,
           -1.1604e-02,  1.7593e-02],
          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,
            3.4976e-04,  1.4732e-02],
          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,
           -3.2684e-02, -7.0076e-03],
          ...,
          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,
           -1.1253e-02, -9.8648e-03],
          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,
           -3.7231e-02, -2.6505e-02],
          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,
           -4.2000e-03,  3.9368e-02]],

         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,
           -1.2558e-02,  1.7303e-02],
          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,
            4.3440e-04,  1.5656e-02],
          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,
           -2.9968e-02, -6.5422e-03],
          ...,
          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,
           -8.7967e-03, -8.7662e-03],
          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,
           -3.0518e-02, -2.4918e-02],
          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,
           -7.3242e-04,  3.8818e-02]]],


        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,
            1.4229e-02,  1.8768e-02],
          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,
            5.4283e-03,  6.6032e-03],
          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,
            2.5959e-03,  6.8703e-03],
          ...,
          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,
            1.4397e-02,  1.2421e-02],
          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,
            2.2766e-02,  2.2659e-02],
          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,
            2.2263e-02,  2.5238e-02]],

         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,
            1.9653e-02,  2.8290e-02],
          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,
            6.0501e-03,  1.2810e-02],
          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,
           -5.9271e-04,  8.8959e-03],
          ...,
          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,
            2.4902e-02,  2.6871e-02],
          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,
            3.3569e-02,  3.9612e-02],
          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,
            3.9276e-02,  4.6051e-02]],

         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,
            2.1042e-02,  2.9053e-02],
          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,
            7.7019e-03,  1.2169e-02],
          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,
            3.3913e-03,  9.0408e-03],
          ...,
          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,
            8.0795e-03,  1.4221e-02],
          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,
            1.1887e-02,  1.8204e-02],
          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,
            1.5701e-02,  2.2247e-02]]],


        ...,


        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,
            3.1686e-04, -3.0446e-04],
          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,
           -2.2995e-04, -1.6510e-04],
          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,
           -5.0831e-04,  5.9748e-04],
          ...,
          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,
           -9.3746e-04, -6.7472e-04],
          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,
           -1.4048e-03, -1.3056e-03],
          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,
            3.2640e-04,  1.7679e-04]],

         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,
            1.0500e-03, -5.0831e-04],
          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,
            1.0071e-03, -4.9925e-04],
          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,
            8.0919e-04,  9.7132e-04],
          ...,
          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,
            6.2895e-04,  4.0889e-04],
          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,
           -2.8610e-04,  1.9038e-04],
          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,
            1.4138e-04,  4.2319e-04]],

         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,
           -4.3130e-04, -5.6791e-04],
          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,
            1.9002e-04,  1.8311e-04],
          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,
            2.3186e-05, -5.7578e-05],
          ...,
          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,
            1.3471e-04,  6.5708e-04],
          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,
            1.0538e-04, -4.9019e-04],
          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,
           -4.1580e-04,  5.5599e-04]]],


        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,
            6.1874e-03,  2.6535e-02],
          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,
           -1.7639e-02, -3.2768e-03],
          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,
           -2.7237e-02, -5.5046e-03],
          ...,
          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,
            2.8503e-02,  3.6499e-02],
          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,
           -2.3010e-02,  5.0926e-03],
          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,
           -3.9276e-02,  1.3908e-02]],

         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,
            2.8896e-03,  2.2415e-02],
          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,
           -1.8616e-02, -6.5308e-03],
          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,
           -3.0472e-02, -9.3613e-03],
          ...,
          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,
            2.6001e-02,  3.4241e-02],
          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,
           -3.0487e-02, -9.5701e-04],
          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,
           -5.1422e-02,  4.2267e-03]],

         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,
           -2.1572e-03,  1.6891e-02],
          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,
           -2.1347e-02, -9.2316e-03],
          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,
           -2.9694e-02, -1.2733e-02],
          ...,
          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,
            1.9257e-02,  2.4582e-02],
          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,
           -3.1281e-02, -9.1248e-03],
          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,
           -5.2246e-02, -2.8057e-03]]],


        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,
            8.1863e-03, -4.8248e-02],
          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,
            9.3689e-03, -3.8544e-02],
          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,
            2.3956e-02, -1.1154e-02],
          ...,
          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,
           -1.8654e-03, -1.9440e-02],
          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,
            8.4381e-03,  1.4282e-02],
          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,
            1.6689e-03,  1.6891e-02]],

         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,
            1.5839e-02, -4.3243e-02],
          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,
            1.8433e-02, -3.1799e-02],
          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,
            2.9694e-02, -5.4817e-03],
          ...,
          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,
           -1.5268e-03, -1.4626e-02],
          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,
            8.5602e-03,  2.0035e-02],
          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,
           -2.3785e-03,  1.9150e-02]],

         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,
            2.1317e-02, -3.0197e-02],
          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,
            2.4658e-02, -1.7670e-02],
          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,
            3.4302e-02,  4.5395e-03],
          ...,
          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,
            4.1656e-03, -5.9814e-03],
          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,
            1.6068e-02,  2.5879e-02],
          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,
            2.2964e-03,  2.2339e-02]]]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight': tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],
        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],
        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],
        ...,
        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],
        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],
        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight': tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias': tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight': tensor([[-1.1724e-04,  8.3399e-04, -1.5700e-04,  ..., -4.8332e-03,
          1.3428e-02,  3.2604e-05],
        [-4.4703e-05, -9.5272e-04,  1.2279e-04,  ...,  1.9855e-03,
         -1.3626e-02, -4.1783e-05],
        [ 6.6280e-04,  1.0419e-04,  9.0420e-05,  ..., -2.1820e-02,
          4.1199e-03,  3.2187e-06],
        ...,
        [-5.2512e-05, -2.9278e-04, -3.6895e-05,  ...,  8.8196e-03,
         -4.2796e-04, -3.0100e-05],
        [ 7.5936e-05, -6.5148e-05, -9.0182e-05,  ...,  8.1682e-04,
         -6.0844e-03,  1.9014e-05],
        [-6.3896e-05,  9.8705e-05,  4.9829e-05,  ..., -1.2579e-03,
         -7.1793e-03,  2.3961e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias': tensor([ 0.0577, -0.0588, -0.0266,  ..., -0.0147, -0.0175,  0.0096],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight': tensor([[ 2.4986e-04, -1.5283e-04, -5.8556e-04,  ...,  3.3607e-03,
         -9.5901e-03,  5.5373e-05],
        [-3.4356e-04, -1.5092e-04,  5.2691e-05,  ...,  2.5725e-04,
          1.0010e-02, -6.2883e-05],
        [ 6.7472e-04, -9.6798e-05,  2.5392e-04,  ..., -1.0386e-03,
         -1.9531e-02, -1.2141e-04],
        ...,
        [ 2.9850e-04,  4.0436e-04, -9.7811e-05,  ...,  4.6654e-03,
         -2.2392e-03, -6.6221e-05],
        [ 3.2973e-04, -3.2961e-05, -2.1207e-04,  ...,  1.1917e-02,
          3.4637e-03,  6.9439e-05],
        [ 2.1458e-06,  4.7874e-04,  4.8459e-05,  ..., -1.1612e-02,
          2.6779e-03, -8.3089e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias': tensor([-0.0277,  0.0222, -0.0355,  ...,  0.0123,  0.0105, -0.0041],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight': tensor([[-2.6703e-05, -1.3638e-04, -8.3923e-05,  ...,  4.2152e-03,
         -2.7649e-02, -7.5042e-05],
        [-1.6391e-04,  9.0241e-05,  5.4836e-05,  ..., -1.5821e-03,
          2.9831e-02,  7.0333e-05],
        [ 4.7588e-04,  7.6008e-04, -1.0198e-04,  ..., -1.7090e-02,
          4.1809e-02,  1.5020e-04],
        ...,
        [ 6.9141e-05,  7.0274e-05,  8.6784e-05,  ..., -4.3411e-03,
          1.1421e-02, -3.8803e-05],
        [-1.8144e-04,  1.4305e-06, -2.5940e-04,  ...,  1.5802e-03,
         -1.8799e-04,  1.6689e-05],
        [-1.2624e-04,  9.4473e-05,  5.3406e-05,  ..., -1.4961e-02,
         -5.8937e-04,  4.2021e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias': tensor([ 1.5693, -1.6172, -0.8213,  ..., -1.2852, -0.0976,  0.7852],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight': tensor([[-0.0073,  0.0083, -0.0076,  ..., -0.0090, -0.0080,  0.0038],
        [ 0.0107,  0.0062,  0.0133,  ..., -0.0036,  0.0022,  0.0034],
        [-0.0065,  0.0033,  0.0139,  ...,  0.0069,  0.0004, -0.0009],
        ...,
        [-0.0002, -0.0035, -0.0027,  ..., -0.0046, -0.0187,  0.0087],
        [-0.0093,  0.0047, -0.0083,  ...,  0.0006, -0.0013, -0.0006],
        [ 0.0092,  0.0003,  0.0016,  ...,  0.0016, -0.0045,  0.0045]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias': tensor([-0.0263, -0.0654,  0.0031,  ...,  0.1759, -0.0438,  0.0020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight': tensor([8.3113e-04, 2.9087e-03, 1.1456e-04,  ..., 6.9092e-01, 3.5498e-01,
        2.4021e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias': tensor([ 6.9141e-06,  7.7629e-04, -8.8811e-05,  ..., -3.6816e-01,
         1.7981e-01, -1.0854e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight': tensor([[ 4.2367e-04, -2.1219e-05,  5.9605e-08,  ..., -5.6458e-03,
         -1.2026e-03, -6.4087e-04],
        [ 6.1340e-03,  1.3588e-02, -3.5858e-04,  ..., -3.5954e-03,
         -7.6485e-04,  6.7101e-03],
        [ 1.3552e-03,  1.2817e-03, -2.0266e-06,  ..., -2.8351e-02,
         -1.2054e-03,  1.4830e-03],
        ...,
        [-2.4002e-02, -1.0193e-02,  2.1684e-04,  ..., -2.5864e-03,
         -1.1841e-02,  5.9166e-03],
        [ 4.1008e-04,  4.2856e-05, -1.1921e-07,  ..., -5.0697e-03,
         -7.7248e-04, -6.3896e-04],
        [-6.3753e-04, -2.3392e-02, -2.6226e-04,  ..., -4.2801e-03,
          2.7962e-03, -8.1863e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias': tensor([-0.6826, -0.3130, -0.8076,  ..., -0.2166, -0.6538, -0.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight': tensor([[-0.0037, -0.0032,  0.0043,  ...,  0.0117, -0.0042, -0.0073],
        [ 0.0017,  0.0183, -0.0100,  ..., -0.0255,  0.0024,  0.0209],
        [ 0.0033,  0.0024, -0.0029,  ...,  0.0037,  0.0032, -0.0154],
        ...,
        [ 0.0015, -0.0007, -0.0035,  ...,  0.0049,  0.0009,  0.0082],
        [-0.0060,  0.0064,  0.0067,  ..., -0.0009, -0.0061,  0.0016],
        [ 0.0007, -0.0034, -0.0020,  ..., -0.0091,  0.0009,  0.0035]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias': tensor([-0.0185, -0.1009,  0.0397,  ..., -0.0955, -0.1080, -0.0239],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight': tensor([2.8296e-01, 5.9082e-01, 1.0455e-04,  ..., 2.0195e+00, 7.7490e-01,
        2.9736e-01], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias': tensor([2.1988e-02, 2.1716e-01, 9.2089e-05,  ..., 2.6318e-01, 4.5020e-01,
        5.0903e-02], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight': tensor([[-3.9864e-03,  1.4374e-02, -2.8610e-03,  ...,  1.0399e-02,
         -2.8076e-02,  5.1155e-03],
        [ 8.1024e-03,  2.2583e-03,  1.1635e-02,  ..., -7.1716e-03,
         -7.5607e-03,  2.5375e-02],
        [ 9.5596e-03,  1.1284e-02, -3.6469e-03,  ..., -6.6757e-03,
         -1.2465e-03, -1.1475e-02],
        ...,
        [ 7.7188e-05, -1.6190e-02,  3.6583e-03,  ...,  2.1240e-02,
          4.3907e-03, -1.0063e-02],
        [ 1.5762e-02,  1.7273e-02, -3.3447e-02,  ..., -2.2507e-03,
         -1.2947e-02,  1.1726e-02],
        [-2.2697e-04,  1.2230e-02, -4.3411e-03,  ...,  3.3436e-03,
         -4.9973e-03,  5.5504e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias': tensor([-0.0012,  0.0081,  0.0097,  ...,  0.0535,  0.0071,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight': tensor([[ 0.0077,  0.0006,  0.0053,  ..., -0.0067,  0.0008,  0.0013],
        [ 0.0230, -0.0166, -0.0004,  ...,  0.0092, -0.0118, -0.0134],
        [-0.0103,  0.0013,  0.0111,  ..., -0.0549, -0.0047,  0.0056],
        ...,
        [ 0.0119,  0.0002, -0.0045,  ...,  0.0001,  0.0034, -0.0075],
        [-0.0129, -0.0114,  0.0075,  ..., -0.0030,  0.0044,  0.0061],
        [-0.0006, -0.0018,  0.0009,  ..., -0.0068, -0.0205, -0.0002]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias': tensor([ 0.0038, -0.0079, -0.1469,  ..., -0.0014, -0.0041,  0.0007],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight': tensor([[-2.4929e-03,  4.6706e-04, -1.8919e-04,  ...,  6.1684e-03,
         -2.4582e-02,  8.7051e-03],
        [ 6.5422e-03,  4.3602e-03,  1.5930e-02,  ..., -6.5994e-03,
          8.2169e-03,  6.1111e-03],
        [ 1.0727e-02, -9.2239e-03, -7.5698e-06,  ...,  3.7136e-03,
          1.6861e-02,  3.5305e-03],
        ...,
        [-2.3708e-03,  6.6452e-03,  5.9052e-03,  ..., -1.0399e-02,
          2.9945e-04, -9.6989e-04],
        [ 3.0609e-02,  1.3458e-02, -3.3386e-02,  ..., -1.3857e-03,
          3.5801e-03,  1.3245e-02],
        [-3.2291e-03,  4.7607e-03, -1.8759e-03,  ...,  6.1035e-04,
          4.9515e-03, -5.3520e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias': tensor([-0.1035,  0.8804,  1.4414,  ..., -2.2109, -0.1892,  0.0048],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight': tensor([[-0.0013, -0.0215,  0.0011,  ..., -0.0115,  0.0102, -0.0012],
        [-0.0010,  0.0065, -0.0018,  ..., -0.0036,  0.0112, -0.0025],
        [ 0.0015, -0.0069, -0.0120,  ..., -0.0047, -0.0009, -0.0056],
        ...,
        [ 0.0053, -0.0177,  0.0780,  ..., -0.0228, -0.0122,  0.0151],
        [-0.0086, -0.0019,  0.0054,  ...,  0.0081, -0.0049,  0.0067],
        [-0.0037,  0.0063, -0.0005,  ...,  0.0054,  0.0045, -0.0036]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias': tensor([-0.0204, -0.0210,  0.0255,  ..., -0.0381, -0.0211, -0.0043],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight': tensor([0.3650, 0.7476, 0.0972,  ..., 0.8521, 0.4248, 0.2639],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias': tensor([-0.0482, -0.1315,  0.0198,  ..., -0.1031, -0.0545,  0.0076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight': tensor([[ 0.0026,  0.0065,  0.0155,  ..., -0.0063,  0.0479, -0.0807],
        [ 0.0002, -0.0075,  0.0009,  ..., -0.0009, -0.0030,  0.0036],
        [ 0.0070, -0.0211,  0.0002,  ..., -0.0094,  0.0178, -0.0043],
        ...,
        [ 0.0026, -0.0113,  0.0019,  ..., -0.0057, -0.0008,  0.0038],
        [-0.0059,  0.0099,  0.0010,  ...,  0.0037, -0.0142, -0.0178],
        [ 0.0160,  0.0002,  0.0312,  ..., -0.0003, -0.0056, -0.0220]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias': tensor([-0.1216, -0.6841, -0.5278,  ..., -0.7573, -0.0995, -0.3076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight': tensor([[ 0.0008, -0.0008, -0.0176,  ..., -0.0029, -0.0098, -0.0047],
        [-0.0157,  0.0059,  0.0156,  ...,  0.0064, -0.0005, -0.0058],
        [ 0.0051, -0.0005,  0.0091,  ..., -0.0056, -0.0015,  0.0059],
        ...,
        [ 0.0030, -0.0024,  0.0040,  ...,  0.0014,  0.0002,  0.0047],
        [ 0.0007, -0.0015,  0.0031,  ..., -0.0015,  0.0046, -0.0055],
        [ 0.0299,  0.0036,  0.0020,  ...,  0.0047,  0.0134,  0.0043]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias': tensor([ 0.0244, -0.0645,  0.0788,  ..., -0.0807, -0.1028, -0.0836],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight': tensor([0.4128, 0.9854, 0.1910,  ..., 0.7715, 0.5596, 0.5142],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias': tensor([-0.0198, -0.1075, -0.0195,  ...,  0.0887,  0.1349,  0.0288],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight': tensor([[-0.0085,  0.0006, -0.0289,  ...,  0.0041,  0.0569, -0.0674],
        [-0.0052,  0.0245, -0.0213,  ..., -0.0084,  0.0220, -0.0248],
        [-0.0135, -0.0092,  0.0144,  ...,  0.0162,  0.0298, -0.0357],
        ...,
        [-0.0062,  0.0068,  0.0082,  ...,  0.0119,  0.0132, -0.0033],
        [-0.0083,  0.0247, -0.0094,  ..., -0.0040, -0.0122,  0.0142],
        [-0.0048, -0.0044, -0.0164,  ...,  0.0119, -0.0213, -0.0117]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias': tensor([ 0.0234,  0.0084, -0.0015,  ...,  0.0951,  0.0065,  0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight': tensor([[ 0.0164,  0.0053, -0.0065,  ..., -0.0008,  0.0037, -0.0120],
        [-0.0057, -0.0036, -0.0029,  ..., -0.0013,  0.0026, -0.0108],
        [-0.0081,  0.0057,  0.0067,  ...,  0.0028, -0.0068, -0.0023],
        ...,
        [-0.0249,  0.0121,  0.0107,  ...,  0.0037,  0.0007,  0.0044],
        [ 0.0115,  0.0107,  0.0118,  ...,  0.0015, -0.0038, -0.0073],
        [-0.0073,  0.0032, -0.0060,  ...,  0.0023, -0.0074,  0.0047]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias': tensor([-0.0014, -0.0060,  0.0129,  ...,  0.1081,  0.0069,  0.0455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight': tensor([[-0.0067, -0.0208, -0.0222,  ...,  0.0014,  0.0279, -0.0558],
        [-0.0030,  0.0016, -0.0191,  ...,  0.0001, -0.0169, -0.0034],
        [-0.0079, -0.0049,  0.0074,  ..., -0.0163, -0.0186, -0.0105],
        ...,
        [ 0.0002, -0.0036,  0.0084,  ..., -0.0038,  0.0105, -0.0002],
        [-0.0035, -0.0039, -0.0118,  ..., -0.0067, -0.0292,  0.0361],
        [-0.0044, -0.0008, -0.0187,  ...,  0.0014, -0.0064, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias': tensor([ 0.1927, -0.0745, -0.0890,  ...,  0.6807,  0.7334, -0.5073],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight': tensor([[-2.4796e-02,  3.3035e-03, -5.1379e-05,  ...,  2.5177e-02,
         -2.3010e-02,  1.2245e-02],
        [-2.7504e-03,  1.5330e-04, -1.1650e-02,  ..., -8.4229e-03,
         -4.1389e-03, -6.9275e-03],
        [-1.2238e-02, -7.1983e-03, -1.0323e-02,  ..., -1.6312e-02,
         -5.9547e-03, -1.4572e-03],
        ...,
        [-1.8501e-03,  5.0354e-04, -6.7101e-03,  ..., -7.3471e-03,
         -2.3518e-03, -1.8501e-03],
        [ 5.4131e-03, -4.4937e-03,  1.2329e-02,  ..., -7.1716e-04,
          9.8038e-04,  7.2708e-03],
        [ 1.0040e-02,  6.5422e-03,  9.2163e-03,  ..., -4.5815e-03,
         -1.1330e-03, -2.6169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias': tensor([ 0.0182, -0.0970,  0.0244,  ..., -0.0159, -0.0449, -0.0308],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight': tensor([0.5078, 0.3108, 0.4004,  ..., 1.4219, 0.5015, 0.3591],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias': tensor([-0.0750, -0.0109,  0.0618,  ..., -0.0417,  0.0176, -0.0477],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight': tensor([[-0.0066, -0.0264,  0.0131,  ..., -0.0004,  0.0194, -0.0154],
        [ 0.0097,  0.0090, -0.0017,  ...,  0.0023, -0.0030,  0.0246],
        [-0.0057,  0.0093,  0.0011,  ..., -0.0040,  0.0003,  0.0128],
        ...,
        [ 0.0005, -0.0012, -0.0009,  ...,  0.0011, -0.0034, -0.0059],
        [ 0.0002,  0.0115,  0.0158,  ...,  0.0040,  0.0015,  0.0208],
        [-0.0148,  0.0111, -0.0085,  ...,  0.0049, -0.0076, -0.0022]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias': tensor([-0.2452, -0.3076, -0.4565,  ..., -0.1678, -0.2119, -0.5581],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight': tensor([[ 1.3428e-03, -3.5172e-03,  9.3317e-04,  ..., -5.0354e-03,
          4.3907e-03,  2.0161e-03],
        [ 1.2999e-03, -1.6678e-02, -4.5662e-03,  ..., -4.4584e-04,
          1.3359e-02, -3.9558e-03],
        [-1.8829e-02,  5.2261e-03,  4.7760e-03,  ...,  8.3113e-04,
         -1.8860e-02,  1.0452e-03],
        ...,
        [-7.8201e-03,  8.4305e-04, -2.1601e-04,  ..., -5.6207e-05,
          4.8339e-05,  1.7557e-03],
        [-4.5300e-05, -7.9498e-03, -9.6178e-04,  ...,  3.4180e-03,
         -1.0208e-02,  2.4460e-02],
        [ 6.0883e-03,  3.3398e-03, -3.7789e-04,  ...,  1.5259e-02,
          6.6223e-03,  6.8169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias': tensor([ 0.0453, -0.0798, -0.0027,  ..., -0.0154, -0.1379, -0.0307],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight': tensor([0.6362, 0.5508, 0.3787,  ..., 1.3506, 0.4011, 0.4910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias': tensor([-0.0338, -0.0840, -0.0964,  ..., -0.0491,  0.0855, -0.2158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight': tensor([[ 0.0149, -0.0155, -0.0083,  ...,  0.0066,  0.0086, -0.0173],
        [ 0.0067,  0.0134,  0.0050,  ..., -0.0056, -0.0293, -0.0028],
        [ 0.0041, -0.0027, -0.0011,  ...,  0.0060,  0.0020, -0.0035],
        ...,
        [ 0.0110, -0.0188,  0.0174,  ..., -0.0223,  0.0017, -0.0122],
        [ 0.0165, -0.0201, -0.0204,  ..., -0.0262, -0.0232, -0.0039],
        [ 0.0062, -0.0148,  0.0194,  ...,  0.0090, -0.0007, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias': tensor([-0.0385, -0.0122,  0.0262,  ...,  0.1536,  0.0992, -0.0590],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight': tensor([[ 0.0275, -0.0126, -0.0067,  ...,  0.0002,  0.0201,  0.0163],
        [-0.0074,  0.0475,  0.0058,  ..., -0.0040,  0.0014,  0.0004],
        [-0.0100, -0.0039, -0.0155,  ...,  0.0009, -0.0079,  0.0033],
        ...,
        [ 0.0009,  0.0007,  0.0107,  ...,  0.0007,  0.0007, -0.0059],
        [-0.0008,  0.0147,  0.0066,  ...,  0.0022, -0.0062, -0.0033],
        [-0.0195, -0.0065,  0.0118,  ..., -0.0030,  0.0058,  0.0028]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias': tensor([ 0.0095, -0.0516,  0.0111,  ..., -0.0145,  0.0041,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight': tensor([[ 2.7618e-02,  1.0513e-02,  4.2725e-03,  ...,  6.3095e-03,
         -8.5907e-03, -1.3008e-02],
        [ 2.4605e-03,  1.8875e-02, -3.9787e-03,  ..., -5.7335e-03,
         -2.1698e-02,  5.3406e-03],
        [-5.1880e-04, -1.0147e-02, -1.0471e-03,  ...,  1.0002e-02,
          1.0025e-02, -1.6159e-02],
        ...,
        [ 1.4210e-03, -1.6434e-02,  5.2299e-03,  ..., -1.5053e-02,
          1.1284e-02,  1.2054e-03],
        [ 1.5579e-02,  1.5251e-02, -3.5915e-03,  ..., -2.6520e-02,
         -1.4130e-02, -7.7133e-03],
        [ 1.0399e-02, -2.2491e-02,  3.2783e-06,  ...,  8.3542e-03,
         -6.7215e-03,  1.6525e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias': tensor([-0.1852, -0.5479, -0.1450,  ..., -0.9072, -0.3499, -0.3457],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight': tensor([[-2.1683e-02,  2.3556e-03, -1.9245e-03,  ..., -9.4910e-03,
          1.6251e-02,  1.2527e-02],
        [ 6.4430e-03, -3.8055e-02, -3.1567e-03,  ..., -2.6455e-03,
         -2.1515e-02,  1.1864e-02],
        [ 5.2147e-03, -8.5602e-03,  1.5732e-02,  ..., -1.2611e-02,
          7.3395e-03, -1.2505e-02],
        ...,
        [-1.1325e-04,  3.4676e-03, -1.1169e-02,  ..., -1.0071e-02,
         -5.4538e-05, -1.7357e-03],
        [-6.8245e-03, -1.0139e-02,  1.4579e-04,  ...,  2.0309e-02,
          1.3527e-02, -3.0098e-03],
        [-1.7868e-02,  6.0368e-04, -6.7101e-03,  ...,  6.6853e-04,
         -3.0327e-03,  3.0651e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias': tensor([-0.0147, -0.0586,  0.0197,  ...,  0.0204, -0.1210,  0.0171],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight': tensor([0.7456, 0.3557, 0.6133,  ..., 2.2637, 0.5059, 0.3938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias': tensor([-0.0006,  0.0249,  0.0189,  ..., -0.1539, -0.0345,  0.0151],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight': tensor([[ 0.0034,  0.0025,  0.0007,  ..., -0.0021, -0.0065,  0.0058],
        [ 0.0011, -0.0024, -0.0028,  ..., -0.0094, -0.0078, -0.0065],
        [-0.0051, -0.0246, -0.0075,  ..., -0.0073,  0.0121,  0.0036],
        ...,
        [ 0.0077,  0.0038, -0.0011,  ..., -0.0060, -0.0017,  0.0005],
        [-0.0208, -0.0176, -0.0064,  ..., -0.0076, -0.0137, -0.0056],
        [-0.0240,  0.0082, -0.0047,  ..., -0.0105, -0.0069, -0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias': tensor([-0.0952, -0.1888, -0.1597,  ..., -0.2030, -0.3225, -0.3745],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight': tensor([[ 0.0074, -0.0074,  0.0041,  ...,  0.0181,  0.0235,  0.0145],
        [ 0.0106,  0.0015, -0.0078,  ..., -0.0323, -0.0017,  0.0073],
        [-0.0059, -0.0090, -0.0087,  ...,  0.0023,  0.0091,  0.0240],
        ...,
        [ 0.0054,  0.0013, -0.0012,  ..., -0.0047, -0.0021, -0.0053],
        [-0.0028,  0.0165,  0.0051,  ...,  0.0006, -0.0043, -0.0041],
        [-0.0045,  0.0066,  0.0154,  ..., -0.0027,  0.0146, -0.0076]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias': tensor([ 0.0139, -0.0796,  0.0050,  ...,  0.0715, -0.1787,  0.0414],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight': tensor([0.9761, 0.5317, 0.6523,  ..., 0.0116, 0.5054, 0.5391],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias': tensor([ 0.0585,  0.0282,  0.0207,  ...,  0.3896, -0.0784, -0.1201],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight': tensor([[ 2.0187e-02,  9.6970e-03,  1.7242e-02,  ..., -2.5925e-02,
         -1.5945e-02,  6.4671e-05],
        [ 1.0201e-02, -7.3357e-03,  3.3722e-02,  ...,  8.9111e-03,
         -3.2410e-02,  5.5122e-03],
        [ 9.6817e-03, -2.4231e-02,  5.7907e-03,  ...,  4.0955e-02,
          2.2415e-02, -1.8143e-02],
        ...,
        [-2.4857e-02, -2.5803e-02, -3.2673e-03,  ..., -1.3596e-02,
          3.6240e-03, -5.7650e-04],
        [-6.4754e-04,  2.4719e-02, -3.0411e-02,  ..., -1.3008e-02,
          5.0879e-04, -1.9455e-02],
        [ 1.7380e-02, -2.3804e-02,  1.2428e-02,  ..., -4.4670e-03,
         -4.2297e-02,  9.2545e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias': tensor([-0.0362, -0.0177,  0.0258,  ...,  0.0230,  0.0147,  0.0451],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight': tensor([[-0.0050,  0.0089,  0.0017,  ..., -0.0001, -0.0173, -0.0087],
        [ 0.0064, -0.0170,  0.0071,  ..., -0.0039,  0.0387, -0.0100],
        [-0.0151,  0.0005, -0.0012,  ..., -0.0011, -0.0048,  0.0012],
        ...,
        [ 0.0129, -0.0303, -0.0177,  ...,  0.0005,  0.0013,  0.0006],
        [ 0.0157,  0.0140, -0.0101,  ...,  0.0011,  0.0336, -0.0216],
        [ 0.0171, -0.0183, -0.0061,  ...,  0.0016, -0.0197, -0.0110]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias': tensor([ 0.0241, -0.0481, -0.0028,  ...,  0.0268,  0.0064, -0.0023],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight': tensor([[ 0.0075,  0.0013, -0.0144,  ..., -0.0114, -0.0454, -0.0086],
        [-0.0035, -0.0501,  0.0037,  ..., -0.0065, -0.0287,  0.0070],
        [ 0.0061, -0.0005,  0.0146,  ...,  0.0271,  0.0069, -0.0366],
        ...,
        [-0.0107,  0.0089, -0.0109,  ..., -0.0074, -0.0206, -0.0009],
        [-0.0004, -0.0072, -0.0339,  ..., -0.0124, -0.0053, -0.0094],
        [ 0.0051, -0.0136, -0.0062,  ..., -0.0015, -0.0242, -0.0031]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias': tensor([-0.4634, -0.0086,  0.2761,  ..., -0.2158, -0.2346, -0.2240],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight': tensor([[-2.6817e-03, -4.3983e-03,  1.3580e-03,  ..., -2.4681e-03,
         -1.6296e-02, -1.9119e-02],
        [-6.3057e-03,  1.3931e-02,  2.0657e-03,  ...,  2.4063e-02,
         -2.3544e-02,  2.3361e-02],
        [ 4.4098e-03,  2.9049e-03,  3.0816e-05,  ...,  1.9028e-02,
          1.2093e-02,  9.4528e-03],
        ...,
        [-6.3095e-03,  7.6141e-03, -4.4861e-03,  ..., -6.6261e-03,
         -6.6795e-03, -3.0851e-04],
        [ 1.7075e-02, -3.9612e-02,  9.1248e-03,  ...,  1.1742e-02,
         -3.6469e-02,  2.8046e-02],
        [ 8.2626e-03,  1.3752e-03, -1.0185e-02,  ...,  6.5994e-04,
          1.5320e-02,  1.1871e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias': tensor([ 0.0089, -0.0782,  0.0222,  ..., -0.0115, -0.1763,  0.0233],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight': tensor([0.7534, 0.5015, 0.7891,  ..., 1.1660, 0.6074, 0.5796],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias': tensor([ 0.0149, -0.0122,  0.0052,  ..., -0.1028,  0.0337, -0.0357],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight': tensor([[ 0.0072, -0.0114, -0.0013,  ..., -0.0066,  0.0127,  0.0151],
        [-0.0095,  0.0185,  0.0141,  ..., -0.0075,  0.0141,  0.0101],
        [-0.0018,  0.0118,  0.0032,  ..., -0.0046,  0.0148,  0.0008],
        ...,
        [ 0.0204,  0.0075,  0.0235,  ..., -0.0079,  0.0030, -0.0164],
        [ 0.0157, -0.0033, -0.0008,  ..., -0.0085,  0.0043, -0.0139],
        [-0.0009, -0.0003,  0.0257,  ..., -0.0072, -0.0059, -0.0217]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias': tensor([-0.2440, -0.3796, -0.5205,  ..., -0.2163, -0.4248, -0.2197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight': tensor([[-1.6296e-02,  6.4087e-03, -1.4839e-03,  ..., -2.2827e-02,
          1.9302e-02,  1.6346e-03],
        [ 5.0888e-03, -1.3763e-02,  5.1537e-03,  ..., -1.9989e-02,
         -2.7637e-03, -1.0567e-02],
        [ 2.8763e-03, -5.1460e-03, -5.6326e-05,  ..., -7.1030e-03,
         -9.8724e-03, -2.3098e-03],
        ...,
        [-5.3024e-03, -2.0905e-03,  2.9635e-04,  ..., -5.4092e-03,
          2.0993e-04,  2.4395e-03],
        [-9.9411e-03, -1.4748e-02, -2.4283e-04,  ...,  1.8127e-02,
          3.3779e-03,  2.1927e-02],
        [-5.7182e-03,  1.5316e-03,  1.1997e-03,  ...,  2.5387e-03,
         -5.6725e-03,  4.6387e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias': tensor([-0.0155, -0.0524, -0.0402,  ...,  0.1025, -0.1437, -0.0174],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight': tensor([1.1230, 0.5190, 1.0762,  ..., 0.0112, 0.6738, 0.7544],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias': tensor([ 0.0829, -0.0929, -0.0049,  ...,  0.1129, -0.0392, -0.0677],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight': tensor([[ 0.0035, -0.0081,  0.0270,  ..., -0.0032,  0.0041,  0.0172],
        [-0.0174,  0.0256,  0.0060,  ..., -0.0001,  0.0052, -0.0038],
        [ 0.0038,  0.0144, -0.0161,  ..., -0.0028,  0.0033,  0.0003],
        ...,
        [-0.0023, -0.0123, -0.0080,  ...,  0.0256,  0.0213, -0.0097],
        [-0.0147,  0.0030,  0.0045,  ...,  0.0211,  0.0161, -0.0218],
        [-0.0035,  0.0147,  0.0030,  ..., -0.0244, -0.0005, -0.0255]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias': tensor([-0.0187, -0.0076,  0.0053,  ...,  0.0369,  0.0955,  0.0978],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight': tensor([[-0.0090,  0.0047, -0.0008,  ..., -0.0064, -0.0025, -0.0247],
        [-0.0128, -0.0091,  0.0087,  ...,  0.0024, -0.0012,  0.0007],
        [ 0.0101, -0.0021, -0.0005,  ...,  0.0017,  0.0007, -0.0170],
        ...,
        [-0.0120,  0.0108,  0.0011,  ..., -0.0008, -0.0032,  0.0003],
        [-0.0157, -0.0033,  0.0135,  ..., -0.0007, -0.0310, -0.0129],
        [ 0.0124, -0.0001,  0.0213,  ..., -0.0014, -0.0043, -0.0239]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias': tensor([-0.0186, -0.0071, -0.0258,  ..., -0.0043, -0.0113, -0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight': tensor([[-1.7075e-02,  3.0457e-02,  8.3542e-03,  ..., -8.0032e-03,
          1.6724e-02, -1.0490e-02],
        [-1.2169e-02,  8.2474e-03, -4.2725e-03,  ..., -9.4366e-04,
         -4.9591e-03, -1.0300e-02],
        [ 1.0185e-03, -1.2466e-02, -3.0880e-03,  ..., -3.4428e-03,
         -1.3107e-02,  6.5384e-03],
        ...,
        [ 1.5793e-02,  2.0809e-03,  1.9424e-02,  ...,  2.6367e-02,
          1.0529e-02, -2.1439e-02],
        [-5.6992e-03,  4.1580e-04,  3.8116e-02,  ...,  1.6739e-02,
         -9.0103e-03, -1.6327e-02],
        [ 2.8789e-05, -9.8114e-03,  1.0004e-03,  ..., -2.2293e-02,
         -3.0365e-02,  6.1569e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias': tensor([-0.0072, -1.4619,  0.3447,  ..., -0.6147, -0.3474, -0.6455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight': tensor([[ 5.2567e-03,  1.1238e-02, -6.8092e-03,  ..., -8.0013e-04,
          1.5930e-02, -1.4336e-02],
        [-6.6223e-03,  1.9255e-03, -1.6006e-02,  ..., -2.0706e-02,
         -1.1848e-02, -1.1147e-02],
        [ 2.3087e-02,  1.1986e-02, -1.7288e-02,  ...,  5.7144e-03,
          1.4824e-02, -1.6876e-02],
        ...,
        [ 1.6647e-02,  5.3596e-03, -1.5154e-03,  ..., -2.9736e-03,
          1.8129e-03,  1.0559e-02],
        [ 4.1847e-03,  8.3694e-03,  1.2535e-02,  ..., -1.0323e-02,
          1.6327e-02, -3.2544e-05],
        [ 1.0185e-03, -2.1400e-03, -4.4098e-03,  ..., -4.6120e-03,
          6.0921e-03,  1.5152e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias': tensor([-0.0087, -0.0482, -0.0096,  ..., -0.0479, -0.1366,  0.0062],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight': tensor([0.8506, 0.6484, 0.8960,  ..., 1.2539, 0.7212, 0.8564],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias': tensor([-0.0077,  0.0670, -0.0532,  ..., -0.1699, -0.0490,  0.0434],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight': tensor([[ 0.0058,  0.0115,  0.0089,  ..., -0.0020, -0.0053,  0.0026],
        [-0.0017, -0.0024,  0.0162,  ...,  0.0009, -0.0208, -0.0094],
        [-0.0388, -0.0012, -0.0004,  ...,  0.0032, -0.0029, -0.0226],
        ...,
        [ 0.0085,  0.0130,  0.0209,  ..., -0.0057, -0.0040, -0.0012],
        [ 0.0260,  0.0055,  0.0095,  ..., -0.0008,  0.0056, -0.0098],
        [ 0.0116,  0.0073, -0.0117,  ...,  0.0011, -0.0095, -0.0163]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias': tensor([-0.4192, -0.2394, -0.3069,  ..., -0.3667, -0.2563, -0.1315],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight': tensor([[ 0.0154, -0.0020, -0.0083,  ...,  0.0161, -0.0060,  0.0146],
        [ 0.0042,  0.0226,  0.0055,  ...,  0.0110,  0.0033,  0.0034],
        [ 0.0140, -0.0083,  0.0006,  ...,  0.0085,  0.0010,  0.0007],
        ...,
        [-0.0025, -0.0010, -0.0020,  ...,  0.0007, -0.0030, -0.0018],
        [-0.0141, -0.0032, -0.0003,  ...,  0.0106, -0.0021, -0.0400],
        [ 0.0069,  0.0051, -0.0135,  ..., -0.0115,  0.0067, -0.0104]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias': tensor([-0.0416,  0.0127, -0.0229,  ...,  0.0723, -0.0145, -0.0363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight': tensor([1.1514, 0.7275, 1.1299,  ..., 1.0918, 0.8794, 1.1055],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias': tensor([ 0.0418, -0.1718, -0.0305,  ...,  0.0424, -0.2144, -0.0068],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight': tensor([[ 0.0195, -0.0016, -0.0010,  ...,  0.1302, -0.0123, -0.0063],
        [-0.0176,  0.0024, -0.0196,  ..., -0.1481, -0.0101, -0.0231],
        [-0.0042, -0.0077,  0.0033,  ...,  0.0850, -0.0172,  0.0256],
        ...,
        [ 0.0024, -0.0123,  0.0282,  ..., -0.0123,  0.0272,  0.0247],
        [ 0.0084, -0.0235,  0.0189,  ...,  0.0040, -0.0171,  0.0120],
        [ 0.0308, -0.0003,  0.0095,  ..., -0.0054, -0.0117, -0.0379]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias': tensor([-0.0049,  0.0073,  0.0145,  ...,  0.0185, -0.0033,  0.0204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight': tensor([[ 0.0096,  0.0166, -0.0025,  ..., -0.0005,  0.0005,  0.0034],
        [ 0.0066,  0.0109, -0.0074,  ...,  0.0010,  0.0079, -0.0095],
        [-0.0074, -0.0047,  0.0016,  ...,  0.0002,  0.0039,  0.0040],
        ...,
        [-0.0159,  0.0166, -0.0176,  ...,  0.0020, -0.0064,  0.0302],
        [ 0.0316, -0.0076, -0.0238,  ..., -0.0002, -0.0032, -0.0157],
        [-0.0096, -0.0192,  0.0207,  ..., -0.0009, -0.0289, -0.0082]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias': tensor([ 0.0264, -0.0288,  0.0074,  ...,  0.0075, -0.0047,  0.0190],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight': tensor([[ 0.0136, -0.0235, -0.0059,  ...,  0.0935,  0.0115, -0.0124],
        [-0.0146, -0.0224,  0.0003,  ..., -0.1112, -0.0056, -0.0134],
        [-0.0018,  0.0100,  0.0052,  ...,  0.0525,  0.0120,  0.0163],
        ...,
        [ 0.0338,  0.0004,  0.0047,  ..., -0.0146,  0.0189, -0.0173],
        [ 0.0022, -0.0096, -0.0040,  ...,  0.0011, -0.0013,  0.0135],
        [ 0.0178,  0.0135,  0.0019,  ..., -0.0075,  0.0044, -0.0363]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias': tensor([ 0.2430,  0.3418, -0.1379,  ...,  0.0247,  1.4775,  0.2130],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight': tensor([[-0.0026,  0.0052,  0.0064,  ...,  0.0172, -0.0226,  0.0066],
        [-0.0029,  0.0043, -0.0091,  ..., -0.0054, -0.0009,  0.0137],
        [-0.0161,  0.0021,  0.0049,  ...,  0.0088,  0.0251, -0.0076],
        ...,
        [ 0.0092,  0.0003, -0.0009,  ..., -0.0040,  0.0036,  0.0044],
        [ 0.0016, -0.0087,  0.0108,  ..., -0.0028, -0.0046,  0.0207],
        [ 0.0181, -0.0077, -0.0030,  ..., -0.0368, -0.0015,  0.0158]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias': tensor([-0.0217,  0.0017,  0.0176,  ...,  0.0564, -0.0415, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight': tensor([0.8926, 0.8076, 1.0293,  ..., 2.0488, 0.9590, 0.9756],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias': tensor([-0.1279, -0.0777, -0.0509,  ..., -0.2275, -0.0558,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight': tensor([[ 0.0265,  0.0048,  0.0027,  ..., -0.0071,  0.0051,  0.0187],
        [ 0.0004,  0.0177,  0.0098,  ..., -0.0020, -0.0084,  0.0181],
        [-0.0045,  0.0070, -0.0007,  ..., -0.0080, -0.0070, -0.0316],
        ...,
        [-0.0285,  0.0282,  0.0047,  ...,  0.0006, -0.0079,  0.0194],
        [-0.0049, -0.0312, -0.0060,  ..., -0.0043,  0.0310, -0.0003],
        [ 0.0185,  0.0199,  0.0079,  ..., -0.0067, -0.0297, -0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias': tensor([-0.1132, -0.1494, -0.4023,  ..., -0.2355, -0.3335, -0.2045],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight': tensor([[-0.0180,  0.0037,  0.0069,  ..., -0.0019, -0.0086, -0.0024],
        [-0.0006, -0.0030, -0.0042,  ..., -0.0177,  0.0375, -0.0014],
        [-0.0129, -0.0050, -0.0065,  ...,  0.0015, -0.0005, -0.0149],
        ...,
        [ 0.0031,  0.0014, -0.0087,  ..., -0.0003,  0.0073,  0.0014],
        [ 0.0105,  0.0060,  0.0064,  ..., -0.0005, -0.0007,  0.0372],
        [-0.0087, -0.0052,  0.0026,  ..., -0.0113, -0.0085,  0.0098]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias': tensor([-0.0068,  0.0179, -0.0552,  ...,  0.1210, -0.0750, -0.1090],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight': tensor([1.1914, 0.9712, 1.2656,  ..., 0.1719, 0.9092, 1.1973],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias': tensor([-0.0956, -0.1851, -0.0547,  ...,  0.2583, -0.0542,  0.0387],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight': tensor([[ 0.0076, -0.0117, -0.0114,  ...,  0.0770, -0.0048, -0.0017],
        [-0.0195, -0.0001, -0.0053,  ...,  0.0370, -0.0298,  0.0023],
        [-0.0094, -0.0034,  0.0132,  ...,  0.0014,  0.0088, -0.0013],
        ...,
        [ 0.0047, -0.0200, -0.0213,  ..., -0.0028, -0.0125, -0.0193],
        [-0.0028,  0.0018, -0.0313,  ..., -0.0143, -0.0024,  0.0085],
        [-0.0081, -0.0074,  0.0052,  ..., -0.0006, -0.0049, -0.0085]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias': tensor([ 0.0311, -0.0070, -0.0134,  ...,  0.0024, -0.0121, -0.0230],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight': tensor([[ 0.0104, -0.0064, -0.0062,  ...,  0.0015,  0.0052, -0.0058],
        [ 0.0179, -0.0065, -0.0221,  ..., -0.0002, -0.0032, -0.0219],
        [-0.0078,  0.0084, -0.0027,  ..., -0.0003,  0.0120,  0.0011],
        ...,
        [-0.0272, -0.0105,  0.0010,  ..., -0.0082,  0.0024,  0.0062],
        [ 0.0284, -0.0029, -0.0178,  ..., -0.0007, -0.0008, -0.0054],
        [-0.0113,  0.0083,  0.0034,  ..., -0.0102,  0.0250,  0.0115]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias': tensor([ 0.0282,  0.0175, -0.0284,  ...,  0.0397, -0.0209, -0.1344],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight': tensor([[ 0.0094, -0.0159, -0.0203,  ...,  0.0367, -0.0055, -0.0276],
        [ 0.0029, -0.0178, -0.0045,  ..., -0.0709, -0.0047, -0.0184],
        [-0.0128,  0.0083,  0.0116,  ..., -0.0014,  0.0039,  0.0124],
        ...,
        [-0.0292,  0.0131, -0.0025,  ...,  0.0003, -0.0127, -0.0156],
        [-0.0237,  0.0121, -0.0025,  ..., -0.0010,  0.0081, -0.0145],
        [ 0.0137,  0.0139,  0.0163,  ...,  0.0071,  0.0116, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias': tensor([-1.8535,  0.1802,  2.3398,  ..., -0.0595, -0.0338,  0.0305],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight': tensor([[ 0.0028, -0.0249,  0.0077,  ...,  0.0163, -0.0069, -0.0036],
        [ 0.0140, -0.0086,  0.0026,  ...,  0.0077,  0.0073, -0.0239],
        [ 0.0044,  0.0041, -0.0237,  ..., -0.0202, -0.0074,  0.0211],
        ...,
        [-0.0025,  0.0102, -0.0030,  ...,  0.0096,  0.0018,  0.0186],
        [ 0.0052, -0.0034,  0.0046,  ..., -0.0001,  0.0089, -0.0238],
        [-0.0090,  0.0134,  0.0052,  ..., -0.0156, -0.0131,  0.0157]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias': tensor([ 0.0039,  0.0259, -0.0086,  ..., -0.0503, -0.0064, -0.0460],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight': tensor([1.1934, 1.1006, 1.2510,  ..., 1.4092, 1.1592, 1.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias': tensor([ 0.0223, -0.0916,  0.0971,  ..., -0.2983, -0.0408,  0.0070],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight': tensor([[-0.0150,  0.0078,  0.0025,  ..., -0.0011, -0.0016,  0.0092],
        [-0.0219,  0.0313,  0.0128,  ...,  0.0032,  0.0150,  0.0033],
        [-0.0176, -0.0190,  0.0216,  ...,  0.0038, -0.0361,  0.0145],
        ...,
        [ 0.0060, -0.0061, -0.0066,  ...,  0.0027, -0.0050, -0.0172],
        [-0.0283, -0.0057,  0.0115,  ..., -0.0054, -0.0136, -0.0057],
        [-0.0160,  0.0153, -0.0277,  ..., -0.0289, -0.0194,  0.0007]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias': tensor([-0.1221, -0.2144, -0.4114,  ..., -0.1118, -0.1782, -0.3628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight': tensor([[-0.0016,  0.0125, -0.0344,  ..., -0.0221,  0.0044, -0.0154],
        [-0.0039, -0.0351,  0.0205,  ...,  0.0108, -0.0206, -0.0023],
        [ 0.0063, -0.0273, -0.0012,  ...,  0.0131,  0.0057, -0.0150],
        ...,
        [-0.0002, -0.0069,  0.0022,  ..., -0.0065,  0.0032,  0.0088],
        [ 0.0108, -0.0061, -0.0134,  ..., -0.0061,  0.0058, -0.0083],
        [ 0.0133,  0.0173,  0.0049,  ...,  0.0188, -0.0199, -0.0074]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias': tensor([-0.0200,  0.0232, -0.0657,  ...,  0.1028, -0.0782, -0.1134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight': tensor([1.2578, 1.1084, 1.2061,  ..., 0.5884, 1.0264, 1.2910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias': tensor([-0.0061, -0.0651,  0.0878,  ...,  0.1716,  0.1021, -0.0355],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight': tensor([[-0.0184, -0.0017,  0.0284,  ..., -0.0922, -0.0121,  0.0085],
        [ 0.0216,  0.0109,  0.0091,  ..., -0.0531,  0.0165, -0.0052],
        [-0.0036,  0.0282,  0.0128,  ...,  0.0421, -0.0305, -0.0203],
        ...,
        [-0.0003, -0.0044, -0.0082,  ..., -0.0171,  0.0052,  0.0071],
        [ 0.0136, -0.0294, -0.0073,  ..., -0.0191, -0.0179,  0.0170],
        [-0.0079,  0.0298, -0.0092,  ...,  0.0071,  0.0015,  0.0033]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias': tensor([-0.0044, -0.0038, -0.0472,  ...,  0.0818,  0.0363, -0.0465],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight': tensor([[ 1.9028e-02,  3.3264e-03, -1.4641e-02,  ..., -4.6754e-04,
         -1.4366e-02,  1.6556e-02],
        [ 2.1267e-04, -1.5457e-02, -3.2166e-02,  ..., -2.4629e-04,
          5.9090e-03, -9.8267e-03],
        [-1.2535e-02, -1.2222e-02,  9.6970e-03,  ...,  1.7128e-03,
         -2.1992e-03,  3.7842e-03],
        ...,
        [ 1.0918e-02,  1.8097e-02,  1.2695e-02,  ...,  4.8494e-04,
          5.1918e-03, -1.9058e-02],
        [ 9.9792e-03, -1.2085e-02,  6.0320e-04,  ...,  3.4790e-03,
          1.0284e-02,  2.8300e-04],
        [ 2.2034e-02, -1.5373e-03, -2.1362e-02,  ...,  4.9706e-03,
         -4.9174e-05, -6.5117e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias': tensor([ 0.0094,  0.0439, -0.0031,  ..., -0.0485, -0.1193,  0.0170],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight': tensor([[-1.2352e-02,  2.3239e-02,  5.5618e-03,  ..., -5.1178e-02,
         -2.8687e-02,  2.2531e-05],
        [-1.0605e-02, -2.5497e-02,  1.1894e-02,  ..., -2.0462e-02,
         -8.5449e-04,  4.6265e-02],
        [ 8.6212e-03, -9.3765e-03,  5.9357e-03,  ...,  2.0432e-02,
         -2.2537e-02,  4.4495e-02],
        ...,
        [ 1.3062e-02, -5.5428e-03,  1.0025e-02,  ..., -4.5746e-02,
          6.3477e-03,  2.0248e-02],
        [ 9.6588e-03, -1.4442e-02, -2.0096e-02,  ...,  6.9542e-03,
          5.9013e-03, -3.3588e-03],
        [-5.3177e-03,  2.2705e-02, -2.1713e-02,  ...,  2.4307e-02,
          1.5465e-02, -8.3237e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias': tensor([ 0.0542, -0.0733,  0.2440,  ..., -0.3313, -0.1129,  0.1049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight': tensor([[-0.0227,  0.0130, -0.0113,  ..., -0.0045,  0.0108, -0.0190],
        [-0.0057, -0.0069,  0.0119,  ..., -0.0068,  0.0143,  0.0030],
        [ 0.0062,  0.0204,  0.0161,  ..., -0.0079, -0.0057,  0.0308],
        ...,
        [ 0.0001,  0.0003,  0.0048,  ...,  0.0089, -0.0032,  0.0210],
        [-0.0079,  0.0007,  0.0030,  ...,  0.0093, -0.0068, -0.0121],
        [-0.0154,  0.0158, -0.0231,  ..., -0.0158,  0.0141, -0.0072]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias': tensor([-0.0179,  0.0685, -0.0152,  ..., -0.0815,  0.0257,  0.0175],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight': tensor([1.1738, 1.1582, 1.1592,  ..., 1.5869, 1.1748, 1.2314],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias': tensor([-0.0068,  0.0917, -0.0354,  ..., -0.3271, -0.1141, -0.0543],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight': tensor([[-0.0195, -0.0128, -0.0054,  ..., -0.0029, -0.0047,  0.0116],
        [-0.0031, -0.0199,  0.0011,  ..., -0.0044,  0.0127,  0.0019],
        [ 0.0130, -0.0056,  0.0037,  ..., -0.0005,  0.0237,  0.0081],
        ...,
        [ 0.0115,  0.0130, -0.0272,  ...,  0.0021,  0.0227,  0.0057],
        [-0.0035,  0.0108, -0.0211,  ..., -0.0011,  0.0154, -0.0001],
        [-0.0336,  0.0183,  0.0121,  ..., -0.0012, -0.0093,  0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias': tensor([-0.3628, -0.2211, -0.1648,  ..., -0.2524, -0.2686, -0.2517],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight': tensor([[-4.5166e-03,  7.6828e-03,  1.3664e-02,  ..., -2.5959e-03,
         -2.0126e-02, -7.1602e-03],
        [-1.4015e-02,  2.0084e-03,  6.2370e-03,  ...,  1.9714e-02,
         -4.8294e-03, -2.3682e-02],
        [-4.3793e-03,  6.3400e-03,  5.3253e-03,  ...,  9.2888e-04,
          7.6599e-03, -1.8555e-02],
        ...,
        [-4.1809e-03, -1.8768e-03,  4.0741e-03,  ..., -1.5802e-03,
         -3.6144e-03,  8.3983e-05],
        [-2.7523e-03, -2.6489e-02, -1.3283e-02,  ...,  3.4904e-03,
         -1.4786e-02,  6.2981e-03],
        [-3.0880e-03, -2.1713e-02, -1.7853e-02,  ...,  1.1139e-02,
          7.2784e-03, -1.2558e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias': tensor([-0.0283,  0.0284, -0.0329,  ...,  0.0671, -0.0050, -0.0488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight': tensor([1.2725, 1.2539, 1.2041,  ..., 0.7529, 1.0645, 1.2422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias': tensor([ 0.0019, -0.0140,  0.0246,  ...,  0.2150, -0.1251, -0.2118],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0117,  0.0046,  ..., -0.0265, -0.0033,  0.0070],
        [ 0.0061,  0.0207, -0.0110,  ...,  0.0132,  0.0091,  0.0226],
        [-0.0012,  0.0130,  0.0031,  ...,  0.0025,  0.0157,  0.0028],
        ...,
        [ 0.0178,  0.0099,  0.0200,  ...,  0.0006, -0.0303, -0.0324],
        [-0.0035,  0.0138,  0.0245,  ..., -0.0032, -0.0065,  0.0055],
        [-0.0023,  0.0024, -0.0018,  ...,  0.0053,  0.0023, -0.0070]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias': tensor([ 0.1105, -0.0046,  0.0618,  ...,  0.0103, -0.0147,  0.0179],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight': tensor([[ 0.0128, -0.0147,  0.0370,  ..., -0.0059,  0.0019, -0.0157],
        [-0.0200,  0.0040, -0.0021,  ..., -0.0084, -0.0056, -0.0079],
        [-0.0030, -0.0037, -0.0301,  ..., -0.0076,  0.0190,  0.0188],
        ...,
        [ 0.0036,  0.0197, -0.0007,  ..., -0.0078,  0.0181, -0.0004],
        [-0.0112,  0.0034, -0.0117,  ...,  0.0041, -0.0017, -0.0116],
        [-0.0199,  0.0032, -0.0224,  ..., -0.0046,  0.0289,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias': tensor([-0.0085, -0.0267, -0.0139,  ..., -0.0130,  0.0113,  0.0014],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight': tensor([[-5.2223e-03, -1.1261e-02,  2.0859e-02,  ..., -3.4424e-02,
          5.4245e-03,  3.5515e-03],
        [ 2.7637e-03,  4.4861e-03,  5.6877e-03,  ...,  6.7830e-05,
         -1.3123e-02,  1.6266e-02],
        [-7.9575e-03,  6.3133e-03,  1.7059e-02,  ...,  2.5711e-03,
         -5.4283e-03, -1.0437e-02],
        ...,
        [-1.2264e-03,  2.9633e-02, -8.0185e-03,  ...,  1.4366e-02,
          2.8824e-02, -1.8001e-05],
        [ 5.7316e-04,  8.2397e-03,  1.8951e-02,  ...,  1.4248e-03,
          1.8433e-02, -1.7624e-02],
        [ 6.5842e-03,  2.7451e-02, -1.9012e-02,  ...,  1.1887e-02,
         -7.3357e-03,  1.1284e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias': tensor([-0.8462,  0.0103, -1.0879,  ..., -0.1941,  0.1663, -1.2803],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight': tensor([[-0.0020,  0.0252,  0.0039,  ...,  0.0061, -0.0123,  0.0283],
        [ 0.0043,  0.0004, -0.0082,  ..., -0.0251,  0.0068,  0.0017],
        [-0.0231,  0.0006,  0.0164,  ...,  0.0248,  0.0101,  0.0125],
        ...,
        [ 0.0080,  0.0312,  0.0238,  ...,  0.0045,  0.0003,  0.0054],
        [ 0.0077,  0.0073, -0.0009,  ..., -0.0016,  0.0038, -0.0133],
        [ 0.0194, -0.0053, -0.0238,  ...,  0.0249, -0.0041,  0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias': tensor([-0.0205,  0.0181, -0.0017,  ..., -0.0779,  0.0408, -0.0200],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight': tensor([1.1533, 1.2090, 1.1787,  ..., 1.6367, 1.1729, 1.2188],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias': tensor([-0.0550,  0.0990, -0.0018,  ..., -0.1779, -0.0518, -0.0147],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight': tensor([[-0.0073, -0.0223,  0.0130,  ..., -0.0079, -0.0028,  0.0022],
        [-0.0071,  0.0068,  0.0017,  ..., -0.0123, -0.0179, -0.0108],
        [ 0.0072,  0.0217,  0.0110,  ...,  0.0060,  0.0005,  0.0016],
        ...,
        [ 0.0225, -0.0085,  0.0064,  ...,  0.0007,  0.0014, -0.0003],
        [-0.0191,  0.0245,  0.0085,  ..., -0.0102, -0.0108, -0.0063],
        [ 0.0290, -0.0322, -0.0287,  ..., -0.0045,  0.0156, -0.0153]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias': tensor([-0.4795, -0.1469, -0.1043,  ..., -0.2998, -0.2252, -0.3262],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight': tensor([[-0.0205,  0.0170, -0.0019,  ...,  0.0084,  0.0040,  0.0268],
        [ 0.0060,  0.0025, -0.0069,  ...,  0.0071, -0.0261,  0.0028],
        [ 0.0291, -0.0064, -0.0019,  ..., -0.0131,  0.0078, -0.0294],
        ...,
        [-0.0110,  0.0011, -0.0081,  ..., -0.0030,  0.0036, -0.0003],
        [-0.0195,  0.0083,  0.0063,  ...,  0.0095, -0.0105,  0.0214],
        [-0.0028,  0.0316,  0.0016,  ..., -0.0094, -0.0051,  0.0145]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias': tensor([ 0.0411, -0.0040, -0.0517,  ...,  0.1116,  0.0086, -0.0608],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight': tensor([1.3838, 1.2871, 1.2334,  ..., 0.6108, 1.1768, 1.2568],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias': tensor([-0.2367,  0.0573,  0.1235,  ...,  0.2408,  0.0240, -0.0257],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight': tensor([[-0.0176,  0.0033,  0.0183,  ..., -0.0038,  0.0074,  0.0088],
        [-0.0091,  0.0276, -0.0216,  ...,  0.0220,  0.0110,  0.0020],
        [-0.0428, -0.0160,  0.0246,  ...,  0.0130, -0.0163, -0.0116],
        ...,
        [ 0.0326,  0.0183, -0.0093,  ...,  0.0212, -0.0169,  0.0020],
        [ 0.0131,  0.0204,  0.0034,  ...,  0.0138,  0.0030,  0.0125],
        [ 0.0216,  0.0034,  0.0112,  ..., -0.0203,  0.0063, -0.0135]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias': tensor([-0.0005,  0.0142, -0.0017,  ...,  0.0816, -0.0667,  0.0688],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight': tensor([[-0.0305, -0.0173,  0.0406,  ...,  0.0054,  0.0093, -0.0001],
        [ 0.0040,  0.0132, -0.0068,  ..., -0.0034, -0.0217, -0.0175],
        [-0.0051,  0.0121, -0.0121,  ..., -0.0104, -0.0141, -0.0050],
        ...,
        [ 0.0016,  0.0205, -0.0056,  ..., -0.0040, -0.0046,  0.0020],
        [ 0.0378,  0.0040, -0.0073,  ...,  0.0001, -0.0014,  0.0133],
        [ 0.0088, -0.0021, -0.0040,  ..., -0.0019,  0.0257, -0.0056]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias': tensor([-0.0842, -0.0092,  0.0031,  ...,  0.0677, -0.0071,  0.0129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight': tensor([[ 0.0169, -0.0117, -0.0191,  ...,  0.0101, -0.0038,  0.0100],
        [-0.0080,  0.0092,  0.0094,  ...,  0.0197, -0.0175, -0.0183],
        [-0.0264, -0.0041,  0.0021,  ...,  0.0114,  0.0084, -0.0139],
        ...,
        [-0.0015,  0.0094,  0.0175,  ...,  0.0220, -0.0158,  0.0012],
        [-0.0012,  0.0214, -0.0034,  ...,  0.0166, -0.0191,  0.0039],
        [ 0.0204, -0.0130,  0.0074,  ..., -0.0208,  0.0063, -0.0040]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias': tensor([ 0.0173,  0.2045, -0.1959,  ..., -0.0136, -0.0571, -0.2710],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight': tensor([[ 1.1879e-02, -8.7357e-03, -2.2980e-02,  ..., -5.5885e-03,
         -2.6260e-02,  1.4985e-04],
        [ 2.3117e-02, -1.8127e-02,  2.0111e-02,  ..., -5.3711e-03,
         -3.0880e-03, -2.6855e-03],
        [-7.4577e-03,  5.7449e-03, -2.7313e-02,  ...,  2.7695e-03,
          7.9803e-03,  1.0475e-02],
        ...,
        [-1.1810e-02,  1.0620e-02,  1.4153e-02,  ...,  7.8049e-03,
          7.3671e-04,  2.8267e-03],
        [ 6.1150e-03,  1.5244e-02,  2.3621e-02,  ...,  9.0599e-05,
          2.7008e-03, -3.2196e-02],
        [ 3.8743e-04, -6.6109e-03, -1.4534e-02,  ...,  1.1330e-03,
         -1.8280e-02, -3.4065e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias': tensor([-0.0230,  0.0388, -0.0072,  ..., -0.0651,  0.0296, -0.0002],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight': tensor([1.2031, 1.2344, 1.1543,  ..., 1.5986, 1.2275, 1.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias': tensor([-0.0587,  0.0094, -0.0588,  ..., -0.2544, -0.1669, -0.0670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight': tensor([[-0.0105, -0.0159, -0.0260,  ..., -0.0012,  0.0033,  0.0001],
        [ 0.0232, -0.0237,  0.0074,  ..., -0.0032,  0.0108,  0.0003],
        [ 0.0088,  0.0072,  0.0034,  ...,  0.0001, -0.0065,  0.0012],
        ...,
        [ 0.0007, -0.0093,  0.0181,  ..., -0.0021, -0.0059,  0.0082],
        [ 0.0024,  0.0102, -0.0177,  ..., -0.0005, -0.0069, -0.0302],
        [ 0.0112,  0.0245,  0.0004,  ...,  0.0030, -0.0044,  0.0190]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias': tensor([-0.1327, -0.2241, -0.0568,  ..., -0.2708, -0.3245, -0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight': tensor([[ 1.0185e-02, -1.1162e-02, -2.3911e-02,  ...,  2.9709e-02,
         -1.3023e-02, -1.1803e-02],
        [ 8.2092e-03, -4.3631e-04, -3.1257e-04,  ..., -1.3252e-02,
          5.4598e-05, -1.8997e-02],
        [ 5.5885e-03,  1.8112e-02,  9.0179e-03,  ..., -3.1700e-03,
          8.4686e-03, -3.6144e-03],
        ...,
        [ 4.7798e-03,  3.0174e-03, -3.5143e-04,  ...,  5.4665e-03,
         -3.4122e-03, -4.2953e-03],
        [ 3.2082e-03, -1.4816e-02, -9.4986e-04,  ..., -1.9455e-02,
         -9.8825e-05,  9.9869e-03],
        [-7.2784e-03, -5.8289e-03, -3.9062e-03,  ...,  5.5122e-03,
         -2.4323e-02, -2.7542e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias': tensor([ 0.0389,  0.0069, -0.0129,  ...,  0.0417,  0.0218,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight': tensor([1.4287, 1.3613, 1.2949,  ..., 1.0137, 1.1826, 1.3213],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias': tensor([-0.1137,  0.0275,  0.0679,  ...,  0.1796,  0.0205, -0.2534],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight': tensor([[ 0.0030,  0.0209, -0.0001,  ..., -0.0044,  0.0148,  0.0093],
        [-0.0027, -0.0116,  0.0012,  ...,  0.0060, -0.0152, -0.0084],
        [-0.0064,  0.0066, -0.0148,  ..., -0.0031, -0.0160,  0.0061],
        ...,
        [ 0.0134, -0.0141, -0.0170,  ...,  0.0031, -0.0175,  0.0096],
        [ 0.0032, -0.0072,  0.0027,  ...,  0.0026,  0.0248,  0.0016],
        [ 0.0372, -0.0190,  0.0259,  ..., -0.0076,  0.0134,  0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias': tensor([ 0.0132, -0.0158,  0.0312,  ...,  0.1599,  0.0190, -0.0702],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight': tensor([[-0.0019,  0.0161, -0.0136,  ...,  0.0041,  0.0124, -0.0042],
        [ 0.0003, -0.0210,  0.0050,  ...,  0.0030, -0.0272,  0.0083],
        [-0.0101, -0.0327, -0.0195,  ..., -0.0035,  0.0067, -0.0172],
        ...,
        [ 0.0214, -0.0060, -0.0126,  ..., -0.0054, -0.0032,  0.0097],
        [-0.0153, -0.0010, -0.0009,  ...,  0.0023, -0.0131,  0.0013],
        [ 0.0080,  0.0060,  0.0053,  ..., -0.0054, -0.0073,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias': tensor([-0.0223, -0.0200, -0.0063,  ..., -0.0170, -0.0150,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight': tensor([[-0.0132,  0.0006,  0.0249,  ..., -0.0071,  0.0142, -0.0221],
        [-0.0046,  0.0369, -0.0272,  ...,  0.0017,  0.0163,  0.0032],
        [-0.0089, -0.0084,  0.0370,  ..., -0.0099,  0.0085,  0.0120],
        ...,
        [ 0.0223, -0.0226, -0.0282,  ...,  0.0133, -0.0224, -0.0005],
        [ 0.0005, -0.0127, -0.0058,  ..., -0.0071,  0.0076, -0.0049],
        [-0.0067,  0.0026,  0.0143,  ...,  0.0054, -0.0011,  0.0246]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias': tensor([-0.0499, -0.0381,  0.5078,  ..., -0.0939, -1.3535,  0.2761],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight': tensor([[ 0.0038,  0.0181,  0.0089,  ..., -0.0054,  0.0091,  0.0008],
        [-0.0116,  0.0084,  0.0211,  ...,  0.0138,  0.0282, -0.0086],
        [ 0.0388,  0.0029,  0.0070,  ..., -0.0161,  0.0043, -0.0173],
        ...,
        [ 0.0053, -0.0073, -0.0049,  ...,  0.0171, -0.0165,  0.0032],
        [ 0.0020, -0.0032,  0.0069,  ...,  0.0089,  0.0018,  0.0021],
        [ 0.0025, -0.0044,  0.0106,  ..., -0.0193,  0.0141, -0.0083]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias': tensor([ 0.0060,  0.0680,  0.0354,  ..., -0.0553,  0.0136,  0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight': tensor([1.2344, 1.2090, 1.1689,  ..., 1.8428, 1.1562, 1.2676],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias': tensor([-0.0174, -0.0716, -0.1256,  ..., -0.2900, -0.1460,  0.1504],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight': tensor([[-0.0042, -0.0027,  0.0133,  ..., -0.0005,  0.0226, -0.0110],
        [ 0.0404,  0.0308,  0.0195,  ...,  0.0055, -0.0234,  0.0145],
        [-0.0008, -0.0259, -0.0103,  ...,  0.0008,  0.0100,  0.0084],
        ...,
        [ 0.0190, -0.0154,  0.0061,  ..., -0.0111, -0.0397,  0.0165],
        [ 0.0025, -0.0002,  0.0089,  ..., -0.0010, -0.0172, -0.0077],
        [ 0.0183, -0.0069, -0.0037,  ...,  0.0029, -0.0036,  0.0130]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias': tensor([-0.2314, -0.3215, -0.0735,  ..., -0.3020, -0.1613, -0.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight': tensor([[ 1.0155e-02,  3.2532e-02,  8.2626e-03,  ..., -6.4468e-03,
         -4.7760e-03,  5.5432e-06],
        [-1.1612e-02,  1.7509e-03,  2.4841e-02,  ...,  8.9645e-03,
         -2.5436e-02, -8.4152e-03],
        [ 1.5182e-02,  7.3395e-03,  6.1264e-03,  ..., -1.5427e-02,
         -1.8677e-02,  1.9806e-02],
        ...,
        [-5.6686e-03,  6.3848e-04,  4.5128e-03,  ..., -9.9792e-03,
          1.1284e-02,  6.5231e-04],
        [-3.6335e-03,  3.6285e-02, -9.9277e-04,  ...,  4.8828e-03,
          9.6283e-03,  1.3008e-02],
        [ 9.3918e-03, -2.1927e-02, -1.4038e-02,  ...,  1.3329e-02,
          5.4359e-03,  3.3169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias': tensor([0.0373, 0.0198, 0.0018,  ..., 0.0559, 0.0675, 0.0106],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight': tensor([1.4990, 1.4297, 1.3555,  ..., 0.9502, 1.1816, 1.4072],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias': tensor([-0.1736, -0.0029,  0.0179,  ...,  0.2495,  0.0637, -0.1158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight': tensor([[ 0.0138, -0.0022,  0.0212,  ...,  0.0048,  0.0084,  0.0082],
        [-0.0165, -0.0025,  0.0060,  ...,  0.0063,  0.0062, -0.0098],
        [ 0.0116,  0.0009,  0.0094,  ...,  0.0054,  0.0176,  0.0027],
        ...,
        [ 0.0160, -0.0161,  0.0148,  ..., -0.0268,  0.0052,  0.0090],
        [-0.0136,  0.0253, -0.0004,  ...,  0.0156,  0.0059,  0.0038],
        [-0.0080,  0.0130, -0.0251,  ...,  0.0136, -0.0164,  0.0184]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias': tensor([ 0.1146,  1.0303,  0.1827,  ...,  0.0439,  0.0025, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0085, -0.0074,  ...,  0.0006, -0.0214, -0.0142],
        [ 0.0022,  0.0155, -0.0111,  ..., -0.0004, -0.0232, -0.0101],
        [-0.0139,  0.0073, -0.0043,  ..., -0.0005, -0.0110, -0.0235],
        ...,
        [ 0.0153,  0.0130, -0.0090,  ...,  0.0045,  0.0109,  0.0025],
        [ 0.0072,  0.0052, -0.0024,  ..., -0.0120,  0.0016, -0.0072],
        [ 0.0013, -0.0272, -0.0105,  ..., -0.0043,  0.0004, -0.0020]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias': tensor([ 0.0573, -0.0360, -0.0042,  ...,  0.0485, -0.0465,  0.0206],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight': tensor([[ 0.0094,  0.0003,  0.0279,  ...,  0.0015, -0.0191,  0.0090],
        [ 0.0041, -0.0014,  0.0020,  ...,  0.0017, -0.0018,  0.0040],
        [-0.0280,  0.0335,  0.0134,  ...,  0.0017,  0.0047, -0.0206],
        ...,
        [-0.0081, -0.0019,  0.0095,  ..., -0.0111, -0.0239,  0.0087],
        [-0.0195, -0.0019,  0.0218,  ...,  0.0267,  0.0121, -0.0089],
        [-0.0340, -0.0066,  0.0098,  ...,  0.0160,  0.0019, -0.0100]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias': tensor([ 0.2460,  1.7949,  0.0708,  ..., -0.2112,  0.1188,  0.6323],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight': tensor([[ 0.0051,  0.0107, -0.0119,  ..., -0.0148,  0.0005, -0.0302],
        [-0.0066, -0.0071, -0.0048,  ..., -0.0226, -0.0094,  0.0276],
        [ 0.0101,  0.0083,  0.0168,  ..., -0.0064,  0.0009, -0.0152],
        ...,
        [ 0.0094, -0.0071,  0.0016,  ..., -0.0147,  0.0114,  0.0020],
        [ 0.0223,  0.0076,  0.0287,  ..., -0.0214,  0.0006,  0.0041],
        [ 0.0177,  0.0222,  0.0063,  ...,  0.0065,  0.0120, -0.0114]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias': tensor([ 0.0267, -0.0057, -0.0027,  ..., -0.0531, -0.0267,  0.0482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight': tensor([1.2383, 1.2549, 1.2197,  ..., 1.8193, 1.1484, 1.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias': tensor([ 0.1250, -0.0352,  0.1172,  ..., -0.1227, -0.0328,  0.1005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight': tensor([[-0.0007, -0.0112,  0.0090,  ..., -0.0016,  0.0087,  0.0027],
        [ 0.0122, -0.0152,  0.0042,  ..., -0.0079, -0.0033, -0.0148],
        [ 0.0095, -0.0118, -0.0270,  ...,  0.0040,  0.0046, -0.0246],
        ...,
        [-0.0209, -0.0194, -0.0025,  ..., -0.0006, -0.0144,  0.0085],
        [ 0.0016,  0.0133,  0.0006,  ..., -0.0033, -0.0143,  0.0128],
        [-0.0106,  0.0115,  0.0019,  ..., -0.0046, -0.0505,  0.0052]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias': tensor([-0.3506, -0.3098, -0.0692,  ..., -0.3076, -0.2494, -0.4229],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight': tensor([[-0.0116,  0.0186, -0.0109,  ...,  0.0093, -0.0051, -0.0192],
        [ 0.0115,  0.0091,  0.0046,  ...,  0.0060, -0.0104, -0.0086],
        [-0.0004,  0.0162,  0.0221,  ...,  0.0048,  0.0374,  0.0092],
        ...,
        [-0.0029,  0.0068, -0.0073,  ...,  0.0019, -0.0060,  0.0068],
        [ 0.0121, -0.0012, -0.0035,  ..., -0.0168, -0.0036, -0.0015],
        [ 0.0085, -0.0005,  0.0138,  ..., -0.0026,  0.0074, -0.0113]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias': tensor([ 0.0374, -0.0088, -0.0430,  ...,  0.0654, -0.0126, -0.0253],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight': tensor([1.5195, 1.3818, 1.3984,  ..., 0.8403, 1.2627, 1.5020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias': tensor([-0.1865,  0.1162,  0.4048,  ...,  0.2292,  0.4202, -0.0959],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight': tensor([[ 0.0295,  0.0205, -0.0174,  ...,  0.0181,  0.0055,  0.0153],
        [ 0.0159, -0.0236, -0.0138,  ...,  0.0058,  0.0019,  0.0084],
        [-0.0116, -0.0219,  0.0080,  ...,  0.0020, -0.0022,  0.0255],
        ...,
        [-0.0140,  0.0030, -0.0549,  ...,  0.0038, -0.0079,  0.0469],
        [-0.0193,  0.0216, -0.0092,  ...,  0.0083,  0.0186,  0.0123],
        [ 0.0039,  0.0084,  0.0082,  ..., -0.0016, -0.0041, -0.0187]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias': tensor([-0.0278, -0.0587, -0.0110,  ..., -0.0826, -0.0213, -0.0725],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight': tensor([[-0.0007,  0.0020,  0.0042,  ..., -0.0033, -0.0094, -0.0123],
        [ 0.0162,  0.0139,  0.0239,  ..., -0.0017, -0.0188,  0.0138],
        [-0.0234,  0.0133, -0.0101,  ..., -0.0029, -0.0003,  0.0196],
        ...,
        [ 0.0244,  0.0202,  0.0058,  ..., -0.0130,  0.0092, -0.0032],
        [ 0.0215,  0.0236, -0.0171,  ..., -0.0159, -0.0069,  0.0134],
        [-0.0087,  0.0025,  0.0248,  ..., -0.0004,  0.0047, -0.0208]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias': tensor([-0.0305,  0.0005, -0.0124,  ..., -0.0511, -0.0883,  0.0079],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight': tensor([[-0.0156,  0.0022, -0.0072,  ...,  0.0036,  0.0290,  0.0180],
        [-0.0003,  0.0088, -0.0014,  ..., -0.0144, -0.0101,  0.0001],
        [-0.0141, -0.0287,  0.0098,  ..., -0.0024,  0.0292,  0.0254],
        ...,
        [-0.0255,  0.0364, -0.0171,  ...,  0.0032,  0.0116, -0.0182],
        [-0.0159,  0.0349, -0.0009,  ..., -0.0083, -0.0006, -0.0242],
        [-0.0239,  0.0287,  0.0045,  ...,  0.0057, -0.0037, -0.0132]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias': tensor([-0.2856, -0.3130, -0.2024,  ...,  0.1942, -0.0307, -0.0692],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight': tensor([[ 0.0021, -0.0248,  0.0393,  ..., -0.0213, -0.0080,  0.0129],
        [-0.0123, -0.0083,  0.0236,  ..., -0.0091, -0.0172, -0.0205],
        [-0.0194, -0.0024,  0.0146,  ..., -0.0071,  0.0185, -0.0175],
        ...,
        [-0.0277,  0.0011, -0.0187,  ...,  0.0559,  0.0597, -0.0009],
        [ 0.0156,  0.0051, -0.0020,  ..., -0.0031,  0.0066,  0.0040],
        [-0.0057, -0.0281, -0.0138,  ...,  0.0075, -0.0093,  0.0108]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias': tensor([ 0.0077,  0.0031,  0.0012,  ..., -0.0701,  0.0300,  0.0083],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight': tensor([1.2822, 1.2529, 1.2988,  ..., 2.2090, 1.1758, 1.3721],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias': tensor([ 0.1495, -0.0801, -0.0723,  ..., -0.1654, -0.0899,  0.0350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight': tensor([[ 0.0063,  0.0413,  0.0369,  ...,  0.0064,  0.0150,  0.0227],
        [ 0.0141,  0.0154,  0.0189,  ...,  0.0018,  0.0107,  0.0041],
        [-0.0081, -0.0167,  0.0103,  ..., -0.0018, -0.0027,  0.0110],
        ...,
        [ 0.0142,  0.0290,  0.0162,  ..., -0.0030,  0.0042,  0.0023],
        [ 0.0167,  0.0140,  0.0168,  ..., -0.0036, -0.0046,  0.0118],
        [-0.0082,  0.0164,  0.0227,  ...,  0.0009, -0.0199, -0.0222]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias': tensor([-0.2788, -0.1959, -0.3855,  ..., -0.3228, -0.2610, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight': tensor([[-6.8474e-03, -1.1681e-02, -1.7517e-02,  ...,  1.0986e-02,
         -1.8341e-02,  2.0432e-02],
        [ 1.1215e-02, -7.8430e-03, -6.9542e-03,  ...,  1.2108e-02,
         -9.6741e-03, -1.2093e-02],
        [ 1.2321e-02, -2.7924e-02, -2.8896e-03,  ...,  4.8676e-03,
         -2.0275e-03, -1.2695e-02],
        ...,
        [-2.5902e-03,  1.4412e-02, -3.3092e-03,  ..., -2.8193e-05,
          6.4087e-04, -7.4434e-04],
        [-1.8280e-02, -8.6746e-03,  9.6130e-03,  ...,  4.2915e-03,
         -1.1269e-02,  2.3453e-02],
        [-6.6452e-03, -2.1088e-02, -1.2444e-02,  ..., -3.5534e-03,
         -7.8659e-03,  2.5589e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias': tensor([ 0.0329,  0.0112, -0.0181,  ...,  0.0332,  0.0061, -0.0410],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight': tensor([1.6201, 1.4990, 1.4219,  ..., 0.7642, 1.2715, 1.4961],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias': tensor([-0.1376, -0.0238, -0.0118,  ...,  0.3352,  0.1462, -0.0976],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight': tensor([[ 0.0070,  0.0068,  0.0031,  ...,  0.0113, -0.0308, -0.0060],
        [ 0.0026, -0.0039,  0.0043,  ..., -0.0343, -0.0066,  0.0307],
        [-0.0036,  0.0332, -0.0028,  ...,  0.0011, -0.0337,  0.0031],
        ...,
        [-0.0229, -0.0187, -0.0097,  ..., -0.0007,  0.0183, -0.0038],
        [ 0.0047,  0.0152, -0.0175,  ...,  0.0070,  0.0130, -0.0114],
        [-0.0206,  0.0068, -0.0252,  ...,  0.0070, -0.0134, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias': tensor([ 0.1860, -0.2378,  0.0005,  ...,  0.0031,  0.1797, -0.0522],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight': tensor([[-0.0298, -0.0140,  0.0248,  ...,  0.0035, -0.0014, -0.0059],
        [-0.0006, -0.0080,  0.0046,  ...,  0.0036,  0.0106, -0.0112],
        [ 0.0055,  0.0188,  0.0175,  ...,  0.0029, -0.0033, -0.0018],
        ...,
        [ 0.0039, -0.0129,  0.0162,  ...,  0.0032, -0.0222, -0.0056],
        [-0.0039, -0.0104,  0.0050,  ..., -0.0019,  0.0213, -0.0076],
        [ 0.0024,  0.0067, -0.0013,  ..., -0.0021,  0.0013,  0.0046]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias': tensor([ 0.0186, -0.0095,  0.0066,  ...,  0.0210,  0.0131,  0.0208],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight': tensor([[ 0.0029, -0.0233, -0.0027,  ...,  0.0144, -0.0352, -0.0105],
        [-0.0247, -0.0116,  0.0012,  ..., -0.0372,  0.0113, -0.0128],
        [ 0.0080, -0.0012, -0.0150,  ...,  0.0013, -0.0024,  0.0199],
        ...,
        [-0.0113, -0.0235, -0.0017,  ...,  0.0006, -0.0010, -0.0029],
        [ 0.0197, -0.0205, -0.0153,  ...,  0.0061,  0.0182,  0.0045],
        [-0.0173, -0.0083,  0.0412,  ...,  0.0141, -0.0057,  0.0143]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias': tensor([ 0.2690, -0.1337,  0.1326,  ...,  0.5728, -0.2661, -0.0468],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight': tensor([[ 0.0029,  0.0160,  0.0056,  ...,  0.0018,  0.0077, -0.0090],
        [ 0.0110, -0.0064,  0.0049,  ...,  0.0272,  0.0262,  0.0051],
        [-0.0114, -0.0032,  0.0054,  ...,  0.0236, -0.0132, -0.0082],
        ...,
        [-0.0007,  0.0021, -0.0044,  ..., -0.0028, -0.0311, -0.0200],
        [-0.0074, -0.0073, -0.0035,  ..., -0.0198, -0.0346, -0.0070],
        [-0.0123, -0.0216,  0.0046,  ...,  0.0036,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias': tensor([-0.0063, -0.0193, -0.0133,  ...,  0.0398,  0.0332,  0.0196],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight': tensor([1.3359, 1.2266, 1.2646,  ..., 1.9346, 1.1377, 1.3818],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias': tensor([ 0.1417,  0.0006,  0.0168,  ...,  0.0170, -0.0730,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight': tensor([[ 0.0115,  0.0003, -0.0145,  ..., -0.0144, -0.0194, -0.0104],
        [-0.0015,  0.0058,  0.0179,  ..., -0.0030,  0.0044, -0.0100],
        [-0.0029,  0.0045,  0.0084,  ..., -0.0206,  0.0133,  0.0283],
        ...,
        [ 0.0059, -0.0118, -0.0161,  ..., -0.0221, -0.0054,  0.0157],
        [ 0.0215, -0.0010,  0.0022,  ...,  0.0130,  0.0179,  0.0099],
        [ 0.0113,  0.0054, -0.0108,  ...,  0.0036,  0.0090, -0.0237]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias': tensor([-0.2153, -0.2783, -0.3320,  ..., -0.1221, -0.1306, -0.2898],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight': tensor([[-0.0038, -0.0308,  0.0166,  ..., -0.0028, -0.0180,  0.0016],
        [ 0.0179,  0.0086,  0.0044,  ...,  0.0105,  0.0129, -0.0061],
        [-0.0078, -0.0048,  0.0276,  ...,  0.0158, -0.0102,  0.0017],
        ...,
        [-0.0093,  0.0032, -0.0129,  ...,  0.0116, -0.0041, -0.0039],
        [-0.0126,  0.0043,  0.0086,  ...,  0.0042, -0.0106,  0.0038],
        [-0.0054, -0.0066, -0.0067,  ..., -0.0130, -0.0257,  0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias': tensor([ 0.0253, -0.0025, -0.0242,  ...,  0.0955,  0.0208, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight': tensor([1.6533, 1.5479, 1.5508,  ..., 0.4094, 1.3984, 1.6689],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias': tensor([-0.2152,  0.1279,  0.3982,  ...,  0.3850,  0.3862, -0.2152],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight': tensor([[ 0.0007,  0.0003,  0.0054,  ...,  0.0126,  0.0008,  0.0107],
        [-0.0359,  0.0132, -0.0041,  ..., -0.0473,  0.0050, -0.0005],
        [ 0.0122, -0.0012, -0.0178,  ..., -0.0031,  0.0207, -0.0100],
        ...,
        [ 0.0512, -0.0152, -0.0452,  ...,  0.0250, -0.0268,  0.0074],
        [ 0.0115,  0.0260, -0.0071,  ...,  0.0085,  0.0057,  0.0017],
        [ 0.0223, -0.0031, -0.0004,  ...,  0.0035, -0.0175,  0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias': tensor([-0.8135, -0.1840,  0.0576,  ..., -0.0189,  0.0277,  0.0699],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight': tensor([[ 2.6184e-02,  6.5842e-03, -6.6528e-03,  ...,  2.3901e-05,
          1.5297e-02, -1.9302e-02],
        [ 4.0741e-03,  3.0079e-03,  3.1090e-03,  ..., -9.0485e-03,
          1.0986e-02,  4.2953e-03],
        [ 4.1504e-03,  1.6336e-03, -1.1185e-02,  ...,  5.6496e-03,
          2.0889e-02, -1.3113e-04],
        ...,
        [-3.6945e-03,  1.4648e-02, -8.8348e-03,  ...,  8.1711e-03,
         -2.6073e-03,  1.3008e-02],
        [ 1.9562e-02, -1.5762e-02,  7.0877e-03,  ...,  6.5517e-04,
         -2.1744e-02, -2.0233e-02],
        [ 1.8417e-02, -1.2039e-02, -9.2239e-03,  ..., -4.6659e-04,
         -1.3191e-02, -7.4272e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias': tensor([ 0.0088,  0.0188,  0.0441,  ..., -0.0099, -0.0044,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight': tensor([[-0.0029,  0.0020, -0.0026,  ...,  0.0042, -0.0110, -0.0049],
        [-0.0278,  0.0302,  0.0003,  ..., -0.0331,  0.0236,  0.0125],
        [ 0.0239,  0.0206,  0.0083,  ..., -0.0029,  0.0212, -0.0040],
        ...,
        [ 0.0231,  0.0166, -0.0169,  ...,  0.0415, -0.0144,  0.0037],
        [ 0.0159,  0.0033, -0.0034,  ...,  0.0044, -0.0091,  0.0034],
        [ 0.0106, -0.0117, -0.0165,  ...,  0.0030, -0.0196,  0.0211]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias': tensor([-2.5234,  0.2341, -0.3838,  ..., -0.0643,  0.1272,  0.1238],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight': tensor([[-0.0296, -0.0036,  0.0027,  ...,  0.0065,  0.0073, -0.0128],
        [-0.0154, -0.0153,  0.0213,  ...,  0.0241,  0.0144,  0.0159],
        [-0.0073, -0.0148,  0.0064,  ...,  0.0165,  0.0177,  0.0191],
        ...,
        [-0.0013,  0.0025, -0.0111,  ..., -0.0081,  0.0079,  0.0101],
        [-0.0041, -0.0076, -0.0202,  ..., -0.0055,  0.0170,  0.0018],
        [ 0.0106, -0.0025,  0.0060,  ...,  0.0055, -0.0079,  0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias': tensor([ 0.0107, -0.0549,  0.0179,  ...,  0.0266,  0.0321, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight': tensor([1.3027, 1.2529, 1.3281,  ..., 1.4834, 1.1562, 1.3789],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias': tensor([ 0.1531,  0.0493, -0.0565,  ..., -0.0096, -0.0239, -0.0371],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight': tensor([[ 0.0043,  0.0120,  0.0113,  ..., -0.0241, -0.0064, -0.0090],
        [ 0.0006, -0.0211, -0.0018,  ..., -0.0029, -0.0108,  0.0110],
        [ 0.0030,  0.0094, -0.0028,  ..., -0.0025, -0.0057,  0.0185],
        ...,
        [-0.0027, -0.0314, -0.0122,  ..., -0.0098, -0.0206, -0.0127],
        [-0.0042,  0.0269, -0.0155,  ..., -0.0024, -0.0119, -0.0034],
        [-0.0102,  0.0069, -0.0109,  ..., -0.0012,  0.0015, -0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias': tensor([-0.2781, -0.2573, -0.3364,  ..., -0.3469, -0.2040, -0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight': tensor([[ 0.0010, -0.0122,  0.0169,  ...,  0.0076, -0.0051,  0.0080],
        [ 0.0136, -0.0151, -0.0033,  ..., -0.0080,  0.0146, -0.0023],
        [ 0.0173, -0.0216,  0.0123,  ...,  0.0066, -0.0024, -0.0003],
        ...,
        [-0.0117,  0.0076, -0.0053,  ...,  0.0010,  0.0026,  0.0003],
        [-0.0175,  0.0074, -0.0194,  ..., -0.0246, -0.0096, -0.0045],
        [ 0.0076,  0.0037,  0.0206,  ...,  0.0206, -0.0109,  0.0051]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias': tensor([ 0.0366, -0.0981, -0.0667,  ...,  0.0356,  0.0194, -0.0255],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight': tensor([1.7695, 1.6426, 1.7236,  ..., 0.6680, 1.5166, 1.7900],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias': tensor([-0.1890,  0.3459,  0.1487,  ...,  0.4136,  0.4312, -0.1221],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight': tensor([[ 0.0141,  0.0079,  0.0303,  ..., -0.0145,  0.0041,  0.0001],
        [-0.0112,  0.0048,  0.0240,  ..., -0.0055, -0.0139,  0.0003],
        [ 0.0167,  0.0107,  0.0269,  ..., -0.0065,  0.0130, -0.0072],
        ...,
        [-0.0014,  0.0062,  0.0020,  ..., -0.0017,  0.0170, -0.0246],
        [-0.0123, -0.0318, -0.0099,  ..., -0.0016, -0.0070, -0.0297],
        [ 0.0025,  0.0103,  0.0089,  ...,  0.0022,  0.0038,  0.0318]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias': tensor([-0.0931,  0.0089, -0.0538,  ...,  0.1041,  0.1436,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight': tensor([[-0.0085,  0.0049, -0.0003,  ...,  0.0036, -0.0302,  0.0040],
        [ 0.0075, -0.0265, -0.0065,  ..., -0.0031,  0.0134, -0.0018],
        [-0.0087, -0.0006, -0.0056,  ...,  0.0055,  0.0154,  0.0372],
        ...,
        [-0.0022, -0.0078,  0.0144,  ...,  0.0019, -0.0084,  0.0115],
        [ 0.0047, -0.0127, -0.0223,  ..., -0.0021, -0.0109,  0.0101],
        [-0.0105, -0.0005, -0.0008,  ..., -0.0030, -0.0079, -0.0039]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias': tensor([-0.0321,  0.0378,  0.0632,  ...,  0.0502, -0.0048, -0.0005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight': tensor([[-0.0095, -0.0095,  0.0312,  ...,  0.0022, -0.0092,  0.0262],
        [-0.0264, -0.0028, -0.0018,  ..., -0.0075, -0.0155, -0.0109],
        [-0.0025, -0.0001,  0.0389,  ..., -0.0119,  0.0128, -0.0002],
        ...,
        [ 0.0271, -0.0069,  0.0122,  ...,  0.0018,  0.0167, -0.0080],
        [ 0.0080, -0.0216,  0.0023,  ...,  0.0015, -0.0140,  0.0002],
        [-0.0039,  0.0055,  0.0021,  ...,  0.0071, -0.0103,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias': tensor([-0.2311,  0.2390, -0.0950,  ...,  0.0876,  0.1581,  0.0798],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight': tensor([[-0.0281, -0.0058,  0.0026,  ..., -0.0079,  0.0053, -0.0023],
        [ 0.0130, -0.0057, -0.0072,  ..., -0.0006, -0.0015, -0.0051],
        [-0.0112,  0.0132,  0.0089,  ..., -0.0184,  0.0022, -0.0036],
        ...,
        [ 0.0086,  0.0047, -0.0106,  ..., -0.0117, -0.0147, -0.0069],
        [ 0.0147, -0.0031, -0.0165,  ...,  0.0125, -0.0091,  0.0107],
        [ 0.0214,  0.0008, -0.0262,  ..., -0.0205, -0.0144,  0.0057]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias': tensor([-0.0645, -0.0639,  0.0044,  ..., -0.0346, -0.0156, -0.0320],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight': tensor([1.3975, 1.3584, 1.4883,  ..., 1.8799, 1.3203, 1.4980],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias': tensor([ 0.0757, -0.1133, -0.0580,  ..., -0.0255, -0.0899, -0.1061],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight': tensor([[-7.1793e-03,  4.6234e-03,  1.7502e-02,  ..., -1.0124e-02,
          1.3245e-02, -6.4430e-03],
        [-1.6571e-02,  1.1040e-02, -5.1537e-03,  ..., -6.7616e-04,
         -2.2491e-02, -9.1019e-03],
        [-7.6675e-04,  2.2156e-02,  1.0216e-02,  ..., -4.4708e-03,
         -1.6510e-02, -2.4704e-02],
        ...,
        [-2.9205e-02, -7.1602e-03,  8.7559e-05,  ..., -9.7656e-03,
          1.6312e-02,  2.7145e-02],
        [-1.2413e-02,  6.9084e-03,  2.4399e-02,  ..., -7.0381e-03,
         -7.9803e-03,  9.6130e-03],
        [ 6.4039e-04, -4.3259e-03,  4.3121e-02,  ..., -3.9101e-03,
         -1.3245e-02,  1.4565e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias': tensor([-0.3418, -0.2771, -0.3467,  ..., -0.3992, -0.2385, -0.2927],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight': tensor([[-9.4452e-03,  1.2772e-02,  1.8539e-02,  ..., -2.6276e-02,
          4.2343e-04, -1.3672e-02],
        [ 3.2593e-02,  8.7070e-04, -2.8477e-03,  ..., -8.7814e-03,
          1.1383e-02, -3.0182e-02],
        [-4.3488e-03, -2.7359e-02,  1.8482e-03,  ..., -6.5002e-03,
          2.6016e-02,  3.3539e-02],
        ...,
        [-4.1504e-03,  1.6251e-02,  7.8354e-03,  ...,  1.4816e-02,
         -1.9627e-03, -6.3002e-05],
        [ 6.4125e-03, -1.6647e-02,  4.3945e-03,  ...,  1.2833e-02,
         -1.5268e-03, -1.7975e-02],
        [-1.8167e-03, -1.1734e-02, -1.4511e-02,  ...,  3.0396e-02,
          1.1108e-02, -9.7580e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias': tensor([-0.0361, -0.0392,  0.0150,  ..., -0.0163,  0.0041, -0.0078],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight': tensor([2.1113, 2.0137, 2.0352,  ..., 0.7090, 1.8164, 2.2012],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias': tensor([-0.1631, -0.1508,  0.1484,  ...,  0.4434,  0.6812, -0.3279],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight': tensor([[-9.9716e-03, -2.5208e-02,  8.4457e-03,  ...,  1.3168e-02,
         -5.3942e-05, -2.8748e-02],
        [-3.1233e-05,  1.3992e-02, -2.2476e-02,  ...,  6.3232e-02,
         -1.4221e-02, -1.4404e-02],
        [-5.1785e-04, -3.1403e-02,  6.5517e-04,  ..., -1.0399e-02,
          1.1505e-02, -2.8076e-03],
        ...,
        [-6.2132e-04, -1.0201e-02,  1.3947e-02,  ..., -5.4810e-02,
         -8.1787e-03, -2.0981e-02],
        [ 9.8572e-03, -1.7899e-02,  1.1734e-02,  ..., -4.1885e-03,
          1.4870e-02,  1.1244e-03],
        [ 1.5884e-02,  2.2827e-02,  4.2000e-03,  ..., -4.3091e-02,
         -2.2690e-02, -1.3191e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias': tensor([ 0.2656, -0.2185,  0.0432,  ..., -0.1787, -0.2061,  0.0742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight': tensor([[ 0.0261,  0.0077, -0.0120,  ..., -0.0027, -0.0164, -0.0107],
        [-0.0080,  0.0102,  0.0077,  ...,  0.0039,  0.0010, -0.0050],
        [ 0.0017, -0.0101, -0.0256,  ...,  0.0058, -0.0145, -0.0055],
        ...,
        [-0.0161,  0.0100, -0.0047,  ..., -0.0049, -0.0208,  0.0245],
        [ 0.0115, -0.0098,  0.0141,  ...,  0.0035, -0.0129, -0.0005],
        [-0.0111, -0.0270,  0.0220,  ..., -0.0022, -0.0052, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias': tensor([-0.0182,  0.0114,  0.1055,  ..., -0.0048, -0.0138,  0.0093],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight': tensor([[-0.0116, -0.0250, -0.0204,  ...,  0.0060, -0.0022, -0.0020],
        [ 0.0243,  0.0011, -0.0106,  ...,  0.0480, -0.0213,  0.0138],
        [ 0.0116, -0.0210, -0.0045,  ..., -0.0067, -0.0268, -0.0189],
        ...,
        [ 0.0013,  0.0050,  0.0468,  ..., -0.0500,  0.0203,  0.0043],
        [ 0.0273, -0.0117,  0.0099,  ..., -0.0033, -0.0067,  0.0015],
        [-0.0062,  0.0012,  0.0167,  ..., -0.0361, -0.0010,  0.0275]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias': tensor([ 0.2439, -0.1146,  0.0887,  ...,  0.2213,  0.1515, -0.0186],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight': tensor([[-3.0136e-02,  1.2367e-02, -9.5749e-03,  ...,  1.8692e-02,
          9.2697e-03, -4.0054e-03],
        [-3.6682e-02, -9.7504e-03,  7.6950e-05,  ..., -1.0941e-02,
          8.2474e-03, -8.6546e-04],
        [ 1.9424e-02, -2.1729e-02,  5.8022e-03,  ...,  6.4888e-03,
         -4.6577e-03, -6.9504e-03],
        ...,
        [-7.0953e-03, -1.1024e-02,  1.4248e-03,  ...,  3.1490e-03,
         -7.8735e-03, -1.8097e-02],
        [ 1.8778e-03, -1.1490e-02, -8.2855e-03,  ..., -1.9104e-02,
          7.3166e-03, -8.8959e-03],
        [-8.1558e-03,  1.7426e-02,  1.1551e-02,  ..., -4.8790e-03,
          5.9700e-03,  9.9030e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias': tensor([-0.0732,  0.0212,  0.0239,  ...,  0.0091, -0.0001, -0.0141],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight': tensor([1.3848, 1.3320, 1.4814,  ..., 1.5195, 1.3164, 1.4180],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias': tensor([ 0.0473, -0.0936, -0.0594,  ...,  0.0325,  0.0149, -0.0659],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight': tensor([[ 1.5793e-02, -8.3160e-03,  2.2156e-02,  ...,  1.8814e-02,
         -5.4436e-03, -1.1604e-02],
        [ 1.5007e-02, -9.5978e-03, -2.5284e-02,  ..., -1.6510e-02,
         -3.3539e-02, -2.3102e-02],
        [-2.1622e-02,  2.0309e-02,  2.1801e-03,  ...,  7.5798e-03,
          1.4145e-02, -7.3433e-03],
        ...,
        [-4.5624e-03, -2.5757e-02,  6.9199e-03,  ...,  3.5572e-03,
          1.4694e-02, -2.2339e-02],
        [-9.1791e-06,  7.1487e-03, -1.3298e-02,  ...,  5.6610e-03,
          4.4975e-03,  1.1978e-02],
        [-5.8289e-03,  5.1689e-03, -1.4862e-02,  ...,  1.8585e-02,
          9.6655e-04,  1.1856e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias': tensor([-0.2683, -0.3921, -0.3279,  ..., -0.3718, -0.2028, -0.3127],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight': tensor([[-0.0059, -0.0140,  0.0130,  ...,  0.0043,  0.0292, -0.0014],
        [ 0.0265, -0.0073, -0.0116,  ..., -0.0211,  0.0206,  0.0263],
        [ 0.0022, -0.0233,  0.0002,  ...,  0.0067, -0.0096, -0.0120],
        ...,
        [ 0.0080, -0.0016,  0.0073,  ..., -0.0021, -0.0057, -0.0010],
        [ 0.0048, -0.0163, -0.0040,  ...,  0.0130, -0.0188,  0.0429],
        [-0.0011, -0.0383, -0.0151,  ..., -0.0132,  0.0248,  0.0216]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias': tensor([ 0.0359,  0.0342,  0.0545,  ...,  0.0745, -0.0070,  0.0030],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight': tensor([2.5176, 2.3496, 2.4785,  ..., 0.5151, 2.0352, 2.4492],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias': tensor([-0.2339, -0.0297,  0.1533,  ...,  0.4067,  0.7363, -0.2054],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0246, -0.0315,  ...,  0.0246, -0.0050,  0.0121],
        [ 0.0096,  0.0193,  0.0106,  ..., -0.0207, -0.0075,  0.0043],
        [ 0.0199,  0.0022, -0.0148,  ..., -0.0771, -0.0211,  0.0064],
        ...,
        [ 0.0369,  0.0040, -0.0087,  ..., -0.0215,  0.0106,  0.0167],
        [-0.0061, -0.0050, -0.0032,  ..., -0.0078,  0.0147,  0.0186],
        [ 0.0009,  0.0079, -0.0195,  ..., -0.0096, -0.0309,  0.0012]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias': tensor([ 0.0911, -0.1252, -0.4846,  ...,  0.0673, -0.0733,  0.0197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight': tensor([[ 0.0141,  0.0237,  0.0094,  ..., -0.0007, -0.0127, -0.0134],
        [ 0.0092, -0.0071,  0.0201,  ...,  0.0027, -0.0176, -0.0013],
        [ 0.0039, -0.0016, -0.0055,  ...,  0.0065, -0.0001, -0.0049],
        ...,
        [ 0.0073, -0.0355, -0.0101,  ...,  0.0047, -0.0010, -0.0099],
        [-0.0019,  0.0097, -0.0335,  ..., -0.0019,  0.0006, -0.0019],
        [ 0.0030, -0.0076,  0.0026,  ..., -0.0004,  0.0043, -0.0152]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias': tensor([ 0.0290,  0.0252,  0.0343,  ...,  0.0027, -0.0045, -0.0545],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight': tensor([[ 0.0060, -0.0019, -0.0088,  ...,  0.0198, -0.0025, -0.0177],
        [ 0.0059,  0.0067,  0.0215,  ..., -0.0244, -0.0294,  0.0024],
        [ 0.0271,  0.0004, -0.0182,  ..., -0.0876,  0.0076, -0.0006],
        ...,
        [-0.0081,  0.0160, -0.0380,  ..., -0.0249, -0.0083,  0.0045],
        [ 0.0112, -0.0182, -0.0261,  ..., -0.0056, -0.0009, -0.0319],
        [ 0.0435,  0.0031,  0.0118,  ..., -0.0163,  0.0102, -0.0193]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias': tensor([ 0.0622,  0.0999, -0.5308,  ..., -0.1455,  0.0368, -0.1086],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight': tensor([[ 4.6425e-03, -2.0313e-03,  2.7237e-02,  ...,  1.0216e-02,
         -2.0187e-02,  1.1955e-02],
        [-5.8823e-03,  2.6627e-02,  7.8506e-03,  ...,  3.9864e-03,
         -1.8646e-02,  2.6762e-05],
        [-5.6601e-04,  5.0240e-03,  2.1591e-02,  ...,  1.1375e-02,
          6.1035e-03,  7.7581e-04],
        ...,
        [ 9.0256e-03, -4.1656e-03, -1.2932e-02,  ...,  9.0778e-05,
          1.9577e-02, -6.6452e-03],
        [ 1.5488e-02,  5.1928e-04,  1.3100e-02,  ..., -2.1057e-02,
         -4.6921e-03,  1.0338e-02],
        [ 3.2501e-03, -2.0432e-02, -2.8076e-02,  ..., -8.2169e-03,
         -2.1858e-03,  3.8376e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias': tensor([ 0.0169,  0.0075, -0.0464,  ...,  0.0064, -0.0125, -0.0271],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight': tensor([1.4844, 1.5352, 1.5859,  ..., 1.5234, 1.4395, 1.5938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias': tensor([ 0.1630, -0.0892, -0.0373,  ..., -0.0082, -0.0609, -0.1628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight': tensor([[-0.0057, -0.0090,  0.0211,  ...,  0.0072, -0.0180, -0.0063],
        [ 0.0278,  0.0188,  0.0136,  ..., -0.0074,  0.0133, -0.0087],
        [-0.0168,  0.0028, -0.0226,  ..., -0.0184, -0.0072, -0.0020],
        ...,
        [ 0.0011, -0.0155, -0.0045,  ..., -0.0092, -0.0268,  0.0125],
        [ 0.0054, -0.0030,  0.0160,  ...,  0.0257, -0.0181, -0.0068],
        [ 0.0045,  0.0018,  0.0164,  ..., -0.0108, -0.0191, -0.0004]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias': tensor([-0.2793, -0.3452, -0.2959,  ..., -0.1838, -0.1981, -0.2494],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight': tensor([[-0.0017, -0.0146,  0.0010,  ...,  0.0037, -0.0001,  0.0201],
        [ 0.0174, -0.0161, -0.0016,  ..., -0.0007, -0.0096, -0.0005],
        [ 0.0072,  0.0077, -0.0210,  ...,  0.0165, -0.0019, -0.0208],
        ...,
        [ 0.0195, -0.0092,  0.0151,  ..., -0.0062, -0.0071, -0.0216],
        [ 0.0159,  0.0006,  0.0077,  ..., -0.0073,  0.0030,  0.0091],
        [ 0.0062,  0.0206,  0.0089,  ...,  0.0090, -0.0033, -0.0063]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias': tensor([0.0065, 0.0102, 0.0046,  ..., 0.0065, 0.0796, 0.0695],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight': tensor([2.6719, 2.5625, 2.7695,  ..., 0.6802, 2.2539, 2.7422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias': tensor([-0.0354,  0.2776,  0.4175,  ...,  0.5674,  0.5327, -0.4670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight': tensor([[-0.0087,  0.0027,  0.0113,  ..., -0.0616,  0.0051, -0.0137],
        [-0.0173,  0.0047,  0.0124,  ...,  0.0239, -0.0160,  0.0129],
        [ 0.0097, -0.0005, -0.0050,  ...,  0.0011,  0.0099, -0.0130],
        ...,
        [-0.0052,  0.0120,  0.0098,  ..., -0.0244,  0.0038,  0.0010],
        [ 0.0119, -0.0235, -0.0134,  ..., -0.0140, -0.0140,  0.0065],
        [ 0.0291,  0.0226, -0.0254,  ..., -0.0035, -0.0137,  0.0350]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias': tensor([ 0.2783, -0.2036, -0.0648,  ...,  0.1705,  0.1809,  0.1080],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight': tensor([[-0.0184,  0.0137,  0.0067,  ..., -0.0029,  0.0099,  0.0297],
        [-0.0110,  0.0184,  0.0020,  ...,  0.0024, -0.0151,  0.0009],
        [ 0.0191, -0.0126,  0.0212,  ...,  0.0024, -0.0348,  0.0026],
        ...,
        [ 0.0005,  0.0007, -0.0011,  ...,  0.0046, -0.0222, -0.0393],
        [ 0.0117,  0.0042,  0.0002,  ..., -0.0006,  0.0005, -0.0083],
        [-0.0062,  0.0128,  0.0124,  ..., -0.0037, -0.0134,  0.0008]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias': tensor([-0.0114,  0.0300,  0.0252,  ..., -0.0060,  0.0197,  0.0400],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight': tensor([[ 1.4931e-02, -1.2466e-02,  2.4918e-02,  ..., -5.9814e-02,
         -4.3068e-03,  1.2131e-02],
        [-1.6464e-02, -9.9030e-03, -1.1108e-02,  ...,  2.3956e-02,
         -3.6163e-02,  1.1703e-02],
        [ 1.0757e-02,  2.5730e-03, -7.3338e-04,  ...,  2.4662e-03,
          6.1493e-03,  6.6528e-03],
        ...,
        [ 5.1003e-03, -7.8678e-06,  5.1041e-03,  ..., -4.5410e-02,
         -3.1738e-02,  1.8631e-02],
        [ 1.7502e-02, -4.1084e-03,  3.9978e-03,  ..., -1.8753e-02,
         -2.2335e-03,  2.1057e-03],
        [ 1.7303e-02,  6.7902e-03,  1.1360e-02,  ...,  8.0719e-03,
         -5.0278e-03,  2.1713e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias': tensor([-0.2339,  0.0393, -0.0323,  ..., -0.1953,  0.0200,  0.0049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight': tensor([[ 0.0254,  0.0050,  0.0049,  ...,  0.0120, -0.0121,  0.0091],
        [ 0.0248, -0.0193, -0.0093,  ..., -0.0044, -0.0032,  0.0151],
        [ 0.0053,  0.0182, -0.0142,  ..., -0.0130, -0.0033, -0.0087],
        ...,
        [ 0.0006, -0.0051, -0.0173,  ...,  0.0031, -0.0128,  0.0099],
        [ 0.0081, -0.0134,  0.0246,  ...,  0.0185, -0.0136,  0.0109],
        [-0.0261, -0.0152, -0.0080,  ...,  0.0230, -0.0056,  0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias': tensor([-0.0083,  0.0091, -0.0955,  ..., -0.0067,  0.0003, -0.0047],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight': tensor([1.5762, 1.4580, 1.5850,  ..., 1.7383, 1.4209, 1.5967],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias': tensor([ 0.1272, -0.2208, -0.0098,  ..., -0.0831, -0.0858, -0.1576],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight': tensor([[-0.0051,  0.0014, -0.0012,  ...,  0.0091, -0.0065, -0.0086],
        [-0.0191,  0.0118,  0.0002,  ..., -0.0095, -0.0148,  0.0134],
        [-0.0012, -0.0324,  0.0047,  ..., -0.0084,  0.0050, -0.0089],
        ...,
        [ 0.0005, -0.0097, -0.0229,  ..., -0.0036, -0.0164, -0.0044],
        [ 0.0058, -0.0019, -0.0019,  ...,  0.0053,  0.0177,  0.0073],
        [ 0.0128,  0.0044, -0.0019,  ..., -0.0147,  0.0180, -0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias': tensor([-0.1597, -0.3298, -0.3066,  ..., -0.3003, -0.3157, -0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight': tensor([[-0.0060, -0.0143,  0.0279,  ..., -0.0150,  0.0291,  0.0124],
        [ 0.0095, -0.0208, -0.0114,  ...,  0.0116, -0.0289,  0.0051],
        [-0.0165,  0.0403, -0.0052,  ...,  0.0008, -0.0144, -0.0153],
        ...,
        [-0.0120,  0.0119, -0.0007,  ...,  0.0051,  0.0161, -0.0073],
        [ 0.0291,  0.0090, -0.0140,  ...,  0.0286,  0.0029, -0.0079],
        [ 0.0233, -0.0179, -0.0138,  ..., -0.0036, -0.0180, -0.0041]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias': tensor([ 0.0113,  0.0318, -0.0128,  ..., -0.0561, -0.0155,  0.0321],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight': tensor([2.7773, 2.7402, 2.7402,  ..., 0.8696, 2.4961, 2.8711],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias': tensor([-0.1473, -0.0198,  0.2091,  ...,  0.4590,  0.5410, -0.2742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight': tensor([[ 0.0005, -0.0174, -0.0133,  ..., -0.0195,  0.0176,  0.0196],
        [ 0.0332, -0.0111, -0.0092,  ..., -0.0143,  0.0277, -0.0138],
        [-0.0094,  0.0108, -0.0135,  ..., -0.0078, -0.0209, -0.0013],
        ...,
        [ 0.0136,  0.0224,  0.0235,  ..., -0.0533, -0.0095,  0.0097],
        [-0.0183, -0.0031, -0.0219,  ..., -0.0209, -0.0113,  0.0082],
        [ 0.0187,  0.0257,  0.0352,  ..., -0.0150,  0.0010,  0.0060]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias': tensor([-0.2089,  0.1558,  0.3555,  ...,  0.0323,  0.1013,  0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight': tensor([[-0.0096,  0.0058, -0.0198,  ...,  0.0084,  0.0249,  0.0066],
        [ 0.0346, -0.0048, -0.0196,  ..., -0.0008, -0.0481, -0.0151],
        [-0.0034,  0.0091,  0.0039,  ..., -0.0047,  0.0017, -0.0073],
        ...,
        [-0.0277, -0.0315,  0.0064,  ..., -0.0131, -0.0027,  0.0125],
        [ 0.0013,  0.0095,  0.0286,  ..., -0.0024,  0.0112,  0.0018],
        [-0.0154,  0.0043, -0.0169,  ...,  0.0051,  0.0013, -0.0213]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias': tensor([0.0214, 0.0242, 0.0006,  ..., 0.0194, 0.0418, 0.0340],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight': tensor([[-0.0110, -0.0187, -0.0399,  ..., -0.0132,  0.0016,  0.0080],
        [ 0.0197,  0.0169,  0.0061,  ..., -0.0240,  0.0292,  0.0127],
        [-0.0047, -0.0227, -0.0048,  ..., -0.0150, -0.0014,  0.0108],
        ...,
        [-0.0113,  0.0006, -0.0214,  ..., -0.0389, -0.0254,  0.0096],
        [ 0.0066,  0.0193,  0.0392,  ...,  0.0004,  0.0306, -0.0154],
        [-0.0041,  0.0141, -0.0124,  ..., -0.0156, -0.0206,  0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias': tensor([-0.0377, -0.0410, -0.0185,  ..., -0.2778,  0.1395,  0.1525],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight': tensor([[-1.2112e-03,  2.4259e-05, -4.5753e-04,  ...,  4.1847e-03,
          3.2597e-03, -3.2745e-02],
        [-1.3557e-02, -5.1613e-03,  2.0218e-02,  ..., -7.0801e-03,
         -2.9678e-02, -3.8872e-03],
        [-2.0355e-02, -4.8676e-03,  1.2039e-02,  ...,  1.1337e-02,
         -5.5161e-03, -1.0376e-02],
        ...,
        [ 1.2032e-02,  1.7944e-02, -4.4212e-03,  ...,  3.3722e-02,
         -1.9394e-02, -2.0691e-02],
        [-1.6998e-02,  2.0340e-02, -9.7885e-03,  ..., -4.0588e-03,
          4.5967e-03, -7.2937e-03],
        [-1.6357e-02, -1.8204e-02,  1.9684e-02,  ...,  1.2749e-02,
         -2.2552e-02, -1.4832e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias': tensor([-0.0427,  0.0264, -0.0947,  ..., -0.0744, -0.0230, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight': tensor([1.6475, 1.5273, 1.6768,  ..., 1.8574, 1.4951, 1.6426],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias': tensor([-0.0313, -0.3167, -0.0297,  ..., -0.0391, -0.0746, -0.2402],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight': tensor([[-0.0260, -0.0154,  0.0028,  ..., -0.0228, -0.0295, -0.0447],
        [ 0.0029, -0.0058,  0.0197,  ...,  0.0138,  0.0183,  0.0026],
        [ 0.0218, -0.0178,  0.0015,  ..., -0.0087,  0.0014,  0.0125],
        ...,
        [ 0.0404,  0.0179, -0.0153,  ...,  0.0049,  0.0196, -0.0120],
        [ 0.0015, -0.0189,  0.0088,  ...,  0.0184, -0.0162, -0.0341],
        [ 0.0035, -0.0139, -0.0161,  ...,  0.0040, -0.0222, -0.0067]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias': tensor([-0.3091, -0.1617, -0.2668,  ..., -0.2510, -0.2261, -0.2350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight': tensor([[-0.0030, -0.0123, -0.0188,  ...,  0.0186, -0.0332, -0.0181],
        [ 0.0014, -0.0037, -0.0307,  ..., -0.0058,  0.0160,  0.0274],
        [ 0.0273, -0.0119, -0.0110,  ..., -0.0013, -0.0041, -0.0059],
        ...,
        [ 0.0018, -0.0187, -0.0384,  ...,  0.0141,  0.0053,  0.0090],
        [ 0.0151, -0.0128, -0.0045,  ...,  0.0167, -0.0064,  0.0077],
        [ 0.0001,  0.0021,  0.0336,  ..., -0.0046, -0.0128,  0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias': tensor([ 0.1198, -0.0191,  0.1595,  ..., -0.0292, -0.0284, -0.0580],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight': tensor([3.1777, 3.2344, 3.2090,  ..., 1.1455, 2.6172, 3.2363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias': tensor([-0.3699,  0.0534, -0.3181,  ...,  0.1720,  0.3350, -0.2013],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight': tensor([[ 0.0132,  0.0254, -0.0020,  ..., -0.0305,  0.0047,  0.0051],
        [ 0.0022, -0.0257,  0.0199,  ..., -0.0184,  0.0286,  0.0047],
        [-0.0092, -0.0116,  0.0196,  ..., -0.0357,  0.0290,  0.0171],
        ...,
        [ 0.0071, -0.0053,  0.0001,  ..., -0.0139, -0.0043, -0.0191],
        [-0.0128,  0.0084, -0.0034,  ..., -0.0035, -0.0175, -0.0111],
        [ 0.0023, -0.0036, -0.0063,  ...,  0.0125, -0.0132,  0.0166]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias': tensor([ 2.2266,  1.3135, -0.9771,  ...,  0.3726,  2.3047,  0.1869],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight': tensor([[-0.0117,  0.0124, -0.0160,  ...,  0.0026,  0.0036,  0.0293],
        [ 0.0022, -0.0097, -0.0008,  ..., -0.0094,  0.0017, -0.0152],
        [-0.0117, -0.0052, -0.0132,  ...,  0.0201,  0.0020, -0.0049],
        ...,
        [ 0.0122, -0.0035, -0.0111,  ..., -0.0017,  0.0214,  0.0207],
        [-0.0134,  0.0110, -0.0031,  ...,  0.0010,  0.0070,  0.0225],
        [ 0.0003,  0.0153,  0.0004,  ...,  0.0096,  0.0122,  0.0161]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias': tensor([ 0.0095, -0.0149, -0.0342,  ...,  0.0316,  0.0107, -0.0553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight': tensor([[ 2.4475e-02,  1.0361e-02, -3.1738e-03,  ...,  6.3629e-03,
         -4.1161e-03,  4.0770e-05],
        [ 6.4735e-03, -1.1032e-02, -4.1046e-03,  ...,  2.4471e-03,
         -7.7009e-04,  3.3226e-03],
        [-2.2324e-02, -5.0497e-04, -2.1210e-02,  ..., -6.5186e-02,
         -3.9253e-03, -4.9324e-03],
        ...,
        [ 7.4692e-03, -2.1229e-03, -2.2095e-02,  ..., -3.7079e-02,
         -3.3173e-02,  2.9621e-03],
        [-2.3987e-02, -1.8463e-03, -3.8791e-04,  ..., -1.6312e-02,
         -2.0157e-02,  1.9180e-02],
        [ 5.5695e-03, -1.0750e-02,  1.4153e-03,  ...,  1.7136e-02,
         -1.8829e-02, -3.1219e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias': tensor([ 0.0942, -0.0380, -0.0066,  ..., -0.2206,  0.0908,  0.0343],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight': tensor([[ 0.0108, -0.0169,  0.0143,  ..., -0.0040, -0.0186, -0.0120],
        [-0.0099,  0.0158, -0.0007,  ..., -0.0126,  0.0125, -0.0013],
        [ 0.0059, -0.0186,  0.0080,  ...,  0.0038,  0.0261, -0.0122],
        ...,
        [ 0.0193, -0.0006, -0.0168,  ..., -0.0111, -0.0033,  0.0045],
        [ 0.0071,  0.0175, -0.0099,  ...,  0.0238,  0.0111,  0.0132],
        [ 0.0269,  0.0227,  0.0074,  ..., -0.0048, -0.0153, -0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias': tensor([ 0.1117, -0.0344, -0.0097,  ..., -0.0479, -0.0558, -0.0235],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight': tensor([1.5781, 1.5361, 1.5830,  ..., 0.8071, 1.4404, 1.7129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias': tensor([ 0.0493, -0.2202, -0.1034,  ...,  0.0678, -0.1000, -0.2034],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight': tensor([[-0.0206, -0.0153,  0.0054,  ...,  0.0216,  0.0042, -0.0064],
        [-0.0240,  0.0083,  0.0154,  ..., -0.0026,  0.0077, -0.0042],
        [ 0.0143,  0.0016,  0.0010,  ...,  0.0362,  0.0050,  0.0193],
        ...,
        [ 0.0191,  0.0038,  0.0125,  ..., -0.0049, -0.0139, -0.0164],
        [ 0.0050,  0.0037,  0.0237,  ..., -0.0271,  0.0079, -0.0093],
        [ 0.0163,  0.0038, -0.0141,  ..., -0.0026, -0.0191,  0.0084]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias': tensor([-0.2673, -0.2559, -0.2236,  ..., -0.2888, -0.2781, -0.0958],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight': tensor([[-0.0093, -0.0160, -0.0221,  ...,  0.0137, -0.0174, -0.0188],
        [-0.0096,  0.0156, -0.0179,  ..., -0.0231,  0.0060, -0.0123],
        [ 0.0032, -0.0022,  0.0147,  ..., -0.0053,  0.0070,  0.0076],
        ...,
        [-0.0122, -0.0089,  0.0011,  ...,  0.0205,  0.0041, -0.0117],
        [ 0.0056, -0.0073, -0.0155,  ..., -0.0081, -0.0361,  0.0044],
        [ 0.0310,  0.0010,  0.0081,  ..., -0.0060, -0.0118, -0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias': tensor([-0.0192, -0.0717,  0.1105,  ..., -0.1528,  0.0851, -0.0401],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight': tensor([3.1602, 3.0371, 2.9180,  ..., 1.5098, 2.5527, 3.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias': tensor([ 0.2227,  0.6216, -0.4958,  ...,  0.2568,  0.0677, -0.4553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight': tensor([[ 0.0037,  0.0141,  0.0131,  ...,  0.0058,  0.0128,  0.0105],
        [ 0.0020, -0.0168, -0.0078,  ...,  0.0242, -0.0173, -0.0008],
        [ 0.0030,  0.0062, -0.0284,  ..., -0.0097,  0.0236,  0.0083],
        ...,
        [-0.0080, -0.0243, -0.0079,  ..., -0.0201, -0.0240, -0.0208],
        [ 0.0029,  0.0056,  0.0167,  ...,  0.0065, -0.0012, -0.0019],
        [-0.0047, -0.0198, -0.0200,  ...,  0.0153,  0.0093, -0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias': tensor([ 0.9746, -1.5684,  4.0703,  ..., -4.7695,  2.3730,  0.0641],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight': tensor([[-0.0094,  0.0040, -0.0081,  ...,  0.0087,  0.0034, -0.0086],
        [-0.0218, -0.0027,  0.0096,  ...,  0.0072, -0.0114, -0.0138],
        [-0.0069,  0.0196,  0.0128,  ...,  0.0089, -0.0430,  0.0282],
        ...,
        [ 0.0080, -0.0076,  0.0247,  ..., -0.0006,  0.0264, -0.0060],
        [-0.0081,  0.0084,  0.0222,  ...,  0.0080, -0.0070,  0.0124],
        [-0.0113,  0.0073,  0.0137,  ..., -0.0100, -0.0085,  0.0073]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias': tensor([-0.0650, -0.0600,  0.0630,  ..., -0.0726,  0.0070, -0.1204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight': tensor([[ 0.0016,  0.0027, -0.0018,  ...,  0.0349, -0.0049, -0.0009],
        [ 0.0076,  0.0003, -0.0250,  ...,  0.0064,  0.0064,  0.0147],
        [-0.0011, -0.0325, -0.0602,  ...,  0.0003, -0.0238,  0.0107],
        ...,
        [ 0.0233,  0.0226,  0.0270,  ...,  0.0236, -0.0239, -0.0167],
        [ 0.0041, -0.0097, -0.0143,  ..., -0.0173, -0.0098,  0.0124],
        [ 0.0090, -0.0034,  0.0003,  ...,  0.0278,  0.0114,  0.0061]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias': tensor([-0.4348, -0.0033, -0.1771,  ..., -0.0897,  0.1703,  0.3945],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight': tensor([[ 0.0021,  0.0206, -0.0078,  ..., -0.0072, -0.0010,  0.0115],
        [ 0.0005,  0.0042, -0.0142,  ...,  0.0190, -0.0119, -0.0008],
        [ 0.0061, -0.0182,  0.0112,  ..., -0.0376, -0.0023, -0.0042],
        ...,
        [-0.0143,  0.0111, -0.0015,  ..., -0.0087,  0.0175, -0.0019],
        [-0.0039,  0.0022,  0.0231,  ..., -0.0050,  0.0082, -0.0150],
        [ 0.0005, -0.0005, -0.0158,  ..., -0.0120, -0.0067, -0.0141]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias': tensor([-0.0269, -0.0574,  0.0638,  ..., -0.1498,  0.0551, -0.1482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight': tensor([1.5703, 1.8379, 1.9336,  ..., 0.8516, 1.4707, 1.7686],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias': tensor([0.3889, 0.2372, 0.1531,  ..., 0.6260, 0.2163, 0.1549],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight': tensor([[-1.1892e-03,  3.9005e-03, -5.7487e-03,  ...,  4.7989e-03,
         -4.2915e-03, -2.5539e-03],
        [ 1.5236e-02, -2.3232e-03, -3.3325e-02,  ...,  2.3758e-02,
         -1.0595e-03, -3.8986e-03],
        [ 2.0737e-02,  7.2479e-03, -3.0842e-03,  ..., -5.4207e-03,
          2.6047e-02, -1.4210e-03],
        ...,
        [ 7.4120e-03, -2.9163e-03,  3.3661e-02,  ..., -4.4785e-03,
          9.1400e-03, -1.5297e-02],
        [-4.3964e-04,  8.5297e-03, -1.5350e-02,  ..., -1.3519e-02,
         -6.6490e-03,  5.9700e-04],
        [-7.5579e-05,  1.0449e-04,  8.8196e-03,  ..., -1.0658e-02,
         -6.6032e-03, -5.4703e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias': tensor([-0.3184, -0.2345, -0.2834,  ..., -0.2498, -0.1849, -0.2729],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight': tensor([[ 0.0369,  0.0093, -0.0179,  ..., -0.0141, -0.0035,  0.0064],
        [ 0.0050,  0.0101,  0.0117,  ...,  0.0070, -0.0066, -0.0147],
        [-0.0015,  0.0263,  0.0119,  ..., -0.0270,  0.0052, -0.0028],
        ...,
        [ 0.0133,  0.0236, -0.0152,  ...,  0.0251, -0.0268, -0.0321],
        [ 0.0021, -0.0061,  0.0079,  ..., -0.0029,  0.0145, -0.0033],
        [-0.0097,  0.0175, -0.0111,  ..., -0.0278, -0.0016, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias': tensor([-0.1587, -0.0068,  0.1970,  ...,  0.0549, -0.0199,  0.0069],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight': tensor([2.5664, 2.3809, 2.5742,  ..., 1.8262, 2.4121, 2.7520],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias': tensor([ 0.1838,  0.3330, -0.2296,  ..., -0.1086,  0.5938, -0.2812],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight': tensor([[ 0.0305, -0.0035, -0.0098,  ...,  0.0054, -0.0111,  0.0049],
        [-0.0194,  0.0099,  0.0032,  ...,  0.0125,  0.0277, -0.0057],
        [ 0.0115,  0.0072, -0.0170,  ...,  0.0162,  0.0032,  0.0142],
        ...,
        [ 0.0076, -0.0034,  0.0187,  ...,  0.0278, -0.0174, -0.0046],
        [-0.0037, -0.0002,  0.0051,  ..., -0.0108,  0.0012,  0.0065],
        [-0.0047, -0.0013,  0.0154,  ...,  0.0158, -0.0106,  0.0013]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias': tensor([-0.0001,  0.0002, -0.0072,  ...,  0.0011, -0.0007, -0.0008],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight': tensor([[ 0.0221, -0.0052,  0.0127,  ..., -0.0090, -0.0092, -0.0165],
        [-0.0569, -0.0251, -0.0167,  ..., -0.0070, -0.0093, -0.0182],
        [-0.0159, -0.0159,  0.0239,  ...,  0.0133,  0.0071,  0.0088],
        ...,
        [ 0.0025,  0.0141, -0.0087,  ...,  0.0007, -0.0157, -0.0012],
        [ 0.0053,  0.0023, -0.0199,  ...,  0.0264,  0.0148, -0.0300],
        [-0.0040,  0.0095, -0.0180,  ..., -0.0396, -0.0316, -0.0156]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias': tensor([-0.0095, -0.0084,  0.0243,  ...,  0.1217, -0.0273,  0.0116],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight': tensor([[ 1.3329e-02, -5.8022e-03,  2.2945e-03,  ...,  1.0509e-03,
          2.1591e-02, -3.7422e-03],
        [-1.7593e-02,  9.9182e-03,  2.1652e-02,  ..., -1.7380e-02,
         -1.1452e-02, -1.1536e-02],
        [-4.2648e-03,  3.6955e-06,  8.7585e-03,  ...,  5.5428e-03,
          1.0963e-02, -8.2855e-03],
        ...,
        [ 2.6302e-03, -6.2828e-03,  1.8387e-02,  ...,  2.4658e-02,
         -1.4015e-02, -1.8509e-02],
        [-1.9140e-03, -1.3588e-02, -1.2770e-03,  ..., -1.8143e-02,
         -2.0309e-02, -2.0172e-02],
        [-1.6346e-03,  5.2338e-03, -1.7044e-02,  ..., -4.7073e-03,
          1.5930e-02,  1.8097e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias': tensor([ 0.0486, -0.0525, -1.9268,  ...,  0.0309,  0.1466, -0.0662],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight': tensor([[-0.0204,  0.0447, -0.0052,  ...,  0.0069,  0.0077,  0.0218],
        [ 0.0017,  0.0142, -0.0191,  ...,  0.0062, -0.0003,  0.0145],
        [-0.0078,  0.0171, -0.0142,  ..., -0.0220,  0.0106,  0.0089],
        ...,
        [-0.0215, -0.0144, -0.0043,  ...,  0.0026, -0.0030,  0.0222],
        [ 0.0184,  0.0181,  0.0050,  ...,  0.0064, -0.0177,  0.0218],
        [ 0.0176,  0.0081, -0.0153,  ..., -0.0053,  0.0065,  0.0165]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias': tensor([-0.2126,  0.1382,  0.1891,  ...,  0.0073,  0.0610, -0.0497],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight': tensor([1.5518, 1.4453, 1.4551,  ..., 0.8970, 1.4531, 1.5488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias': tensor([-0.0075, -0.0621, -0.0674,  ..., -0.0965, -0.1760, -0.1098],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight': tensor([[ 0.0173, -0.0038, -0.0434,  ..., -0.0142, -0.0269,  0.0163],
        [ 0.0112,  0.0112, -0.0199,  ...,  0.0013,  0.0100, -0.0072],
        [-0.0037, -0.0045, -0.0143,  ..., -0.0011, -0.0073, -0.0100],
        ...,
        [-0.0162, -0.0028, -0.0142,  ...,  0.0240, -0.0207, -0.0169],
        [ 0.0084,  0.0172, -0.0097,  ..., -0.0170, -0.0171, -0.0099],
        [ 0.0414, -0.0024, -0.0073,  ..., -0.0142,  0.0116,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias': tensor([-0.2035, -0.6177, -0.2632,  ..., -0.2837, -0.4905, -0.3960],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight': tensor([[-0.0123, -0.0106,  0.0170,  ..., -0.0074, -0.0057,  0.0038],
        [ 0.0014, -0.0104, -0.0019,  ...,  0.0073,  0.0064, -0.0129],
        [-0.0083, -0.0003,  0.0169,  ...,  0.0021,  0.0054,  0.0217],
        ...,
        [-0.0205, -0.0112, -0.0028,  ..., -0.0033,  0.0101,  0.0241],
        [ 0.0122, -0.0082,  0.0100,  ..., -0.0086,  0.0083, -0.0369],
        [ 0.0042, -0.0036,  0.0006,  ..., -0.0066,  0.0024,  0.0018]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias': tensor([ 0.0215, -0.1328, -0.1233,  ..., -0.1167,  0.0634,  0.0916],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight': tensor([1.6230, 1.6143, 1.6387,  ..., 1.4531, 1.7188, 1.8516],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias': tensor([-0.0200, -0.0892,  0.0742,  ...,  0.0301,  0.1517, -0.2600],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight': tensor([0.9370, 1.0215, 0.9346,  ..., 0.8223, 1.0596, 1.0498],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias': tensor([-0.0060,  0.1511, -0.0550,  ...,  0.2749,  0.0767,  0.0092],
       dtype=torch.float16), 'model.mm_projector.weight': tensor([[-0.0058,  0.0183,  0.0040,  ...,  0.0120, -0.0213, -0.0254],
        [ 0.0293,  0.0225,  0.0172,  ...,  0.0072,  0.0080, -0.0079],
        [-0.0066,  0.0113,  0.0238,  ...,  0.0290, -0.0191,  0.0269],
        ...,
        [ 0.0110, -0.0014, -0.0078,  ..., -0.0036,  0.0293, -0.0229],
        [-0.0262,  0.0114, -0.0109,  ...,  0.0125, -0.0284, -0.0200],
        [-0.0090,  0.0195,  0.0217,  ...,  0.0064, -0.0226, -0.0227]]), 'model.mm_projector.bias': tensor([ 0.0163, -0.0104,  0.0238,  ...,  0.0042,  0.0243, -0.0145]), 'model.perceiver.latents': tensor([[ 0.2479, -1.4467,  0.7551,  ...,  1.7504, -0.6530, -0.1281],
        [ 0.0421,  1.7885,  1.7728,  ...,  0.5902,  1.1691,  0.2311],
        [-0.3791,  0.8578, -0.2799,  ..., -2.2811, -0.2102, -1.1457],
        ...,
        [-0.3750,  2.3468,  0.4717,  ..., -0.2282,  0.3013,  1.8180],
        [ 0.5708,  0.3021, -1.1437,  ..., -2.3328,  0.4123, -0.6557],
        [-1.3990,  1.1140,  1.3416,  ...,  1.1621,  0.4688, -0.6750]]), 'model.perceiver.frame_embs': tensor([[ 0.8099,  1.8869, -1.1476,  ..., -1.5629, -0.8787,  1.1017],
        [ 1.0209, -0.4010, -0.0802,  ...,  0.0273,  0.3210,  0.2409],
        [-0.1564, -1.4243,  0.0817,  ...,  1.3751,  0.9447, -0.9461],
        ...,
        [-0.4654, -1.5972,  0.5061,  ..., -0.0652,  0.0486,  0.7143],
        [-0.0115, -0.9264, -2.1191,  ...,  0.5616,  1.1096, -2.1345],
        [ 2.2288,  1.4096, -0.4821,  ...,  1.5747, -0.1848, -0.3058]]), 'model.perceiver.media_time_embs': tensor([[[-1.9470,  1.4758,  0.2359,  ...,  0.5319, -0.2437,  0.4565]],

        [[-0.3077, -0.0568,  1.6924,  ...,  0.1392, -2.7157,  1.3711]],

        [[ 1.9595, -0.9069,  2.2371,  ..., -0.1717, -0.2775, -0.2876]],

        [[-0.3869,  0.4347,  1.8879,  ...,  0.3422,  1.0039, -0.3439]]]), 'model.perceiver.layers.0.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.to_q.weight': tensor([[ 0.0001,  0.0124, -0.0021,  ..., -0.0154, -0.0133,  0.0104],
        [ 0.0058,  0.0084,  0.0121,  ..., -0.0058, -0.0139, -0.0141],
        [-0.0003,  0.0133, -0.0044,  ...,  0.0112, -0.0037, -0.0068],
        ...,
        [ 0.0004,  0.0070,  0.0033,  ...,  0.0117, -0.0095,  0.0046],
        [-0.0060, -0.0078,  0.0112,  ...,  0.0089, -0.0041,  0.0096],
        [-0.0020, -0.0059,  0.0137,  ..., -0.0047, -0.0067,  0.0008]]), 'model.perceiver.layers.0.0.to_kv.weight': tensor([[-0.0058, -0.0051,  0.0032,  ..., -0.0110, -0.0063, -0.0056],
        [ 0.0077, -0.0152,  0.0152,  ...,  0.0065,  0.0004, -0.0067],
        [ 0.0123, -0.0115, -0.0066,  ..., -0.0061, -0.0098,  0.0102],
        ...,
        [ 0.0023,  0.0022,  0.0014,  ..., -0.0069,  0.0071,  0.0076],
        [ 0.0056, -0.0155, -0.0116,  ...,  0.0064,  0.0145, -0.0103],
        [-0.0047,  0.0126, -0.0010,  ..., -0.0032, -0.0022,  0.0089]]), 'model.perceiver.layers.0.0.to_out.weight': tensor([[-0.0223,  0.0164,  0.0317,  ..., -0.0136,  0.0382, -0.0190],
        [ 0.0046,  0.0400,  0.0230,  ..., -0.0048,  0.0033,  0.0379],
        [-0.0031, -0.0196, -0.0387,  ...,  0.0400,  0.0068,  0.0073],
        ...,
        [-0.0316, -0.0041, -0.0030,  ..., -0.0248,  0.0396,  0.0075],
        [ 0.0395,  0.0271, -0.0239,  ..., -0.0233,  0.0022,  0.0356],
        [ 0.0126, -0.0207, -0.0403,  ..., -0.0370,  0.0035,  0.0064]]), 'model.perceiver.layers.0.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.1.1.weight': tensor([[ 0.0063, -0.0051,  0.0108,  ...,  0.0103, -0.0019, -0.0140],
        [ 0.0105, -0.0023,  0.0035,  ...,  0.0143, -0.0058, -0.0046],
        [ 0.0087, -0.0067, -0.0009,  ..., -0.0090,  0.0064, -0.0132],
        ...,
        [ 0.0055,  0.0055,  0.0013,  ..., -0.0054,  0.0119, -0.0106],
        [-0.0068,  0.0145,  0.0101,  ...,  0.0101, -0.0010,  0.0040],
        [-0.0084,  0.0117,  0.0024,  ...,  0.0131,  0.0128, -0.0115]]), 'model.perceiver.layers.0.1.3.weight': tensor([[-0.0044, -0.0027, -0.0030,  ..., -0.0038,  0.0076,  0.0009],
        [-0.0074, -0.0032, -0.0076,  ...,  0.0025,  0.0021, -0.0063],
        [ 0.0037, -0.0031, -0.0011,  ..., -0.0011,  0.0020, -0.0066],
        ...,
        [ 0.0075, -0.0075,  0.0011,  ..., -0.0033, -0.0034, -0.0043],
        [ 0.0075, -0.0067, -0.0064,  ...,  0.0033,  0.0053,  0.0036],
        [-0.0056, -0.0067, -0.0002,  ...,  0.0053,  0.0028,  0.0070]]), 'model.perceiver.layers.1.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.to_q.weight': tensor([[ 0.0038,  0.0114, -0.0035,  ...,  0.0126,  0.0127,  0.0006],
        [ 0.0071, -0.0140, -0.0033,  ...,  0.0150, -0.0144, -0.0085],
        [ 0.0014, -0.0151,  0.0109,  ..., -0.0033, -0.0101, -0.0005],
        ...,
        [ 0.0109,  0.0103,  0.0093,  ..., -0.0070,  0.0147,  0.0128],
        [ 0.0032,  0.0026, -0.0132,  ...,  0.0029,  0.0010, -0.0109],
        [ 0.0150, -0.0002, -0.0072,  ...,  0.0021,  0.0034,  0.0079]]), 'model.perceiver.layers.1.0.to_kv.weight': tensor([[-0.0043, -0.0134,  0.0005,  ...,  0.0115, -0.0013,  0.0005],
        [-0.0012, -0.0028,  0.0139,  ..., -0.0131, -0.0013, -0.0020],
        [ 0.0067, -0.0132,  0.0071,  ...,  0.0041,  0.0089, -0.0069],
        ...,
        [ 0.0039, -0.0048, -0.0085,  ...,  0.0154, -0.0119, -0.0046],
        [-0.0118, -0.0013,  0.0112,  ...,  0.0009, -0.0074,  0.0114],
        [ 0.0106,  0.0090, -0.0082,  ...,  0.0097,  0.0108,  0.0065]]), 'model.perceiver.layers.1.0.to_out.weight': tensor([[-0.0400, -0.0295,  0.0153,  ...,  0.0194, -0.0146, -0.0381],
        [-0.0401, -0.0202, -0.0260,  ...,  0.0418,  0.0026, -0.0342],
        [ 0.0222,  0.0041, -0.0171,  ...,  0.0034, -0.0055,  0.0156],
        ...,
        [-0.0331,  0.0149,  0.0130,  ..., -0.0110, -0.0117,  0.0264],
        [-0.0315,  0.0010, -0.0078,  ...,  0.0161, -0.0057,  0.0332],
        [ 0.0212,  0.0245, -0.0194,  ...,  0.0137,  0.0123,  0.0430]]), 'model.perceiver.layers.1.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.1.1.weight': tensor([[ 0.0030, -0.0017, -0.0039,  ...,  0.0096,  0.0018, -0.0086],
        [-0.0011, -0.0075, -0.0134,  ...,  0.0139, -0.0074,  0.0073],
        [ 0.0058,  0.0112, -0.0150,  ...,  0.0022,  0.0148,  0.0023],
        ...,
        [-0.0014,  0.0148, -0.0109,  ...,  0.0076,  0.0026, -0.0032],
        [ 0.0117, -0.0044, -0.0030,  ...,  0.0072, -0.0136,  0.0067],
        [-0.0018,  0.0012,  0.0141,  ...,  0.0060,  0.0063,  0.0078]]), 'model.perceiver.layers.1.1.3.weight': tensor([[-0.0016,  0.0038, -0.0022,  ...,  0.0014, -0.0062,  0.0010],
        [ 0.0076,  0.0010,  0.0043,  ..., -0.0010, -0.0004, -0.0056],
        [ 0.0057, -0.0034, -0.0028,  ...,  0.0011,  0.0052,  0.0003],
        ...,
        [ 0.0048, -0.0016,  0.0006,  ...,  0.0051, -0.0040,  0.0022],
        [-0.0067,  0.0065,  0.0043,  ...,  0.0068,  0.0040, -0.0045],
        [ 0.0007,  0.0068, -0.0069,  ...,  0.0048, -0.0073,  0.0018]]), 'model.perceiver.layers.2.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.to_q.weight': tensor([[ 0.0153, -0.0115,  0.0095,  ..., -0.0043,  0.0090,  0.0089],
        [-0.0148, -0.0142, -0.0038,  ..., -0.0102,  0.0121, -0.0123],
        [ 0.0006, -0.0007,  0.0153,  ..., -0.0116,  0.0118,  0.0114],
        ...,
        [-0.0060,  0.0134, -0.0119,  ...,  0.0135, -0.0075,  0.0054],
        [ 0.0125,  0.0115,  0.0096,  ...,  0.0026,  0.0076, -0.0136],
        [ 0.0002, -0.0044,  0.0036,  ...,  0.0081,  0.0121, -0.0009]]), 'model.perceiver.layers.2.0.to_kv.weight': tensor([[ 0.0004,  0.0007, -0.0100,  ...,  0.0151, -0.0114, -0.0119],
        [ 0.0071,  0.0075, -0.0035,  ..., -0.0140,  0.0087, -0.0149],
        [ 0.0123, -0.0049,  0.0039,  ...,  0.0109,  0.0080, -0.0104],
        ...,
        [ 0.0027, -0.0021, -0.0151,  ...,  0.0116,  0.0135, -0.0003],
        [-0.0041,  0.0063, -0.0016,  ..., -0.0137, -0.0083,  0.0042],
        [-0.0033,  0.0046, -0.0037,  ..., -0.0151,  0.0137,  0.0145]]), 'model.perceiver.layers.2.0.to_out.weight': tensor([[ 5.2583e-03, -6.4157e-03, -2.7344e-02,  ...,  1.1083e-02,
          9.3395e-03,  2.0924e-02],
        [ 3.0683e-02,  9.4313e-03,  3.4424e-02,  ..., -4.3447e-02,
          5.0160e-05, -4.2498e-03],
        [ 4.2354e-02, -1.6262e-02, -2.3757e-02,  ..., -2.6116e-02,
         -1.2513e-02, -3.5802e-03],
        ...,
        [ 3.6673e-02,  3.3299e-02,  1.4160e-02,  ...,  1.2371e-02,
          6.6954e-03, -8.1962e-03],
        [-3.6501e-03, -1.6589e-02, -8.5443e-04,  ..., -1.0026e-03,
          4.2797e-02, -2.0065e-02],
        [-4.1445e-02, -3.2325e-02,  3.2793e-03,  ...,  3.7536e-02,
         -3.7075e-02,  4.0261e-02]]), 'model.perceiver.layers.2.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.1.1.weight': tensor([[-0.0104,  0.0122, -0.0096,  ..., -0.0131, -0.0103, -0.0115],
        [-0.0037, -0.0130,  0.0139,  ...,  0.0050, -0.0139, -0.0012],
        [-0.0070, -0.0037,  0.0022,  ..., -0.0045,  0.0023, -0.0133],
        ...,
        [-0.0008,  0.0005,  0.0057,  ...,  0.0074, -0.0109,  0.0104],
        [-0.0136,  0.0110,  0.0001,  ..., -0.0091, -0.0153, -0.0149],
        [ 0.0156, -0.0042, -0.0093,  ..., -0.0119,  0.0083,  0.0090]]), 'model.perceiver.layers.2.1.3.weight': tensor([[ 0.0041,  0.0067,  0.0039,  ...,  0.0051, -0.0022,  0.0017],
        [ 0.0002, -0.0076, -0.0031,  ...,  0.0020,  0.0054,  0.0045],
        [ 0.0062, -0.0038, -0.0006,  ...,  0.0023,  0.0042, -0.0071],
        ...,
        [ 0.0046, -0.0036, -0.0068,  ...,  0.0051, -0.0059, -0.0014],
        [-0.0010,  0.0042,  0.0021,  ...,  0.0050,  0.0050, -0.0066],
        [-0.0051, -0.0049, -0.0067,  ..., -0.0050,  0.0054,  0.0069]]), 'model.perceiver.layers.3.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.to_q.weight': tensor([[ 0.0136,  0.0149,  0.0038,  ..., -0.0142,  0.0055,  0.0084],
        [-0.0021, -0.0099,  0.0042,  ..., -0.0032,  0.0104,  0.0074],
        [ 0.0022, -0.0007, -0.0120,  ...,  0.0137,  0.0004,  0.0095],
        ...,
        [ 0.0002, -0.0010, -0.0139,  ...,  0.0018,  0.0087,  0.0051],
        [ 0.0054, -0.0031,  0.0098,  ..., -0.0040,  0.0006, -0.0016],
        [-0.0146, -0.0154,  0.0144,  ..., -0.0055,  0.0149,  0.0133]]), 'model.perceiver.layers.3.0.to_kv.weight': tensor([[-0.0084, -0.0153,  0.0092,  ..., -0.0101,  0.0109,  0.0131],
        [-0.0047,  0.0060, -0.0151,  ..., -0.0004, -0.0119,  0.0149],
        [ 0.0154, -0.0150,  0.0136,  ...,  0.0119,  0.0067,  0.0037],
        ...,
        [-0.0039, -0.0019, -0.0044,  ..., -0.0096, -0.0119, -0.0098],
        [ 0.0113, -0.0130, -0.0047,  ...,  0.0042, -0.0038, -0.0146],
        [ 0.0006,  0.0082,  0.0072,  ..., -0.0127,  0.0010, -0.0089]]), 'model.perceiver.layers.3.0.to_out.weight': tensor([[-0.0017, -0.0069, -0.0022,  ...,  0.0102, -0.0254, -0.0232],
        [-0.0280, -0.0189,  0.0156,  ...,  0.0057, -0.0119, -0.0158],
        [ 0.0215,  0.0429,  0.0080,  ..., -0.0015,  0.0304,  0.0125],
        ...,
        [-0.0385,  0.0047,  0.0045,  ..., -0.0238, -0.0056,  0.0333],
        [ 0.0180, -0.0059,  0.0289,  ...,  0.0067, -0.0396,  0.0040],
        [ 0.0222,  0.0170,  0.0393,  ...,  0.0435,  0.0192, -0.0378]]), 'model.perceiver.layers.3.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.1.1.weight': tensor([[-0.0121,  0.0130, -0.0004,  ..., -0.0083, -0.0124, -0.0081],
        [ 0.0127, -0.0156,  0.0142,  ...,  0.0146, -0.0088, -0.0104],
        [-0.0009,  0.0141,  0.0100,  ...,  0.0122,  0.0018,  0.0097],
        ...,
        [ 0.0055,  0.0100,  0.0040,  ...,  0.0054, -0.0154, -0.0069],
        [-0.0071, -0.0086, -0.0117,  ...,  0.0031, -0.0065, -0.0024],
        [-0.0116,  0.0128, -0.0038,  ..., -0.0027, -0.0092, -0.0119]]), 'model.perceiver.layers.3.1.3.weight': tensor([[-6.4930e-04,  1.3525e-03, -5.7210e-03,  ..., -2.8284e-03,
          4.7265e-03,  5.8436e-03],
        [-9.3297e-04,  7.0548e-03, -5.8330e-03,  ...,  6.7066e-03,
          1.9577e-03, -4.0148e-03],
        [-5.5743e-03,  4.4059e-03,  4.1372e-04,  ...,  1.5304e-03,
          4.4718e-03,  1.7701e-03],
        ...,
        [ 2.2085e-03,  3.4237e-03,  6.1652e-03,  ..., -8.1121e-04,
          1.3833e-03, -6.1790e-03],
        [ 6.8315e-03, -4.3239e-03, -5.4212e-03,  ...,  4.9372e-03,
          6.2887e-03,  2.7110e-04],
        [-2.5682e-03, -5.9206e-03,  5.8745e-03,  ...,  2.9119e-03,
          1.2803e-03,  2.3675e-05]]), 'model.perceiver.layers.4.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.to_q.weight': tensor([[-1.2965e-02,  4.6517e-03, -1.2025e-02,  ..., -6.5546e-03,
          1.4791e-02,  3.5122e-03],
        [-4.6026e-03, -2.6166e-05, -5.7909e-03,  ..., -1.9841e-03,
          1.1345e-02,  8.9583e-03],
        [-1.2528e-02, -1.4561e-02, -7.2201e-03,  ...,  2.6510e-03,
          5.9479e-03,  8.2450e-03],
        ...,
        [ 2.5162e-04,  8.4066e-03, -8.0761e-03,  ..., -6.6903e-03,
         -1.2099e-03,  2.3353e-03],
        [ 9.1250e-04, -1.3302e-02, -9.8282e-03,  ..., -1.7758e-03,
         -7.2781e-03,  1.5410e-02],
        [-1.4486e-02, -4.5816e-03,  1.2280e-02,  ...,  1.5517e-02,
         -1.5047e-02, -4.3668e-04]]), 'model.perceiver.layers.4.0.to_kv.weight': tensor([[ 0.0019, -0.0033, -0.0118,  ..., -0.0035, -0.0024,  0.0118],
        [-0.0151, -0.0129,  0.0073,  ...,  0.0090,  0.0028,  0.0116],
        [-0.0064, -0.0103,  0.0155,  ...,  0.0011,  0.0006,  0.0067],
        ...,
        [ 0.0028,  0.0139, -0.0051,  ...,  0.0052,  0.0061, -0.0059],
        [-0.0008, -0.0110,  0.0118,  ..., -0.0051, -0.0144, -0.0117],
        [ 0.0036,  0.0042, -0.0148,  ...,  0.0012, -0.0112, -0.0048]]), 'model.perceiver.layers.4.0.to_out.weight': tensor([[-0.0206,  0.0178, -0.0248,  ...,  0.0391,  0.0421,  0.0423],
        [-0.0029,  0.0181, -0.0108,  ..., -0.0432, -0.0268, -0.0228],
        [ 0.0140,  0.0355,  0.0197,  ..., -0.0103, -0.0100,  0.0382],
        ...,
        [-0.0207,  0.0271, -0.0331,  ...,  0.0153,  0.0348,  0.0032],
        [ 0.0182, -0.0378,  0.0006,  ..., -0.0424,  0.0072,  0.0303],
        [-0.0213, -0.0029, -0.0405,  ...,  0.0088,  0.0121,  0.0094]]), 'model.perceiver.layers.4.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.1.1.weight': tensor([[ 0.0108,  0.0135,  0.0133,  ..., -0.0038,  0.0054, -0.0049],
        [ 0.0142,  0.0052,  0.0020,  ..., -0.0090, -0.0138, -0.0030],
        [-0.0136,  0.0048,  0.0012,  ..., -0.0037, -0.0106,  0.0148],
        ...,
        [-0.0048, -0.0008, -0.0144,  ..., -0.0054, -0.0079,  0.0005],
        [ 0.0048,  0.0127, -0.0046,  ..., -0.0085,  0.0075, -0.0050],
        [ 0.0094,  0.0135, -0.0081,  ...,  0.0122,  0.0129, -0.0029]]), 'model.perceiver.layers.4.1.3.weight': tensor([[-4.1727e-03,  4.6809e-03, -7.3026e-04,  ..., -5.6049e-03,
         -2.8747e-03, -2.9786e-03],
        [ 1.2112e-03,  5.9014e-03, -7.7832e-04,  ..., -5.5060e-03,
          7.4346e-03,  5.8432e-03],
        [-2.0869e-03, -4.3240e-03, -4.2255e-05,  ...,  1.4724e-03,
          7.2666e-03, -3.8338e-03],
        ...,
        [-6.7587e-03,  3.7082e-03, -6.3032e-03,  ..., -5.0321e-03,
          8.7862e-04, -2.1084e-03],
        [-4.2036e-03, -2.0574e-03,  7.4617e-04,  ...,  3.5713e-03,
         -6.3757e-03, -4.0248e-03],
        [ 2.9537e-04,  5.6361e-03,  5.4085e-03,  ..., -6.2174e-03,
         -6.2441e-03, -6.1675e-03]]), 'model.perceiver.layers.5.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.to_q.weight': tensor([[-0.0055, -0.0023,  0.0050,  ..., -0.0088, -0.0130, -0.0149],
        [ 0.0052, -0.0076,  0.0137,  ...,  0.0115,  0.0043, -0.0116],
        [ 0.0058,  0.0033, -0.0049,  ...,  0.0083,  0.0099, -0.0017],
        ...,
        [ 0.0033, -0.0101, -0.0015,  ...,  0.0089,  0.0152, -0.0013],
        [ 0.0122, -0.0121,  0.0034,  ...,  0.0053, -0.0057, -0.0044],
        [-0.0144, -0.0031, -0.0068,  ...,  0.0122, -0.0047,  0.0049]]), 'model.perceiver.layers.5.0.to_kv.weight': tensor([[ 0.0031,  0.0049,  0.0097,  ...,  0.0108,  0.0044, -0.0125],
        [ 0.0089, -0.0100,  0.0103,  ...,  0.0155,  0.0013,  0.0039],
        [-0.0153,  0.0106,  0.0072,  ..., -0.0006, -0.0025, -0.0001],
        ...,
        [-0.0073,  0.0116, -0.0016,  ..., -0.0135,  0.0088, -0.0037],
        [-0.0037, -0.0015,  0.0014,  ..., -0.0074, -0.0105,  0.0108],
        [ 0.0035, -0.0124, -0.0141,  ..., -0.0156, -0.0046, -0.0097]]), 'model.perceiver.layers.5.0.to_out.weight': tensor([[-0.0354,  0.0263,  0.0184,  ..., -0.0239,  0.0027, -0.0093],
        [ 0.0222, -0.0199, -0.0276,  ..., -0.0106, -0.0409, -0.0165],
        [-0.0007,  0.0427,  0.0296,  ..., -0.0049,  0.0272,  0.0130],
        ...,
        [ 0.0283,  0.0385,  0.0299,  ...,  0.0300, -0.0151,  0.0135],
        [ 0.0333,  0.0335,  0.0336,  ...,  0.0109, -0.0321, -0.0043],
        [ 0.0379,  0.0336, -0.0202,  ..., -0.0058,  0.0026, -0.0247]]), 'model.perceiver.layers.5.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.1.1.weight': tensor([[-0.0047,  0.0014,  0.0014,  ...,  0.0055,  0.0002, -0.0073],
        [ 0.0128, -0.0034,  0.0050,  ..., -0.0036, -0.0076, -0.0125],
        [ 0.0126,  0.0058, -0.0138,  ..., -0.0006,  0.0079,  0.0146],
        ...,
        [ 0.0127,  0.0039,  0.0047,  ...,  0.0016, -0.0093, -0.0097],
        [-0.0070, -0.0107, -0.0128,  ...,  0.0142,  0.0101,  0.0090],
        [-0.0125, -0.0074, -0.0059,  ..., -0.0113,  0.0084, -0.0062]]), 'model.perceiver.layers.5.1.3.weight': tensor([[-4.8000e-03,  7.5507e-03, -5.5058e-04,  ...,  2.2348e-03,
         -1.8482e-03, -5.9647e-05],
        [ 1.7140e-03,  1.1859e-03, -2.6182e-03,  ..., -1.5777e-03,
         -5.9963e-04,  3.1298e-03],
        [-7.7869e-03,  1.0172e-03, -5.8174e-03,  ...,  2.1914e-03,
         -3.7913e-03,  5.5316e-03],
        ...,
        [ 2.8844e-03, -5.9057e-03,  1.0570e-03,  ..., -4.1111e-03,
          5.4406e-03, -4.5309e-03],
        [ 3.4242e-03,  2.9593e-03,  2.8462e-03,  ..., -3.8769e-03,
          5.2546e-03,  3.2420e-03],
        [-2.4404e-03, -7.0739e-03, -2.7338e-03,  ..., -2.6478e-03,
          1.7313e-03, -5.6981e-03]]), 'model.perceiver.norm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.norm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'lm_head.weight': tensor([[-0.0058, -0.0009, -0.0071,  ...,  0.0035, -0.0099,  0.0190],
        [-0.0278,  0.0547, -0.0115,  ..., -0.0232,  0.0147,  0.0332],
        [-0.0140, -0.0099,  0.0201,  ..., -0.0344,  0.0142, -0.0150],
        ...,
        [-0.0243,  0.0031,  0.0008,  ..., -0.0046,  0.0029, -0.0072],
        [ 0.0070,  0.0007,  0.0051,  ..., -0.0131, -0.0103, -0.0041],
        [-0.0041, -0.0077, -0.0308,  ...,  0.0179,  0.0084,  0.0356]],
       dtype=torch.float16)}
[INFO] Medical save done, finish
[INFO] medical_state_dict: {'model.embed_tokens.weight': tensor([[-0.0013,  0.0004, -0.0018,  ...,  0.0004, -0.0038, -0.0033],
        [ 0.0011, -0.0046, -0.0005,  ..., -0.0079, -0.0010,  0.0003],
        [ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
        ...,
        [-0.0052,  0.0041, -0.0056,  ..., -0.0011,  0.0072,  0.0068],
        [ 0.0075, -0.0039,  0.0058,  ...,  0.0447,  0.0135, -0.0091],
        [-0.0026,  0.0215, -0.0237,  ..., -0.0354,  0.0114,  0.0210]],
       dtype=torch.float16), 'model.layers.0.self_attn.q_proj.weight': tensor([[-9.6512e-03, -1.4015e-02, -1.5736e-03,  ...,  2.1338e-05,
          1.3115e-02, -3.8280e-03],
        [ 2.9144e-02,  4.8027e-03,  5.9013e-03,  ..., -1.3435e-02,
         -8.2550e-03,  1.8204e-02],
        [-1.3481e-02,  1.8463e-02, -3.4637e-03,  ...,  6.7596e-03,
          2.8107e-02, -7.3576e-04],
        ...,
        [ 1.1032e-02,  1.4496e-02, -1.0233e-03,  ..., -2.4509e-03,
         -9.9945e-03,  1.9012e-02],
        [ 2.2018e-02,  9.6817e-03,  3.0251e-03,  ..., -2.1957e-02,
         -2.9984e-02, -1.5228e-02],
        [-4.3945e-03, -3.2215e-03,  2.4204e-03,  ...,  1.5717e-02,
          2.7542e-02, -3.5992e-03]], dtype=torch.float16), 'model.layers.0.self_attn.k_proj.weight': tensor([[-1.8356e-02,  4.0359e-03, -1.2512e-03,  ...,  1.7609e-02,
         -8.6746e-03, -1.4610e-02],
        [ 1.5823e-02,  6.5346e-03,  2.6360e-03,  ..., -1.8021e-02,
          1.6815e-02,  2.4765e-02],
        [ 2.4891e-04, -2.5513e-02,  9.2087e-03,  ...,  1.0544e-02,
         -2.4979e-02, -1.9958e-02],
        ...,
        [ 1.5572e-02,  6.2644e-05,  2.2449e-03,  ..., -7.4625e-04,
          1.9274e-03,  5.2757e-03],
        [-1.0864e-02,  2.2339e-02, -8.3771e-03,  ...,  2.7027e-03,
          1.7319e-02, -7.6866e-03],
        [ 5.8746e-03,  5.1308e-04,  6.3248e-03,  ...,  7.2708e-03,
         -1.2901e-02,  6.5727e-03]], dtype=torch.float16), 'model.layers.0.self_attn.v_proj.weight': tensor([[ 0.0007,  0.0044,  0.0010,  ...,  0.0090,  0.0010,  0.0093],
        [-0.0099, -0.0005, -0.0035,  ..., -0.0119,  0.0113,  0.0107],
        [ 0.0048,  0.0068, -0.0029,  ...,  0.0021, -0.0156, -0.0190],
        ...,
        [-0.0073, -0.0050,  0.0162,  ...,  0.0033,  0.0020, -0.0007],
        [-0.0006,  0.0075, -0.0048,  ...,  0.0051,  0.0155,  0.0017],
        [-0.0032,  0.0046,  0.0082,  ..., -0.0016, -0.0035,  0.0023]],
       dtype=torch.float16), 'model.layers.0.self_attn.o_proj.weight': tensor([[ 1.3628e-03, -3.9444e-03,  3.8643e-03,  ...,  2.2564e-03,
          2.7990e-04, -8.9340e-03],
        [-2.4300e-03,  5.6076e-03,  1.1387e-03,  ..., -1.7481e-03,
          2.0924e-03,  5.7678e-03],
        [-3.3474e-03, -7.6914e-04,  2.4796e-03,  ..., -2.0561e-03,
         -6.5956e-03, -8.0681e-04],
        ...,
        [ 4.8943e-03, -1.4791e-03,  7.6332e-03,  ...,  2.2650e-06,
          4.2534e-03,  3.3951e-03],
        [-2.9583e-03, -1.8663e-03, -1.1358e-03,  ...,  5.2490e-03,
         -5.8899e-03, -2.8267e-03],
        [ 4.0221e-04, -1.2932e-03,  3.3665e-03,  ...,  6.5804e-03,
         -4.6806e-03, -5.0964e-03]], dtype=torch.float16), 'model.layers.0.mlp.gate_proj.weight': tensor([[ 0.0081,  0.0134,  0.0292,  ..., -0.0172,  0.0053,  0.0193],
        [-0.0028, -0.0027,  0.0029,  ...,  0.0147, -0.0076,  0.0114],
        [-0.0002, -0.0256,  0.0180,  ..., -0.0189,  0.0257,  0.0206],
        ...,
        [ 0.0058, -0.0258,  0.0025,  ..., -0.0036, -0.0106,  0.0365],
        [ 0.0223,  0.0168, -0.0171,  ..., -0.0017, -0.0030, -0.0196],
        [-0.0070, -0.0135, -0.0268,  ..., -0.0042,  0.0025, -0.0229]],
       dtype=torch.float16), 'model.layers.0.mlp.up_proj.weight': tensor([[-0.0072, -0.0297,  0.0135,  ..., -0.0198, -0.0236,  0.0091],
        [-0.0119, -0.0311,  0.0110,  ...,  0.0178,  0.0034,  0.0087],
        [-0.0066,  0.0157, -0.0102,  ..., -0.0231,  0.0132,  0.0038],
        ...,
        [-0.0121, -0.0005, -0.0019,  ...,  0.0259, -0.0082,  0.0114],
        [-0.0198,  0.0047,  0.0170,  ..., -0.0023, -0.0186,  0.0037],
        [ 0.0142,  0.0268, -0.0009,  ...,  0.0088, -0.0174, -0.0420]],
       dtype=torch.float16), 'model.layers.0.mlp.down_proj.weight': tensor([[ 0.0044, -0.0123,  0.0141,  ..., -0.0181, -0.0041, -0.0016],
        [-0.0006, -0.0026,  0.0135,  ...,  0.0106, -0.0167,  0.0315],
        [ 0.0044,  0.0371,  0.0019,  ..., -0.0117,  0.0212,  0.0207],
        ...,
        [-0.0078, -0.0106,  0.0062,  ...,  0.0204, -0.0163,  0.0254],
        [-0.0202,  0.0401,  0.0176,  ..., -0.0138, -0.0104, -0.0290],
        [ 0.0179, -0.0031, -0.0126,  ...,  0.0003, -0.0050, -0.0296]],
       dtype=torch.float16), 'model.layers.0.input_layernorm.weight': tensor([ 0.0193,  0.0087, -0.0008,  ...,  0.0058,  0.0089,  0.0019],
       dtype=torch.float16), 'model.layers.0.post_attention_layernorm.weight': tensor([0.0530, 0.0537, 0.0498,  ..., 0.0540, 0.0569, 0.0491],
       dtype=torch.float16), 'model.layers.1.self_attn.q_proj.weight': tensor([[-0.0228, -0.0012, -0.0327,  ..., -0.0147, -0.0572,  0.0403],
        [-0.0012, -0.0125,  0.0112,  ..., -0.0081, -0.0516,  0.0322],
        [ 0.0274,  0.0308,  0.0248,  ..., -0.0133, -0.0764,  0.0221],
        ...,
        [-0.0004,  0.0029,  0.0050,  ..., -0.0099, -0.0020, -0.0116],
        [-0.0018, -0.0048, -0.0055,  ...,  0.0103,  0.0032,  0.0117],
        [ 0.0002,  0.0064,  0.0077,  ..., -0.0088,  0.0019, -0.0165]],
       dtype=torch.float16), 'model.layers.1.self_attn.k_proj.weight': tensor([[-0.0254,  0.0089,  0.0425,  ...,  0.0178,  0.0165, -0.0135],
        [-0.0323,  0.0092, -0.0083,  ..., -0.0091,  0.0150, -0.0595],
        [-0.0262,  0.0288, -0.0696,  ...,  0.0352,  0.0172, -0.0609],
        ...,
        [-0.0149,  0.0229,  0.0028,  ...,  0.0081, -0.0048,  0.0070],
        [ 0.0114, -0.0230, -0.0001,  ..., -0.0092,  0.0033, -0.0068],
        [-0.0111,  0.0184,  0.0055,  ...,  0.0007, -0.0071,  0.0058]],
       dtype=torch.float16), 'model.layers.1.self_attn.v_proj.weight': tensor([[ 6.8245e-03, -4.9133e-03,  1.0071e-03,  ..., -4.8561e-03,
         -2.9144e-02, -2.2125e-02],
        [-5.1346e-03,  4.9515e-03, -3.3360e-03,  ...,  2.7618e-03,
          1.1398e-02,  3.1982e-02],
        [ 3.6736e-03, -1.1612e-02,  8.0032e-03,  ..., -2.2590e-05,
         -1.4648e-03, -3.3340e-03],
        ...,
        [-3.6926e-03,  5.3062e-03,  7.3509e-03,  ..., -2.7981e-03,
         -1.4305e-03,  2.2399e-04],
        [-7.8735e-03, -3.1986e-03,  7.9422e-03,  ..., -6.5727e-03,
          8.4534e-03, -5.7817e-06],
        [ 1.0643e-03,  6.4468e-03,  8.0719e-03,  ..., -6.3095e-03,
         -2.6455e-03,  1.0246e-02]], dtype=torch.float16), 'model.layers.1.self_attn.o_proj.weight': tensor([[ 0.0024, -0.0163,  0.0091,  ..., -0.0058, -0.0015, -0.0006],
        [-0.0016, -0.0059, -0.0052,  ...,  0.0035, -0.0019,  0.0037],
        [ 0.0247,  0.0128, -0.0125,  ...,  0.0022, -0.0027,  0.0011],
        ...,
        [ 0.0058,  0.0022,  0.0012,  ..., -0.0011, -0.0004, -0.0001],
        [ 0.0036, -0.0075,  0.0050,  ..., -0.0054,  0.0002,  0.0056],
        [-0.0017, -0.0238,  0.0015,  ..., -0.0021, -0.0055,  0.0007]],
       dtype=torch.float16), 'model.layers.1.mlp.gate_proj.weight': tensor([[ 0.0305, -0.0128,  0.0422,  ..., -0.0312, -0.0152, -0.0100],
        [-0.0312, -0.0045, -0.0312,  ...,  0.0140, -0.0307, -0.0427],
        [-0.0055, -0.0319,  0.0095,  ..., -0.0064, -0.0123, -0.0204],
        ...,
        [-0.0385,  0.0105, -0.0028,  ..., -0.0023,  0.0122,  0.0004],
        [-0.0149, -0.0031, -0.0339,  ...,  0.0217,  0.0198, -0.0084],
        [-0.0266,  0.0121,  0.0041,  ...,  0.0391,  0.0065, -0.0430]],
       dtype=torch.float16), 'model.layers.1.mlp.up_proj.weight': tensor([[-0.0034,  0.0414, -0.0204,  ...,  0.0118,  0.0263, -0.0124],
        [ 0.0071, -0.0067, -0.0129,  ..., -0.0086,  0.0069,  0.0108],
        [ 0.0309, -0.0436,  0.0134,  ...,  0.0177, -0.0427,  0.0297],
        ...,
        [-0.0148, -0.0275,  0.0184,  ...,  0.0293,  0.0069, -0.0238],
        [ 0.0356,  0.0030, -0.0164,  ...,  0.0032, -0.0060, -0.0045],
        [-0.0108, -0.0150, -0.0105,  ..., -0.0249, -0.0061,  0.0173]],
       dtype=torch.float16), 'model.layers.1.mlp.down_proj.weight': tensor([[ 0.0107,  0.0179,  0.0578,  ..., -0.0177,  0.0072, -0.0210],
        [ 0.0088,  0.0063, -0.0363,  ...,  0.0069, -0.0142,  0.0028],
        [-0.0113, -0.0138, -0.0245,  ...,  0.0014, -0.0134,  0.0023],
        ...,
        [-0.0099, -0.0073, -0.0143,  ...,  0.0442, -0.0065,  0.0090],
        [-0.0116,  0.0203,  0.0101,  ..., -0.0278, -0.0228,  0.0261],
        [ 0.0262, -0.0061, -0.0175,  ..., -0.0080, -0.0135,  0.0338]],
       dtype=torch.float16), 'model.layers.1.input_layernorm.weight': tensor([0.1050, 0.0967, 0.0884,  ..., 0.0518, 0.0781, 0.0608],
       dtype=torch.float16), 'model.layers.1.post_attention_layernorm.weight': tensor([0.0986, 0.0991, 0.0957,  ..., 0.1060, 0.1006, 0.1001],
       dtype=torch.float16), 'model.layers.2.self_attn.q_proj.weight': tensor([[-0.0236, -0.0038,  0.0098,  ..., -0.0133, -0.0098, -0.0003],
        [-0.0190,  0.0037, -0.0345,  ..., -0.0344, -0.0162,  0.0232],
        [-0.0165,  0.0366, -0.0252,  ..., -0.0018, -0.0211,  0.0159],
        ...,
        [-0.0526,  0.0145, -0.0261,  ..., -0.0085, -0.0328, -0.0351],
        [ 0.0019, -0.0063,  0.0003,  ..., -0.0023, -0.0186,  0.0160],
        [-0.0048, -0.0168,  0.0231,  ...,  0.0604, -0.0444,  0.0058]],
       dtype=torch.float16), 'model.layers.2.self_attn.k_proj.weight': tensor([[ 0.0004,  0.0156, -0.0085,  ..., -0.0106, -0.0010,  0.0175],
        [ 0.0163, -0.0154, -0.0090,  ...,  0.0110, -0.0093, -0.0075],
        [ 0.0128,  0.0151,  0.0360,  ..., -0.0084,  0.0124,  0.0131],
        ...,
        [ 0.0299,  0.0465, -0.0237,  ...,  0.0386, -0.0369,  0.0006],
        [-0.0072, -0.0126, -0.0009,  ...,  0.0045,  0.0003, -0.0041],
        [ 0.0020, -0.0215, -0.0021,  ..., -0.0809, -0.0249,  0.0965]],
       dtype=torch.float16), 'model.layers.2.self_attn.v_proj.weight': tensor([[-7.3767e-04,  6.2332e-03,  1.5961e-02,  ...,  3.8208e-02,
         -3.6240e-03, -6.9313e-03],
        [ 5.0621e-03,  1.1269e-02, -2.1118e-02,  ..., -7.7972e-03,
          7.8506e-03, -1.4595e-02],
        [-6.8617e-04,  1.8463e-02,  3.3112e-03,  ..., -2.0950e-02,
         -3.0457e-02, -2.9480e-02],
        ...,
        [-5.3465e-05, -2.5360e-02, -2.0248e-02,  ..., -1.0956e-02,
         -9.5272e-04,  3.3970e-03],
        [-3.7140e-02, -7.9775e-04,  1.4175e-02,  ..., -1.0040e-02,
         -6.6071e-03, -1.5135e-03],
        [-1.1009e-02,  1.4809e-02,  4.5662e-03,  ..., -5.1880e-03,
          1.8234e-02, -7.3395e-03]], dtype=torch.float16), 'model.layers.2.self_attn.o_proj.weight': tensor([[ 0.0041,  0.0149,  0.0103,  ...,  0.0196,  0.0020, -0.0260],
        [ 0.0006, -0.0130,  0.0079,  ...,  0.0049, -0.0125, -0.0198],
        [-0.0215,  0.0032, -0.0169,  ..., -0.0224, -0.0103,  0.0078],
        ...,
        [-0.0046, -0.0235,  0.0281,  ..., -0.0049, -0.0220,  0.0198],
        [ 0.0184, -0.0113,  0.0301,  ...,  0.0192, -0.0004, -0.0239],
        [-0.0107,  0.0023,  0.0075,  ..., -0.0129,  0.0050, -0.0142]],
       dtype=torch.float16), 'model.layers.2.mlp.gate_proj.weight': tensor([[ 0.0072,  0.0239, -0.0107,  ..., -0.0090,  0.0302, -0.0034],
        [ 0.0013,  0.0012, -0.0015,  ...,  0.0126, -0.0138, -0.0115],
        [-0.0069, -0.0083,  0.0255,  ..., -0.0112,  0.0158,  0.0069],
        ...,
        [ 0.0342, -0.0119, -0.0193,  ..., -0.0285, -0.0400, -0.0150],
        [-0.0113, -0.0116, -0.0017,  ...,  0.0174, -0.0425,  0.0180],
        [-0.0015,  0.0111,  0.0085,  ..., -0.0133, -0.0261,  0.0048]],
       dtype=torch.float16), 'model.layers.2.mlp.up_proj.weight': tensor([[-0.0008, -0.0006,  0.0139,  ..., -0.0152,  0.0090, -0.0034],
        [ 0.0053, -0.0186, -0.0090,  ...,  0.0056,  0.0114,  0.0062],
        [ 0.0306,  0.0189,  0.0293,  ..., -0.0141, -0.0088,  0.0175],
        ...,
        [-0.0071, -0.0148,  0.0009,  ..., -0.0116, -0.0025,  0.0209],
        [ 0.0155, -0.0129,  0.0144,  ...,  0.0003,  0.0049, -0.0228],
        [-0.0146, -0.0302, -0.0243,  ..., -0.0050,  0.0011, -0.0050]],
       dtype=torch.float16), 'model.layers.2.mlp.down_proj.weight': tensor([[ 0.0146,  0.0174,  0.0375,  ..., -0.0273, -0.0011, -0.0335],
        [ 0.0209, -0.0227, -0.0188,  ...,  0.0180,  0.0023, -0.0226],
        [ 0.0438, -0.0178,  0.0010,  ..., -0.0302,  0.0004, -0.0330],
        ...,
        [-0.0133,  0.0283, -0.0105,  ..., -0.0015, -0.0013, -0.0135],
        [-0.0211,  0.0298,  0.0079,  ...,  0.0158, -0.0182, -0.0113],
        [ 0.0315,  0.0117, -0.0220,  ...,  0.0192, -0.0449, -0.0119]],
       dtype=torch.float16), 'model.layers.2.input_layernorm.weight': tensor([0.1729, 0.1787, 0.1709,  ..., 0.1768, 0.1680, 0.1748],
       dtype=torch.float16), 'model.layers.2.post_attention_layernorm.weight': tensor([0.1338, 0.1377, 0.1367,  ..., 0.1367, 0.1387, 0.1367],
       dtype=torch.float16), 'model.layers.3.self_attn.q_proj.weight': tensor([[ 0.0001,  0.0111,  0.0058,  ...,  0.0241,  0.0127,  0.0220],
        [-0.0121,  0.0172, -0.0149,  ..., -0.0432,  0.0006, -0.0074],
        [ 0.0129,  0.0027, -0.0203,  ...,  0.0116, -0.0187, -0.0406],
        ...,
        [ 0.0717, -0.0696,  0.0428,  ..., -0.0779, -0.0139,  0.0070],
        [-0.0797,  0.0404, -0.0023,  ...,  0.0363,  0.0769,  0.0251],
        [-0.0153, -0.0497,  0.0779,  ..., -0.0225, -0.0032, -0.0130]],
       dtype=torch.float16), 'model.layers.3.self_attn.k_proj.weight': tensor([[ 0.0074, -0.0077, -0.0088,  ..., -0.0140,  0.0067,  0.0404],
        [-0.0116,  0.0102, -0.0252,  ...,  0.0031, -0.0150, -0.0390],
        [ 0.0029, -0.0079,  0.0005,  ...,  0.0074, -0.0090, -0.0374],
        ...,
        [ 0.0884, -0.0848,  0.0065,  ..., -0.0621,  0.0024,  0.0343],
        [-0.0830,  0.0328,  0.0418,  ...,  0.0079,  0.0463, -0.0032],
        [ 0.0020, -0.0524,  0.0955,  ..., -0.0163,  0.0029, -0.0172]],
       dtype=torch.float16), 'model.layers.3.self_attn.v_proj.weight': tensor([[-0.0039,  0.0125, -0.0059,  ..., -0.0148,  0.0063, -0.0150],
        [-0.0113,  0.0269, -0.0179,  ..., -0.0122, -0.0101, -0.0094],
        [ 0.0024, -0.0062,  0.0057,  ..., -0.0406, -0.0087, -0.0281],
        ...,
        [-0.0131, -0.0097, -0.0019,  ...,  0.0023, -0.0041, -0.0064],
        [ 0.0055, -0.0019,  0.0020,  ...,  0.0007, -0.0084,  0.0018],
        [-0.0120, -0.0069,  0.0093,  ..., -0.0012, -0.0018,  0.0084]],
       dtype=torch.float16), 'model.layers.3.self_attn.o_proj.weight': tensor([[-2.7054e-02,  5.7945e-03, -1.2451e-02,  ...,  2.7256e-03,
         -1.1616e-03, -2.2335e-03],
        [ 2.4536e-02, -2.4429e-02, -1.0193e-02,  ...,  6.5651e-03,
         -2.5272e-03, -2.3193e-03],
        [-3.7498e-03, -1.3260e-02,  1.9197e-03,  ...,  2.6493e-03,
          3.3932e-03,  8.3084e-03],
        ...,
        [ 1.1963e-02,  1.3344e-02,  1.3680e-02,  ...,  1.3313e-03,
          7.1793e-03,  9.9335e-03],
        [ 1.7960e-02,  2.6199e-02,  2.9206e-06,  ...,  3.6945e-03,
         -1.1940e-03, -2.8419e-03],
        [ 8.5297e-03, -9.2773e-03,  1.0519e-03,  ..., -6.4993e-04,
          5.8823e-03,  1.0956e-02]], dtype=torch.float16), 'model.layers.3.mlp.gate_proj.weight': tensor([[ 0.0009, -0.0099, -0.0182,  ..., -0.0315,  0.0460,  0.0153],
        [ 0.0189,  0.0017, -0.0123,  ..., -0.0025, -0.0261, -0.0161],
        [-0.0253,  0.0021, -0.0174,  ...,  0.0050, -0.0040, -0.0361],
        ...,
        [-0.0003,  0.0394,  0.0065,  ...,  0.0199, -0.0123, -0.0001],
        [-0.0057,  0.0087, -0.0060,  ...,  0.0003, -0.0041, -0.0112],
        [-0.0025, -0.0155,  0.0031,  ...,  0.0264, -0.0254,  0.0148]],
       dtype=torch.float16), 'model.layers.3.mlp.up_proj.weight': tensor([[-0.0160,  0.0154,  0.0104,  ...,  0.0014,  0.0186, -0.0085],
        [-0.0123, -0.0174,  0.0343,  ...,  0.0175,  0.0141, -0.0052],
        [-0.0005, -0.0031, -0.0144,  ..., -0.0012,  0.0091, -0.0125],
        ...,
        [-0.0042, -0.0016, -0.0006,  ...,  0.0215,  0.0084, -0.0228],
        [ 0.0052, -0.0099, -0.0050,  ...,  0.0113, -0.0249, -0.0080],
        [ 0.0486, -0.0004, -0.0031,  ...,  0.0433,  0.0057,  0.0085]],
       dtype=torch.float16), 'model.layers.3.mlp.down_proj.weight': tensor([[ 0.0014, -0.0079, -0.0008,  ..., -0.0033,  0.0087,  0.0142],
        [ 0.0225,  0.0028,  0.0088,  ..., -0.0140, -0.0148, -0.0148],
        [ 0.0144,  0.0119, -0.0174,  ..., -0.0200, -0.0066,  0.0060],
        ...,
        [ 0.0280, -0.0107, -0.0166,  ...,  0.0040,  0.0193,  0.0221],
        [-0.0217,  0.0099, -0.0106,  ..., -0.0006, -0.0170,  0.0130],
        [ 0.0110, -0.0169, -0.0266,  ...,  0.0033,  0.0121,  0.0063]],
       dtype=torch.float16), 'model.layers.3.input_layernorm.weight': tensor([0.2852, 0.2852, 0.2832,  ..., 0.2812, 0.2910, 0.2969],
       dtype=torch.float16), 'model.layers.3.post_attention_layernorm.weight': tensor([0.1738, 0.1748, 0.1689,  ..., 0.1719, 0.1719, 0.1758],
       dtype=torch.float16), 'model.layers.4.self_attn.q_proj.weight': tensor([[-0.0206, -0.0058,  0.0019,  ..., -0.0113, -0.0038,  0.0106],
        [ 0.0190, -0.0170, -0.0051,  ...,  0.0039, -0.0259, -0.0004],
        [-0.0124, -0.0312,  0.0122,  ..., -0.0027, -0.0195, -0.0239],
        ...,
        [ 0.0246,  0.0004, -0.0039,  ...,  0.0032,  0.0244, -0.0600],
        [-0.0293,  0.0085,  0.0295,  ..., -0.0561,  0.0037,  0.0337],
        [-0.0074, -0.0351,  0.0680,  ...,  0.0638,  0.0376, -0.0406]],
       dtype=torch.float16), 'model.layers.4.self_attn.k_proj.weight': tensor([[-0.0037,  0.0210, -0.0139,  ..., -0.0044,  0.0025, -0.0019],
        [-0.0307, -0.0041, -0.0032,  ..., -0.0014,  0.0142, -0.0028],
        [ 0.0089, -0.0021, -0.0143,  ...,  0.0076,  0.0189,  0.0352],
        ...,
        [-0.0089,  0.1188,  0.0593,  ...,  0.0388, -0.0216, -0.0060],
        [ 0.0320,  0.0533, -0.0162,  ...,  0.0641, -0.0399,  0.0720],
        [ 0.0100,  0.0640,  0.0195,  ..., -0.0011,  0.0424, -0.0209]],
       dtype=torch.float16), 'model.layers.4.self_attn.v_proj.weight': tensor([[-3.6507e-03, -8.4000e-03,  1.2493e-03,  ..., -6.4735e-03,
         -3.6030e-03, -6.0320e-05],
        [-1.4557e-02,  3.6133e-02,  5.1346e-03,  ...,  3.2978e-03,
          1.1721e-03,  2.7237e-03],
        [ 1.0719e-02, -6.2370e-03, -3.4729e-02,  ...,  5.4436e-03,
         -1.3771e-03, -1.8631e-02],
        ...,
        [-3.3283e-03, -8.3771e-03, -2.2263e-02,  ..., -9.6893e-03,
         -1.1740e-03,  3.3360e-03],
        [-2.0599e-03, -1.0277e-02, -1.9855e-03,  ...,  7.9956e-03,
         -1.5678e-03,  4.0550e-03],
        [-2.6131e-04, -1.7914e-02, -3.6087e-03,  ..., -5.3263e-04,
         -5.2681e-03,  1.1940e-02]], dtype=torch.float16), 'model.layers.4.self_attn.o_proj.weight': tensor([[ 0.0270,  0.0083, -0.0050,  ..., -0.0021, -0.0267, -0.0015],
        [ 0.0075, -0.0009, -0.0082,  ...,  0.0017, -0.0215,  0.0036],
        [-0.0045,  0.0041, -0.0073,  ..., -0.0134,  0.0101, -0.0084],
        ...,
        [-0.0148,  0.0272, -0.0037,  ..., -0.0209,  0.0081, -0.0208],
        [ 0.0033, -0.0025, -0.0150,  ..., -0.0094, -0.0004, -0.0059],
        [ 0.0100,  0.0215, -0.0056,  ..., -0.0007,  0.0051,  0.0010]],
       dtype=torch.float16), 'model.layers.4.mlp.gate_proj.weight': tensor([[-0.0053,  0.0065, -0.0110,  ..., -0.0182, -0.0035, -0.0159],
        [-0.0267,  0.0111,  0.0142,  ...,  0.0066,  0.0154, -0.0106],
        [-0.0136, -0.0220, -0.0006,  ...,  0.0055, -0.0028,  0.0260],
        ...,
        [ 0.0008, -0.0025,  0.0095,  ..., -0.0211,  0.0097, -0.0120],
        [-0.0265,  0.0148, -0.0281,  ...,  0.0098,  0.0180, -0.0102],
        [ 0.0017, -0.0143, -0.0135,  ..., -0.0124,  0.0221,  0.0190]],
       dtype=torch.float16), 'model.layers.4.mlp.up_proj.weight': tensor([[-1.6373e-02, -5.6725e-03, -4.0833e-02,  ...,  8.6670e-03,
         -8.2254e-04, -5.4932e-03],
        [-2.2400e-02, -4.0680e-02,  5.3253e-03,  ..., -8.6517e-03,
          9.8953e-03, -2.4872e-02],
        [-1.2989e-03,  2.9587e-02,  7.5042e-05,  ..., -2.8885e-02,
         -1.1322e-02,  8.4839e-03],
        ...,
        [-8.8882e-03, -3.1769e-02, -7.3433e-03,  ...,  1.2138e-02,
         -6.8016e-03,  5.5023e-02],
        [ 1.2787e-02, -1.0330e-02, -1.5060e-02,  ..., -4.2175e-02,
         -1.6281e-02,  9.5596e-03],
        [ 3.7937e-03,  1.3062e-02,  8.8272e-03,  ...,  3.7594e-03,
         -3.4237e-03, -2.4376e-03]], dtype=torch.float16), 'model.layers.4.mlp.down_proj.weight': tensor([[ 2.3834e-02, -4.2458e-03,  2.3529e-02,  ..., -1.9836e-02,
         -8.3983e-05,  2.9861e-02],
        [-5.7335e-03, -4.8859e-02,  4.5746e-02,  ..., -2.4323e-02,
         -2.1210e-02, -7.2365e-03],
        [-2.9135e-04, -2.7969e-02,  1.6556e-02,  ...,  1.1406e-02,
         -2.8000e-03,  2.2263e-02],
        ...,
        [-3.4393e-02, -1.9779e-03, -9.8801e-03,  ...,  2.4658e-02,
          2.1534e-03,  1.5030e-02],
        [-7.8430e-03,  1.8177e-03, -2.0020e-02,  ...,  1.2718e-02,
         -4.1931e-02, -1.1818e-02],
        [ 1.6479e-02, -3.2135e-02, -1.5076e-02,  ..., -3.5000e-03,
         -4.4739e-02, -2.3956e-02]], dtype=torch.float16), 'model.layers.4.input_layernorm.weight': tensor([0.2617, 0.2676, 0.2617,  ..., 0.2578, 0.2656, 0.2734],
       dtype=torch.float16), 'model.layers.4.post_attention_layernorm.weight': tensor([0.1914, 0.1895, 0.1855,  ..., 0.1904, 0.1885, 0.1895],
       dtype=torch.float16), 'model.layers.5.self_attn.q_proj.weight': tensor([[-0.0089, -0.0005, -0.0254,  ..., -0.0074, -0.0164,  0.0120],
        [-0.0202,  0.0197,  0.0401,  ..., -0.0054, -0.0094, -0.0347],
        [ 0.0045,  0.0043, -0.0135,  ...,  0.0205, -0.0172,  0.0105],
        ...,
        [-0.0121,  0.0095, -0.0033,  ...,  0.0542,  0.0104,  0.0356],
        [ 0.0433,  0.0046,  0.0262,  ..., -0.0415, -0.0351, -0.0303],
        [ 0.0103,  0.0194,  0.0370,  ..., -0.0282, -0.0147, -0.0007]],
       dtype=torch.float16), 'model.layers.5.self_attn.k_proj.weight': tensor([[-0.0049,  0.0373,  0.0067,  ...,  0.0198, -0.0056, -0.0016],
        [ 0.0006,  0.0027, -0.0324,  ...,  0.0231, -0.0123,  0.0318],
        [-0.0116, -0.0233,  0.0013,  ...,  0.0026, -0.0059,  0.0032],
        ...,
        [ 0.0031, -0.0016, -0.0228,  ...,  0.0397,  0.0098, -0.0320],
        [ 0.0524,  0.0166, -0.0242,  ..., -0.0012, -0.0159, -0.0361],
        [-0.0242, -0.0217,  0.0421,  ..., -0.0155, -0.0347,  0.0102]],
       dtype=torch.float16), 'model.layers.5.self_attn.v_proj.weight': tensor([[-3.0975e-02,  6.6643e-03,  9.8114e-03,  ...,  2.2919e-02,
          7.3671e-05,  2.3392e-02],
        [ 3.9635e-03,  1.0124e-02, -1.8448e-02,  ..., -1.1353e-02,
          3.7670e-03, -1.3893e-02],
        [ 2.2354e-02,  2.4128e-03, -2.9063e-04,  ..., -2.4063e-02,
          2.8976e-02,  1.1208e-02],
        ...,
        [ 2.0477e-02,  1.1581e-02,  1.0353e-02,  ...,  3.7048e-02,
         -5.7449e-03,  1.1454e-03],
        [-5.3596e-03,  3.0289e-03, -4.7684e-03,  ...,  9.9945e-04,
         -9.2010e-03,  8.7404e-04],
        [-1.2375e-02, -6.2561e-03,  2.1561e-02,  ..., -9.5673e-03,
         -9.2545e-03, -1.5900e-02]], dtype=torch.float16), 'model.layers.5.self_attn.o_proj.weight': tensor([[-0.0155, -0.0091,  0.0050,  ..., -0.0181, -0.0074,  0.0271],
        [ 0.0017,  0.0016, -0.0094,  ..., -0.0182,  0.0043,  0.0034],
        [-0.0014, -0.0026,  0.0131,  ...,  0.0181,  0.0119,  0.0234],
        ...,
        [ 0.0181,  0.0066, -0.0060,  ...,  0.0162,  0.0306, -0.0247],
        [-0.0016,  0.0017, -0.0038,  ..., -0.0184, -0.0139, -0.0013],
        [ 0.0051,  0.0035, -0.0148,  ..., -0.0011, -0.0060, -0.0158]],
       dtype=torch.float16), 'model.layers.5.mlp.gate_proj.weight': tensor([[-0.0002, -0.0082, -0.0302,  ...,  0.0003, -0.0062, -0.0114],
        [ 0.0216, -0.0073, -0.0212,  ...,  0.0374, -0.0015,  0.0022],
        [ 0.0123,  0.0039, -0.0196,  ...,  0.0148,  0.0164, -0.0348],
        ...,
        [ 0.0065,  0.0096,  0.0416,  ..., -0.0671,  0.0157, -0.0199],
        [-0.0280,  0.0043,  0.0038,  ...,  0.0014,  0.0170, -0.0017],
        [ 0.0282, -0.0299, -0.0141,  ..., -0.0040, -0.0043, -0.0409]],
       dtype=torch.float16), 'model.layers.5.mlp.up_proj.weight': tensor([[-0.0063, -0.0135, -0.0069,  ..., -0.0147,  0.0037, -0.0168],
        [-0.0320, -0.0062,  0.0009,  ...,  0.0124,  0.0182,  0.0228],
        [-0.0019,  0.0090,  0.0094,  ...,  0.0040,  0.0080,  0.0185],
        ...,
        [ 0.0077,  0.0239, -0.0076,  ..., -0.0109,  0.0145,  0.0252],
        [ 0.0447, -0.0130, -0.0292,  ..., -0.0080, -0.0179,  0.0240],
        [ 0.0085,  0.0172,  0.0130,  ..., -0.0103, -0.0041, -0.0160]],
       dtype=torch.float16), 'model.layers.5.mlp.down_proj.weight': tensor([[-0.0074, -0.0270, -0.0031,  ...,  0.0008,  0.0067,  0.0141],
        [-0.0113,  0.0156,  0.0281,  ...,  0.0215,  0.0064, -0.0341],
        [ 0.0131,  0.0207,  0.0143,  ..., -0.0241, -0.0463,  0.0110],
        ...,
        [ 0.0110, -0.0240, -0.0051,  ...,  0.0063, -0.0257, -0.0186],
        [-0.0034, -0.0391,  0.0152,  ...,  0.0161,  0.0156, -0.0515],
        [ 0.0212,  0.0142, -0.0118,  ...,  0.0309,  0.0092, -0.0177]],
       dtype=torch.float16), 'model.layers.5.input_layernorm.weight': tensor([0.2617, 0.2695, 0.2637,  ..., 0.2500, 0.2695, 0.2676],
       dtype=torch.float16), 'model.layers.5.post_attention_layernorm.weight': tensor([0.2090, 0.1953, 0.1934,  ..., 0.2051, 0.2021, 0.2051],
       dtype=torch.float16), 'model.layers.6.self_attn.q_proj.weight': tensor([[-9.7351e-03, -1.1505e-02,  6.6071e-03,  ..., -3.3630e-02,
         -6.4468e-03, -4.9515e-03],
        [ 4.4250e-03, -6.5613e-03,  5.6343e-03,  ...,  1.4587e-02,
          3.5286e-03, -3.1464e-02],
        [-1.7654e-02,  2.4216e-02, -3.8513e-02,  ...,  3.0502e-02,
         -4.8431e-02, -3.2272e-03],
        ...,
        [ 1.2878e-02,  9.0103e-03, -3.7628e-02,  ...,  2.3987e-02,
          2.7657e-03,  1.5497e-03],
        [ 3.5614e-02,  3.2532e-02,  5.3329e-03,  ..., -9.7885e-03,
         -9.6497e-02, -2.0844e-02],
        [-6.3538e-02, -5.3558e-02, -4.8697e-05,  ...,  1.7288e-02,
          5.1155e-03,  8.5220e-03]], dtype=torch.float16), 'model.layers.6.self_attn.k_proj.weight': tensor([[ 0.0139, -0.0106,  0.0204,  ..., -0.0071,  0.0222,  0.0589],
        [-0.0198, -0.0036,  0.0422,  ...,  0.0071, -0.0126,  0.0158],
        [-0.0102, -0.0131, -0.0068,  ..., -0.0006, -0.0307, -0.0107],
        ...,
        [ 0.0214, -0.0376, -0.0183,  ...,  0.0607, -0.0023, -0.0482],
        [-0.0199,  0.0045, -0.0262,  ..., -0.0461, -0.0408,  0.0156],
        [-0.0544, -0.0241, -0.0399,  ...,  0.0161, -0.0420, -0.0188]],
       dtype=torch.float16), 'model.layers.6.self_attn.v_proj.weight': tensor([[ 0.0140,  0.0336,  0.0101,  ...,  0.0127, -0.0017,  0.0078],
        [ 0.0381, -0.0063, -0.0095,  ...,  0.0046, -0.0005,  0.0038],
        [-0.0079, -0.0024,  0.0124,  ...,  0.0101,  0.0240,  0.0046],
        ...,
        [-0.0221, -0.0061,  0.0052,  ...,  0.0010, -0.0165,  0.0085],
        [-0.0243, -0.0088, -0.0003,  ..., -0.0012, -0.0083,  0.0198],
        [ 0.0311,  0.0049,  0.0161,  ..., -0.0222,  0.0005, -0.0030]],
       dtype=torch.float16), 'model.layers.6.self_attn.o_proj.weight': tensor([[ 0.0112, -0.0127, -0.0365,  ..., -0.0135,  0.0086,  0.0113],
        [-0.0260,  0.0067, -0.0001,  ..., -0.0224,  0.0014, -0.0022],
        [ 0.0019, -0.0115, -0.0042,  ...,  0.0106,  0.0079,  0.0094],
        ...,
        [-0.0053, -0.0143, -0.0063,  ...,  0.0074, -0.0062,  0.0256],
        [-0.0204,  0.0092, -0.0014,  ..., -0.0024,  0.0081, -0.0214],
        [-0.0201, -0.0129,  0.0079,  ..., -0.0237,  0.0066,  0.0064]],
       dtype=torch.float16), 'model.layers.6.mlp.gate_proj.weight': tensor([[ 0.0222,  0.0260, -0.0189,  ..., -0.0039, -0.0074, -0.0042],
        [ 0.0321,  0.0016, -0.0231,  ...,  0.0066,  0.0205,  0.0123],
        [-0.0146,  0.0217, -0.0156,  ..., -0.0187,  0.0011,  0.0088],
        ...,
        [ 0.0056, -0.0261,  0.0048,  ...,  0.0091, -0.0184, -0.0066],
        [ 0.0083,  0.0047, -0.0169,  ..., -0.0235, -0.0025, -0.0016],
        [-0.0396, -0.0513,  0.0267,  ..., -0.0413, -0.0027,  0.0164]],
       dtype=torch.float16), 'model.layers.6.mlp.up_proj.weight': tensor([[-0.0147, -0.0145, -0.0228,  ...,  0.0067, -0.0053, -0.0105],
        [ 0.0071, -0.0485,  0.0392,  ...,  0.0123,  0.0003, -0.0055],
        [-0.0220, -0.0162, -0.0241,  ...,  0.0055,  0.0135,  0.0216],
        ...,
        [-0.0267,  0.0002,  0.0167,  ...,  0.0149, -0.0019,  0.0385],
        [ 0.0244,  0.0173, -0.0063,  ..., -0.0283,  0.0101,  0.0017],
        [-0.0249,  0.0287, -0.0220,  ...,  0.0081, -0.0178, -0.0498]],
       dtype=torch.float16), 'model.layers.6.mlp.down_proj.weight': tensor([[-0.0122,  0.0100, -0.0043,  ...,  0.0013,  0.0143,  0.0160],
        [-0.0081, -0.0157,  0.0045,  ..., -0.0036, -0.0266, -0.0125],
        [ 0.0030,  0.0159, -0.0086,  ...,  0.0244,  0.0240,  0.0227],
        ...,
        [ 0.0110, -0.0024,  0.0207,  ...,  0.0316, -0.0336, -0.0099],
        [ 0.0216, -0.0065,  0.0070,  ...,  0.0098, -0.0135, -0.0126],
        [ 0.0152, -0.0165, -0.0085,  ...,  0.0319, -0.0050,  0.0079]],
       dtype=torch.float16), 'model.layers.6.input_layernorm.weight': tensor([0.3223, 0.3613, 0.3242,  ..., 0.3145, 0.3359, 0.3223],
       dtype=torch.float16), 'model.layers.6.post_attention_layernorm.weight': tensor([0.2217, 0.2129, 0.2090,  ..., 0.2227, 0.2168, 0.2178],
       dtype=torch.float16), 'model.layers.7.self_attn.q_proj.weight': tensor([[-6.2637e-03, -1.0843e-03, -8.1658e-06,  ..., -3.4428e-03,
         -2.0752e-02, -6.3477e-03],
        [-1.0460e-02,  1.4365e-04, -1.0338e-03,  ...,  1.2947e-02,
         -3.6564e-03, -1.6739e-02],
        [ 5.0201e-03,  6.6719e-03, -3.1158e-02,  ..., -2.0416e-02,
         -7.5684e-03,  9.1553e-03],
        ...,
        [-1.5259e-03, -3.3752e-02, -2.5040e-02,  ..., -1.2718e-02,
          3.4180e-02,  3.5553e-02],
        [ 1.3344e-02,  5.2917e-02, -4.0039e-02,  ..., -1.1269e-02,
         -6.7383e-02, -5.6915e-02],
        [ 7.9102e-02, -2.4200e-02, -1.8158e-02,  ...,  8.2947e-02,
          3.1113e-02, -4.3716e-03]], dtype=torch.float16), 'model.layers.7.self_attn.k_proj.weight': tensor([[ 0.0032, -0.0077, -0.0123,  ...,  0.0064,  0.0024, -0.0099],
        [-0.0070, -0.0178,  0.0048,  ..., -0.0072,  0.0043,  0.0185],
        [-0.0024, -0.0103,  0.0107,  ..., -0.0082, -0.0065, -0.0179],
        ...,
        [ 0.0429,  0.0077,  0.0243,  ...,  0.0351,  0.0396,  0.0282],
        [ 0.0400,  0.0500, -0.0002,  ..., -0.0307, -0.0344, -0.0016],
        [ 0.0403,  0.0058,  0.0104,  ..., -0.0012,  0.0019, -0.0272]],
       dtype=torch.float16), 'model.layers.7.self_attn.v_proj.weight': tensor([[-1.4038e-02,  5.2605e-03,  1.2993e-02,  ...,  2.8549e-02,
          4.2191e-03, -1.3847e-02],
        [ 2.6672e-02, -2.6993e-02,  4.3640e-03,  ...,  2.0035e-02,
         -1.8890e-02, -1.5915e-02],
        [-6.8970e-03, -1.0094e-02, -3.4523e-03,  ..., -1.8097e-02,
          1.1665e-02, -7.9453e-05],
        ...,
        [-1.3485e-03, -3.8300e-02,  2.7924e-03,  ...,  5.7297e-03,
         -6.9427e-03, -4.0016e-03],
        [-3.7872e-02,  1.9394e-02, -2.7618e-02,  ..., -1.8707e-02,
          1.0628e-02, -1.9252e-04],
        [-7.4272e-03,  2.6951e-03, -8.4991e-03,  ...,  2.0401e-02,
          7.3357e-03,  1.1787e-02]], dtype=torch.float16), 'model.layers.7.self_attn.o_proj.weight': tensor([[ 0.0116, -0.0154,  0.0014,  ...,  0.0091, -0.0194,  0.0053],
        [-0.0066,  0.0281,  0.0115,  ..., -0.0417, -0.0176, -0.0100],
        [ 0.0047, -0.0011, -0.0201,  ..., -0.0096, -0.0059, -0.0107],
        ...,
        [-0.0163, -0.0252, -0.0036,  ...,  0.0259, -0.0186,  0.0010],
        [-0.0226,  0.0085,  0.0167,  ...,  0.0080, -0.0130,  0.0153],
        [ 0.0028, -0.0002,  0.0005,  ...,  0.0060, -0.0161,  0.0039]],
       dtype=torch.float16), 'model.layers.7.mlp.gate_proj.weight': tensor([[ 7.7896e-03,  4.7340e-03, -5.0850e-03,  ..., -4.3983e-03,
         -3.3386e-02, -7.2746e-03],
        [-3.1647e-02,  1.0490e-02, -8.5449e-03,  ..., -4.9400e-03,
         -3.8891e-03,  2.0676e-03],
        [ 1.7075e-02, -3.0640e-02, -8.4043e-06,  ...,  2.5543e-02,
         -2.7069e-02,  3.4237e-03],
        ...,
        [ 1.6441e-03,  2.0504e-03, -1.4145e-02,  ..., -2.0462e-02,
          4.6463e-03, -2.1713e-02],
        [ 2.6989e-03,  1.8036e-02,  1.2131e-02,  ..., -4.7798e-03,
          6.1493e-03, -3.0258e-02],
        [ 1.9714e-02, -1.6556e-02, -1.0773e-02,  ...,  1.7761e-02,
          1.8799e-02, -6.9962e-03]], dtype=torch.float16), 'model.layers.7.mlp.up_proj.weight': tensor([[ 0.0250,  0.0014, -0.0038,  ...,  0.0224, -0.0396,  0.0026],
        [-0.0110, -0.0190,  0.0299,  ...,  0.0095, -0.0108,  0.0154],
        [ 0.0259, -0.0214,  0.0107,  ..., -0.0126,  0.0181, -0.0352],
        ...,
        [-0.0019, -0.0023, -0.0150,  ..., -0.0095, -0.0177,  0.0024],
        [ 0.0003,  0.0084,  0.0167,  ..., -0.0071,  0.0215, -0.0067],
        [-0.0245, -0.0151,  0.0063,  ...,  0.0170,  0.0119,  0.0050]],
       dtype=torch.float16), 'model.layers.7.mlp.down_proj.weight': tensor([[-0.0079, -0.0069,  0.0050,  ..., -0.0115, -0.0060, -0.0211],
        [-0.0095, -0.0072,  0.0217,  ..., -0.0125,  0.0093,  0.0047],
        [ 0.0106,  0.0077,  0.0231,  ..., -0.0157, -0.0048, -0.0210],
        ...,
        [-0.0100,  0.0002, -0.0191,  ...,  0.0123,  0.0022, -0.0257],
        [ 0.0428, -0.0037,  0.0073,  ..., -0.0168,  0.0043, -0.0133],
        [ 0.0117,  0.0195, -0.0333,  ...,  0.0041, -0.0196, -0.0012]],
       dtype=torch.float16), 'model.layers.7.input_layernorm.weight': tensor([0.3242, 0.3652, 0.3340,  ..., 0.3203, 0.3574, 0.3320],
       dtype=torch.float16), 'model.layers.7.post_attention_layernorm.weight': tensor([0.2383, 0.2197, 0.2236,  ..., 0.2314, 0.2324, 0.2314],
       dtype=torch.float16), 'model.layers.8.self_attn.q_proj.weight': tensor([[-0.0004, -0.0152, -0.0297,  ..., -0.0065,  0.0065, -0.0091],
        [-0.0125, -0.0141, -0.0328,  ...,  0.0038, -0.0112,  0.0025],
        [-0.0400, -0.0028, -0.0129,  ..., -0.0023,  0.0260, -0.0321],
        ...,
        [-0.0062,  0.0861,  0.0443,  ..., -0.0247, -0.0285, -0.0468],
        [ 0.0012, -0.0596, -0.0192,  ...,  0.0352,  0.0269, -0.0008],
        [-0.0648, -0.0531, -0.0116,  ..., -0.0541,  0.0303, -0.0170]],
       dtype=torch.float16), 'model.layers.8.self_attn.k_proj.weight': tensor([[-0.0032, -0.0058, -0.0180,  ..., -0.0109,  0.0052,  0.0049],
        [-0.0125,  0.0011, -0.0050,  ...,  0.0228, -0.0019,  0.0143],
        [-0.0167,  0.0023,  0.0027,  ...,  0.0063, -0.0082, -0.0249],
        ...,
        [ 0.0031, -0.0395, -0.0067,  ..., -0.0295, -0.0149,  0.0230],
        [ 0.0078,  0.0294,  0.0184,  ..., -0.0301,  0.0431, -0.0562],
        [ 0.0190, -0.0026, -0.0326,  ...,  0.0140,  0.0077, -0.0147]],
       dtype=torch.float16), 'model.layers.8.self_attn.v_proj.weight': tensor([[-0.0287, -0.0166,  0.0045,  ..., -0.0193, -0.0085, -0.0096],
        [-0.0234, -0.0132,  0.0059,  ...,  0.0352,  0.0096,  0.0248],
        [-0.0082,  0.0140,  0.0135,  ..., -0.0079,  0.0031, -0.0204],
        ...,
        [ 0.0319, -0.0149,  0.0065,  ...,  0.0218, -0.0201,  0.0271],
        [ 0.0327, -0.0165,  0.0041,  ...,  0.0074, -0.0036,  0.0023],
        [ 0.0126, -0.0004, -0.0005,  ..., -0.0017,  0.0009, -0.0126]],
       dtype=torch.float16), 'model.layers.8.self_attn.o_proj.weight': tensor([[ 0.0177,  0.0157, -0.0148,  ..., -0.0109,  0.0026,  0.0176],
        [ 0.0054,  0.0004, -0.0322,  ..., -0.0121, -0.0108, -0.0186],
        [ 0.0025,  0.0138, -0.0094,  ..., -0.0011,  0.0121,  0.0166],
        ...,
        [-0.0150,  0.0233, -0.0010,  ...,  0.0010, -0.0001, -0.0027],
        [ 0.0086,  0.0015, -0.0089,  ...,  0.0043,  0.0054, -0.0251],
        [-0.0232, -0.0003, -0.0096,  ...,  0.0193, -0.0100,  0.0087]],
       dtype=torch.float16), 'model.layers.8.mlp.gate_proj.weight': tensor([[ 0.0158, -0.0021, -0.0490,  ...,  0.0059, -0.0245, -0.0163],
        [-0.0002, -0.0475,  0.0061,  ..., -0.0033, -0.0370,  0.0276],
        [ 0.0212,  0.0191,  0.0176,  ...,  0.0272,  0.0241, -0.0056],
        ...,
        [-0.0111,  0.0015,  0.0134,  ...,  0.0221,  0.0168,  0.0057],
        [-0.0146,  0.0039,  0.0056,  ..., -0.0016, -0.0165,  0.0145],
        [-0.0243,  0.0096, -0.0066,  ..., -0.0134,  0.0060,  0.0033]],
       dtype=torch.float16), 'model.layers.8.mlp.up_proj.weight': tensor([[-0.0055,  0.0251, -0.0157,  ...,  0.0298,  0.0039, -0.0158],
        [-0.0517,  0.0134, -0.0384,  ...,  0.0145, -0.0113, -0.0159],
        [ 0.0176, -0.0004,  0.0102,  ..., -0.0102, -0.0179,  0.0334],
        ...,
        [-0.0138,  0.0403, -0.0309,  ...,  0.0130,  0.0027,  0.0163],
        [ 0.0054, -0.0047, -0.0058,  ..., -0.0160,  0.0193, -0.0173],
        [-0.0224,  0.0174, -0.0155,  ..., -0.0185, -0.0012, -0.0002]],
       dtype=torch.float16), 'model.layers.8.mlp.down_proj.weight': tensor([[-0.0099, -0.0094,  0.0129,  ...,  0.0072,  0.0198, -0.0290],
        [ 0.0178,  0.0132, -0.0227,  ..., -0.0072,  0.0143, -0.0171],
        [ 0.0061, -0.0186, -0.0251,  ..., -0.0091, -0.0019,  0.0038],
        ...,
        [ 0.0090, -0.0205, -0.0343,  ...,  0.0038,  0.0098, -0.0160],
        [ 0.0096,  0.0107, -0.0036,  ..., -0.0060, -0.0068, -0.0226],
        [-0.0031,  0.0103,  0.0024,  ...,  0.0047,  0.0011,  0.0048]],
       dtype=torch.float16), 'model.layers.8.input_layernorm.weight': tensor([0.3301, 0.3477, 0.3320,  ..., 0.3203, 0.3398, 0.3242],
       dtype=torch.float16), 'model.layers.8.post_attention_layernorm.weight': tensor([0.2422, 0.2314, 0.2236,  ..., 0.2363, 0.2324, 0.2305],
       dtype=torch.float16), 'model.layers.9.self_attn.q_proj.weight': tensor([[-0.0147,  0.0026,  0.0210,  ..., -0.0103, -0.0100, -0.0244],
        [-0.0023, -0.0385,  0.0208,  ..., -0.0013, -0.0039,  0.0068],
        [ 0.0012, -0.0021, -0.0153,  ..., -0.0283, -0.0279, -0.0179],
        ...,
        [-0.0006, -0.0509,  0.0130,  ...,  0.0190,  0.0121, -0.0163],
        [ 0.0161, -0.0186,  0.0037,  ...,  0.0068,  0.0028,  0.0125],
        [-0.0003,  0.0516,  0.0195,  ..., -0.0563,  0.0534, -0.0034]],
       dtype=torch.float16), 'model.layers.9.self_attn.k_proj.weight': tensor([[-0.0307,  0.0100, -0.0252,  ..., -0.0017, -0.0205, -0.0061],
        [-0.0069,  0.0352,  0.0098,  ..., -0.0149,  0.0085,  0.0003],
        [-0.0164, -0.0064,  0.0345,  ...,  0.0036, -0.0246, -0.0038],
        ...,
        [ 0.0229, -0.0136, -0.0035,  ..., -0.0085,  0.0241,  0.0240],
        [ 0.0319,  0.0002,  0.0217,  ...,  0.0495, -0.0169,  0.0517],
        [ 0.0084, -0.0259,  0.0257,  ...,  0.0061,  0.0235, -0.0248]],
       dtype=torch.float16), 'model.layers.9.self_attn.v_proj.weight': tensor([[-0.0064,  0.0087,  0.0034,  ...,  0.0043, -0.0216, -0.0148],
        [-0.0142, -0.0147, -0.0031,  ...,  0.0340, -0.0037, -0.0044],
        [ 0.0071, -0.0220,  0.0211,  ..., -0.0274,  0.0032, -0.0137],
        ...,
        [-0.0094, -0.0083,  0.0037,  ...,  0.0052, -0.0218, -0.0055],
        [-0.0172, -0.0003, -0.0087,  ..., -0.0159,  0.0021, -0.0135],
        [ 0.0245,  0.0242, -0.0037,  ..., -0.0092, -0.0047, -0.0060]],
       dtype=torch.float16), 'model.layers.9.self_attn.o_proj.weight': tensor([[ 0.0102,  0.0094,  0.0113,  ..., -0.0143,  0.0007, -0.0113],
        [-0.0017, -0.0193, -0.0068,  ..., -0.0033,  0.0041,  0.0140],
        [-0.0407, -0.0316,  0.0091,  ...,  0.0292,  0.0020,  0.0106],
        ...,
        [ 0.0148, -0.0133,  0.0091,  ...,  0.0057,  0.0059, -0.0098],
        [ 0.0072,  0.0159,  0.0002,  ...,  0.0084,  0.0001,  0.0006],
        [ 0.0189,  0.0456, -0.0234,  ..., -0.0009,  0.0104,  0.0045]],
       dtype=torch.float16), 'model.layers.9.mlp.gate_proj.weight': tensor([[-0.0097,  0.0258,  0.0002,  ..., -0.0271, -0.0084,  0.0018],
        [-0.0202,  0.0319,  0.0322,  ...,  0.0281,  0.0377,  0.0024],
        [ 0.0390,  0.0285, -0.0269,  ..., -0.0217,  0.0120,  0.0011],
        ...,
        [-0.0204, -0.0079, -0.0243,  ...,  0.0019, -0.0409,  0.0066],
        [-0.0061, -0.0243,  0.0275,  ..., -0.0112,  0.0039,  0.0113],
        [ 0.0146, -0.0229, -0.0039,  ...,  0.0122, -0.0083,  0.0163]],
       dtype=torch.float16), 'model.layers.9.mlp.up_proj.weight': tensor([[-0.0143,  0.0186,  0.0150,  ..., -0.0016, -0.0087,  0.0038],
        [ 0.0086, -0.0010,  0.0079,  ...,  0.0153,  0.0204, -0.0192],
        [-0.0182, -0.0051, -0.0223,  ..., -0.0026, -0.0114,  0.0033],
        ...,
        [ 0.0029,  0.0126, -0.0075,  ..., -0.0150, -0.0307, -0.0130],
        [ 0.0031,  0.0218, -0.0348,  ..., -0.0351, -0.0096, -0.0163],
        [ 0.0102, -0.0337, -0.0058,  ..., -0.0190,  0.0217, -0.0074]],
       dtype=torch.float16), 'model.layers.9.mlp.down_proj.weight': tensor([[-0.0030,  0.0313, -0.0411,  ...,  0.0004, -0.0109,  0.0136],
        [ 0.0216, -0.0283, -0.0173,  ..., -0.0057, -0.0223, -0.0278],
        [-0.0026, -0.0015,  0.0022,  ..., -0.0155,  0.0007, -0.0026],
        ...,
        [-0.0101,  0.0194,  0.0052,  ..., -0.0095, -0.0285,  0.0141],
        [-0.0309,  0.0034,  0.0155,  ..., -0.0204, -0.0034, -0.0333],
        [ 0.0165,  0.0171,  0.0078,  ...,  0.0404,  0.0161,  0.0167]],
       dtype=torch.float16), 'model.layers.9.input_layernorm.weight': tensor([0.3535, 0.3633, 0.3281,  ..., 0.3477, 0.3477, 0.3438],
       dtype=torch.float16), 'model.layers.9.post_attention_layernorm.weight': tensor([0.2490, 0.2334, 0.2285,  ..., 0.2451, 0.2422, 0.2383],
       dtype=torch.float16), 'model.layers.10.self_attn.q_proj.weight': tensor([[-3.6449e-03,  3.8357e-03,  2.0087e-05,  ..., -2.7161e-03,
         -6.6376e-03, -1.4206e-02],
        [-9.7427e-03, -4.9667e-03,  2.0599e-02,  ..., -1.9287e-02,
          6.4575e-02, -3.7270e-03],
        [-1.3718e-02, -1.5106e-02,  2.1040e-04,  ...,  3.4210e-02,
         -9.4452e-03, -1.4389e-02],
        ...,
        [ 3.2104e-02,  6.3049e-02, -1.7929e-02,  ...,  3.7445e-02,
          3.3508e-02, -9.3842e-03],
        [-6.6040e-02,  5.6519e-02, -2.7695e-03,  ..., -6.0577e-02,
         -5.7068e-03, -3.6221e-03],
        [-4.9713e-02, -2.1591e-02, -7.7477e-03,  ..., -1.2627e-02,
         -3.6346e-02, -9.3536e-03]], dtype=torch.float16), 'model.layers.10.self_attn.k_proj.weight': tensor([[-0.0320,  0.0131, -0.0093,  ..., -0.0153,  0.0091, -0.0001],
        [-0.0056,  0.0082, -0.0056,  ..., -0.0057, -0.0101,  0.0133],
        [-0.0008, -0.0022,  0.0067,  ..., -0.0274,  0.0042,  0.0012],
        ...,
        [-0.0464, -0.0599,  0.0127,  ...,  0.0291, -0.0853,  0.0117],
        [-0.0345, -0.0131,  0.0234,  ..., -0.0141, -0.0415, -0.0148],
        [-0.0192,  0.0225, -0.0224,  ...,  0.0083,  0.0425, -0.0002]],
       dtype=torch.float16), 'model.layers.10.self_attn.v_proj.weight': tensor([[-0.0387,  0.0081, -0.0087,  ...,  0.0097,  0.0140,  0.0083],
        [-0.0083,  0.0136,  0.0120,  ..., -0.0067, -0.0419,  0.0195],
        [ 0.0170, -0.0150,  0.0130,  ...,  0.0145,  0.0079, -0.0095],
        ...,
        [ 0.0214,  0.0277,  0.0017,  ...,  0.0253,  0.0023, -0.0228],
        [-0.0040,  0.0057, -0.0005,  ...,  0.0020,  0.0113, -0.0018],
        [ 0.0172,  0.0061, -0.0238,  ..., -0.0072, -0.0071,  0.0242]],
       dtype=torch.float16), 'model.layers.10.self_attn.o_proj.weight': tensor([[-0.0057,  0.0007, -0.0348,  ...,  0.0022,  0.0056,  0.0074],
        [ 0.0006, -0.0118,  0.0126,  ...,  0.0058,  0.0132,  0.0075],
        [ 0.0153, -0.0353, -0.0162,  ...,  0.0007, -0.0036, -0.0031],
        ...,
        [-0.0021,  0.0080, -0.0197,  ..., -0.0031, -0.0003,  0.0199],
        [ 0.0090, -0.0164, -0.0207,  ...,  0.0118,  0.0087,  0.0109],
        [ 0.0075, -0.0081, -0.0278,  ...,  0.0101, -0.0039,  0.0009]],
       dtype=torch.float16), 'model.layers.10.mlp.gate_proj.weight': tensor([[-0.0255, -0.0464, -0.0296,  ...,  0.0059, -0.0014, -0.0041],
        [-0.0152, -0.0224, -0.0173,  ...,  0.0032,  0.0152,  0.0143],
        [-0.0210, -0.0214,  0.0097,  ...,  0.0347, -0.0098,  0.0017],
        ...,
        [-0.0465, -0.0077,  0.0100,  ...,  0.0039, -0.0303,  0.0208],
        [ 0.0046,  0.0114,  0.0203,  ...,  0.0042, -0.0112, -0.0007],
        [-0.0159, -0.0042, -0.0147,  ..., -0.0145,  0.0072, -0.0121]],
       dtype=torch.float16), 'model.layers.10.mlp.up_proj.weight': tensor([[-0.0320, -0.0040, -0.0427,  ...,  0.0109, -0.0067, -0.0190],
        [-0.0074,  0.0061,  0.0065,  ...,  0.0190,  0.0319, -0.0167],
        [-0.0080, -0.0042,  0.0192,  ...,  0.0319, -0.0360,  0.0033],
        ...,
        [ 0.0242,  0.0213, -0.0094,  ..., -0.0432, -0.0039,  0.0027],
        [-0.0012, -0.0116, -0.0232,  ...,  0.0270, -0.0056,  0.0214],
        [-0.0042,  0.0167, -0.0049,  ..., -0.0009,  0.0034,  0.0205]],
       dtype=torch.float16), 'model.layers.10.mlp.down_proj.weight': tensor([[-0.0152, -0.0201, -0.0101,  ...,  0.0302, -0.0133,  0.0010],
        [-0.0054,  0.0221, -0.0139,  ..., -0.0116,  0.0119, -0.0105],
        [-0.0275, -0.0021,  0.0208,  ..., -0.0218, -0.0254,  0.0118],
        ...,
        [ 0.0098, -0.0068, -0.0057,  ...,  0.0063,  0.0142,  0.0074],
        [-0.0106,  0.0519, -0.0189,  ...,  0.0284,  0.0307, -0.0305],
        [-0.0471,  0.0020, -0.0252,  ..., -0.0184, -0.0151,  0.0109]],
       dtype=torch.float16), 'model.layers.10.input_layernorm.weight': tensor([0.3652, 0.3594, 0.3223,  ..., 0.3398, 0.3496, 0.3379],
       dtype=torch.float16), 'model.layers.10.post_attention_layernorm.weight': tensor([0.2500, 0.2383, 0.2285,  ..., 0.2432, 0.2432, 0.2432],
       dtype=torch.float16), 'model.layers.11.self_attn.q_proj.weight': tensor([[ 0.0161, -0.0006, -0.0169,  ...,  0.0251, -0.0088,  0.0062],
        [-0.0113,  0.0006,  0.0061,  ...,  0.0169,  0.0102,  0.0040],
        [ 0.0104,  0.0213, -0.0237,  ..., -0.0047, -0.0055,  0.0015],
        ...,
        [ 0.0066,  0.0024,  0.0322,  ...,  0.0338,  0.0438, -0.0291],
        [ 0.0504,  0.0148, -0.0166,  ..., -0.0151,  0.0161, -0.0268],
        [ 0.0818, -0.0201, -0.0214,  ..., -0.0201,  0.0410,  0.0539]],
       dtype=torch.float16), 'model.layers.11.self_attn.k_proj.weight': tensor([[-0.0052,  0.0221,  0.0030,  ..., -0.0179,  0.0177, -0.0154],
        [ 0.0012,  0.0016, -0.0310,  ..., -0.0106,  0.0045,  0.0256],
        [ 0.0298, -0.0297,  0.0027,  ...,  0.0140,  0.0046,  0.0079],
        ...,
        [-0.0032,  0.0288,  0.0043,  ..., -0.0189, -0.0055,  0.0403],
        [ 0.0598, -0.0065, -0.0142,  ..., -0.0078,  0.0050, -0.0079],
        [ 0.0110,  0.0065,  0.0253,  ..., -0.0007,  0.0569,  0.0267]],
       dtype=torch.float16), 'model.layers.11.self_attn.v_proj.weight': tensor([[ 9.6436e-03,  1.0605e-03, -4.5738e-03,  ..., -2.2232e-02,
         -1.0233e-03,  7.4806e-03],
        [ 2.6855e-03, -6.0806e-03, -1.6937e-02,  ..., -5.5611e-05,
          3.7360e-04, -2.7130e-02],
        [ 2.9392e-03,  9.2468e-03, -7.0686e-03,  ...,  1.6724e-02,
          1.0735e-02, -2.5055e-02],
        ...,
        [-2.0782e-02,  7.5455e-03, -1.4633e-02,  ...,  8.2016e-03,
         -1.7349e-02, -2.2812e-03],
        [-9.9487e-03,  1.0506e-02, -1.1917e-02,  ..., -1.3245e-02,
         -1.7868e-02,  3.2711e-03],
        [ 1.7990e-02, -2.1179e-02, -1.4639e-03,  ..., -4.0344e-02,
          1.8826e-03, -1.2375e-02]], dtype=torch.float16), 'model.layers.11.self_attn.o_proj.weight': tensor([[-0.0191, -0.0035,  0.0060,  ...,  0.0097,  0.0109,  0.0016],
        [-0.0016, -0.0260,  0.0116,  ..., -0.0118, -0.0028, -0.0255],
        [-0.0051, -0.0058,  0.0210,  ...,  0.0021, -0.0066,  0.0139],
        ...,
        [ 0.0016, -0.0042,  0.0228,  ...,  0.0024, -0.0016, -0.0029],
        [ 0.0077,  0.0177,  0.0082,  ...,  0.0172,  0.0129, -0.0298],
        [-0.0027, -0.0047,  0.0054,  ..., -0.0081, -0.0022, -0.0107]],
       dtype=torch.float16), 'model.layers.11.mlp.gate_proj.weight': tensor([[-0.0440, -0.0086,  0.0052,  ...,  0.0062, -0.0116,  0.0425],
        [ 0.0074, -0.0107,  0.0206,  ...,  0.0087, -0.0197, -0.0413],
        [-0.0010, -0.0459, -0.0289,  ..., -0.0025, -0.0084, -0.0026],
        ...,
        [-0.0202, -0.0397, -0.0216,  ..., -0.0041, -0.0321,  0.0039],
        [ 0.0090, -0.0044, -0.0364,  ..., -0.0127,  0.0069,  0.0010],
        [ 0.0023,  0.0186,  0.0080,  ...,  0.0468, -0.0007, -0.0140]],
       dtype=torch.float16), 'model.layers.11.mlp.up_proj.weight': tensor([[-0.0093,  0.0016, -0.0275,  ...,  0.0240,  0.0097,  0.0313],
        [ 0.0179, -0.0028, -0.0222,  ...,  0.0172, -0.0467,  0.0077],
        [-0.0064, -0.0369,  0.0014,  ..., -0.0048, -0.0177,  0.0154],
        ...,
        [ 0.0408,  0.0105, -0.0095,  ...,  0.0014, -0.0005,  0.0161],
        [-0.0116,  0.0200,  0.0059,  ...,  0.0163,  0.0094,  0.0065],
        [-0.0041,  0.0019, -0.0054,  ..., -0.0172, -0.0005,  0.0250]],
       dtype=torch.float16), 'model.layers.11.mlp.down_proj.weight': tensor([[-0.0162,  0.0454,  0.0091,  ...,  0.0194,  0.0163, -0.0040],
        [-0.0136, -0.0092, -0.0251,  ..., -0.0202, -0.0090,  0.0154],
        [-0.0237, -0.0169,  0.0102,  ...,  0.0052, -0.0217, -0.0031],
        ...,
        [ 0.0215,  0.0262, -0.0104,  ..., -0.0017, -0.0003,  0.0087],
        [-0.0111, -0.0290, -0.0306,  ..., -0.0254, -0.0089,  0.0139],
        [ 0.0362,  0.0240,  0.0214,  ..., -0.0028, -0.0135,  0.0383]],
       dtype=torch.float16), 'model.layers.11.input_layernorm.weight': tensor([0.3965, 0.3965, 0.3652,  ..., 0.3848, 0.3828, 0.3711],
       dtype=torch.float16), 'model.layers.11.post_attention_layernorm.weight': tensor([0.2598, 0.2471, 0.2383,  ..., 0.2578, 0.2559, 0.2559],
       dtype=torch.float16), 'model.layers.12.self_attn.q_proj.weight': tensor([[-0.0093, -0.0171,  0.0036,  ...,  0.0262, -0.0099,  0.0055],
        [ 0.0065, -0.0070, -0.0075,  ..., -0.0127,  0.0223,  0.0202],
        [ 0.0106,  0.0411, -0.0328,  ...,  0.0061,  0.0025, -0.0291],
        ...,
        [ 0.0094,  0.0321, -0.0197,  ..., -0.0311, -0.0004, -0.0008],
        [ 0.0424, -0.0059,  0.0097,  ...,  0.0322,  0.0067, -0.0247],
        [ 0.0332,  0.0143, -0.0364,  ..., -0.0210,  0.0215,  0.0238]],
       dtype=torch.float16), 'model.layers.12.self_attn.k_proj.weight': tensor([[ 0.0099, -0.0011, -0.0045,  ...,  0.0193, -0.0024, -0.0102],
        [ 0.0073,  0.0208, -0.0157,  ..., -0.0014, -0.0157, -0.0293],
        [-0.0113, -0.0283,  0.0173,  ...,  0.0087,  0.0026,  0.0026],
        ...,
        [ 0.0132,  0.0322, -0.0148,  ..., -0.0355, -0.0164, -0.0242],
        [-0.0381,  0.0037,  0.0226,  ..., -0.0282,  0.0146, -0.0006],
        [-0.0007,  0.0322,  0.0109,  ...,  0.0129, -0.0465, -0.0404]],
       dtype=torch.float16), 'model.layers.12.self_attn.v_proj.weight': tensor([[ 0.0064,  0.0072,  0.0069,  ..., -0.0077,  0.0109, -0.0189],
        [-0.0275,  0.0104, -0.0036,  ..., -0.0175, -0.0006,  0.0191],
        [-0.0148, -0.0132,  0.0088,  ..., -0.0069,  0.0475, -0.0107],
        ...,
        [ 0.0081, -0.0017, -0.0150,  ..., -0.0068, -0.0115, -0.0013],
        [-0.0010, -0.0147, -0.0047,  ...,  0.0034,  0.0109,  0.0122],
        [ 0.0225,  0.0017,  0.0007,  ...,  0.0178,  0.0139, -0.0070]],
       dtype=torch.float16), 'model.layers.12.self_attn.o_proj.weight': tensor([[ 0.0277,  0.0071, -0.0019,  ..., -0.0012,  0.0083, -0.0061],
        [-0.0092, -0.0141, -0.0014,  ..., -0.0108,  0.0061, -0.0138],
        [ 0.0068, -0.0023, -0.0018,  ...,  0.0037, -0.0232,  0.0125],
        ...,
        [ 0.0032, -0.0023,  0.0126,  ..., -0.0084, -0.0009,  0.0019],
        [-0.0108, -0.0346, -0.0278,  ..., -0.0121,  0.0109,  0.0143],
        [ 0.0210,  0.0093,  0.0084,  ...,  0.0209, -0.0084, -0.0171]],
       dtype=torch.float16), 'model.layers.12.mlp.gate_proj.weight': tensor([[ 0.0057, -0.0110,  0.0123,  ..., -0.0042,  0.0268, -0.0024],
        [-0.0266, -0.0214,  0.0172,  ...,  0.0121,  0.0153,  0.0057],
        [-0.0005,  0.0258, -0.0114,  ..., -0.0099, -0.0289, -0.0045],
        ...,
        [-0.0024,  0.0108,  0.0106,  ..., -0.0328,  0.0070,  0.0276],
        [-0.0325, -0.0083,  0.0082,  ...,  0.0103,  0.0123, -0.0085],
        [ 0.0045, -0.0267, -0.0056,  ..., -0.0053, -0.0018, -0.0202]],
       dtype=torch.float16), 'model.layers.12.mlp.up_proj.weight': tensor([[ 2.9488e-03,  1.7151e-02,  3.6030e-03,  ..., -9.1076e-05,
          1.3832e-02,  1.5427e-02],
        [-3.6373e-03, -1.4801e-02, -1.3435e-02,  ...,  6.5842e-03,
         -7.0915e-03,  2.4414e-02],
        [ 1.4610e-02, -1.2291e-02,  7.4959e-03,  ..., -4.1534e-02,
          4.9171e-03,  1.6441e-03],
        ...,
        [-2.6154e-02, -3.3844e-02, -7.3738e-03,  ...,  1.6922e-02,
         -1.5038e-02,  3.0403e-03],
        [-1.5144e-03, -4.3915e-02, -8.0156e-04,  ...,  1.3924e-02,
          3.0556e-03, -1.5656e-02],
        [ 2.2144e-03, -2.8961e-02,  3.7813e-04,  ...,  3.2440e-02,
         -3.6602e-03, -3.8300e-02]], dtype=torch.float16), 'model.layers.12.mlp.down_proj.weight': tensor([[ 0.0081, -0.0018, -0.0294,  ..., -0.0123,  0.0035,  0.0029],
        [ 0.0170, -0.0288,  0.0046,  ..., -0.0004, -0.0089, -0.0230],
        [ 0.0200,  0.0030,  0.0241,  ...,  0.0043, -0.0012, -0.0281],
        ...,
        [ 0.0183, -0.0085, -0.0380,  ...,  0.0313, -0.0193, -0.0176],
        [-0.0259,  0.0179,  0.0106,  ..., -0.0092,  0.0359, -0.0229],
        [ 0.0075,  0.0262,  0.0221,  ..., -0.0381,  0.0273, -0.0022]],
       dtype=torch.float16), 'model.layers.12.input_layernorm.weight': tensor([0.4062, 0.4023, 0.3691,  ..., 0.3848, 0.3867, 0.3887],
       dtype=torch.float16), 'model.layers.12.post_attention_layernorm.weight': tensor([0.2656, 0.2520, 0.2432,  ..., 0.2656, 0.2617, 0.2598],
       dtype=torch.float16), 'model.layers.13.self_attn.q_proj.weight': tensor([[-0.0002, -0.0013, -0.0132,  ...,  0.0055, -0.0150, -0.0128],
        [-0.0118, -0.0142,  0.0031,  ..., -0.0004,  0.0004, -0.0026],
        [-0.0175,  0.0138,  0.0197,  ..., -0.0115, -0.0075, -0.0069],
        ...,
        [ 0.0483,  0.0084,  0.0043,  ...,  0.0573,  0.0140, -0.0512],
        [ 0.0078,  0.0083, -0.0259,  ...,  0.0091,  0.0111, -0.0104],
        [-0.0040, -0.0248, -0.0212,  ..., -0.0068,  0.0285, -0.0065]],
       dtype=torch.float16), 'model.layers.13.self_attn.k_proj.weight': tensor([[ 0.0134,  0.0048, -0.0030,  ..., -0.0130,  0.0337,  0.0125],
        [ 0.0155,  0.0307, -0.0005,  ..., -0.0055,  0.0136,  0.0046],
        [-0.0007, -0.0130,  0.0334,  ..., -0.0083,  0.0110, -0.0375],
        ...,
        [ 0.0375,  0.0356,  0.0033,  ...,  0.0048, -0.0061, -0.0118],
        [-0.0010,  0.0045,  0.0287,  ..., -0.0342, -0.0217,  0.0352],
        [-0.0229, -0.0535, -0.0142,  ..., -0.0378, -0.0310,  0.0118]],
       dtype=torch.float16), 'model.layers.13.self_attn.v_proj.weight': tensor([[ 0.0149,  0.0064, -0.0058,  ..., -0.0005,  0.0173,  0.0124],
        [-0.0029,  0.0087,  0.0005,  ...,  0.0233, -0.0065, -0.0029],
        [ 0.0146, -0.0016, -0.0023,  ..., -0.0212,  0.0366, -0.0090],
        ...,
        [-0.0011,  0.0251, -0.0052,  ..., -0.0111,  0.0272, -0.0211],
        [-0.0103,  0.0104,  0.0128,  ...,  0.0017,  0.0274,  0.0058],
        [-0.0045, -0.0064,  0.0239,  ...,  0.0154, -0.0026,  0.0374]],
       dtype=torch.float16), 'model.layers.13.self_attn.o_proj.weight': tensor([[-0.0035,  0.0010, -0.0044,  ..., -0.0015, -0.0045, -0.0012],
        [ 0.0222,  0.0148,  0.0101,  ..., -0.0146, -0.0108,  0.0024],
        [ 0.0118,  0.0055,  0.0036,  ...,  0.0065, -0.0233, -0.0088],
        ...,
        [-0.0102,  0.0102,  0.0194,  ..., -0.0114, -0.0154, -0.0165],
        [ 0.0083, -0.0005,  0.0301,  ..., -0.0037, -0.0268, -0.0238],
        [ 0.0100,  0.0019,  0.0086,  ...,  0.0171, -0.0083, -0.0238]],
       dtype=torch.float16), 'model.layers.13.mlp.gate_proj.weight': tensor([[ 0.0249, -0.0034, -0.0082,  ...,  0.0114,  0.0034, -0.0122],
        [-0.0141,  0.0452,  0.0071,  ...,  0.0416, -0.0012, -0.0260],
        [ 0.0035, -0.0199, -0.0103,  ...,  0.0047, -0.0093, -0.0152],
        ...,
        [ 0.0153, -0.0196,  0.0202,  ..., -0.0065,  0.0133,  0.0111],
        [ 0.0154, -0.0125,  0.0203,  ...,  0.0181,  0.0106, -0.0270],
        [ 0.0028,  0.0392,  0.0161,  ..., -0.0045,  0.0059,  0.0285]],
       dtype=torch.float16), 'model.layers.13.mlp.up_proj.weight': tensor([[-0.0423,  0.0199, -0.0013,  ...,  0.0037,  0.0091,  0.0011],
        [ 0.0138, -0.0066,  0.0247,  ...,  0.0468,  0.0286,  0.0224],
        [ 0.0281, -0.0344,  0.0093,  ...,  0.0069,  0.0009, -0.0082],
        ...,
        [-0.0130, -0.0038,  0.0297,  ...,  0.0190, -0.0247,  0.0139],
        [-0.0103, -0.0171,  0.0079,  ...,  0.0177,  0.0563,  0.0096],
        [ 0.0117, -0.0212,  0.0179,  ..., -0.0185, -0.0004,  0.0269]],
       dtype=torch.float16), 'model.layers.13.mlp.down_proj.weight': tensor([[-0.0062, -0.0036, -0.0027,  ...,  0.0226, -0.0265, -0.0220],
        [-0.0117,  0.0470, -0.0413,  ..., -0.0018,  0.0133, -0.0090],
        [ 0.0081,  0.0038,  0.0183,  ...,  0.0015, -0.0249, -0.0031],
        ...,
        [ 0.0058,  0.0077,  0.0354,  ..., -0.0014, -0.0209,  0.0290],
        [ 0.0167, -0.0015,  0.0188,  ..., -0.0109,  0.0164, -0.0045],
        [ 0.0029, -0.0229,  0.0393,  ...,  0.0041,  0.0022,  0.0325]],
       dtype=torch.float16), 'model.layers.13.input_layernorm.weight': tensor([0.4199, 0.4121, 0.3770,  ..., 0.3926, 0.3848, 0.3965],
       dtype=torch.float16), 'model.layers.13.post_attention_layernorm.weight': tensor([0.2715, 0.2598, 0.2539,  ..., 0.2715, 0.2734, 0.2656],
       dtype=torch.float16), 'model.layers.14.self_attn.q_proj.weight': tensor([[-0.0088, -0.0028,  0.0195,  ..., -0.0054,  0.0162,  0.0367],
        [ 0.0097,  0.0160, -0.0124,  ..., -0.0348, -0.0203, -0.0406],
        [-0.0202, -0.0112,  0.0171,  ...,  0.0106,  0.0140, -0.0339],
        ...,
        [-0.0201,  0.0005, -0.0295,  ...,  0.0018,  0.0130, -0.0074],
        [ 0.0269, -0.0389,  0.0497,  ..., -0.0134,  0.0061, -0.0092],
        [-0.0175, -0.0090, -0.0035,  ...,  0.0170,  0.0184, -0.0447]],
       dtype=torch.float16), 'model.layers.14.self_attn.k_proj.weight': tensor([[-0.0143, -0.0049,  0.0068,  ..., -0.0091,  0.0271,  0.0431],
        [ 0.0191,  0.0324, -0.0204,  ..., -0.0030, -0.0276, -0.0050],
        [-0.0183,  0.0034,  0.0196,  ...,  0.0239,  0.0110,  0.0012],
        ...,
        [-0.0387, -0.0029,  0.0264,  ..., -0.0049,  0.0017, -0.0254],
        [-0.0293,  0.0005,  0.0153,  ..., -0.0359, -0.0144,  0.0012],
        [-0.0202,  0.0292,  0.0236,  ...,  0.0703,  0.0087, -0.0386]],
       dtype=torch.float16), 'model.layers.14.self_attn.v_proj.weight': tensor([[ 7.4310e-03,  7.7629e-03, -3.8025e-02,  ..., -3.4210e-02,
         -5.2032e-03,  1.2451e-02],
        [-1.0204e-03, -2.5452e-02, -3.0117e-03,  ...,  1.0887e-02,
         -5.2512e-05, -3.2425e-03],
        [ 2.6276e-02, -1.5022e-02,  2.2659e-03,  ..., -5.5466e-03,
          2.3460e-03,  8.2321e-03],
        ...,
        [ 1.5747e-02, -1.1642e-02,  1.5343e-02,  ...,  1.5533e-02,
         -1.1597e-02,  2.6016e-03],
        [-1.1391e-02,  2.2583e-02, -3.5553e-02,  ..., -7.8058e-04,
         -8.8654e-03, -2.5574e-02],
        [ 3.5992e-03,  2.3102e-02, -2.2568e-02,  ..., -5.2261e-03,
         -3.3932e-03,  1.8295e-02]], dtype=torch.float16), 'model.layers.14.self_attn.o_proj.weight': tensor([[-0.0108,  0.0044, -0.0227,  ..., -0.0021,  0.0010, -0.0110],
        [ 0.0080,  0.0304,  0.0077,  ...,  0.0221, -0.0049,  0.0021],
        [ 0.0060,  0.0082,  0.0024,  ...,  0.0075,  0.0206,  0.0054],
        ...,
        [ 0.0245, -0.0073,  0.0008,  ..., -0.0073, -0.0022,  0.0139],
        [-0.0025,  0.0010, -0.0195,  ..., -0.0021,  0.0362,  0.0155],
        [-0.0085, -0.0104, -0.0139,  ..., -0.0070,  0.0146,  0.0060]],
       dtype=torch.float16), 'model.layers.14.mlp.gate_proj.weight': tensor([[-0.0084,  0.0011, -0.0090,  ...,  0.0102, -0.0185, -0.0064],
        [ 0.0296,  0.0080, -0.0390,  ...,  0.0377,  0.0119, -0.0075],
        [ 0.0095,  0.0148, -0.0004,  ..., -0.0081,  0.0108, -0.0179],
        ...,
        [ 0.0065,  0.0105, -0.0190,  ...,  0.0003, -0.0047,  0.0004],
        [ 0.0033,  0.0159,  0.0201,  ..., -0.0192,  0.0087,  0.0073],
        [ 0.0200,  0.0017,  0.0183,  ..., -0.0106, -0.0248,  0.0258]],
       dtype=torch.float16), 'model.layers.14.mlp.up_proj.weight': tensor([[ 0.0052,  0.0099,  0.0201,  ..., -0.0153,  0.0073,  0.0048],
        [ 0.0269,  0.0089, -0.0300,  ...,  0.0064,  0.0262,  0.0104],
        [ 0.0012, -0.0055,  0.0300,  ..., -0.0013,  0.0177, -0.0023],
        ...,
        [-0.0164, -0.0013, -0.0479,  ..., -0.0145, -0.0116, -0.0048],
        [-0.0415,  0.0074, -0.0075,  ..., -0.0081,  0.0239, -0.0144],
        [ 0.0029,  0.0235,  0.0122,  ...,  0.0086, -0.0140,  0.0131]],
       dtype=torch.float16), 'model.layers.14.mlp.down_proj.weight': tensor([[ 0.0100,  0.0243,  0.0113,  ..., -0.0290, -0.0019, -0.0056],
        [ 0.0121,  0.0222, -0.0091,  ...,  0.0131, -0.0032,  0.0189],
        [ 0.0080, -0.0420,  0.0119,  ...,  0.0042, -0.0302,  0.0124],
        ...,
        [ 0.0005,  0.0152, -0.0169,  ..., -0.0046, -0.0100, -0.0109],
        [ 0.0242,  0.0335,  0.0364,  ..., -0.0051, -0.0155,  0.0210],
        [-0.0245,  0.0057, -0.0101,  ..., -0.0300,  0.0070,  0.0187]],
       dtype=torch.float16), 'model.layers.14.input_layernorm.weight': tensor([0.4219, 0.4297, 0.3789,  ..., 0.4141, 0.4062, 0.3984],
       dtype=torch.float16), 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2734, 0.2656,  ..., 0.2871, 0.2832, 0.2793],
       dtype=torch.float16), 'model.layers.15.self_attn.q_proj.weight': tensor([[-0.0194, -0.0154, -0.0142,  ...,  0.0138, -0.0084,  0.0010],
        [ 0.0363, -0.0190,  0.0038,  ..., -0.0058,  0.0144,  0.0015],
        [ 0.0084, -0.0132,  0.0030,  ...,  0.0098, -0.0134, -0.0160],
        ...,
        [-0.0477, -0.0267,  0.0071,  ..., -0.0063, -0.0128,  0.0200],
        [-0.0155, -0.0536,  0.0174,  ...,  0.0155, -0.0015,  0.0025],
        [ 0.0236,  0.0251,  0.0278,  ..., -0.0140, -0.0227, -0.0165]],
       dtype=torch.float16), 'model.layers.15.self_attn.k_proj.weight': tensor([[ 0.0209, -0.0054, -0.0045,  ..., -0.0027,  0.0014,  0.0044],
        [ 0.0111, -0.0042, -0.0052,  ..., -0.0015,  0.0046, -0.0135],
        [-0.0021,  0.0020, -0.0083,  ..., -0.0007,  0.0133, -0.0119],
        ...,
        [-0.0540, -0.0380,  0.0168,  ...,  0.0214,  0.0069, -0.0060],
        [ 0.0092,  0.0011,  0.0159,  ...,  0.0275, -0.0217,  0.0132],
        [-0.0067, -0.0060,  0.0341,  ..., -0.0027, -0.0171,  0.0033]],
       dtype=torch.float16), 'model.layers.15.self_attn.v_proj.weight': tensor([[ 0.0088,  0.0023,  0.0053,  ...,  0.0037,  0.0141,  0.0177],
        [-0.0096, -0.0142,  0.0151,  ...,  0.0168,  0.0018,  0.0224],
        [ 0.0075, -0.0377, -0.0064,  ..., -0.0365,  0.0073,  0.0073],
        ...,
        [-0.0038, -0.0107,  0.0116,  ...,  0.0066,  0.0181, -0.0141],
        [ 0.0056, -0.0006, -0.0311,  ...,  0.0116,  0.0151, -0.0054],
        [ 0.0169,  0.0104,  0.0152,  ..., -0.0160,  0.0075,  0.0077]],
       dtype=torch.float16), 'model.layers.15.self_attn.o_proj.weight': tensor([[ 0.0012,  0.0029, -0.0154,  ...,  0.0104, -0.0127,  0.0282],
        [-0.0046, -0.0112, -0.0177,  ...,  0.0099, -0.0261,  0.0198],
        [ 0.0020, -0.0083,  0.0008,  ...,  0.0102, -0.0070,  0.0095],
        ...,
        [-0.0089, -0.0197,  0.0142,  ..., -0.0044, -0.0201, -0.0100],
        [ 0.0005, -0.0017, -0.0072,  ...,  0.0113,  0.0051,  0.0044],
        [-0.0241,  0.0053,  0.0263,  ..., -0.0118, -0.0254, -0.0296]],
       dtype=torch.float16), 'model.layers.15.mlp.gate_proj.weight': tensor([[-0.0145,  0.0259, -0.0075,  ...,  0.0116, -0.0298,  0.0140],
        [ 0.0069, -0.0101,  0.0278,  ..., -0.0192,  0.0056,  0.0099],
        [ 0.0088, -0.0179, -0.0112,  ...,  0.0231, -0.0539, -0.0260],
        ...,
        [-0.0106, -0.0046,  0.0301,  ..., -0.0094,  0.0175,  0.0069],
        [-0.0124, -0.0172,  0.0103,  ..., -0.0082, -0.0106, -0.0440],
        [ 0.0040, -0.0142, -0.0008,  ...,  0.0002,  0.0071, -0.0001]],
       dtype=torch.float16), 'model.layers.15.mlp.up_proj.weight': tensor([[-1.2886e-02, -9.5215e-03,  2.7924e-02,  ...,  1.2367e-02,
          1.1269e-02, -4.3579e-02],
        [-1.5732e-02,  4.2908e-02,  2.9343e-02,  ...,  1.0506e-02,
          7.6866e-03,  3.9864e-03],
        [-4.2419e-02, -7.7896e-03, -4.7994e-04,  ..., -1.5518e-02,
          1.5602e-02, -1.0269e-02],
        ...,
        [-6.7863e-03, -2.3376e-02, -7.8659e-03,  ...,  8.5068e-03,
         -4.8757e-05, -4.9782e-03],
        [ 2.7618e-02, -5.3329e-03,  7.8354e-03,  ..., -1.0330e-02,
          1.5747e-02,  5.7030e-04],
        [-7.5302e-03, -2.7130e-02, -9.7809e-03,  ...,  4.5633e-04,
         -1.2245e-02,  1.1940e-03]], dtype=torch.float16), 'model.layers.15.mlp.down_proj.weight': tensor([[-1.2512e-02, -6.8245e-03, -1.6098e-02,  ...,  2.5909e-02,
          9.1171e-03, -1.0674e-02],
        [ 1.0666e-02, -1.1749e-02, -2.6199e-02,  ..., -1.1993e-02,
         -2.3163e-02,  1.6129e-02],
        [ 3.8452e-02,  4.4830e-02, -1.5747e-02,  ..., -1.1589e-02,
          3.4302e-02,  1.8906e-02],
        ...,
        [-4.5853e-03, -3.9978e-02,  6.3210e-03,  ...,  9.4833e-03,
          5.5046e-03,  7.1466e-05],
        [-4.1779e-02, -1.7502e-02, -1.1826e-03,  ..., -2.9480e-02,
         -1.5137e-02,  7.0038e-03],
        [ 1.5354e-03,  2.3773e-02, -6.3553e-03,  ..., -1.7715e-02,
         -3.2593e-02, -2.0401e-02]], dtype=torch.float16), 'model.layers.15.input_layernorm.weight': tensor([0.4160, 0.4102, 0.3809,  ..., 0.3867, 0.3945, 0.3945],
       dtype=torch.float16), 'model.layers.15.post_attention_layernorm.weight': tensor([0.2930, 0.2793, 0.2793,  ..., 0.2969, 0.2910, 0.2891],
       dtype=torch.float16), 'model.layers.16.self_attn.q_proj.weight': tensor([[ 0.0090,  0.0135, -0.0253,  ...,  0.0048,  0.0263, -0.0078],
        [ 0.0172, -0.0415,  0.0228,  ...,  0.0170,  0.0186, -0.0237],
        [-0.0128, -0.0067,  0.0088,  ..., -0.0257,  0.0021, -0.0261],
        ...,
        [ 0.0328, -0.0378, -0.0080,  ..., -0.0196,  0.0181, -0.0271],
        [-0.0166, -0.0170,  0.0283,  ...,  0.0018, -0.0181,  0.0157],
        [ 0.0046,  0.0219,  0.0146,  ..., -0.0030, -0.0327, -0.0095]],
       dtype=torch.float16), 'model.layers.16.self_attn.k_proj.weight': tensor([[-0.0072,  0.0235,  0.0023,  ...,  0.0131,  0.0227,  0.0217],
        [ 0.0223, -0.0315,  0.0097,  ..., -0.0058, -0.0194, -0.0077],
        [ 0.0272, -0.0056, -0.0197,  ..., -0.0234,  0.0092, -0.0277],
        ...,
        [ 0.0239,  0.0135, -0.0127,  ..., -0.0233, -0.0399, -0.0581],
        [ 0.0161,  0.0086,  0.0133,  ...,  0.0302,  0.0043,  0.0115],
        [-0.0444,  0.0565,  0.0591,  ...,  0.0017, -0.0147,  0.0274]],
       dtype=torch.float16), 'model.layers.16.self_attn.v_proj.weight': tensor([[-0.0166,  0.0066, -0.0049,  ...,  0.0065, -0.0008, -0.0020],
        [-0.0576, -0.0069,  0.0042,  ...,  0.0035,  0.0128, -0.0267],
        [-0.0069, -0.0133, -0.0021,  ..., -0.0211,  0.0416,  0.0151],
        ...,
        [ 0.0040, -0.0079,  0.0167,  ..., -0.0125, -0.0001,  0.0166],
        [-0.0169,  0.0023,  0.0052,  ...,  0.0389, -0.0043,  0.0089],
        [ 0.0118,  0.0102,  0.0083,  ..., -0.0158, -0.0042, -0.0301]],
       dtype=torch.float16), 'model.layers.16.self_attn.o_proj.weight': tensor([[ 0.0388, -0.0079, -0.0170,  ...,  0.0112, -0.0126,  0.0047],
        [-0.0246,  0.0107, -0.0208,  ...,  0.0039, -0.0083,  0.0016],
        [-0.0285, -0.0177, -0.0134,  ..., -0.0021,  0.0259,  0.0170],
        ...,
        [-0.0030, -0.0207,  0.0029,  ...,  0.0046, -0.0266,  0.0010],
        [-0.0073,  0.0199,  0.0344,  ..., -0.0005,  0.0009, -0.0051],
        [-0.0192,  0.0035,  0.0066,  ...,  0.0018,  0.0024,  0.0109]],
       dtype=torch.float16), 'model.layers.16.mlp.gate_proj.weight': tensor([[-0.0275, -0.0157, -0.0233,  ...,  0.0007, -0.0003,  0.0085],
        [ 0.0313,  0.0157, -0.0098,  ...,  0.0153,  0.0087,  0.0166],
        [ 0.0027,  0.0056,  0.0041,  ..., -0.0008, -0.0035, -0.0189],
        ...,
        [-0.0086,  0.0085,  0.0053,  ...,  0.0223,  0.0300,  0.0286],
        [-0.0033, -0.0147,  0.0094,  ...,  0.0099,  0.0210,  0.0115],
        [ 0.0256,  0.0212,  0.0310,  ..., -0.0399,  0.0148, -0.0203]],
       dtype=torch.float16), 'model.layers.16.mlp.up_proj.weight': tensor([[-0.0403,  0.0147,  0.0066,  ...,  0.0294, -0.0128,  0.0091],
        [ 0.0156, -0.0131,  0.0048,  ...,  0.0215, -0.0303, -0.0077],
        [-0.0078, -0.0256, -0.0064,  ..., -0.0124, -0.0047,  0.0258],
        ...,
        [-0.0096,  0.0263, -0.0066,  ...,  0.0095, -0.0235, -0.0248],
        [-0.0098,  0.0216, -0.0177,  ...,  0.0097, -0.0052,  0.0185],
        [ 0.0099,  0.0079, -0.0118,  ...,  0.0013, -0.0239, -0.0209]],
       dtype=torch.float16), 'model.layers.16.mlp.down_proj.weight': tensor([[-0.0236,  0.0045,  0.0134,  ...,  0.0206, -0.0091, -0.0008],
        [-0.0233, -0.0041, -0.0123,  ...,  0.0286,  0.0018, -0.0002],
        [-0.0142,  0.0049, -0.0120,  ...,  0.0201, -0.0042, -0.0009],
        ...,
        [ 0.0143, -0.0248, -0.0242,  ...,  0.0203,  0.0178, -0.0020],
        [ 0.0227,  0.0019, -0.0097,  ..., -0.0214, -0.0128, -0.0098],
        [ 0.0107, -0.0168, -0.0371,  ...,  0.0256, -0.0010, -0.0141]],
       dtype=torch.float16), 'model.layers.16.input_layernorm.weight': tensor([0.4180, 0.4219, 0.3906,  ..., 0.3984, 0.4160, 0.4082],
       dtype=torch.float16), 'model.layers.16.post_attention_layernorm.weight': tensor([0.3164, 0.2949, 0.2988,  ..., 0.3105, 0.3086, 0.3047],
       dtype=torch.float16), 'model.layers.17.self_attn.q_proj.weight': tensor([[-0.0125, -0.0138,  0.0065,  ...,  0.0073, -0.0072, -0.0107],
        [ 0.0094, -0.0095,  0.0169,  ...,  0.0019, -0.0260,  0.0081],
        [-0.0130, -0.0020, -0.0129,  ...,  0.0152, -0.0114,  0.0020],
        ...,
        [ 0.0362, -0.0261,  0.0562,  ..., -0.0142, -0.0178,  0.0079],
        [ 0.0282, -0.0184,  0.0462,  ...,  0.0094, -0.0215, -0.0601],
        [ 0.0126, -0.0017,  0.0116,  ...,  0.0320,  0.0013,  0.0742]],
       dtype=torch.float16), 'model.layers.17.self_attn.k_proj.weight': tensor([[-0.0127, -0.0063,  0.0040,  ..., -0.0014,  0.0197,  0.0079],
        [ 0.0078,  0.0072,  0.0041,  ...,  0.0103,  0.0002, -0.0138],
        [ 0.0077, -0.0085,  0.0012,  ...,  0.0154, -0.0231, -0.0079],
        ...,
        [ 0.0041, -0.0500, -0.0091,  ..., -0.0221,  0.0599, -0.0676],
        [ 0.0275,  0.0191,  0.0122,  ..., -0.0132, -0.0267, -0.0225],
        [-0.0380, -0.0470, -0.0048,  ...,  0.0278,  0.0259, -0.0048]],
       dtype=torch.float16), 'model.layers.17.self_attn.v_proj.weight': tensor([[-0.0122,  0.0105,  0.0024,  ...,  0.0239, -0.0088, -0.0096],
        [-0.0039, -0.0155, -0.0111,  ...,  0.0116, -0.0257, -0.0144],
        [ 0.0174,  0.0158, -0.0024,  ...,  0.0018, -0.0111, -0.0288],
        ...,
        [ 0.0010, -0.0043,  0.0143,  ...,  0.0121,  0.0051, -0.0155],
        [ 0.0189, -0.0031, -0.0388,  ..., -0.0152, -0.0034, -0.0341],
        [-0.0093, -0.0103, -0.0053,  ...,  0.0055,  0.0081,  0.0092]],
       dtype=torch.float16), 'model.layers.17.self_attn.o_proj.weight': tensor([[-0.0049, -0.0105,  0.0036,  ..., -0.0197,  0.0008, -0.0131],
        [-0.0116, -0.0207,  0.0218,  ...,  0.0219, -0.0174,  0.0221],
        [ 0.0098, -0.0111, -0.0045,  ..., -0.0186, -0.0138, -0.0218],
        ...,
        [-0.0109,  0.0140, -0.0118,  ..., -0.0310, -0.0329, -0.0185],
        [-0.0070,  0.0101, -0.0009,  ..., -0.0287,  0.0044,  0.0065],
        [-0.0155, -0.0129,  0.0072,  ...,  0.0329, -0.0223,  0.0173]],
       dtype=torch.float16), 'model.layers.17.mlp.gate_proj.weight': tensor([[-0.0341,  0.0291,  0.0243,  ...,  0.0059,  0.0021,  0.0031],
        [-0.0008,  0.0264,  0.0270,  ...,  0.0185,  0.0077,  0.0121],
        [ 0.0100,  0.0120, -0.0222,  ...,  0.0171,  0.0307, -0.0055],
        ...,
        [-0.0114, -0.0160, -0.0122,  ..., -0.0103, -0.0229, -0.0157],
        [ 0.0041,  0.0033,  0.0092,  ...,  0.0065,  0.0431, -0.0114],
        [-0.0032,  0.0208,  0.0144,  ..., -0.0138, -0.0018, -0.0032]],
       dtype=torch.float16), 'model.layers.17.mlp.up_proj.weight': tensor([[-0.0169, -0.0280, -0.0067,  ...,  0.0061,  0.0168, -0.0130],
        [-0.0231,  0.0152,  0.0278,  ...,  0.0003,  0.0016,  0.0020],
        [-0.0010, -0.0031,  0.0035,  ...,  0.0089, -0.0150,  0.0119],
        ...,
        [ 0.0138,  0.0168,  0.0068,  ...,  0.0064, -0.0204, -0.0130],
        [-0.0162, -0.0182, -0.0103,  ..., -0.0115, -0.0220,  0.0159],
        [-0.0032,  0.0038, -0.0083,  ...,  0.0034, -0.0360, -0.0131]],
       dtype=torch.float16), 'model.layers.17.mlp.down_proj.weight': tensor([[ 0.0260, -0.0225,  0.0134,  ...,  0.0120, -0.0079, -0.0022],
        [ 0.0285,  0.0301,  0.0086,  ...,  0.0063, -0.0083,  0.0336],
        [-0.0263, -0.0165, -0.0178,  ...,  0.0121, -0.0150, -0.0046],
        ...,
        [ 0.0067, -0.0222, -0.0068,  ..., -0.0141, -0.0051, -0.0367],
        [ 0.0015,  0.0053, -0.0114,  ..., -0.0275, -0.0274,  0.0174],
        [-0.0009, -0.0200,  0.0189,  ..., -0.0368, -0.0108,  0.0045]],
       dtype=torch.float16), 'model.layers.17.input_layernorm.weight': tensor([0.4316, 0.4336, 0.4043,  ..., 0.4238, 0.4277, 0.4062],
       dtype=torch.float16), 'model.layers.17.post_attention_layernorm.weight': tensor([0.3320, 0.3164, 0.3145,  ..., 0.3320, 0.3301, 0.3223],
       dtype=torch.float16), 'model.layers.18.self_attn.q_proj.weight': tensor([[ 0.0067,  0.0054,  0.0022,  ..., -0.0046, -0.0363,  0.0100],
        [ 0.0022, -0.0133,  0.0213,  ...,  0.0001,  0.0255,  0.0434],
        [ 0.0111, -0.0257, -0.0097,  ...,  0.0015, -0.0081,  0.0164],
        ...,
        [-0.0324,  0.0133,  0.0033,  ...,  0.0230,  0.0055,  0.0155],
        [ 0.0622, -0.0166, -0.0270,  ...,  0.0574,  0.0266,  0.0184],
        [ 0.0301,  0.0155,  0.0043,  ...,  0.0281,  0.0549, -0.0513]],
       dtype=torch.float16), 'model.layers.18.self_attn.k_proj.weight': tensor([[-0.0115,  0.0326, -0.0141,  ...,  0.0089, -0.0094, -0.0243],
        [ 0.0082, -0.0191,  0.0162,  ...,  0.0176,  0.0292,  0.0015],
        [ 0.0123, -0.0097, -0.0019,  ...,  0.0210, -0.0017,  0.0248],
        ...,
        [-0.1082, -0.0282, -0.0618,  ...,  0.0203, -0.0044, -0.0386],
        [ 0.0520,  0.0363, -0.0182,  ...,  0.0459,  0.0646, -0.0261],
        [-0.0487, -0.0503, -0.0435,  ...,  0.0343, -0.0235, -0.0319]],
       dtype=torch.float16), 'model.layers.18.self_attn.v_proj.weight': tensor([[-0.0296,  0.0286, -0.0176,  ...,  0.0053,  0.0276,  0.0051],
        [ 0.0173,  0.0070, -0.0124,  ..., -0.0175,  0.0382, -0.0023],
        [ 0.0001,  0.0193,  0.0009,  ...,  0.0046, -0.0021, -0.0077],
        ...,
        [ 0.0137,  0.0160, -0.0047,  ..., -0.0077, -0.0233,  0.0025],
        [ 0.0073, -0.0028,  0.0031,  ...,  0.0136,  0.0159,  0.0355],
        [-0.0068,  0.0012,  0.0111,  ..., -0.0062, -0.0200,  0.0024]],
       dtype=torch.float16), 'model.layers.18.self_attn.o_proj.weight': tensor([[-0.0180,  0.0188, -0.0144,  ...,  0.0118,  0.0222,  0.0198],
        [-0.0003, -0.0400,  0.0047,  ..., -0.0010, -0.0070, -0.0164],
        [ 0.0022, -0.0141,  0.0099,  ...,  0.0279,  0.0158,  0.0373],
        ...,
        [-0.0351, -0.0236, -0.0248,  ...,  0.0230,  0.0176, -0.0098],
        [ 0.0128,  0.0511,  0.0149,  ...,  0.0131, -0.0084, -0.0367],
        [-0.0119, -0.0472, -0.0218,  ..., -0.0158,  0.0139, -0.0140]],
       dtype=torch.float16), 'model.layers.18.mlp.gate_proj.weight': tensor([[ 0.0147, -0.0038,  0.0166,  ..., -0.0080,  0.0101, -0.0105],
        [-0.0428,  0.0071, -0.0162,  ..., -0.0086, -0.0150, -0.0096],
        [-0.0190,  0.0073,  0.0444,  ..., -0.0250,  0.0031,  0.0038],
        ...,
        [-0.0438, -0.0219, -0.0285,  ..., -0.0296, -0.0218, -0.0233],
        [ 0.0015,  0.0197,  0.0297,  ..., -0.0164, -0.0011,  0.0164],
        [ 0.0040, -0.0041,  0.0039,  ...,  0.0107, -0.0188, -0.0050]],
       dtype=torch.float16), 'model.layers.18.mlp.up_proj.weight': tensor([[ 0.0165,  0.0081,  0.0298,  ..., -0.0004,  0.0271, -0.0095],
        [-0.0201,  0.0243, -0.0282,  ..., -0.0057, -0.0087, -0.0003],
        [-0.0311, -0.0098,  0.0076,  ...,  0.0074,  0.0209,  0.0261],
        ...,
        [-0.0012,  0.0045,  0.0046,  ...,  0.0238, -0.0075,  0.0040],
        [-0.0094, -0.0048, -0.0210,  ...,  0.0134,  0.0343,  0.0362],
        [ 0.0087,  0.0248,  0.0111,  ..., -0.0163,  0.0135,  0.0152]],
       dtype=torch.float16), 'model.layers.18.mlp.down_proj.weight': tensor([[ 0.0152,  0.0034, -0.0323,  ...,  0.0311,  0.0165,  0.0073],
        [ 0.0117, -0.0078,  0.0196,  ...,  0.0007, -0.0016, -0.0021],
        [ 0.0172, -0.0250, -0.0335,  ...,  0.0177,  0.0036,  0.0148],
        ...,
        [-0.0127,  0.0210,  0.0102,  ...,  0.0230, -0.0081, -0.0087],
        [-0.0160,  0.0116,  0.0182,  ...,  0.0120,  0.0356,  0.0087],
        [-0.0091,  0.0257,  0.0244,  ..., -0.0073,  0.0167,  0.0157]],
       dtype=torch.float16), 'model.layers.18.input_layernorm.weight': tensor([0.4570, 0.4551, 0.4316,  ..., 0.4375, 0.4512, 0.4355],
       dtype=torch.float16), 'model.layers.18.post_attention_layernorm.weight': tensor([0.3477, 0.3340, 0.3320,  ..., 0.3477, 0.3496, 0.3457],
       dtype=torch.float16), 'model.layers.19.self_attn.q_proj.weight': tensor([[ 5.5275e-03,  7.6294e-03, -9.7961e-03,  ..., -1.0323e-02,
         -3.1209e-04,  8.8806e-03],
        [ 2.6894e-03, -2.5539e-03,  3.1719e-03,  ..., -4.7493e-03,
          2.9022e-02,  1.7868e-02],
        [ 5.2185e-03,  2.1896e-02,  4.5896e-05,  ...,  8.6498e-04,
          1.5182e-02,  3.0727e-03],
        ...,
        [-1.4160e-02, -1.4923e-02,  1.0290e-03,  ..., -4.4189e-02,
         -3.1805e-04,  2.4979e-02],
        [ 4.7226e-03,  4.8279e-02,  2.3041e-02,  ...,  5.4077e-02,
          2.9755e-02, -2.9358e-02],
        [-1.5991e-02,  4.9011e-02,  5.8014e-02,  ..., -6.6414e-03,
         -4.1382e-02, -1.4290e-02]], dtype=torch.float16), 'model.layers.19.self_attn.k_proj.weight': tensor([[ 0.0216,  0.0117,  0.0022,  ..., -0.0116, -0.0213, -0.0106],
        [-0.0142,  0.0180, -0.0159,  ...,  0.0100,  0.0034,  0.0251],
        [-0.0157,  0.0043, -0.0122,  ...,  0.0044,  0.0137,  0.0252],
        ...,
        [ 0.0005,  0.0502, -0.0095,  ..., -0.0208,  0.0299, -0.0225],
        [-0.0653, -0.0269, -0.0101,  ...,  0.0084,  0.0184, -0.0099],
        [-0.0202,  0.0115, -0.0150,  ..., -0.0266,  0.0129,  0.0399]],
       dtype=torch.float16), 'model.layers.19.self_attn.v_proj.weight': tensor([[-0.0011, -0.0055, -0.0055,  ..., -0.0020,  0.0005,  0.0070],
        [-0.0020,  0.0188, -0.0031,  ...,  0.0351, -0.0211,  0.0162],
        [-0.0448, -0.0359, -0.0080,  ..., -0.0085, -0.0002,  0.0056],
        ...,
        [ 0.0013, -0.0373, -0.0014,  ...,  0.0010, -0.0002, -0.0166],
        [ 0.0145, -0.0095, -0.0219,  ..., -0.0066, -0.0073, -0.0058],
        [-0.0033,  0.0275,  0.0008,  ..., -0.0254, -0.0120,  0.0062]],
       dtype=torch.float16), 'model.layers.19.self_attn.o_proj.weight': tensor([[ 0.0296, -0.0517,  0.0258,  ...,  0.0012,  0.0066, -0.0257],
        [ 0.0307, -0.0164, -0.0036,  ..., -0.0145, -0.0012, -0.0030],
        [-0.0033, -0.0176, -0.0195,  ...,  0.0010,  0.0150,  0.0012],
        ...,
        [ 0.0123, -0.0018,  0.0002,  ...,  0.0056, -0.0152,  0.0122],
        [ 0.0089, -0.0057, -0.0186,  ..., -0.0244, -0.0204,  0.0051],
        [ 0.0127,  0.0175,  0.0140,  ..., -0.0233, -0.0083,  0.0153]],
       dtype=torch.float16), 'model.layers.19.mlp.gate_proj.weight': tensor([[-0.0082,  0.0010,  0.0049,  ..., -0.0039,  0.0037, -0.0065],
        [ 0.0145,  0.0183,  0.0011,  ..., -0.0036,  0.0125, -0.0351],
        [-0.0169, -0.0121, -0.0127,  ..., -0.0433,  0.0002,  0.0285],
        ...,
        [-0.0016,  0.0101, -0.0004,  ..., -0.0291, -0.0092, -0.0010],
        [-0.0475, -0.0082,  0.0029,  ..., -0.0074, -0.0217,  0.0107],
        [-0.0205, -0.0197,  0.0153,  ...,  0.0069,  0.0052, -0.0020]],
       dtype=torch.float16), 'model.layers.19.mlp.up_proj.weight': tensor([[ 0.0020, -0.0107,  0.0096,  ...,  0.0065,  0.0100,  0.0032],
        [-0.0134, -0.0063, -0.0158,  ...,  0.0269, -0.0230, -0.0070],
        [ 0.0094,  0.0039,  0.0094,  ..., -0.0246, -0.0129,  0.0532],
        ...,
        [ 0.0142,  0.0140,  0.0074,  ...,  0.0136, -0.0170,  0.0311],
        [ 0.0013,  0.0262,  0.0249,  ..., -0.0094,  0.0361, -0.0004],
        [-0.0002, -0.0181, -0.0124,  ..., -0.0027,  0.0045,  0.0140]],
       dtype=torch.float16), 'model.layers.19.mlp.down_proj.weight': tensor([[-0.0026, -0.0278,  0.0015,  ...,  0.0057, -0.0235,  0.0278],
        [-0.0050, -0.0306, -0.0208,  ...,  0.0139,  0.0175, -0.0169],
        [-0.0209, -0.0261,  0.0290,  ...,  0.0159, -0.0008,  0.0071],
        ...,
        [-0.0104, -0.0050,  0.0274,  ...,  0.0129,  0.0162,  0.0012],
        [ 0.0065, -0.0093, -0.0501,  ...,  0.0219, -0.0086, -0.0152],
        [ 0.0041, -0.0093, -0.0342,  ...,  0.0006,  0.0090,  0.0042]],
       dtype=torch.float16), 'model.layers.19.input_layernorm.weight': tensor([0.4570, 0.4629, 0.4395,  ..., 0.4316, 0.4395, 0.4414],
       dtype=torch.float16), 'model.layers.19.post_attention_layernorm.weight': tensor([0.3613, 0.3477, 0.3457,  ..., 0.3574, 0.3555, 0.3594],
       dtype=torch.float16), 'model.layers.20.self_attn.q_proj.weight': tensor([[-3.3512e-03,  2.7599e-03,  2.2141e-02,  ...,  3.8643e-03,
          3.5381e-03, -2.3499e-02],
        [ 1.8127e-02, -2.1729e-02, -4.8876e-06,  ..., -6.9809e-03,
         -1.2131e-02,  1.7120e-02],
        [ 7.9117e-03, -6.8665e-03, -1.8326e-02,  ...,  1.7166e-02,
          7.0038e-03,  8.3780e-04],
        ...,
        [-3.1219e-02, -5.3162e-02,  1.0094e-02,  ..., -1.0918e-02,
          3.9520e-02,  1.1047e-02],
        [-8.0872e-02, -1.9455e-02,  1.1688e-02,  ...,  8.7585e-03,
          2.6505e-02,  8.3389e-03],
        [ 2.6978e-02,  2.4643e-03, -5.2071e-03,  ..., -1.9089e-02,
         -5.4512e-03, -1.3123e-03]], dtype=torch.float16), 'model.layers.20.self_attn.k_proj.weight': tensor([[-5.6038e-03,  7.3128e-03,  3.8834e-03,  ..., -1.6464e-02,
         -3.4750e-05,  3.6964e-03],
        [-3.7003e-04,  8.7585e-03,  4.4060e-03,  ..., -2.0161e-03,
          4.6120e-03,  1.1047e-02],
        [ 1.4694e-02,  2.8610e-03, -1.1185e-02,  ..., -1.5091e-02,
          1.4725e-03,  1.9836e-02],
        ...,
        [ 2.0256e-03,  4.9706e-03, -1.7044e-02,  ..., -2.3407e-02,
          2.5925e-02,  3.5919e-02],
        [-2.4094e-02,  2.4918e-02,  2.4490e-03,  ...,  2.1759e-02,
          3.0762e-02,  5.1605e-02],
        [-1.5228e-02, -3.0060e-02, -1.5793e-02,  ...,  2.0111e-02,
         -2.3468e-02,  5.2704e-02]], dtype=torch.float16), 'model.layers.20.self_attn.v_proj.weight': tensor([[-7.1526e-03, -1.8005e-02,  1.3290e-02,  ..., -2.7752e-03,
          1.9043e-02,  1.1086e-02],
        [-1.5945e-02, -3.7201e-02,  5.2223e-03,  ..., -1.2299e-02,
          3.4332e-04,  9.0942e-03],
        [-3.0174e-03, -1.3779e-02,  3.5763e-03,  ..., -2.5085e-02,
          9.9301e-05,  6.9046e-04],
        ...,
        [ 9.6893e-03, -1.2962e-02, -2.5940e-03,  ...,  2.4796e-02,
         -7.9269e-03,  9.0103e-03],
        [ 1.8799e-02,  1.4400e-03, -9.5062e-03,  ...,  8.0681e-04,
          1.1032e-02, -1.3542e-02],
        [ 2.3708e-03, -3.8452e-03,  2.4155e-02,  ..., -5.8403e-03,
         -1.1604e-02, -4.0283e-02]], dtype=torch.float16), 'model.layers.20.self_attn.o_proj.weight': tensor([[-0.0066,  0.0037,  0.0200,  ..., -0.0024,  0.0155, -0.0167],
        [ 0.0103, -0.0098, -0.0066,  ..., -0.0050, -0.0065,  0.0191],
        [ 0.0099, -0.0022, -0.0135,  ..., -0.0240,  0.0092,  0.0103],
        ...,
        [-0.0074, -0.0039,  0.0135,  ...,  0.0168, -0.0150,  0.0116],
        [-0.0101,  0.0031, -0.0113,  ...,  0.0121, -0.0273,  0.0036],
        [ 0.0107, -0.0183, -0.0039,  ...,  0.0065, -0.0230,  0.0195]],
       dtype=torch.float16), 'model.layers.20.mlp.gate_proj.weight': tensor([[ 0.0012, -0.0088, -0.0118,  ...,  0.0177, -0.0055,  0.0139],
        [-0.0275,  0.0091, -0.0060,  ..., -0.0098, -0.0143,  0.0149],
        [-0.0167, -0.0078,  0.0665,  ..., -0.0155,  0.0111, -0.0063],
        ...,
        [-0.0048, -0.0114,  0.0241,  ..., -0.0145,  0.0109, -0.0033],
        [ 0.0093,  0.0071,  0.0046,  ...,  0.0154,  0.0030,  0.0123],
        [-0.0032, -0.0308, -0.0070,  ...,  0.0059, -0.0142, -0.0134]],
       dtype=torch.float16), 'model.layers.20.mlp.up_proj.weight': tensor([[-0.0601, -0.0002, -0.0019,  ...,  0.0153, -0.0108, -0.0119],
        [-0.0098,  0.0006, -0.0098,  ..., -0.0502, -0.0143,  0.0372],
        [ 0.0060,  0.0302,  0.0182,  ...,  0.0070, -0.0175,  0.0047],
        ...,
        [-0.0139,  0.0211, -0.0016,  ..., -0.0180, -0.0043, -0.0030],
        [ 0.0155, -0.0318, -0.0148,  ...,  0.0031, -0.0208, -0.0377],
        [ 0.0145, -0.0241,  0.0311,  ..., -0.0039, -0.0222,  0.0036]],
       dtype=torch.float16), 'model.layers.20.mlp.down_proj.weight': tensor([[-0.0016,  0.0202, -0.0034,  ...,  0.0053, -0.0169, -0.0248],
        [ 0.0021,  0.0127, -0.0073,  ...,  0.0044, -0.0178,  0.0143],
        [-0.0127,  0.0180, -0.0242,  ..., -0.0042,  0.0238, -0.0053],
        ...,
        [-0.0375,  0.0276,  0.0056,  ...,  0.0026, -0.0002, -0.0114],
        [-0.0156,  0.0062, -0.0158,  ...,  0.0057,  0.0178, -0.0025],
        [ 0.0120, -0.0131,  0.0019,  ..., -0.0029, -0.0063, -0.0147]],
       dtype=torch.float16), 'model.layers.20.input_layernorm.weight': tensor([0.4590, 0.4688, 0.4395,  ..., 0.4414, 0.4375, 0.4590],
       dtype=torch.float16), 'model.layers.20.post_attention_layernorm.weight': tensor([0.3711, 0.3633, 0.3535,  ..., 0.3672, 0.3672, 0.3691],
       dtype=torch.float16), 'model.layers.21.self_attn.q_proj.weight': tensor([[-0.0138, -0.0057,  0.0144,  ..., -0.0153, -0.0030,  0.0070],
        [ 0.0252,  0.0060, -0.0012,  ...,  0.0031,  0.0002,  0.0141],
        [-0.0117, -0.0101,  0.0026,  ...,  0.0280,  0.0023,  0.0066],
        ...,
        [-0.0025, -0.0157,  0.0354,  ..., -0.0107, -0.0593,  0.0191],
        [-0.0115,  0.0166,  0.0210,  ...,  0.0295,  0.0328,  0.0014],
        [-0.0795, -0.0016, -0.0130,  ..., -0.0056,  0.0264, -0.0380]],
       dtype=torch.float16), 'model.layers.21.self_attn.k_proj.weight': tensor([[-1.3864e-04,  4.9858e-03, -3.4065e-03,  ...,  7.4348e-03,
          3.9625e-04,  1.0353e-02],
        [-8.3685e-05,  7.3128e-03,  1.9882e-02,  ...,  6.2561e-03,
          9.4681e-03,  8.8806e-03],
        [ 1.8494e-02,  2.9202e-03,  2.8900e-02,  ...,  1.5823e-02,
          1.2871e-02,  1.4816e-02],
        ...,
        [-1.8295e-02,  2.6428e-02,  1.5945e-03,  ...,  2.5818e-02,
         -1.9394e-02,  4.6265e-02],
        [ 2.0866e-03, -3.1281e-03, -1.4458e-02,  ..., -2.2232e-02,
          3.1250e-02,  1.6203e-03],
        [-1.8906e-02, -8.1329e-03, -3.1433e-02,  ...,  7.8888e-03,
         -7.5493e-03,  5.9235e-02]], dtype=torch.float16), 'model.layers.21.self_attn.v_proj.weight': tensor([[ 0.0032,  0.0054, -0.0003,  ...,  0.0005,  0.0223, -0.0286],
        [-0.0232,  0.0240, -0.0079,  ...,  0.0211, -0.0195,  0.0266],
        [ 0.0280, -0.0030,  0.0003,  ..., -0.0232,  0.0258, -0.0058],
        ...,
        [-0.0056, -0.0269,  0.0320,  ..., -0.0065,  0.0038, -0.0102],
        [-0.0154, -0.0090,  0.0156,  ...,  0.0048, -0.0052,  0.0086],
        [-0.0069,  0.0157, -0.0162,  ...,  0.0070, -0.0155, -0.0029]],
       dtype=torch.float16), 'model.layers.21.self_attn.o_proj.weight': tensor([[-0.0118, -0.0017,  0.0116,  ..., -0.0132,  0.0231,  0.0102],
        [-0.0058,  0.0267, -0.0098,  ..., -0.0189,  0.0061, -0.0112],
        [-0.0298, -0.0130,  0.0119,  ...,  0.0249,  0.0273,  0.0079],
        ...,
        [ 0.0198, -0.0042, -0.0136,  ...,  0.0248, -0.0006,  0.0144],
        [ 0.0152, -0.0136,  0.0135,  ..., -0.0006,  0.0018, -0.0185],
        [-0.0264,  0.0155, -0.0134,  ...,  0.0298, -0.0163,  0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.gate_proj.weight': tensor([[-0.0058, -0.0234,  0.0144,  ..., -0.0285,  0.0456,  0.0089],
        [ 0.0061,  0.0061,  0.0039,  ..., -0.0275,  0.0574,  0.0085],
        [ 0.0084,  0.0064,  0.0049,  ..., -0.0498,  0.0041, -0.0245],
        ...,
        [ 0.0102, -0.0292, -0.0215,  ...,  0.0331, -0.0270,  0.0024],
        [-0.0010,  0.0293,  0.0065,  ...,  0.0160, -0.0249,  0.0030],
        [ 0.0093, -0.0124, -0.0017,  ..., -0.0182,  0.0064, -0.0024]],
       dtype=torch.float16), 'model.layers.21.mlp.up_proj.weight': tensor([[ 0.0276, -0.0258, -0.0142,  ...,  0.0225,  0.0422, -0.0112],
        [-0.0261, -0.0107,  0.0040,  ...,  0.0379,  0.0453, -0.0010],
        [ 0.0133, -0.0011, -0.0018,  ...,  0.0067, -0.0079, -0.0061],
        ...,
        [-0.0461, -0.0002,  0.0137,  ...,  0.0162, -0.0095, -0.0118],
        [-0.0100, -0.0107,  0.0042,  ..., -0.0188, -0.0023,  0.0027],
        [-0.0051, -0.0337, -0.0248,  ..., -0.0035, -0.0055, -0.0260]],
       dtype=torch.float16), 'model.layers.21.mlp.down_proj.weight': tensor([[ 0.0117,  0.0132,  0.0028,  ...,  0.0198,  0.0068,  0.0062],
        [ 0.0095, -0.0029, -0.0151,  ...,  0.0037, -0.0319, -0.0163],
        [-0.0061,  0.0059,  0.0132,  ..., -0.0084,  0.0412,  0.0299],
        ...,
        [-0.0106,  0.0375,  0.0182,  ..., -0.0093, -0.0024,  0.0179],
        [ 0.0125,  0.0007, -0.0043,  ..., -0.0493, -0.0052,  0.0049],
        [ 0.0089,  0.0014,  0.0242,  ..., -0.0152,  0.0267, -0.0278]],
       dtype=torch.float16), 'model.layers.21.input_layernorm.weight': tensor([0.4805, 0.4883, 0.4688,  ..., 0.4609, 0.4805, 0.4824],
       dtype=torch.float16), 'model.layers.21.post_attention_layernorm.weight': tensor([0.3770, 0.3730, 0.3652,  ..., 0.3848, 0.3789, 0.3828],
       dtype=torch.float16), 'model.layers.22.self_attn.q_proj.weight': tensor([[-0.0249, -0.0096, -0.0046,  ...,  0.0535, -0.0391,  0.0201],
        [-0.0361, -0.0200, -0.0063,  ..., -0.0361,  0.0211, -0.0515],
        [-0.0322,  0.0232, -0.0146,  ...,  0.0286,  0.0173, -0.0100],
        ...,
        [ 0.0094,  0.0199,  0.0122,  ...,  0.0116,  0.0576, -0.0013],
        [-0.0323,  0.0064, -0.0220,  ...,  0.0465,  0.0088, -0.0131],
        [ 0.0380, -0.0125,  0.0065,  ..., -0.0505,  0.0111,  0.0195]],
       dtype=torch.float16), 'model.layers.22.self_attn.k_proj.weight': tensor([[-0.0130, -0.0065,  0.0037,  ...,  0.0139, -0.0164, -0.0157],
        [ 0.0106, -0.0099,  0.0312,  ..., -0.0320,  0.0375, -0.0140],
        [-0.0207,  0.0286, -0.0425,  ...,  0.0614,  0.0035, -0.0076],
        ...,
        [ 0.0210,  0.0074, -0.0286,  ..., -0.0204, -0.0135,  0.0172],
        [-0.0150, -0.0424,  0.0025,  ..., -0.0002, -0.0132, -0.0070],
        [ 0.0240, -0.0025,  0.0283,  ...,  0.0377, -0.0425,  0.0131]],
       dtype=torch.float16), 'model.layers.22.self_attn.v_proj.weight': tensor([[-0.0201,  0.0126, -0.0017,  ..., -0.0395, -0.0264,  0.0152],
        [-0.0346, -0.0108,  0.0072,  ..., -0.0269, -0.0413, -0.0159],
        [ 0.0243, -0.0267, -0.0040,  ...,  0.0528, -0.0026, -0.0139],
        ...,
        [-0.0104, -0.0462, -0.0226,  ...,  0.0124, -0.0114,  0.0218],
        [-0.0375, -0.0086,  0.0181,  ..., -0.0198,  0.0020, -0.0155],
        [ 0.0007,  0.0152, -0.0433,  ...,  0.0020, -0.0053,  0.0264]],
       dtype=torch.float16), 'model.layers.22.self_attn.o_proj.weight': tensor([[ 0.0263,  0.0156, -0.0218,  ..., -0.0026, -0.0353,  0.0123],
        [ 0.0242,  0.0126,  0.0108,  ...,  0.0045, -0.0100, -0.0247],
        [ 0.0046,  0.0026, -0.0081,  ..., -0.0232,  0.0110,  0.0107],
        ...,
        [-0.0008, -0.0238, -0.0129,  ..., -0.0138, -0.0166,  0.0042],
        [ 0.0259, -0.0104, -0.0196,  ..., -0.0260, -0.0027,  0.0137],
        [ 0.0039, -0.0258,  0.0213,  ...,  0.0115,  0.0122,  0.0111]],
       dtype=torch.float16), 'model.layers.22.mlp.gate_proj.weight': tensor([[-0.0284, -0.0156,  0.0184,  ...,  0.0108,  0.0197, -0.0452],
        [ 0.0226, -0.0165,  0.0014,  ...,  0.0043,  0.0029,  0.0221],
        [ 0.0005, -0.0069,  0.0054,  ...,  0.0142,  0.0002, -0.0003],
        ...,
        [-0.0043, -0.0079,  0.0014,  ..., -0.0152,  0.0073,  0.0022],
        [ 0.0095,  0.0165, -0.0293,  ..., -0.0035,  0.0127, -0.0289],
        [-0.0101,  0.0012,  0.0053,  ..., -0.0148,  0.0278,  0.0245]],
       dtype=torch.float16), 'model.layers.22.mlp.up_proj.weight': tensor([[ 0.0293,  0.0162, -0.0013,  ...,  0.0170,  0.0276,  0.0071],
        [ 0.0198,  0.0076,  0.0164,  ..., -0.0117, -0.0078,  0.0030],
        [ 0.0086, -0.0282, -0.0375,  ...,  0.0255,  0.0104,  0.0061],
        ...,
        [-0.0032, -0.0006, -0.0185,  ..., -0.0040,  0.0057,  0.0067],
        [ 0.0126, -0.0111, -0.0286,  ..., -0.0226,  0.0108, -0.0270],
        [-0.0014,  0.0023, -0.0036,  ..., -0.0440, -0.0598,  0.0154]],
       dtype=torch.float16), 'model.layers.22.mlp.down_proj.weight': tensor([[ 1.3527e-02, -5.1918e-03,  1.2299e-02,  ..., -1.8967e-02,
         -4.1428e-03, -3.6041e-02],
        [ 5.5885e-03,  2.6581e-02, -4.9362e-03,  ..., -1.1017e-02,
          1.4084e-02, -2.6627e-02],
        [-9.6512e-03,  3.9363e-04,  4.1962e-03,  ...,  1.2886e-02,
          4.5013e-03,  1.7517e-02],
        ...,
        [ 1.8250e-02, -8.5297e-03, -4.5288e-02,  ..., -2.8934e-03,
         -1.2947e-02, -1.7014e-02],
        [-1.1414e-02, -4.8767e-02,  1.1642e-02,  ...,  1.9028e-02,
         -2.7069e-02,  3.1433e-02],
        [ 1.4130e-02,  3.7551e-06, -3.1067e-02,  ..., -3.3903e-04,
         -1.8875e-02,  2.1286e-03]], dtype=torch.float16), 'model.layers.22.input_layernorm.weight': tensor([0.4883, 0.4922, 0.4805,  ..., 0.4688, 0.5000, 0.4902],
       dtype=torch.float16), 'model.layers.22.post_attention_layernorm.weight': tensor([0.3867, 0.3848, 0.3848,  ..., 0.3965, 0.3945, 0.3965],
       dtype=torch.float16), 'model.layers.23.self_attn.q_proj.weight': tensor([[-0.0039, -0.0179,  0.0076,  ..., -0.0155, -0.0002,  0.0023],
        [ 0.0042,  0.0015,  0.0140,  ..., -0.0166, -0.0002,  0.0083],
        [-0.0038,  0.0028,  0.0219,  ...,  0.0002, -0.0167,  0.0066],
        ...,
        [-0.0211,  0.0670,  0.0119,  ..., -0.0314, -0.0684, -0.0263],
        [-0.0411, -0.0311,  0.0199,  ..., -0.0232,  0.0020,  0.0060],
        [ 0.0047, -0.0559, -0.0093,  ...,  0.0072,  0.0403, -0.0026]],
       dtype=torch.float16), 'model.layers.23.self_attn.k_proj.weight': tensor([[-0.0030,  0.0121,  0.0090,  ...,  0.0010, -0.0083,  0.0059],
        [-0.0224,  0.0057, -0.0117,  ...,  0.0093,  0.0254,  0.0036],
        [ 0.0182,  0.0078, -0.0185,  ...,  0.0181,  0.0016, -0.0107],
        ...,
        [ 0.0067,  0.0374,  0.0580,  ..., -0.0332, -0.0120, -0.0131],
        [ 0.0034, -0.0352, -0.0113,  ..., -0.0232, -0.0226,  0.0194],
        [-0.0173, -0.0081, -0.0259,  ...,  0.0043,  0.0060, -0.0084]],
       dtype=torch.float16), 'model.layers.23.self_attn.v_proj.weight': tensor([[-0.0028,  0.0343, -0.0120,  ..., -0.0097, -0.0016, -0.0112],
        [-0.0093, -0.0038, -0.0190,  ..., -0.0033, -0.0097,  0.0105],
        [ 0.0111, -0.0211, -0.0208,  ...,  0.0130, -0.0508, -0.0305],
        ...,
        [ 0.0070,  0.0084,  0.0091,  ..., -0.0020,  0.0338,  0.0089],
        [ 0.0261,  0.0316, -0.0011,  ...,  0.0070,  0.0022, -0.0127],
        [-0.0201, -0.0131, -0.0540,  ...,  0.0057,  0.0076, -0.0381]],
       dtype=torch.float16), 'model.layers.23.self_attn.o_proj.weight': tensor([[-0.0019,  0.0019, -0.0202,  ..., -0.0179,  0.0104, -0.0070],
        [-0.0127, -0.0213, -0.0022,  ..., -0.0004,  0.0100, -0.0021],
        [ 0.0130,  0.0094,  0.0306,  ..., -0.0228, -0.0026, -0.0276],
        ...,
        [ 0.0290, -0.0114,  0.0348,  ..., -0.0162,  0.0113, -0.0013],
        [-0.0044,  0.0202, -0.0200,  ...,  0.0056, -0.0164,  0.0007],
        [ 0.0013, -0.0023, -0.0177,  ..., -0.0060,  0.0059, -0.0296]],
       dtype=torch.float16), 'model.layers.23.mlp.gate_proj.weight': tensor([[-1.1848e-02,  3.4424e-02, -1.0048e-02,  ..., -7.0152e-03,
          3.2776e-02,  9.2316e-03],
        [-1.4702e-02,  4.7729e-02, -1.7593e-02,  ...,  7.1678e-03,
         -1.8631e-02,  2.5070e-02],
        [-3.2349e-02,  1.4786e-02,  2.6913e-03,  ...,  1.5274e-02,
         -6.7444e-02,  1.2131e-02],
        ...,
        [-3.1548e-03,  1.9089e-02,  3.1509e-03,  ..., -8.1863e-03,
          7.2556e-03, -2.4643e-03],
        [-2.0828e-02,  3.8971e-02,  2.9430e-03,  ...,  3.3021e-05,
          7.8201e-03, -2.8381e-02],
        [ 8.8692e-04,  8.5144e-03,  1.6830e-02,  ..., -7.6561e-03,
          1.5450e-02, -1.6495e-02]], dtype=torch.float16), 'model.layers.23.mlp.up_proj.weight': tensor([[ 0.0283,  0.0066,  0.0351,  ...,  0.0134, -0.0322, -0.0074],
        [-0.0003,  0.0065, -0.0196,  ..., -0.0043, -0.0111,  0.0061],
        [-0.0177,  0.0038, -0.0218,  ...,  0.0182,  0.0106, -0.0052],
        ...,
        [-0.0084, -0.0166,  0.0116,  ...,  0.0093,  0.0408,  0.0053],
        [ 0.0036,  0.0078, -0.0382,  ...,  0.0106,  0.0070,  0.0220],
        [ 0.0014,  0.0079, -0.0071,  ...,  0.0070, -0.0126,  0.0127]],
       dtype=torch.float16), 'model.layers.23.mlp.down_proj.weight': tensor([[-0.0008,  0.0069, -0.0182,  ..., -0.0434, -0.0227,  0.0330],
        [-0.0012,  0.0231, -0.0064,  ...,  0.0257,  0.0306,  0.0021],
        [-0.0066, -0.0139, -0.0233,  ...,  0.0102,  0.0330, -0.0052],
        ...,
        [ 0.0001, -0.0050,  0.0135,  ...,  0.0180,  0.0037, -0.0187],
        [ 0.0296, -0.0114, -0.0007,  ..., -0.0026,  0.0101,  0.0058],
        [ 0.0031, -0.0307, -0.0152,  ..., -0.0104,  0.0204, -0.0025]],
       dtype=torch.float16), 'model.layers.23.input_layernorm.weight': tensor([0.5156, 0.5312, 0.5117,  ..., 0.5039, 0.5352, 0.5273],
       dtype=torch.float16), 'model.layers.23.post_attention_layernorm.weight': tensor([0.4043, 0.4023, 0.3965,  ..., 0.4043, 0.4121, 0.4062],
       dtype=torch.float16), 'model.layers.24.self_attn.q_proj.weight': tensor([[ 0.0204, -0.0176,  0.0145,  ...,  0.0364, -0.0300,  0.0106],
        [ 0.0215,  0.0088,  0.0012,  ..., -0.0026,  0.0186, -0.0139],
        [-0.0056, -0.0111, -0.0277,  ...,  0.0088, -0.0132,  0.0202],
        ...,
        [-0.0147,  0.0136, -0.0193,  ...,  0.0181, -0.0004, -0.0123],
        [-0.0288,  0.0078,  0.0070,  ...,  0.0100, -0.0323, -0.0062],
        [-0.0231, -0.0385, -0.0181,  ..., -0.0132,  0.0128,  0.0677]],
       dtype=torch.float16), 'model.layers.24.self_attn.k_proj.weight': tensor([[ 0.0235, -0.0035, -0.0125,  ...,  0.0110, -0.0008,  0.0021],
        [ 0.0118, -0.0169,  0.0035,  ..., -0.0216,  0.0245,  0.0066],
        [ 0.0097,  0.0045, -0.0445,  ...,  0.0204,  0.0171, -0.0175],
        ...,
        [ 0.0344,  0.0036,  0.0493,  ...,  0.0161,  0.0179, -0.0516],
        [-0.0119,  0.0177,  0.0127,  ...,  0.0320, -0.0181,  0.0027],
        [-0.0318, -0.0295, -0.0190,  ...,  0.0139, -0.0048,  0.0518]],
       dtype=torch.float16), 'model.layers.24.self_attn.v_proj.weight': tensor([[ 0.0212, -0.0251, -0.0028,  ..., -0.0041, -0.0040,  0.0113],
        [ 0.0288, -0.0173, -0.0054,  ..., -0.0646, -0.0470, -0.0240],
        [-0.0579, -0.0169, -0.0134,  ..., -0.0156, -0.0121, -0.0027],
        ...,
        [ 0.0011, -0.0192,  0.0171,  ...,  0.0272,  0.0067,  0.0217],
        [-0.0034, -0.0157, -0.0141,  ...,  0.0332, -0.0036,  0.0038],
        [ 0.0172,  0.0228,  0.0187,  ...,  0.0274, -0.0135, -0.0108]],
       dtype=torch.float16), 'model.layers.24.self_attn.o_proj.weight': tensor([[-0.0016,  0.0144,  0.0280,  ...,  0.0066, -0.0051, -0.0141],
        [-0.0118,  0.0308,  0.0156,  ...,  0.0195,  0.0282, -0.0186],
        [-0.0057, -0.0029,  0.0094,  ..., -0.0232,  0.0084, -0.0049],
        ...,
        [ 0.0045,  0.0179,  0.0119,  ..., -0.0027, -0.0031, -0.0005],
        [ 0.0508,  0.0096, -0.0061,  ...,  0.0075, -0.0257, -0.0106],
        [ 0.0026,  0.0155,  0.0109,  ...,  0.0046, -0.0261,  0.0131]],
       dtype=torch.float16), 'model.layers.24.mlp.gate_proj.weight': tensor([[-0.0267, -0.0104,  0.0093,  ..., -0.0031, -0.0058,  0.0011],
        [ 0.0075, -0.0302, -0.0231,  ...,  0.0075,  0.0110, -0.0131],
        [ 0.0014, -0.0466,  0.0257,  ...,  0.0015, -0.0532, -0.0207],
        ...,
        [ 0.0042, -0.0358, -0.0088,  ...,  0.0080,  0.0152, -0.0062],
        [ 0.0094,  0.0158,  0.0041,  ...,  0.0043,  0.0011,  0.0048],
        [-0.0410,  0.0326,  0.0009,  ...,  0.0294, -0.0074, -0.0473]],
       dtype=torch.float16), 'model.layers.24.mlp.up_proj.weight': tensor([[ 0.0016, -0.0057,  0.0201,  ...,  0.0262,  0.0025,  0.0263],
        [-0.0026,  0.0136, -0.0327,  ..., -0.0081, -0.0044, -0.0171],
        [ 0.0114, -0.0520,  0.0097,  ...,  0.0402,  0.0179, -0.0341],
        ...,
        [ 0.0115, -0.0207, -0.0147,  ..., -0.0067,  0.0112,  0.0111],
        [ 0.0412, -0.0033,  0.0132,  ...,  0.0025,  0.0054, -0.0100],
        [-0.0056, -0.0197,  0.0203,  ...,  0.0303,  0.0333,  0.0164]],
       dtype=torch.float16), 'model.layers.24.mlp.down_proj.weight': tensor([[-0.0052, -0.0114, -0.0357,  ...,  0.0015,  0.0022, -0.0194],
        [ 0.0278, -0.0030,  0.0175,  ..., -0.0015,  0.0048, -0.0508],
        [ 0.0195,  0.0135, -0.0284,  ...,  0.0095,  0.0215,  0.0078],
        ...,
        [-0.0092,  0.0149, -0.0204,  ..., -0.0330, -0.0109, -0.0146],
        [ 0.0112,  0.0248,  0.0120,  ...,  0.0257, -0.0255,  0.0133],
        [-0.0171, -0.0086,  0.0033,  ...,  0.0172, -0.0154, -0.0324]],
       dtype=torch.float16), 'model.layers.24.input_layernorm.weight': tensor([0.4980, 0.5273, 0.5195,  ..., 0.4863, 0.5234, 0.5156],
       dtype=torch.float16), 'model.layers.24.post_attention_layernorm.weight': tensor([0.4219, 0.4180, 0.4180,  ..., 0.4199, 0.4258, 0.4219],
       dtype=torch.float16), 'model.layers.25.self_attn.q_proj.weight': tensor([[ 1.7204e-03, -1.9974e-02, -2.5269e-02,  ...,  1.2192e-02,
         -9.5139e-03,  4.5357e-03],
        [-1.3947e-02,  3.5877e-03,  2.3804e-02,  ..., -1.4412e-02,
         -3.4485e-03,  2.4557e-05],
        [ 9.1629e-03,  8.6136e-03,  3.9368e-03,  ..., -1.1436e-02,
         -2.0157e-02, -1.5068e-02],
        ...,
        [ 5.5756e-02,  4.5746e-02,  2.2964e-03,  ...,  4.9858e-03,
          1.5762e-02, -2.6688e-02],
        [-6.3721e-02, -5.0293e-02, -1.2497e-02,  ..., -1.0338e-02,
         -2.1088e-02,  4.0932e-03],
        [ 3.9978e-02, -4.3365e-02, -2.2217e-02,  ...,  3.9279e-05,
          1.0757e-02, -2.6917e-02]], dtype=torch.float16), 'model.layers.25.self_attn.k_proj.weight': tensor([[-5.6648e-03, -1.3237e-02, -1.2611e-02,  ...,  1.5726e-03,
          1.6232e-03,  1.4572e-03],
        [-1.4183e-02, -1.4297e-02,  2.7120e-05,  ..., -3.4618e-03,
         -2.1515e-02,  7.6561e-03],
        [-8.5354e-04,  1.9426e-03,  4.9133e-03,  ...,  6.0310e-03,
         -6.0654e-03,  7.2212e-03],
        ...,
        [ 1.3847e-02,  4.8248e-02, -9.6283e-03,  ..., -5.4504e-02,
         -5.6427e-02,  3.7598e-02],
        [ 3.4454e-02, -3.4393e-02,  4.3602e-03,  ..., -8.3771e-03,
          2.8229e-03,  1.0277e-02],
        [-7.9346e-03, -2.7908e-02,  3.2768e-03,  ...,  3.6316e-02,
          8.8501e-03, -2.9388e-02]], dtype=torch.float16), 'model.layers.25.self_attn.v_proj.weight': tensor([[ 0.0173,  0.0201,  0.0084,  ...,  0.0248, -0.0133, -0.0128],
        [-0.0143, -0.0107,  0.0099,  ...,  0.0090, -0.0273, -0.0127],
        [-0.0150,  0.0164, -0.0202,  ..., -0.0099,  0.0054, -0.0090],
        ...,
        [-0.0186, -0.0324, -0.0026,  ...,  0.0150,  0.0097,  0.0189],
        [-0.0152,  0.0089,  0.0258,  ..., -0.0068,  0.0044, -0.0216],
        [-0.0386, -0.0105, -0.0145,  ...,  0.0065,  0.0192,  0.0297]],
       dtype=torch.float16), 'model.layers.25.self_attn.o_proj.weight': tensor([[ 1.9470e-02,  1.0475e-02,  1.3229e-02,  ...,  1.4595e-02,
          2.8362e-03,  3.7861e-03],
        [-2.6352e-02, -9.8953e-03, -1.6998e-02,  ...,  2.6093e-02,
         -7.1945e-03, -1.3523e-03],
        [-8.1863e-03, -1.5879e-03,  2.5925e-02,  ..., -1.9821e-02,
         -1.3336e-02, -1.3371e-03],
        ...,
        [-1.3893e-02,  2.3819e-02, -2.7676e-03,  ...,  1.0544e-02,
          1.3359e-02,  2.7084e-02],
        [-4.1842e-05, -2.7664e-02, -3.7750e-02,  ..., -2.3926e-02,
         -1.6037e-02,  2.2125e-03],
        [-2.4704e-02, -8.4839e-03, -1.3412e-02,  ..., -3.7964e-02,
         -2.0554e-02, -1.3344e-02]], dtype=torch.float16), 'model.layers.25.mlp.gate_proj.weight': tensor([[ 0.0037, -0.0402,  0.0397,  ..., -0.0020, -0.0228,  0.0070],
        [-0.0239, -0.0074, -0.0153,  ...,  0.0345,  0.0486,  0.0262],
        [-0.0017,  0.0171, -0.0012,  ...,  0.0176,  0.0161,  0.0310],
        ...,
        [-0.0347,  0.0086,  0.0019,  ..., -0.0027, -0.0130,  0.0004],
        [ 0.0218,  0.0088,  0.0610,  ...,  0.0170,  0.0224,  0.0062],
        [-0.0047, -0.0022, -0.0174,  ...,  0.0450,  0.0030, -0.0100]],
       dtype=torch.float16), 'model.layers.25.mlp.up_proj.weight': tensor([[-0.0265, -0.0114,  0.0169,  ...,  0.0016,  0.0052, -0.0100],
        [-0.0138, -0.0033,  0.0076,  ..., -0.0056,  0.0163,  0.0114],
        [ 0.0298,  0.0056,  0.0224,  ..., -0.0136, -0.0282, -0.0026],
        ...,
        [ 0.0102,  0.0049,  0.0475,  ...,  0.0056, -0.0394, -0.0210],
        [-0.0387, -0.0015, -0.0307,  ..., -0.0457, -0.0228, -0.0002],
        [-0.0147, -0.0097,  0.0229,  ...,  0.0258, -0.0055,  0.0242]],
       dtype=torch.float16), 'model.layers.25.mlp.down_proj.weight': tensor([[ 0.0289, -0.0159,  0.0110,  ...,  0.0204, -0.0067,  0.0310],
        [-0.0150, -0.0020,  0.0045,  ...,  0.0100, -0.0012,  0.0230],
        [ 0.0123,  0.0103, -0.0082,  ..., -0.0229,  0.0118, -0.0181],
        ...,
        [ 0.0188, -0.0142, -0.0232,  ..., -0.0466, -0.0010,  0.0237],
        [ 0.0065, -0.0114,  0.0031,  ...,  0.0045,  0.0039,  0.0058],
        [-0.0111, -0.0243,  0.0161,  ..., -0.0298, -0.0061, -0.0051]],
       dtype=torch.float16), 'model.layers.25.input_layernorm.weight': tensor([0.5547, 0.5703, 0.5547,  ..., 0.5547, 0.5742, 0.5625],
       dtype=torch.float16), 'model.layers.25.post_attention_layernorm.weight': tensor([0.4316, 0.4316, 0.4297,  ..., 0.4355, 0.4336, 0.4395],
       dtype=torch.float16), 'model.layers.26.self_attn.q_proj.weight': tensor([[ 0.0299, -0.0067, -0.0090,  ..., -0.0101,  0.0408,  0.0010],
        [-0.0050, -0.0182,  0.0142,  ...,  0.0062, -0.0230,  0.0177],
        [-0.0064,  0.0024,  0.0114,  ...,  0.0050, -0.0381, -0.0195],
        ...,
        [ 0.0009, -0.0125, -0.0078,  ...,  0.0158,  0.0216,  0.0021],
        [ 0.0070, -0.0182, -0.0230,  ...,  0.0060, -0.0005, -0.0075],
        [-0.0146,  0.0520,  0.0271,  ..., -0.0072, -0.0645, -0.0416]],
       dtype=torch.float16), 'model.layers.26.self_attn.k_proj.weight': tensor([[ 0.0220,  0.0199, -0.0121,  ..., -0.0308,  0.0384,  0.0029],
        [-0.0267,  0.0055,  0.0148,  ...,  0.0016,  0.0168,  0.0291],
        [ 0.0129,  0.0286,  0.0004,  ..., -0.0190, -0.0591, -0.0098],
        ...,
        [ 0.0247,  0.0246,  0.0012,  ..., -0.0466, -0.0545,  0.0259],
        [-0.0216, -0.0389, -0.0074,  ...,  0.0483,  0.0228, -0.0051],
        [-0.0171,  0.0094, -0.0132,  ...,  0.0006, -0.0198, -0.0154]],
       dtype=torch.float16), 'model.layers.26.self_attn.v_proj.weight': tensor([[ 0.0506, -0.0262, -0.0245,  ..., -0.0152,  0.0105, -0.0191],
        [-0.0491, -0.0213,  0.0254,  ...,  0.0101, -0.0062,  0.0016],
        [ 0.0013, -0.0020, -0.0238,  ..., -0.0061,  0.0042, -0.0306],
        ...,
        [-0.0236, -0.0176, -0.0008,  ...,  0.0428, -0.0050,  0.0086],
        [ 0.0039, -0.0365, -0.0094,  ..., -0.0166, -0.0242, -0.0042],
        [ 0.0092,  0.0188, -0.0045,  ...,  0.0071,  0.0064,  0.0172]],
       dtype=torch.float16), 'model.layers.26.self_attn.o_proj.weight': tensor([[ 0.0108, -0.0005, -0.0306,  ...,  0.0052,  0.0149,  0.0272],
        [ 0.0067,  0.0455,  0.0062,  ..., -0.0016,  0.0462, -0.0053],
        [ 0.0013,  0.0102, -0.0247,  ..., -0.0226,  0.0037, -0.0018],
        ...,
        [ 0.0307,  0.0040,  0.0108,  ..., -0.0002,  0.0182,  0.0043],
        [-0.0128,  0.0049, -0.0096,  ...,  0.0135, -0.0017, -0.0425],
        [ 0.0257,  0.0072,  0.0050,  ..., -0.0276,  0.0283, -0.0160]],
       dtype=torch.float16), 'model.layers.26.mlp.gate_proj.weight': tensor([[ 0.0187,  0.0045,  0.0131,  ...,  0.0258,  0.0262, -0.0261],
        [-0.0062,  0.0102, -0.0258,  ..., -0.0255, -0.0266,  0.0190],
        [ 0.0022, -0.0109,  0.0007,  ...,  0.0060,  0.0038, -0.0172],
        ...,
        [-0.0065,  0.0356, -0.0078,  ..., -0.0015, -0.0380, -0.0219],
        [-0.0150,  0.0138,  0.0250,  ...,  0.0159,  0.0240,  0.0123],
        [ 0.0182, -0.0038, -0.0058,  ..., -0.0301, -0.0062, -0.0043]],
       dtype=torch.float16), 'model.layers.26.mlp.up_proj.weight': tensor([[-0.0168,  0.0401,  0.0018,  ...,  0.0049, -0.0029, -0.0195],
        [-0.0410, -0.0193,  0.0116,  ...,  0.0265, -0.0069,  0.0175],
        [ 0.0082, -0.0065, -0.0241,  ...,  0.0146, -0.0218, -0.0152],
        ...,
        [ 0.0058, -0.0324,  0.0059,  ...,  0.0126,  0.0300, -0.0139],
        [-0.0445,  0.0100,  0.0505,  ...,  0.0299, -0.0133,  0.0091],
        [ 0.0003, -0.0191,  0.0266,  ..., -0.0121,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.layers.26.mlp.down_proj.weight': tensor([[-0.0157, -0.0151, -0.0184,  ...,  0.0317,  0.0165,  0.0026],
        [ 0.0194,  0.0122,  0.0013,  ...,  0.0555,  0.0187, -0.0188],
        [-0.0182,  0.0041, -0.0274,  ..., -0.0111,  0.0171,  0.0083],
        ...,
        [-0.0175, -0.0124, -0.0203,  ...,  0.0105,  0.0436, -0.0020],
        [-0.0128, -0.0142, -0.0195,  ...,  0.0095,  0.0033,  0.0230],
        [ 0.0049, -0.0129, -0.0006,  ...,  0.0101,  0.0221,  0.0164]],
       dtype=torch.float16), 'model.layers.26.input_layernorm.weight': tensor([0.5312, 0.5469, 0.5469,  ..., 0.5234, 0.5508, 0.5547],
       dtype=torch.float16), 'model.layers.26.post_attention_layernorm.weight': tensor([0.4492, 0.4492, 0.4375,  ..., 0.4512, 0.4590, 0.4590],
       dtype=torch.float16), 'model.layers.27.self_attn.q_proj.weight': tensor([[-0.0292,  0.0145,  0.0077,  ..., -0.0038,  0.0122,  0.0435],
        [-0.0134,  0.0433,  0.0299,  ..., -0.0242,  0.0111,  0.0059],
        [-0.0217, -0.0236,  0.0096,  ...,  0.0025, -0.0223,  0.0289],
        ...,
        [-0.0505,  0.0273, -0.0095,  ...,  0.0185, -0.0201, -0.0225],
        [-0.0039,  0.0271,  0.0072,  ...,  0.0084,  0.0002,  0.0258],
        [-0.0235, -0.0104,  0.0114,  ...,  0.0226,  0.0154, -0.0077]],
       dtype=torch.float16), 'model.layers.27.self_attn.k_proj.weight': tensor([[-0.0173, -0.0195,  0.0098,  ..., -0.0015, -0.0104,  0.0059],
        [-0.0029,  0.0090,  0.0194,  ...,  0.0424, -0.0081, -0.0110],
        [ 0.0017, -0.0138,  0.0081,  ..., -0.0129,  0.0021, -0.0088],
        ...,
        [-0.0041, -0.0153,  0.0362,  ...,  0.0069, -0.0344, -0.0087],
        [ 0.0248, -0.0192, -0.0473,  ...,  0.0660, -0.0128,  0.0439],
        [ 0.0315,  0.0143, -0.0021,  ..., -0.0374, -0.0376,  0.0114]],
       dtype=torch.float16), 'model.layers.27.self_attn.v_proj.weight': tensor([[ 0.0174, -0.0144, -0.0334,  ...,  0.0311,  0.0319, -0.0054],
        [ 0.0185,  0.0108,  0.0118,  ...,  0.0023, -0.0246,  0.0214],
        [-0.0263, -0.0055,  0.0169,  ..., -0.0106,  0.0546, -0.0242],
        ...,
        [ 0.0146, -0.0203, -0.0192,  ...,  0.0176, -0.0095, -0.0034],
        [ 0.0059, -0.0240, -0.0200,  ..., -0.0100, -0.0106, -0.0184],
        [ 0.0211, -0.0241, -0.0149,  ..., -0.0229, -0.0193,  0.0111]],
       dtype=torch.float16), 'model.layers.27.self_attn.o_proj.weight': tensor([[ 0.0038, -0.0119,  0.0095,  ...,  0.0242,  0.0067, -0.0269],
        [ 0.0054,  0.0286, -0.0241,  ..., -0.0172, -0.0162,  0.0058],
        [-0.0047, -0.0113, -0.0132,  ...,  0.0162,  0.0009, -0.0092],
        ...,
        [ 0.0251, -0.0114, -0.0128,  ...,  0.0111,  0.0484, -0.0008],
        [ 0.0368, -0.0221, -0.0091,  ..., -0.0011, -0.0006,  0.0184],
        [ 0.0446,  0.0125,  0.0281,  ..., -0.0113, -0.0002, -0.0220]],
       dtype=torch.float16), 'model.layers.27.mlp.gate_proj.weight': tensor([[ 0.0450,  0.0128, -0.0067,  ...,  0.0097,  0.0032, -0.0147],
        [-0.0158,  0.0018, -0.0322,  ...,  0.0303,  0.0333,  0.0226],
        [ 0.0075,  0.0203, -0.0080,  ..., -0.0125, -0.0238,  0.0320],
        ...,
        [ 0.0358,  0.0211,  0.0024,  ..., -0.0008,  0.0165, -0.0047],
        [-0.0144,  0.0255, -0.0209,  ..., -0.0090, -0.0178,  0.0073],
        [ 0.0026, -0.0184, -0.0149,  ..., -0.0166, -0.0047, -0.0048]],
       dtype=torch.float16), 'model.layers.27.mlp.up_proj.weight': tensor([[-0.0049,  0.0078,  0.0265,  ..., -0.0012,  0.0131, -0.0389],
        [-0.0102,  0.0028, -0.0278,  ...,  0.0119, -0.0223, -0.0237],
        [ 0.0258,  0.0162,  0.0435,  ...,  0.0278,  0.0015, -0.0196],
        ...,
        [-0.0044,  0.0250,  0.0330,  ..., -0.0218,  0.0206, -0.0381],
        [ 0.0097,  0.0212,  0.0149,  ...,  0.0130, -0.0131, -0.0248],
        [-0.0111,  0.0048, -0.0053,  ..., -0.0063, -0.0244, -0.0093]],
       dtype=torch.float16), 'model.layers.27.mlp.down_proj.weight': tensor([[ 2.4376e-03, -2.2705e-02,  3.4363e-02,  ..., -1.9394e-02,
          1.9669e-02, -1.1414e-02],
        [ 8.0466e-05,  1.3931e-02, -9.4910e-03,  ..., -1.9272e-02,
         -3.1616e-02,  1.2093e-02],
        [ 4.6478e-02,  1.3847e-02,  5.7602e-03,  ..., -3.2166e-02,
          4.1733e-03,  2.9587e-02],
        ...,
        [-7.6523e-03,  1.0971e-02,  1.5335e-02,  ...,  7.5302e-03,
         -4.5685e-02,  2.5742e-02],
        [-2.2018e-02, -3.3932e-03, -1.7227e-02,  ...,  2.2934e-02,
         -9.0866e-03,  2.0813e-02],
        [ 4.7493e-03,  1.7471e-02, -9.1858e-03,  ...,  1.9531e-02,
         -2.3441e-03, -4.7493e-03]], dtype=torch.float16), 'model.layers.27.input_layernorm.weight': tensor([0.5625, 0.5625, 0.5586,  ..., 0.5547, 0.5625, 0.5703],
       dtype=torch.float16), 'model.layers.27.post_attention_layernorm.weight': tensor([0.4688, 0.4629, 0.4531,  ..., 0.4668, 0.4707, 0.4688],
       dtype=torch.float16), 'model.layers.28.self_attn.q_proj.weight': tensor([[-3.2127e-05, -1.9119e-02, -7.1669e-04,  ..., -1.4694e-02,
         -9.0561e-03, -1.0872e-02],
        [ 1.1421e-02, -1.8387e-02, -2.4986e-03,  ...,  1.3634e-02,
          5.4283e-03, -3.9635e-03],
        [ 1.4305e-02,  6.4993e-04, -1.0948e-02,  ..., -3.7956e-03,
         -2.4414e-02,  2.4261e-02],
        ...,
        [-1.1253e-02,  2.4719e-02, -5.3101e-02,  ...,  1.6006e-02,
         -7.5684e-03, -3.9825e-02],
        [ 1.6541e-02, -2.6855e-02, -1.2665e-02,  ...,  2.0569e-02,
          3.2928e-02, -6.5002e-02],
        [ 1.9409e-02,  1.4633e-02, -4.5654e-02,  ...,  4.5868e-02,
          1.4122e-02, -3.6987e-02]], dtype=torch.float16), 'model.layers.28.self_attn.k_proj.weight': tensor([[-0.0036, -0.0034,  0.0078,  ..., -0.0043,  0.0148, -0.0134],
        [-0.0133, -0.0068, -0.0168,  ..., -0.0066,  0.0050,  0.0043],
        [ 0.0061,  0.0063, -0.0146,  ..., -0.0197, -0.0112,  0.0050],
        ...,
        [-0.0251, -0.0133, -0.0040,  ..., -0.0014, -0.0604, -0.0040],
        [ 0.0462, -0.0221,  0.0039,  ...,  0.0161,  0.0397,  0.0285],
        [ 0.0180, -0.0042,  0.0045,  ..., -0.0038, -0.0185, -0.0136]],
       dtype=torch.float16), 'model.layers.28.self_attn.v_proj.weight': tensor([[-0.0240,  0.0090,  0.0227,  ..., -0.0210, -0.0288,  0.0260],
        [ 0.0231, -0.0178, -0.0135,  ..., -0.0447,  0.0313, -0.0163],
        [-0.0102,  0.0174, -0.0021,  ...,  0.0075, -0.0479,  0.0167],
        ...,
        [ 0.0193,  0.0043, -0.0005,  ...,  0.0143, -0.0064, -0.0217],
        [ 0.0511,  0.0041,  0.0421,  ...,  0.0019,  0.0046, -0.0031],
        [ 0.0181,  0.0192, -0.0485,  ...,  0.0328, -0.0048,  0.0090]],
       dtype=torch.float16), 'model.layers.28.self_attn.o_proj.weight': tensor([[ 1.1208e-02,  2.4567e-02, -4.1473e-02,  ..., -3.4485e-02,
          1.7929e-02, -9.8646e-05],
        [-1.2238e-02, -2.0905e-02, -2.8381e-03,  ..., -1.7075e-02,
          2.7145e-02,  3.2501e-02],
        [ 2.7863e-02,  1.7838e-02, -5.3741e-02,  ...,  2.2293e-02,
          1.5701e-02, -1.6464e-02],
        ...,
        [ 2.5444e-03, -4.4098e-03,  3.4332e-02,  ..., -9.8801e-03,
         -3.9917e-02, -6.6757e-03],
        [-7.5188e-03, -5.8655e-02, -1.8112e-02,  ...,  2.0889e-02,
         -2.8183e-02, -2.7084e-02],
        [-4.3823e-02, -4.1618e-03, -1.0742e-02,  ..., -1.9196e-02,
         -8.0719e-03,  4.2839e-03]], dtype=torch.float16), 'model.layers.28.mlp.gate_proj.weight': tensor([[-0.0007,  0.0031, -0.0068,  ...,  0.0274, -0.0111,  0.0312],
        [-0.0257,  0.0139, -0.0106,  ...,  0.0121,  0.0034,  0.0177],
        [ 0.0099,  0.0288,  0.0274,  ...,  0.0168,  0.0038,  0.0067],
        ...,
        [-0.0053,  0.0228,  0.0102,  ...,  0.0135,  0.0128, -0.0202],
        [ 0.0124, -0.0344, -0.0104,  ..., -0.0197, -0.0044, -0.0032],
        [-0.0318,  0.0149,  0.0106,  ..., -0.0078, -0.0112,  0.0179]],
       dtype=torch.float16), 'model.layers.28.mlp.up_proj.weight': tensor([[ 0.0224,  0.0047,  0.0220,  ...,  0.0277,  0.0156,  0.0114],
        [-0.0177, -0.0260, -0.0041,  ..., -0.0033, -0.0355, -0.0220],
        [ 0.0064,  0.0259, -0.0073,  ...,  0.0068,  0.0073, -0.0160],
        ...,
        [-0.0055, -0.0151,  0.0324,  ..., -0.0026,  0.0111, -0.0013],
        [-0.0215,  0.0078, -0.0074,  ...,  0.0127, -0.0099, -0.0497],
        [-0.0093, -0.0252, -0.0048,  ..., -0.0067,  0.0076,  0.0080]],
       dtype=torch.float16), 'model.layers.28.mlp.down_proj.weight': tensor([[ 0.0077,  0.0342, -0.0055,  ...,  0.0029, -0.0016, -0.0298],
        [-0.0009, -0.0338,  0.0198,  ..., -0.0268, -0.0070, -0.0280],
        [-0.0241,  0.0253, -0.0140,  ...,  0.0032,  0.0074, -0.0012],
        ...,
        [ 0.0106, -0.0143, -0.0053,  ..., -0.0309, -0.0309,  0.0070],
        [-0.0170, -0.0194,  0.0628,  ..., -0.0242, -0.0061,  0.0128],
        [-0.0234,  0.0108, -0.0081,  ...,  0.0294,  0.0295, -0.0142]],
       dtype=torch.float16), 'model.layers.28.input_layernorm.weight': tensor([0.5781, 0.5859, 0.5664,  ..., 0.5547, 0.5742, 0.5742],
       dtype=torch.float16), 'model.layers.28.post_attention_layernorm.weight': tensor([0.4805, 0.4785, 0.4648,  ..., 0.4785, 0.4727, 0.4727],
       dtype=torch.float16), 'model.layers.29.self_attn.q_proj.weight': tensor([[ 0.0060,  0.0026, -0.0075,  ...,  0.0002, -0.0110,  0.0094],
        [-0.0288, -0.0180, -0.0257,  ..., -0.0128, -0.0063, -0.0059],
        [-0.0291,  0.0377, -0.0024,  ..., -0.0022, -0.0156,  0.0146],
        ...,
        [ 0.0005,  0.0704, -0.0331,  ...,  0.0133, -0.0080, -0.0352],
        [-0.0236, -0.0242,  0.0169,  ..., -0.0142, -0.0230,  0.0260],
        [ 0.0005, -0.0416, -0.0127,  ...,  0.0132,  0.0065, -0.0391]],
       dtype=torch.float16), 'model.layers.29.self_attn.k_proj.weight': tensor([[ 0.0357, -0.0135, -0.0162,  ...,  0.0005,  0.0101, -0.0023],
        [-0.0177,  0.0316, -0.0048,  ..., -0.0086,  0.0006, -0.0218],
        [ 0.0214,  0.0079,  0.0186,  ...,  0.0193,  0.0339, -0.0014],
        ...,
        [-0.0317,  0.0448,  0.0010,  ..., -0.0091,  0.0024, -0.0117],
        [ 0.0014, -0.0123, -0.0701,  ..., -0.0106, -0.0095, -0.0427],
        [ 0.0107, -0.0124, -0.0583,  ..., -0.0584, -0.0144,  0.0027]],
       dtype=torch.float16), 'model.layers.29.self_attn.v_proj.weight': tensor([[ 0.0110,  0.0064,  0.0324,  ...,  0.0194,  0.0085,  0.0135],
        [-0.0017,  0.0247,  0.0385,  ..., -0.0199,  0.0092, -0.0022],
        [-0.0130,  0.0104, -0.0103,  ...,  0.0083,  0.0268,  0.0188],
        ...,
        [ 0.0067,  0.0294,  0.0116,  ..., -0.0203, -0.0125, -0.0172],
        [ 0.0001,  0.0276, -0.0236,  ...,  0.0186,  0.0294, -0.0053],
        [-0.0033, -0.0211,  0.0092,  ..., -0.0019, -0.0083,  0.0262]],
       dtype=torch.float16), 'model.layers.29.self_attn.o_proj.weight': tensor([[-6.3057e-03,  3.2288e-02,  3.3630e-02,  ...,  5.8222e-04,
         -1.7517e-02, -6.4850e-03],
        [-2.0340e-02, -2.5772e-02, -1.2833e-02,  ...,  1.2199e-02,
         -2.8244e-02,  1.2634e-02],
        [ 2.6093e-02,  2.8381e-02, -8.5678e-03,  ..., -3.7781e-02,
          1.7441e-02, -2.1240e-02],
        ...,
        [-2.8381e-02, -1.6617e-02,  2.8061e-02,  ..., -7.0839e-03,
         -7.8201e-03, -1.4076e-02],
        [-1.3969e-02, -1.0399e-02,  3.3966e-02,  ..., -4.7803e-05,
         -2.0554e-02,  4.7226e-03],
        [ 1.5411e-02,  3.9749e-03, -3.4275e-03,  ...,  4.1122e-03,
          1.9104e-02, -2.8473e-02]], dtype=torch.float16), 'model.layers.29.mlp.gate_proj.weight': tensor([[ 0.0161,  0.0169, -0.0145,  ..., -0.0036, -0.0243,  0.0359],
        [ 0.0034,  0.0243, -0.0081,  ..., -0.0228,  0.0151,  0.0046],
        [ 0.0371, -0.0013, -0.0085,  ..., -0.0063,  0.0206,  0.0335],
        ...,
        [-0.0048,  0.0104, -0.0152,  ...,  0.0026,  0.0065,  0.0039],
        [ 0.0079,  0.0031, -0.0292,  ..., -0.0222, -0.0051,  0.0174],
        [-0.0031,  0.0190, -0.0012,  ...,  0.0228, -0.0130, -0.0158]],
       dtype=torch.float16), 'model.layers.29.mlp.up_proj.weight': tensor([[-0.0069,  0.0021,  0.0118,  ...,  0.0150,  0.0049,  0.0057],
        [ 0.0012,  0.0072,  0.0320,  ...,  0.0089, -0.0199,  0.0363],
        [-0.0076, -0.0212, -0.0125,  ..., -0.0495,  0.0085, -0.0360],
        ...,
        [ 0.0260,  0.0129,  0.0126,  ...,  0.0124,  0.0245,  0.0357],
        [-0.0250, -0.0191, -0.0051,  ...,  0.0142,  0.0133,  0.0017],
        [ 0.0065, -0.0030,  0.0111,  ..., -0.0080,  0.0094,  0.0100]],
       dtype=torch.float16), 'model.layers.29.mlp.down_proj.weight': tensor([[ 0.0411,  0.0098, -0.0018,  ...,  0.0168, -0.0244, -0.0152],
        [ 0.0184,  0.0098,  0.0223,  ...,  0.0344,  0.0027,  0.0017],
        [ 0.0008, -0.0209, -0.0160,  ..., -0.0007,  0.0110, -0.0271],
        ...,
        [ 0.0088, -0.0090,  0.0057,  ..., -0.0189, -0.0051, -0.0197],
        [ 0.0228,  0.0159,  0.0265,  ...,  0.0094, -0.0411,  0.0024],
        [ 0.0148, -0.0185, -0.0088,  ..., -0.0158, -0.0135,  0.0045]],
       dtype=torch.float16), 'model.layers.29.input_layernorm.weight': tensor([0.5430, 0.5586, 0.5391,  ..., 0.5312, 0.5586, 0.5625],
       dtype=torch.float16), 'model.layers.29.post_attention_layernorm.weight': tensor([0.4902, 0.4922, 0.4785,  ..., 0.4785, 0.4922, 0.4805],
       dtype=torch.float16), 'model.layers.30.self_attn.q_proj.weight': tensor([[-0.0041, -0.0047,  0.0075,  ..., -0.0091, -0.0045,  0.0028],
        [ 0.0163,  0.0142,  0.0050,  ..., -0.0033, -0.0027, -0.0191],
        [-0.0086, -0.0204,  0.0428,  ...,  0.0224,  0.0053, -0.0305],
        ...,
        [-0.0093, -0.0009, -0.0012,  ...,  0.0209, -0.0119,  0.0017],
        [-0.0005, -0.0218, -0.0206,  ...,  0.0153,  0.0086, -0.0354],
        [-0.0708, -0.0093,  0.0420,  ..., -0.0094, -0.0046, -0.0015]],
       dtype=torch.float16), 'model.layers.30.self_attn.k_proj.weight': tensor([[ 0.0262, -0.0208,  0.0015,  ..., -0.0112,  0.0095,  0.0076],
        [ 0.0337,  0.0127,  0.0035,  ..., -0.0041, -0.0045,  0.0022],
        [-0.0044, -0.0148,  0.0216,  ...,  0.0055, -0.0088, -0.0004],
        ...,
        [ 0.0057,  0.0255,  0.0007,  ...,  0.0564, -0.0037, -0.0002],
        [ 0.0107, -0.0630,  0.0325,  ...,  0.0062, -0.0082, -0.0273],
        [-0.0373, -0.0082,  0.0209,  ...,  0.0079,  0.0169, -0.0247]],
       dtype=torch.float16), 'model.layers.30.self_attn.v_proj.weight': tensor([[-0.0035, -0.0291,  0.0310,  ..., -0.0268, -0.0363,  0.0307],
        [ 0.0073,  0.0172,  0.0300,  ..., -0.0118,  0.0262,  0.0019],
        [-0.0203,  0.0174, -0.0189,  ...,  0.0050, -0.0255, -0.0103],
        ...,
        [ 0.0184, -0.0039, -0.0030,  ..., -0.0245,  0.0030,  0.0241],
        [-0.0072, -0.0434,  0.0219,  ...,  0.0296, -0.0089,  0.0216],
        [-0.0088,  0.0059,  0.0193,  ..., -0.0144, -0.0613, -0.0227]],
       dtype=torch.float16), 'model.layers.30.self_attn.o_proj.weight': tensor([[-0.0074,  0.0176, -0.0070,  ...,  0.0119, -0.0119, -0.0202],
        [-0.0116, -0.0252, -0.0082,  ...,  0.0136, -0.0305, -0.0236],
        [-0.0294, -0.0029,  0.0179,  ..., -0.0482, -0.0128, -0.0113],
        ...,
        [ 0.0068,  0.0052,  0.0028,  ..., -0.0247,  0.0106,  0.0177],
        [ 0.0227, -0.0089,  0.0036,  ...,  0.0353, -0.0069,  0.0047],
        [-0.0028,  0.0133, -0.0032,  ..., -0.0048,  0.0101, -0.0147]],
       dtype=torch.float16), 'model.layers.30.mlp.gate_proj.weight': tensor([[-0.0422, -0.0289, -0.0057,  ...,  0.0138, -0.0067, -0.0003],
        [-0.0175,  0.0047,  0.0389,  ..., -0.0063, -0.0058,  0.0305],
        [-0.0219, -0.0067, -0.0307,  ...,  0.0154, -0.0004, -0.0035],
        ...,
        [-0.0204, -0.0261,  0.0121,  ..., -0.0081, -0.0219, -0.0244],
        [ 0.0268,  0.0282, -0.0097,  ...,  0.0118, -0.0396, -0.0025],
        [-0.0012, -0.0307, -0.0203,  ..., -0.0023,  0.0182, -0.0061]],
       dtype=torch.float16), 'model.layers.30.mlp.up_proj.weight': tensor([[ 0.0034,  0.0162,  0.0123,  ...,  0.0126,  0.0213, -0.0029],
        [-0.0196, -0.0118,  0.0388,  ...,  0.0008, -0.0193, -0.0033],
        [-0.0327, -0.0235, -0.0368,  ..., -0.0176,  0.0011,  0.0209],
        ...,
        [-0.0163, -0.0128,  0.0153,  ...,  0.0128, -0.0097, -0.0216],
        [-0.0081,  0.0077, -0.0097,  ...,  0.0053, -0.0229,  0.0164],
        [-0.0030, -0.0283,  0.0003,  ..., -0.0168,  0.0070,  0.0171]],
       dtype=torch.float16), 'model.layers.30.mlp.down_proj.weight': tensor([[ 2.2812e-02, -1.3634e-02, -3.0258e-02,  ...,  3.1342e-02,
         -7.2098e-03, -8.8263e-04],
        [ 2.5818e-02,  4.8409e-03,  4.3427e-02,  ...,  1.2611e-02,
          1.6594e-03, -7.8888e-03],
        [ 3.6883e-04, -3.0899e-03, -2.1591e-02,  ...,  3.1242e-03,
          1.0376e-02,  2.0767e-02],
        ...,
        [-3.1921e-02,  6.3400e-03, -2.4643e-02,  ...,  1.8341e-02,
         -2.4780e-02, -9.6664e-03],
        [-4.3750e-05, -1.9287e-02,  2.8934e-03,  ...,  1.9730e-02,
          2.3232e-03,  1.2312e-03],
        [-8.7738e-03, -1.4030e-02, -2.5955e-02,  ...,  1.0109e-02,
          3.0589e-04, -1.9150e-02]], dtype=torch.float16), 'model.layers.30.input_layernorm.weight': tensor([0.5859, 0.6016, 0.5664,  ..., 0.5586, 0.5781, 0.6016],
       dtype=torch.float16), 'model.layers.30.post_attention_layernorm.weight': tensor([0.4824, 0.5039, 0.4824,  ..., 0.4883, 0.4980, 0.4863],
       dtype=torch.float16), 'model.layers.31.self_attn.q_proj.weight': tensor([[-0.0350,  0.0179,  0.0228,  ...,  0.0133, -0.0005, -0.0199],
        [-0.0200, -0.0252, -0.0369,  ...,  0.0008, -0.0122, -0.0238],
        [-0.0219,  0.0272,  0.0192,  ..., -0.0004,  0.0037,  0.0022],
        ...,
        [ 0.0171, -0.0177, -0.0151,  ..., -0.0145,  0.0273, -0.0253],
        [-0.0265,  0.0056, -0.0053,  ..., -0.0029,  0.0124,  0.0107],
        [-0.0533, -0.0123,  0.0282,  ...,  0.0389, -0.0044,  0.0329]],
       dtype=torch.float16), 'model.layers.31.self_attn.k_proj.weight': tensor([[-0.0058, -0.0082,  0.0132,  ..., -0.0011, -0.0107, -0.0206],
        [ 0.0245, -0.0202,  0.0109,  ..., -0.0002,  0.0066, -0.0021],
        [ 0.0027,  0.0117, -0.0064,  ...,  0.0055, -0.0005, -0.0275],
        ...,
        [ 0.0315, -0.0261, -0.0244,  ..., -0.0081, -0.0101, -0.0515],
        [ 0.0134,  0.0200,  0.0124,  ..., -0.0259, -0.0236,  0.0204],
        [-0.0787, -0.0352,  0.0162,  ..., -0.0131,  0.0023, -0.0065]],
       dtype=torch.float16), 'model.layers.31.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0230, -0.0018,  ...,  0.0031,  0.0012,  0.0155],
        [ 0.0281,  0.0153,  0.0112,  ...,  0.0094,  0.0336,  0.0164],
        [ 0.0143, -0.0011, -0.0159,  ...,  0.0129,  0.0024,  0.0344],
        ...,
        [-0.0017, -0.0013, -0.0144,  ..., -0.0160, -0.0032,  0.0248],
        [ 0.0126, -0.0183,  0.0156,  ..., -0.0102, -0.0292,  0.0144],
        [-0.0103, -0.0228,  0.0264,  ...,  0.0243, -0.0042,  0.0403]],
       dtype=torch.float16), 'model.layers.31.self_attn.o_proj.weight': tensor([[ 0.0089,  0.0304, -0.0052,  ..., -0.0004, -0.0148, -0.0504],
        [-0.0065,  0.0034, -0.0314,  ...,  0.0269, -0.0200, -0.0146],
        [ 0.0102,  0.0023,  0.0032,  ..., -0.0174,  0.0214,  0.0120],
        ...,
        [ 0.0077, -0.0209,  0.0315,  ..., -0.0161, -0.0128, -0.0216],
        [ 0.0010,  0.0138, -0.0207,  ..., -0.0174, -0.0141, -0.0177],
        [ 0.0062,  0.0165, -0.0088,  ...,  0.0295, -0.0164,  0.0075]],
       dtype=torch.float16), 'model.layers.31.mlp.gate_proj.weight': tensor([[ 0.0088, -0.0101,  0.0378,  ...,  0.0157,  0.0179,  0.0108],
        [-0.0751, -0.0179,  0.0038,  ...,  0.0049, -0.0193,  0.0181],
        [ 0.0142,  0.0066, -0.0107,  ..., -0.0041, -0.0197, -0.0075],
        ...,
        [-0.0168, -0.0297,  0.0126,  ..., -0.0009,  0.0242,  0.0329],
        [ 0.0417,  0.0298, -0.0222,  ...,  0.0354, -0.0096, -0.0061],
        [ 0.0174, -0.0382, -0.0287,  ..., -0.0177,  0.0085,  0.0057]],
       dtype=torch.float16), 'model.layers.31.mlp.up_proj.weight': tensor([[-0.0397, -0.0182,  0.0206,  ...,  0.0010, -0.0187,  0.0024],
        [ 0.0275,  0.0354,  0.0046,  ..., -0.0228,  0.0012, -0.0013],
        [-0.0043,  0.0044, -0.0210,  ...,  0.0143,  0.0034, -0.0117],
        ...,
        [ 0.0134, -0.0182,  0.0072,  ...,  0.0026,  0.0326, -0.0186],
        [ 0.0055,  0.0044, -0.0258,  ...,  0.0280,  0.0101, -0.0022],
        [ 0.0409, -0.0411, -0.0085,  ..., -0.0104,  0.0099,  0.0237]],
       dtype=torch.float16), 'model.layers.31.mlp.down_proj.weight': tensor([[-1.2767e-04, -2.5101e-02, -9.8572e-03,  ..., -3.8147e-02,
         -1.4954e-02,  2.7756e-02],
        [ 3.8208e-02,  3.5248e-03, -3.6736e-03,  ..., -5.2691e-04,
         -1.6205e-02,  1.3901e-02],
        [-1.2566e-02, -1.2192e-02,  2.5131e-02,  ...,  3.0304e-02,
         -1.5383e-03,  2.3193e-02],
        ...,
        [ 4.7088e-05,  2.8351e-02, -2.0237e-03,  ...,  1.1597e-02,
          5.3177e-03,  1.7136e-02],
        [-9.8515e-04,  4.7424e-02, -5.3787e-03,  ..., -7.3509e-03,
          2.3331e-02,  1.7090e-02],
        [ 2.6001e-02, -3.8910e-02,  1.8829e-02,  ...,  4.1313e-03,
          1.2999e-03,  2.6016e-02]], dtype=torch.float16), 'model.layers.31.input_layernorm.weight': tensor([0.4961, 0.4980, 0.4453,  ..., 0.4375, 0.4727, 0.4922],
       dtype=torch.float16), 'model.layers.31.post_attention_layernorm.weight': tensor([0.4414, 0.4434, 0.4531,  ..., 0.4336, 0.4219, 0.4375],
       dtype=torch.float16), 'model.norm.weight': tensor([2.0000, 2.0469, 1.9453,  ..., 1.8594, 1.9453, 1.7656],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding': tensor([ 0.0137,  0.2371, -0.1284,  ...,  0.0171, -0.3352, -0.2383],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight': tensor([[[[ 2.4582e-02,  1.0330e-02,  7.1983e-03,  ...,  2.3529e-02,
            2.1957e-02,  5.0011e-03],
          [ 1.2756e-02, -6.1417e-03, -4.8676e-03,  ...,  1.6586e-02,
            7.5417e-03, -1.2230e-02],
          [ 9.9945e-03,  2.1954e-03,  2.3632e-03,  ...,  6.1607e-03,
            5.3940e-03, -1.2283e-02],
          ...,
          [-9.9182e-03, -5.7507e-04, -5.5237e-03,  ..., -1.8646e-02,
           -2.3239e-02, -2.4017e-02],
          [-3.8624e-03, -1.1452e-02, -1.3794e-02,  ..., -7.1030e-03,
            1.5745e-03, -4.1771e-03],
          [-2.1545e-02, -4.2786e-02, -2.9480e-02,  ..., -4.9706e-03,
            4.0169e-03, -6.7177e-03]],

         [[ 1.4839e-02, -5.3024e-03, -1.2367e-02,  ...,  2.5696e-02,
            2.4185e-02,  5.8136e-03],
          [ 8.6403e-04, -2.4017e-02, -2.6428e-02,  ...,  1.4999e-02,
            5.4970e-03, -1.4351e-02],
          [ 4.8218e-03, -7.4463e-03, -9.7122e-03,  ...,  8.0948e-03,
            5.5618e-03, -1.2390e-02],
          ...,
          [-4.4479e-03,  5.3673e-03, -1.1482e-03,  ...,  3.6259e-03,
            3.9816e-04, -5.1346e-03],
          [-3.6697e-03, -1.2306e-02, -1.4244e-02,  ...,  1.4938e-02,
            2.2552e-02,  1.2917e-02],
          [-2.8137e-02, -4.9500e-02, -3.0746e-02,  ...,  1.2810e-02,
            1.8158e-02,  9.2745e-04]],

         [[ 1.5839e-02, -2.0618e-03, -4.8103e-03,  ...,  1.6174e-02,
            1.1757e-02,  5.7259e-03],
          [ 1.1625e-03, -2.1133e-02, -2.4445e-02,  ...,  6.3782e-03,
           -4.2191e-03, -7.1831e-03],
          [ 5.0583e-03, -1.0559e-02, -1.4809e-02,  ...,  1.3199e-03,
            1.3041e-04, -7.3051e-03],
          ...,
          [ 2.0676e-03,  2.0599e-03, -8.4915e-03,  ..., -9.9335e-03,
           -9.8267e-03, -6.7825e-03],
          [ 7.3013e-03, -3.9787e-03, -9.5062e-03,  ..., -3.2978e-03,
            6.3400e-03,  5.3177e-03],
          [-1.1139e-02, -2.7283e-02, -1.5518e-02,  ...,  1.6184e-03,
            6.5193e-03,  2.9850e-04]]],


        [[[ 1.5656e-02,  2.6489e-02,  6.7024e-03,  ...,  8.8120e-03,
           -8.4381e-03,  2.0447e-02],
          [-1.8280e-02, -6.8855e-03, -1.5854e-02,  ...,  3.4313e-03,
            3.5906e-04,  1.5945e-02],
          [-2.4139e-02, -1.1620e-02,  2.1858e-03,  ..., -2.5436e-02,
           -2.7924e-02, -3.2177e-03],
          ...,
          [ 7.2670e-03, -7.0534e-03,  1.4343e-02,  ...,  1.4709e-02,
           -5.4741e-03, -5.9624e-03],
          [ 6.3133e-03, -8.2016e-03,  4.0527e-02,  ..., -3.4785e-04,
           -2.7969e-02, -1.8875e-02],
          [ 1.6861e-02, -1.1154e-02,  6.0089e-02,  ..., -4.8828e-04,
            7.1335e-03,  4.6478e-02]],

         [[ 2.1027e-02,  3.3264e-02,  1.0895e-02,  ...,  6.6605e-03,
           -1.1604e-02,  1.7593e-02],
          [-1.4885e-02, -6.6757e-04, -9.0332e-03,  ...,  4.8904e-03,
            3.4976e-04,  1.4732e-02],
          [-2.2797e-02, -6.2103e-03,  1.1116e-02,  ..., -2.8809e-02,
           -3.2684e-02, -7.0076e-03],
          ...,
          [ 5.2643e-03, -1.2299e-02,  6.8703e-03,  ...,  1.1002e-02,
           -1.1253e-02, -9.8648e-03],
          [ 2.2411e-03, -1.5686e-02,  3.5126e-02,  ..., -4.9324e-03,
           -3.7231e-02, -2.6505e-02],
          [ 1.0132e-02, -2.3972e-02,  5.1697e-02,  ..., -1.1131e-02,
           -4.2000e-03,  3.9368e-02]],

         [[ 1.0323e-02,  2.2186e-02,  1.1730e-03,  ...,  5.4436e-03,
           -1.2558e-02,  1.7303e-02],
          [-2.5055e-02, -1.1391e-02, -1.8631e-02,  ...,  4.7417e-03,
            4.3440e-04,  1.5656e-02],
          [-3.3234e-02, -1.7807e-02, -1.1635e-03,  ..., -2.8015e-02,
           -2.9968e-02, -6.5422e-03],
          ...,
          [ 4.8828e-03, -1.0849e-02,  9.8877e-03,  ...,  1.3313e-02,
           -8.7967e-03, -8.7662e-03],
          [ 2.7046e-03, -1.3275e-02,  4.0527e-02,  ...,  4.4370e-04,
           -3.0518e-02, -2.4918e-02],
          [ 8.8272e-03, -2.1423e-02,  5.2643e-02,  ..., -6.3934e-03,
           -7.3242e-04,  3.8818e-02]]],


        [[[ 6.9427e-03,  3.4122e-03, -2.5864e-03,  ...,  1.0246e-02,
            1.4229e-02,  1.8768e-02],
          [-2.8629e-03, -3.3722e-03, -1.3168e-02,  ...,  9.1696e-04,
            5.4283e-03,  6.6032e-03],
          [-3.9787e-03,  5.2147e-03, -3.4542e-03,  ...,  8.4639e-04,
            2.5959e-03,  6.8703e-03],
          ...,
          [ 5.0049e-03,  4.1161e-03,  2.0683e-04,  ...,  1.6174e-02,
            1.4397e-02,  1.2421e-02],
          [ 2.5986e-02,  1.5144e-02,  5.7869e-03,  ...,  2.3376e-02,
            2.2766e-02,  2.2659e-02],
          [ 3.1830e-02,  2.6642e-02,  1.4381e-02,  ...,  2.5604e-02,
            2.2263e-02,  2.5238e-02]],

         [[ 6.8245e-03,  4.8637e-03, -2.8706e-03,  ...,  1.7715e-02,
            1.9653e-02,  2.8290e-02],
          [-2.6302e-03, -1.3628e-03, -1.1459e-02,  ...,  5.4474e-03,
            6.0501e-03,  1.2810e-02],
          [-9.0714e-03,  4.1199e-03, -5.6505e-05,  ...,  9.6178e-04,
           -5.9271e-04,  8.8959e-03],
          ...,
          [ 6.5079e-03,  5.4359e-03,  2.5978e-03,  ...,  2.5131e-02,
            2.4902e-02,  2.6871e-02],
          [ 3.1647e-02,  2.0325e-02,  8.9188e-03,  ...,  3.4180e-02,
            3.3569e-02,  3.9612e-02],
          [ 3.8391e-02,  3.2745e-02,  1.8616e-02,  ...,  4.2664e-02,
            3.9276e-02,  4.6051e-02]],

         [[ 1.6922e-02,  1.5205e-02,  1.1314e-02,  ...,  2.0981e-02,
            2.1042e-02,  2.9053e-02],
          [ 7.5378e-03,  7.6141e-03,  7.9107e-04,  ...,  7.1449e-03,
            7.7019e-03,  1.2169e-02],
          [-2.0492e-04,  1.0826e-02,  6.2065e-03,  ...,  3.9253e-03,
            3.3913e-03,  9.0408e-03],
          ...,
          [ 3.7727e-03,  4.7541e-04,  1.6661e-03,  ...,  8.1329e-03,
            8.0795e-03,  1.4221e-02],
          [ 1.7258e-02,  3.2291e-03,  1.0824e-03,  ...,  1.2383e-02,
            1.1887e-02,  1.8204e-02],
          [ 2.0462e-02,  1.1421e-02,  3.3875e-03,  ...,  2.1469e-02,
            1.5701e-02,  2.2247e-02]]],


        ...,


        [[[-2.4652e-04, -3.0947e-04, -4.7588e-04,  ..., -3.1114e-05,
            3.1686e-04, -3.0446e-04],
          [-1.0872e-04, -7.8440e-04, -8.4782e-04,  ..., -4.0114e-05,
           -2.2995e-04, -1.6510e-04],
          [-1.3084e-03, -6.0129e-04, -9.7513e-04,  ..., -6.2561e-04,
           -5.0831e-04,  5.9748e-04],
          ...,
          [-9.9087e-04, -6.6948e-04, -4.1127e-06,  ..., -4.7803e-05,
           -9.3746e-04, -6.7472e-04],
          [-1.0452e-03,  2.7657e-05, -1.3571e-03,  ..., -6.7282e-04,
           -1.4048e-03, -1.3056e-03],
          [-3.6526e-04, -4.2915e-04, -1.7321e-04,  ..., -1.3387e-04,
            3.2640e-04,  1.7679e-04]],

         [[ 4.7207e-04, -1.0139e-04,  2.9981e-05,  ...,  2.3270e-04,
            1.0500e-03, -5.0831e-04],
          [ 9.1600e-04, -1.1677e-04,  5.0116e-04,  ...,  4.8614e-04,
            1.0071e-03, -4.9925e-04],
          [-5.6362e-04,  2.9826e-04,  1.7405e-03,  ...,  7.9107e-04,
            8.0919e-04,  9.7132e-04],
          ...,
          [ 4.4680e-04,  3.2568e-04,  3.8528e-04,  ...,  1.0176e-03,
            6.2895e-04,  4.0889e-04],
          [ 8.1253e-04,  4.8256e-04, -9.0313e-04,  ...,  7.1192e-04,
           -2.8610e-04,  1.9038e-04],
          [ 3.9649e-04, -3.9983e-04,  6.3944e-04,  ..., -6.4135e-05,
            1.4138e-04,  4.2319e-04]],

         [[ 4.6372e-04,  3.6657e-05, -4.9829e-04,  ..., -2.3520e-04,
           -4.3130e-04, -5.6791e-04],
          [-2.8670e-05,  2.8181e-04,  3.0351e-04,  ..., -3.4332e-04,
            1.9002e-04,  1.8311e-04],
          [-1.2398e-03, -4.5681e-04, -4.3273e-04,  ...,  3.8576e-04,
            2.3186e-05, -5.7578e-05],
          ...,
          [ 2.3723e-04, -2.5702e-04,  5.3215e-04,  ...,  4.0674e-04,
            1.3471e-04,  6.5708e-04],
          [ 6.1452e-05,  3.3474e-04, -6.3944e-04,  ...,  3.9101e-04,
            1.0538e-04, -4.9019e-04],
          [-1.4639e-04, -4.9543e-04,  1.3185e-04,  ...,  8.1062e-06,
           -4.1580e-04,  5.5599e-04]]],


        [[[ 1.2093e-02,  1.8646e-02,  5.2299e-03,  ...,  1.1078e-02,
            6.1874e-03,  2.6535e-02],
          [ 1.1375e-02,  2.9419e-02,  1.3588e-02,  ..., -9.1476e-03,
           -1.7639e-02, -3.2768e-03],
          [ 2.0905e-02,  3.0792e-02,  1.7181e-02,  ..., -1.1398e-02,
           -2.7237e-02, -5.5046e-03],
          ...,
          [ 3.7140e-02,  2.5406e-02,  6.6452e-03,  ...,  1.8311e-02,
            2.8503e-02,  3.6499e-02],
          [ 1.9501e-02, -5.5923e-03, -2.1042e-02,  ..., -1.6556e-02,
           -2.3010e-02,  5.0926e-03],
          [ 1.3893e-02, -2.6947e-02, -5.0720e-02,  ..., -1.2222e-02,
           -3.9276e-02,  1.3908e-02]],

         [[ 1.4706e-03,  9.1858e-03, -2.5845e-03,  ...,  7.8201e-03,
            2.8896e-03,  2.2415e-02],
          [ 1.3762e-03,  2.3300e-02,  1.1292e-02,  ..., -8.3771e-03,
           -1.8616e-02, -6.5308e-03],
          [ 1.0567e-02,  2.6245e-02,  1.8402e-02,  ..., -1.2131e-02,
           -3.0472e-02, -9.3613e-03],
          ...,
          [ 3.4790e-02,  2.1149e-02,  8.6117e-04,  ...,  1.6159e-02,
            2.6001e-02,  3.4241e-02],
          [ 1.4679e-02, -1.1284e-02, -2.6978e-02,  ..., -1.9974e-02,
           -3.0487e-02, -9.5701e-04],
          [ 5.8899e-03, -3.8544e-02, -6.2622e-02,  ..., -2.1103e-02,
           -5.1422e-02,  4.2267e-03]],

         [[-1.0635e-02, -1.9264e-03, -8.6594e-03,  ...,  4.3297e-03,
           -2.1572e-03,  1.6891e-02],
          [-1.2665e-02,  1.1078e-02,  5.2528e-03,  ..., -8.9035e-03,
           -2.1347e-02, -9.2316e-03],
          [-3.2139e-03,  1.4435e-02,  1.3611e-02,  ..., -1.2436e-02,
           -2.9694e-02, -1.2733e-02],
          ...,
          [ 3.2898e-02,  2.2339e-02,  7.0572e-03,  ...,  1.0818e-02,
            1.9257e-02,  2.4582e-02],
          [ 1.3977e-02, -6.0883e-03, -1.4099e-02,  ..., -2.1851e-02,
           -3.1281e-02, -9.1248e-03],
          [ 6.0272e-03, -3.1830e-02, -5.0995e-02,  ..., -2.3849e-02,
           -5.2246e-02, -2.8057e-03]]],


        [[[ 2.2202e-02, -7.5188e-03, -2.8854e-02,  ..., -2.2507e-02,
            8.1863e-03, -4.8248e-02],
          [ 1.6983e-02, -3.1281e-02, -4.2389e-02,  ..., -6.0692e-03,
            9.3689e-03, -3.8544e-02],
          [ 2.1973e-02, -1.5793e-02, -4.1107e-02,  ...,  4.5807e-02,
            2.3956e-02, -1.1154e-02],
          ...,
          [ 2.8351e-02,  3.7689e-02,  4.1321e-02,  ...,  2.4643e-02,
           -1.8654e-03, -1.9440e-02],
          [-1.5114e-02, -2.0706e-02, -2.7962e-03,  ...,  2.0645e-02,
            8.4381e-03,  1.4282e-02],
          [-2.9125e-03, -8.9722e-03,  7.0572e-03,  ...,  1.6861e-02,
            1.6689e-03,  1.6891e-02]],

         [[ 2.2232e-02, -8.1863e-03, -3.0563e-02,  ..., -1.9592e-02,
            1.5839e-02, -4.3243e-02],
          [ 1.6281e-02, -3.2288e-02, -4.2389e-02,  ..., -3.5310e-04,
            1.8433e-02, -3.1799e-02],
          [ 2.0615e-02, -1.6006e-02, -3.9795e-02,  ...,  5.0415e-02,
            2.9694e-02, -5.4817e-03],
          ...,
          [ 4.2480e-02,  5.0110e-02,  4.9622e-02,  ...,  2.2232e-02,
           -1.5268e-03, -1.4626e-02],
          [-4.3030e-03, -1.0712e-02,  6.6299e-03,  ...,  1.9241e-02,
            8.5602e-03,  2.0035e-02],
          [ 5.2910e-03, -1.5764e-03,  1.4839e-02,  ...,  1.1139e-02,
           -2.3785e-03,  1.9150e-02]],

         [[ 6.6986e-03, -1.8478e-02, -3.5858e-02,  ..., -1.4862e-02,
            2.1317e-02, -3.0197e-02],
          [-5.2166e-04, -4.1260e-02, -4.5319e-02,  ...,  5.1880e-03,
            2.4658e-02, -1.7670e-02],
          [ 2.0237e-03, -2.8397e-02, -4.5319e-02,  ...,  5.0110e-02,
            3.4302e-02,  4.5395e-03],
          ...,
          [ 3.7628e-02,  4.5807e-02,  4.9103e-02,  ...,  2.0233e-02,
            4.1656e-03, -5.9814e-03],
          [-5.2338e-03, -9.2239e-03,  1.2566e-02,  ...,  2.1179e-02,
            1.6068e-02,  2.5879e-02],
          [ 2.6760e-03, -5.6696e-04,  1.7899e-02,  ...,  1.1452e-02,
            2.2964e-03,  2.2339e-02]]]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight': tensor([[ 0.0017,  0.0484, -0.0145,  ...,  0.0005, -0.0566, -0.0468],
        [ 0.0112, -0.0406,  0.0338,  ...,  0.0249, -0.0308, -0.0376],
        [ 0.0016, -0.0357,  0.0118,  ...,  0.0215, -0.0292, -0.0399],
        ...,
        [-0.0033, -0.0346, -0.0031,  ..., -0.0287, -0.0336, -0.0360],
        [-0.0055, -0.0331, -0.0074,  ..., -0.0286, -0.0326, -0.0354],
        [-0.0067, -0.0280, -0.0148,  ..., -0.0182, -0.0268, -0.0353]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight': tensor([0.3306, 0.0026, 0.1605,  ..., 2.1934, 0.0042, 0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias': tensor([-0.0044, -0.0450, -0.0473,  ...,  0.0395, -0.1389, -0.0134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight': tensor([[-1.1724e-04,  8.3399e-04, -1.5700e-04,  ..., -4.8332e-03,
          1.3428e-02,  3.2604e-05],
        [-4.4703e-05, -9.5272e-04,  1.2279e-04,  ...,  1.9855e-03,
         -1.3626e-02, -4.1783e-05],
        [ 6.6280e-04,  1.0419e-04,  9.0420e-05,  ..., -2.1820e-02,
          4.1199e-03,  3.2187e-06],
        ...,
        [-5.2512e-05, -2.9278e-04, -3.6895e-05,  ...,  8.8196e-03,
         -4.2796e-04, -3.0100e-05],
        [ 7.5936e-05, -6.5148e-05, -9.0182e-05,  ...,  8.1682e-04,
         -6.0844e-03,  1.9014e-05],
        [-6.3896e-05,  9.8705e-05,  4.9829e-05,  ..., -1.2579e-03,
         -7.1793e-03,  2.3961e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias': tensor([ 0.0577, -0.0588, -0.0266,  ..., -0.0147, -0.0175,  0.0096],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight': tensor([[ 2.4986e-04, -1.5283e-04, -5.8556e-04,  ...,  3.3607e-03,
         -9.5901e-03,  5.5373e-05],
        [-3.4356e-04, -1.5092e-04,  5.2691e-05,  ...,  2.5725e-04,
          1.0010e-02, -6.2883e-05],
        [ 6.7472e-04, -9.6798e-05,  2.5392e-04,  ..., -1.0386e-03,
         -1.9531e-02, -1.2141e-04],
        ...,
        [ 2.9850e-04,  4.0436e-04, -9.7811e-05,  ...,  4.6654e-03,
         -2.2392e-03, -6.6221e-05],
        [ 3.2973e-04, -3.2961e-05, -2.1207e-04,  ...,  1.1917e-02,
          3.4637e-03,  6.9439e-05],
        [ 2.1458e-06,  4.7874e-04,  4.8459e-05,  ..., -1.1612e-02,
          2.6779e-03, -8.3089e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias': tensor([-0.0277,  0.0222, -0.0355,  ...,  0.0123,  0.0105, -0.0041],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight': tensor([[-2.6703e-05, -1.3638e-04, -8.3923e-05,  ...,  4.2152e-03,
         -2.7649e-02, -7.5042e-05],
        [-1.6391e-04,  9.0241e-05,  5.4836e-05,  ..., -1.5821e-03,
          2.9831e-02,  7.0333e-05],
        [ 4.7588e-04,  7.6008e-04, -1.0198e-04,  ..., -1.7090e-02,
          4.1809e-02,  1.5020e-04],
        ...,
        [ 6.9141e-05,  7.0274e-05,  8.6784e-05,  ..., -4.3411e-03,
          1.1421e-02, -3.8803e-05],
        [-1.8144e-04,  1.4305e-06, -2.5940e-04,  ...,  1.5802e-03,
         -1.8799e-04,  1.6689e-05],
        [-1.2624e-04,  9.4473e-05,  5.3406e-05,  ..., -1.4961e-02,
         -5.8937e-04,  4.2021e-05]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias': tensor([ 1.5693, -1.6172, -0.8213,  ..., -1.2852, -0.0976,  0.7852],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight': tensor([[-0.0073,  0.0083, -0.0076,  ..., -0.0090, -0.0080,  0.0038],
        [ 0.0107,  0.0062,  0.0133,  ..., -0.0036,  0.0022,  0.0034],
        [-0.0065,  0.0033,  0.0139,  ...,  0.0069,  0.0004, -0.0009],
        ...,
        [-0.0002, -0.0035, -0.0027,  ..., -0.0046, -0.0187,  0.0087],
        [-0.0093,  0.0047, -0.0083,  ...,  0.0006, -0.0013, -0.0006],
        [ 0.0092,  0.0003,  0.0016,  ...,  0.0016, -0.0045,  0.0045]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias': tensor([-0.0263, -0.0654,  0.0031,  ...,  0.1759, -0.0438,  0.0020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight': tensor([8.3113e-04, 2.9087e-03, 1.1456e-04,  ..., 6.9092e-01, 3.5498e-01,
        2.4021e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias': tensor([ 6.9141e-06,  7.7629e-04, -8.8811e-05,  ..., -3.6816e-01,
         1.7981e-01, -1.0854e-04], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight': tensor([[ 4.2367e-04, -2.1219e-05,  5.9605e-08,  ..., -5.6458e-03,
         -1.2026e-03, -6.4087e-04],
        [ 6.1340e-03,  1.3588e-02, -3.5858e-04,  ..., -3.5954e-03,
         -7.6485e-04,  6.7101e-03],
        [ 1.3552e-03,  1.2817e-03, -2.0266e-06,  ..., -2.8351e-02,
         -1.2054e-03,  1.4830e-03],
        ...,
        [-2.4002e-02, -1.0193e-02,  2.1684e-04,  ..., -2.5864e-03,
         -1.1841e-02,  5.9166e-03],
        [ 4.1008e-04,  4.2856e-05, -1.1921e-07,  ..., -5.0697e-03,
         -7.7248e-04, -6.3896e-04],
        [-6.3753e-04, -2.3392e-02, -2.6226e-04,  ..., -4.2801e-03,
          2.7962e-03, -8.1863e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias': tensor([-0.6826, -0.3130, -0.8076,  ..., -0.2166, -0.6538, -0.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight': tensor([[-0.0037, -0.0032,  0.0043,  ...,  0.0117, -0.0042, -0.0073],
        [ 0.0017,  0.0183, -0.0100,  ..., -0.0255,  0.0024,  0.0209],
        [ 0.0033,  0.0024, -0.0029,  ...,  0.0037,  0.0032, -0.0154],
        ...,
        [ 0.0015, -0.0007, -0.0035,  ...,  0.0049,  0.0009,  0.0082],
        [-0.0060,  0.0064,  0.0067,  ..., -0.0009, -0.0061,  0.0016],
        [ 0.0007, -0.0034, -0.0020,  ..., -0.0091,  0.0009,  0.0035]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias': tensor([-0.0185, -0.1009,  0.0397,  ..., -0.0955, -0.1080, -0.0239],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight': tensor([2.8296e-01, 5.9082e-01, 1.0455e-04,  ..., 2.0195e+00, 7.7490e-01,
        2.9736e-01], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias': tensor([2.1988e-02, 2.1716e-01, 9.2089e-05,  ..., 2.6318e-01, 4.5020e-01,
        5.0903e-02], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight': tensor([[-3.9864e-03,  1.4374e-02, -2.8610e-03,  ...,  1.0399e-02,
         -2.8076e-02,  5.1155e-03],
        [ 8.1024e-03,  2.2583e-03,  1.1635e-02,  ..., -7.1716e-03,
         -7.5607e-03,  2.5375e-02],
        [ 9.5596e-03,  1.1284e-02, -3.6469e-03,  ..., -6.6757e-03,
         -1.2465e-03, -1.1475e-02],
        ...,
        [ 7.7188e-05, -1.6190e-02,  3.6583e-03,  ...,  2.1240e-02,
          4.3907e-03, -1.0063e-02],
        [ 1.5762e-02,  1.7273e-02, -3.3447e-02,  ..., -2.2507e-03,
         -1.2947e-02,  1.1726e-02],
        [-2.2697e-04,  1.2230e-02, -4.3411e-03,  ...,  3.3436e-03,
         -4.9973e-03,  5.5504e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias': tensor([-0.0012,  0.0081,  0.0097,  ...,  0.0535,  0.0071,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight': tensor([[ 0.0077,  0.0006,  0.0053,  ..., -0.0067,  0.0008,  0.0013],
        [ 0.0230, -0.0166, -0.0004,  ...,  0.0092, -0.0118, -0.0134],
        [-0.0103,  0.0013,  0.0111,  ..., -0.0549, -0.0047,  0.0056],
        ...,
        [ 0.0119,  0.0002, -0.0045,  ...,  0.0001,  0.0034, -0.0075],
        [-0.0129, -0.0114,  0.0075,  ..., -0.0030,  0.0044,  0.0061],
        [-0.0006, -0.0018,  0.0009,  ..., -0.0068, -0.0205, -0.0002]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias': tensor([ 0.0038, -0.0079, -0.1469,  ..., -0.0014, -0.0041,  0.0007],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight': tensor([[-2.4929e-03,  4.6706e-04, -1.8919e-04,  ...,  6.1684e-03,
         -2.4582e-02,  8.7051e-03],
        [ 6.5422e-03,  4.3602e-03,  1.5930e-02,  ..., -6.5994e-03,
          8.2169e-03,  6.1111e-03],
        [ 1.0727e-02, -9.2239e-03, -7.5698e-06,  ...,  3.7136e-03,
          1.6861e-02,  3.5305e-03],
        ...,
        [-2.3708e-03,  6.6452e-03,  5.9052e-03,  ..., -1.0399e-02,
          2.9945e-04, -9.6989e-04],
        [ 3.0609e-02,  1.3458e-02, -3.3386e-02,  ..., -1.3857e-03,
          3.5801e-03,  1.3245e-02],
        [-3.2291e-03,  4.7607e-03, -1.8759e-03,  ...,  6.1035e-04,
          4.9515e-03, -5.3520e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias': tensor([-0.1035,  0.8804,  1.4414,  ..., -2.2109, -0.1892,  0.0048],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight': tensor([[-0.0013, -0.0215,  0.0011,  ..., -0.0115,  0.0102, -0.0012],
        [-0.0010,  0.0065, -0.0018,  ..., -0.0036,  0.0112, -0.0025],
        [ 0.0015, -0.0069, -0.0120,  ..., -0.0047, -0.0009, -0.0056],
        ...,
        [ 0.0053, -0.0177,  0.0780,  ..., -0.0228, -0.0122,  0.0151],
        [-0.0086, -0.0019,  0.0054,  ...,  0.0081, -0.0049,  0.0067],
        [-0.0037,  0.0063, -0.0005,  ...,  0.0054,  0.0045, -0.0036]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias': tensor([-0.0204, -0.0210,  0.0255,  ..., -0.0381, -0.0211, -0.0043],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight': tensor([0.3650, 0.7476, 0.0972,  ..., 0.8521, 0.4248, 0.2639],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias': tensor([-0.0482, -0.1315,  0.0198,  ..., -0.1031, -0.0545,  0.0076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight': tensor([[ 0.0026,  0.0065,  0.0155,  ..., -0.0063,  0.0479, -0.0807],
        [ 0.0002, -0.0075,  0.0009,  ..., -0.0009, -0.0030,  0.0036],
        [ 0.0070, -0.0211,  0.0002,  ..., -0.0094,  0.0178, -0.0043],
        ...,
        [ 0.0026, -0.0113,  0.0019,  ..., -0.0057, -0.0008,  0.0038],
        [-0.0059,  0.0099,  0.0010,  ...,  0.0037, -0.0142, -0.0178],
        [ 0.0160,  0.0002,  0.0312,  ..., -0.0003, -0.0056, -0.0220]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias': tensor([-0.1216, -0.6841, -0.5278,  ..., -0.7573, -0.0995, -0.3076],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight': tensor([[ 0.0008, -0.0008, -0.0176,  ..., -0.0029, -0.0098, -0.0047],
        [-0.0157,  0.0059,  0.0156,  ...,  0.0064, -0.0005, -0.0058],
        [ 0.0051, -0.0005,  0.0091,  ..., -0.0056, -0.0015,  0.0059],
        ...,
        [ 0.0030, -0.0024,  0.0040,  ...,  0.0014,  0.0002,  0.0047],
        [ 0.0007, -0.0015,  0.0031,  ..., -0.0015,  0.0046, -0.0055],
        [ 0.0299,  0.0036,  0.0020,  ...,  0.0047,  0.0134,  0.0043]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias': tensor([ 0.0244, -0.0645,  0.0788,  ..., -0.0807, -0.1028, -0.0836],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight': tensor([0.4128, 0.9854, 0.1910,  ..., 0.7715, 0.5596, 0.5142],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias': tensor([-0.0198, -0.1075, -0.0195,  ...,  0.0887,  0.1349,  0.0288],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight': tensor([[-0.0085,  0.0006, -0.0289,  ...,  0.0041,  0.0569, -0.0674],
        [-0.0052,  0.0245, -0.0213,  ..., -0.0084,  0.0220, -0.0248],
        [-0.0135, -0.0092,  0.0144,  ...,  0.0162,  0.0298, -0.0357],
        ...,
        [-0.0062,  0.0068,  0.0082,  ...,  0.0119,  0.0132, -0.0033],
        [-0.0083,  0.0247, -0.0094,  ..., -0.0040, -0.0122,  0.0142],
        [-0.0048, -0.0044, -0.0164,  ...,  0.0119, -0.0213, -0.0117]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias': tensor([ 0.0234,  0.0084, -0.0015,  ...,  0.0951,  0.0065,  0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight': tensor([[ 0.0164,  0.0053, -0.0065,  ..., -0.0008,  0.0037, -0.0120],
        [-0.0057, -0.0036, -0.0029,  ..., -0.0013,  0.0026, -0.0108],
        [-0.0081,  0.0057,  0.0067,  ...,  0.0028, -0.0068, -0.0023],
        ...,
        [-0.0249,  0.0121,  0.0107,  ...,  0.0037,  0.0007,  0.0044],
        [ 0.0115,  0.0107,  0.0118,  ...,  0.0015, -0.0038, -0.0073],
        [-0.0073,  0.0032, -0.0060,  ...,  0.0023, -0.0074,  0.0047]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias': tensor([-0.0014, -0.0060,  0.0129,  ...,  0.1081,  0.0069,  0.0455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight': tensor([[-0.0067, -0.0208, -0.0222,  ...,  0.0014,  0.0279, -0.0558],
        [-0.0030,  0.0016, -0.0191,  ...,  0.0001, -0.0169, -0.0034],
        [-0.0079, -0.0049,  0.0074,  ..., -0.0163, -0.0186, -0.0105],
        ...,
        [ 0.0002, -0.0036,  0.0084,  ..., -0.0038,  0.0105, -0.0002],
        [-0.0035, -0.0039, -0.0118,  ..., -0.0067, -0.0292,  0.0361],
        [-0.0044, -0.0008, -0.0187,  ...,  0.0014, -0.0064, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias': tensor([ 0.1927, -0.0745, -0.0890,  ...,  0.6807,  0.7334, -0.5073],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight': tensor([[-2.4796e-02,  3.3035e-03, -5.1379e-05,  ...,  2.5177e-02,
         -2.3010e-02,  1.2245e-02],
        [-2.7504e-03,  1.5330e-04, -1.1650e-02,  ..., -8.4229e-03,
         -4.1389e-03, -6.9275e-03],
        [-1.2238e-02, -7.1983e-03, -1.0323e-02,  ..., -1.6312e-02,
         -5.9547e-03, -1.4572e-03],
        ...,
        [-1.8501e-03,  5.0354e-04, -6.7101e-03,  ..., -7.3471e-03,
         -2.3518e-03, -1.8501e-03],
        [ 5.4131e-03, -4.4937e-03,  1.2329e-02,  ..., -7.1716e-04,
          9.8038e-04,  7.2708e-03],
        [ 1.0040e-02,  6.5422e-03,  9.2163e-03,  ..., -4.5815e-03,
         -1.1330e-03, -2.6169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias': tensor([ 0.0182, -0.0970,  0.0244,  ..., -0.0159, -0.0449, -0.0308],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight': tensor([0.5078, 0.3108, 0.4004,  ..., 1.4219, 0.5015, 0.3591],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias': tensor([-0.0750, -0.0109,  0.0618,  ..., -0.0417,  0.0176, -0.0477],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight': tensor([[-0.0066, -0.0264,  0.0131,  ..., -0.0004,  0.0194, -0.0154],
        [ 0.0097,  0.0090, -0.0017,  ...,  0.0023, -0.0030,  0.0246],
        [-0.0057,  0.0093,  0.0011,  ..., -0.0040,  0.0003,  0.0128],
        ...,
        [ 0.0005, -0.0012, -0.0009,  ...,  0.0011, -0.0034, -0.0059],
        [ 0.0002,  0.0115,  0.0158,  ...,  0.0040,  0.0015,  0.0208],
        [-0.0148,  0.0111, -0.0085,  ...,  0.0049, -0.0076, -0.0022]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias': tensor([-0.2452, -0.3076, -0.4565,  ..., -0.1678, -0.2119, -0.5581],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight': tensor([[ 1.3428e-03, -3.5172e-03,  9.3317e-04,  ..., -5.0354e-03,
          4.3907e-03,  2.0161e-03],
        [ 1.2999e-03, -1.6678e-02, -4.5662e-03,  ..., -4.4584e-04,
          1.3359e-02, -3.9558e-03],
        [-1.8829e-02,  5.2261e-03,  4.7760e-03,  ...,  8.3113e-04,
         -1.8860e-02,  1.0452e-03],
        ...,
        [-7.8201e-03,  8.4305e-04, -2.1601e-04,  ..., -5.6207e-05,
          4.8339e-05,  1.7557e-03],
        [-4.5300e-05, -7.9498e-03, -9.6178e-04,  ...,  3.4180e-03,
         -1.0208e-02,  2.4460e-02],
        [ 6.0883e-03,  3.3398e-03, -3.7789e-04,  ...,  1.5259e-02,
          6.6223e-03,  6.8169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias': tensor([ 0.0453, -0.0798, -0.0027,  ..., -0.0154, -0.1379, -0.0307],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight': tensor([0.6362, 0.5508, 0.3787,  ..., 1.3506, 0.4011, 0.4910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias': tensor([-0.0338, -0.0840, -0.0964,  ..., -0.0491,  0.0855, -0.2158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight': tensor([[ 0.0149, -0.0155, -0.0083,  ...,  0.0066,  0.0086, -0.0173],
        [ 0.0067,  0.0134,  0.0050,  ..., -0.0056, -0.0293, -0.0028],
        [ 0.0041, -0.0027, -0.0011,  ...,  0.0060,  0.0020, -0.0035],
        ...,
        [ 0.0110, -0.0188,  0.0174,  ..., -0.0223,  0.0017, -0.0122],
        [ 0.0165, -0.0201, -0.0204,  ..., -0.0262, -0.0232, -0.0039],
        [ 0.0062, -0.0148,  0.0194,  ...,  0.0090, -0.0007, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias': tensor([-0.0385, -0.0122,  0.0262,  ...,  0.1536,  0.0992, -0.0590],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight': tensor([[ 0.0275, -0.0126, -0.0067,  ...,  0.0002,  0.0201,  0.0163],
        [-0.0074,  0.0475,  0.0058,  ..., -0.0040,  0.0014,  0.0004],
        [-0.0100, -0.0039, -0.0155,  ...,  0.0009, -0.0079,  0.0033],
        ...,
        [ 0.0009,  0.0007,  0.0107,  ...,  0.0007,  0.0007, -0.0059],
        [-0.0008,  0.0147,  0.0066,  ...,  0.0022, -0.0062, -0.0033],
        [-0.0195, -0.0065,  0.0118,  ..., -0.0030,  0.0058,  0.0028]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias': tensor([ 0.0095, -0.0516,  0.0111,  ..., -0.0145,  0.0041,  0.0051],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight': tensor([[ 2.7618e-02,  1.0513e-02,  4.2725e-03,  ...,  6.3095e-03,
         -8.5907e-03, -1.3008e-02],
        [ 2.4605e-03,  1.8875e-02, -3.9787e-03,  ..., -5.7335e-03,
         -2.1698e-02,  5.3406e-03],
        [-5.1880e-04, -1.0147e-02, -1.0471e-03,  ...,  1.0002e-02,
          1.0025e-02, -1.6159e-02],
        ...,
        [ 1.4210e-03, -1.6434e-02,  5.2299e-03,  ..., -1.5053e-02,
          1.1284e-02,  1.2054e-03],
        [ 1.5579e-02,  1.5251e-02, -3.5915e-03,  ..., -2.6520e-02,
         -1.4130e-02, -7.7133e-03],
        [ 1.0399e-02, -2.2491e-02,  3.2783e-06,  ...,  8.3542e-03,
         -6.7215e-03,  1.6525e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias': tensor([-0.1852, -0.5479, -0.1450,  ..., -0.9072, -0.3499, -0.3457],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight': tensor([[-2.1683e-02,  2.3556e-03, -1.9245e-03,  ..., -9.4910e-03,
          1.6251e-02,  1.2527e-02],
        [ 6.4430e-03, -3.8055e-02, -3.1567e-03,  ..., -2.6455e-03,
         -2.1515e-02,  1.1864e-02],
        [ 5.2147e-03, -8.5602e-03,  1.5732e-02,  ..., -1.2611e-02,
          7.3395e-03, -1.2505e-02],
        ...,
        [-1.1325e-04,  3.4676e-03, -1.1169e-02,  ..., -1.0071e-02,
         -5.4538e-05, -1.7357e-03],
        [-6.8245e-03, -1.0139e-02,  1.4579e-04,  ...,  2.0309e-02,
          1.3527e-02, -3.0098e-03],
        [-1.7868e-02,  6.0368e-04, -6.7101e-03,  ...,  6.6853e-04,
         -3.0327e-03,  3.0651e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias': tensor([-0.0147, -0.0586,  0.0197,  ...,  0.0204, -0.1210,  0.0171],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight': tensor([0.7456, 0.3557, 0.6133,  ..., 2.2637, 0.5059, 0.3938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias': tensor([-0.0006,  0.0249,  0.0189,  ..., -0.1539, -0.0345,  0.0151],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight': tensor([[ 0.0034,  0.0025,  0.0007,  ..., -0.0021, -0.0065,  0.0058],
        [ 0.0011, -0.0024, -0.0028,  ..., -0.0094, -0.0078, -0.0065],
        [-0.0051, -0.0246, -0.0075,  ..., -0.0073,  0.0121,  0.0036],
        ...,
        [ 0.0077,  0.0038, -0.0011,  ..., -0.0060, -0.0017,  0.0005],
        [-0.0208, -0.0176, -0.0064,  ..., -0.0076, -0.0137, -0.0056],
        [-0.0240,  0.0082, -0.0047,  ..., -0.0105, -0.0069, -0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias': tensor([-0.0952, -0.1888, -0.1597,  ..., -0.2030, -0.3225, -0.3745],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight': tensor([[ 0.0074, -0.0074,  0.0041,  ...,  0.0181,  0.0235,  0.0145],
        [ 0.0106,  0.0015, -0.0078,  ..., -0.0323, -0.0017,  0.0073],
        [-0.0059, -0.0090, -0.0087,  ...,  0.0023,  0.0091,  0.0240],
        ...,
        [ 0.0054,  0.0013, -0.0012,  ..., -0.0047, -0.0021, -0.0053],
        [-0.0028,  0.0165,  0.0051,  ...,  0.0006, -0.0043, -0.0041],
        [-0.0045,  0.0066,  0.0154,  ..., -0.0027,  0.0146, -0.0076]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias': tensor([ 0.0139, -0.0796,  0.0050,  ...,  0.0715, -0.1787,  0.0414],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight': tensor([0.9761, 0.5317, 0.6523,  ..., 0.0116, 0.5054, 0.5391],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias': tensor([ 0.0585,  0.0282,  0.0207,  ...,  0.3896, -0.0784, -0.1201],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight': tensor([[ 2.0187e-02,  9.6970e-03,  1.7242e-02,  ..., -2.5925e-02,
         -1.5945e-02,  6.4671e-05],
        [ 1.0201e-02, -7.3357e-03,  3.3722e-02,  ...,  8.9111e-03,
         -3.2410e-02,  5.5122e-03],
        [ 9.6817e-03, -2.4231e-02,  5.7907e-03,  ...,  4.0955e-02,
          2.2415e-02, -1.8143e-02],
        ...,
        [-2.4857e-02, -2.5803e-02, -3.2673e-03,  ..., -1.3596e-02,
          3.6240e-03, -5.7650e-04],
        [-6.4754e-04,  2.4719e-02, -3.0411e-02,  ..., -1.3008e-02,
          5.0879e-04, -1.9455e-02],
        [ 1.7380e-02, -2.3804e-02,  1.2428e-02,  ..., -4.4670e-03,
         -4.2297e-02,  9.2545e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias': tensor([-0.0362, -0.0177,  0.0258,  ...,  0.0230,  0.0147,  0.0451],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight': tensor([[-0.0050,  0.0089,  0.0017,  ..., -0.0001, -0.0173, -0.0087],
        [ 0.0064, -0.0170,  0.0071,  ..., -0.0039,  0.0387, -0.0100],
        [-0.0151,  0.0005, -0.0012,  ..., -0.0011, -0.0048,  0.0012],
        ...,
        [ 0.0129, -0.0303, -0.0177,  ...,  0.0005,  0.0013,  0.0006],
        [ 0.0157,  0.0140, -0.0101,  ...,  0.0011,  0.0336, -0.0216],
        [ 0.0171, -0.0183, -0.0061,  ...,  0.0016, -0.0197, -0.0110]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias': tensor([ 0.0241, -0.0481, -0.0028,  ...,  0.0268,  0.0064, -0.0023],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight': tensor([[ 0.0075,  0.0013, -0.0144,  ..., -0.0114, -0.0454, -0.0086],
        [-0.0035, -0.0501,  0.0037,  ..., -0.0065, -0.0287,  0.0070],
        [ 0.0061, -0.0005,  0.0146,  ...,  0.0271,  0.0069, -0.0366],
        ...,
        [-0.0107,  0.0089, -0.0109,  ..., -0.0074, -0.0206, -0.0009],
        [-0.0004, -0.0072, -0.0339,  ..., -0.0124, -0.0053, -0.0094],
        [ 0.0051, -0.0136, -0.0062,  ..., -0.0015, -0.0242, -0.0031]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias': tensor([-0.4634, -0.0086,  0.2761,  ..., -0.2158, -0.2346, -0.2240],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight': tensor([[-2.6817e-03, -4.3983e-03,  1.3580e-03,  ..., -2.4681e-03,
         -1.6296e-02, -1.9119e-02],
        [-6.3057e-03,  1.3931e-02,  2.0657e-03,  ...,  2.4063e-02,
         -2.3544e-02,  2.3361e-02],
        [ 4.4098e-03,  2.9049e-03,  3.0816e-05,  ...,  1.9028e-02,
          1.2093e-02,  9.4528e-03],
        ...,
        [-6.3095e-03,  7.6141e-03, -4.4861e-03,  ..., -6.6261e-03,
         -6.6795e-03, -3.0851e-04],
        [ 1.7075e-02, -3.9612e-02,  9.1248e-03,  ...,  1.1742e-02,
         -3.6469e-02,  2.8046e-02],
        [ 8.2626e-03,  1.3752e-03, -1.0185e-02,  ...,  6.5994e-04,
          1.5320e-02,  1.1871e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias': tensor([ 0.0089, -0.0782,  0.0222,  ..., -0.0115, -0.1763,  0.0233],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight': tensor([0.7534, 0.5015, 0.7891,  ..., 1.1660, 0.6074, 0.5796],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias': tensor([ 0.0149, -0.0122,  0.0052,  ..., -0.1028,  0.0337, -0.0357],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight': tensor([[ 0.0072, -0.0114, -0.0013,  ..., -0.0066,  0.0127,  0.0151],
        [-0.0095,  0.0185,  0.0141,  ..., -0.0075,  0.0141,  0.0101],
        [-0.0018,  0.0118,  0.0032,  ..., -0.0046,  0.0148,  0.0008],
        ...,
        [ 0.0204,  0.0075,  0.0235,  ..., -0.0079,  0.0030, -0.0164],
        [ 0.0157, -0.0033, -0.0008,  ..., -0.0085,  0.0043, -0.0139],
        [-0.0009, -0.0003,  0.0257,  ..., -0.0072, -0.0059, -0.0217]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias': tensor([-0.2440, -0.3796, -0.5205,  ..., -0.2163, -0.4248, -0.2197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight': tensor([[-1.6296e-02,  6.4087e-03, -1.4839e-03,  ..., -2.2827e-02,
          1.9302e-02,  1.6346e-03],
        [ 5.0888e-03, -1.3763e-02,  5.1537e-03,  ..., -1.9989e-02,
         -2.7637e-03, -1.0567e-02],
        [ 2.8763e-03, -5.1460e-03, -5.6326e-05,  ..., -7.1030e-03,
         -9.8724e-03, -2.3098e-03],
        ...,
        [-5.3024e-03, -2.0905e-03,  2.9635e-04,  ..., -5.4092e-03,
          2.0993e-04,  2.4395e-03],
        [-9.9411e-03, -1.4748e-02, -2.4283e-04,  ...,  1.8127e-02,
          3.3779e-03,  2.1927e-02],
        [-5.7182e-03,  1.5316e-03,  1.1997e-03,  ...,  2.5387e-03,
         -5.6725e-03,  4.6387e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias': tensor([-0.0155, -0.0524, -0.0402,  ...,  0.1025, -0.1437, -0.0174],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight': tensor([1.1230, 0.5190, 1.0762,  ..., 0.0112, 0.6738, 0.7544],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias': tensor([ 0.0829, -0.0929, -0.0049,  ...,  0.1129, -0.0392, -0.0677],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight': tensor([[ 0.0035, -0.0081,  0.0270,  ..., -0.0032,  0.0041,  0.0172],
        [-0.0174,  0.0256,  0.0060,  ..., -0.0001,  0.0052, -0.0038],
        [ 0.0038,  0.0144, -0.0161,  ..., -0.0028,  0.0033,  0.0003],
        ...,
        [-0.0023, -0.0123, -0.0080,  ...,  0.0256,  0.0213, -0.0097],
        [-0.0147,  0.0030,  0.0045,  ...,  0.0211,  0.0161, -0.0218],
        [-0.0035,  0.0147,  0.0030,  ..., -0.0244, -0.0005, -0.0255]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias': tensor([-0.0187, -0.0076,  0.0053,  ...,  0.0369,  0.0955,  0.0978],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight': tensor([[-0.0090,  0.0047, -0.0008,  ..., -0.0064, -0.0025, -0.0247],
        [-0.0128, -0.0091,  0.0087,  ...,  0.0024, -0.0012,  0.0007],
        [ 0.0101, -0.0021, -0.0005,  ...,  0.0017,  0.0007, -0.0170],
        ...,
        [-0.0120,  0.0108,  0.0011,  ..., -0.0008, -0.0032,  0.0003],
        [-0.0157, -0.0033,  0.0135,  ..., -0.0007, -0.0310, -0.0129],
        [ 0.0124, -0.0001,  0.0213,  ..., -0.0014, -0.0043, -0.0239]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias': tensor([-0.0186, -0.0071, -0.0258,  ..., -0.0043, -0.0113, -0.0044],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight': tensor([[-1.7075e-02,  3.0457e-02,  8.3542e-03,  ..., -8.0032e-03,
          1.6724e-02, -1.0490e-02],
        [-1.2169e-02,  8.2474e-03, -4.2725e-03,  ..., -9.4366e-04,
         -4.9591e-03, -1.0300e-02],
        [ 1.0185e-03, -1.2466e-02, -3.0880e-03,  ..., -3.4428e-03,
         -1.3107e-02,  6.5384e-03],
        ...,
        [ 1.5793e-02,  2.0809e-03,  1.9424e-02,  ...,  2.6367e-02,
          1.0529e-02, -2.1439e-02],
        [-5.6992e-03,  4.1580e-04,  3.8116e-02,  ...,  1.6739e-02,
         -9.0103e-03, -1.6327e-02],
        [ 2.8789e-05, -9.8114e-03,  1.0004e-03,  ..., -2.2293e-02,
         -3.0365e-02,  6.1569e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias': tensor([-0.0072, -1.4619,  0.3447,  ..., -0.6147, -0.3474, -0.6455],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight': tensor([[ 5.2567e-03,  1.1238e-02, -6.8092e-03,  ..., -8.0013e-04,
          1.5930e-02, -1.4336e-02],
        [-6.6223e-03,  1.9255e-03, -1.6006e-02,  ..., -2.0706e-02,
         -1.1848e-02, -1.1147e-02],
        [ 2.3087e-02,  1.1986e-02, -1.7288e-02,  ...,  5.7144e-03,
          1.4824e-02, -1.6876e-02],
        ...,
        [ 1.6647e-02,  5.3596e-03, -1.5154e-03,  ..., -2.9736e-03,
          1.8129e-03,  1.0559e-02],
        [ 4.1847e-03,  8.3694e-03,  1.2535e-02,  ..., -1.0323e-02,
          1.6327e-02, -3.2544e-05],
        [ 1.0185e-03, -2.1400e-03, -4.4098e-03,  ..., -4.6120e-03,
          6.0921e-03,  1.5152e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias': tensor([-0.0087, -0.0482, -0.0096,  ..., -0.0479, -0.1366,  0.0062],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight': tensor([0.8506, 0.6484, 0.8960,  ..., 1.2539, 0.7212, 0.8564],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias': tensor([-0.0077,  0.0670, -0.0532,  ..., -0.1699, -0.0490,  0.0434],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight': tensor([[ 0.0058,  0.0115,  0.0089,  ..., -0.0020, -0.0053,  0.0026],
        [-0.0017, -0.0024,  0.0162,  ...,  0.0009, -0.0208, -0.0094],
        [-0.0388, -0.0012, -0.0004,  ...,  0.0032, -0.0029, -0.0226],
        ...,
        [ 0.0085,  0.0130,  0.0209,  ..., -0.0057, -0.0040, -0.0012],
        [ 0.0260,  0.0055,  0.0095,  ..., -0.0008,  0.0056, -0.0098],
        [ 0.0116,  0.0073, -0.0117,  ...,  0.0011, -0.0095, -0.0163]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias': tensor([-0.4192, -0.2394, -0.3069,  ..., -0.3667, -0.2563, -0.1315],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight': tensor([[ 0.0154, -0.0020, -0.0083,  ...,  0.0161, -0.0060,  0.0146],
        [ 0.0042,  0.0226,  0.0055,  ...,  0.0110,  0.0033,  0.0034],
        [ 0.0140, -0.0083,  0.0006,  ...,  0.0085,  0.0010,  0.0007],
        ...,
        [-0.0025, -0.0010, -0.0020,  ...,  0.0007, -0.0030, -0.0018],
        [-0.0141, -0.0032, -0.0003,  ...,  0.0106, -0.0021, -0.0400],
        [ 0.0069,  0.0051, -0.0135,  ..., -0.0115,  0.0067, -0.0104]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias': tensor([-0.0416,  0.0127, -0.0229,  ...,  0.0723, -0.0145, -0.0363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight': tensor([1.1514, 0.7275, 1.1299,  ..., 1.0918, 0.8794, 1.1055],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias': tensor([ 0.0418, -0.1718, -0.0305,  ...,  0.0424, -0.2144, -0.0068],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight': tensor([[ 0.0195, -0.0016, -0.0010,  ...,  0.1302, -0.0123, -0.0063],
        [-0.0176,  0.0024, -0.0196,  ..., -0.1481, -0.0101, -0.0231],
        [-0.0042, -0.0077,  0.0033,  ...,  0.0850, -0.0172,  0.0256],
        ...,
        [ 0.0024, -0.0123,  0.0282,  ..., -0.0123,  0.0272,  0.0247],
        [ 0.0084, -0.0235,  0.0189,  ...,  0.0040, -0.0171,  0.0120],
        [ 0.0308, -0.0003,  0.0095,  ..., -0.0054, -0.0117, -0.0379]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias': tensor([-0.0049,  0.0073,  0.0145,  ...,  0.0185, -0.0033,  0.0204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight': tensor([[ 0.0096,  0.0166, -0.0025,  ..., -0.0005,  0.0005,  0.0034],
        [ 0.0066,  0.0109, -0.0074,  ...,  0.0010,  0.0079, -0.0095],
        [-0.0074, -0.0047,  0.0016,  ...,  0.0002,  0.0039,  0.0040],
        ...,
        [-0.0159,  0.0166, -0.0176,  ...,  0.0020, -0.0064,  0.0302],
        [ 0.0316, -0.0076, -0.0238,  ..., -0.0002, -0.0032, -0.0157],
        [-0.0096, -0.0192,  0.0207,  ..., -0.0009, -0.0289, -0.0082]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias': tensor([ 0.0264, -0.0288,  0.0074,  ...,  0.0075, -0.0047,  0.0190],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight': tensor([[ 0.0136, -0.0235, -0.0059,  ...,  0.0935,  0.0115, -0.0124],
        [-0.0146, -0.0224,  0.0003,  ..., -0.1112, -0.0056, -0.0134],
        [-0.0018,  0.0100,  0.0052,  ...,  0.0525,  0.0120,  0.0163],
        ...,
        [ 0.0338,  0.0004,  0.0047,  ..., -0.0146,  0.0189, -0.0173],
        [ 0.0022, -0.0096, -0.0040,  ...,  0.0011, -0.0013,  0.0135],
        [ 0.0178,  0.0135,  0.0019,  ..., -0.0075,  0.0044, -0.0363]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias': tensor([ 0.2430,  0.3418, -0.1379,  ...,  0.0247,  1.4775,  0.2130],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight': tensor([[-0.0026,  0.0052,  0.0064,  ...,  0.0172, -0.0226,  0.0066],
        [-0.0029,  0.0043, -0.0091,  ..., -0.0054, -0.0009,  0.0137],
        [-0.0161,  0.0021,  0.0049,  ...,  0.0088,  0.0251, -0.0076],
        ...,
        [ 0.0092,  0.0003, -0.0009,  ..., -0.0040,  0.0036,  0.0044],
        [ 0.0016, -0.0087,  0.0108,  ..., -0.0028, -0.0046,  0.0207],
        [ 0.0181, -0.0077, -0.0030,  ..., -0.0368, -0.0015,  0.0158]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias': tensor([-0.0217,  0.0017,  0.0176,  ...,  0.0564, -0.0415, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight': tensor([0.8926, 0.8076, 1.0293,  ..., 2.0488, 0.9590, 0.9756],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias': tensor([-0.1279, -0.0777, -0.0509,  ..., -0.2275, -0.0558,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight': tensor([[ 0.0265,  0.0048,  0.0027,  ..., -0.0071,  0.0051,  0.0187],
        [ 0.0004,  0.0177,  0.0098,  ..., -0.0020, -0.0084,  0.0181],
        [-0.0045,  0.0070, -0.0007,  ..., -0.0080, -0.0070, -0.0316],
        ...,
        [-0.0285,  0.0282,  0.0047,  ...,  0.0006, -0.0079,  0.0194],
        [-0.0049, -0.0312, -0.0060,  ..., -0.0043,  0.0310, -0.0003],
        [ 0.0185,  0.0199,  0.0079,  ..., -0.0067, -0.0297, -0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias': tensor([-0.1132, -0.1494, -0.4023,  ..., -0.2355, -0.3335, -0.2045],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight': tensor([[-0.0180,  0.0037,  0.0069,  ..., -0.0019, -0.0086, -0.0024],
        [-0.0006, -0.0030, -0.0042,  ..., -0.0177,  0.0375, -0.0014],
        [-0.0129, -0.0050, -0.0065,  ...,  0.0015, -0.0005, -0.0149],
        ...,
        [ 0.0031,  0.0014, -0.0087,  ..., -0.0003,  0.0073,  0.0014],
        [ 0.0105,  0.0060,  0.0064,  ..., -0.0005, -0.0007,  0.0372],
        [-0.0087, -0.0052,  0.0026,  ..., -0.0113, -0.0085,  0.0098]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias': tensor([-0.0068,  0.0179, -0.0552,  ...,  0.1210, -0.0750, -0.1090],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight': tensor([1.1914, 0.9712, 1.2656,  ..., 0.1719, 0.9092, 1.1973],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias': tensor([-0.0956, -0.1851, -0.0547,  ...,  0.2583, -0.0542,  0.0387],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight': tensor([[ 0.0076, -0.0117, -0.0114,  ...,  0.0770, -0.0048, -0.0017],
        [-0.0195, -0.0001, -0.0053,  ...,  0.0370, -0.0298,  0.0023],
        [-0.0094, -0.0034,  0.0132,  ...,  0.0014,  0.0088, -0.0013],
        ...,
        [ 0.0047, -0.0200, -0.0213,  ..., -0.0028, -0.0125, -0.0193],
        [-0.0028,  0.0018, -0.0313,  ..., -0.0143, -0.0024,  0.0085],
        [-0.0081, -0.0074,  0.0052,  ..., -0.0006, -0.0049, -0.0085]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias': tensor([ 0.0311, -0.0070, -0.0134,  ...,  0.0024, -0.0121, -0.0230],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight': tensor([[ 0.0104, -0.0064, -0.0062,  ...,  0.0015,  0.0052, -0.0058],
        [ 0.0179, -0.0065, -0.0221,  ..., -0.0002, -0.0032, -0.0219],
        [-0.0078,  0.0084, -0.0027,  ..., -0.0003,  0.0120,  0.0011],
        ...,
        [-0.0272, -0.0105,  0.0010,  ..., -0.0082,  0.0024,  0.0062],
        [ 0.0284, -0.0029, -0.0178,  ..., -0.0007, -0.0008, -0.0054],
        [-0.0113,  0.0083,  0.0034,  ..., -0.0102,  0.0250,  0.0115]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias': tensor([ 0.0282,  0.0175, -0.0284,  ...,  0.0397, -0.0209, -0.1344],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight': tensor([[ 0.0094, -0.0159, -0.0203,  ...,  0.0367, -0.0055, -0.0276],
        [ 0.0029, -0.0178, -0.0045,  ..., -0.0709, -0.0047, -0.0184],
        [-0.0128,  0.0083,  0.0116,  ..., -0.0014,  0.0039,  0.0124],
        ...,
        [-0.0292,  0.0131, -0.0025,  ...,  0.0003, -0.0127, -0.0156],
        [-0.0237,  0.0121, -0.0025,  ..., -0.0010,  0.0081, -0.0145],
        [ 0.0137,  0.0139,  0.0163,  ...,  0.0071,  0.0116, -0.0080]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias': tensor([-1.8535,  0.1802,  2.3398,  ..., -0.0595, -0.0338,  0.0305],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight': tensor([[ 0.0028, -0.0249,  0.0077,  ...,  0.0163, -0.0069, -0.0036],
        [ 0.0140, -0.0086,  0.0026,  ...,  0.0077,  0.0073, -0.0239],
        [ 0.0044,  0.0041, -0.0237,  ..., -0.0202, -0.0074,  0.0211],
        ...,
        [-0.0025,  0.0102, -0.0030,  ...,  0.0096,  0.0018,  0.0186],
        [ 0.0052, -0.0034,  0.0046,  ..., -0.0001,  0.0089, -0.0238],
        [-0.0090,  0.0134,  0.0052,  ..., -0.0156, -0.0131,  0.0157]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias': tensor([ 0.0039,  0.0259, -0.0086,  ..., -0.0503, -0.0064, -0.0460],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight': tensor([1.1934, 1.1006, 1.2510,  ..., 1.4092, 1.1592, 1.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias': tensor([ 0.0223, -0.0916,  0.0971,  ..., -0.2983, -0.0408,  0.0070],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight': tensor([[-0.0150,  0.0078,  0.0025,  ..., -0.0011, -0.0016,  0.0092],
        [-0.0219,  0.0313,  0.0128,  ...,  0.0032,  0.0150,  0.0033],
        [-0.0176, -0.0190,  0.0216,  ...,  0.0038, -0.0361,  0.0145],
        ...,
        [ 0.0060, -0.0061, -0.0066,  ...,  0.0027, -0.0050, -0.0172],
        [-0.0283, -0.0057,  0.0115,  ..., -0.0054, -0.0136, -0.0057],
        [-0.0160,  0.0153, -0.0277,  ..., -0.0289, -0.0194,  0.0007]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias': tensor([-0.1221, -0.2144, -0.4114,  ..., -0.1118, -0.1782, -0.3628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight': tensor([[-0.0016,  0.0125, -0.0344,  ..., -0.0221,  0.0044, -0.0154],
        [-0.0039, -0.0351,  0.0205,  ...,  0.0108, -0.0206, -0.0023],
        [ 0.0063, -0.0273, -0.0012,  ...,  0.0131,  0.0057, -0.0150],
        ...,
        [-0.0002, -0.0069,  0.0022,  ..., -0.0065,  0.0032,  0.0088],
        [ 0.0108, -0.0061, -0.0134,  ..., -0.0061,  0.0058, -0.0083],
        [ 0.0133,  0.0173,  0.0049,  ...,  0.0188, -0.0199, -0.0074]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias': tensor([-0.0200,  0.0232, -0.0657,  ...,  0.1028, -0.0782, -0.1134],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight': tensor([1.2578, 1.1084, 1.2061,  ..., 0.5884, 1.0264, 1.2910],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias': tensor([-0.0061, -0.0651,  0.0878,  ...,  0.1716,  0.1021, -0.0355],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight': tensor([[-0.0184, -0.0017,  0.0284,  ..., -0.0922, -0.0121,  0.0085],
        [ 0.0216,  0.0109,  0.0091,  ..., -0.0531,  0.0165, -0.0052],
        [-0.0036,  0.0282,  0.0128,  ...,  0.0421, -0.0305, -0.0203],
        ...,
        [-0.0003, -0.0044, -0.0082,  ..., -0.0171,  0.0052,  0.0071],
        [ 0.0136, -0.0294, -0.0073,  ..., -0.0191, -0.0179,  0.0170],
        [-0.0079,  0.0298, -0.0092,  ...,  0.0071,  0.0015,  0.0033]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias': tensor([-0.0044, -0.0038, -0.0472,  ...,  0.0818,  0.0363, -0.0465],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight': tensor([[ 1.9028e-02,  3.3264e-03, -1.4641e-02,  ..., -4.6754e-04,
         -1.4366e-02,  1.6556e-02],
        [ 2.1267e-04, -1.5457e-02, -3.2166e-02,  ..., -2.4629e-04,
          5.9090e-03, -9.8267e-03],
        [-1.2535e-02, -1.2222e-02,  9.6970e-03,  ...,  1.7128e-03,
         -2.1992e-03,  3.7842e-03],
        ...,
        [ 1.0918e-02,  1.8097e-02,  1.2695e-02,  ...,  4.8494e-04,
          5.1918e-03, -1.9058e-02],
        [ 9.9792e-03, -1.2085e-02,  6.0320e-04,  ...,  3.4790e-03,
          1.0284e-02,  2.8300e-04],
        [ 2.2034e-02, -1.5373e-03, -2.1362e-02,  ...,  4.9706e-03,
         -4.9174e-05, -6.5117e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias': tensor([ 0.0094,  0.0439, -0.0031,  ..., -0.0485, -0.1193,  0.0170],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight': tensor([[-1.2352e-02,  2.3239e-02,  5.5618e-03,  ..., -5.1178e-02,
         -2.8687e-02,  2.2531e-05],
        [-1.0605e-02, -2.5497e-02,  1.1894e-02,  ..., -2.0462e-02,
         -8.5449e-04,  4.6265e-02],
        [ 8.6212e-03, -9.3765e-03,  5.9357e-03,  ...,  2.0432e-02,
         -2.2537e-02,  4.4495e-02],
        ...,
        [ 1.3062e-02, -5.5428e-03,  1.0025e-02,  ..., -4.5746e-02,
          6.3477e-03,  2.0248e-02],
        [ 9.6588e-03, -1.4442e-02, -2.0096e-02,  ...,  6.9542e-03,
          5.9013e-03, -3.3588e-03],
        [-5.3177e-03,  2.2705e-02, -2.1713e-02,  ...,  2.4307e-02,
          1.5465e-02, -8.3237e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias': tensor([ 0.0542, -0.0733,  0.2440,  ..., -0.3313, -0.1129,  0.1049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight': tensor([[-0.0227,  0.0130, -0.0113,  ..., -0.0045,  0.0108, -0.0190],
        [-0.0057, -0.0069,  0.0119,  ..., -0.0068,  0.0143,  0.0030],
        [ 0.0062,  0.0204,  0.0161,  ..., -0.0079, -0.0057,  0.0308],
        ...,
        [ 0.0001,  0.0003,  0.0048,  ...,  0.0089, -0.0032,  0.0210],
        [-0.0079,  0.0007,  0.0030,  ...,  0.0093, -0.0068, -0.0121],
        [-0.0154,  0.0158, -0.0231,  ..., -0.0158,  0.0141, -0.0072]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias': tensor([-0.0179,  0.0685, -0.0152,  ..., -0.0815,  0.0257,  0.0175],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight': tensor([1.1738, 1.1582, 1.1592,  ..., 1.5869, 1.1748, 1.2314],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias': tensor([-0.0068,  0.0917, -0.0354,  ..., -0.3271, -0.1141, -0.0543],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight': tensor([[-0.0195, -0.0128, -0.0054,  ..., -0.0029, -0.0047,  0.0116],
        [-0.0031, -0.0199,  0.0011,  ..., -0.0044,  0.0127,  0.0019],
        [ 0.0130, -0.0056,  0.0037,  ..., -0.0005,  0.0237,  0.0081],
        ...,
        [ 0.0115,  0.0130, -0.0272,  ...,  0.0021,  0.0227,  0.0057],
        [-0.0035,  0.0108, -0.0211,  ..., -0.0011,  0.0154, -0.0001],
        [-0.0336,  0.0183,  0.0121,  ..., -0.0012, -0.0093,  0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias': tensor([-0.3628, -0.2211, -0.1648,  ..., -0.2524, -0.2686, -0.2517],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight': tensor([[-4.5166e-03,  7.6828e-03,  1.3664e-02,  ..., -2.5959e-03,
         -2.0126e-02, -7.1602e-03],
        [-1.4015e-02,  2.0084e-03,  6.2370e-03,  ...,  1.9714e-02,
         -4.8294e-03, -2.3682e-02],
        [-4.3793e-03,  6.3400e-03,  5.3253e-03,  ...,  9.2888e-04,
          7.6599e-03, -1.8555e-02],
        ...,
        [-4.1809e-03, -1.8768e-03,  4.0741e-03,  ..., -1.5802e-03,
         -3.6144e-03,  8.3983e-05],
        [-2.7523e-03, -2.6489e-02, -1.3283e-02,  ...,  3.4904e-03,
         -1.4786e-02,  6.2981e-03],
        [-3.0880e-03, -2.1713e-02, -1.7853e-02,  ...,  1.1139e-02,
          7.2784e-03, -1.2558e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias': tensor([-0.0283,  0.0284, -0.0329,  ...,  0.0671, -0.0050, -0.0488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight': tensor([1.2725, 1.2539, 1.2041,  ..., 0.7529, 1.0645, 1.2422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias': tensor([ 0.0019, -0.0140,  0.0246,  ...,  0.2150, -0.1251, -0.2118],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0117,  0.0046,  ..., -0.0265, -0.0033,  0.0070],
        [ 0.0061,  0.0207, -0.0110,  ...,  0.0132,  0.0091,  0.0226],
        [-0.0012,  0.0130,  0.0031,  ...,  0.0025,  0.0157,  0.0028],
        ...,
        [ 0.0178,  0.0099,  0.0200,  ...,  0.0006, -0.0303, -0.0324],
        [-0.0035,  0.0138,  0.0245,  ..., -0.0032, -0.0065,  0.0055],
        [-0.0023,  0.0024, -0.0018,  ...,  0.0053,  0.0023, -0.0070]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias': tensor([ 0.1105, -0.0046,  0.0618,  ...,  0.0103, -0.0147,  0.0179],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight': tensor([[ 0.0128, -0.0147,  0.0370,  ..., -0.0059,  0.0019, -0.0157],
        [-0.0200,  0.0040, -0.0021,  ..., -0.0084, -0.0056, -0.0079],
        [-0.0030, -0.0037, -0.0301,  ..., -0.0076,  0.0190,  0.0188],
        ...,
        [ 0.0036,  0.0197, -0.0007,  ..., -0.0078,  0.0181, -0.0004],
        [-0.0112,  0.0034, -0.0117,  ...,  0.0041, -0.0017, -0.0116],
        [-0.0199,  0.0032, -0.0224,  ..., -0.0046,  0.0289,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias': tensor([-0.0085, -0.0267, -0.0139,  ..., -0.0130,  0.0113,  0.0014],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight': tensor([[-5.2223e-03, -1.1261e-02,  2.0859e-02,  ..., -3.4424e-02,
          5.4245e-03,  3.5515e-03],
        [ 2.7637e-03,  4.4861e-03,  5.6877e-03,  ...,  6.7830e-05,
         -1.3123e-02,  1.6266e-02],
        [-7.9575e-03,  6.3133e-03,  1.7059e-02,  ...,  2.5711e-03,
         -5.4283e-03, -1.0437e-02],
        ...,
        [-1.2264e-03,  2.9633e-02, -8.0185e-03,  ...,  1.4366e-02,
          2.8824e-02, -1.8001e-05],
        [ 5.7316e-04,  8.2397e-03,  1.8951e-02,  ...,  1.4248e-03,
          1.8433e-02, -1.7624e-02],
        [ 6.5842e-03,  2.7451e-02, -1.9012e-02,  ...,  1.1887e-02,
         -7.3357e-03,  1.1284e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias': tensor([-0.8462,  0.0103, -1.0879,  ..., -0.1941,  0.1663, -1.2803],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight': tensor([[-0.0020,  0.0252,  0.0039,  ...,  0.0061, -0.0123,  0.0283],
        [ 0.0043,  0.0004, -0.0082,  ..., -0.0251,  0.0068,  0.0017],
        [-0.0231,  0.0006,  0.0164,  ...,  0.0248,  0.0101,  0.0125],
        ...,
        [ 0.0080,  0.0312,  0.0238,  ...,  0.0045,  0.0003,  0.0054],
        [ 0.0077,  0.0073, -0.0009,  ..., -0.0016,  0.0038, -0.0133],
        [ 0.0194, -0.0053, -0.0238,  ...,  0.0249, -0.0041,  0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias': tensor([-0.0205,  0.0181, -0.0017,  ..., -0.0779,  0.0408, -0.0200],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight': tensor([1.1533, 1.2090, 1.1787,  ..., 1.6367, 1.1729, 1.2188],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias': tensor([-0.0550,  0.0990, -0.0018,  ..., -0.1779, -0.0518, -0.0147],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight': tensor([[-0.0073, -0.0223,  0.0130,  ..., -0.0079, -0.0028,  0.0022],
        [-0.0071,  0.0068,  0.0017,  ..., -0.0123, -0.0179, -0.0108],
        [ 0.0072,  0.0217,  0.0110,  ...,  0.0060,  0.0005,  0.0016],
        ...,
        [ 0.0225, -0.0085,  0.0064,  ...,  0.0007,  0.0014, -0.0003],
        [-0.0191,  0.0245,  0.0085,  ..., -0.0102, -0.0108, -0.0063],
        [ 0.0290, -0.0322, -0.0287,  ..., -0.0045,  0.0156, -0.0153]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias': tensor([-0.4795, -0.1469, -0.1043,  ..., -0.2998, -0.2252, -0.3262],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight': tensor([[-0.0205,  0.0170, -0.0019,  ...,  0.0084,  0.0040,  0.0268],
        [ 0.0060,  0.0025, -0.0069,  ...,  0.0071, -0.0261,  0.0028],
        [ 0.0291, -0.0064, -0.0019,  ..., -0.0131,  0.0078, -0.0294],
        ...,
        [-0.0110,  0.0011, -0.0081,  ..., -0.0030,  0.0036, -0.0003],
        [-0.0195,  0.0083,  0.0063,  ...,  0.0095, -0.0105,  0.0214],
        [-0.0028,  0.0316,  0.0016,  ..., -0.0094, -0.0051,  0.0145]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias': tensor([ 0.0411, -0.0040, -0.0517,  ...,  0.1116,  0.0086, -0.0608],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight': tensor([1.3838, 1.2871, 1.2334,  ..., 0.6108, 1.1768, 1.2568],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias': tensor([-0.2367,  0.0573,  0.1235,  ...,  0.2408,  0.0240, -0.0257],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight': tensor([[-0.0176,  0.0033,  0.0183,  ..., -0.0038,  0.0074,  0.0088],
        [-0.0091,  0.0276, -0.0216,  ...,  0.0220,  0.0110,  0.0020],
        [-0.0428, -0.0160,  0.0246,  ...,  0.0130, -0.0163, -0.0116],
        ...,
        [ 0.0326,  0.0183, -0.0093,  ...,  0.0212, -0.0169,  0.0020],
        [ 0.0131,  0.0204,  0.0034,  ...,  0.0138,  0.0030,  0.0125],
        [ 0.0216,  0.0034,  0.0112,  ..., -0.0203,  0.0063, -0.0135]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias': tensor([-0.0005,  0.0142, -0.0017,  ...,  0.0816, -0.0667,  0.0688],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight': tensor([[-0.0305, -0.0173,  0.0406,  ...,  0.0054,  0.0093, -0.0001],
        [ 0.0040,  0.0132, -0.0068,  ..., -0.0034, -0.0217, -0.0175],
        [-0.0051,  0.0121, -0.0121,  ..., -0.0104, -0.0141, -0.0050],
        ...,
        [ 0.0016,  0.0205, -0.0056,  ..., -0.0040, -0.0046,  0.0020],
        [ 0.0378,  0.0040, -0.0073,  ...,  0.0001, -0.0014,  0.0133],
        [ 0.0088, -0.0021, -0.0040,  ..., -0.0019,  0.0257, -0.0056]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias': tensor([-0.0842, -0.0092,  0.0031,  ...,  0.0677, -0.0071,  0.0129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight': tensor([[ 0.0169, -0.0117, -0.0191,  ...,  0.0101, -0.0038,  0.0100],
        [-0.0080,  0.0092,  0.0094,  ...,  0.0197, -0.0175, -0.0183],
        [-0.0264, -0.0041,  0.0021,  ...,  0.0114,  0.0084, -0.0139],
        ...,
        [-0.0015,  0.0094,  0.0175,  ...,  0.0220, -0.0158,  0.0012],
        [-0.0012,  0.0214, -0.0034,  ...,  0.0166, -0.0191,  0.0039],
        [ 0.0204, -0.0130,  0.0074,  ..., -0.0208,  0.0063, -0.0040]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias': tensor([ 0.0173,  0.2045, -0.1959,  ..., -0.0136, -0.0571, -0.2710],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight': tensor([[ 1.1879e-02, -8.7357e-03, -2.2980e-02,  ..., -5.5885e-03,
         -2.6260e-02,  1.4985e-04],
        [ 2.3117e-02, -1.8127e-02,  2.0111e-02,  ..., -5.3711e-03,
         -3.0880e-03, -2.6855e-03],
        [-7.4577e-03,  5.7449e-03, -2.7313e-02,  ...,  2.7695e-03,
          7.9803e-03,  1.0475e-02],
        ...,
        [-1.1810e-02,  1.0620e-02,  1.4153e-02,  ...,  7.8049e-03,
          7.3671e-04,  2.8267e-03],
        [ 6.1150e-03,  1.5244e-02,  2.3621e-02,  ...,  9.0599e-05,
          2.7008e-03, -3.2196e-02],
        [ 3.8743e-04, -6.6109e-03, -1.4534e-02,  ...,  1.1330e-03,
         -1.8280e-02, -3.4065e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias': tensor([-0.0230,  0.0388, -0.0072,  ..., -0.0651,  0.0296, -0.0002],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight': tensor([1.2031, 1.2344, 1.1543,  ..., 1.5986, 1.2275, 1.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias': tensor([-0.0587,  0.0094, -0.0588,  ..., -0.2544, -0.1669, -0.0670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight': tensor([[-0.0105, -0.0159, -0.0260,  ..., -0.0012,  0.0033,  0.0001],
        [ 0.0232, -0.0237,  0.0074,  ..., -0.0032,  0.0108,  0.0003],
        [ 0.0088,  0.0072,  0.0034,  ...,  0.0001, -0.0065,  0.0012],
        ...,
        [ 0.0007, -0.0093,  0.0181,  ..., -0.0021, -0.0059,  0.0082],
        [ 0.0024,  0.0102, -0.0177,  ..., -0.0005, -0.0069, -0.0302],
        [ 0.0112,  0.0245,  0.0004,  ...,  0.0030, -0.0044,  0.0190]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias': tensor([-0.1327, -0.2241, -0.0568,  ..., -0.2708, -0.3245, -0.0823],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight': tensor([[ 1.0185e-02, -1.1162e-02, -2.3911e-02,  ...,  2.9709e-02,
         -1.3023e-02, -1.1803e-02],
        [ 8.2092e-03, -4.3631e-04, -3.1257e-04,  ..., -1.3252e-02,
          5.4598e-05, -1.8997e-02],
        [ 5.5885e-03,  1.8112e-02,  9.0179e-03,  ..., -3.1700e-03,
          8.4686e-03, -3.6144e-03],
        ...,
        [ 4.7798e-03,  3.0174e-03, -3.5143e-04,  ...,  5.4665e-03,
         -3.4122e-03, -4.2953e-03],
        [ 3.2082e-03, -1.4816e-02, -9.4986e-04,  ..., -1.9455e-02,
         -9.8825e-05,  9.9869e-03],
        [-7.2784e-03, -5.8289e-03, -3.9062e-03,  ...,  5.5122e-03,
         -2.4323e-02, -2.7542e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias': tensor([ 0.0389,  0.0069, -0.0129,  ...,  0.0417,  0.0218,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight': tensor([1.4287, 1.3613, 1.2949,  ..., 1.0137, 1.1826, 1.3213],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias': tensor([-0.1137,  0.0275,  0.0679,  ...,  0.1796,  0.0205, -0.2534],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight': tensor([[ 0.0030,  0.0209, -0.0001,  ..., -0.0044,  0.0148,  0.0093],
        [-0.0027, -0.0116,  0.0012,  ...,  0.0060, -0.0152, -0.0084],
        [-0.0064,  0.0066, -0.0148,  ..., -0.0031, -0.0160,  0.0061],
        ...,
        [ 0.0134, -0.0141, -0.0170,  ...,  0.0031, -0.0175,  0.0096],
        [ 0.0032, -0.0072,  0.0027,  ...,  0.0026,  0.0248,  0.0016],
        [ 0.0372, -0.0190,  0.0259,  ..., -0.0076,  0.0134,  0.0181]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias': tensor([ 0.0132, -0.0158,  0.0312,  ...,  0.1599,  0.0190, -0.0702],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight': tensor([[-0.0019,  0.0161, -0.0136,  ...,  0.0041,  0.0124, -0.0042],
        [ 0.0003, -0.0210,  0.0050,  ...,  0.0030, -0.0272,  0.0083],
        [-0.0101, -0.0327, -0.0195,  ..., -0.0035,  0.0067, -0.0172],
        ...,
        [ 0.0214, -0.0060, -0.0126,  ..., -0.0054, -0.0032,  0.0097],
        [-0.0153, -0.0010, -0.0009,  ...,  0.0023, -0.0131,  0.0013],
        [ 0.0080,  0.0060,  0.0053,  ..., -0.0054, -0.0073,  0.0102]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias': tensor([-0.0223, -0.0200, -0.0063,  ..., -0.0170, -0.0150,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight': tensor([[-0.0132,  0.0006,  0.0249,  ..., -0.0071,  0.0142, -0.0221],
        [-0.0046,  0.0369, -0.0272,  ...,  0.0017,  0.0163,  0.0032],
        [-0.0089, -0.0084,  0.0370,  ..., -0.0099,  0.0085,  0.0120],
        ...,
        [ 0.0223, -0.0226, -0.0282,  ...,  0.0133, -0.0224, -0.0005],
        [ 0.0005, -0.0127, -0.0058,  ..., -0.0071,  0.0076, -0.0049],
        [-0.0067,  0.0026,  0.0143,  ...,  0.0054, -0.0011,  0.0246]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias': tensor([-0.0499, -0.0381,  0.5078,  ..., -0.0939, -1.3535,  0.2761],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight': tensor([[ 0.0038,  0.0181,  0.0089,  ..., -0.0054,  0.0091,  0.0008],
        [-0.0116,  0.0084,  0.0211,  ...,  0.0138,  0.0282, -0.0086],
        [ 0.0388,  0.0029,  0.0070,  ..., -0.0161,  0.0043, -0.0173],
        ...,
        [ 0.0053, -0.0073, -0.0049,  ...,  0.0171, -0.0165,  0.0032],
        [ 0.0020, -0.0032,  0.0069,  ...,  0.0089,  0.0018,  0.0021],
        [ 0.0025, -0.0044,  0.0106,  ..., -0.0193,  0.0141, -0.0083]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias': tensor([ 0.0060,  0.0680,  0.0354,  ..., -0.0553,  0.0136,  0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight': tensor([1.2344, 1.2090, 1.1689,  ..., 1.8428, 1.1562, 1.2676],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias': tensor([-0.0174, -0.0716, -0.1256,  ..., -0.2900, -0.1460,  0.1504],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight': tensor([[-0.0042, -0.0027,  0.0133,  ..., -0.0005,  0.0226, -0.0110],
        [ 0.0404,  0.0308,  0.0195,  ...,  0.0055, -0.0234,  0.0145],
        [-0.0008, -0.0259, -0.0103,  ...,  0.0008,  0.0100,  0.0084],
        ...,
        [ 0.0190, -0.0154,  0.0061,  ..., -0.0111, -0.0397,  0.0165],
        [ 0.0025, -0.0002,  0.0089,  ..., -0.0010, -0.0172, -0.0077],
        [ 0.0183, -0.0069, -0.0037,  ...,  0.0029, -0.0036,  0.0130]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias': tensor([-0.2314, -0.3215, -0.0735,  ..., -0.3020, -0.1613, -0.3066],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight': tensor([[ 1.0155e-02,  3.2532e-02,  8.2626e-03,  ..., -6.4468e-03,
         -4.7760e-03,  5.5432e-06],
        [-1.1612e-02,  1.7509e-03,  2.4841e-02,  ...,  8.9645e-03,
         -2.5436e-02, -8.4152e-03],
        [ 1.5182e-02,  7.3395e-03,  6.1264e-03,  ..., -1.5427e-02,
         -1.8677e-02,  1.9806e-02],
        ...,
        [-5.6686e-03,  6.3848e-04,  4.5128e-03,  ..., -9.9792e-03,
          1.1284e-02,  6.5231e-04],
        [-3.6335e-03,  3.6285e-02, -9.9277e-04,  ...,  4.8828e-03,
          9.6283e-03,  1.3008e-02],
        [ 9.3918e-03, -2.1927e-02, -1.4038e-02,  ...,  1.3329e-02,
          5.4359e-03,  3.3169e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias': tensor([0.0373, 0.0198, 0.0018,  ..., 0.0559, 0.0675, 0.0106],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight': tensor([1.4990, 1.4297, 1.3555,  ..., 0.9502, 1.1816, 1.4072],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias': tensor([-0.1736, -0.0029,  0.0179,  ...,  0.2495,  0.0637, -0.1158],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight': tensor([[ 0.0138, -0.0022,  0.0212,  ...,  0.0048,  0.0084,  0.0082],
        [-0.0165, -0.0025,  0.0060,  ...,  0.0063,  0.0062, -0.0098],
        [ 0.0116,  0.0009,  0.0094,  ...,  0.0054,  0.0176,  0.0027],
        ...,
        [ 0.0160, -0.0161,  0.0148,  ..., -0.0268,  0.0052,  0.0090],
        [-0.0136,  0.0253, -0.0004,  ...,  0.0156,  0.0059,  0.0038],
        [-0.0080,  0.0130, -0.0251,  ...,  0.0136, -0.0164,  0.0184]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias': tensor([ 0.1146,  1.0303,  0.1827,  ...,  0.0439,  0.0025, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight': tensor([[ 0.0113, -0.0085, -0.0074,  ...,  0.0006, -0.0214, -0.0142],
        [ 0.0022,  0.0155, -0.0111,  ..., -0.0004, -0.0232, -0.0101],
        [-0.0139,  0.0073, -0.0043,  ..., -0.0005, -0.0110, -0.0235],
        ...,
        [ 0.0153,  0.0130, -0.0090,  ...,  0.0045,  0.0109,  0.0025],
        [ 0.0072,  0.0052, -0.0024,  ..., -0.0120,  0.0016, -0.0072],
        [ 0.0013, -0.0272, -0.0105,  ..., -0.0043,  0.0004, -0.0020]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias': tensor([ 0.0573, -0.0360, -0.0042,  ...,  0.0485, -0.0465,  0.0206],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight': tensor([[ 0.0094,  0.0003,  0.0279,  ...,  0.0015, -0.0191,  0.0090],
        [ 0.0041, -0.0014,  0.0020,  ...,  0.0017, -0.0018,  0.0040],
        [-0.0280,  0.0335,  0.0134,  ...,  0.0017,  0.0047, -0.0206],
        ...,
        [-0.0081, -0.0019,  0.0095,  ..., -0.0111, -0.0239,  0.0087],
        [-0.0195, -0.0019,  0.0218,  ...,  0.0267,  0.0121, -0.0089],
        [-0.0340, -0.0066,  0.0098,  ...,  0.0160,  0.0019, -0.0100]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias': tensor([ 0.2460,  1.7949,  0.0708,  ..., -0.2112,  0.1188,  0.6323],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight': tensor([[ 0.0051,  0.0107, -0.0119,  ..., -0.0148,  0.0005, -0.0302],
        [-0.0066, -0.0071, -0.0048,  ..., -0.0226, -0.0094,  0.0276],
        [ 0.0101,  0.0083,  0.0168,  ..., -0.0064,  0.0009, -0.0152],
        ...,
        [ 0.0094, -0.0071,  0.0016,  ..., -0.0147,  0.0114,  0.0020],
        [ 0.0223,  0.0076,  0.0287,  ..., -0.0214,  0.0006,  0.0041],
        [ 0.0177,  0.0222,  0.0063,  ...,  0.0065,  0.0120, -0.0114]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias': tensor([ 0.0267, -0.0057, -0.0027,  ..., -0.0531, -0.0267,  0.0482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight': tensor([1.2383, 1.2549, 1.2197,  ..., 1.8193, 1.1484, 1.3037],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias': tensor([ 0.1250, -0.0352,  0.1172,  ..., -0.1227, -0.0328,  0.1005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight': tensor([[-0.0007, -0.0112,  0.0090,  ..., -0.0016,  0.0087,  0.0027],
        [ 0.0122, -0.0152,  0.0042,  ..., -0.0079, -0.0033, -0.0148],
        [ 0.0095, -0.0118, -0.0270,  ...,  0.0040,  0.0046, -0.0246],
        ...,
        [-0.0209, -0.0194, -0.0025,  ..., -0.0006, -0.0144,  0.0085],
        [ 0.0016,  0.0133,  0.0006,  ..., -0.0033, -0.0143,  0.0128],
        [-0.0106,  0.0115,  0.0019,  ..., -0.0046, -0.0505,  0.0052]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias': tensor([-0.3506, -0.3098, -0.0692,  ..., -0.3076, -0.2494, -0.4229],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight': tensor([[-0.0116,  0.0186, -0.0109,  ...,  0.0093, -0.0051, -0.0192],
        [ 0.0115,  0.0091,  0.0046,  ...,  0.0060, -0.0104, -0.0086],
        [-0.0004,  0.0162,  0.0221,  ...,  0.0048,  0.0374,  0.0092],
        ...,
        [-0.0029,  0.0068, -0.0073,  ...,  0.0019, -0.0060,  0.0068],
        [ 0.0121, -0.0012, -0.0035,  ..., -0.0168, -0.0036, -0.0015],
        [ 0.0085, -0.0005,  0.0138,  ..., -0.0026,  0.0074, -0.0113]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias': tensor([ 0.0374, -0.0088, -0.0430,  ...,  0.0654, -0.0126, -0.0253],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight': tensor([1.5195, 1.3818, 1.3984,  ..., 0.8403, 1.2627, 1.5020],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias': tensor([-0.1865,  0.1162,  0.4048,  ...,  0.2292,  0.4202, -0.0959],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight': tensor([[ 0.0295,  0.0205, -0.0174,  ...,  0.0181,  0.0055,  0.0153],
        [ 0.0159, -0.0236, -0.0138,  ...,  0.0058,  0.0019,  0.0084],
        [-0.0116, -0.0219,  0.0080,  ...,  0.0020, -0.0022,  0.0255],
        ...,
        [-0.0140,  0.0030, -0.0549,  ...,  0.0038, -0.0079,  0.0469],
        [-0.0193,  0.0216, -0.0092,  ...,  0.0083,  0.0186,  0.0123],
        [ 0.0039,  0.0084,  0.0082,  ..., -0.0016, -0.0041, -0.0187]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias': tensor([-0.0278, -0.0587, -0.0110,  ..., -0.0826, -0.0213, -0.0725],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight': tensor([[-0.0007,  0.0020,  0.0042,  ..., -0.0033, -0.0094, -0.0123],
        [ 0.0162,  0.0139,  0.0239,  ..., -0.0017, -0.0188,  0.0138],
        [-0.0234,  0.0133, -0.0101,  ..., -0.0029, -0.0003,  0.0196],
        ...,
        [ 0.0244,  0.0202,  0.0058,  ..., -0.0130,  0.0092, -0.0032],
        [ 0.0215,  0.0236, -0.0171,  ..., -0.0159, -0.0069,  0.0134],
        [-0.0087,  0.0025,  0.0248,  ..., -0.0004,  0.0047, -0.0208]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias': tensor([-0.0305,  0.0005, -0.0124,  ..., -0.0511, -0.0883,  0.0079],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight': tensor([[-0.0156,  0.0022, -0.0072,  ...,  0.0036,  0.0290,  0.0180],
        [-0.0003,  0.0088, -0.0014,  ..., -0.0144, -0.0101,  0.0001],
        [-0.0141, -0.0287,  0.0098,  ..., -0.0024,  0.0292,  0.0254],
        ...,
        [-0.0255,  0.0364, -0.0171,  ...,  0.0032,  0.0116, -0.0182],
        [-0.0159,  0.0349, -0.0009,  ..., -0.0083, -0.0006, -0.0242],
        [-0.0239,  0.0287,  0.0045,  ...,  0.0057, -0.0037, -0.0132]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias': tensor([-0.2856, -0.3130, -0.2024,  ...,  0.1942, -0.0307, -0.0692],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight': tensor([[ 0.0021, -0.0248,  0.0393,  ..., -0.0213, -0.0080,  0.0129],
        [-0.0123, -0.0083,  0.0236,  ..., -0.0091, -0.0172, -0.0205],
        [-0.0194, -0.0024,  0.0146,  ..., -0.0071,  0.0185, -0.0175],
        ...,
        [-0.0277,  0.0011, -0.0187,  ...,  0.0559,  0.0597, -0.0009],
        [ 0.0156,  0.0051, -0.0020,  ..., -0.0031,  0.0066,  0.0040],
        [-0.0057, -0.0281, -0.0138,  ...,  0.0075, -0.0093,  0.0108]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias': tensor([ 0.0077,  0.0031,  0.0012,  ..., -0.0701,  0.0300,  0.0083],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight': tensor([1.2822, 1.2529, 1.2988,  ..., 2.2090, 1.1758, 1.3721],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias': tensor([ 0.1495, -0.0801, -0.0723,  ..., -0.1654, -0.0899,  0.0350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight': tensor([[ 0.0063,  0.0413,  0.0369,  ...,  0.0064,  0.0150,  0.0227],
        [ 0.0141,  0.0154,  0.0189,  ...,  0.0018,  0.0107,  0.0041],
        [-0.0081, -0.0167,  0.0103,  ..., -0.0018, -0.0027,  0.0110],
        ...,
        [ 0.0142,  0.0290,  0.0162,  ..., -0.0030,  0.0042,  0.0023],
        [ 0.0167,  0.0140,  0.0168,  ..., -0.0036, -0.0046,  0.0118],
        [-0.0082,  0.0164,  0.0227,  ...,  0.0009, -0.0199, -0.0222]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias': tensor([-0.2788, -0.1959, -0.3855,  ..., -0.3228, -0.2610, -0.0354],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight': tensor([[-6.8474e-03, -1.1681e-02, -1.7517e-02,  ...,  1.0986e-02,
         -1.8341e-02,  2.0432e-02],
        [ 1.1215e-02, -7.8430e-03, -6.9542e-03,  ...,  1.2108e-02,
         -9.6741e-03, -1.2093e-02],
        [ 1.2321e-02, -2.7924e-02, -2.8896e-03,  ...,  4.8676e-03,
         -2.0275e-03, -1.2695e-02],
        ...,
        [-2.5902e-03,  1.4412e-02, -3.3092e-03,  ..., -2.8193e-05,
          6.4087e-04, -7.4434e-04],
        [-1.8280e-02, -8.6746e-03,  9.6130e-03,  ...,  4.2915e-03,
         -1.1269e-02,  2.3453e-02],
        [-6.6452e-03, -2.1088e-02, -1.2444e-02,  ..., -3.5534e-03,
         -7.8659e-03,  2.5589e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias': tensor([ 0.0329,  0.0112, -0.0181,  ...,  0.0332,  0.0061, -0.0410],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight': tensor([1.6201, 1.4990, 1.4219,  ..., 0.7642, 1.2715, 1.4961],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias': tensor([-0.1376, -0.0238, -0.0118,  ...,  0.3352,  0.1462, -0.0976],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight': tensor([[ 0.0070,  0.0068,  0.0031,  ...,  0.0113, -0.0308, -0.0060],
        [ 0.0026, -0.0039,  0.0043,  ..., -0.0343, -0.0066,  0.0307],
        [-0.0036,  0.0332, -0.0028,  ...,  0.0011, -0.0337,  0.0031],
        ...,
        [-0.0229, -0.0187, -0.0097,  ..., -0.0007,  0.0183, -0.0038],
        [ 0.0047,  0.0152, -0.0175,  ...,  0.0070,  0.0130, -0.0114],
        [-0.0206,  0.0068, -0.0252,  ...,  0.0070, -0.0134, -0.0160]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias': tensor([ 0.1860, -0.2378,  0.0005,  ...,  0.0031,  0.1797, -0.0522],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight': tensor([[-0.0298, -0.0140,  0.0248,  ...,  0.0035, -0.0014, -0.0059],
        [-0.0006, -0.0080,  0.0046,  ...,  0.0036,  0.0106, -0.0112],
        [ 0.0055,  0.0188,  0.0175,  ...,  0.0029, -0.0033, -0.0018],
        ...,
        [ 0.0039, -0.0129,  0.0162,  ...,  0.0032, -0.0222, -0.0056],
        [-0.0039, -0.0104,  0.0050,  ..., -0.0019,  0.0213, -0.0076],
        [ 0.0024,  0.0067, -0.0013,  ..., -0.0021,  0.0013,  0.0046]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias': tensor([ 0.0186, -0.0095,  0.0066,  ...,  0.0210,  0.0131,  0.0208],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight': tensor([[ 0.0029, -0.0233, -0.0027,  ...,  0.0144, -0.0352, -0.0105],
        [-0.0247, -0.0116,  0.0012,  ..., -0.0372,  0.0113, -0.0128],
        [ 0.0080, -0.0012, -0.0150,  ...,  0.0013, -0.0024,  0.0199],
        ...,
        [-0.0113, -0.0235, -0.0017,  ...,  0.0006, -0.0010, -0.0029],
        [ 0.0197, -0.0205, -0.0153,  ...,  0.0061,  0.0182,  0.0045],
        [-0.0173, -0.0083,  0.0412,  ...,  0.0141, -0.0057,  0.0143]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias': tensor([ 0.2690, -0.1337,  0.1326,  ...,  0.5728, -0.2661, -0.0468],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight': tensor([[ 0.0029,  0.0160,  0.0056,  ...,  0.0018,  0.0077, -0.0090],
        [ 0.0110, -0.0064,  0.0049,  ...,  0.0272,  0.0262,  0.0051],
        [-0.0114, -0.0032,  0.0054,  ...,  0.0236, -0.0132, -0.0082],
        ...,
        [-0.0007,  0.0021, -0.0044,  ..., -0.0028, -0.0311, -0.0200],
        [-0.0074, -0.0073, -0.0035,  ..., -0.0198, -0.0346, -0.0070],
        [-0.0123, -0.0216,  0.0046,  ...,  0.0036,  0.0109, -0.0127]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias': tensor([-0.0063, -0.0193, -0.0133,  ...,  0.0398,  0.0332,  0.0196],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight': tensor([1.3359, 1.2266, 1.2646,  ..., 1.9346, 1.1377, 1.3818],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias': tensor([ 0.1417,  0.0006,  0.0168,  ...,  0.0170, -0.0730,  0.0124],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight': tensor([[ 0.0115,  0.0003, -0.0145,  ..., -0.0144, -0.0194, -0.0104],
        [-0.0015,  0.0058,  0.0179,  ..., -0.0030,  0.0044, -0.0100],
        [-0.0029,  0.0045,  0.0084,  ..., -0.0206,  0.0133,  0.0283],
        ...,
        [ 0.0059, -0.0118, -0.0161,  ..., -0.0221, -0.0054,  0.0157],
        [ 0.0215, -0.0010,  0.0022,  ...,  0.0130,  0.0179,  0.0099],
        [ 0.0113,  0.0054, -0.0108,  ...,  0.0036,  0.0090, -0.0237]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias': tensor([-0.2153, -0.2783, -0.3320,  ..., -0.1221, -0.1306, -0.2898],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight': tensor([[-0.0038, -0.0308,  0.0166,  ..., -0.0028, -0.0180,  0.0016],
        [ 0.0179,  0.0086,  0.0044,  ...,  0.0105,  0.0129, -0.0061],
        [-0.0078, -0.0048,  0.0276,  ...,  0.0158, -0.0102,  0.0017],
        ...,
        [-0.0093,  0.0032, -0.0129,  ...,  0.0116, -0.0041, -0.0039],
        [-0.0126,  0.0043,  0.0086,  ...,  0.0042, -0.0106,  0.0038],
        [-0.0054, -0.0066, -0.0067,  ..., -0.0130, -0.0257,  0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias': tensor([ 0.0253, -0.0025, -0.0242,  ...,  0.0955,  0.0208, -0.0150],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight': tensor([1.6533, 1.5479, 1.5508,  ..., 0.4094, 1.3984, 1.6689],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias': tensor([-0.2152,  0.1279,  0.3982,  ...,  0.3850,  0.3862, -0.2152],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight': tensor([[ 0.0007,  0.0003,  0.0054,  ...,  0.0126,  0.0008,  0.0107],
        [-0.0359,  0.0132, -0.0041,  ..., -0.0473,  0.0050, -0.0005],
        [ 0.0122, -0.0012, -0.0178,  ..., -0.0031,  0.0207, -0.0100],
        ...,
        [ 0.0512, -0.0152, -0.0452,  ...,  0.0250, -0.0268,  0.0074],
        [ 0.0115,  0.0260, -0.0071,  ...,  0.0085,  0.0057,  0.0017],
        [ 0.0223, -0.0031, -0.0004,  ...,  0.0035, -0.0175,  0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias': tensor([-0.8135, -0.1840,  0.0576,  ..., -0.0189,  0.0277,  0.0699],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight': tensor([[ 2.6184e-02,  6.5842e-03, -6.6528e-03,  ...,  2.3901e-05,
          1.5297e-02, -1.9302e-02],
        [ 4.0741e-03,  3.0079e-03,  3.1090e-03,  ..., -9.0485e-03,
          1.0986e-02,  4.2953e-03],
        [ 4.1504e-03,  1.6336e-03, -1.1185e-02,  ...,  5.6496e-03,
          2.0889e-02, -1.3113e-04],
        ...,
        [-3.6945e-03,  1.4648e-02, -8.8348e-03,  ...,  8.1711e-03,
         -2.6073e-03,  1.3008e-02],
        [ 1.9562e-02, -1.5762e-02,  7.0877e-03,  ...,  6.5517e-04,
         -2.1744e-02, -2.0233e-02],
        [ 1.8417e-02, -1.2039e-02, -9.2239e-03,  ..., -4.6659e-04,
         -1.3191e-02, -7.4272e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias': tensor([ 0.0088,  0.0188,  0.0441,  ..., -0.0099, -0.0044,  0.0406],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight': tensor([[-0.0029,  0.0020, -0.0026,  ...,  0.0042, -0.0110, -0.0049],
        [-0.0278,  0.0302,  0.0003,  ..., -0.0331,  0.0236,  0.0125],
        [ 0.0239,  0.0206,  0.0083,  ..., -0.0029,  0.0212, -0.0040],
        ...,
        [ 0.0231,  0.0166, -0.0169,  ...,  0.0415, -0.0144,  0.0037],
        [ 0.0159,  0.0033, -0.0034,  ...,  0.0044, -0.0091,  0.0034],
        [ 0.0106, -0.0117, -0.0165,  ...,  0.0030, -0.0196,  0.0211]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias': tensor([-2.5234,  0.2341, -0.3838,  ..., -0.0643,  0.1272,  0.1238],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight': tensor([[-0.0296, -0.0036,  0.0027,  ...,  0.0065,  0.0073, -0.0128],
        [-0.0154, -0.0153,  0.0213,  ...,  0.0241,  0.0144,  0.0159],
        [-0.0073, -0.0148,  0.0064,  ...,  0.0165,  0.0177,  0.0191],
        ...,
        [-0.0013,  0.0025, -0.0111,  ..., -0.0081,  0.0079,  0.0101],
        [-0.0041, -0.0076, -0.0202,  ..., -0.0055,  0.0170,  0.0018],
        [ 0.0106, -0.0025,  0.0060,  ...,  0.0055, -0.0079,  0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias': tensor([ 0.0107, -0.0549,  0.0179,  ...,  0.0266,  0.0321, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight': tensor([1.3027, 1.2529, 1.3281,  ..., 1.4834, 1.1562, 1.3789],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias': tensor([ 0.1531,  0.0493, -0.0565,  ..., -0.0096, -0.0239, -0.0371],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight': tensor([[ 0.0043,  0.0120,  0.0113,  ..., -0.0241, -0.0064, -0.0090],
        [ 0.0006, -0.0211, -0.0018,  ..., -0.0029, -0.0108,  0.0110],
        [ 0.0030,  0.0094, -0.0028,  ..., -0.0025, -0.0057,  0.0185],
        ...,
        [-0.0027, -0.0314, -0.0122,  ..., -0.0098, -0.0206, -0.0127],
        [-0.0042,  0.0269, -0.0155,  ..., -0.0024, -0.0119, -0.0034],
        [-0.0102,  0.0069, -0.0109,  ..., -0.0012,  0.0015, -0.0005]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias': tensor([-0.2781, -0.2573, -0.3364,  ..., -0.3469, -0.2040, -0.0554],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight': tensor([[ 0.0010, -0.0122,  0.0169,  ...,  0.0076, -0.0051,  0.0080],
        [ 0.0136, -0.0151, -0.0033,  ..., -0.0080,  0.0146, -0.0023],
        [ 0.0173, -0.0216,  0.0123,  ...,  0.0066, -0.0024, -0.0003],
        ...,
        [-0.0117,  0.0076, -0.0053,  ...,  0.0010,  0.0026,  0.0003],
        [-0.0175,  0.0074, -0.0194,  ..., -0.0246, -0.0096, -0.0045],
        [ 0.0076,  0.0037,  0.0206,  ...,  0.0206, -0.0109,  0.0051]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias': tensor([ 0.0366, -0.0981, -0.0667,  ...,  0.0356,  0.0194, -0.0255],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight': tensor([1.7695, 1.6426, 1.7236,  ..., 0.6680, 1.5166, 1.7900],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias': tensor([-0.1890,  0.3459,  0.1487,  ...,  0.4136,  0.4312, -0.1221],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight': tensor([[ 0.0141,  0.0079,  0.0303,  ..., -0.0145,  0.0041,  0.0001],
        [-0.0112,  0.0048,  0.0240,  ..., -0.0055, -0.0139,  0.0003],
        [ 0.0167,  0.0107,  0.0269,  ..., -0.0065,  0.0130, -0.0072],
        ...,
        [-0.0014,  0.0062,  0.0020,  ..., -0.0017,  0.0170, -0.0246],
        [-0.0123, -0.0318, -0.0099,  ..., -0.0016, -0.0070, -0.0297],
        [ 0.0025,  0.0103,  0.0089,  ...,  0.0022,  0.0038,  0.0318]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias': tensor([-0.0931,  0.0089, -0.0538,  ...,  0.1041,  0.1436,  0.0084],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight': tensor([[-0.0085,  0.0049, -0.0003,  ...,  0.0036, -0.0302,  0.0040],
        [ 0.0075, -0.0265, -0.0065,  ..., -0.0031,  0.0134, -0.0018],
        [-0.0087, -0.0006, -0.0056,  ...,  0.0055,  0.0154,  0.0372],
        ...,
        [-0.0022, -0.0078,  0.0144,  ...,  0.0019, -0.0084,  0.0115],
        [ 0.0047, -0.0127, -0.0223,  ..., -0.0021, -0.0109,  0.0101],
        [-0.0105, -0.0005, -0.0008,  ..., -0.0030, -0.0079, -0.0039]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias': tensor([-0.0321,  0.0378,  0.0632,  ...,  0.0502, -0.0048, -0.0005],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight': tensor([[-0.0095, -0.0095,  0.0312,  ...,  0.0022, -0.0092,  0.0262],
        [-0.0264, -0.0028, -0.0018,  ..., -0.0075, -0.0155, -0.0109],
        [-0.0025, -0.0001,  0.0389,  ..., -0.0119,  0.0128, -0.0002],
        ...,
        [ 0.0271, -0.0069,  0.0122,  ...,  0.0018,  0.0167, -0.0080],
        [ 0.0080, -0.0216,  0.0023,  ...,  0.0015, -0.0140,  0.0002],
        [-0.0039,  0.0055,  0.0021,  ...,  0.0071, -0.0103,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias': tensor([-0.2311,  0.2390, -0.0950,  ...,  0.0876,  0.1581,  0.0798],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight': tensor([[-0.0281, -0.0058,  0.0026,  ..., -0.0079,  0.0053, -0.0023],
        [ 0.0130, -0.0057, -0.0072,  ..., -0.0006, -0.0015, -0.0051],
        [-0.0112,  0.0132,  0.0089,  ..., -0.0184,  0.0022, -0.0036],
        ...,
        [ 0.0086,  0.0047, -0.0106,  ..., -0.0117, -0.0147, -0.0069],
        [ 0.0147, -0.0031, -0.0165,  ...,  0.0125, -0.0091,  0.0107],
        [ 0.0214,  0.0008, -0.0262,  ..., -0.0205, -0.0144,  0.0057]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias': tensor([-0.0645, -0.0639,  0.0044,  ..., -0.0346, -0.0156, -0.0320],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight': tensor([1.3975, 1.3584, 1.4883,  ..., 1.8799, 1.3203, 1.4980],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias': tensor([ 0.0757, -0.1133, -0.0580,  ..., -0.0255, -0.0899, -0.1061],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight': tensor([[-7.1793e-03,  4.6234e-03,  1.7502e-02,  ..., -1.0124e-02,
          1.3245e-02, -6.4430e-03],
        [-1.6571e-02,  1.1040e-02, -5.1537e-03,  ..., -6.7616e-04,
         -2.2491e-02, -9.1019e-03],
        [-7.6675e-04,  2.2156e-02,  1.0216e-02,  ..., -4.4708e-03,
         -1.6510e-02, -2.4704e-02],
        ...,
        [-2.9205e-02, -7.1602e-03,  8.7559e-05,  ..., -9.7656e-03,
          1.6312e-02,  2.7145e-02],
        [-1.2413e-02,  6.9084e-03,  2.4399e-02,  ..., -7.0381e-03,
         -7.9803e-03,  9.6130e-03],
        [ 6.4039e-04, -4.3259e-03,  4.3121e-02,  ..., -3.9101e-03,
         -1.3245e-02,  1.4565e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias': tensor([-0.3418, -0.2771, -0.3467,  ..., -0.3992, -0.2385, -0.2927],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight': tensor([[-9.4452e-03,  1.2772e-02,  1.8539e-02,  ..., -2.6276e-02,
          4.2343e-04, -1.3672e-02],
        [ 3.2593e-02,  8.7070e-04, -2.8477e-03,  ..., -8.7814e-03,
          1.1383e-02, -3.0182e-02],
        [-4.3488e-03, -2.7359e-02,  1.8482e-03,  ..., -6.5002e-03,
          2.6016e-02,  3.3539e-02],
        ...,
        [-4.1504e-03,  1.6251e-02,  7.8354e-03,  ...,  1.4816e-02,
         -1.9627e-03, -6.3002e-05],
        [ 6.4125e-03, -1.6647e-02,  4.3945e-03,  ...,  1.2833e-02,
         -1.5268e-03, -1.7975e-02],
        [-1.8167e-03, -1.1734e-02, -1.4511e-02,  ...,  3.0396e-02,
          1.1108e-02, -9.7580e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias': tensor([-0.0361, -0.0392,  0.0150,  ..., -0.0163,  0.0041, -0.0078],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight': tensor([2.1113, 2.0137, 2.0352,  ..., 0.7090, 1.8164, 2.2012],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias': tensor([-0.1631, -0.1508,  0.1484,  ...,  0.4434,  0.6812, -0.3279],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight': tensor([[-9.9716e-03, -2.5208e-02,  8.4457e-03,  ...,  1.3168e-02,
         -5.3942e-05, -2.8748e-02],
        [-3.1233e-05,  1.3992e-02, -2.2476e-02,  ...,  6.3232e-02,
         -1.4221e-02, -1.4404e-02],
        [-5.1785e-04, -3.1403e-02,  6.5517e-04,  ..., -1.0399e-02,
          1.1505e-02, -2.8076e-03],
        ...,
        [-6.2132e-04, -1.0201e-02,  1.3947e-02,  ..., -5.4810e-02,
         -8.1787e-03, -2.0981e-02],
        [ 9.8572e-03, -1.7899e-02,  1.1734e-02,  ..., -4.1885e-03,
          1.4870e-02,  1.1244e-03],
        [ 1.5884e-02,  2.2827e-02,  4.2000e-03,  ..., -4.3091e-02,
         -2.2690e-02, -1.3191e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias': tensor([ 0.2656, -0.2185,  0.0432,  ..., -0.1787, -0.2061,  0.0742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight': tensor([[ 0.0261,  0.0077, -0.0120,  ..., -0.0027, -0.0164, -0.0107],
        [-0.0080,  0.0102,  0.0077,  ...,  0.0039,  0.0010, -0.0050],
        [ 0.0017, -0.0101, -0.0256,  ...,  0.0058, -0.0145, -0.0055],
        ...,
        [-0.0161,  0.0100, -0.0047,  ..., -0.0049, -0.0208,  0.0245],
        [ 0.0115, -0.0098,  0.0141,  ...,  0.0035, -0.0129, -0.0005],
        [-0.0111, -0.0270,  0.0220,  ..., -0.0022, -0.0052, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias': tensor([-0.0182,  0.0114,  0.1055,  ..., -0.0048, -0.0138,  0.0093],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight': tensor([[-0.0116, -0.0250, -0.0204,  ...,  0.0060, -0.0022, -0.0020],
        [ 0.0243,  0.0011, -0.0106,  ...,  0.0480, -0.0213,  0.0138],
        [ 0.0116, -0.0210, -0.0045,  ..., -0.0067, -0.0268, -0.0189],
        ...,
        [ 0.0013,  0.0050,  0.0468,  ..., -0.0500,  0.0203,  0.0043],
        [ 0.0273, -0.0117,  0.0099,  ..., -0.0033, -0.0067,  0.0015],
        [-0.0062,  0.0012,  0.0167,  ..., -0.0361, -0.0010,  0.0275]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias': tensor([ 0.2439, -0.1146,  0.0887,  ...,  0.2213,  0.1515, -0.0186],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight': tensor([[-3.0136e-02,  1.2367e-02, -9.5749e-03,  ...,  1.8692e-02,
          9.2697e-03, -4.0054e-03],
        [-3.6682e-02, -9.7504e-03,  7.6950e-05,  ..., -1.0941e-02,
          8.2474e-03, -8.6546e-04],
        [ 1.9424e-02, -2.1729e-02,  5.8022e-03,  ...,  6.4888e-03,
         -4.6577e-03, -6.9504e-03],
        ...,
        [-7.0953e-03, -1.1024e-02,  1.4248e-03,  ...,  3.1490e-03,
         -7.8735e-03, -1.8097e-02],
        [ 1.8778e-03, -1.1490e-02, -8.2855e-03,  ..., -1.9104e-02,
          7.3166e-03, -8.8959e-03],
        [-8.1558e-03,  1.7426e-02,  1.1551e-02,  ..., -4.8790e-03,
          5.9700e-03,  9.9030e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias': tensor([-0.0732,  0.0212,  0.0239,  ...,  0.0091, -0.0001, -0.0141],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight': tensor([1.3848, 1.3320, 1.4814,  ..., 1.5195, 1.3164, 1.4180],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias': tensor([ 0.0473, -0.0936, -0.0594,  ...,  0.0325,  0.0149, -0.0659],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight': tensor([[ 1.5793e-02, -8.3160e-03,  2.2156e-02,  ...,  1.8814e-02,
         -5.4436e-03, -1.1604e-02],
        [ 1.5007e-02, -9.5978e-03, -2.5284e-02,  ..., -1.6510e-02,
         -3.3539e-02, -2.3102e-02],
        [-2.1622e-02,  2.0309e-02,  2.1801e-03,  ...,  7.5798e-03,
          1.4145e-02, -7.3433e-03],
        ...,
        [-4.5624e-03, -2.5757e-02,  6.9199e-03,  ...,  3.5572e-03,
          1.4694e-02, -2.2339e-02],
        [-9.1791e-06,  7.1487e-03, -1.3298e-02,  ...,  5.6610e-03,
          4.4975e-03,  1.1978e-02],
        [-5.8289e-03,  5.1689e-03, -1.4862e-02,  ...,  1.8585e-02,
          9.6655e-04,  1.1856e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias': tensor([-0.2683, -0.3921, -0.3279,  ..., -0.3718, -0.2028, -0.3127],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight': tensor([[-0.0059, -0.0140,  0.0130,  ...,  0.0043,  0.0292, -0.0014],
        [ 0.0265, -0.0073, -0.0116,  ..., -0.0211,  0.0206,  0.0263],
        [ 0.0022, -0.0233,  0.0002,  ...,  0.0067, -0.0096, -0.0120],
        ...,
        [ 0.0080, -0.0016,  0.0073,  ..., -0.0021, -0.0057, -0.0010],
        [ 0.0048, -0.0163, -0.0040,  ...,  0.0130, -0.0188,  0.0429],
        [-0.0011, -0.0383, -0.0151,  ..., -0.0132,  0.0248,  0.0216]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias': tensor([ 0.0359,  0.0342,  0.0545,  ...,  0.0745, -0.0070,  0.0030],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight': tensor([2.5176, 2.3496, 2.4785,  ..., 0.5151, 2.0352, 2.4492],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias': tensor([-0.2339, -0.0297,  0.1533,  ...,  0.4067,  0.7363, -0.2054],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight': tensor([[ 0.0047,  0.0246, -0.0315,  ...,  0.0246, -0.0050,  0.0121],
        [ 0.0096,  0.0193,  0.0106,  ..., -0.0207, -0.0075,  0.0043],
        [ 0.0199,  0.0022, -0.0148,  ..., -0.0771, -0.0211,  0.0064],
        ...,
        [ 0.0369,  0.0040, -0.0087,  ..., -0.0215,  0.0106,  0.0167],
        [-0.0061, -0.0050, -0.0032,  ..., -0.0078,  0.0147,  0.0186],
        [ 0.0009,  0.0079, -0.0195,  ..., -0.0096, -0.0309,  0.0012]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias': tensor([ 0.0911, -0.1252, -0.4846,  ...,  0.0673, -0.0733,  0.0197],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight': tensor([[ 0.0141,  0.0237,  0.0094,  ..., -0.0007, -0.0127, -0.0134],
        [ 0.0092, -0.0071,  0.0201,  ...,  0.0027, -0.0176, -0.0013],
        [ 0.0039, -0.0016, -0.0055,  ...,  0.0065, -0.0001, -0.0049],
        ...,
        [ 0.0073, -0.0355, -0.0101,  ...,  0.0047, -0.0010, -0.0099],
        [-0.0019,  0.0097, -0.0335,  ..., -0.0019,  0.0006, -0.0019],
        [ 0.0030, -0.0076,  0.0026,  ..., -0.0004,  0.0043, -0.0152]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias': tensor([ 0.0290,  0.0252,  0.0343,  ...,  0.0027, -0.0045, -0.0545],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight': tensor([[ 0.0060, -0.0019, -0.0088,  ...,  0.0198, -0.0025, -0.0177],
        [ 0.0059,  0.0067,  0.0215,  ..., -0.0244, -0.0294,  0.0024],
        [ 0.0271,  0.0004, -0.0182,  ..., -0.0876,  0.0076, -0.0006],
        ...,
        [-0.0081,  0.0160, -0.0380,  ..., -0.0249, -0.0083,  0.0045],
        [ 0.0112, -0.0182, -0.0261,  ..., -0.0056, -0.0009, -0.0319],
        [ 0.0435,  0.0031,  0.0118,  ..., -0.0163,  0.0102, -0.0193]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias': tensor([ 0.0622,  0.0999, -0.5308,  ..., -0.1455,  0.0368, -0.1086],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight': tensor([[ 4.6425e-03, -2.0313e-03,  2.7237e-02,  ...,  1.0216e-02,
         -2.0187e-02,  1.1955e-02],
        [-5.8823e-03,  2.6627e-02,  7.8506e-03,  ...,  3.9864e-03,
         -1.8646e-02,  2.6762e-05],
        [-5.6601e-04,  5.0240e-03,  2.1591e-02,  ...,  1.1375e-02,
          6.1035e-03,  7.7581e-04],
        ...,
        [ 9.0256e-03, -4.1656e-03, -1.2932e-02,  ...,  9.0778e-05,
          1.9577e-02, -6.6452e-03],
        [ 1.5488e-02,  5.1928e-04,  1.3100e-02,  ..., -2.1057e-02,
         -4.6921e-03,  1.0338e-02],
        [ 3.2501e-03, -2.0432e-02, -2.8076e-02,  ..., -8.2169e-03,
         -2.1858e-03,  3.8376e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias': tensor([ 0.0169,  0.0075, -0.0464,  ...,  0.0064, -0.0125, -0.0271],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight': tensor([1.4844, 1.5352, 1.5859,  ..., 1.5234, 1.4395, 1.5938],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias': tensor([ 0.1630, -0.0892, -0.0373,  ..., -0.0082, -0.0609, -0.1628],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight': tensor([[-0.0057, -0.0090,  0.0211,  ...,  0.0072, -0.0180, -0.0063],
        [ 0.0278,  0.0188,  0.0136,  ..., -0.0074,  0.0133, -0.0087],
        [-0.0168,  0.0028, -0.0226,  ..., -0.0184, -0.0072, -0.0020],
        ...,
        [ 0.0011, -0.0155, -0.0045,  ..., -0.0092, -0.0268,  0.0125],
        [ 0.0054, -0.0030,  0.0160,  ...,  0.0257, -0.0181, -0.0068],
        [ 0.0045,  0.0018,  0.0164,  ..., -0.0108, -0.0191, -0.0004]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias': tensor([-0.2793, -0.3452, -0.2959,  ..., -0.1838, -0.1981, -0.2494],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight': tensor([[-0.0017, -0.0146,  0.0010,  ...,  0.0037, -0.0001,  0.0201],
        [ 0.0174, -0.0161, -0.0016,  ..., -0.0007, -0.0096, -0.0005],
        [ 0.0072,  0.0077, -0.0210,  ...,  0.0165, -0.0019, -0.0208],
        ...,
        [ 0.0195, -0.0092,  0.0151,  ..., -0.0062, -0.0071, -0.0216],
        [ 0.0159,  0.0006,  0.0077,  ..., -0.0073,  0.0030,  0.0091],
        [ 0.0062,  0.0206,  0.0089,  ...,  0.0090, -0.0033, -0.0063]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias': tensor([0.0065, 0.0102, 0.0046,  ..., 0.0065, 0.0796, 0.0695],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight': tensor([2.6719, 2.5625, 2.7695,  ..., 0.6802, 2.2539, 2.7422],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias': tensor([-0.0354,  0.2776,  0.4175,  ...,  0.5674,  0.5327, -0.4670],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight': tensor([[-0.0087,  0.0027,  0.0113,  ..., -0.0616,  0.0051, -0.0137],
        [-0.0173,  0.0047,  0.0124,  ...,  0.0239, -0.0160,  0.0129],
        [ 0.0097, -0.0005, -0.0050,  ...,  0.0011,  0.0099, -0.0130],
        ...,
        [-0.0052,  0.0120,  0.0098,  ..., -0.0244,  0.0038,  0.0010],
        [ 0.0119, -0.0235, -0.0134,  ..., -0.0140, -0.0140,  0.0065],
        [ 0.0291,  0.0226, -0.0254,  ..., -0.0035, -0.0137,  0.0350]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias': tensor([ 0.2783, -0.2036, -0.0648,  ...,  0.1705,  0.1809,  0.1080],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight': tensor([[-0.0184,  0.0137,  0.0067,  ..., -0.0029,  0.0099,  0.0297],
        [-0.0110,  0.0184,  0.0020,  ...,  0.0024, -0.0151,  0.0009],
        [ 0.0191, -0.0126,  0.0212,  ...,  0.0024, -0.0348,  0.0026],
        ...,
        [ 0.0005,  0.0007, -0.0011,  ...,  0.0046, -0.0222, -0.0393],
        [ 0.0117,  0.0042,  0.0002,  ..., -0.0006,  0.0005, -0.0083],
        [-0.0062,  0.0128,  0.0124,  ..., -0.0037, -0.0134,  0.0008]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias': tensor([-0.0114,  0.0300,  0.0252,  ..., -0.0060,  0.0197,  0.0400],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight': tensor([[ 1.4931e-02, -1.2466e-02,  2.4918e-02,  ..., -5.9814e-02,
         -4.3068e-03,  1.2131e-02],
        [-1.6464e-02, -9.9030e-03, -1.1108e-02,  ...,  2.3956e-02,
         -3.6163e-02,  1.1703e-02],
        [ 1.0757e-02,  2.5730e-03, -7.3338e-04,  ...,  2.4662e-03,
          6.1493e-03,  6.6528e-03],
        ...,
        [ 5.1003e-03, -7.8678e-06,  5.1041e-03,  ..., -4.5410e-02,
         -3.1738e-02,  1.8631e-02],
        [ 1.7502e-02, -4.1084e-03,  3.9978e-03,  ..., -1.8753e-02,
         -2.2335e-03,  2.1057e-03],
        [ 1.7303e-02,  6.7902e-03,  1.1360e-02,  ...,  8.0719e-03,
         -5.0278e-03,  2.1713e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias': tensor([-0.2339,  0.0393, -0.0323,  ..., -0.1953,  0.0200,  0.0049],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight': tensor([[ 0.0254,  0.0050,  0.0049,  ...,  0.0120, -0.0121,  0.0091],
        [ 0.0248, -0.0193, -0.0093,  ..., -0.0044, -0.0032,  0.0151],
        [ 0.0053,  0.0182, -0.0142,  ..., -0.0130, -0.0033, -0.0087],
        ...,
        [ 0.0006, -0.0051, -0.0173,  ...,  0.0031, -0.0128,  0.0099],
        [ 0.0081, -0.0134,  0.0246,  ...,  0.0185, -0.0136,  0.0109],
        [-0.0261, -0.0152, -0.0080,  ...,  0.0230, -0.0056,  0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias': tensor([-0.0083,  0.0091, -0.0955,  ..., -0.0067,  0.0003, -0.0047],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight': tensor([1.5762, 1.4580, 1.5850,  ..., 1.7383, 1.4209, 1.5967],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias': tensor([ 0.1272, -0.2208, -0.0098,  ..., -0.0831, -0.0858, -0.1576],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight': tensor([[-0.0051,  0.0014, -0.0012,  ...,  0.0091, -0.0065, -0.0086],
        [-0.0191,  0.0118,  0.0002,  ..., -0.0095, -0.0148,  0.0134],
        [-0.0012, -0.0324,  0.0047,  ..., -0.0084,  0.0050, -0.0089],
        ...,
        [ 0.0005, -0.0097, -0.0229,  ..., -0.0036, -0.0164, -0.0044],
        [ 0.0058, -0.0019, -0.0019,  ...,  0.0053,  0.0177,  0.0073],
        [ 0.0128,  0.0044, -0.0019,  ..., -0.0147,  0.0180, -0.0173]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias': tensor([-0.1597, -0.3298, -0.3066,  ..., -0.3003, -0.3157, -0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight': tensor([[-0.0060, -0.0143,  0.0279,  ..., -0.0150,  0.0291,  0.0124],
        [ 0.0095, -0.0208, -0.0114,  ...,  0.0116, -0.0289,  0.0051],
        [-0.0165,  0.0403, -0.0052,  ...,  0.0008, -0.0144, -0.0153],
        ...,
        [-0.0120,  0.0119, -0.0007,  ...,  0.0051,  0.0161, -0.0073],
        [ 0.0291,  0.0090, -0.0140,  ...,  0.0286,  0.0029, -0.0079],
        [ 0.0233, -0.0179, -0.0138,  ..., -0.0036, -0.0180, -0.0041]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias': tensor([ 0.0113,  0.0318, -0.0128,  ..., -0.0561, -0.0155,  0.0321],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight': tensor([2.7773, 2.7402, 2.7402,  ..., 0.8696, 2.4961, 2.8711],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias': tensor([-0.1473, -0.0198,  0.2091,  ...,  0.4590,  0.5410, -0.2742],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight': tensor([[ 0.0005, -0.0174, -0.0133,  ..., -0.0195,  0.0176,  0.0196],
        [ 0.0332, -0.0111, -0.0092,  ..., -0.0143,  0.0277, -0.0138],
        [-0.0094,  0.0108, -0.0135,  ..., -0.0078, -0.0209, -0.0013],
        ...,
        [ 0.0136,  0.0224,  0.0235,  ..., -0.0533, -0.0095,  0.0097],
        [-0.0183, -0.0031, -0.0219,  ..., -0.0209, -0.0113,  0.0082],
        [ 0.0187,  0.0257,  0.0352,  ..., -0.0150,  0.0010,  0.0060]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias': tensor([-0.2089,  0.1558,  0.3555,  ...,  0.0323,  0.1013,  0.1327],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight': tensor([[-0.0096,  0.0058, -0.0198,  ...,  0.0084,  0.0249,  0.0066],
        [ 0.0346, -0.0048, -0.0196,  ..., -0.0008, -0.0481, -0.0151],
        [-0.0034,  0.0091,  0.0039,  ..., -0.0047,  0.0017, -0.0073],
        ...,
        [-0.0277, -0.0315,  0.0064,  ..., -0.0131, -0.0027,  0.0125],
        [ 0.0013,  0.0095,  0.0286,  ..., -0.0024,  0.0112,  0.0018],
        [-0.0154,  0.0043, -0.0169,  ...,  0.0051,  0.0013, -0.0213]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias': tensor([0.0214, 0.0242, 0.0006,  ..., 0.0194, 0.0418, 0.0340],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight': tensor([[-0.0110, -0.0187, -0.0399,  ..., -0.0132,  0.0016,  0.0080],
        [ 0.0197,  0.0169,  0.0061,  ..., -0.0240,  0.0292,  0.0127],
        [-0.0047, -0.0227, -0.0048,  ..., -0.0150, -0.0014,  0.0108],
        ...,
        [-0.0113,  0.0006, -0.0214,  ..., -0.0389, -0.0254,  0.0096],
        [ 0.0066,  0.0193,  0.0392,  ...,  0.0004,  0.0306, -0.0154],
        [-0.0041,  0.0141, -0.0124,  ..., -0.0156, -0.0206,  0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias': tensor([-0.0377, -0.0410, -0.0185,  ..., -0.2778,  0.1395,  0.1525],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight': tensor([[-1.2112e-03,  2.4259e-05, -4.5753e-04,  ...,  4.1847e-03,
          3.2597e-03, -3.2745e-02],
        [-1.3557e-02, -5.1613e-03,  2.0218e-02,  ..., -7.0801e-03,
         -2.9678e-02, -3.8872e-03],
        [-2.0355e-02, -4.8676e-03,  1.2039e-02,  ...,  1.1337e-02,
         -5.5161e-03, -1.0376e-02],
        ...,
        [ 1.2032e-02,  1.7944e-02, -4.4212e-03,  ...,  3.3722e-02,
         -1.9394e-02, -2.0691e-02],
        [-1.6998e-02,  2.0340e-02, -9.7885e-03,  ..., -4.0588e-03,
          4.5967e-03, -7.2937e-03],
        [-1.6357e-02, -1.8204e-02,  1.9684e-02,  ...,  1.2749e-02,
         -2.2552e-02, -1.4832e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias': tensor([-0.0427,  0.0264, -0.0947,  ..., -0.0744, -0.0230, -0.0399],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight': tensor([1.6475, 1.5273, 1.6768,  ..., 1.8574, 1.4951, 1.6426],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias': tensor([-0.0313, -0.3167, -0.0297,  ..., -0.0391, -0.0746, -0.2402],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight': tensor([[-0.0260, -0.0154,  0.0028,  ..., -0.0228, -0.0295, -0.0447],
        [ 0.0029, -0.0058,  0.0197,  ...,  0.0138,  0.0183,  0.0026],
        [ 0.0218, -0.0178,  0.0015,  ..., -0.0087,  0.0014,  0.0125],
        ...,
        [ 0.0404,  0.0179, -0.0153,  ...,  0.0049,  0.0196, -0.0120],
        [ 0.0015, -0.0189,  0.0088,  ...,  0.0184, -0.0162, -0.0341],
        [ 0.0035, -0.0139, -0.0161,  ...,  0.0040, -0.0222, -0.0067]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias': tensor([-0.3091, -0.1617, -0.2668,  ..., -0.2510, -0.2261, -0.2350],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight': tensor([[-0.0030, -0.0123, -0.0188,  ...,  0.0186, -0.0332, -0.0181],
        [ 0.0014, -0.0037, -0.0307,  ..., -0.0058,  0.0160,  0.0274],
        [ 0.0273, -0.0119, -0.0110,  ..., -0.0013, -0.0041, -0.0059],
        ...,
        [ 0.0018, -0.0187, -0.0384,  ...,  0.0141,  0.0053,  0.0090],
        [ 0.0151, -0.0128, -0.0045,  ...,  0.0167, -0.0064,  0.0077],
        [ 0.0001,  0.0021,  0.0336,  ..., -0.0046, -0.0128,  0.0093]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias': tensor([ 0.1198, -0.0191,  0.1595,  ..., -0.0292, -0.0284, -0.0580],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight': tensor([3.1777, 3.2344, 3.2090,  ..., 1.1455, 2.6172, 3.2363],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias': tensor([-0.3699,  0.0534, -0.3181,  ...,  0.1720,  0.3350, -0.2013],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight': tensor([[ 0.0132,  0.0254, -0.0020,  ..., -0.0305,  0.0047,  0.0051],
        [ 0.0022, -0.0257,  0.0199,  ..., -0.0184,  0.0286,  0.0047],
        [-0.0092, -0.0116,  0.0196,  ..., -0.0357,  0.0290,  0.0171],
        ...,
        [ 0.0071, -0.0053,  0.0001,  ..., -0.0139, -0.0043, -0.0191],
        [-0.0128,  0.0084, -0.0034,  ..., -0.0035, -0.0175, -0.0111],
        [ 0.0023, -0.0036, -0.0063,  ...,  0.0125, -0.0132,  0.0166]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias': tensor([ 2.2266,  1.3135, -0.9771,  ...,  0.3726,  2.3047,  0.1869],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight': tensor([[-0.0117,  0.0124, -0.0160,  ...,  0.0026,  0.0036,  0.0293],
        [ 0.0022, -0.0097, -0.0008,  ..., -0.0094,  0.0017, -0.0152],
        [-0.0117, -0.0052, -0.0132,  ...,  0.0201,  0.0020, -0.0049],
        ...,
        [ 0.0122, -0.0035, -0.0111,  ..., -0.0017,  0.0214,  0.0207],
        [-0.0134,  0.0110, -0.0031,  ...,  0.0010,  0.0070,  0.0225],
        [ 0.0003,  0.0153,  0.0004,  ...,  0.0096,  0.0122,  0.0161]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias': tensor([ 0.0095, -0.0149, -0.0342,  ...,  0.0316,  0.0107, -0.0553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight': tensor([[ 2.4475e-02,  1.0361e-02, -3.1738e-03,  ...,  6.3629e-03,
         -4.1161e-03,  4.0770e-05],
        [ 6.4735e-03, -1.1032e-02, -4.1046e-03,  ...,  2.4471e-03,
         -7.7009e-04,  3.3226e-03],
        [-2.2324e-02, -5.0497e-04, -2.1210e-02,  ..., -6.5186e-02,
         -3.9253e-03, -4.9324e-03],
        ...,
        [ 7.4692e-03, -2.1229e-03, -2.2095e-02,  ..., -3.7079e-02,
         -3.3173e-02,  2.9621e-03],
        [-2.3987e-02, -1.8463e-03, -3.8791e-04,  ..., -1.6312e-02,
         -2.0157e-02,  1.9180e-02],
        [ 5.5695e-03, -1.0750e-02,  1.4153e-03,  ...,  1.7136e-02,
         -1.8829e-02, -3.1219e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias': tensor([ 0.0942, -0.0380, -0.0066,  ..., -0.2206,  0.0908,  0.0343],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight': tensor([[ 0.0108, -0.0169,  0.0143,  ..., -0.0040, -0.0186, -0.0120],
        [-0.0099,  0.0158, -0.0007,  ..., -0.0126,  0.0125, -0.0013],
        [ 0.0059, -0.0186,  0.0080,  ...,  0.0038,  0.0261, -0.0122],
        ...,
        [ 0.0193, -0.0006, -0.0168,  ..., -0.0111, -0.0033,  0.0045],
        [ 0.0071,  0.0175, -0.0099,  ...,  0.0238,  0.0111,  0.0132],
        [ 0.0269,  0.0227,  0.0074,  ..., -0.0048, -0.0153, -0.0069]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias': tensor([ 0.1117, -0.0344, -0.0097,  ..., -0.0479, -0.0558, -0.0235],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight': tensor([1.5781, 1.5361, 1.5830,  ..., 0.8071, 1.4404, 1.7129],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias': tensor([ 0.0493, -0.2202, -0.1034,  ...,  0.0678, -0.1000, -0.2034],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight': tensor([[-0.0206, -0.0153,  0.0054,  ...,  0.0216,  0.0042, -0.0064],
        [-0.0240,  0.0083,  0.0154,  ..., -0.0026,  0.0077, -0.0042],
        [ 0.0143,  0.0016,  0.0010,  ...,  0.0362,  0.0050,  0.0193],
        ...,
        [ 0.0191,  0.0038,  0.0125,  ..., -0.0049, -0.0139, -0.0164],
        [ 0.0050,  0.0037,  0.0237,  ..., -0.0271,  0.0079, -0.0093],
        [ 0.0163,  0.0038, -0.0141,  ..., -0.0026, -0.0191,  0.0084]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias': tensor([-0.2673, -0.2559, -0.2236,  ..., -0.2888, -0.2781, -0.0958],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight': tensor([[-0.0093, -0.0160, -0.0221,  ...,  0.0137, -0.0174, -0.0188],
        [-0.0096,  0.0156, -0.0179,  ..., -0.0231,  0.0060, -0.0123],
        [ 0.0032, -0.0022,  0.0147,  ..., -0.0053,  0.0070,  0.0076],
        ...,
        [-0.0122, -0.0089,  0.0011,  ...,  0.0205,  0.0041, -0.0117],
        [ 0.0056, -0.0073, -0.0155,  ..., -0.0081, -0.0361,  0.0044],
        [ 0.0310,  0.0010,  0.0081,  ..., -0.0060, -0.0118, -0.0159]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias': tensor([-0.0192, -0.0717,  0.1105,  ..., -0.1528,  0.0851, -0.0401],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight': tensor([3.1602, 3.0371, 2.9180,  ..., 1.5098, 2.5527, 3.1855],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias': tensor([ 0.2227,  0.6216, -0.4958,  ...,  0.2568,  0.0677, -0.4553],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight': tensor([[ 0.0037,  0.0141,  0.0131,  ...,  0.0058,  0.0128,  0.0105],
        [ 0.0020, -0.0168, -0.0078,  ...,  0.0242, -0.0173, -0.0008],
        [ 0.0030,  0.0062, -0.0284,  ..., -0.0097,  0.0236,  0.0083],
        ...,
        [-0.0080, -0.0243, -0.0079,  ..., -0.0201, -0.0240, -0.0208],
        [ 0.0029,  0.0056,  0.0167,  ...,  0.0065, -0.0012, -0.0019],
        [-0.0047, -0.0198, -0.0200,  ...,  0.0153,  0.0093, -0.0209]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias': tensor([ 0.9746, -1.5684,  4.0703,  ..., -4.7695,  2.3730,  0.0641],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight': tensor([[-0.0094,  0.0040, -0.0081,  ...,  0.0087,  0.0034, -0.0086],
        [-0.0218, -0.0027,  0.0096,  ...,  0.0072, -0.0114, -0.0138],
        [-0.0069,  0.0196,  0.0128,  ...,  0.0089, -0.0430,  0.0282],
        ...,
        [ 0.0080, -0.0076,  0.0247,  ..., -0.0006,  0.0264, -0.0060],
        [-0.0081,  0.0084,  0.0222,  ...,  0.0080, -0.0070,  0.0124],
        [-0.0113,  0.0073,  0.0137,  ..., -0.0100, -0.0085,  0.0073]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias': tensor([-0.0650, -0.0600,  0.0630,  ..., -0.0726,  0.0070, -0.1204],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight': tensor([[ 0.0016,  0.0027, -0.0018,  ...,  0.0349, -0.0049, -0.0009],
        [ 0.0076,  0.0003, -0.0250,  ...,  0.0064,  0.0064,  0.0147],
        [-0.0011, -0.0325, -0.0602,  ...,  0.0003, -0.0238,  0.0107],
        ...,
        [ 0.0233,  0.0226,  0.0270,  ...,  0.0236, -0.0239, -0.0167],
        [ 0.0041, -0.0097, -0.0143,  ..., -0.0173, -0.0098,  0.0124],
        [ 0.0090, -0.0034,  0.0003,  ...,  0.0278,  0.0114,  0.0061]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias': tensor([-0.4348, -0.0033, -0.1771,  ..., -0.0897,  0.1703,  0.3945],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight': tensor([[ 0.0021,  0.0206, -0.0078,  ..., -0.0072, -0.0010,  0.0115],
        [ 0.0005,  0.0042, -0.0142,  ...,  0.0190, -0.0119, -0.0008],
        [ 0.0061, -0.0182,  0.0112,  ..., -0.0376, -0.0023, -0.0042],
        ...,
        [-0.0143,  0.0111, -0.0015,  ..., -0.0087,  0.0175, -0.0019],
        [-0.0039,  0.0022,  0.0231,  ..., -0.0050,  0.0082, -0.0150],
        [ 0.0005, -0.0005, -0.0158,  ..., -0.0120, -0.0067, -0.0141]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias': tensor([-0.0269, -0.0574,  0.0638,  ..., -0.1498,  0.0551, -0.1482],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight': tensor([1.5703, 1.8379, 1.9336,  ..., 0.8516, 1.4707, 1.7686],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias': tensor([0.3889, 0.2372, 0.1531,  ..., 0.6260, 0.2163, 0.1549],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight': tensor([[-1.1892e-03,  3.9005e-03, -5.7487e-03,  ...,  4.7989e-03,
         -4.2915e-03, -2.5539e-03],
        [ 1.5236e-02, -2.3232e-03, -3.3325e-02,  ...,  2.3758e-02,
         -1.0595e-03, -3.8986e-03],
        [ 2.0737e-02,  7.2479e-03, -3.0842e-03,  ..., -5.4207e-03,
          2.6047e-02, -1.4210e-03],
        ...,
        [ 7.4120e-03, -2.9163e-03,  3.3661e-02,  ..., -4.4785e-03,
          9.1400e-03, -1.5297e-02],
        [-4.3964e-04,  8.5297e-03, -1.5350e-02,  ..., -1.3519e-02,
         -6.6490e-03,  5.9700e-04],
        [-7.5579e-05,  1.0449e-04,  8.8196e-03,  ..., -1.0658e-02,
         -6.6032e-03, -5.4703e-03]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias': tensor([-0.3184, -0.2345, -0.2834,  ..., -0.2498, -0.1849, -0.2729],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight': tensor([[ 0.0369,  0.0093, -0.0179,  ..., -0.0141, -0.0035,  0.0064],
        [ 0.0050,  0.0101,  0.0117,  ...,  0.0070, -0.0066, -0.0147],
        [-0.0015,  0.0263,  0.0119,  ..., -0.0270,  0.0052, -0.0028],
        ...,
        [ 0.0133,  0.0236, -0.0152,  ...,  0.0251, -0.0268, -0.0321],
        [ 0.0021, -0.0061,  0.0079,  ..., -0.0029,  0.0145, -0.0033],
        [-0.0097,  0.0175, -0.0111,  ..., -0.0278, -0.0016, -0.0075]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias': tensor([-0.1587, -0.0068,  0.1970,  ...,  0.0549, -0.0199,  0.0069],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight': tensor([2.5664, 2.3809, 2.5742,  ..., 1.8262, 2.4121, 2.7520],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias': tensor([ 0.1838,  0.3330, -0.2296,  ..., -0.1086,  0.5938, -0.2812],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight': tensor([[ 0.0305, -0.0035, -0.0098,  ...,  0.0054, -0.0111,  0.0049],
        [-0.0194,  0.0099,  0.0032,  ...,  0.0125,  0.0277, -0.0057],
        [ 0.0115,  0.0072, -0.0170,  ...,  0.0162,  0.0032,  0.0142],
        ...,
        [ 0.0076, -0.0034,  0.0187,  ...,  0.0278, -0.0174, -0.0046],
        [-0.0037, -0.0002,  0.0051,  ..., -0.0108,  0.0012,  0.0065],
        [-0.0047, -0.0013,  0.0154,  ...,  0.0158, -0.0106,  0.0013]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias': tensor([-0.0001,  0.0002, -0.0072,  ...,  0.0011, -0.0007, -0.0008],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight': tensor([[ 0.0221, -0.0052,  0.0127,  ..., -0.0090, -0.0092, -0.0165],
        [-0.0569, -0.0251, -0.0167,  ..., -0.0070, -0.0093, -0.0182],
        [-0.0159, -0.0159,  0.0239,  ...,  0.0133,  0.0071,  0.0088],
        ...,
        [ 0.0025,  0.0141, -0.0087,  ...,  0.0007, -0.0157, -0.0012],
        [ 0.0053,  0.0023, -0.0199,  ...,  0.0264,  0.0148, -0.0300],
        [-0.0040,  0.0095, -0.0180,  ..., -0.0396, -0.0316, -0.0156]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias': tensor([-0.0095, -0.0084,  0.0243,  ...,  0.1217, -0.0273,  0.0116],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight': tensor([[ 1.3329e-02, -5.8022e-03,  2.2945e-03,  ...,  1.0509e-03,
          2.1591e-02, -3.7422e-03],
        [-1.7593e-02,  9.9182e-03,  2.1652e-02,  ..., -1.7380e-02,
         -1.1452e-02, -1.1536e-02],
        [-4.2648e-03,  3.6955e-06,  8.7585e-03,  ...,  5.5428e-03,
          1.0963e-02, -8.2855e-03],
        ...,
        [ 2.6302e-03, -6.2828e-03,  1.8387e-02,  ...,  2.4658e-02,
         -1.4015e-02, -1.8509e-02],
        [-1.9140e-03, -1.3588e-02, -1.2770e-03,  ..., -1.8143e-02,
         -2.0309e-02, -2.0172e-02],
        [-1.6346e-03,  5.2338e-03, -1.7044e-02,  ..., -4.7073e-03,
          1.5930e-02,  1.8097e-02]], dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias': tensor([ 0.0486, -0.0525, -1.9268,  ...,  0.0309,  0.1466, -0.0662],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight': tensor([[-0.0204,  0.0447, -0.0052,  ...,  0.0069,  0.0077,  0.0218],
        [ 0.0017,  0.0142, -0.0191,  ...,  0.0062, -0.0003,  0.0145],
        [-0.0078,  0.0171, -0.0142,  ..., -0.0220,  0.0106,  0.0089],
        ...,
        [-0.0215, -0.0144, -0.0043,  ...,  0.0026, -0.0030,  0.0222],
        [ 0.0184,  0.0181,  0.0050,  ...,  0.0064, -0.0177,  0.0218],
        [ 0.0176,  0.0081, -0.0153,  ..., -0.0053,  0.0065,  0.0165]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias': tensor([-0.2126,  0.1382,  0.1891,  ...,  0.0073,  0.0610, -0.0497],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight': tensor([1.5518, 1.4453, 1.4551,  ..., 0.8970, 1.4531, 1.5488],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias': tensor([-0.0075, -0.0621, -0.0674,  ..., -0.0965, -0.1760, -0.1098],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight': tensor([[ 0.0173, -0.0038, -0.0434,  ..., -0.0142, -0.0269,  0.0163],
        [ 0.0112,  0.0112, -0.0199,  ...,  0.0013,  0.0100, -0.0072],
        [-0.0037, -0.0045, -0.0143,  ..., -0.0011, -0.0073, -0.0100],
        ...,
        [-0.0162, -0.0028, -0.0142,  ...,  0.0240, -0.0207, -0.0169],
        [ 0.0084,  0.0172, -0.0097,  ..., -0.0170, -0.0171, -0.0099],
        [ 0.0414, -0.0024, -0.0073,  ..., -0.0142,  0.0116,  0.0242]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias': tensor([-0.2035, -0.6177, -0.2632,  ..., -0.2837, -0.4905, -0.3960],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight': tensor([[-0.0123, -0.0106,  0.0170,  ..., -0.0074, -0.0057,  0.0038],
        [ 0.0014, -0.0104, -0.0019,  ...,  0.0073,  0.0064, -0.0129],
        [-0.0083, -0.0003,  0.0169,  ...,  0.0021,  0.0054,  0.0217],
        ...,
        [-0.0205, -0.0112, -0.0028,  ..., -0.0033,  0.0101,  0.0241],
        [ 0.0122, -0.0082,  0.0100,  ..., -0.0086,  0.0083, -0.0369],
        [ 0.0042, -0.0036,  0.0006,  ..., -0.0066,  0.0024,  0.0018]],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias': tensor([ 0.0215, -0.1328, -0.1233,  ..., -0.1167,  0.0634,  0.0916],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight': tensor([1.6230, 1.6143, 1.6387,  ..., 1.4531, 1.7188, 1.8516],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias': tensor([-0.0200, -0.0892,  0.0742,  ...,  0.0301,  0.1517, -0.2600],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight': tensor([0.9370, 1.0215, 0.9346,  ..., 0.8223, 1.0596, 1.0498],
       dtype=torch.float16), 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias': tensor([-0.0060,  0.1511, -0.0550,  ...,  0.2749,  0.0767,  0.0092],
       dtype=torch.float16), 'model.mm_projector.weight': tensor([[ 0.0072, -0.0140,  0.0289,  ...,  0.0244,  0.0162, -0.0064],
        [-0.0050,  0.0072,  0.0063,  ...,  0.0067, -0.0255,  0.0078],
        [-0.0020,  0.0295,  0.0257,  ..., -0.0297, -0.0094,  0.0162],
        ...,
        [ 0.0177, -0.0114,  0.0283,  ..., -0.0087, -0.0018, -0.0121],
        [ 0.0013,  0.0077, -0.0230,  ...,  0.0190, -0.0050, -0.0048],
        [ 0.0148, -0.0061, -0.0175,  ...,  0.0034,  0.0056,  0.0157]]), 'model.mm_projector.bias': tensor([ 0.0027,  0.0012, -0.0269,  ..., -0.0277, -0.0176,  0.0109]), 'model.perceiver.latents': tensor([[ 0.6032,  0.0950, -0.2789,  ..., -1.1298,  0.3825,  2.6381],
        [ 0.8156,  1.4358,  0.3119,  ..., -0.4883,  0.0505,  2.2539],
        [-0.0900,  0.0581,  1.3257,  ...,  0.9346,  0.1754, -0.7460],
        ...,
        [-0.8013,  0.5337,  0.1446,  ..., -1.2057,  0.7441,  1.3946],
        [-0.7536,  0.9410, -1.9765,  ...,  1.2627, -0.1094,  0.8680],
        [ 1.5926,  0.7226, -0.6941,  ...,  1.8635,  0.4667, -0.4463]]), 'model.perceiver.frame_embs': tensor([[ 1.4814e+00, -1.6191e+00,  4.2530e-01,  ...,  5.9107e-01,
         -5.1701e-02,  1.9817e+00],
        [ 8.4224e-01, -2.2240e-01, -1.0839e+00,  ...,  3.1866e-01,
         -6.0578e-04,  8.7571e-01],
        [ 8.2137e-01, -3.1476e-01, -1.6555e+00,  ..., -3.8659e-01,
         -7.5907e-01, -1.5666e-01],
        ...,
        [ 3.0123e-01, -2.9136e-01,  1.1190e+00,  ..., -4.2654e-01,
         -9.2851e-02,  3.5661e-01],
        [ 1.0553e+00,  1.2917e+00,  1.0895e+00,  ...,  8.0592e-01,
          2.4645e-01,  2.5934e-01],
        [-8.4913e-01, -2.0628e-01, -3.6584e-01,  ..., -5.4967e-01,
         -1.5279e-01, -1.3778e-01]]), 'model.perceiver.media_time_embs': tensor([[[-1.4791,  0.1682, -0.4106,  ...,  0.3592,  0.3300, -1.6745]],

        [[ 1.4654, -0.9382, -0.0626,  ..., -1.3758, -0.5422, -0.2111]],

        [[-1.0566, -0.1494,  1.0415,  ...,  0.7451,  1.2115, -0.4175]],

        [[-0.4773,  0.9881, -1.9979,  ..., -0.9499, -0.2747, -0.0507]]]), 'model.perceiver.layers.0.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.0.to_q.weight': tensor([[ 0.0069,  0.0083,  0.0022,  ...,  0.0147,  0.0140, -0.0023],
        [ 0.0052,  0.0017, -0.0149,  ...,  0.0026,  0.0041, -0.0050],
        [ 0.0036,  0.0033,  0.0113,  ...,  0.0134, -0.0144,  0.0112],
        ...,
        [ 0.0018, -0.0026, -0.0067,  ...,  0.0052, -0.0045,  0.0120],
        [-0.0006, -0.0044, -0.0021,  ..., -0.0121, -0.0150, -0.0085],
        [ 0.0012,  0.0079, -0.0014,  ...,  0.0011,  0.0036,  0.0048]]), 'model.perceiver.layers.0.0.to_kv.weight': tensor([[ 8.5164e-03,  1.1414e-02, -1.0980e-02,  ..., -4.0598e-03,
         -7.6216e-05, -7.5744e-03],
        [-3.6716e-03, -3.3753e-04,  1.4421e-02,  ...,  1.3401e-02,
          2.9648e-03,  8.9951e-03],
        [-7.2066e-03,  3.5412e-03, -7.4685e-03,  ...,  1.7088e-03,
          1.3631e-02,  4.3441e-03],
        ...,
        [-1.3179e-02,  7.4671e-04, -7.3211e-03,  ...,  1.0958e-02,
          4.9095e-04, -9.3363e-03],
        [ 1.3956e-02, -9.1964e-03, -4.5210e-04,  ..., -1.1833e-02,
          1.4250e-02,  8.4286e-03],
        [ 1.3202e-04,  1.1253e-03,  3.6920e-03,  ..., -2.6721e-03,
          6.8727e-04,  3.6197e-03]]), 'model.perceiver.layers.0.0.to_out.weight': tensor([[ 0.0312,  0.0222,  0.0116,  ..., -0.0258, -0.0258, -0.0378],
        [ 0.0334,  0.0250,  0.0115,  ..., -0.0085,  0.0142,  0.0094],
        [-0.0422, -0.0224, -0.0058,  ..., -0.0079,  0.0179, -0.0418],
        ...,
        [-0.0003, -0.0180, -0.0265,  ...,  0.0222,  0.0387, -0.0166],
        [ 0.0030,  0.0304, -0.0203,  ..., -0.0095,  0.0266,  0.0252],
        [-0.0112, -0.0353, -0.0136,  ..., -0.0133, -0.0139,  0.0033]]), 'model.perceiver.layers.0.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.0.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.0.1.1.weight': tensor([[ 0.0150, -0.0133, -0.0020,  ..., -0.0017,  0.0118, -0.0120],
        [-0.0051, -0.0088, -0.0033,  ..., -0.0120,  0.0011, -0.0042],
        [ 0.0070, -0.0129,  0.0095,  ..., -0.0037,  0.0131, -0.0075],
        ...,
        [-0.0154, -0.0016, -0.0105,  ..., -0.0124, -0.0100,  0.0146],
        [ 0.0084, -0.0071,  0.0081,  ...,  0.0010,  0.0137,  0.0133],
        [ 0.0089, -0.0015,  0.0126,  ..., -0.0068, -0.0020, -0.0032]]), 'model.perceiver.layers.0.1.3.weight': tensor([[-0.0041, -0.0024, -0.0016,  ..., -0.0074,  0.0045,  0.0021],
        [ 0.0078,  0.0041, -0.0022,  ...,  0.0021, -0.0067,  0.0022],
        [-0.0059, -0.0046, -0.0070,  ...,  0.0075, -0.0059, -0.0039],
        ...,
        [-0.0065, -0.0077,  0.0055,  ...,  0.0058, -0.0047,  0.0023],
        [ 0.0024,  0.0042, -0.0009,  ...,  0.0059, -0.0067, -0.0015],
        [ 0.0032, -0.0046,  0.0059,  ...,  0.0045, -0.0071, -0.0003]]), 'model.perceiver.layers.1.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.0.to_q.weight': tensor([[ 1.2987e-02,  1.5473e-02, -4.5730e-03,  ..., -3.1023e-03,
         -1.5128e-02,  1.7237e-05],
        [ 3.6099e-03, -4.2390e-03, -4.0067e-03,  ...,  8.2509e-03,
          1.1910e-02, -4.1502e-03],
        [-9.6685e-03,  9.1863e-03,  1.0409e-02,  ..., -1.3244e-02,
         -5.4626e-04, -7.3949e-04],
        ...,
        [-1.3482e-02,  1.3840e-02, -1.0447e-02,  ..., -6.8017e-03,
          1.4218e-02,  7.8849e-03],
        [-3.2466e-03,  1.2187e-02, -1.1135e-02,  ..., -5.2421e-03,
         -1.2553e-02,  1.0316e-02],
        [-1.2678e-02,  1.2456e-02, -1.5331e-04,  ..., -4.7636e-03,
         -1.2789e-02, -1.0441e-02]]), 'model.perceiver.layers.1.0.to_kv.weight': tensor([[-0.0047, -0.0156,  0.0101,  ..., -0.0122, -0.0048, -0.0077],
        [ 0.0113, -0.0052,  0.0134,  ...,  0.0072,  0.0036,  0.0033],
        [-0.0074,  0.0150, -0.0093,  ...,  0.0140, -0.0131,  0.0055],
        ...,
        [-0.0088, -0.0088,  0.0052,  ...,  0.0069,  0.0085,  0.0137],
        [ 0.0144,  0.0042,  0.0052,  ..., -0.0141,  0.0066,  0.0029],
        [ 0.0029,  0.0074,  0.0103,  ..., -0.0155,  0.0124,  0.0009]]), 'model.perceiver.layers.1.0.to_out.weight': tensor([[-0.0099,  0.0319, -0.0163,  ..., -0.0228,  0.0385, -0.0019],
        [ 0.0231,  0.0103, -0.0280,  ...,  0.0230,  0.0127, -0.0340],
        [-0.0078, -0.0366, -0.0197,  ..., -0.0334, -0.0430,  0.0255],
        ...,
        [-0.0045, -0.0321,  0.0075,  ...,  0.0288, -0.0219, -0.0250],
        [ 0.0432, -0.0429, -0.0174,  ...,  0.0112,  0.0413, -0.0339],
        [-0.0015,  0.0177,  0.0218,  ..., -0.0144,  0.0143,  0.0024]]), 'model.perceiver.layers.1.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.1.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.1.1.1.weight': tensor([[-5.3199e-03, -4.0362e-03, -3.0209e-04,  ..., -5.2299e-03,
         -9.9329e-03, -1.1200e-02],
        [ 1.2682e-03,  7.6645e-03,  1.4387e-02,  ..., -1.2078e-02,
          1.1053e-02,  1.1931e-02],
        [ 4.2276e-03,  1.4896e-03,  6.5730e-03,  ...,  2.6497e-03,
          1.0768e-02,  1.4477e-03],
        ...,
        [-1.1489e-02, -1.2327e-02,  1.1230e-02,  ..., -4.8288e-03,
          6.0900e-03, -8.6558e-03],
        [ 8.1196e-03,  7.3673e-03, -1.6185e-04,  ..., -9.8495e-03,
          5.9790e-03,  7.3267e-03],
        [ 1.0321e-02, -1.0219e-02, -1.0177e-02,  ..., -7.7895e-04,
          1.4623e-02,  4.0848e-05]]), 'model.perceiver.layers.1.1.3.weight': tensor([[-0.0010, -0.0064,  0.0017,  ...,  0.0003,  0.0001,  0.0038],
        [-0.0032,  0.0051, -0.0064,  ...,  0.0061, -0.0041,  0.0061],
        [ 0.0024, -0.0055, -0.0008,  ...,  0.0057,  0.0048, -0.0037],
        ...,
        [-0.0005,  0.0032,  0.0025,  ...,  0.0032, -0.0010,  0.0078],
        [ 0.0037, -0.0058,  0.0044,  ..., -0.0037, -0.0072, -0.0072],
        [ 0.0031, -0.0053, -0.0034,  ..., -0.0057,  0.0008,  0.0006]]), 'model.perceiver.layers.2.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.0.to_q.weight': tensor([[ 0.0060,  0.0100,  0.0155,  ...,  0.0079,  0.0101,  0.0039],
        [-0.0132,  0.0099,  0.0081,  ...,  0.0058, -0.0062,  0.0128],
        [-0.0059,  0.0082,  0.0076,  ...,  0.0040,  0.0101, -0.0082],
        ...,
        [ 0.0069, -0.0013, -0.0104,  ...,  0.0111, -0.0102,  0.0054],
        [-0.0110,  0.0092,  0.0108,  ...,  0.0025, -0.0145, -0.0033],
        [-0.0132, -0.0029,  0.0127,  ..., -0.0135, -0.0031,  0.0129]]), 'model.perceiver.layers.2.0.to_kv.weight': tensor([[-0.0125,  0.0015, -0.0143,  ...,  0.0025,  0.0102,  0.0032],
        [-0.0045,  0.0034, -0.0153,  ..., -0.0130,  0.0098, -0.0063],
        [ 0.0063, -0.0106,  0.0156,  ..., -0.0153, -0.0153,  0.0118],
        ...,
        [-0.0141, -0.0125,  0.0099,  ..., -0.0080, -0.0112, -0.0025],
        [-0.0122,  0.0058,  0.0142,  ...,  0.0056,  0.0076, -0.0100],
        [-0.0003, -0.0095, -0.0112,  ...,  0.0101,  0.0002, -0.0060]]), 'model.perceiver.layers.2.0.to_out.weight': tensor([[ 0.0115, -0.0250,  0.0189,  ...,  0.0211,  0.0079, -0.0072],
        [ 0.0091,  0.0246,  0.0354,  ..., -0.0105, -0.0102,  0.0128],
        [-0.0175,  0.0358,  0.0397,  ..., -0.0303,  0.0343,  0.0142],
        ...,
        [ 0.0292, -0.0294,  0.0146,  ...,  0.0084, -0.0366,  0.0270],
        [-0.0295,  0.0095, -0.0367,  ..., -0.0006, -0.0427,  0.0399],
        [-0.0030,  0.0176, -0.0372,  ..., -0.0118, -0.0062,  0.0293]]), 'model.perceiver.layers.2.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.2.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.2.1.1.weight': tensor([[ 2.1907e-04, -9.7492e-03,  2.6583e-03,  ...,  8.3316e-03,
          3.9435e-03,  9.8320e-03],
        [ 5.9586e-03, -1.5308e-02,  1.0731e-02,  ..., -1.2692e-02,
          8.3521e-03, -1.4447e-02],
        [ 1.2781e-02, -1.0554e-03, -8.0503e-03,  ..., -8.9854e-03,
          1.1257e-02, -1.4745e-02],
        ...,
        [-3.9914e-03, -1.0505e-02,  4.2174e-03,  ...,  1.2511e-02,
          2.3478e-03,  8.2803e-03],
        [ 1.2891e-02,  1.2370e-03,  1.1292e-02,  ..., -1.2246e-02,
          1.1382e-03, -6.6663e-03],
        [-1.4478e-02, -1.4484e-02, -2.2352e-08,  ...,  1.2100e-02,
         -7.0019e-03, -1.2963e-02]]), 'model.perceiver.layers.2.1.3.weight': tensor([[ 0.0014,  0.0008,  0.0048,  ..., -0.0016, -0.0055,  0.0043],
        [-0.0078, -0.0046,  0.0029,  ..., -0.0052, -0.0073,  0.0071],
        [ 0.0026,  0.0006,  0.0036,  ...,  0.0066,  0.0077, -0.0003],
        ...,
        [ 0.0054, -0.0065, -0.0025,  ...,  0.0070, -0.0015, -0.0002],
        [ 0.0035, -0.0049,  0.0012,  ...,  0.0026, -0.0043, -0.0001],
        [ 0.0065,  0.0053,  0.0069,  ..., -0.0017, -0.0008,  0.0045]]), 'model.perceiver.layers.3.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.0.to_q.weight': tensor([[ 0.0156,  0.0125,  0.0108,  ...,  0.0007, -0.0088,  0.0056],
        [-0.0008,  0.0008,  0.0081,  ...,  0.0145,  0.0097, -0.0023],
        [-0.0063,  0.0153, -0.0013,  ..., -0.0060,  0.0069, -0.0060],
        ...,
        [-0.0039, -0.0007, -0.0017,  ..., -0.0127, -0.0116, -0.0118],
        [ 0.0028, -0.0119,  0.0020,  ..., -0.0081, -0.0152, -0.0020],
        [-0.0145, -0.0108, -0.0110,  ..., -0.0124,  0.0009,  0.0132]]), 'model.perceiver.layers.3.0.to_kv.weight': tensor([[-0.0084, -0.0038, -0.0049,  ...,  0.0069, -0.0021,  0.0064],
        [-0.0018,  0.0083,  0.0008,  ...,  0.0063,  0.0079, -0.0112],
        [-0.0015,  0.0005, -0.0063,  ..., -0.0070, -0.0023, -0.0057],
        ...,
        [-0.0047, -0.0084, -0.0141,  ...,  0.0054, -0.0068, -0.0095],
        [ 0.0105,  0.0142, -0.0013,  ..., -0.0125, -0.0003, -0.0061],
        [ 0.0098,  0.0127,  0.0056,  ..., -0.0088,  0.0056,  0.0124]]), 'model.perceiver.layers.3.0.to_out.weight': tensor([[ 2.5981e-03,  3.6020e-03, -8.4773e-05,  ...,  2.8115e-02,
          5.2472e-03,  4.2587e-02],
        [ 2.0717e-02, -6.1610e-03,  1.1248e-02,  ...,  4.5502e-03,
          9.3435e-03,  3.4013e-02],
        [ 3.5680e-02, -6.7723e-03,  2.6100e-02,  ...,  7.8936e-03,
          4.3178e-02,  5.5746e-03],
        ...,
        [-2.0254e-02, -2.7215e-03, -1.3026e-02,  ...,  4.3575e-02,
          4.8923e-03,  2.3311e-02],
        [-5.5761e-03, -1.7991e-02,  4.6981e-03,  ...,  1.2925e-03,
          3.7052e-02,  1.1038e-03],
        [ 1.9971e-02, -1.9638e-02,  4.0009e-02,  ...,  4.8555e-03,
         -2.1635e-02, -4.0092e-02]]), 'model.perceiver.layers.3.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.3.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.3.1.1.weight': tensor([[-0.0123, -0.0129,  0.0031,  ...,  0.0127, -0.0024, -0.0053],
        [ 0.0075, -0.0083,  0.0135,  ..., -0.0103,  0.0095, -0.0073],
        [-0.0132, -0.0053, -0.0055,  ..., -0.0063,  0.0145,  0.0118],
        ...,
        [ 0.0061, -0.0061, -0.0025,  ..., -0.0153, -0.0047, -0.0006],
        [-0.0072, -0.0032,  0.0051,  ..., -0.0023, -0.0049, -0.0127],
        [ 0.0040,  0.0085, -0.0131,  ...,  0.0087, -0.0063, -0.0129]]), 'model.perceiver.layers.3.1.3.weight': tensor([[ 0.0030,  0.0049, -0.0076,  ...,  0.0004,  0.0048,  0.0050],
        [-0.0033, -0.0059,  0.0047,  ...,  0.0064, -0.0071,  0.0013],
        [-0.0019,  0.0010, -0.0004,  ...,  0.0034, -0.0064, -0.0025],
        ...,
        [-0.0042, -0.0012,  0.0059,  ..., -0.0059,  0.0068,  0.0057],
        [ 0.0015,  0.0006,  0.0003,  ...,  0.0046,  0.0041,  0.0025],
        [ 0.0016, -0.0017,  0.0041,  ...,  0.0025,  0.0021,  0.0074]]), 'model.perceiver.layers.4.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.0.to_q.weight': tensor([[-0.0045,  0.0102,  0.0069,  ...,  0.0124, -0.0085,  0.0004],
        [-0.0041,  0.0100,  0.0102,  ...,  0.0093, -0.0106,  0.0030],
        [-0.0122, -0.0111,  0.0084,  ..., -0.0041,  0.0103,  0.0044],
        ...,
        [-0.0132, -0.0062, -0.0117,  ...,  0.0106, -0.0135, -0.0065],
        [-0.0029, -0.0095, -0.0097,  ...,  0.0127,  0.0051, -0.0130],
        [-0.0152,  0.0034, -0.0112,  ...,  0.0135,  0.0094, -0.0041]]), 'model.perceiver.layers.4.0.to_kv.weight': tensor([[ 0.0099, -0.0061,  0.0006,  ..., -0.0052, -0.0025,  0.0065],
        [ 0.0106,  0.0070,  0.0090,  ..., -0.0104,  0.0059,  0.0075],
        [-0.0041, -0.0009,  0.0125,  ..., -0.0111, -0.0041, -0.0058],
        ...,
        [ 0.0146, -0.0080,  0.0009,  ...,  0.0096,  0.0007,  0.0075],
        [ 0.0148, -0.0125,  0.0108,  ..., -0.0134, -0.0089,  0.0094],
        [ 0.0119, -0.0087, -0.0059,  ..., -0.0036,  0.0071,  0.0029]]), 'model.perceiver.layers.4.0.to_out.weight': tensor([[-0.0252, -0.0302,  0.0287,  ..., -0.0333, -0.0318,  0.0053],
        [ 0.0017, -0.0322,  0.0177,  ..., -0.0250, -0.0364, -0.0355],
        [-0.0245,  0.0434, -0.0395,  ...,  0.0271, -0.0038, -0.0360],
        ...,
        [-0.0334,  0.0248, -0.0085,  ..., -0.0020,  0.0165, -0.0117],
        [ 0.0362,  0.0245, -0.0401,  ...,  0.0115,  0.0393,  0.0044],
        [ 0.0100,  0.0073,  0.0122,  ...,  0.0037, -0.0398, -0.0191]]), 'model.perceiver.layers.4.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.4.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.4.1.1.weight': tensor([[ 0.0093,  0.0027,  0.0013,  ..., -0.0017,  0.0031,  0.0039],
        [ 0.0073,  0.0073, -0.0052,  ...,  0.0025, -0.0120,  0.0127],
        [ 0.0058, -0.0130, -0.0051,  ..., -0.0123, -0.0107, -0.0069],
        ...,
        [-0.0067, -0.0138,  0.0122,  ...,  0.0040,  0.0080, -0.0032],
        [-0.0150, -0.0118, -0.0097,  ...,  0.0075,  0.0012,  0.0024],
        [-0.0112,  0.0150, -0.0125,  ...,  0.0117,  0.0091, -0.0002]]), 'model.perceiver.layers.4.1.3.weight': tensor([[ 0.0041,  0.0002,  0.0073,  ..., -0.0016, -0.0037,  0.0037],
        [-0.0061,  0.0057, -0.0046,  ..., -0.0074, -0.0026,  0.0006],
        [ 0.0019, -0.0075,  0.0028,  ..., -0.0053, -0.0050, -0.0028],
        ...,
        [ 0.0052,  0.0027,  0.0053,  ...,  0.0021, -0.0074,  0.0077],
        [-0.0074,  0.0028, -0.0059,  ..., -0.0020,  0.0010, -0.0003],
        [-0.0023, -0.0042,  0.0014,  ...,  0.0025,  0.0062,  0.0039]]), 'model.perceiver.layers.5.0.norm_media.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_media.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.norm_latents.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.0.norm_latents.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.0.to_q.weight': tensor([[-0.0024, -0.0057, -0.0131,  ...,  0.0008,  0.0136, -0.0116],
        [ 0.0044,  0.0073,  0.0068,  ...,  0.0077, -0.0024,  0.0007],
        [-0.0126,  0.0023, -0.0152,  ...,  0.0043,  0.0076,  0.0126],
        ...,
        [-0.0093,  0.0143, -0.0137,  ..., -0.0146,  0.0035,  0.0084],
        [ 0.0018, -0.0009, -0.0103,  ...,  0.0090,  0.0009,  0.0154],
        [-0.0064,  0.0075,  0.0100,  ..., -0.0005, -0.0049, -0.0034]]), 'model.perceiver.layers.5.0.to_kv.weight': tensor([[-0.0062, -0.0035, -0.0036,  ...,  0.0044,  0.0095, -0.0063],
        [ 0.0112,  0.0038,  0.0018,  ..., -0.0083,  0.0100,  0.0154],
        [-0.0059, -0.0107,  0.0149,  ..., -0.0100, -0.0136,  0.0049],
        ...,
        [ 0.0015, -0.0089, -0.0100,  ..., -0.0154, -0.0026, -0.0156],
        [-0.0056, -0.0036,  0.0085,  ..., -0.0041,  0.0043,  0.0146],
        [-0.0123,  0.0117,  0.0020,  ..., -0.0002, -0.0030, -0.0059]]), 'model.perceiver.layers.5.0.to_out.weight': tensor([[-0.0155, -0.0378, -0.0289,  ..., -0.0189, -0.0301, -0.0169],
        [-0.0388,  0.0242, -0.0271,  ..., -0.0256,  0.0354,  0.0296],
        [-0.0138,  0.0043,  0.0104,  ..., -0.0211,  0.0376, -0.0008],
        ...,
        [-0.0297, -0.0146, -0.0316,  ..., -0.0355, -0.0441,  0.0151],
        [ 0.0039, -0.0196, -0.0160,  ...,  0.0044, -0.0173,  0.0402],
        [-0.0200,  0.0263,  0.0235,  ...,  0.0190,  0.0244,  0.0023]]), 'model.perceiver.layers.5.1.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.layers.5.1.0.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'model.perceiver.layers.5.1.1.weight': tensor([[-1.4902e-03, -4.5672e-03,  1.4304e-02,  ...,  3.3130e-03,
          1.3409e-02, -9.5835e-03],
        [-7.2341e-03, -1.1365e-02,  8.5967e-03,  ...,  1.1049e-02,
          3.2453e-03,  5.7602e-05],
        [-1.4108e-02, -1.7602e-03,  8.4716e-03,  ...,  1.2884e-02,
          9.6835e-03,  1.1000e-02],
        ...,
        [-8.0789e-03, -1.1689e-02, -9.6140e-04,  ..., -1.0342e-02,
         -1.4696e-02,  7.4580e-06],
        [-6.8127e-03, -9.9356e-03, -5.9147e-03,  ..., -3.0173e-03,
          4.2396e-03, -6.8815e-03],
        [ 1.0204e-02, -9.9582e-03, -6.4458e-03,  ..., -3.8580e-03,
         -1.5448e-02, -3.4449e-03]]), 'model.perceiver.layers.5.1.3.weight': tensor([[-1.7416e-04,  5.3361e-04, -4.7353e-03,  ..., -5.2820e-03,
         -6.6317e-03,  3.3630e-03],
        [ 7.4265e-03, -2.6545e-03, -5.2088e-04,  ..., -5.5110e-03,
          1.1782e-03,  6.9235e-03],
        [ 2.8094e-03, -6.4806e-03,  4.7203e-03,  ...,  5.2703e-05,
         -7.5102e-03,  6.7620e-03],
        ...,
        [-3.0121e-03, -6.1413e-03,  7.1862e-03,  ...,  4.9993e-03,
          5.2702e-03,  2.9280e-03],
        [ 6.7078e-03, -1.6007e-03,  6.2233e-03,  ...,  5.8095e-03,
         -1.5011e-03,  1.2993e-05],
        [-4.7408e-03, -2.7836e-03,  4.0790e-03,  ...,  7.5779e-04,
          3.6262e-03,  6.9641e-03]]), 'model.perceiver.norm.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'model.perceiver.norm.bias': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'lm_head.weight': tensor([[-0.0058, -0.0009, -0.0071,  ...,  0.0035, -0.0099,  0.0190],
        [-0.0278,  0.0547, -0.0115,  ..., -0.0232,  0.0147,  0.0332],
        [-0.0140, -0.0099,  0.0201,  ..., -0.0344,  0.0142, -0.0150],
        ...,
        [-0.0243,  0.0031,  0.0008,  ..., -0.0046,  0.0029, -0.0072],
        [ 0.0070,  0.0007,  0.0051,  ..., -0.0131, -0.0103, -0.0041],
        [-0.0041, -0.0077, -0.0308,  ...,  0.0179,  0.0084,  0.0356]],
       dtype=torch.float16)}
[2023-11-15 07:14:35,664] [INFO] [launch.py:347:main] Process 65074 exits successfully.
[2023-11-15 07:14:35,664] [INFO] [launch.py:347:main] Process 65073 exits successfully.
[2023-11-15 07:14:35,664] [INFO] [launch.py:347:main] Process 65071 exits successfully.
[2023-11-15 07:14:36,666] [INFO] [launch.py:347:main] Process 65069 exits successfully.
[INFO] Medical save done, finish
[2023-11-15 07:15:02,694] [INFO] [launch.py:347:main] Process 65067 exits successfully.
